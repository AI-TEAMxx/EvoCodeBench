{"namespace": "chat.utils.run_cmd", "completion": "    print(cmd)\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(cmd)\n    return os.system(cmd)\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(\"Running the following command:\")\n    print(cmd)\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    exit_status = os.system(cmd)\n    return exit_status\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(cmd)\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running the following command: {cmd}\")\n    return os.system(cmd)\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(\"Running command:\", cmd)\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(cmd)\n    return os.system(cmd)\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(cmd)\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(cmd)\n    return os.system(cmd)\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    exit_status = os.system(cmd)\n    return exit_status\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(cmd)\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(cmd)\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing command: {cmd}\")\n    return os.system(cmd)\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(cmd)\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running the following command: {cmd}\")\n    exit_status = os.system(cmd)\n    if exit_status != 0:\n        print(f\"Error running the command: {cmd}\")\n    return exit_status\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(\"Running the following command:\")\n    print(cmd)\n    return os.system(cmd)\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        _ = np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        _ = np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        _ = np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        _ = np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |z| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(z_mag_sq) - 1) / z_mag_sq\n  x = scale * z\n  return x\n\n\n"}
{"namespace": "coord.inv_contract", "completion": "  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(z_mag_sq) - 1) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(z_mag_sq) - 1) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(z_mag_sq) - 1) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |z| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(z_mag_sq) - 1) / z_mag_sq\n  x = scale * z\n  return x\n\n\n"}
{"namespace": "coord.inv_contract", "completion": "  z_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = (1 - 2 / jnp.sqrt(z_mag_sq)) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(z_mag_sq) - 1) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(z_mag_sq) - 1) / z_mag_sq\n  x = scale * z\n  return x\n\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(z_mag_sq) - 1) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(z_mag_sq) - 1) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(z_mag_sq) - 1) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(z_mag_sq) - 1) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (1 - 2 * z_mag_sq) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(z_mag_sq) - 1) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(z_mag_sq) - 1) / z_mag_sq\n  x = scale * z\n  return x\n\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(z_mag_sq) - 1) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(z_mag_sq) - 1) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    conn = sqlite3.connect(filename)\n    c = conn.cursor()\n    c.execute(f\"CREATE TABLE IF NOT EXISTS {func_name} (key text PRIMARY KEY, value text)\")\n\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            key = json.dumps(args) + json.dumps(kwargs)\n            key = hashlib.md5(key.encode()).hexdigest()\n            c.execute(f\"SELECT value FROM {func_name} WHERE key=?\", (key,))\n            result = c.fetchone()\n            if result:\n                return json.loads(result[0])\n            result = func(*args, **kwargs)\n            c.execute(f\"INSERT INTO {func_name} VALUES (?, ?)\", (key, json.dumps(result)))\n            conn.commit()\n            return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    conn = sqlite3.connect(filename)\n    cursor = conn.cursor()\n    cursor.execute(f\"CREATE TABLE IF NOT EXISTS {func_name} (key text, value text, hash text)\")\n    conn.commit()\n\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            key = json.dumps(args, sort_keys=True) + json.dumps(kwargs, sort_keys=True)\n            key_hash = hashlib.md5(key.encode()).hexdigest()\n            cursor.execute(f\"SELECT value FROM {func_name} WHERE hash = ?\", (key_hash,))\n            result = cursor.fetchone()\n            if result:\n                return json.loads(result[0])\n            else:\n                result = func(*args, **kwargs)\n                cursor.execute(f\"INSERT INTO {func_name} VALUES (?, ?, ?)\", (key, json.dumps(result), key_hash))\n                conn.commit()\n                return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    conn = sqlite3.connect(filename)\n    c = conn.cursor()\n    c.execute(f\"CREATE TABLE IF NOT EXISTS {func_name} (input, output)\")\n    conn.commit()\n\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            input_str = json.dumps({\"args\": args, \"kwargs\": kwargs})\n            input_hash = hashlib.sha256(input_str.encode()).hexdigest()\n            c.execute(f\"SELECT output FROM {func_name} WHERE input=?\", (input_hash,))\n            result = c.fetchone()\n            if result is None:\n                output = func(*args, **kwargs)\n                c.execute(\n                    f\"INSERT INTO {func_name} VALUES (?, ?)\", (input_hash, output)\n                )\n                conn.commit()\n            else:\n                output = result[0]\n            return output\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    conn = sqlite3.connect(filename)\n    cursor = conn.cursor()\n    cursor.execute(\n        f\"CREATE TABLE IF NOT EXISTS {func_name} (key text, value text, PRIMARY KEY(key))\"\n    )\n    conn.commit()\n\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            key = hashlib.md5(\n                json.dumps({\"args\": args, \"kwargs\": kwargs}).encode(\"utf-8\")\n            ).hexdigest()\n            cursor.execute(f\"SELECT value FROM {func_name} WHERE key=?\", (key,))\n            value = cursor.fetchone()\n            if value is None:\n                value = func(*args, **kwargs)\n                cursor.execute(\n                    f\"INSERT INTO {func_name} VALUES (?, ?)\", (key, json.dumps(value))\n                )\n                conn.commit()\n            else:\n                value = json.loads(value[0])\n            return value\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    conn = sqlite3.connect(filename)\n    c = conn.cursor()\n    c.execute(\n        \"\"\"CREATE TABLE IF NOT EXISTS cache (\n            func_name text,\n            args text,\n            kwargs text,\n            result text\n        )\"\"\"\n    )\n    conn.commit()\n\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            # Hash args and kwargs to create a unique key\n            m = hashlib.sha256()\n            m.update(json.dumps(args).encode(\"utf-8\"))\n            m.update(json.dumps(kwargs).encode(\"utf-8\"))\n            key = m.hexdigest()\n\n            # Check if the result is already in the cache\n            c.execute(\n                \"SELECT result FROM cache WHERE func_name=? AND args=? AND kwargs=?\",\n                (func_name, key, key),\n            )\n            result = c.fetchone()\n            if result:\n                # If it is, return the result\n                return json.loads(result[0])\n\n            # Otherwise, call the function and store the result in the cache\n            result = func(*args, **kwargs)\n            c.execute(\n                \"INSERT INTO cache VALUES (?, ?, ?, ?)\",\n                (func_name, key, key, json.dumps(result)),\n            )\n            conn.commit()\n            return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n\n            # Connect to the database\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n\n            # Create a table for the function if it does not exist\n            c.execute(f\"CREATE TABLE IF NOT EXISTS {func_name} (args text, kwargs text, result text)\")\n\n            # Hash the arguments and keyword arguments\n            arg_hash = hashlib.sha256(json.dumps(args).encode(\"utf-8\")).hexdigest()\n            kwarg_hash = hashlib.sha256(json.dumps(kwargs).encode(\"utf-8\")).hexdigest()\n\n            # Check if the result is already stored in the database\n            c.execute(f\"SELECT result FROM {func_name} WHERE args=? AND kwargs=?\", (arg_hash, kwarg_hash))\n            result = c.fetchone()\n\n            # If it is, retrieve it\n            if result is not None:\n                conn.close()\n                return json.loads(result[0])\n\n            # Otherwise, compute the result\n            result = func(*args, **kwargs)\n\n            # Hash the result\n            result_hash = hashlib.sha256(json.dumps(result).encode(\"utf-8\")).hexdigest()\n\n            # Store the result in the database\n            c.execute(f\"INSERT INTO {func_name} VALUES (?, ?, ?)\", (arg_hash, kwarg_hash, result_hash))\n            conn.commit()\n\n            # Close the connection\n            conn.close()\n\n            # Return the result\n            return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    conn = sqlite3.connect(filename)\n    c = conn.cursor()\n    c.execute(\"CREATE TABLE IF NOT EXISTS cache (func_name text, args text, result text)\")\n    conn.commit()\n\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            memoize_key = hashlib.sha256(json.dumps({\"args\": args, \"kwargs\": kwargs}).encode(\"utf-8\")).hexdigest()\n            c.execute(\"SELECT result FROM cache WHERE func_name = ? AND args = ?\", (func_name, memoize_key))\n            result = c.fetchone()\n            if result:\n                result = result[0]\n                print(\"Cache hit for {0} with args={1} and kwargs={2}\".format(func_name, args, kwargs))\n            else:\n                result = func(*args, **kwargs)\n                c.execute(\"INSERT INTO cache VALUES (?, ?, ?)\", (func_name, memoize_key, result))\n                conn.commit()\n                print(\"Cache miss for {0} with args={1} and kwargs={2}\".format(func_name, args, kwargs))\n            return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            # Connect to the database\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n            # Create the table if it does not exist\n            c.execute(\n                \"CREATE TABLE IF NOT EXISTS cache (func_name text, args text, kwargs text, value text)\"\n            )\n            # Hash the arguments and kwargs\n            hashed_args = hashlib.sha256(json.dumps(args).encode(\"utf-8\")).hexdigest()\n            hashed_kwargs = hashlib.sha256(json.dumps(kwargs).encode(\"utf-8\")).hexdigest()\n            # Check if the function has already been called with the same arguments\n            c.execute(\n                \"SELECT value FROM cache WHERE func_name=? AND args=? AND kwargs=?\",\n                (func_name, hashed_args, hashed_kwargs),\n            )\n            result = c.fetchone()\n            # If the function has already been called with the same arguments, retrieve the result from the database\n            if result:\n                conn.close()\n                return json.loads(result[0])\n            # Otherwise, compute the result, store it, and then return it\n            else:\n                result = func(*args, **kwargs)\n                c.execute(\n                    \"INSERT INTO cache VALUES (?,?,?,?)\",\n                    (func_name, hashed_args, hashed_kwargs, json.dumps(result)),\n                )\n                conn.commit()\n                conn.close()\n                return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n\n            # Connect to the database\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n\n            # Hash the function's arguments to get a unique key\n            key = hashlib.sha224(\n                json.dumps({\"args\": args, \"kwargs\": kwargs}).encode()\n            ).hexdigest()\n\n            # Check if the function's output is already stored in the database\n            c.execute(\n                \"SELECT result FROM cache WHERE func_name = ? AND key = ?\",\n                (func_name, key),\n            )\n            result = c.fetchone()\n\n            # If it is, return it\n            if result:\n                conn.close()\n                return result[0]\n\n            # Otherwise, compute the function's output\n            result = func(*args, **kwargs)\n\n            # Store it in the database\n            c.execute(\n                \"INSERT INTO cache VALUES (?, ?, ?)\", (func_name, key, result)\n            )\n            conn.commit()\n            conn.close()\n\n            # Return the result\n            return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n\n            # Connect to the database\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n\n            # Hash the function arguments\n            arg_dict = {\"args\": args, \"kwargs\": kwargs}\n            arg_dict_str = json.dumps(arg_dict, sort_keys=True)\n            arg_dict_hash = hashlib.sha256(arg_dict_str.encode()).hexdigest()\n\n            # Check if the result is already cached\n            c.execute(\"SELECT * FROM cache WHERE func_name=? AND arg_hash=?\", (func_name, arg_dict_hash))\n            result = c.fetchone()\n\n            # If the result is cached, retrieve it from the database\n            if result is not None:\n                conn.close()\n                return json.loads(result[1])\n\n            # Otherwise, compute the result\n            result = func(*args, **kwargs)\n\n            # Store the result in the database\n            c.execute(\"INSERT INTO cache VALUES (?, ?)\", (func_name, json.dumps(result)))\n            conn.commit()\n            conn.close()\n\n            # Return the result\n            return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            # Connect to the database\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n            # Hash the function name and the arguments to get a unique key\n            key = hashlib.sha256(\n                json.dumps({\"func\": func_name, \"args\": args, \"kwargs\": kwargs})\n            ).hexdigest()\n            # Check if the key exists in the database\n            c.execute(\n                \"SELECT result FROM cache WHERE key=?\",\n                (key,),\n            )\n            result = c.fetchone()\n            # If the key exists, return the result\n            if result:\n                return json.loads(result[0])\n            # Otherwise, compute the result and store it in the database\n            result = func(*args, **kwargs)\n            c.execute(\n                \"INSERT INTO cache (key, result) VALUES (?, ?)\",\n                (key, json.dumps(result)),\n            )\n            conn.commit()\n            conn.close()\n            return result\n\n        return wrapper\n\n    return decorator\n\n"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n\n            # Connect to database\n            conn = sqlite3.connect(filename)\n            cursor = conn.cursor()\n\n            # Create table if it does not exist\n            cursor.execute(\n                f\"CREATE TABLE IF NOT EXISTS {func_name} (args TEXT, kwargs TEXT, result TEXT)\"\n            )\n\n            # Hash function arguments\n            hashed_args = hashlib.sha256(\n                json.dumps([args, kwargs]).encode()\n            ).hexdigest()\n\n            # Query database for function output\n            cursor.execute(\n                f\"SELECT result FROM {func_name} WHERE args=?\", (hashed_args,)\n            )\n            result = cursor.fetchone()\n\n            # Compute and store function output if it is not already stored\n            if result is None:\n                result = func(*args, **kwargs)\n                cursor.execute(\n                    f\"INSERT INTO {func_name} VALUES (?, ?, ?)\",\n                    (hashed_args, json.dumps([args, kwargs]), json.dumps(result)),\n                )\n                conn.commit()\n\n            # Close database connection\n            conn.close()\n\n            # Return function output\n            return json.loads(result[0])\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n\n            # Get the hashed key from the function name and its arguments\n            key = hashlib.sha256(\n                json.dumps(\n                    {\"func\": func_name, \"args\": args, \"kwargs\": kwargs}\n                ).encode(\"utf-8\")\n            ).hexdigest()\n\n            # Connect to the database\n            conn = sqlite3.connect(filename)\n            cursor = conn.cursor()\n\n            # Check if the result is already stored in the database\n            cursor.execute(\n                \"SELECT value FROM cache WHERE key=?\",\n                (key,),\n            )\n            result = cursor.fetchone()\n\n            # If the result is already stored, retrieve it\n            if result:\n                conn.close()\n                return json.loads(result[0])\n\n            # Otherwise, compute the result, store it, and return it\n            result = func(*args, **kwargs)\n            cursor.execute(\n                \"INSERT INTO cache VALUES (?, ?)\",\n                (key, json.dumps(result)),\n            )\n            conn.commit()\n            conn.close()\n\n            return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    conn = sqlite3.connect(filename)\n    c = conn.cursor()\n\n    c.execute(\n        f\"CREATE TABLE IF NOT EXISTS {func_name} (input json, output json, hash text, PRIMARY KEY (hash))\"\n    )\n    conn.commit()\n\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n\n            # Convert args and kwargs to json\n            input_json = json.dumps({\"args\": args, \"kwargs\": kwargs})\n\n            # Hash the input\n            input_hash = hashlib.md5(input_json.encode()).hexdigest()\n\n            # Check if the function output is already cached\n            c.execute(\n                f\"SELECT output FROM {func_name} WHERE hash = ?\",\n                (input_hash,),\n            )\n            result = c.fetchone()\n\n            # If the function output is already cached, retrieve it\n            if result:\n                output = json.loads(result[0])\n\n            # Otherwise, compute the function output and cache it\n            else:\n                output = func(*args, **kwargs)\n                c.execute(\n                    f\"INSERT INTO {func_name} VALUES (?, ?, ?)\",\n                    (input_json, json.dumps(output), input_hash),\n                )\n                conn.commit()\n\n            return output\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n\n            # Connect to the SQLite database\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n\n            # Create a table to store the function's output if it does not exist yet\n            c.execute(\n                \"CREATE TABLE IF NOT EXISTS {} (key TEXT, value TEXT, hash TEXT)\".format(\n                    func_name\n                )\n            )\n\n            # Hash the function arguments to use as a key in the database\n            key = json.dumps(args) + json.dumps(kwargs)\n            key_hash = hashlib.md5(key.encode(\"utf-8\")).hexdigest()\n\n            # Check if the function's output is already in the database\n            c.execute(\n                \"SELECT value FROM {} WHERE hash = ?\".format(func_name), (key_hash,)\n            )\n            result = c.fetchone()\n\n            # If it is, return the result\n            if result:\n                conn.close()\n                return json.loads(result[0])\n\n            # Otherwise, compute the result, store it, and return it\n            result = func(*args, **kwargs)\n            c.execute(\n                \"INSERT INTO {} VALUES (?, ?, ?)\".format(func_name),\n                (key, json.dumps(result), key_hash),\n            )\n            conn.commit()\n            conn.close()\n            return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            if not isinstance(args, tuple):\n                args = tuple([args])\n            if not isinstance(kwargs, tuple):\n                kwargs = tuple(kwargs.items())\n            key = hashlib.sha224(\n                json.dumps(\n                    {\"func_name\": func_name, \"args\": args, \"kwargs\": kwargs}\n                ).encode(\"utf-8\")\n            ).hexdigest()\n            with sqlite3.connect(filename) as conn:\n                cursor = conn.cursor()\n                cursor.execute(\n                    \"CREATE TABLE IF NOT EXISTS cache (key TEXT PRIMARY KEY, value TEXT)\"\n                )\n                conn.commit()\n                cursor.execute(\n                    \"SELECT value FROM cache WHERE key=?\", (key,)\n                )  # Retrieve the value of the function call from the cache\n                result = cursor.fetchone()\n                if result:\n                    return json.loads(result[0])  # If the value is found in the cache, return it\n                else:\n                    result = func(*args, **kwargs)\n                    cursor.execute(\n                        \"INSERT INTO cache VALUES (?, ?)\", (key, json.dumps(result))\n                    )\n                    conn.commit()\n                    return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    # Connect to the database\n    conn = sqlite3.connect(filename)\n    c = conn.cursor()\n\n    # Create the table if it doesn't already exist\n    c.execute(\n        \"\"\"CREATE TABLE IF NOT EXISTS cache (\n                                            key TEXT PRIMARY KEY,\n                                            value TEXT\n                                            )\"\"\"\n    )\n\n    def decorator(func):\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n\n            # Create a key from the function's arguments\n            key = json.dumps(\n                {\n                    \"args\": args,\n                    \"kwargs\": kwargs,\n                    \"func_name\": func_name,\n                }\n            )\n\n            # Hash the key to make it unique\n            key = hashlib.sha256(key.encode()).hexdigest()\n\n            # Check if the result is already in the database\n            c.execute(\"SELECT value FROM cache WHERE key = ?\", (key,))\n            result = c.fetchone()\n\n            if result is None:\n                # Compute the result\n                result = func(*args, **kwargs)\n\n                # Store the result in the database\n                c.execute(\n                    \"INSERT INTO cache (key, value) VALUES (?, ?)\",\n                    (key, result),\n                )\n                conn.commit()\n\n            # Return the result\n            return json.loads(result)\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    conn = sqlite3.connect(filename)\n    cursor = conn.cursor()\n    cursor.execute(f\"CREATE TABLE IF NOT EXISTS {func_name} (key text, value text)\")\n    conn.commit()\n\n    @functools.wraps(func_name)\n    def wrapper(*args, **kwargs):\n\n        \"\"\"\n        This function acts as a wrapper for the original function, adding memoization functionality to it.\n\n        Input-Output Arguments\n        :param args: list, The list of arguments that the original function takes as input.\n        :param kwargs: dict, The dictionary of keyword arguments that the original function takes as input.\n        :return: The output of the original function, if the function output is already stored in the database; otherwise, the output of the original function.\n        \"\"\"\n\n        key = json.dumps(args) + json.dumps(kwargs)\n        key = hashlib.md5(key.encode(\"utf-8\")).hexdigest()\n\n        cursor.execute(f\"SELECT value FROM {func_name} WHERE key=?\", (key,))\n        result = cursor.fetchone()\n\n        if result:\n            return json.loads(result[0])\n\n        result = func_name(*args, **kwargs)\n        cursor.execute(f\"INSERT INTO {func_name} VALUES (?, ?)\", (key, json.dumps(result)))\n        conn.commit()\n\n        return result\n\n    return wrapper"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            # Connect to database\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n\n            # Hash arguments to get key\n            key = hashlib.sha256(json.dumps({\"args\": args, \"kwargs\": kwargs}).encode()).hexdigest()\n\n            # Check if key exists\n            c.execute(\"SELECT value FROM cache WHERE key=?\", (func_name + key,))\n            result = c.fetchone()\n\n            # If key does not exist, compute function and store result\n            if result is None:\n                result = func(*args, **kwargs)\n                c.execute(\"INSERT INTO cache VALUES (?, ?)\", (func_name + key, result))\n                conn.commit()\n            else:\n                result = result[0]\n\n            # Close database connection\n            conn.close()\n\n            return result\n\n        return wrapper\n\n    return decorator\n\n"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    # Create a connection to the SQLite database\n    conn = sqlite3.connect(filename)\n    # Create a cursor to the SQLite database\n    c = conn.cursor()\n    # Create a table to store the function's name and its output\n    c.execute(\"CREATE TABLE IF NOT EXISTS cache (func_name TEXT, func_output TEXT)\")\n    # Commit the changes to the SQLite database\n    conn.commit()\n    # Close the connection to the SQLite database\n    conn.close()\n\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            # Compute a hash of the function's arguments\n            hashed_args = hashlib.md5(json.dumps([args, kwargs]).encode(\"utf-8\")).hexdigest()\n            # Create a connection to the SQLite database\n            conn = sqlite3.connect(filename)\n            # Create a cursor to the SQLite database\n            c = conn.cursor()\n            # Query the database to check if the function's output is already cached\n            c.execute(\n                \"SELECT func_output FROM cache WHERE func_name=? AND func_output=?\",\n                (func_name, hashed_args),\n            )\n            # If the function's output is cached, retrieve it from the database\n            if c.fetchone():\n                output = c.fetchone()[0]\n            # Otherwise, compute the output, store it in the database, and then return it\n            else:\n                output = func(*args, **kwargs)\n                c.execute(\n                    \"INSERT INTO cache VALUES (?, ?)\", (func_name, hashed_args)\n                )\n                conn.commit()\n            # Close the connection to the SQLite database\n            conn.close()\n            # Return the output\n            return output\n\n        return wrapper\n\n    return decorator"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    x_min = values[\"x_min\"]\n    x_max = values[\"x_max\"]\n    y_min = values[\"y_min\"]\n    y_max = values[\"y_max\"]\n\n    if x_min >= x_max:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n\n    if y_min >= y_max:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    x_min = values[\"x_min\"]\n    x_max = values[\"x_max\"]\n    y_min = values[\"y_min\"]\n    y_max = values[\"y_max\"]\n\n    if x_min >= x_max:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max\")\n\n    if y_min >= y_max:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    # Ensure that the bounding box values are valid\n    if values[\"x_min\"] > values[\"x_max\"] or values[\"y_min\"] > values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: The bounding box values are invalid. Ensure that the minimum x and y values are less than the maximum x and y values, respectively.\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    # Check if the bounding box is valid\n    if values[\"x_min\"] > values[\"x_max\"] or values[\"y_min\"] > values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: bounding box values are invalid. Received {values}\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    # Check that the minimum x and y values are less than the maximum x and y values, respectively.\n    if values[\"x_min\"] > values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: The minimum x value must be less than the maximum x value.\")\n    if values[\"y_min\"] > values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: The minimum y value must be less than the maximum y value.\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    # Check if the bounding box is valid\n    if values[\"x_min\"] > values[\"x_max\"] or values[\"y_min\"] > values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: The bounding box is invalid. The minimum x and y values must be less than the maximum x and y values, respectively.\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if (values[\"x_min\"] > values[\"x_max\"]) or (values[\"y_min\"] > values[\"y_max\"]):\n        raise ValueError(f\"{cls.__name__}: Invalid bounding box. The minimum x and y values must be less than the maximum x and y values, respectively.\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    x_min = values.get(\"x_min\")\n    x_max = values.get(\"x_max\")\n    y_min = values.get(\"y_min\")\n    y_max = values.get(\"y_max\")\n\n    if x_min > x_max:\n        raise ValueError(f\"{cls.__name__}: x_min ({x_min}) must be less than x_max ({x_max})\")\n    if y_min > y_max:\n        raise ValueError(f\"{cls.__name__}: y_min ({y_min}) must be less than y_max ({y_max})\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    # Check if bounding box is valid\n    if values[\"x_min\"] >= values[\"x_max\"] or values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: Bounding box is invalid. x_min must be less than x_max and y_min must be less than y_max.\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    x_min, x_max, y_min, y_max = values[\"x_min\"], values[\"x_max\"], values[\"y_min\"], values[\"y_max\"]\n    if x_min > x_max:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than or equal to x_max. Received {x_min} and {x_max}, respectively.\")\n    if y_min > y_max:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than or equal to y_max. Received {y_min} and {y_max}, respectively.\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    # Check that the bounding box is valid\n    if values[\"x_min\"] > values[\"x_max\"] or values[\"y_min\"] > values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: Bounding box is invalid. Ensure that the minimum x and y values are less than the maximum x and y values, respectively.\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    # check if the bounding box is valid\n    if values[\"x_min\"] >= values[\"x_max\"] or values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: The bounding box is invalid. The minimum x and y values must be less than the maximum x and y values, respectively.\")\n\n    # return the bounding box values\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    # Check if the bounding box is valid\n    if (\n        values[\"x_min\"] <= values[\"x_max\"]\n        and values[\"y_min\"] <= values[\"y_max\"]\n    ):\n        return values\n    else:\n        raise ValueError(\n            f\"{cls.__name__}: The bounding box values are invalid. Make sure that x_min <= x_max and y_min <= y_max.\"\n        )\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    x_min = values.get(\"x_min\")\n    x_max = values.get(\"x_max\")\n    y_min = values.get(\"y_min\")\n    y_max = values.get(\"y_max\")\n\n    # check if the bounding box values are valid\n    if x_min >= x_max:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max\")\n    if y_min >= y_max:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    # check if the bounding box values are valid\n    if values[\"x_min\"] > values[\"x_max\"] or values[\"y_min\"] > values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: The bounding box values are invalid.\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    # Check if the bounding box values are valid\n    if (values[\"x_min\"] >= values[\"x_max\"]) or (values[\"y_min\"] >= values[\"y_max\"]):\n        raise ValueError(f\"{cls.__name__}: Bounding box values are invalid. Received {values}\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    # Check if the bounding box is valid\n    if (values[\"x_min\"] >= values[\"x_max\"]) or (values[\"y_min\"] >= values[\"y_max\"]):\n        raise ValueError(f\"{cls.__name__}: bounding box values must be valid. Received {values}\")\n\n    return values\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  # Compute the norms of each column.\n  mat0_norms = np.linalg.norm(mat0, axis=0)\n  mat1_norms = np.linalg.norm(mat1, axis=0)\n\n  # Compute the dot product between each pair of columns.\n  mat0_dot_mat1 = np.dot(mat0.T, mat1)\n\n  # Compute the squared Euclidean distance between each pair of columns.\n  sq_dist = mat0_norms ** 2 + mat1_norms ** 2 - 2 * mat0_dot_mat1\n\n  # Ensure that negative distances are set to zero.\n  sq_dist[sq_dist < 0] = 0\n\n  return sq_dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  return np.sum(mat0 ** 2, axis=0, keepdims=True) - 2 * np.dot(mat0, mat1.T) + np.sum(mat1 ** 2, axis=0, keepdims=True).T\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  # Compute the norms of each column.\n  norm0 = np.linalg.norm(mat0, axis=0)\n  norm1 = np.linalg.norm(mat1, axis=0)\n\n  # Compute the dot product between each column.\n  dot = np.dot(mat0.T, mat1)\n\n  # Compute the squared Euclidean distance between each column.\n  sq_dist = norm0 ** 2 - 2 * dot + norm1 ** 2\n\n  # Set negative distances to zero.\n  sq_dist[sq_dist < 0] = 0\n\n  return sq_dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  return np.sum(np.square(mat0), axis=0, keepdims=True) - 2 * np.matmul(mat0, mat1.T) + np.sum(np.square(mat1), axis=0, keepdims=True).T\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  return np.sum(mat0 ** 2, axis=0, keepdims=True) - 2 * np.dot(mat0, mat1.T) + np.sum(mat1 ** 2, axis=0, keepdims=True).T\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  norm0 = np.linalg.norm(mat0, axis=0)\n  norm1 = np.linalg.norm(mat1, axis=0)\n  dot = np.dot(mat0.T, mat1)\n\n  return np.sum(norm0**2) - 2 * dot + np.sum(norm1**2)\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  # Compute the norms of each column in each matrix.\n  mat0_norms = np.linalg.norm(mat0, axis=0)\n  mat1_norms = np.linalg.norm(mat1, axis=0)\n\n  # Compute the dot product between each column in each matrix.\n  mat0_dot_mat1 = np.dot(mat0.T, mat1)\n\n  # Compute the squared distance between each column in each matrix.\n  sq_dist = mat0_norms ** 2 - 2 * mat0_dot_mat1 + mat1_norms ** 2\n\n  # Set negative distances to zero.\n  sq_dist[sq_dist < 0] = 0\n\n  return sq_dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  mat0 = np.asarray(mat0)\n  mat1 = np.asarray(mat1)\n  sq_dist = np.sum(mat0 ** 2, axis=0, keepdims=True) - 2 * np.dot(mat0, mat1.T) + np.sum(mat1 ** 2, axis=0, keepdims=True).T\n  sq_dist[sq_dist < 0] = 0\n  return sq_dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  # Compute the norms of each column of mat0 and mat1\n  mat0_norms = np.linalg.norm(mat0, axis=0)\n  mat1_norms = np.linalg.norm(mat1, axis=0)\n\n  # Compute the dot products of each column of mat0 with each column of mat1\n  mat0_dot_mat1 = np.dot(mat0.T, mat1)\n\n  # Compute the squared distances between each column of mat0 and mat1\n  sq_dist = mat0_norms ** 2 + mat1_norms ** 2 - 2 * mat0_dot_mat1\n\n  # Ensure that negative distances are set to zero\n  sq_dist[sq_dist < 0] = 0\n\n  return sq_dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  mat0_norms = np.sum(np.square(mat0), axis=0)\n  mat1_norms = np.sum(np.square(mat1), axis=0)\n  mat0_dot_mat1 = np.dot(mat0.T, mat1)\n  return mat0_norms.reshape((-1, 1)) + mat1_norms - 2 * mat0_dot_mat1\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  # Compute the norms of each column in the matrices.\n  norms0 = np.linalg.norm(mat0, axis=0)\n  norms1 = np.linalg.norm(mat1, axis=0)\n\n  # Compute the dot product between each column in the matrices.\n  dot = np.dot(mat0.T, mat1)\n\n  # Compute the squared distances between each column in the matrices.\n  sq_dist = norms0 ** 2 - 2 * dot + norms1 ** 2\n\n  # Set negative distances to zero.\n  sq_dist[sq_dist < 0] = 0\n\n  return sq_dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  mat0_norms = np.linalg.norm(mat0, axis=0)\n  mat1_norms = np.linalg.norm(mat1, axis=0)\n  mat0_dot_mat1 = np.dot(mat0.T, mat1)\n  sq_dist = mat0_norms.reshape(1, -1) + mat1_norms.reshape(-1, 1) - 2 * mat0_dot_mat1\n  sq_dist[sq_dist < 0] = 0\n  return sq_dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  mat0_norms = np.sum(mat0 ** 2, axis=0)\n  mat1_norms = np.sum(mat1 ** 2, axis=0)\n  cross_products = np.dot(mat0.T, mat1)\n  sq_dist = mat0_norms - 2 * cross_products + mat1_norms\n  sq_dist = np.maximum(sq_dist, 0)\n  return sq_dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  # Compute the norms of each column of mat0 and mat1.\n  norm0 = np.linalg.norm(mat0, axis=0)\n  norm1 = np.linalg.norm(mat1, axis=0)\n\n  # Compute the dot product between each column of mat0 and mat1.\n  dot = np.dot(mat0.T, mat1)\n\n  # Compute the squared distance between each column of mat0 and mat1.\n  sq_dist = norm0 ** 2 - 2 * dot + norm1 ** 2\n\n  # Set negative distances to zero.\n  sq_dist[sq_dist < 0] = 0\n\n  return sq_dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  return np.sum(mat0 ** 2, axis=0, keepdims=True) - 2 * np.dot(mat0, mat1.T) + np.sum(mat1 ** 2, axis=0, keepdims=True).T\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  # Compute the norms of each column of each matrix.\n  norms0 = np.linalg.norm(mat0, axis=0)\n  norms1 = np.linalg.norm(mat1, axis=0)\n\n  # Compute the dot products of each column of each matrix.\n  dot_prod = (mat0 * mat1).sum(axis=0)\n\n  # Compute the squared distances.\n  sq_dist = norms0 ** 2 - 2 * dot_prod + norms1 ** 2\n\n  # Set negative distances to zero.\n  sq_dist[sq_dist < 0] = 0\n\n  return sq_dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  norm0 = np.linalg.norm(mat0, axis=0)\n  norm1 = np.linalg.norm(mat1, axis=0)\n  dot_product = np.dot(mat0.T, mat1)\n\n  return np.clip(norm0 ** 2 + norm1 ** 2 - 2 * dot_product, 0.0, None)\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  assert mat0.ndim == mat1.ndim == 2, 'Matrices must be 2-dimensional'\n  assert mat0.shape[1] == mat1.shape[1], 'Matrices must have the same number of columns'\n  sq_dist = np.sum(mat0**2, axis=0)[:, np.newaxis] - 2*mat0.dot(mat1.T) + np.sum(mat1**2, axis=0)[np.newaxis, :]\n  sq_dist[sq_dist < 0] = 0\n  return sq_dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  return np.sum(mat0 ** 2, axis=0, keepdims=True) + np.sum(mat1 ** 2, axis=0, keepdims=True) - 2 * np.dot(mat0.T, mat1)\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  # Compute the norms of each vector\n  norm0 = np.linalg.norm(mat0, axis=0)\n  norm1 = np.linalg.norm(mat1, axis=0)\n\n  # Compute the dot products of each pair of vectors\n  dot = np.dot(mat0.T, mat1)\n\n  # Compute the squared distance matrix\n  sq_dist = norm0 ** 2 + norm1 ** 2 - 2 * dot\n\n  # Set negative distances to zero\n  sq_dist = np.maximum(sq_dist, 0)\n\n  return sq_dist\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    return path is None or path == \"\" or path.startswith(\n        (\n            \"http://\",\n            \"https://\",\n            \"gs://\",\n            \"hdfs://\",\n            \"s3://\",\n            \"s3a://\",\n            \"s3n://\",\n            \"wasb://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs://\",\n            \"wasbs"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\" or path.startswith((\"/cache\", \"/tmp\")):\n        return True\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\":\n        return True\n    if path.startswith(\"s3://\") or path.startswith(\"gs://\") or path.startswith(\"http://\") or path.startswith(\"https://\"):\n        return True\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\" or path.startswith(\"s3://\") or path.startswith(\"gs://\"):\n        return True\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\":\n        return True\n\n    return path.startswith(\"gs://\") or path.startswith(\"s3://\") or path.startswith(\"hdfs://\")\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    return path is None or path == \"\" or path.startswith(\"/input/\") or path.startswith(\"/output/\")\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\":\n        return True\n    if path.startswith(\"gs://\") or path.startswith(\"s3://\") or path.startswith(\"hdfs://\"):\n        return True\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\":\n        return True\n    if path.startswith(\"gs://\") or path.startswith(\"s3://\") or path.startswith(\"hdfs://\"):\n        return True\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\":\n        return True\n    if path.startswith(\"gs://\"):\n        return True\n    if path.startswith(\"http://\") or path.startswith(\"https://\"):\n        return True\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\":\n        return True\n    return path.startswith(\"https://\") or path.startswith(\"gs://\") or path.startswith(\"s3://\")\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\" or path.startswith(\"http://\") or path.startswith(\"https://\") or path.startswith(\n        \"s3://\"\n    ):\n        return True\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None:\n        return True\n    if path == \"\":\n        return True\n    if path.startswith(\"/cache\"):\n        return True\n    if path.startswith(\"/tmp\"):\n        return True\n    if path.startswith(\"/data\"):\n        return True\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\" or path.startswith(\"/cache\") or path.startswith(\"/data\") or path.startswith(\"/opt\"):\n        return True\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    return path is None or path == \"\" or path.startswith(\n        (\n            \"https://\",\n            \"gs://\",\n            \"s3://\",\n            \"hdfs://\",\n            \"ftp://\",\n            \"sftp://\",\n            \"ssh://\",\n            \"file://\",\n            \"wasbs://\",\n            \"wasbf://\",\n            \"wasfg://\",\n        )\n    )\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\":\n        return True\n\n    return any([path.startswith(prefix) for prefix in [\"gs://\", \"s3://\"]])\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\":\n        return True\n\n    if path.startswith(\"gs://\") or path.startswith(\"s3://\") or path.startswith(\"hdfs://\") or path.startswith(\"http://\"):\n        return True\n\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\":\n        return True\n    if path.startswith(\"gs://\") or path.startswith(\"s3://\"):\n        return True\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\":\n        return True\n    if path.startswith(\"s3://\") or path.startswith(\"gs://\"):\n        return True\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None:\n        return True\n\n    if path == \"\":\n        return True\n\n    if path.startswith(\"s3://\"):\n        return True\n\n    if path.startswith(\"gs://\"):\n        return True\n\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\":\n        return True\n\n    if path.startswith(\"gs://\") or path.startswith(\"s3://\"):\n        return True\n\n    return False\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if dim == 1:\n        if isinstance(items, dict):\n            if assets_names is None:\n                raise ValueError(\n                    \"If 'items' is a dictionary, 'assets_names' must be provided.\"\n                )\n            if len(assets_names) != n_assets:\n                raise ValueError(\n                    f\"Expected {n_assets} assets, but only {len(assets_names)} are \"\n                    f\"provided in 'assets_names'.\"\n                )\n            if len(items) != len(assets_names):\n                raise ValueError(\n                    f\"Expected {len(assets_names)} assets, but only {len(items)} are \"\n                    f\"provided in 'items'.\"\n                )\n            for asset_name in assets_names:\n                if asset_name not in items:\n                    items[asset_name] = fill_value\n            return np.array([items[asset_name] for asset_name in assets_names])\n        else:\n            if len(items) != n_assets:\n                raise ValueError(\n                    f\"Expected {n_assets} assets, but only {len(items)} are provided \"\n                    f\"in 'items'.\"\n                )\n            return np.array(items)\n    elif dim == 2:\n        if isinstance(items, dict):\n            if assets_names is None:\n                raise ValueError(\n                    \"If 'items' is a dictionary, 'assets_names' must be provided.\"\n                )\n            if len(assets_names) != n_assets:\n                raise ValueError(\n                    f\"Expected {n_assets} assets, but only {len(assets_names)} are \"\n                    f\"provided in 'assets_names'.\"\n                )\n            if len(items) != len(assets_names):\n                raise ValueError(\n                    f\"Expected {len(assets_names)} assets, but only {len(items)} are \"\n                    f\"provided in 'items'.\"\n                )\n            for asset_name in assets_names:\n                if asset_name"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            assets_names = list(items.keys())\n        if len(assets_names) != n_assets:\n            raise ValueError(\n                f\"Expected {n_assets} assets, got {len(items)} in '{name}'\"\n            )\n        if dim == 1:\n            return np.array(\n                [\n                    items.get(asset_name, fill_value)\n                    for asset_name in assets_names\n                ]\n            )\n        elif dim == 2:\n            return np.array(\n                [\n                    [\n                        items.get(asset_name, fill_value)\n                        for asset_name in assets_names\n                    ]\n                    for _ in range(n_assets)\n                ]\n            )\n        else:\n            raise ValueError(\n                f\"Expected dimension of 1 or 2, got {dim} in '{name}'\"\n            )\n    elif isinstance(items, np.ndarray):\n        if dim == 1:\n            if items.ndim != 1:\n                raise ValueError(\n                    f\"Expected 1D array, got {items.ndim}D in '{name}'\"\n                )\n            if len(items) != n_assets:\n                raise ValueError(\n                    f\"Expected {n_assets} assets, got {len(items)} in '{name}'\"\n                )\n        elif dim == 2:\n            if items.ndim != 2:\n                raise ValueError(\n                    f\"Expected 2D array, got {items.ndim}D in '{name}'\"\n                )\n            if items.shape[1] != n_assets:\n                raise ValueError(\n                    f\"Expected {n_assets} assets, got {items.shape[1]} in '{name}'\"\n                )\n        else:\n            raise ValueError(\n                f\"Expected dimension of 1 or 2, got {dim} in '{name}'\"\n            )\n        return items\n    else:\n        raise ValueError("}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if dim not in (1, 2):\n        raise ValueError(\"'dim' must be either 1 or 2\")\n\n    if isinstance(items, dict):\n        if assets_names is None:\n            assets_names = np.array(list(items.keys()))\n        else:\n            assets_names = np.array(assets_names)\n        if assets_names.shape[0] != len(items):\n            raise ValueError(\n                f\"'{name}' dictionary keys and 'assets_names' must have the same length\"\n            )\n        if fill_value is None:\n            raise ValueError(f\"'{name}' dictionary cannot have missing values\")\n        if dim == 1:\n            return np.array(\n                [items[k] if k in items else fill_value for k in assets_names]\n            )\n        elif dim == 2:\n            return np.array(\n                [\n                    [items[k] if k in items else fill_value for k in assets_names]\n                    for _ in range(n_assets)\n                ]\n            )\n    elif isinstance(items, np.ndarray):\n        if dim == 1:\n            if items.shape[0] != n_assets:\n                raise ValueError(\n                    f\"'{name}' array must have the same number of elements as 'n_assets'\"\n                )\n        elif dim == 2:\n            if items.shape != (n_assets, n_assets):\n                raise ValueError(\n                    f\"'{name}' array must have shape ({n_assets}, {n_assets})\"\n                )\n        return items\n    else:\n        if dim == 1:\n            return np.array(items)\n        elif dim == 2:\n            return np.array(items).reshape((n_assets, n_assets))\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if dim not in [1, 2]:\n        raise ValueError(\"'dim' must be either 1 or 2\")\n\n    if dim == 1:\n        if isinstance(items, dict):\n            if assets_names is None:\n                raise ValueError(\"'assets_names' must be provided when 'items' is a\"\n                                 \" dictionary\")\n            if assets_names.size != len(items):\n                raise ValueError(\"'items' has the wrong number of assets\")\n            if not all(asset in items for asset in assets_names):\n                raise ValueError(\"'items' is missing assets\")\n            array = np.array([items[asset] for asset in assets_names])\n        else:\n            array = np.array(items)\n        if array.ndim != 1:\n            raise ValueError(\"'items' must be a 1-dimensional array\")\n        if array.size != n_assets:\n            raise ValueError(\"'items' has the wrong number of assets\")\n    else:\n        if isinstance(items, dict):\n            if assets_names is None:\n                raise ValueError(\"'assets_names' must be provided when 'items' is a\"\n                                 \" dictionary\")\n            if assets_names.size != len(items):\n                raise ValueError(\"'items' has the wrong number of assets\")\n            if not all(asset in items for asset in assets_names):\n                raise ValueError(\"'items' is missing assets\")\n            array = np.array([[items[asset] for asset in assets_names]])\n        else:\n            array = np.array(items)\n        if array.ndim != 2:\n            raise ValueError(\"'items' must be a 2-dimensional array\")\n        if array.shape[1] != n_assets:\n            raise ValueError(\"'items' has the wrong number of assets\")\n\n    if fill_value is not None:\n        if isinstance(fill_value, Iterator):\n            raise ValueError(\"'fill_value' must be a constant\")\n        if dim == 1:\n            for i in range(n_assets):\n                if np.isnan"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    # Check for valid 'dim'\n    if dim not in [1, 2]:\n        raise ValueError(f\"Expected 'dim' to be 1 or 2, got {dim}\")\n\n    # Check for valid 'items'\n    if isinstance(items, dict):\n        # Check for valid 'assets_names'\n        if assets_names is None:\n            raise ValueError(f\"Expected 'assets_names' to be provided when 'items' is a dictionary\")\n        # Check for valid 'fill_value'\n        if not isinstance(fill_value, (int, float)):\n            raise ValueError(f\"Expected 'fill_value' to be an integer or float, got {type(fill_value)}\")\n        # Check for valid 'items' keys\n        if not all(isinstance(k, str) for k in items.keys()):\n            raise ValueError(f\"Expected all keys in 'items' to be strings\")\n        # Check for valid 'assets_names' keys\n        if not all(k in items.keys() for k in assets_names):\n            raise ValueError(f\"Expected all keys in 'assets_names' to be in 'items'\")\n        # Check for valid 'items' values\n        if not all(isinstance(v, (int, float, np.ndarray)) for v in items.values()):\n            raise ValueError(f\"Expected all values in 'items' to be integers, floats, or numpy arrays\")\n        # Check for valid 'items' values shape\n        if not all(v.ndim == 1 for v in items.values()):\n            raise ValueError(f\"Expected all values in 'items' to be 1-dimensional\")\n        # Check for valid 'items' values length\n        if not all(v.shape[0] == n_assets for v in items.values()):\n            raise ValueError(f\"Expected all values in 'items' to be of length {n_assets}\")\n        # Check for valid 'items' values type\n        if not all(v.dtype.kind in \"iuf\" for v in items.values()):\n            raise ValueError"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if dim not in [1, 2]:\n        raise ValueError(\"Dimension must be either 1 or 2\")\n\n    if isinstance(items, dict):\n        if assets_names is None:\n            assets_names = np.array(list(items.keys()))\n        if assets_names.shape[0] != len(items):\n            raise ValueError(\n                f\"The number of assets in the '{name}' dictionary does not match the \"\n                f\"number of assets in the assets_names array\"\n            )\n        if fill_value is None:\n            raise ValueError(\n                f\"The '{name}' dictionary contains missing values, but the fill value is \"\n                f\"not specified\"\n            )\n        missing_assets = np.setdiff1d(assets_names, list(items.keys()))\n        if missing_assets.shape[0] > 0:\n            items = {\n                k: items[k] if k in items else fill_value for k in assets_names\n            }\n        else:\n            items = {k: items[k] for k in assets_names}\n        items = np.array(list(items.values()))\n\n    if dim == 1:\n        if items.ndim != 1:\n            raise ValueError(\n                f\"The '{name}' array must be 1-dimensional, but the converted array has \"\n                f\"{items.ndim} dimensions\"\n            )\n        if items.shape[0] != n_assets:\n            raise ValueError(\n                f\"The number of assets in the '{name}' array does not match the number \"\n                f\"of assets in the assets_names array\"\n            )\n    else:\n        if items.ndim != 2:\n            raise ValueError(\n                f\"The '{name}' array must be 2-dimensional, but the converted array has \"\n                f\"{items.ndim} dimensions\"\n            )\n        if items.shape[1] != n_assets:\n            raise ValueError(\n                f\"The number of assets in the '{name}' array does not match the number \"\n                f\"of assets in the assets_names"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if dim not in (1, 2):\n        raise ValueError(f\"'dim' must be either 1 or 2, got {dim}\")\n\n    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                f\"'assets_names' must be provided when 'items' is a dictionary\"\n            )\n        if fill_value is None:\n            raise ValueError(\n                f\"'fill_value' must be provided when 'items' is a dictionary\"\n            )\n        if len(items) != len(assets_names):\n            raise ValueError(\n                f\"'items' must have the same number of elements as 'assets_names'\"\n            )\n        if not all(asset in items for asset in assets_names):\n            raise ValueError(\n                f\"'items' must contain the same keys as 'assets_names'\"\n            )\n        missing_assets = [asset for asset in assets_names if asset not in items]\n        if missing_assets:\n            raise ValueError(\n                f\"'items' must contain the same keys as 'assets_names', missing {missing_assets}\"\n            )\n        array = np.array(\n            [\n                items[asset] if asset in items else fill_value\n                for asset in assets_names\n            ],\n            dtype=float,\n        )\n    else:\n        array = np.asarray(items)\n\n    if dim == 1:\n        if array.ndim != 1:\n            raise ValueError(\n                f\"'{name}' must be a 1-dimensional array, got {array.ndim} dimensions\"\n            )\n        if len(array) != n_assets:\n            raise ValueError(\n                f\"'{name}' must have the same number of elements as 'n_assets'\"\n            )\n    elif dim == 2:\n        if array.ndim != 2:\n            raise ValueError(\n                f\"'{name}' must be a 2-dimensional array, got {array.ndim} dimensions\"\n            )\n        if array.shape[1] != n_assets:\n            raise ValueError"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if dim not in [1, 2]:\n        raise ValueError(\"dim must be either 1 or 2\")\n\n    if isinstance(items, dict):\n        if assets_names is None:\n            assets_names = np.array(list(items.keys()))\n        else:\n            assets_names = np.array(assets_names)\n        if len(assets_names) != n_assets:\n            raise ValueError(\n                f\"Expected {n_assets} assets, but only {len(assets_names)} are provided\"\n            )\n        if dim == 1:\n            if not all(\n                [isinstance(item, (int, float, str, np.number)) for item in items.values()]\n            ):\n                raise ValueError(\n                    f\"Expected numeric values for {name}, but got {type(items[0])}\"\n                )\n            items = np.array(\n                [\n                    items[asset_name] if asset_name in items else fill_value\n                    for asset_name in assets_names\n                ]\n            )\n        elif dim == 2:\n            items = np.array(\n                [\n                    [\n                        items[asset_name][group_name]\n                        if asset_name in items and group_name in items[asset_name]\n                        else fill_value\n                        for asset_name in assets_names\n                    ]\n                    for group_name in assets_names\n                ]\n            )\n    elif isinstance(items, (np.ndarray, pd.DataFrame, pd.Series)):\n        if dim == 1:\n            if len(items.shape) != 1:\n                raise ValueError(f\"Expected 1-D array for {name}, but got {items.shape}\")\n            if len(items) != n_assets:\n                raise ValueError(\n                    f\"Expected {n_assets} assets, but only {len(items)} are provided\"\n                )\n        elif dim == 2:\n            if len(items.shape) != 2:\n                raise ValueError(f\"Expected 2-D array for"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if dim not in [1, 2]:\n        raise ValueError(f\"Expected dim to be either 1 or 2, got {dim}\")\n\n    if dim == 1:\n        if assets_names is not None:\n            raise ValueError(\"Expected assets_names to be None for dim=1\")\n\n        if isinstance(items, dict):\n            if len(items) != n_assets:\n                raise ValueError(\n                    f\"Expected {n_assets} assets for {name}, got {len(items)}\"\n                )\n\n            if fill_value is not None:\n                if not isinstance(fill_value, (int, float)):\n                    raise ValueError(\n                        f\"Expected fill_value to be None or a numeric value, got {fill_value}\"\n                    )\n\n                if fill_value != 0:\n                    raise ValueError(\n                        f\"Expected fill_value to be 0 for dim=1, got {fill_value}\"\n                    )\n\n            if not all(isinstance(k, str) for k in items.keys()):\n                raise ValueError(\n                    f\"Expected {name} keys to be strings, got {list(items.keys())}\"\n                )\n\n            if not all(isinstance(v, (int, float)) for v in items.values()):\n                raise ValueError(\n                    f\"Expected {name} values to be numeric, got {list(items.values())}\"\n                )\n\n            if not all(k in items.keys() for k in assets_names):\n                raise ValueError(\n                    f\"Expected {name} to contain all assets names, got {list(items.keys())}\"\n                )\n\n            return np.array([items[k] for k in assets_names], dtype=float)\n\n        elif isinstance(items, (list, tuple, np.ndarray)):\n            if len(items) != n_assets:\n                raise ValueError(\n                    f\"Expected {n_assets} assets for {name}, got {len(items)}\"\n                )\n\n           "}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if dim not in [1, 2]:\n        raise ValueError(\"Dimension must be either 1 or 2.\")\n    if dim == 1:\n        if not isinstance(items, (np.ndarray, pd.Series, dict)):\n            raise ValueError(\n                f\"{name} must be a dictionary, numpy array, or pandas Series.\"\n            )\n        if isinstance(items, dict):\n            if assets_names is None:\n                raise ValueError(\n                    f\"{name} is a dictionary, but no assets names were provided.\"\n                )\n            if not isinstance(assets_names, np.ndarray):\n                raise ValueError(\n                    f\"{name} is a dictionary, but the assets names are not a numpy array.\"\n                )\n            if not len(assets_names) == n_assets:\n                raise ValueError(\n                    f\"{name} is a dictionary, but the number of assets names does not match the expected number of assets ({n_assets}).\"\n                )\n            if not set(assets_names) == set(items.keys()):\n                raise ValueError(\n                    f\"{name} is a dictionary, but the keys do not match the assets names.\"\n                )\n            if not isinstance(fill_value, (int, float)):\n                raise ValueError(\n                    f\"{name} is a dictionary, but the fill value is not a numeric value.\"\n                )\n            return np.array(\n                [\n                    items[asset] if asset in items else fill_value\n                    for asset in assets_names\n                ]\n            )\n        if isinstance(items, (np.ndarray, pd.Series)):\n            if not len(items) == n_assets:\n                raise ValueError(\n                    f\"{name} is an array, but the number of assets does not match the expected number of assets ({n_assets}).\"\n                )\n            return np.array(items)\n    if dim == 2:\n        if not isinstance(items, (np.ndarray, pd.Series, dict)):\n            raise ValueError(\n                f\"{name} must be a dictionary,"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if dim not in (1, 2):\n        raise ValueError(f\"Dimension must be either 1 or 2, got {dim}\")\n\n    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\"Assets names are required when items is a dictionary\")\n        if fill_value is None:\n            raise ValueError(\"Fill value is required when items is a dictionary\")\n        if len(items) != n_assets:\n            raise ValueError(f\"Expected {n_assets} assets, got {len(items)}\")\n        if not all(asset in items for asset in assets_names):\n            raise ValueError(f\"Expected {assets_names} assets, got {list(items.keys())}\")\n        # Convert dictionary to array\n        items = np.array([items[asset] for asset in assets_names])\n\n    if dim == 1:\n        if items.ndim != 1:\n            raise ValueError(f\"Expected 1-D array, got {items.ndim}-D\")\n        if items.shape[0] != n_assets:\n            raise ValueError(f\"Expected {n_assets} assets, got {items.shape[0]}\")\n    else:\n        if items.ndim != 2:\n            raise ValueError(f\"Expected 2-D array, got {items.ndim}-D\")\n        if items.shape[1] != n_assets:\n            raise ValueError(f\"Expected {n_assets} assets, got {items.shape[1]}\")\n\n    if fill_value is not None:\n        # Fill missing values\n        if dim == 1:\n            if np.any(np.isnan(items)):\n                items = np.where(np.isnan(items), fill_value, items)\n        else:\n            if np.any(np.isnan(items)):\n                items = np.where(np.isnan(items), fill_value, items)\n            if np.any(np.isnan(items)):\n                raise ValueError(f\"Expected {name} to be a complete matrix"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if dim == 1:\n        if isinstance(items, dict):\n            if assets_names is not None:\n                if not np.array_equal(np.sort(assets_names), np.sort(list(items.keys()))):\n                    raise ValueError(\n                        f\"The keys of the dictionary must match the assets names.\"\n                    )\n            else:\n                assets_names = np.array(list(items.keys()))\n            array = np.array([items[asset] if asset in items else fill_value for asset in assets_names])\n        else:\n            array = np.array(items)\n        if len(array) != n_assets:\n            raise ValueError(f\"The number of assets in '{name}' must be {n_assets}.\")\n    elif dim == 2:\n        if isinstance(items, dict):\n            if assets_names is not None:\n                if not np.array_equal(np.sort(assets_names), np.sort(list(items.keys()))):\n                    raise ValueError(\n                        f\"The keys of the dictionary must match the assets names.\"\n                    )\n            else:\n                assets_names = np.array(list(items.keys()))\n            array = np.array([[items[asset] if asset in items else fill_value for asset in assets_names] for _ in range(n_assets)])\n        else:\n            array = np.array(items)\n        if array.shape != (n_assets, n_assets):\n            raise ValueError(f\"The shape of '{name}' must be (n_assets, n_assets).\")\n    else:\n        raise ValueError(f\"Dimension must be 1 or 2, got {dim}.\")\n\n    return array\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    # Check the dimension\n    if dim != 1 and dim != 2:\n        raise ValueError(f\"Expected dim to be 1 or 2, got {dim}\")\n\n    # Check the number of assets\n    if n_assets <= 0:\n        raise ValueError(f\"Expected n_assets to be positive, got {n_assets}\")\n\n    # Check the number of assets\n    if dim == 1 and n_assets > 1:\n        raise ValueError(\n            f\"Expected n_assets to be 1 for dim=1, got {n_assets}\"\n        )\n\n    # Check the assets names\n    if assets_names is not None and len(assets_names) != n_assets:\n        raise ValueError(\n            f\"Expected assets_names to have length {n_assets}, got {len(assets_names)}\"\n        )\n\n    # Check the name\n    if not isinstance(name, str):\n        raise TypeError(f\"Expected name to be a string, got {type(name)}\")\n\n    # Check the fill value\n    if not isinstance(fill_value, (int, float, str)):\n        raise TypeError(f\"Expected fill_value to be a number, got {type(fill_value)}\")\n\n    # Convert the items into a numpy array\n    if isinstance(items, dict):\n        # Convert the items into a numpy array\n        if dim == 1:\n            items_array = np.full(n_assets, fill_value, dtype=float)\n        elif dim == 2:\n            items_array = np.full((n_assets, n_assets), fill_value, dtype=float)\n        else:\n            raise ValueError(f\"Expected dim to be 1 or 2, got {dim}\")\n\n        # Check the assets names\n        if assets_names is None:\n            assets_names = np.array(list(items.keys()))\n\n        # Fill the items array\n        for i, asset_name in enumerate(assets_names):\n            if asset_name in items:\n                items_array[i] = items[asset_name"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if dim not in (1, 2):\n        raise ValueError(f\"Expected dimension to be 1 or 2, got {dim}\")\n\n    if dim == 1:\n        if isinstance(items, dict):\n            if assets_names is None:\n                assets_names = list(items.keys())\n            elif len(assets_names) != len(items):\n                raise ValueError(\n                    f\"Expected {len(assets_names)} assets names for '{name}', got {len(items)}\"\n                )\n            if len(assets_names) != n_assets:\n                raise ValueError(\n                    f\"Expected {n_assets} assets names for '{name}', got {len(items)}\"\n                )\n            if not all(isinstance(name, str) for name in assets_names):\n                raise TypeError(f\"Expected string asset names for '{name}'\")\n            if not all(name in items for name in assets_names):\n                raise ValueError(\n                    f\"Expected {assets_names} asset names for '{name}', got {list(items.keys())}\"\n                )\n            return np.array(\n                [items[name] if name in items else fill_value for name in assets_names]\n            )\n        elif isinstance(items, np.ndarray):\n            if items.ndim == 1 and items.shape[0] == n_assets:\n                return items\n            raise ValueError(\n                f\"Expected {n_assets} elements for '{name}', got {items.shape[0]}\"\n            )\n        elif isinstance(items, Iterator):\n            items = list(items)\n            if len(items) != n_assets:\n                raise ValueError(\n                    f\"Expected {n_assets} elements for '{name}', got {len(items)}\"\n                )\n            return np.array(items)\n        else:\n            raise TypeError(f\"Expected {name} to be array-like\")\n\n    elif dim == 2:\n        if isinstance(items, dict):\n            if assets_names is None:\n                assets"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    # Check that 'items' is a dictionary\n    if isinstance(items, dict):\n\n        # Check that 'items' is a dictionary of arrays\n        if not all(isinstance(v, (np.ndarray, pd.Series, pd.DataFrame)) for v in items.values()):\n            raise ValueError(f\"Expected type (np.ndarray, pd.Series, pd.DataFrame) for values of '{name}', got {type(items)}\")\n\n        # Check that 'items' has the same number of elements as 'n_assets'\n        if len(items) != n_assets:\n            raise ValueError(f\"Expected {n_assets} elements for '{name}', got {len(items)}\")\n\n        # Check that 'items' has the same keys as 'assets_names'\n        if assets_names is not None:\n            if not all(k in assets_names for k in items.keys()):\n                raise ValueError(f\"Expected {assets_names} keys for '{name}', got {items.keys()}\")\n\n        # Convert 'items' to a numpy array\n        arr = np.array([items[k] for k in assets_names])\n\n    # Check that 'items' is a numpy array\n    elif isinstance(items, (np.ndarray, pd.Series, pd.DataFrame)):\n\n        # Convert 'items' to a numpy array\n        arr = np.array(items)\n\n    # Check that 'items' is an array-like structure\n    else:\n        raise ValueError(f\"Expected type (np.ndarray, pd.Series, pd.DataFrame, dict) for '{name}', got {type(items)}\")\n\n    # Check that 'arr' is a 1-D or 2-D array\n    if arr.ndim not in [1, 2]:\n        raise ValueError(f\"Expected 1-D or 2-D array for '{name}', got {arr.ndim}-D\")\n\n    # Check that 'arr' has the expected number of assets\n    if arr.shape[0] != n_assets:\n        raise ValueError(f\"Expected"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if dim == 1:\n        expected_shape = (n_assets,)\n    elif dim == 2:\n        expected_shape = (1, n_assets)\n    else:\n        raise ValueError(f\"Invalid value for dim: {dim}.\")\n\n    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(f\"Expected 'assets_names' to be provided for dict-like 'items'.\")\n        if len(items) != len(assets_names):\n            raise ValueError(f\"Expected 'items' to have the same length as 'assets_names'.\")\n        if fill_value is None:\n            raise ValueError(f\"Expected 'fill_value' to be provided for dict-like 'items'.\")\n        if not all(asset in items for asset in assets_names):\n            raise ValueError(f\"Expected 'items' to contain all the assets in 'assets_names'.\")\n        array = np.full(assets_names.shape, fill_value)\n        for i, asset in enumerate(assets_names):\n            if asset in items:\n                array[i] = items[asset]\n    elif isinstance(items, (list, tuple, np.ndarray)):\n        if len(items) != n_assets:\n            raise ValueError(f\"Expected 'items' to have length {n_assets}.\")\n        array = np.asarray(items)\n    else:\n        raise ValueError(f\"Expected 'items' to be a dict, list, tuple, or np.ndarray, got {type(items)}.\")\n\n    if array.shape != expected_shape:\n        raise ValueError(f\"Expected '{name}' to have shape {expected_shape}, got {array.shape}.\")\n\n    return array\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if dim not in [1, 2]:\n        raise ValueError(f\"'dim' must be either 1 or 2, got {dim}.\")\n\n    if isinstance(items, dict):\n        if assets_names is None:\n            assets_names = list(items.keys())\n        elif not np.array_equal(np.array(list(items.keys())), assets_names):\n            raise ValueError(\n                f\"'items' and 'assets_names' do not match. \"\n                f\"'items' has {len(items.keys())} assets, \"\n                f\"'assets_names' has {len(assets_names)} assets.\"\n            )\n        if dim == 1:\n            items = np.array(\n                [items.get(asset, fill_value) for asset in assets_names],\n                dtype=np.float64,\n            )\n        elif dim == 2:\n            items = np.array(\n                [\n                    [items.get(asset, fill_value) for asset in assets_names]\n                    for _ in range(n_assets)\n                ],\n                dtype=np.float64,\n            )\n    elif isinstance(items, Iterator):\n        items = np.array(list(items), dtype=np.float64)\n    elif isinstance(items, np.ndarray):\n        if dim == 1:\n            if items.shape[0] != n_assets:\n                raise ValueError(\n                    f\"Expected {n_assets} {name}s, got {items.shape[0]}.\"\n                )\n        elif dim == 2:\n            if items.shape != (n_assets, n_assets):\n                raise ValueError(\n                    f\"Expected {n_assets} x {n_assets} {name}s, got {items.shape}.\"\n                )\n    else:\n        raise TypeError(\n            f\"Expected '{name}' to be a dictionary, numpy array, or array-like, \"\n            f\"got {type(items)}.\"\n        )\n\n    if dim == 1:\n        if items"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if dim not in [1, 2]:\n        raise ValueError(\"'dim' must be either 1 or 2.\")\n\n    if assets_names is not None:\n        if len(assets_names) != n_assets:\n            raise ValueError(\n                f\"Expected {n_assets} asset names, got {len(assets_names)}.\"\n            )\n\n    if isinstance(items, dict):\n        if assets_names is None:\n            assets_names = list(items.keys())\n        if len(assets_names) != n_assets:\n            raise ValueError(\n                f\"Expected {n_assets} asset names, got {len(assets_names)}.\"\n            )\n        if fill_value is None:\n            raise ValueError(\n                f\"'items' is a dictionary but 'fill_value' is None. Please provide a value to fill in for missing elements.\"\n            )\n        if dim == 1:\n            array = np.full(n_assets, fill_value)\n        else:\n            array = np.full((n_assets, n_assets), fill_value)\n        for i in range(n_assets):\n            if assets_names[i] in items:\n                array[i] = items[assets_names[i]]\n        return array\n\n    if dim == 1:\n        array = np.asarray(items)\n        if len(array) != n_assets:\n            raise ValueError(f\"Expected {n_assets} assets, got {len(array)}.\")\n        return array\n\n    array = np.asarray(items)\n    if len(array.shape) != 2:\n        raise ValueError(f\"Expected 2-dimensional array, got {len(array.shape)}.\")\n    if array.shape[0] != array.shape[1]:\n        raise ValueError(\n            f\"Expected square 2-dimensional array, got {array.shape[0]} x {array.shape[1]}.\"\n        )\n    if array.shape[0] != n_assets:\n        raise ValueError(f\"Expected {n_assets} assets,"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(f\"'assets_names' must be provided when 'items' is a dict\")\n        if len(items) != len(assets_names):\n            raise ValueError(\n                f\"'items' and 'assets_names' must have the same length, got {len(items)} and {len(assets_names)}\"\n            )\n        if fill_value is None:\n            raise ValueError(f\"'fill_value' must be provided when 'items' is a dict\")\n        if dim != 2:\n            raise ValueError(f\"'dim' must be 2 when 'items' is a dict\")\n        if len(assets_names) != n_assets:\n            raise ValueError(\n                f\"'assets_names' must have the same length as 'n_assets', got {len(assets_names)} and {n_assets}\"\n            )\n        array = np.full((n_assets, n_assets), fill_value)\n        for key, value in items.items():\n            if key not in assets_names:\n                raise ValueError(\n                    f\"'{key}' is not a valid asset name, got {list(assets_names)}\"\n                )\n            if value is None:\n                raise ValueError(\n                    f\"'{key}' is missing a value for '{name}', got {items}\"\n                )\n            array[assets_names == key] = value\n    else:\n        if dim != 1:\n            raise ValueError(f\"'dim' must be 1 when 'items' is not a dict\")\n        if n_assets != len(items):\n            raise ValueError(\n                f\"'items' must have length equal to 'n_assets', got {len(items)} and {n_assets}\"\n            )\n        array = np.asarray(items)\n    if array.ndim != dim:\n        raise ValueError(\n            f\"'{name}' must have dimension '{dim}', got {array.ndim} for {array}\"\n        )\n    if array.shape != (n_assets,"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if dim not in [1, 2]:\n        raise ValueError(f\"Dimension must be either 1 or 2, got {dim}\")\n\n    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                f\"'{name}' is a dictionary but 'assets_names' is None.\"\n                f\"'assets_names' must be provided if '{name}' is a dictionary.\"\n            )\n        if len(assets_names) != len(items):\n            raise ValueError(\n                f\"Expected {len(assets_names)} assets names, got {len(items)}.\"\n            )\n        if fill_value is None:\n            raise ValueError(\n                f\"'{name}' is a dictionary but 'fill_value' is None.\"\n                f\"'fill_value' must be provided if '{name}' is a dictionary.\"\n            )\n        if not all(name in items for name in assets_names):\n            raise ValueError(\n                f\"'{name}' is a dictionary but not all asset names are present.\"\n                f\"'{name}' must have all the asset names specified in 'assets_names'.\"\n            )\n        items = np.array(\n            [items[name] if name in items else fill_value for name in assets_names]\n        )\n\n    if isinstance(items, pd.DataFrame):\n        if dim == 1:\n            items = items.to_numpy()\n        else:\n            items = items.to_numpy().reshape(-1, n_assets)\n\n    if isinstance(items, pd.Series):\n        items = items.to_numpy()\n\n    if isinstance(items, np.ndarray):\n        if dim == 1:\n            if items.ndim != 1:\n                raise ValueError(\n                    f\"Expected 1D array for '{name}', got {items.ndim}D array.\"\n                )\n            if len(items) != n_assets:\n                raise ValueError(\n                    f\"Expected {n_assets} assets, got {len(items)} assets.\"\n                )\n        else:"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data[\"purpose_embedding\"]\n        if isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data[\"dynamic_prompt\"],\n            purpose=data[\"purpose\"],\n            purpose_embedding=purpose_embedding,\n            depth=data[\"depth\"],\n            max_depth=data[\"max_depth\"],\n            usage_count=data[\"usage_count\"],\n            id=data[\"id\"],\n            parent_id=data[\"parent_id\"],\n            working_agent=data[\"working_agent\"],\n            is_prime=data[\"is_prime\"],\n            evolve_count=data[\"evolve_count\"],\n            number_of_code_executions=data[\"number_of_code_executions\"],\n            last_input=data[\"last_input\"],\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data[\"purpose_embedding\"]\n        if isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data[\"dynamic_prompt\"],\n            purpose=data[\"purpose\"],\n            purpose_embedding=purpose_embedding,\n            depth=data[\"depth\"],\n            max_depth=data[\"max_depth\"],\n            usage_count=data[\"usage_count\"],\n            id=data[\"id\"],\n            parent_id=data[\"parent_id\"],\n            working_agent=data[\"working_agent\"],\n            is_prime=data[\"is_prime\"],\n            evolve_count=data[\"evolve_count\"],\n            number_of_code_executions=data[\"number_of_code_executions\"],\n            last_input=data[\"last_input\"],\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data[\"purpose_embedding\"]\n        if isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data[\"dynamic_prompt\"],\n            purpose=data[\"purpose\"],\n            purpose_embedding=purpose_embedding,\n            depth=data[\"depth\"],\n            max_depth=data[\"max_depth\"],\n            usage_count=data[\"usage_count\"],\n            id=data[\"id\"],\n            parent_id=data[\"parent_id\"],\n            working_agent=data[\"working_agent\"],\n            is_prime=data[\"is_prime\"],\n            evolve_count=data[\"evolve_count\"],\n            number_of_code_executions=data[\"number_of_code_executions\"],\n            last_input=data[\"last_input\"],\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data[\"purpose_embedding\"]\n        if isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data[\"dynamic_prompt\"],\n            purpose=data[\"purpose\"],\n            purpose_embedding=purpose_embedding,\n            depth=data[\"depth\"],\n            max_depth=data[\"max_depth\"],\n            usage_count=data[\"usage_count\"],\n            id=data[\"id\"],\n            parent_id=data[\"parent_id\"],\n            working_agent=data[\"working_agent\"],\n            is_prime=data[\"is_prime\"],\n            evolve_count=data[\"evolve_count\"],\n            number_of_code_executions=data[\"number_of_code_executions\"],\n            last_input=data[\"last_input\"],\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n        )\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = np.array(data[\"purpose_embedding\"])\n        return MicroAgent(\n            dynamic_prompt=data[\"dynamic_prompt\"],\n            purpose=data[\"purpose\"],\n            purpose_embedding=purpose_embedding,\n            depth=data[\"depth\"],\n            max_depth=data[\"max_depth\"],\n            usage_count=data[\"usage_count\"],\n            id=data[\"id\"],\n            parent_id=data[\"parent_id\"],\n            working_agent=data[\"working_agent\"],\n            is_prime=data[\"is_prime\"],\n            evolve_count=data[\"evolve_count\"],\n            number_of_code_executions=data[\"number_of_code_executions\"],\n            last_input=data[\"last_input\"],\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\", None)\n        if purpose_embedding is not None:\n            purpose_embedding = np.array(purpose_embedding)\n\n        return MicroAgent(\n            dynamic_prompt=data[\"dynamic_prompt\"],\n            purpose=data[\"purpose\"],\n            purpose_embedding=purpose_embedding,\n            depth=data[\"depth\"],\n            max_depth=data[\"max_depth\"],\n            usage_count=data[\"usage_count\"],\n            id=data[\"id\"],\n            parent_id=data[\"parent_id\"],\n            working_agent=data[\"working_agent\"],\n            is_prime=data[\"is_prime\"],\n            evolve_count=data[\"evolve_count\"],\n            number_of_code_executions=data[\"number_of_code_executions\"],\n            last_input=data[\"last_input\"],\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n        )\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding:\n            purpose_embedding = np.array(purpose_embedding)\n\n        agent = MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n        )\n\n        return agent"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data[\"purpose_embedding\"]\n        if isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data[\"dynamic_prompt\"],\n            purpose=data[\"purpose\"],\n            purpose_embedding=purpose_embedding,\n            depth=data[\"depth\"],\n            max_depth=data[\"max_depth\"],\n            usage_count=data[\"usage_count\"],\n            id=data[\"id\"],\n            parent_id=data[\"parent_id\"],\n            working_agent=data[\"working_agent\"],\n            is_prime=data[\"is_prime\"],\n            evolve_count=data[\"evolve_count\"],\n            number_of_code_executions=data[\"number_of_code_executions\"],\n            last_input=data[\"last_input\"],\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n        )\n\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data[\"purpose_embedding\"]\n        if isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)\n\n        return MicroAgent(\n            dynamic_prompt=data[\"dynamic_prompt\"],\n            purpose=data[\"purpose\"],\n            purpose_embedding=purpose_embedding,\n            depth=data[\"depth\"],\n            max_depth=data[\"max_depth\"],\n            usage_count=data[\"usage_count\"],\n            id=data[\"id\"],\n            parent_id=data[\"parent_id\"],\n            working_agent=data[\"working_agent\"],\n            is_prime=data[\"is_prime\"],\n            evolve_count=data[\"evolve_count\"],\n            number_of_code_executions=data[\"number_of_code_executions\"],\n            last_input=data[\"last_input\"],\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n        )\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        if \"dynamic_prompt\" in data:\n            dynamic_prompt = data[\"dynamic_prompt\"]\n        else:\n            dynamic_prompt = \"\"\n\n        if \"purpose\" in data:\n            purpose = data[\"purpose\"]\n        else:\n            purpose = \"\"\n\n        if \"purpose_embedding\" in data:\n            purpose_embedding = np.array(data[\"purpose_embedding\"])\n        else:\n            purpose_embedding = np.array([])\n\n        if \"depth\" in data:\n            depth = data[\"depth\"]\n        else:\n            depth = 0\n\n        if \"max_depth\" in data:\n            max_depth = data[\"max_depth\"]\n        else:\n            max_depth = 0\n\n        if \"usage_count\" in data:\n            usage_count = data[\"usage_count\"]\n        else:\n            usage_count = 0\n\n        if \"id\" in data:\n            id = data[\"id\"]\n        else:\n            id = \"\"\n\n        if \"parent_id\" in data:\n            parent_id = data[\"parent_id\"]\n        else:\n            parent_id = \"\"\n\n        if \"working_agent\" in data:\n            working_agent = data[\"working_agent\"]\n        else:\n            working_agent = \"\"\n\n        if \"is_prime\" in data:\n            is_prime = data[\"is_prime\"]\n        else:\n            is_prime = False\n\n        if \"evolve_count\" in data:\n            evolve_count = data[\"evolve_count\"]\n        else:\n            evolve_count = 0\n\n        if \"number_of_code_executions\" in data:\n            number_of_code_executions = data[\"number_of_code_executions\"]\n        else:\n            number_of_code_executions = 0\n\n        if \"last_input\" in data:\n            last_input = data[\"last_input\"]\n        else:\n            last_input = \"\"\n\n        return MicroAgent(\n            dynamic_prompt,\n            purpose,"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data[\"purpose_embedding\"]\n        if isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data[\"dynamic_prompt\"],\n            purpose=data[\"purpose\"],\n            purpose_embedding=purpose_embedding,\n            depth=data[\"depth\"],\n            max_depth=data[\"max_depth\"],\n            usage_count=data[\"usage_count\"],\n            id=data[\"id\"],\n            parent_id=data[\"parent_id\"],\n            working_agent=data[\"working_agent\"],\n            is_prime=data[\"is_prime\"],\n            evolve_count=data[\"evolve_count\"],\n            number_of_code_executions=data[\"number_of_code_executions\"],\n            last_input=data[\"last_input\"],\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n        )\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        if \"dynamic_prompt\" in data:\n            dynamic_prompt = data[\"dynamic_prompt\"]\n        else:\n            dynamic_prompt = \"\"\n\n        if \"purpose\" in data:\n            purpose = data[\"purpose\"]\n        else:\n            purpose = \"\"\n\n        if \"purpose_embedding\" in data:\n            purpose_embedding = data[\"purpose_embedding\"]\n        else:\n            purpose_embedding = []\n\n        if \"depth\" in data:\n            depth = data[\"depth\"]\n        else:\n            depth = 0\n\n        if \"max_depth\" in data:\n            max_depth = data[\"max_depth\"]\n        else:\n            max_depth = 0\n\n        if \"usage_count\" in data:\n            usage_count = data[\"usage_count\"]\n        else:\n            usage_count = 0\n\n        if \"id\" in data:\n            id = data[\"id\"]\n        else:\n            id = \"\"\n\n        if \"parent_id\" in data:\n            parent_id = data[\"parent_id\"]\n        else:\n            parent_id = \"\"\n\n        if \"working_agent\" in data:\n            working_agent = data[\"working_agent\"]\n        else:\n            working_agent = \"\"\n\n        if \"is_prime\" in data:\n            is_prime = data[\"is_prime\"]\n        else:\n            is_prime = False\n\n        if \"evolve_count\" in data:\n            evolve_count = data[\"evolve_count\"]\n        else:\n            evolve_count = 0\n\n        if \"number_of_code_executions\" in data:\n            number_of_code_executions = data[\"number_of_code_executions\"]\n        else:\n            number_of_code_executions = 0\n\n        if \"last_input\" in data:\n            last_input = data[\"last_input\"]\n        else:\n            last_input = \"\"\n\n        return MicroAgent(\n            dynamic_prompt=dynamic_prompt,\n            purpose=purpose,"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        if \"purpose_embedding\" in data:\n            purpose_embedding = np.array(data[\"purpose_embedding\"])\n        else:\n            purpose_embedding = None\n\n        return MicroAgent(\n            dynamic_prompt=data[\"dynamic_prompt\"],\n            purpose=data[\"purpose\"],\n            purpose_embedding=purpose_embedding,\n            depth=data[\"depth\"],\n            max_depth=data[\"max_depth\"],\n            usage_count=data[\"usage_count\"],\n            id=data[\"id\"],\n            parent_id=data[\"parent_id\"],\n            working_agent=data[\"working_agent\"],\n            is_prime=data[\"is_prime\"],\n            evolve_count=data[\"evolve_count\"],\n            number_of_code_executions=data[\"number_of_code_executions\"],\n            last_input=data[\"last_input\"],\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n        )\n\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data[\"purpose_embedding\"]\n        if isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)\n\n        agent = MicroAgent(\n            purpose=data[\"purpose\"],\n            dynamic_prompt=data[\"dynamic_prompt\"],\n            purpose_embedding=purpose_embedding,\n            depth=data[\"depth\"],\n            max_depth=data[\"max_depth\"],\n            usage_count=data[\"usage_count\"],\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n            id=data[\"id\"],\n            parent_id=data[\"parent_id\"],\n            working_agent=data[\"working_agent\"],\n            is_prime=data[\"is_prime\"],\n            evolve_count=data[\"evolve_count\"],\n            number_of_code_executions=data[\"number_of_code_executions\"],\n            last_input=data[\"last_input\"],\n        )\n        return agent"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\", None)\n        if purpose_embedding is not None:\n            purpose_embedding = np.array(purpose_embedding)\n\n        return MicroAgent(\n            dynamic_prompt=data[\"dynamic_prompt\"],\n            purpose=data[\"purpose\"],\n            purpose_embedding=purpose_embedding,\n            depth=data[\"depth\"],\n            max_depth=data[\"max_depth\"],\n            usage_count=data[\"usage_count\"],\n            id=data[\"id\"],\n            parent_id=data[\"parent_id\"],\n            working_agent=data[\"working_agent\"],\n            is_prime=data[\"is_prime\"],\n            evolve_count=data[\"evolve_count\"],\n            number_of_code_executions=data[\"number_of_code_executions\"],\n            last_input=data[\"last_input\"],\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n        )\n\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding is not None:\n            purpose_embedding = np.array(purpose_embedding)\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n        )\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        agent = MicroAgent(\n            dynamic_prompt=data[\"dynamic_prompt\"],\n            purpose=data[\"purpose\"],\n            purpose_embedding=np.array(data[\"purpose_embedding\"]),\n            depth=data[\"depth\"],\n            max_depth=data[\"max_depth\"],\n            usage_count=data[\"usage_count\"],\n            id=data[\"id\"],\n            parent_id=data[\"parent_id\"],\n            working_agent=data[\"working_agent\"],\n            is_prime=data[\"is_prime\"],\n            evolve_count=data[\"evolve_count\"],\n            number_of_code_executions=data[\"number_of_code_executions\"],\n            last_input=data[\"last_input\"],\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n        )\n\n        return agent\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data[\"purpose_embedding\"]\n        if isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data[\"dynamic_prompt\"],\n            purpose=data[\"purpose\"],\n            purpose_embedding=purpose_embedding,\n            depth=data[\"depth\"],\n            max_depth=data[\"max_depth\"],\n            usage_count=data[\"usage_count\"],\n            id=data[\"id\"],\n            parent_id=data[\"parent_id\"],\n            working_agent=data[\"working_agent\"],\n            is_prime=data[\"is_prime\"],\n            evolve_count=data[\"evolve_count\"],\n            number_of_code_executions=data[\"number_of_code_executions\"],\n            last_input=data[\"last_input\"],\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n        )\n\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        agent = MicroAgent(\n            agent_lifecycle,\n            data[\"purpose\"],\n            openai_wrapper,\n            data[\"dynamic_prompt\"],\n            data[\"max_depth\"],\n            data[\"depth\"],\n            data[\"is_prime\"],\n            data[\"evolve_count\"],\n            data[\"number_of_code_executions\"],\n            data[\"last_input\"],\n        )\n        agent.id = data[\"id\"]\n        agent.parent_id = data[\"parent_id\"]\n        agent.usage_count = data[\"usage_count\"]\n        agent.purpose_embedding = data[\"purpose_embedding\"]\n        agent.working_agent = data[\"working_agent\"]\n        return agent"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data[\"purpose_embedding\"]\n        if isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data[\"dynamic_prompt\"],\n            purpose=data[\"purpose\"],\n            purpose_embedding=purpose_embedding,\n            depth=data[\"depth\"],\n            max_depth=data[\"max_depth\"],\n            usage_count=data[\"usage_count\"],\n            id=data[\"id\"],\n            parent_id=data[\"parent_id\"],\n            working_agent=data[\"working_agent\"],\n            is_prime=data[\"is_prime\"],\n            evolve_count=data[\"evolve_count\"],\n            number_of_code_executions=data[\"number_of_code_executions\"],\n            last_input=data[\"last_input\"],\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n        )\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = 12.92 * srgb\n  linear1 = (srgb + 0.055) / 1.055 ** 2.4\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = 12.92 * srgb\n  linear1 = (srgb + 0.055) / 1.055 ** 2.4\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = 12.92 * srgb\n  linear1 = 1.055 * xnp.power(srgb, 1 / 2.4) - 0.055\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = 12.92 * srgb\n  linear1 = (srgb + 0.055) / 1.055 ** 2.4\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = 12.92 * srgb\n  linear1 = 1.055 * xnp.power(srgb, 1 / 2.4) - 0.055\n  return xnp.where(srgb <= 0.0031308, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = 12.92 * srgb\n  linear1 = 1.055 * xnp.power(srgb, 1 / 2.4) - 0.055\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = 12.92 * srgb\n  linear1 = 1.055 * srgb ** (1 / 2.4) - 0.055\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = 12.92 * srgb\n  linear1 = (srgb + 0.055) / 1.055\n  linear2 = (1.055 * xnp.power(srgb, 1 / 2.4)) - 0.055\n  return xnp.where(srgb <= 0.0031308, linear0, xnp.where(srgb <= 0.4045, linear1, linear2))\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = 12.92 * srgb\n  linear1 = (srgb + 0.055) / 1.055 ** 2.4\n  return xnp.where(srgb <= 0.0031308, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = 12.92 * srgb\n  linear1 = 1.055 * xnp.power(srgb, 1 / 2.4) - 0.055\n  return xnp.where(srgb <= 0.0031308, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = 12.92 * srgb\n  linear1 = 1.055 * xnp.power(srgb, 1 / 2.4) - 0.055\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  srgb = xnp.maximum(eps, srgb)\n  linear0 = 12.92 * srgb\n  linear1 = 1.055 * xnp.power(srgb, 1 / 2.4) - 0.055\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = 323 / 25 * srgb\n  linear1 = 211 * srgb ** (1 / 12) - 11 / 500\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = 12.92 * srgb\n  linear1 = 1.055 * xnp.power(srgb, 1 / 2.4) - 0.055\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = 323 / 25 * srgb\n  linear1 = 211 * xnp.maximum(eps, srgb) ** (5 / 12) - 11\n  return xnp.where(srgb <= 0.04045, linear0, linear1) / 100\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = 12.92 * srgb\n  linear1 = (srgb + 0.055) / 1.055 ** 2.4\n  return xnp.where(srgb <= 0.0031308, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = 323 / 25 * srgb\n  linear1 = 116 * srgb - 16\n  return xnp.where(srgb <= 0.04045, linear0, xnp.where(srgb <= 0.41666666666666663, linear1, xnp.power((srgb + eps) / 1.055, 2.4)))\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = 12.92 * srgb\n  linear1 = 1.055 * srgb ** (1 / 2.4) - 0.055\n  return xnp.where(srgb <= 0.0031308, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  return xnp.where(srgb <= 0.04045, srgb / 12.92, ((srgb + eps) / 1.055) ** 2.4)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = 12.92 * srgb\n  linear1 = 1.055 * srgb ** (xnp.exp(1 / 2.4) - 1)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  spline_degree = min(spline_degree, len(x) - 1)\n  x_interp = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n  return scipy.interpolate.splev(t_output, x_interp)\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Adjust spline degree to be at most one less than the number of points in x.\n  spline_degree = min(spline_degree, len(x) - 1)\n\n  # Calculate the spline coefficients.\n  tck = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n\n  # Interpolate the signal at the output times.\n  return scipy.interpolate.splev(t_output, tck)\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  x = np.asarray(x)\n  t_input = np.asarray(t_input)\n  t_output = np.asarray(t_output)\n  spline_degree = min(spline_degree, len(x) - 1)\n  tck, _ = scipy.interpolate.splprep(x, k=spline_degree, s=smoothness)\n  return scipy.interpolate.splev(t_output, tck)\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  spline_degree = min(spline_degree, len(t_input) - 1)\n  t_input = np.array(t_input)\n  t_output = np.array(t_output)\n  x = np.array(x)\n  tck, _ = scipy.interpolate.splprep(x.T, k=spline_degree, s=smoothness)\n  x_interpolated = scipy.interpolate.splev(t_output, tck)\n  return x_interpolated\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  spline_degree = min(spline_degree, len(x) - 1)\n  tck, u_keyframes = scipy.interpolate.splprep(x, k=spline_degree, s=smoothness)\n  new_x = np.array(scipy.interpolate.splev(t_output, tck))\n  return new_x\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Set up the interpolation.\n  spline_degree = min(spline_degree, len(x) - 1)\n  tck, _ = scipy.interpolate.splprep(x.T, k=spline_degree, s=smoothness)\n\n  # Interpolate the signal.\n  x_interpolated = scipy.interpolate.splev(t_output, tck)\n\n  return x_interpolated\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Calculate the spline coefficients.\n  tck, u_keyframes = scipy.interpolate.splprep(x, k=spline_degree, s=smoothness)\n  # Interpolate the signal.\n  x_interp = scipy.interpolate.splev(t_output, tck)\n  return x_interp\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Setup the spline interpolation\n  x = np.array(x)\n  t_input = np.array(t_input)\n  t_output = np.array(t_output)\n  spline_degree = min(spline_degree, len(x) - 1)\n  tck, _ = scipy.interpolate.splprep(x.T, k=spline_degree, s=smoothness, per=False)\n\n  # Interpolate the signal\n  x_interp = scipy.interpolate.splev(t_output, tck)\n\n  return x_interp\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Calculate the number of points in the signal.\n  n_points = len(x)\n\n  # Calculate the number of points in the spline.\n  n_spline_points = n_points + spline_degree\n\n  # Calculate the number of knots in the spline.\n  n_knots = n_spline_points + 1\n\n  # Calculate the number of spline coefficients.\n  n_coefficients = n_knots - spline_degree\n\n  # Calculate the number of knots in the spline.\n  n_knots = n_spline_points + 1\n\n  # Calculate the number of spline coefficients.\n  n_coefficients = n_knots - spline_degree\n\n  # Calculate the number of spline coefficients.\n  n_coefficients = n_knots - spline_degree\n\n  # Calculate the number of spline coefficients.\n  n_coefficients = n_knots - spline_degree\n\n  # Calculate the number of spline coefficients.\n  n_coefficients = n_knots - spline_degree\n\n  # Calculate the number of spline coefficients.\n  n_coefficients = n_knots - spline_degree\n\n  # Calculate the number of spline coefficients.\n  n_coefficients = n_knots - spline_degree\n\n  # Calculate the number of spline coefficients.\n  n_coefficients = n_knots - spline_degree\n\n  # Calculate the number of spline coefficients.\n  n_coefficients = n_knots - spline_degree\n\n  # Calculate the number of spline coefficients.\n  n_coefficients = n_knots - spline_degree\n\n  # Calculate the number of spline coefficients.\n  n_coefficients = n_knots - spline_degree\n\n  # Calculate the number of spline coefficients.\n  n_coefficients = n_knot"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Adjust the spline degree to be at most one less than the number of points in x.\n  spline_degree = min(spline_degree, len(x) - 1)\n\n  # Get the spline coefficients.\n  tck, _ = scipy.interpolate.splprep(x.T, k=spline_degree, s=smoothness)\n\n  # Interpolate the signal at the desired output times.\n  x_interp = scipy.interpolate.splev(t_output, tck)\n\n  return x_interp\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Ensure that the input and output times are numpy arrays.\n  t_input = np.asarray(t_input)\n  t_output = np.asarray(t_output)\n\n  # Ensure that the input and output times are sorted.\n  assert np.all(t_input[1:] - t_input[:-1] >= 0)\n  assert np.all(t_output[1:] - t_output[:-1] >= 0)\n\n  # Ensure that the input and output times have the same dimension.\n  assert t_input.ndim == t_output.ndim\n\n  # Ensure that the input and output times have the same number of elements.\n  assert t_input.size == t_output.size\n\n  # Ensure that the input and output times have the same dimension.\n  assert t_input.ndim == t_output.ndim\n\n  # Ensure that the input and output times have the same number of elements.\n  assert t_input.size == t_output.size\n\n  # Ensure that the input and output times have the same dimension.\n  assert t_input.ndim == t_output.ndim\n\n  # Ensure that the input and output times have the same number of elements.\n  assert t_input.size == t_output.size\n\n  # Ensure that the input and output times have the same dimension.\n  assert t_input.ndim == t_output.ndim\n\n  # Ensure that the input and output times have the same number of elements.\n  assert t_input.size == t_output.size\n\n  # Ensure that the input and output times have the same dimension.\n  assert t_input.ndim == t_output.ndim\n\n  # Ensure that the input and output times have the same number of elements.\n  assert t_input.size == t_output.size\n\n  # Ensure that the input and output times have the same dimension.\n  assert t_input.ndim == t_output.ndim\n\n  # Ensure that the input and output times have the same number of elements.\n  assert t_input."}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Get the number of points in x.\n  n = len(x)\n\n  # Adjust the spline degree to be at most one less than the number of points in x.\n  k = min(n - 1, spline_degree)\n\n  # Fit the spline.\n  tck, u = scipy.interpolate.splprep(x.T, k=k, s=smoothness)\n\n  # Interpolate the signal at the output times.\n  return scipy.interpolate.splev(t_output, tck)\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Ensure that the number of points in x is at least equal to the spline degree.\n  if len(x) < spline_degree:\n    spline_degree = len(x)\n\n  # Calculate the knots of the spline.\n  t_knots = np.linspace(np.min(t_input), np.max(t_input), len(x))\n\n  # Calculate the spline coefficients.\n  c = scipy.interpolate.splrep(t_knots, x, k=spline_degree, s=smoothness)\n\n  # Interpolate the signal at the requested times.\n  x_interpolated = scipy.interpolate.splev(t_output, c)\n\n  return x_interpolated\n\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Convert input arguments to numpy arrays\n  x = np.array(x)\n  t_input = np.array(t_input)\n  t_output = np.array(t_output)\n\n  # Determine the maximum spline degree\n  spline_degree = min(spline_degree, len(x) - 1)\n\n  # Determine the knot vector\n  t = np.concatenate((t_input, np.array([t_input[-1]])))\n\n  # Interpolate the signal\n  x_interpolated = scipy.interpolate.splrep(t, x, k=spline_degree, s=smoothness)\n  x_interpolated = scipy.interpolate.splev(t_output, x_interpolated)\n\n  return x_interpolated\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  x = np.asarray(x)\n  t_input = np.asarray(t_input)\n  t_output = np.asarray(t_output)\n  assert x.ndim == 1\n  assert t_input.ndim == 1\n  assert t_output.ndim == 1\n  assert x.shape[0] == t_input.shape[0]\n  assert t_input.shape[0] >= spline_degree + 1\n  assert t_input.shape[0] >= 2\n  assert np.all(np.diff(t_input) > 0)\n  assert np.all(t_output >= t_input[0])\n  assert np.all(t_output <= t_input[-1])\n\n  # Adjust the spline degree to be at most one less than the number of points.\n  spline_degree = min(spline_degree, x.shape[0] - 1)\n\n  # Fit the spline.\n  tck, _ = scipy.interpolate.splprep(x.T, k=spline_degree, s=smoothness)\n\n  # Interpolate the spline.\n  x_interp = scipy.interpolate.splev(t_output, tck)\n  return x_interp\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Make sure the input is a numpy array\n  x = np.array(x)\n  t_input = np.array(t_input)\n  t_output = np.array(t_output)\n\n  # Make sure that the input is 1-dimensional\n  if len(x.shape) != 1:\n    raise ValueError(\"The input signal x must be 1-dimensional.\")\n  if len(t_input.shape) != 1:\n    raise ValueError(\"The input times t_input must be 1-dimensional.\")\n  if len(t_output.shape) != 1:\n    raise ValueError(\"The input times t_output must be 1-dimensional.\")\n\n  # Make sure that the input times are sorted\n  if not np.all(np.diff(t_input) > 0):\n    raise ValueError(\"The input times t_input must be sorted in ascending order.\")\n  if not np.all(np.diff(t_output) > 0):\n    raise ValueError(\"The input times t_output must be sorted in ascending order.\")\n\n  # Make sure that the input signal is defined at all input times\n  if not np.all(np.isin(t_input, t_output)):\n    raise ValueError(\"The input signal x is not defined at all input times t_input.\")\n\n  # Make sure that the input signal is defined at all output times\n  if not np.all(np.isin(t_output, t_input)):\n    raise ValueError(\"The input signal x is not defined at all output times t_output.\")\n\n  # Make sure that the spline degree is at most one less than the number of points in x\n  if spline_degree >= len(x):\n    raise ValueError(\"The spline degree must be at most one less than the number of points in x.\")\n\n  # Make sure that the smoothness parameter is positive\n  if smoothness <= 0:\n    raise ValueError(\"The smoothness parameter must be positive.\")\n\n  # Make sure that the input times are unique\n  if len(np.unique(t_input)) != len(t_input):\n   "}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Make sure the input signal is a 1-dimensional array.\n  x = np.array(x)\n  if len(x.shape) != 1:\n    raise ValueError('x must be a 1-dimensional array.')\n\n  # Make sure the input and output times are 1-dimensional arrays.\n  t_input = np.array(t_input)\n  t_output = np.array(t_output)\n  if len(t_input.shape) != 1 or len(t_output.shape) != 1:\n    raise ValueError('t_input and t_output must be 1-dimensional arrays.')\n\n  # Make sure the input and output times are sorted.\n  if not np.all(np.diff(t_input) >= 0) or not np.all(np.diff(t_output) >= 0):\n    raise ValueError('t_input and t_output must be sorted.')\n\n  # Make sure the input and output times are not empty.\n  if len(t_input) == 0 or len(t_output) == 0:\n    raise ValueError('t_input and t_output must have at least one element.')\n\n  # Make sure the input and output times have the same number of elements.\n  if len(t_input) != len(t_output):\n    raise ValueError('t_input and t_output must have the same number of elements.')\n\n  # Make sure the input signal has the same number of elements as the input times.\n  if len(x) != len(t_input):\n    raise ValueError('x and t_input must have the same number of elements.')\n\n  # Make sure the spline degree is at least one.\n  if spline_degree < 1:\n    raise ValueError('spline_degree must be at least 1.')\n\n  # Make sure the smoothness parameter is positive.\n  if smoothness <= 0:\n    raise ValueError('smoothness must be positive.')\n\n  # Make sure the spline degree is at most one less than the number of points in x.\n  if spl"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Check that the input and output times are sorted.\n  if not np.all(np.diff(t_input) > 0):\n    raise ValueError(\"Input times are not sorted.\")\n  if not np.all(np.diff(t_output) > 0):\n    raise ValueError(\"Output times are not sorted.\")\n\n  # Check that the input and output times are within the bounds of the input times.\n  if np.min(t_output) < np.min(t_input):\n    raise ValueError(\"Output times are out of bounds.\")\n  if np.max(t_output) > np.max(t_input):\n    raise ValueError(\"Output times are out of bounds.\")\n\n  # Check that the input and output times are within the bounds of the input times.\n  if np.min(t_input) < 0:\n    raise ValueError(\"Input times are out of bounds.\")\n\n  # Check that the input signal is 1-dimensional.\n  if len(x.shape) != 1:\n    raise ValueError(\"Input signal is not 1-dimensional.\")\n\n  # Check that the input and output times are within the bounds of the input times.\n  if np.max(t_output) > len(x):\n    raise ValueError(\"Output times are out of bounds.\")\n\n  # Check that the input and output times are within the bounds of the input times.\n  if np.max(t_input) > len(x):\n    raise ValueError(\"Input times are out of bounds.\")\n\n  # Check that the spline degree is at most one less than the number of points.\n  if spline_degree >= len(x) - 1:\n    raise ValueError(\"Spline degree is too high.\")\n\n  # Check that the smoothness parameter is positive.\n  if smoothness <= 0:\n    raise ValueError(\"Smoothness parameter is not positive.\")\n\n  # Check that the input and output times are within the bounds of the input times.\n  if np.min(t_output) < 0:\n    raise ValueError(\"Output times are out of bounds.\")\n\n  # Check that the input and output"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Make sure the input is in the right format.\n  t_input = np.asarray(t_input)\n  x = np.asarray(x)\n  t_output = np.asarray(t_output)\n\n  # Calculate the number of points in the spline.\n  n_points = len(t_input)\n\n  # Calculate the number of degrees of freedom in the spline.\n  n_dof = n_points - spline_degree\n\n  # Calculate the number of degrees of freedom in the spline.\n  n_dof = n_points - spline_degree\n\n  # Calculate the knot vector.\n  knots = np.zeros(n_dof + spline_degree + 1)\n  knots[0:spline_degree] = np.linspace(t_input[0], t_input[spline_degree], spline_degree)\n  knots[spline_degree:n_dof + spline_degree] = np.linspace(t_input[spline_degree], t_input[n_points - 1], n_dof)\n  knots[n_dof + spline_degree:] = np.linspace(t_input[n_points - 1], t_input[n_points - 1], spline_degree)\n\n  # Calculate the B-spline coefficients.\n  coeffs = np.zeros(n_dof)\n  coeffs[0:n_dof] = x\n\n  # Calculate the B-spline basis functions.\n  basis_funcs = scipy.interpolate.BSpline(knots, coeffs, spline_degree)\n\n  # Calculate the interpolated values of the signal at t_output times.\n  x_interp = basis_funcs(t_output, nu=spline_degree)\n\n  return x_interp\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Number of input points.\n  n_input = len(t_input)\n\n  # Number of output points.\n  n_output = len(t_output)\n\n  # Number of spline points.\n  n_spline = n_input - spline_degree\n\n  # Number of spline intervals.\n  n_intervals = n_spline - 1\n\n  # Number of spline basis functions.\n  n_basis = n_intervals + spline_degree + 1\n\n  # Spline basis functions.\n  # The first spline basis function is 1 at the first interval and 0 elsewhere.\n  # The last spline basis function is 1 at the last interval and 0 elsewhere.\n  # The other spline basis functions are the Bernstein polynomials.\n  basis = np.zeros((n_basis, n_intervals))\n  basis[0, :] = 1.0\n  basis[spline_degree, :] = 1.0\n  for i in range(1, spline_degree):\n    basis[i, :] = (t_input[i : n_spline + i] - t_input[i - 1 : n_spline + i - 1]) / (t_input[n_spline + i - 1 : n_spline + i] - t_input[i - 1 : i])\n    basis[spline_degree + i, :] = (t_input[n_spline + i : n_input] - t_input[n_spline + i - 1 : n_spline + i]) / (t_input[n_spline + i : n_input] - t_input[n_spline + i - 1 : n_spline + i - 1])\n  for i in range(spline_degree + 1, n_intervals):\n    basis[i, :] = scipy.special.binom(n_intervals - 1, i - 1) * (t_input[i : n_spline + i] - t_input[i - "}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    # if lower no uppers after\n    # if upper no\n    if word.islower():\n        return word\n    if word.isupper():\n        return word\n\n    # if upper no uppers after\n    # if lower no\n    if word[0].isupper() and word[1:].islower():\n        return word.lower()\n    if word[0].islower() and word[1:].isupper():\n        return word.upper()\n\n    # if upper no uppers after\n    # if lower no\n    if word[0].isupper() and word[1:].islower():\n        return word.lower()\n    if word[0].islower() and word[1:].isupper():\n        return word.upper()\n\n    # if upper no uppers after\n    # if lower no\n    if word[0].isupper() and word[1:].islower():\n        return word.lower()\n    if word[0].islower() and word[1:].isupper():\n        return word.upper()\n\n    # if upper no uppers after\n    # if lower no\n    if word[0].isupper() and word[1:].islower():\n        return word.lower()\n    if word[0].islower() and word[1:].isupper():\n        return word.upper()\n\n    # if upper no uppers after\n    # if lower no\n    if word[0].isupper() and word[1:].islower():\n        return word.lower()\n    if word[0].islower() and word[1:].isupper():\n        return word.upper()\n\n    # if upper no uppers after\n    # if lower no\n    if word[0].isupper() and word[1:].islower():\n        return word.lower()\n    if word[0].islower() and word[1:].isupper():\n        return word.upper()\n\n    # if upper no uppers after\n    # if lower no\n    if word[0].isupper() and word[1:].islower():\n        return word.lower()\n    if word[0].islower() and"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    if word.isupper():\n        return word.lower()\n    if word[0].isupper() and word[1].islower():\n        return word\n    if word[0].islower() and word[1].isupper():\n        return word.capitalize()\n    return word\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    elif word.islower():\n        return word.capitalize()\n    else:\n        if word[0].isupper() and word[1].isupper():\n            return word\n        elif word[0].isupper() and word[1].islower():\n            return word.capitalize()\n        else:\n            return word.lower()\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    if word.islower():\n        return word.capitalize()\n    if word.istitle():\n        return word\n    if word[0].isupper() and word[1].isupper():\n        return word\n    if word[0].isupper() and word[1].islower():\n        return word.lower()\n    if word[0].islower() and word[1].isupper():\n        return word.capitalize()\n    return word\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    elif word.islower():\n        return word.capitalize()\n    else:\n        # mixed case\n        if word[0].isupper() and word[1].isupper():\n            return word\n        elif word[0].isupper() and word[1].islower():\n            return word.lower()\n        elif word[0].islower() and word[1].isupper():\n            return word.upper()\n        else:\n            return word.capitalize()\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper() or word.islower():\n        return word\n    if word[0].isupper() and word[1].isupper():\n        return word\n    if word[0].isupper() and word[1].islower():\n        return word\n    if word[0].islower() and word[1].isupper():\n        return word.capitalize()\n    if word[0].islower() and word[1].islower():\n        return word.lower()\n    return word\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    if word.isupper():\n        return word.lower()\n    if word.istitle():\n        return word\n    if len(word) < 3:\n        return word.lower()\n    if word[0].isupper() and word[1].isupper():\n        return word\n    if word[0].isupper() and word[1].islower():\n        return word.lower()\n    if word[0].islower() and word[1].isupper():\n        return word.capitalize()\n    return word.lower()\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    # if lower no uppers after\n    # if upper no\n    # if upper no uppers after\n    # if lower no uppers after\n\n    if word.islower():\n        return word\n    if word.isupper():\n        return word\n    if word[0].isupper() and word[1].islower():\n        return word\n    if word[0].islower() and word[1].isupper():\n        return word.capitalize()\n    return word.lower()\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    # if lower no uppers after\n    # if upper no\n    if word.islower():\n        return word\n    elif word.isupper():\n        return word\n    else:\n        if word[0].islower() and word[1].islower():\n            return word.lower()\n        elif word[0].isupper() and word[1].isupper():\n            return word.upper()\n        else:\n            return word[0].upper() + word[1:]\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    # check if all uppercase\n    if word.isupper():\n        return word\n    # check if all lowercase\n    if word.islower():\n        return word.capitalize()\n    # check if mixed case\n    if word[0].isupper() and word[1].islower():\n        return word\n    if word[0].islower() and word[1].isupper():\n        return word.capitalize()\n\n    return word.lower()\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    if word.islower():\n        return word.capitalize()\n    if len(word) == 1:\n        return word.upper()\n    if len(word) == 2:\n        if word[0].isupper() and word[1].islower():\n            return word.capitalize()\n        if word[0].islower() and word[1].isupper():\n            return word\n    if len(word) > 2:\n        if word[0].isupper() and word[1].islower():\n            return word.capitalize()\n        if word[0].islower() and word[1].isupper():\n            return word\n    return word\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    # if lower no uppers after\n    # if upper no\n    if word.islower():\n        return word\n    if word.isupper():\n        return word\n    if word.isalpha():\n        if word[0].islower() and word[1].isupper():\n            return word\n        if word[0].isupper() and word[1].islower():\n            return word.capitalize()\n    return word\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    if word.isupper():\n        return word.lower()\n    if word.istitle():\n        return word.lower().capitalize()\n    if word[0].isupper() and word[1].islower():\n        return word.lower()\n    if word[0].islower() and word[1].isupper():\n        return word.capitalize()\n    return word\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    # if lower no uppers after\n    if word.islower():\n        return word\n    # if upper no\n    if word.isupper():\n        return word.lower()\n    # if mixed case\n    if word[0].isupper():\n        return word.lower()\n    if word[1].isupper():\n        return word.capitalize()\n    return word\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    if word.isupper():\n        return word.lower()\n    if word.istitle():\n        return word.lower().capitalize()\n\n    if len(word) == 1:\n        return word.upper()\n\n    if word[0].islower() and word[1].islower():\n        return word.lower()\n    if word[0].isupper() and word[1].isupper():\n        return word.lower()\n    if word[0].isupper() and word[1].islower():\n        return word.lower().capitalize()\n\n    return word\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    # if lower no uppers after\n    # if upper no\n    if word.islower() or word.isupper():\n        return word\n    # if first two letters are uppercase, lowercase the rest\n    if word[0].isupper() and word[1].isupper():\n        return word[0].lower() + word[1:].lower()\n    # if first two letters are lowercase, capitalize the rest\n    if word[0].islower() and word[1].islower():\n        return word[0].upper() + word[1:].upper()\n    # if first two letters are lowercase, capitalize the rest\n    if word[0].islower() and word[1].isupper():\n        return word[0].upper() + word[1:].upper()\n\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    # if lower no uppers after\n    # if upper no\n    if word.islower():\n        return word\n    if word.isupper():\n        return word.lower()\n    # if first two letters are upper, capitalize the whole word\n    if word[0:2].isupper():\n        return word.capitalize()\n    # if first two letters are lower, convert to upper\n    if word[0:2].islower():\n        return word[0:2].upper() + word[2:]\n    # if first letter is upper, convert to lower\n    if word[0].isupper():\n        return word[0].lower() + word[1:]\n    # if first letter is lower, convert to upper\n    if word[0].islower():\n        return word[0].upper() + word[1:]\n    # if no upper or lower, return as is\n    return word\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    # if lower no uppers after\n    # if upper no\n    if word.islower():\n        return word\n    elif word.isupper():\n        return word\n    elif word[0].isupper() and word[1].isupper():\n        return word\n    elif word[0].islower() and word[1].islower():\n        return word.capitalize()\n    elif word[0].isupper() and word[1].islower():\n        return word.lower()\n    elif word[0].islower() and word[1].isupper():\n        return word.upper()\n    else:\n        return word\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    # if lower no uppers after\n    if word.islower():\n        return word\n    # if upper no\n    if word.isupper():\n        return word.lower()\n    # if lower no uppers after\n    if word.isupper():\n        return word.lower()\n\n    # if mixed case, check first 2 letters\n    # if lower, lowercase\n    # if upper, capitalize\n    if word[0].islower() and word[1].islower():\n        return word.lower()\n    # if mixed case, check first 2 letters\n    # if upper, capitalize\n    # if lower, capitalize\n    if word[0].isupper() and word[1].isupper():\n        return word.capitalize()\n    # if mixed case, check first 2 letters\n    # if upper, capitalize\n    # if lower, capitalize\n    if word[0].isupper() and word[1].islower():\n        return word.capitalize()\n\n    # if mixed case, check first 2 letters\n    # if upper, capitalize\n    # if lower, capitalize\n    if word[0].islower() and word[1].isupper():\n        return word.capitalize()\n\n    return word\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    # if lower no uppers after\n    # if upper no\n\n    if word.islower():\n        return word\n    if word.isupper():\n        return word.lower()\n\n    # if first two letters are lowercase, make it all lowercase\n    if word[0:2].islower():\n        return word.lower()\n    # if first two letters are uppercase, make it all uppercase\n    if word[0:2].isupper():\n        return word.upper()\n\n    # if first two letters are capitalized, capitalize the whole word\n    if word[0].isupper() and word[1].isupper():\n        return word.capitalize()\n\n    return word\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.all(np.isin(v, [True, False])):\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not (v.dtype == np.bool):\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.array_equal(v, v.astype(bool)):\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not isinstance(v, np.ndarray):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a numpy array.\")\n\n    if not np.all(np.isin(v, [True, False])):\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only True or False values.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.all(np.isin(v, [True, False])):\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    # Check if array contains only boolean values\n    if not np.all(np.isin(v, [True, False])):\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.array_equal(v, v.astype(bool)):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a binary array.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    # Check if the input array contains only boolean values.\n    if not np.all(v == np.logical_or(v == True, v == False)):\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    # Check if the input array contains only boolean values.\n    if not np.all(np.isin(v, [True, False])):\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a binary array.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    # Check if the array contains only boolean values\n    if not np.all(np.isin(v, [True, False])):\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only binary values (i.e., True or False).\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not isinstance(v, np.ndarray):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a numpy array. \"\n            f\"Found {type(v)}\"\n        )\n\n    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a numpy array of booleans. \"\n            f\"Found {v.dtype}\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.array_equal(v, v.astype(bool)):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be binary values (i.e., contain only True or False values).\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not isinstance(v, np.ndarray):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a numpy array.\")\n\n    if not np.all(np.isin(v, [0, 1])):\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only binary values (0 or 1).\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.array_equal(v, v.astype(bool)):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be binary values (True or False).\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    # Check if the array contains only boolean values\n    if not np.all(np.isin(v, [True, False])):\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not isinstance(v, np.ndarray):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a numpy array.\")\n\n    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    # Check if the array contains only boolean values.\n    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.all(np.isin(v, [True, False])):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must contain only True or False values.\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    # check if the array contains only boolean values\n    if not np.all(np.isin(v, [True, False])):\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n\n    return v\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Compute the norm of the input array.\n  x_norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n\n  # Compute the scaled version of the input array.\n  x_scaled = x / x_norm\n\n  # Return the scaled version of the input array.\n  return x_scaled\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Compute the norm of the input.\n  norm = np.linalg.norm(x)\n\n  # Compute the scaled version of the input.\n  x_scaled = x / norm\n\n  return x_scaled\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Compute the norm of the input\n  x_norm = np.linalg.norm(x, axis=-1, keepdims=True)\n\n  # Compute the scaled version of the input\n  x_scaled = x / x_norm\n\n  return x_scaled\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Compute the norm of the input array.\n  x_norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  # Compute the scaled version of the input array.\n  x_scaled = x / x_norm\n  return x_scaled\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Compute the norm of the input.\n  x_norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  # Apply the scaling operation.\n  x_scaled = x / x_norm\n  return x_scaled\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Compute the norm of the input.\n  norm = np.linalg.norm(x)\n\n  # Apply the isotropic scaling operation.\n  x = x / norm\n\n  return x\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Compute the norm of the input array.\n  x_norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n\n  # Compute the scaled version of the input array.\n  x_scaled = x / x_norm\n\n  # Return the scaled version of the input array.\n  return x_scaled\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Compute the norm of the input.\n  x_norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n\n  # Compute the scaled version of the input.\n  x_scaled = x * (1 / x_norm)\n\n  return x_scaled\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Compute the norm of the input array.\n  x_norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n\n  # Compute the scaled version of the input array.\n  x_scaled = x * jnp.sqrt(3) / x_norm\n\n  return x_scaled\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Compute the norm of the input.\n  norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n\n  # Scale the input.\n  x_scaled = x / norm\n\n  return x_scaled\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  x_scaled = x / x_norm\n  return x_scaled\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # 3D norm\n  norm = jnp.linalg.norm(x, axis=-1)\n  # 3D scaling\n  x = x * (1 - norm)\n  return x\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Compute the norm of the input.\n  x_norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n\n  # Compute the scaled input.\n  x_scaled = x / x_norm\n\n  return x_scaled\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  x_scaled = x * (1. / x_norm)\n  return x_scaled\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  x_norm_scaled = x / x_norm\n  return x_norm_scaled\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Compute the norm of the input.\n  x_norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n\n  # Compute the scaling factor.\n  x_scale = 1. / (1. + x_norm)\n\n  # Scale the input.\n  x_scaled = x_scale * x\n\n  return x_scaled\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Compute the norm of the input array.\n  x_norm = np.linalg.norm(x)\n  # Compute the scaling factor.\n  x_scale = np.sqrt(3.0) / x_norm\n  # Apply the scaling operation.\n  x_contracted = x_scale * x\n  return x_contracted\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Compute the norm of the input.\n  x_norm = jnp.linalg.norm(x, axis=-1)\n\n  # Compute the scaling factor.\n  x_scale = 1.0 / x_norm\n\n  # Apply the scaling operation.\n  x_scaled = x * x_scale\n\n  # Return the scaled input.\n  return x_scaled\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Contracting\n  x_contract = contract(x)\n\n  # Computing the norm of the contracted input\n  x_contract_norm = jnp.linalg.norm(x_contract, axis=-1)\n\n  # Scaling the contracted input\n  x_contract_scaled = x_contract / x_contract_norm\n\n  return x_contract_scaled\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # The input array is expected to be 3-dimensional.\n  if len(x.shape) != 3:\n    raise ValueError(\n        f'Input array is expected to be 3-dimensional, but it is {len(x.shape)}-dimensional.'\n    )\n  # The input array is expected to be isotropic.\n  if x.shape[1] != x.shape[2]:\n    raise ValueError(\n        f'Input array is expected to be isotropic, but it is not.'\n    )\n  # The input array is expected to be non-negative.\n  if jnp.any(x < 0):\n    raise ValueError(\n        f'Input array is expected to be non-negative, but it is not.'\n    )\n  # The input array is expected to be non-zero.\n  if jnp.all(x == 0):\n    raise ValueError(\n        f'Input array is expected to be non-zero, but it is not.'\n    )\n  # The input array is expected to be non-singular.\n  if jnp.linalg.det(x) == 0:\n    raise ValueError(\n        f'Input array is expected to be non-singular, but it is not.'\n    )\n\n  # The input array is expected to be positive definite.\n  if jnp.all(jnp.linalg.eigvals(x) > 0):\n    raise ValueError(\n        f'Input array is expected to be positive definite, but it is not.'\n    )\n\n  # The input array is expected to be positive semi-definite.\n  if jnp.all(jnp.linalg.eigvals(x) >= 0):\n    raise ValueError(\n        f'Input array is expected to be positive semi-definite, but it is not.'\n    )\n\n  # The input array is expected to be symmetric.\n  if jnp.allclose(x, jnp.transpose(x, axes=(0, 2, 1))):\n    raise ValueError(\n        f'Input array is expected to be symmetric, but it is not"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(lambda x: ast.literal_eval(x))\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(eval)\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(lambda x: ast.literal_eval(x))\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(lambda x: ast.literal_eval(x))\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(lambda x: ast.literal_eval(x))\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(lambda x: eval(x))\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    # Load the summary file\n    summary_df = pd.read_csv(summary_path)\n\n    # Convert columns from string to dictionary\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n    for col in dict_columns:\n        summary_df[col] = summary_df[col].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else {})\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(lambda x: ast.literal_eval(x) if type(x) == str else x)\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(lambda x: ast.literal_eval(x))\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for dict_column in dict_columns:\n        summary_df[dict_column] = summary_df[dict_column].apply(lambda x: ast.literal_eval(x))\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    # Read the summary file into a DataFrame\n    summary_df = pd.read_csv(summary_path)\n\n    # Convert the dictionary-like strings in the specified columns into actual dictionaries\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    # Read the summary file into a DataFrame\n    summary_df = pd.read_csv(summary_path)\n\n    # Convert the specified columns into dictionary objects\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(ast.literal_eval)\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    with open(summary_path, 'r') as summary_file:\n        summary_lines = summary_file.readlines()\n\n    summary_dict = {}\n    for line in summary_lines:\n        line_split = line.split(',')\n        line_dict = {}\n        for i in range(len(line_split)):\n            if line_split[i] == '':\n                continue\n            elif line_split[i][0] == '\\'':\n                line_dict[dict_columns[i]] = line_split[i]\n            else:\n                line_dict[dict_columns[i]] = ast.literal_eval(line_split[i])\n        summary_dict[line_dict['doc_id']] = line_dict\n\n    summary_df = pd.DataFrame.from_dict(summary_dict, orient='index')\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    with open(summary_path, 'r') as f:\n        summary_str = f.read()\n\n    summary_dict = ast.literal_eval(summary_str)\n\n    summary_df = pd.DataFrame.from_dict(summary_dict)\n\n    for col in dict_columns:\n        summary_df[col] = summary_df[col].apply(ast.literal_eval)\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    # Load the summary file.\n    summary_df = pd.read_csv(summary_path)\n\n    # Convert the specified columns into dictionaries.\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(lambda x: ast.literal_eval(x))\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    # Load summary file\n    summary_df = pd.read_csv(summary_path)\n\n    # Convert specified columns to dictionary objects\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(lambda x: ast.literal_eval(x))\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(lambda x: ast.literal_eval(x))\n\n    return summary_df\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    det = jnp.linalg.det(cov)\n    iso_cov = cov / jnp.sqrt(det)\n  elif mode == 'accurate':\n    det = jnp.linalg.slogdet(cov)\n    iso_cov = cov / jnp.sqrt(det[1])\n  else:\n    raise ValueError(\"mode must be 'fast' or 'accurate'\")\n\n  return iso_cov\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    det = jnp.linalg.det(cov)\n    cov_iso = cov / jnp.sqrt(det)\n  elif mode == 'accurate':\n    det = jnp.linalg.slogdet(cov)\n    cov_iso = cov / jnp.exp(0.5 * det[1])\n  else:\n    raise ValueError('Invalid mode.')\n\n  return cov_iso\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    det = jnp.linalg.det(cov)\n    iso_cov = jnp.einsum('...ij,...j->...ij', cov, jnp.sqrt(det))\n  elif mode == 'accurate':\n    det = jnp.linalg.slogdet(cov)[1]\n    iso_cov = jnp.einsum('...ij,...j->...ij', cov, jnp.exp(0.5 * det))\n  else:\n    raise ValueError('Invalid mode.')\n\n  return iso_cov\n\n"}
{"namespace": "coord.isotropize", "completion": "  # Compute the eigenvalues and eigenvectors of the covariance matrices.\n  eigvec, eigval = jax.lax.linalg.eigh(\n      cov, symmetrize_input=False, sort_eigenvalues=False\n  )\n\n  # Compute the square root of the eigenvalues.\n  eigval_sqrt = math.safe_sqrt(eigval)\n\n  # Compute the isotropic covariance matrices.\n  isotropic_cov = math.matmul(eigvec * eigval_sqrt, jnp.moveaxis(eigvec, -2, -1))\n\n  return isotropic_cov\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    det = jnp.linalg.det(cov)\n    return (cov / det) * (1 / jnp.sqrt(det))\n  elif mode == 'accurate':\n    det = jnp.linalg.slogdet(cov)\n    return (cov / det[1]) * (1 / jnp.sqrt(det[1]))\n  else:\n    raise ValueError('Invalid mode.')\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    det = jnp.linalg.det(cov)\n    iso_cov = cov / jnp.sqrt(det)\n  elif mode == 'accurate':\n    log_det = jnp.linalg.slogdet(cov)[1]\n    iso_cov = cov / jnp.exp(0.5 * log_det)\n  else:\n    raise ValueError(f'Invalid mode {mode}.')\n  return iso_cov\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    det = jnp.linalg.det(cov)\n    return (cov / det) * jnp.sqrt(det)\n  elif mode == 'accurate':\n    det = jnp.linalg.slogdet(cov)\n    return (cov / det[1]) * jnp.exp(0.5 * det[0])\n  else:\n    raise ValueError(f'Invalid mode: {mode}.')\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    determinant = jnp.sqrt(jnp.linalg.det(cov))\n    isotropic_cov = cov / determinant\n  elif mode == 'accurate':\n    determinant = jnp.log(jnp.linalg.det(cov))\n    isotropic_cov = cov / jnp.exp(0.5 * determinant)\n  else:\n    raise ValueError('Invalid mode for isotropization.')\n\n  return isotropic_cov\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    determinant = jnp.linalg.det(cov)\n    isotropic_cov = cov / jnp.sqrt(determinant)\n  elif mode == 'accurate':\n    determinant = jnp.linalg.slogdet(cov)\n    isotropic_cov = cov / jnp.sqrt(determinant)\n  else:\n    raise ValueError('Invalid mode.')\n  return isotropic_cov\n\n"}
{"namespace": "coord.isotropize", "completion": "  # Check for invalid determinants.\n  if mode == 'fast':\n    if jnp.any(jnp.isclose(jnp.linalg.det(cov), 0.0)):\n      raise ValueError('Invalid determinant.')\n  elif mode == 'accurate':\n    if jnp.any(jnp.isclose(jnp.log(jnp.linalg.det(cov)), -jnp.inf)):\n      raise ValueError('Invalid determinant.')\n\n  # Compute the isotropic covariance matrix.\n  if mode == 'fast':\n    iso_cov = cov * jnp.sqrt(jnp.linalg.det(cov))[..., None, None]\n  elif mode == 'accurate':\n    iso_cov = cov * jnp.exp(0.5 * jnp.log(jnp.linalg.det(cov)))[..., None, None]\n\n  return iso_cov\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    # Compute the determinant of the covariance matrix.\n    det = jnp.linalg.det(cov)\n    # Compute the inverse of the covariance matrix.\n    inv = jnp.linalg.inv(cov)\n    # Compute the trace of the covariance matrix.\n    tr = jnp.trace(cov)\n    # Compute the isotropic covariance matrix.\n    iso = inv * (tr / det)\n    # Return the isotropic covariance matrix.\n    return iso\n  elif mode == 'accurate':\n    # Compute the determinant of the covariance matrix.\n    det = jnp.linalg.slogdet(cov)\n    # Compute the inverse of the covariance matrix.\n    inv = jnp.linalg.inv(cov)\n    # Compute the trace of the covariance matrix.\n    tr = jnp.trace(cov)\n    # Compute the isotropic covariance matrix.\n    iso = inv * (tr / det[0])\n    # Return the isotropic covariance matrix.\n    return iso\n  else:\n    raise ValueError('The mode of operation must be either fast or accurate.')\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    det = jnp.linalg.det(cov)\n    isotropic_cov = cov / jnp.sqrt(det)\n  elif mode == 'accurate':\n    det = jnp.linalg.slogdet(cov)[1]\n    isotropic_cov = cov / jnp.exp(0.5 * det)\n  else:\n    raise ValueError('Invalid mode.')\n\n  return isotropic_cov\n\n"}
{"namespace": "coord.isotropize", "completion": "  # Check for valid inputs\n  if mode not in ['fast', 'accurate']:\n    raise ValueError('Invalid mode.')\n\n  # Compute the determinant and logarithm of the determinant\n  det = jnp.linalg.det(cov)\n  log_det = jnp.log(det)\n\n  # Compute the eigenvalues and eigenvectors\n  eigval, eigvec = jnp.linalg.eigh(cov)\n\n  # Compute the isotropic covariance matrices\n  if mode == 'fast':\n    iso_cov = (eigval * eigvec) @ eigvec.T * det\n  else:\n    iso_cov = (eigval * eigvec) @ eigvec.T * jnp.exp(log_det)\n\n  # Return the isotropic covariance matrices\n  return iso_cov\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    det = jnp.linalg.det(cov)\n    iso_cov = cov / jnp.sqrt(det)\n  elif mode == 'accurate':\n    log_det = jnp.log(jnp.linalg.det(cov))\n    iso_cov = cov / jnp.exp(0.5 * log_det)\n  else:\n    raise ValueError('Invalid mode.')\n\n  return iso_cov\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    det = jnp.linalg.det(cov)\n    iso_cov = jnp.einsum('...ij,...jk->...ik', jnp.linalg.inv(cov), cov)\n    iso_cov = iso_cov / det\n  elif mode == 'accurate':\n    det = jnp.linalg.slogdet(cov)\n    iso_cov = jnp.einsum('...ij,...jk->...ik', jnp.linalg.inv(cov), cov)\n    iso_cov = iso_cov / det[1]\n  else:\n    raise ValueError('Invalid mode')\n\n  return iso_cov\n\n"}
{"namespace": "coord.isotropize", "completion": "  # Compute the determinant of the covariance matrix\n  det_cov = jnp.linalg.det(cov)\n\n  # Check if the determinant is zero\n  if jnp.isclose(det_cov, 0.0):\n    return jnp.zeros_like(cov)\n\n  # Compute the isotropic covariance matrix\n  if mode == 'fast':\n    iso_cov = cov / det_cov\n  elif mode == 'accurate':\n    iso_cov = cov / jnp.log(det_cov)\n\n  return iso_cov\n\n"}
{"namespace": "coord.isotropize", "completion": "  # Compute the determinant of the covariance matrix.\n  det = jnp.linalg.det(cov)\n\n  # Check if the determinant is zero or close to zero.\n  if mode == 'accurate':\n    # If the determinant is zero, return a matrix of zeros.\n    if jnp.isclose(det, 0):\n      return jnp.zeros_like(cov)\n    # Otherwise, compute the logarithm of the determinant.\n    else:\n      log_det = jnp.log(det)\n  elif mode == 'fast':\n    # If the determinant is zero, return a matrix of zeros.\n    if jnp.isclose(det, 0):\n      return jnp.zeros_like(cov)\n    # Otherwise, compute the determinant.\n    else:\n      log_det = jnp.log(det)\n  else:\n    raise ValueError('Invalid mode.')\n\n  # Compute the inverse of the covariance matrix.\n  inv = jnp.linalg.inv(cov)\n\n  # Compute the trace of the inverse of the covariance matrix.\n  tr = jnp.trace(inv)\n\n  # Compute the isotropic covariance matrix.\n  iso_cov = inv * tr / jnp.sqrt(det)\n\n  # Return the isotropic covariance matrix.\n  return iso_cov\n\n"}
{"namespace": "coord.isotropize", "completion": "  # Compute the determinant and the logarithm of the determinant.\n  det = jnp.linalg.det(cov)\n  log_det = jnp.log(det)\n\n  # If the determinant is zero, return an array of zeros.\n  if det == 0:\n    return jnp.zeros_like(cov)\n\n  # If the determinant is nonzero, compute the isotropic covariance matrix.\n  if mode == 'fast':\n    isotropic_cov = cov * jnp.sqrt(det)\n  elif mode == 'accurate':\n    isotropic_cov = cov * jnp.exp(0.5 * log_det)\n\n  # Return the isotropic covariance matrix.\n  return isotropic_cov\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    det = jnp.linalg.det(cov)\n  elif mode == 'accurate':\n    det = jnp.log(jnp.linalg.det(cov))\n  else:\n    raise ValueError('Invalid mode.')\n\n  # The following lines are a workaround to handle the case of an invalid determinant.\n  det_mask = det > -1e-8\n  det_mask = jnp.reshape(det_mask, [-1] + [1] * (len(det.shape) - 1))\n  det = det * det_mask + (1 - det_mask) * 1e-8\n\n  iso_cov = (1. / jnp.sqrt(det)) * cov\n\n  return iso_cov\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    # This is the fast version, which uses the determinant directly.\n    det = jnp.linalg.det(cov)\n    det = jnp.where(det > 0, det, jnp.ones_like(det))\n    iso_cov = jnp.sqrt(det) * jnp.eye(cov.shape[-1])\n  elif mode == 'accurate':\n    # This is the accurate version, which uses the logarithm of the determinant for stability.\n    det = jnp.linalg.slogdet(cov)[1]\n    det = jnp.where(det > 0, det, jnp.ones_like(det))\n    iso_cov = jnp.sqrt(det) * jnp.eye(cov.shape[-1])\n  else:\n    raise ValueError('The mode of computation must be either fast or accurate.')\n\n  return iso_cov\n\n"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent')\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', type=str, nargs='*', help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', help='Operational mode, which can be \"auto\" or \"manual\", specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"XAgent\")\n    parser.add_argument(\"--task\", type=str, required=True, help=\"The task description, specifying what task should be performed.\")\n    parser.add_argument(\"--upload-files\", type=str, nargs=\"*\", help=\"List of files to upload, allowing multiple files to be specified.\")\n    parser.add_argument(\"--model\", type=str, help=\"Model identifier for the task, specifying which model to use.\")\n    parser.add_argument(\"--record-dir\", type=str, help=\"Directory to record task execution logs, specifying where to save the logs.\")\n    parser.add_argument(\"--mode\", type=str, default=\"auto\", help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\")\n    parser.add_argument(\"--quiet\", action=\"store_true\", help=\"If set, the program runs in quiet mode with minimal output.\")\n    parser.add_argument(\"--max-subtask-chain-length\", type=int, help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\")\n    parser.add_argument(\"--enable-ask-human-for-help\", action=\"store_true\", help=\"Flag to enable asking for human assistance during task execution.\")\n    parser.add_argument(\"--max-plan-refine-chain-length\", type=int, help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\")\n    parser.add_argument(\"--max-plan-tree-depth\", type=int, help=\"Maximum depth of the plan tree, specifying how deep the plan tree can be.\")\n    parser.add_argument(\"--max-plan-tree-width\", type=int, help=\"Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.\")\n    parser.add_argument(\"--max-retry-times\", type=int, help=\"Maximum number of retry attempts, specifying how many times a task can be retried upon failure.\")\n    parser.add_argument(\"--config-file\", type=str, default=os.getenv(\"CONFIG_"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent')\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', type=str, nargs='*', help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default=\"auto\", help='Operational mode, which can be \"auto\" or \"manual\", specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"XAgent\")\n    parser.add_argument(\"--task\", type=str, required=True, help=\"The task description, specifying what task should be performed.\")\n    parser.add_argument(\"--upload-files\", type=str, nargs='*', help=\"List of files to upload, allowing multiple files to be specified.\")\n    parser.add_argument(\"--model\", type=str, help=\"Model identifier for the task, specifying which model to use.\")\n    parser.add_argument(\"--record-dir\", type=str, help=\"Directory to record task execution logs, specifying where to save the logs.\")\n    parser.add_argument(\"--mode\", type=str, default=\"auto\", help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\")\n    parser.add_argument(\"--quiet\", action=\"store_true\", help=\"If set, the program runs in quiet mode with minimal output.\")\n    parser.add_argument(\"--max-subtask-chain-length\", type=int, help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\")\n    parser.add_argument(\"--enable-ask-human-for-help\", action=\"store_true\", help=\"Flag to enable asking for human assistance during task execution.\")\n    parser.add_argument(\"--max-plan-refine-chain-length\", type=int, help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\")\n    parser.add_argument(\"--max-plan-tree-depth\", type=int, help=\"Maximum depth of the plan tree, specifying how deep the plan tree can be.\")\n    parser.add_argument(\"--max-plan-tree-width\", type=int, help=\"Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.\")\n    parser.add_argument(\"--max-retry-times\", type=int, help=\"Maximum number of retry attempts, specifying how many times a task can be retried upon failure.\")\n    parser.add_argument(\"--config-file\", type=str, help=\"Path to the configuration file, specifying"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser()\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', type=str, nargs='+', help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', help='Operational mode, which can be \"auto\" or \"manual\", specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type=str, default="}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent command line interface')\n    parser.add_argument('--task', type=str, required=True, help='Task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', type=str, nargs='*', help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', help='Operational mode, which can be \"auto\" or \"manual\", specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"XAgent\")\n    parser.add_argument(\"--task\", type=str, required=True, help=\"The task description, specifying what task should be performed.\")\n    parser.add_argument(\"--upload-files\", type=str, nargs=\"*\", help=\"List of files to upload, allowing multiple files to be specified.\")\n    parser.add_argument(\"--model\", type=str, help=\"Model identifier for the task, specifying which model to use.\")\n    parser.add_argument(\"--record-dir\", type=str, help=\"Directory to record task execution logs, specifying where to save the logs.\")\n    parser.add_argument(\"--mode\", type=str, default=\"auto\", help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\")\n    parser.add_argument(\"--quiet\", action=\"store_true\", default=False, help=\"If set, the program runs in quiet mode with minimal output.\")\n    parser.add_argument(\"--max-subtask-chain-length\", type=int, default=CONFIG[\"max_subtask_chain_length\"], help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\")\n    parser.add_argument(\"--enable-ask-human-for-help\", action=\"store_true\", default=CONFIG[\"enable_ask_human_for_help\"], help=\"Flag to enable asking for human assistance during task execution.\")\n    parser.add_argument(\"--max-plan-refine-chain-length\", type=int, default=CONFIG[\"max_plan_refine_chain_length\"], help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\")\n    parser.add_argument(\"--max-plan-tree-depth\", type=int, default=CONFIG[\"max_plan_tree_depth\"], help=\"Maximum depth of the plan tree, specifying how deep the plan tree can be.\")\n    parser.add_argument(\"--max-plan-tree-width\", type=int, default=CONFIG[\"max_plan_tree_width\"], help=\"Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser()\n    parser.add_argument('--task', type=str, required=True, help='Task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', type=str, nargs='+', help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default=\"auto\", help='Operational mode, which can be \"auto\" or \"manual\", specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type=str, default=os"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--task\", type=str, required=True, help=\"The task description, specifying what task should be performed.\")\n    parser.add_argument(\"--upload-files\", type=str, nargs=\"*\", help=\"List of files to upload, allowing multiple files to be specified.\")\n    parser.add_argument(\"--model\", type=str, help=\"Model identifier for the task, specifying which model to use.\")\n    parser.add_argument(\"--record-dir\", type=str, help=\"Directory to record task execution logs, specifying where to save the logs.\")\n    parser.add_argument(\"--mode\", type=str, default=\"auto\", help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\")\n    parser.add_argument(\"--quiet\", action=\"store_true\", default=False, help=\"If set, the program runs in quiet mode with minimal output.\")\n    parser.add_argument(\"--max-subtask-chain-length\", type=int, default=CONFIG[\"max_subtask_chain_length\"], help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\")\n    parser.add_argument(\"--enable-ask-human-for-help\", action=\"store_true\", default=CONFIG[\"enable_ask_human_for_help\"], help=\"Flag to enable asking for human assistance during task execution.\")\n    parser.add_argument(\"--max-plan-refine-chain-length\", type=int, default=CONFIG[\"max_plan_refine_chain_length\"], help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\")\n    parser.add_argument(\"--max-plan-tree-depth\", type=int, default=CONFIG[\"max_plan_tree_depth\"], help=\"Maximum depth of the plan tree, specifying how deep the plan tree can be.\")\n    parser.add_argument(\"--max-plan-tree-width\", type=int, default=CONFIG[\"max_plan_tree_width\"], help=\"Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.\")\n    parser."}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent Command Line Interface')\n\n    parser.add_argument('--task', type=str, help='The task description, specifying what task should be performed.', required=True)\n    parser.add_argument('--upload-files', type=str, nargs='+', help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', help='Operational mode, which can be \"auto\" or \"manual\", specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"XAgent Command Line Interface\")\n\n    parser.add_argument(\"--task\", type=str, required=True,\n                        help=\"The task description, specifying what task should be performed.\")\n    parser.add_argument(\"--upload-files\", type=str, nargs=\"+\",\n                        help=\"List of files to upload, allowing multiple files to be specified.\")\n    parser.add_argument(\"--model\", type=str,\n                        help=\"Model identifier for the task, specifying which model to use.\")\n    parser.add_argument(\"--record-dir\", type=str,\n                        help=\"Directory to record task execution logs, specifying where to save the logs.\")\n    parser.add_argument(\"--mode\", type=str, default=\"auto\",\n                        help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\")\n    parser.add_argument(\"--quiet\", action=\"store_true\", default=False,\n                        help=\"If set, the program runs in quiet mode with minimal output.\")\n    parser.add_argument(\"--max-subtask-chain-length\", type=int,\n                        help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\")\n    parser.add_argument(\"--enable-ask-human-for-help\", action=\"store_true\", default=False,\n                        help=\"Flag to enable asking for human assistance during task execution.\")\n    parser.add_argument(\"--max-plan-refine-chain-length\", type=int,\n                        help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\")\n    parser.add_argument(\"--max-plan-tree-depth\", type=int,\n                        help=\"Maximum depth of the plan tree, specifying how deep the plan tree can be.\")\n    parser.add_argument(\"--max-plan-tree-width\", type=int,\n                        help=\"Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.\")\n    parser.add_argument(\"--max-retry-times\", type=int,\n                        help"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent: A general purpose agent for task automation.')\n\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', type=str, nargs='+', help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', help='Operational mode, which can be \"auto\" or \"manual\", specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"XAgent\")\n\n    parser.add_argument(\n        \"--task\",\n        help=\"The task description, specifying what task should be performed.\",\n        required=True,\n    )\n\n    parser.add_argument(\n        \"--upload-files\",\n        help=\"List of files to upload, allowing multiple files to be specified.\",\n        nargs=\"+\",\n    )\n\n    parser.add_argument(\n        \"--model\",\n        help=\"Model identifier for the task, specifying which model to use.\",\n        default=\"\",\n    )\n\n    parser.add_argument(\n        \"--record-dir\",\n        help=\"Directory to record task execution logs, specifying where to save the logs.\",\n        default=\"\",\n    )\n\n    parser.add_argument(\n        \"--mode\",\n        help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\",\n        default=\"auto\",\n    )\n\n    parser.add_argument(\n        \"--quiet\",\n        help=\"If set, the program runs in quiet mode with minimal output.\",\n        action=\"store_true\",\n    )\n\n    parser.add_argument(\n        \"--max-subtask-chain-length\",\n        help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\",\n        type=int,\n        default=100,\n    )\n\n    parser.add_argument(\n        \"--enable-ask-human-for-help\",\n        help=\"Flag to enable asking for human assistance during task execution.\",\n        action=\"store_true\",\n    )\n\n    parser.add_argument(\n        \"--max-plan-refine-chain-length\",\n        help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\",\n        type=int,\n        default=10,\n    )\n\n    parser.add_argument(\n        \"--max-plan-tree-depth\",\n        help=\"Maximum depth of the plan tree, specifying how deep the plan tree can be.\",\n        type=int,\n        default=1"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"XAgent: A Multi-Agent Framework for Multi-Agent Task Automation\")\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', type=str, nargs='+', help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default=\"auto\", help='Operational mode, which can be \"auto\" or \"manual\", specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent CLI')\n    parser.add_argument('--task', type=str, required=True, help='Task description')\n    parser.add_argument('--upload-files', type=str, nargs='*', help='Files to upload')\n    parser.add_argument('--model', type=str, help='Model identifier')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs')\n    parser.add_argument('--mode', type=str, default='auto', help='Operational mode')\n    parser.add_argument('--quiet', action='store_true', help='Quiet mode')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Enable asking for human assistance during task execution')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts')\n    parser.add_argument('--config-file', type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file')\n    args = parser.parse_args()\n\n    return args\n\n"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent command line interface.')\n\n    parser.add_argument('--task', type=str, required=True, help='Task description')\n    parser.add_argument('--upload-files', type=str, nargs='+', help='Files to upload')\n    parser.add_argument('--model', type=str, help='Model identifier')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs')\n    parser.add_argument('--mode', type=str, default='auto', help='Operational mode')\n    parser.add_argument('--quiet', action='store_true', help='Run in quiet mode')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Enable asking for human assistance during task execution')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts')\n    parser.add_argument('--config-file', type=str, default=os.environ.get('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file')\n\n    args = parser.parse_args()\n\n    return args\n\n"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(\n        description=\"XAgent is a flexible and extendable framework for autonomous agents that can perform tasks autonomously. It is a command line utility that can be used to run tasks and perform other operations.\"\n    )\n\n    parser.add_argument(\n        \"--task\",\n        type=str,\n        required=True,\n        help=\"The task description, specifying what task should be performed.\",\n    )\n\n    parser.add_argument(\n        \"--upload-files\",\n        nargs=\"*\",\n        type=str,\n        default=[],\n        help=\"List of files to upload, allowing multiple files to be specified.\",\n    )\n\n    parser.add_argument(\n        \"--model\",\n        type=str,\n        default=\"\",\n        help=\"Model identifier for the task, specifying which model to use.\",\n    )\n\n    parser.add_argument(\n        \"--record-dir\",\n        type=str,\n        default=\"\",\n        help=\"Directory to record task execution logs, specifying where to save the logs.\",\n    )\n\n    parser.add_argument(\n        \"--mode\",\n        type=str,\n        default=\"auto\",\n        help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\",\n    )\n\n    parser.add_argument(\n        \"--quiet\",\n        action=\"store_true\",\n        help=\"If set, the program runs in quiet mode with minimal output.\",\n    )\n\n    parser.add_argument(\n        \"--max-subtask-chain-length\",\n        type=int,\n        default=10,\n        help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\",\n    )\n\n    parser.add_argument(\n        \"--enable-ask-human-for-help\",\n        action=\"store_true\",\n        help=\"Flag to enable asking for human assistance during task execution.\",\n    )\n\n    parser.add_argument(\n        \"--max-plan-refine-chain-length\",\n        type=int,\n        default=10,\n        help=\""}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--task\", type=str, required=True)\n    parser.add_argument(\"--upload-files\", type=str, nargs=\"*\", default=[])\n    parser.add_argument(\"--model\", type=str, default=None)\n    parser.add_argument(\"--record-dir\", type=str, default=None)\n    parser.add_argument(\"--mode\", type=str, default=\"auto\")\n    parser.add_argument(\"--quiet\", type=bool, default=False)\n    parser.add_argument(\"--max-subtask-chain-length\", type=int, default=None)\n    parser.add_argument(\"--enable-ask-human-for-help\", type=bool, default=None)\n    parser.add_argument(\"--max-plan-refine-chain-length\", type=int, default=None)\n    parser.add_argument(\"--max-plan-tree-depth\", type=int, default=None)\n    parser.add_argument(\"--max-plan-tree-width\", type=int, default=None)\n    parser.add_argument(\"--max-retry-times\", type=int, default=None)\n    parser.add_argument(\"--config-file\", type=str, default=None)\n    return parser.parse_args()\n\n"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent - A Framework for Automating Tasks on Remote Systems')\n    parser.add_argument('--task', type=str, help='task description', required=True)\n    parser.add_argument('--upload-files', type=str, nargs='*', help='files to upload')\n    parser.add_argument('--model', type=str, help='model identifier for the task')\n    parser.add_argument('--record-dir', type=str, help='directory to record task execution logs')\n    parser.add_argument('--mode', type=str, choices=['auto', 'manual'], help='operational mode')\n    parser.add_argument('--quiet', action='store_true', help='run in quiet mode')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='maximum length of subtask chain')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='enable asking for human assistance during task execution')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='maximum length of plan refinement chain')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='maximum depth of the plan tree')\n    parser.add_argument('--max-plan-tree-width', type=int, help='maximum width of the plan tree')\n    parser.add_argument('--max-retry-times', type=int, help='maximum number of retry attempts')\n    parser.add_argument('--config-file', type=str, help='path to the configuration file')\n\n    args = parser.parse_args()\n\n    return args\n\n"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--task\", type=str, required=True)\n    parser.add_argument(\"--upload-files\", type=str, nargs=\"*\")\n    parser.add_argument(\"--model\", type=str, default=\"default\")\n    parser.add_argument(\"--record-dir\", type=str, default=None)\n    parser.add_argument(\"--mode\", type=str, default=\"auto\")\n    parser.add_argument(\"--quiet\", action=\"store_true\")\n    parser.add_argument(\"--max-subtask-chain-length\", type=int, default=10)\n    parser.add_argument(\"--enable-ask-human-for-help\", action=\"store_true\")\n    parser.add_argument(\"--max-plan-refine-chain-length\", type=int, default=10)\n    parser.add_argument(\"--max-plan-tree-depth\", type=int, default=10)\n    parser.add_argument(\"--max-plan-tree-width\", type=int, default=10)\n    parser.add_argument(\"--max-retry-times\", type=int, default=3)\n    parser.add_argument(\"--config-file\", type=str, default=CONFIG.CONFIG_FILE)\n\n    return parser.parse_args()\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Got shape {v.shape}.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[-1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Got shape {v.shape}.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. got shape {v.shape}\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Got shape {v.shape}.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Got shape {v.shape}.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Got shape {v.shape}.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[-1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. got shape {v.shape}\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.ndim != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a 2D array. got shape {v.shape}\")\n\n    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. got shape {v.shape}\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[-1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points, i.e. a numpy array with a shape of (_, 2). Got shape {v.shape}.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points, got shape {v.shape}\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[-1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Got shape {v.shape}.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. got shape {v.shape}\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[-1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points, got shape {v.shape}\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. got shape {v.shape}.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.ndim != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must have a shape of (_, 2).\")\n\n    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must have a shape of (_, 2).\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[-1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Got shape {v.shape}.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of points. got shape {v.shape}\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[-1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of points, i.e. have a shape of (_, 2).\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.ndim != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a 2D array. Got {v.ndim} dimensions.\")\n\n    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must have a shape of (_, 2). Got shape {v.shape}.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[-1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points, i.e. a numpy array with a shape of (_, 2).\")\n\n    return v\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    CHARACTER_SET = string.ascii_lowercase + string.digits + \"_\"\n    return CHARACTER_SET[n]\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    # Define the character set for encoding\n    char_set = string.ascii_lowercase + string.digits + \"_\"\n\n    # Convert the integer into a string\n    n_str = str(n)\n\n    # Convert the string into a list of integers\n    n_list = [int(i) for i in n_str]\n\n    # Encode the list of integers into a string\n    encoded_str = \"\".join([char_set[i] for i in n_list])\n\n    return encoded_str\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    char_set = string.ascii_lowercase + string.digits + \"_\"\n    return char_set[n]\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    # Define the character set for encoding\n    char_set = string.ascii_lowercase + string.digits + '_'\n    return char_set[n]\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    char_set = string.ascii_lowercase + string.digits + \"_\"\n    return char_set[n]\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    assert n >= 0\n    assert n < 62\n    assert isinstance(n, int)\n\n    char_set = string.ascii_lowercase + string.digits + '_'\n    return char_set[n]\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    char_set = string.ascii_lowercase + string.digits + \"_\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n >= len(char_set):\n        raise ValueError(\"n must be less than the length of the character set\")\n    return char_set[n]\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    return string.ascii_lowercase[n]\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    if not isinstance(n, int):\n        raise TypeError(f\"n must be an integer, not {type(n)}\")\n\n    if n < 0:\n        raise ValueError(f\"n must be non-negative, not {n}\")\n\n    # Define the character set for encoding\n    char_set = string.ascii_lowercase + string.digits + \"_\"\n\n    # Define the length of the character set\n    char_set_len = len(char_set)\n\n    # Define the output string\n    out = \"\"\n\n    # Encode the integer\n    while n >= char_set_len:\n        out += char_set[n % char_set_len]\n        n //= char_set_len\n    out += char_set[n]\n\n    # Return the encoded integer\n    return out\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    # Define the character set for encoding\n    character_set = string.ascii_lowercase + string.digits + \"_\"\n    # Define the number of characters in the character set\n    character_set_length = len(character_set)\n    # Define the string to be returned\n    encoded_string = \"\"\n    # Loop while n is greater than 0\n    while n > 0:\n        # Define the character to be appended to the encoded string\n        character = character_set[n % character_set_length]\n        # Append the character to the encoded string\n        encoded_string = character + encoded_string\n        # Define the next index\n        n = n // character_set_length\n    # Return the encoded string\n    return encoded_string\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    # check if input is integer\n    if not isinstance(n, int):\n        raise TypeError(\"input is not integer\")\n    # check if input is negative\n    if n < 0:\n        raise ValueError(\"input is negative\")\n    # check if input is too large\n    if n >= 62:\n        raise ValueError(\"input is too large\")\n    # check if input is too small\n    if n == 0:\n        return \"a\"\n    # check if input is too small\n    if n == 1:\n        return \"b\"\n    # check if input is too small\n    if n == 2:\n        return \"c\"\n    # get character set\n    character_set = string.ascii_lowercase + string.digits + \"_\"\n    # get character corresponding to input\n    return character_set[n]\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    # Define the character set\n    char_set = string.ascii_lowercase + string.digits + \"_\"\n    # Convert the integer into a string\n    n_str = str(n)\n    # Encode the integer\n    encoded_int = \"\".join([char_set[int(c)] for c in n_str])\n    # Return the encoded integer\n    return encoded_int\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    # Define the character set for encoding\n    char_set = string.ascii_lowercase + string.digits + \"_\"\n    # Define the number of characters in the character set\n    n_chars = len(char_set)\n    # Define the base of the encoding\n    base = n_chars\n    # Define the encoded string\n    encoded_string = \"\"\n    # While the input integer is larger than zero\n    while n > 0:\n        # Define the remainder of the integer division by the base\n        remainder = n % base\n        # Concatenate the encoded character to the encoded string\n        encoded_string += char_set[remainder]\n        # Define the input integer as the input integer divided by the base\n        n //= base\n    # Return the encoded string\n    return encoded_string\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    # Define the character set for encoding\n    char_set = string.ascii_lowercase + string.digits + \"_\"\n    # Define the maximum number of characters in the character set\n    char_set_size = len(char_set)\n    # Define the maximum number of digits in the input integer\n    max_digits = len(str(2 ** (char_set_size * 16)))\n    # Define the maximum integer\n    max_int = 2 ** (char_set_size * 16)\n    # Initialize the output string\n    s = \"\"\n    # Loop over the maximum number of digits\n    for i in range(max_digits):\n        # Get the current integer\n        n_i = n % char_set_size\n        # Encode the current integer\n        s += char_set[n_i]\n        # Compute the next integer\n        n = n // char_set_size\n        # Break if the current integer is zero\n        if n == 0:\n            break\n    # Return the encoded string\n    return s\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    # Define the character set for encoding\n    char_set = string.ascii_lowercase + string.digits + '_'\n    return char_set[n % len(char_set)]\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    if n < 0:\n        raise ValueError(\"n must be a non-negative integer\")\n\n    # Define the character set for encoding\n    char_set = string.ascii_lowercase + string.digits + \"_\"\n    # Define the length of the character set\n    char_set_len = len(char_set)\n\n    # Define the string to be returned\n    encoded_string = \"\"\n\n    # Loop while n is non-zero\n    while n > 0:\n        # Define the index of the character to be appended to the encoded string\n        index = n % char_set_len\n        # Append the character at the index to the encoded string\n        encoded_string += char_set[index]\n        # Define the value of n before the last iteration\n        n = n // char_set_len\n\n    # Reverse the encoded string\n    encoded_string = encoded_string[::-1]\n\n    # Return the encoded string\n    return encoded_string\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    # Define the character set for encoding\n    character_set = string.ascii_lowercase + string.digits + '_'\n    # Define the number of characters in the character set\n    num_chars = len(character_set)\n    # Define the maximum integer that can be encoded with the character set\n    max_n = num_chars - 1\n    # Check that the input integer is not too large for the character set\n    assert n <= max_n, 'The input integer is too large for the character set.'\n    # Return the encoded character\n    return character_set[n]\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    # Define the character set for encoding\n    charset = string.ascii_lowercase + string.digits + \"_\"\n\n    # Define the length of the character set\n    charset_len = len(charset)\n\n    # Initialize the output string\n    output = \"\"\n\n    # Keep a temporary copy of the input integer\n    temp = n\n\n    # While the input integer is larger than 0...\n    while temp > 0:\n\n        # Encode the last digit of the input integer\n        output += charset[temp % charset_len]\n\n        # Divide the input integer by the character set length\n        temp //= charset_len\n\n    # Return the output string\n    return output\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    # Define the character set\n    char_set = string.ascii_lowercase + string.digits + \"_\"\n\n    # Define the base\n    base = len(char_set)\n\n    # Define the string to be returned\n    encoded_int = \"\"\n\n    # Define the index\n    index = 0\n\n    # While the integer is greater than 0\n    while n > 0:\n        # Define the remainder\n        remainder = n % base\n\n        # Add the encoded remainder to the string\n        encoded_int = encoded_int + char_set[remainder]\n\n        # Set the new index\n        index = index + 1\n\n        # Set the new integer\n        n = n // base\n\n    # Reverse the string and return it\n    return encoded_int[::-1]\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    # Define the character set for encoding\n    char_set = string.ascii_lowercase + string.digits + '_'\n    # Define the character set length\n    char_set_length = len(char_set)\n\n    # Define the encoded character\n    encoded_char = ''\n\n    # Check if the input integer is valid\n    if n < 0:\n        raise ValueError(\"The input integer must be a non-negative integer.\")\n\n    # Perform encoding\n    while n > 0:\n        # Select the encoded character\n        encoded_char = char_set[n % char_set_length] + encoded_char\n        # Compute the next integer\n        n = n // char_set_length\n\n    return encoded_char\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  return jnp.log(jnp.clip(x, a_min=eps, a_max=None) + value_at_zero)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  return jnp.log(jnp.where(x > eps, x, jnp.full_like(x, value_at_zero)))\n\n"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx in range(len(workers_intervals)):\n        for i, interval in enumerate(workers_intervals[worker_idx]):\n            if indexes[worker_idx] >= interval[0] and indexes[worker_idx] < interval[1]:\n                chunks_index[worker_idx] = i\n                break\n\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx in range(len(workers_intervals)):\n        for i, interval in enumerate(workers_intervals[worker_idx]):\n            if indexes[worker_idx] >= interval[1]:\n                indexes[worker_idx] = indexes[worker_idx] - interval[1]\n                chunks_index[worker_idx] = i + 1\n            else:\n                break\n\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx, intervals in workers_intervals.items():\n        for i, interval in enumerate(intervals):\n            if indexes[worker_idx] >= interval[1] - interval[0]:\n                indexes[worker_idx] = 0\n                chunks_index[worker_idx] = i + 1\n            else:\n                break\n\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    for worker_idx in range(len(workers_intervals)):\n        for chunk_idx, chunk_interval in enumerate(workers_intervals[worker_idx]):\n            if chunk_interval[0] <= indexes[worker_idx] < chunk_interval[1]:\n                indexes[worker_idx] = chunk_interval[0]\n                break\n            else:\n                indexes[worker_idx] += chunk_interval[1] - chunk_interval[0]\n\n    return indexes, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    for worker_idx in range(len(workers_intervals)):\n        for i, interval in enumerate(workers_intervals[worker_idx]):\n            if indexes[worker_idx] >= interval[1] - interval[0]:\n                indexes[worker_idx] = 0\n                if i != len(workers_intervals[worker_idx]) - 1:\n                    indexes[worker_idx] += interval[0]\n                    continue\n                else:\n                    break\n            else:\n                indexes[worker_idx] += 1"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    for worker_idx in range(len(workers_intervals)):\n        for chunk_index, chunk_interval in enumerate(workers_intervals[worker_idx]):\n            if chunk_index == indexes[worker_idx] // (chunk_interval[1] - chunk_interval[0]):\n                indexes[worker_idx] = chunk_interval[0] + (indexes[worker_idx] % (chunk_interval[1] - chunk_interval[0]))\n                break\n            elif chunk_index > indexes[worker_idx] // (chunk_interval[1] - chunk_interval[0]):\n                indexes[worker_idx] = chunk_interval[0] + (indexes[worker_idx] % (chunk_interval[1] - chunk_interval[0]))\n                break\n\n    return indexes, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunk_indexes = {}\n    for worker_idx in range(len(workers_intervals)):\n        chunk_indexes[worker_idx] = 0\n        for interval in workers_intervals[worker_idx]:\n            if indexes[worker_idx] >= interval[0] and indexes[worker_idx] < interval[1]:\n                indexes[worker_idx] = interval[0]\n                break\n            elif indexes[worker_idx] >= interval[1]:\n                indexes[worker_idx] -= interval[1] - interval[0]\n                chunk_indexes[worker_idx] += 1\n            else:\n                break\n\n    return chunk_indexes, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx in range(len(workers_intervals)):\n        chunks_index[worker_idx] = 0\n        current_index = indexes[worker_idx]\n        for interval in workers_intervals[worker_idx]:\n            if current_index < interval[1]:\n                break\n            chunks_index[worker_idx] += 1\n            current_index -= interval[1] - interval[0]\n        indexes[worker_idx] = current_index\n\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx in range(len(workers_intervals)):\n        worker_intervals = workers_intervals[worker_idx]\n        worker_index = indexes[worker_idx]\n\n        for i, interval in enumerate(worker_intervals):\n            if worker_index >= interval[1]:\n                chunks_index[worker_idx] = i\n                worker_index -= interval[1] - interval[0]\n            else:\n                chunks_index[worker_idx] = i\n                worker_index -= interval[0]\n                break\n\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    # iterate through each worker's intervals\n    for worker_idx, intervals in workers_intervals.items():\n        # iterate through each interval\n        for interval in intervals:\n            # if the current index is less than the interval's last element\n            if indexes[worker_idx] < interval[1]:\n                # if the current index is greater than the interval's first element\n                if indexes[worker_idx] >= interval[0]:\n                    # update the chunk index\n                    indexes[worker_idx] = interval[0]\n                # if the current index is less than the interval's first element\n                else:\n                    # update the chunk index\n                    indexes[worker_idx] = interval[0]\n                    # update the current index\n                    indexes[worker_idx] += 1\n\n    return indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunk_index = 0\n    for worker_idx in range(len(workers_intervals)):\n        # update the chunk index\n        if indexes[worker_idx] >= workers_intervals[worker_idx][chunk_index][1] - workers_intervals[worker_idx][0]:\n            chunk_index += 1\n\n        # update the index\n        indexes[worker_idx] += 1\n\n    return indexes, chunk_index"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    for worker_idx in range(len(workers_intervals)):\n        for i, interval in enumerate(workers_intervals[worker_idx]):\n            if indexes[worker_idx] >= interval[1] - interval[0]:\n                indexes[worker_idx] = 0\n                continue\n            indexes[worker_idx] += 1\n            break\n\n    return indexes\n\n"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    for worker_idx in range(len(workers_intervals)):\n        for i, interval in enumerate(workers_intervals[worker_idx]):\n            if indexes[worker_idx] >= interval[1]:\n                indexes[worker_idx] = 0\n                continue\n            if indexes[worker_idx] < interval[0]:\n                indexes[worker_idx] = interval[0]\n                continue\n            if indexes[worker_idx] < interval[1]:\n                indexes[worker_idx] = interval[1]\n                continue\n            if indexes[worker_idx] >= interval[1]:\n                indexes[worker_idx] = 0\n                continue\n            if indexes[worker_idx] < interval[0]:\n                indexes[worker_idx] = interval[0]\n                continue\n            if indexes[worker_idx] >= interval[1]:\n                indexes[worker_idx] = 0\n                continue\n\n            indexes[worker_idx] = 0\n            break\n\n    return indexes, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx, intervals in workers_intervals.items():\n        current_index = indexes[worker_idx]\n        for interval in intervals:\n            if interval[0] <= current_index < interval[1]:\n                chunks_index[worker_idx] = intervals.index(interval)\n                indexes[worker_idx] = interval[0] + (current_index - interval[0])\n                break\n            elif interval[0] > current_index:\n                chunks_index[worker_idx] = intervals.index(interval)\n                indexes[worker_idx] = interval[0]\n                break\n            elif interval[1] <= current_index:\n                chunks_index[worker_idx] = intervals.index(interval)\n                indexes[worker_idx] = interval[0]\n                break\n\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    for worker_idx in range(len(workers_intervals)):\n        worker_intervals = workers_intervals[worker_idx]\n        worker_index = indexes[worker_idx]\n\n        for i, interval in enumerate(worker_intervals):\n            if worker_index < interval[1]:\n                indexes[worker_idx] = worker_index\n                break\n            else:\n                indexes[worker_idx] = 0\n                worker_index = 0\n\n    return indexes\n\n"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    # update the indexes based on the intervals\n    chunk_index = 0\n    for worker_idx in range(len(workers_intervals)):\n        chunk_indexes = []\n        for i, interval in enumerate(workers_intervals[worker_idx]):\n            if indexes[worker_idx] >= interval[1]:\n                chunk_indexes.append(i + 1)\n                indexes[worker_idx] -= interval[1] - interval[0]\n            else:\n                chunk_indexes.append(i)\n                indexes[worker_idx] -= interval[0]\n        chunk_indexes.append(chunk_indexes[-1] + 1)\n        chunk_index = chunk_indexes[worker_idx]\n\n    return indexes, chunk_index"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    # iterate through each worker's intervals\n    for worker_idx in range(len(workers_intervals)):\n        # get the current chunk index and the current index within that chunk\n        chunk_index = indexes[worker_idx]\n        # get the interval for the current chunk\n        chunk_interval = workers_intervals[worker_idx][chunk_index]\n        # get the size of the current chunk\n        chunk_size = chunk_interval[1] - chunk_interval[0]\n        # get the current index within the current chunk\n        chunk_index_within_chunk = indexes[worker_idx] - chunk_interval[0]\n        # get the next chunk index\n        next_chunk_index = chunk_index + 1\n        # if the next chunk index is greater than the number of chunks, then reset it to 0\n        if next_chunk_index >= len(workers_intervals[worker_idx]):\n            next_chunk_index = 0\n        # get the next chunk interval\n        next_chunk_interval = workers_intervals[worker_idx][next_chunk_index]\n        # get the next chunk size\n        next_chunk_size = next_chunk_interval[1] - next_chunk_interval[0]\n        # get the next chunk index within the next chunk\n        next_chunk_index_within_chunk = chunk_index_within_chunk + chunk_size\n        # if the next chunk index is greater than the next chunk size, then reset it to 0\n        if next_chunk_index_within_chunk >= next_chunk_size:\n            next_chunk_index_within_chunk = 0\n        # update the indexes dictionary with the next chunk index and the next chunk index within chunk\n        indexes[worker_idx] = next_chunk_interval[0] + next_chunk_index_within_chunk\n        # update the chunk index dictionary with the next chunk index\n        indexes[worker_idx] = next_chunk_index\n\n    return indexes, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    for worker_idx in range(len(workers_intervals)):\n        worker_intervals = workers_intervals[worker_idx]\n        worker_index = indexes[worker_idx]\n        for i, interval in enumerate(worker_intervals):\n            if worker_index >= interval[1]:\n                continue\n            else:\n                indexes[worker_idx] = worker_index\n                if i == len(worker_intervals) - 1:\n                    indexes[worker_idx] = interval[1]\n                else:\n                    indexes[worker_idx] = interval[0]\n                break\n\n    return indexes, indexes\n\n"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    # iterate through each worker's intervals\n    for worker_idx in range(len(workers_intervals)):\n\n        # get the current chunk index and the current index within that chunk\n        chunk_index = indexes[worker_idx]\n        current_index = indexes[worker_idx] - chunk_index\n\n        # iterate through each interval\n        for interval in workers_intervals[worker_idx]:\n\n            # if the current index is within the current interval\n            if current_index < (interval[1] - interval[0]):\n                # update the chunk index\n                chunk_index += 1\n\n                # update the current index\n                current_index = indexes[worker_idx] - chunk_index\n\n                # if the current index is within the current interval\n                if current_index < (interval[1] - interval[0]):\n                    # update the chunk index\n                    chunk_index += 1\n\n                # update the indexes dictionary\n                indexes[worker_idx] = chunk_index\n\n                # break out of the loop\n                break\n\n            # if the current index is not within the current interval\n            else:\n                # update the chunk index\n                chunk_index += 1\n\n                # update the current index\n                current_index = indexes[worker_idx] - chunk_index\n\n                # if the current index is within the current interval\n                if current_index < (interval[1] - interval[0]):\n                    # update the chunk index\n                    chunk_index += 1\n\n                # update the indexes dictionary\n                indexes[worker_idx] = chunk_index\n\n    return indexes, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    # iterate through each worker's intervals, updating the current index and the chunk index based on the size of each interval\n    for worker_idx, intervals in workers_intervals.items():\n        for i, interval in enumerate(intervals):\n            if indexes[worker_idx] >= interval[1]:\n                indexes[worker_idx] = 0\n                continue\n            if indexes[worker_idx] < interval[0]:\n                indexes[worker_idx] = interval[0]\n                continue\n            if indexes[worker_idx] >= interval[0] and indexes[worker_idx] < interval[1]:\n                indexes[worker_idx] = 0\n                continue\n\n    return indexes\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return trilerp_grid(values, coordinates)\n  elif datastructure == 'hash':\n    return trilerp_hash(values, coordinates)\n  else:\n    raise ValueError('Unsupported datastructure: %s' % datastructure)\n\n\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    values = values.astype(coordinates.dtype)\n    coordinates = jnp.clip(coordinates, 0, 1)\n    return resample.trilerp(values, coordinates)\n\n  elif datastructure == 'hash':\n    return hash_resample.trilerp(values, coordinates)\n\n  else:\n    raise ValueError(\n        'Invalid datastructure passed to trilerp. Expected \"grid\" or \"hash\".')\n\n\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    # Adjust coordinates to be in the range [0,1]\n    coordinates = coordinates / (values.shape[:3] - 1)\n    # Perform trilinear interpolation\n    return math.trilerp(values, coordinates)\n  elif datastructure == 'hash':\n    # Adjust coordinates to be in the range [0,1]\n    coordinates = coordinates / (values.shape[0] - 1)\n    # Perform trilinear interpolation\n    return math.trilerp(values, coordinates)\n  else:\n    raise ValueError('Unsupported datastructure: {}'.format(datastructure))\n\n\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return trilerp_grid(values, coordinates)\n  elif datastructure == 'hash':\n    return trilerp_hash(values, coordinates)\n  else:\n    raise ValueError('Unsupported datastructure: {}'.format(datastructure))\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return trilerp_grid(values, coordinates)\n  elif datastructure == 'hash':\n    return trilerp_hash(values, coordinates)\n  else:\n    raise ValueError('Invalid datastructure: %s' % datastructure)\n\n\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return trilerp_grid(values, coordinates)\n  elif datastructure == 'hash':\n    return trilerp_hash(values, coordinates)\n  else:\n    raise ValueError(\n        'Invalid datastructure. Supported values are \"grid\" and \"hash\".')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return trilerp_grid(values, coordinates)\n  elif datastructure == 'hash':\n    return trilerp_hash(values, coordinates)\n  else:\n    raise ValueError('Unsupported datastructure: %s' % datastructure)\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return trilerp_grid(values, coordinates)\n  elif datastructure == 'hash':\n    return trilerp_hash(values, coordinates)\n  else:\n    raise ValueError(\n        'Unsupported data structure: {}. Supported data structures are grid and hash.'.\n        format(datastructure))\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  # Check if the data structure is a valid one.\n  if datastructure not in ['grid', 'hash']:\n    raise ValueError('Invalid data structure specified.')\n\n  # If the data structure is a grid, perform trilinear interpolation.\n  if datastructure == 'grid':\n    return trilinear_interp(values, coordinates)\n\n  # If the data structure is a hash, perform trilinear interpolation.\n  elif datastructure == 'hash':\n    return trilinear_interp_hash(values, coordinates)\n\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return trilerp_grid(values, coordinates)\n  elif datastructure == 'hash':\n    return trilerp_hash(values, coordinates)\n  else:\n    raise ValueError('Invalid data structure.')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return trilerp_grid(values, coordinates)\n  elif datastructure == 'hash':\n    return trilerp_hash(values, coordinates)\n  else:\n    raise ValueError(\n        'Invalid datastructure passed to trilerp. '\n        'Supported values are \"grid\" and \"hash\".')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return trilerp_grid(values, coordinates)\n  elif datastructure == 'hash':\n    return trilerp_hash(values, coordinates)\n  else:\n    raise ValueError(\n        'Invalid datastructure. Only supports \\'grid\\' or \\'hash\\'')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return trilerp_grid(values, coordinates)\n  elif datastructure == 'hash':\n    return trilerp_hash(values, coordinates)\n  else:\n    raise ValueError('Unsupported datastructure type: %s' % datastructure)\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  # Check for valid data structure.\n  if datastructure not in ['grid', 'hash']:\n    raise ValueError('Unsupported data structure.')\n\n  # Adjust coordinates for hash data structure.\n  if datastructure == 'hash':\n    coordinates = coordinates * values.shape[0]\n\n  # Adjust coordinates for 3D voxel grid.\n  if values.ndim == 4:\n    coordinates = coordinates * values.shape[:3]\n\n  # Adjust coordinates for 2D voxel grid.\n  if values.ndim == 3:\n    coordinates = coordinates * values.shape[:2]\n\n  # Adjust coordinates for 1D voxel grid.\n  if values.ndim == 2:\n    coordinates = coordinates * values.shape[:1]\n\n  # Compute interpolation weights.\n  weights = math.lerp(\n      math.lerp(\n          math.lerp(\n              values[jnp.floor(coordinates[:, 0]), jnp.floor(coordinates[:, 1]),\n                      jnp.floor(coordinates[:, 2])],\n              values[jnp.floor(coordinates[:, 0]), jnp.ceil(coordinates[:, 1]),\n                     jnp.floor(coordinates[:, 2])],\n              coordinates[:, 1] - jnp.floor(coordinates[:, 1])),\n          math.lerp(\n              values[jnp.ceil(coordinates[:, 0]), jnp.floor(coordinates[:, 1]),\n                     jnp.floor(coordinates[:, 2])],\n              values[jnp.ceil(coordinates[:, 0]), jnp.ceil(coordinates[:, 1]),\n                     jnp.floor(coordinates[:, 2])],\n              coordinates[:, 1] - jnp.floor(coordinates[:, 1])),\n          coordinates[:, 0] - jnp.floor(coordinates[:, 0])),\n      math.lerp(\n          math.lerp(\n              values[jnp.floor(coordinates[:, 0"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    # Perform trilinear interpolation on a 3D voxel grid.\n    #\n    # The coordinates are expected to be within the bounds of the dimensions they refer to.\n    #\n    # The values array is expected to be a 4D array with shape (D,H,W,C) representing a 3D voxel grid with channels.\n    #\n    # The coordinates array is expected to be a 2D or higher array with shape (..., 3) containing the coordinates for sampling.\n    #\n    # The output is a 2D or higher array with shape (..., C) containing the interpolated values at the specified coordinates. The shape of the output array matches the input coordinates array, with an additional dimension for channels.\n\n    # Reshape the coordinates array to a 3D array with shape (..., 1, 3).\n    coordinates = coordinates.reshape(coordinates.shape[:-1] + (1, 3))\n\n    # Get the lower and upper coordinates for the trilinear interpolation.\n    #\n    # The lower coordinates are expected to be a 3D array with shape (..., 1, 3).\n    #\n    # The upper coordinates are expected to be a 3D array with shape (..., 1, 3).\n    lower_coordinates = jnp.floor(coordinates).astype(jnp.int32)\n    upper_coordinates = lower_coordinates + 1\n\n    # Get the interpolation weights for the trilinear interpolation.\n    #\n    # The weights are expected to be a 3D array with shape (..., 1, 3).\n    weights = coordinates - lower_coordinates\n\n    # Get the values at the lower coordinates.\n    #\n    # The values are expected to be a 4D array with shape (D,H,W,C).\n    #\n    # The lower_coordinates are expected to be a 3D array with shape (..., 1, 3).\n    lower_values = jnp.take(values, lower_coordinates, axis=0)\n\n    # Get the values at the upper coordinates.\n    #"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return trilerp_voxelgrid(values, coordinates)\n  elif datastructure == 'hash':\n    return trilerp_hash(values, coordinates)\n  else:\n    raise ValueError('Unsupported datastructure: %s' % datastructure)\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return trilerp_grid(values, coordinates)\n  elif datastructure == 'hash':\n    return trilerp_hash(values, coordinates)\n  else:\n    raise ValueError('Invalid datastructure: %s. Only grid and hash are supported.' % datastructure)\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    # Trilinear interpolation on a 3D voxel grid.\n    return trilinear_interpolation_3d(values, coordinates)\n  elif datastructure == 'hash':\n    # Trilinear interpolation on a hashed data structure.\n    return trilinear_interpolation_hash(values, coordinates)\n  else:\n    raise ValueError('Invalid datastructure.')\n\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return trilerp_grid(values, coordinates)\n  elif datastructure == 'hash':\n    return trilerp_hash(values, coordinates)\n  else:\n    raise ValueError(\n        'Unsupported data structure type. Expected \"grid\" or \"hash\".')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  # If datastructure is 'grid', then the input values are expected to be a 4D array.\n  if datastructure == 'grid':\n\n    # Reshape the input coordinates array to (N,3) from (...,3)\n    coordinates = jnp.reshape(coordinates, (-1, 3))\n\n    # Compute the lower and upper coordinates for each coordinate in the input coordinates array.\n    lower_coords = jnp.floor(coordinates).astype(jnp.int32)\n    upper_coords = jnp.ceil(coordinates).astype(jnp.int32)\n\n    # Compute the interpolation weights for each coordinate in the input coordinates array.\n    weights = coordinates - lower_coords\n\n    # Create a mask for the coordinates that are out of bounds.\n    mask = jnp.any(jnp.stack([lower_coords < 0, upper_coords > (values.shape[0] - 1)], axis=1), axis=1)\n\n    # Set the coordinates that are out of bounds to the edge coordinates.\n    lower_coords = jnp.where(mask, 0, lower_coords)\n    upper_coords = jnp.where(mask, 0, upper_coords)\n\n    # Reshape the input values array to (D,H,W,C) from (...,C)\n    values = jnp.reshape(values, (values.shape[0], values.shape[1], values.shape[2], values.shape[3]))\n\n    # Compute the values for each coordinate in the input coordinates array.\n    output = (1 - weights[:, 0]) * (1 - weights[:, 1]) * (1 - weights[:, 2]) * values[lower_coords[:, 0], lower_coords[:, 1], lower_coords[:, 2], :] + \\\n        weights[:, 0] * (1 - weights[:, 1]) * (1 - weights[:, 2]) * values[upper_coords[:, 0], lower_coords[:, 1], lower_coords[:, "}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if v < 1:\n    raise ValueError('Tessellation factor must be greater than or equal to 1.')\n\n  # Generate the integer weights for each vertex of the triangle.\n  weights = np.array([[0, 0, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 1, 0], [1, 0, 1], [0, 1, 1], [1, 1, 1]])\n\n  # Normalize the weights to get the barycentric coordinates.\n  weights = weights / v\n\n  return weights\n\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Check if the tessellation factor is valid.\n  if v < 1:\n    raise ValueError(\"The tessellation factor must be greater than or equal to 1.\")\n\n  # Generate the integer weights for each vertex of the triangle.\n  weights = np.arange(v + 1)\n\n  # Normalize the weights to get the barycentric coordinates.\n  weights = weights / v\n\n  # Return the barycentric weights.\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  assert v >= 1, 'Tessellation factor must be greater than or equal to 1.'\n\n  # Generate the integer weights for each vertex of the triangle.\n  weights = np.arange(v + 1)\n\n  # Normalize the weights to get the barycentric coordinates.\n  weights = weights / (v * (v + 1))\n\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if v < 1:\n    raise ValueError('Tessellation factor must be greater than or equal to 1.')\n\n  # Generate the integer weights for each vertex of the triangle.\n  weights = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n\n  # Subdivide the triangle until the tessellation factor is reached.\n  for i in range(v - 1):\n    weights = np.concatenate((weights, weights + 1), axis=0)\n\n  # Normalize the weights to get the barycentric coordinates.\n  weights /= v\n\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if v < 1:\n    raise ValueError(\n        'The tessellation factor must be greater than or equal to 1.')\n\n  # Generate the integer weights for each vertex of the triangle.\n  weights = np.arange(v**2 + 1)\n  weights = weights.reshape((v, v))\n\n  # Normalize the weights to get the barycentric coordinates.\n  weights = weights / np.sum(weights, axis=0)\n  weights = weights.T\n\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if v < 1:\n    raise ValueError(\"Tessellation factor must be greater than or equal to 1.\")\n\n  # Generate the integer weights for the tessellated triangle.\n  weights = np.arange(0, v + 1)\n\n  # Normalize the weights to get the barycentric coordinates.\n  weights = weights / v\n\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Check input.\n  if v < 1:\n    raise ValueError('v must be greater than or equal to 1.')\n\n  # Generate integer weights for each vertex of the triangle.\n  w = np.arange(v, v * 3 + 1)\n\n  # Normalize these weights to get the barycentric coordinates.\n  w = w - np.min(w)\n  w = w / np.sum(w)\n\n  return w\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Compute the number of vertices in the tessellated triangle.\n  num_vertices = (v * (v + 1)) // 2\n\n  # Initialize the barycentric weights.\n  weights = np.zeros(num_vertices)\n\n  # Compute the barycentric weights for each vertex in the tessellated triangle.\n  for i in range(v + 1):\n    for j in range(v + 1 - i):\n      weights[i * v + j] = 1.0 / (i + j + 1)\n\n  # Normalize the barycentric weights.\n  weights /= np.sum(weights)\n\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Check that the tessellation factor is valid.\n  if v < 1:\n    raise ValueError('The tessellation factor must be greater than or equal to 1.')\n\n  # Get the integer weights for each vertex of the triangle.\n  weights = np.arange(1, v + 1)\n\n  # Normalize the integer weights to get the barycentric weights.\n  weights = weights / np.sum(weights)\n\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Check that the tessellation factor is valid.\n  if v < 1:\n    raise ValueError(\"Tessellation factor must be greater than or equal to 1.\")\n\n  # Generate the integer weights for the vertices of the triangle.\n  weights = np.arange(v ** 2 + 1)\n\n  # Normalize the weights to get the barycentric coordinates.\n  weights = weights / (v ** 2 + 1)\n\n  # Return the barycentric coordinates.\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if v < 1:\n    raise ValueError('v must be greater than or equal to 1.')\n\n  v = int(v)\n  weights = np.zeros((v, v, v))\n\n  # Generate integer weights for each vertex of the triangle.\n  for i in range(v):\n    for j in range(v):\n      for k in range(v):\n        weights[i, j, k] = (i + 1) * (j + 1) * (k + 1)\n\n  # Normalize weights to get barycentric coordinates.\n  weights = weights / np.sum(weights)\n\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  assert v >= 1, \"Tesselation factor must be greater than or equal to 1.\"\n  if v == 1:\n    return np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n  else:\n    # Generate the integer weights for each vertex of the triangle.\n    w = np.arange(0, v + 1)[:, None]\n    # Normalize the weights to get the barycentric coordinates.\n    w = w / (v * (v + 1) / 2)\n    return w\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Compute the integer weights for the triangle.\n  w = np.arange(v**2)\n\n  # Normalize the weights.\n  w = w / (v**2 - (v - 1)**2)\n\n  return w\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  assert v >= 1\n  if v == 1:\n    return np.array([1, 1, 1]) / 3\n  v -= 1\n  # The vertices of the triangle.\n  v1 = np.array([1, 0, 0])\n  v2 = np.array([-0.5, np.sqrt(3) / 2, 0])\n  v3 = np.array([-0.5, -np.sqrt(3) / 2, 0])\n  # The edges of the triangle.\n  e1 = v2 - v1\n  e2 = v3 - v1\n  e3 = v2 - v3\n  # The area of the triangle.\n  area = np.linalg.norm(np.cross(e1, e2)) / 2\n  # The number of points in the tessellation.\n  num_points = (v + 1)**2\n  # The barycentric weights for each point in the tessellation.\n  weights = np.zeros((num_points, 3))\n  # The number of points in each row of the tessellation.\n  num_points_per_row = (v + 1)\n  # The number of points in each column of the tessellation.\n  num_points_per_col = (v + 1)\n  # The number of points in each row of the tessellation, except for the last row.\n  num_points_per_row_except_last = num_points_per_row - 1\n  # The number of points in each column of the tessellation, except for the first column.\n  num_points_per_col_except_first = num_points_per_col - 1\n  # The number of points in the first row of the tessellation.\n  num_points_first_row = num_points_per_row_except_last\n  # The number of points in the last row of the tessellation.\n  num_points_last_row = num_points_per_col_except_first\n  # The number"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if v < 1:\n    raise ValueError(\n        'Tessellation factor must be greater than or equal to 1.')\n\n  # Create an integer array of all possible weights.\n  weights = np.arange(0, v + 1, dtype=np.int32)\n\n  # Repeat the weights for each vertex of the triangle.\n  weights = np.tile(weights, (3, 1))\n\n  # Normalize the weights.\n  weights = weights / (v * v * v)\n\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if v < 1:\n    raise ValueError(\n        'v must be greater than or equal to 1, but got v={}'.format(v))\n\n  # Generate integer weights for each vertex of the triangle.\n  weights = np.arange(v + 1)[:, None]\n\n  # Normalize the weights to get barycentric coordinates.\n  weights = weights / (v * (v + 1))\n\n  return weights\n\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Check that the tessellation factor is valid.\n  if v < 1:\n    raise ValueError(\"The tessellation factor must be greater than or equal to 1.\")\n\n  # Initialize the barycentric weights.\n  weights = np.zeros((3, v**2))\n\n  # Compute the barycentric weights for the tessellated triangle.\n  for i in range(v):\n    for j in range(v):\n      weights[:, (v*i + j)] = np.array([i, j, v*i + j - i - j])\n\n  # Normalize the barycentric weights.\n  weights = weights / np.sum(weights, axis=0)\n\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Input checks.\n  assert v >= 1\n\n  # Compute the integer weights for each vertex of the triangle.\n  weights = np.arange(v + 1)[:, None] - np.arange(v + 1)[None, :]\n\n  # Normalize the weights.\n  weights = weights / np.sum(weights, 0)\n\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  assert v >= 1, \"Tesselation factor must be greater than or equal to 1.\"\n\n  # Generate integer weights for each vertex of the triangle.\n  weights = np.arange(v**2 + 1)[:, None]\n  weights = weights - np.max(weights, 0)[None, :]\n  weights = weights / np.abs(weights).sum(0)\n\n  # Normalize the weights to get the barycentric coordinates.\n  weights = weights / weights.sum(0)\n\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Input checks.\n  assert v >= 1, \"Tessellation factor must be greater than or equal to 1.\"\n\n  # Compute the weights.\n  v_weights = np.zeros((3, v**2))\n  for i in range(v):\n    for j in range(v):\n      v_weights[0, i*v + j] = j/v\n      v_weights[1, i*v + j] = i/v\n      v_weights[2, i*v + j] = 1 - i - j/v\n  return v_weights\n\n"}
{"namespace": "linspline.query", "completion": "  # Check that the endpoints are 0.\n  check_zero_endpoints(v)\n\n  # Check that the query points are sorted.\n  checkify.check(jnp.all(tq[Ellipsis, 1:] > tq[Ellipsis, :-1]),\n                 'Query points must be sorted.')\n\n  # Check that the query points are within the range of the time points.\n  checkify.check(jnp.all(tq[Ellipsis, :] >= t[Ellipsis, 0]),\n                 'Query points must be within the time range.')\n  checkify.check(jnp.all(tq[Ellipsis, :] <= t[Ellipsis, -1]),\n                 'Query points must be within the time range.')\n\n  # Check that the time points are sorted.\n  checkify.check(jnp.all(t[Ellipsis, 1:] > t[Ellipsis, :-1]),\n                 'Time points must be sorted.')\n\n  # Check that the time points are monotonically increasing.\n  checkify.check(jnp.all(t[Ellipsis, 1:] - t[Ellipsis, :-1] >= 0),\n                 'Time points must be monotonically increasing.')\n\n  # Check that the time points are unique.\n  checkify.check(jnp.all(t[Ellipsis, 1:] != t[Ellipsis, :-1]),\n                 'Time points must be unique.')\n\n  # Check that the time points are within the range of the query points.\n  checkify.check(jnp.all(t[Ellipsis, :] >= tq[Ellipsis, 0]),\n                 'Time points must be within the query range.')\n  checkify.check(jnp.all(t[Ellipsis, :] <= tq[Ellipsis, -1]),\n                 'Time points must be within the query range.')\n\n  # Check that the time points are monotonically increasing.\n  checkify.check(jnp"}
{"namespace": "linspline.query", "completion": "  tq = jnp.atleast_1d(tq)\n  t = jnp.atleast_1d(t)\n  v = jnp.atleast_1d(v)\n\n  check_zero_endpoints(v)\n  check_zero_endpoints(t)\n\n  # Ensure that the query points are monotonically increasing.\n  checkify.check(jnp.all(tq[Ellipsis, 1:] > tq[Ellipsis, :-1]),\n                 'Query points must be monotonically increasing.')\n\n  # Ensure that the query points are within the range of the time points.\n  checkify.check(jnp.all(tq[Ellipsis, :] >= t[Ellipsis, 0]),\n                 'Query points must be within the range of the time points.')\n  checkify.check(jnp.all(tq[Ellipsis, :] <= t[Ellipsis, -1]),\n                 'Query points must be within the range of the time points.')\n\n  # Ensure that the time points are monotonically increasing.\n  checkify.check(jnp.all(t[Ellipsis, 1:] > t[Ellipsis, :-1]),\n                 'Time points must be monotonically increasing.')\n\n  # Ensure that the time points are within the range of the query points.\n  checkify.check(jnp.all(t[Ellipsis, :] >= tq[Ellipsis, 0]),\n                 'Time points must be within the range of the query points.')\n  checkify.check(jnp.all(t[Ellipsis, :] <= tq[Ellipsis, -1]),\n                 'Time points must be within the range of the query points.')\n\n  # Ensure that the time points are strictly monotonically increasing.\n  checkify.check(jnp.all(t[Ellipsis, 1:] > t[Ellipsis, :-1]),\n                 'Time points must be strictly monotonically increasing.')"}
{"namespace": "linspline.query", "completion": "  tq = jnp.asarray(tq)\n  t = jnp.asarray(t)\n  v = jnp.asarray(v)\n  check_zero_endpoints(v)\n  check_zero_endpoints(t)\n  return utils.cubic_interpolation(tq, t, v)\n\n"}
{"namespace": "linspline.query", "completion": "  tq = jnp.atleast_1d(tq)\n  t = jnp.atleast_1d(t)\n  v = jnp.atleast_1d(v)\n  check_zero_endpoints(v)\n  # Check that tq is in the range [t[0], t[-1]].\n  checkify.check(jnp.all(tq >= t[0]))\n  checkify.check(jnp.all(tq <= t[-1]))\n\n  # Interpolate the spline.\n  interp = jnp.interp(tq, t, v)\n\n  # Extrapolate the spline outside the range [t[0], t[-1]].\n  interp = jnp.where(tq < t[0], jnp.zeros_like(interp), interp)\n  interp = jnp.where(tq > t[-1], jnp.zeros_like(interp), interp)\n\n  return interp\n\n"}
{"namespace": "linspline.query", "completion": "  # Ensure the spline is valid.\n  check_zero_endpoints(v)\n\n  # Interpolate the spline.\n  return math.linear_interpolation(tq, t, v)\n\n"}
{"namespace": "linspline.query", "completion": "  # Check that the spline starts and ends at zero.\n  check_zero_endpoints(v)\n\n  # Make sure that the query points are sorted.\n  tq = jnp.sort(tq)\n\n  # Check that the query points are within the range of the time points.\n  checkify.check(jnp.all(tq >= t[0]), 'Query points must be >= first time point.')\n  checkify.check(jnp.all(tq <= t[-1]), 'Query points must be <= last time point.')\n\n  # Check that the query points are strictly increasing.\n  checkify.check(jnp.all(tq[1:] - tq[:-1] > 0), 'Query points must be strictly increasing.')\n\n  # Check that the time points are strictly increasing.\n  checkify.check(jnp.all(t[1:] - t[:-1] > 0), 'Time points must be strictly increasing.')\n\n  # Check that the time points are unique.\n  checkify.check(jnp.all(jnp.diff(t) > 0), 'Time points must be unique.')\n\n  # Check that the time points are sorted.\n  checkify.check(jnp.all(t[1:] - t[:-1] >= 0), 'Time points must be sorted.')\n\n  # Check that the time points are at least two apart.\n  checkify.check(jnp.all(t[1:] - t[:-1] > 1e-6), 'Time points must be at least two apart.')\n\n  # Check that the time points are at least two apart.\n  checkify.check(jnp.all(t[1:] - t[:-1] > 1e-6), 'Time points must be at least two apart.')\n\n  # Check that the time points are at least two apart.\n  checkify.check(jnp.all(t[1:] - t[:-1] > 1e-6), 'Time points must be at least two apart.')\n\n  # Check that the time points are at least two apart.\n  check"}
{"namespace": "linspline.query", "completion": "  t, v = jnp.atleast_1d(t), jnp.atleast_1d(v)\n  tq = jnp.atleast_1d(tq)\n  check_zero_endpoints(v)\n  checkify.check(jnp.all(t[1:] > t[:-1]), 'Times must be sorted.')\n  checkify.check(jnp.all(tq >= t[0]) * jnp.all(tq <= t[-1]),\n                 'Query points must be inside time range.')\n  # Interpolate the spline at the query points.\n  v_tq = math.interpolate(tq, t, v)\n  # Extrapolate the spline at the query points.\n  v_tq = jnp.where(tq < t[0], jnp.zeros_like(v_tq), v_tq)\n  v_tq = jnp.where(tq > t[-1], jnp.zeros_like(v_tq), v_tq)\n  return v_tq\n\n"}
{"namespace": "linspline.query", "completion": "  # Check that the spline is valid.\n  check_zero_endpoints(v)\n  check_sorted(t)\n  check_increasing(t)\n  check_tq_in_range(tq, t)\n\n  # Interpolate the spline.\n  return jnp.interp(tq, t, v, left=0., right=0.)\n\n"}
{"namespace": "linspline.query", "completion": "  tq = jnp.array(tq)\n  t = jnp.array(t)\n  v = jnp.array(v)\n\n  check_zero_endpoints(v)\n\n  # Ensure the time points are sorted.\n  t = jnp.sort(t)\n\n  # Ensure the query points are sorted.\n  tq = jnp.sort(tq)\n\n  # Ensure the query points are in the range of the time points.\n  tq = jnp.clip(tq, t[0], t[-1])\n\n  # Ensure the time points are unique.\n  t = math.remove_duplicates(t)\n\n  # Ensure the query points are unique.\n  tq = math.remove_duplicates(tq)\n\n  # Find the index of the first time point.\n  i_t0 = jnp.searchsorted(t, tq[Ellipsis, None], side='right').squeeze(-1) - 1\n\n  # Find the index of the last time point.\n  i_t1 = i_t0 + 1\n\n  # Find the time interval between the two time points.\n  dt = t[Ellipsis, 1:] - t[Ellipsis, :-1]\n\n  # Find the time interval between the query points and the first time point.\n  dt0 = tq[Ellipsis, None] - t[Ellipsis, 0]\n\n  # Find the time interval between the query points and the last time point.\n  dt1 = t[Ellipsis, -1] - tq[Ellipsis, None]\n\n  # Find the time interval between the two time points.\n  dt = jnp.concatenate((dt, dt[-1:]), axis=-1)\n\n  # Find the time interval between the query points and the first time point.\n  dt0 = jnp.concatenate((dt0, dt0[-1:]), axis=-1)\n\n  # Find the time interval between the query points and the last time point.\n  dt1 = jnp."}
{"namespace": "linspline.query", "completion": "  tq = jnp.asarray(tq)\n  t = jnp.asarray(t)\n  v = jnp.asarray(v)\n  check_zero_endpoints(v)\n  checkify.check(jnp.all(jnp.diff(t) > 0), 'Spline must be increasing.')\n  checkify.check(jnp.all(tq >= t[0]) & jnp.all(tq <= t[-1]),\n                 'Query points must be inside the range of the knots.')\n  return jnp.where(tq < t[0], 0,\n                   jnp.where(tq > t[-1], 0,\n                             jnp.interp(tq, t, v, left=0, right=0)))\n\n"}
{"namespace": "linspline.query", "completion": "  tq = jnp.asarray(tq)\n  t = jnp.asarray(t)\n  v = jnp.asarray(v)\n\n  check_zero_endpoints(v)\n  checkify.check(jnp.all(t[1:] > t[:-1]), 'Time points must be sorted.')\n  checkify.check(jnp.all(t[0] <= tq) & jnp.all(tq <= t[-1]),\n                 'Query points must be between the time points.')\n\n  # Find the indices of the first time point to the left of each query point.\n  # If a query point is less than or equal to the first time point, we use that\n  # time point.\n  left_indices = jnp.searchsorted(t, tq, side='right') - 1\n  left_indices = jnp.where(left_indices == -1, 0, left_indices)\n\n  # Find the indices of the first time point to the right of each query point.\n  # If a query point is greater than or equal to the last time point, we use that\n  # time point.\n  right_indices = jnp.searchsorted(t, tq, side='left')\n  right_indices = jnp.where(right_indices == t.shape[0], t.shape[0] - 1,\n                            right_indices)\n\n  # Compute the time deltas and ratios for each segment.\n  dt = t[right_indices] - t[left_indices]\n  slopes = (v[right_indices] - v[left_indices]) / dt\n\n  # Compute the time since the left time point.\n  t_since_left = tq - t[left_indices]\n\n  # Compute the interpolated value for each segment.\n  return v[left_indices] + slopes * t_since_left\n\n"}
{"namespace": "linspline.query", "completion": "  t, v = jnp.atleast_1d(t), jnp.atleast_1d(v)\n  tq = jnp.atleast_1d(tq)\n\n  check_zero_endpoints(v)\n  check_zero_endpoints(tq)\n\n  # Check that the input spline is valid.\n  checkify.check(\n      jnp.all(t[1:] >= t[:-1]), 'Spline knots must be sorted in ascending order.')\n  checkify.check(\n      jnp.all(t[1:] > 0), 'Spline knots must be strictly positive.')\n  checkify.check(\n      jnp.all(tq >= 0), 'Spline query points must be strictly positive.')\n\n  # Check that the input spline is valid.\n  checkify.check(\n      jnp.all(t[1:] >= t[:-1]), 'Spline knots must be sorted in ascending order.')\n  checkify.check(\n      jnp.all(t[1:] > 0), 'Spline knots must be strictly positive.')\n  checkify.check(\n      jnp.all(tq >= 0), 'Spline query points must be strictly positive.')\n\n  # Compute the spline coefficients.\n  a = jnp.diff(v, axis=-1) / jnp.diff(t, axis=-1)\n  b = v[:, :-1] - a * t[:, :-1]\n\n  # Compute the spline values.\n  return math.interpolate(tq, t, a, b)\n\n"}
{"namespace": "linspline.query", "completion": "  # Ensure that the spline is valid.\n  check_zero_endpoints(v)\n\n  # Interpolate the spline at the query points.\n  return math.linear_interpolation(tq, t, v)\n\n"}
{"namespace": "linspline.query", "completion": "  tq = jnp.asarray(tq)\n  t = jnp.asarray(t)\n  v = jnp.asarray(v)\n\n  # Ensure the spline is valid.\n  check_zero_endpoints(v)\n  utils.check_shape_match(tq, (Ellipsis, 1))\n  utils.check_shape_match(t, (Ellipsis, 1))\n  utils.check_shape_match(v, (Ellipsis, 1))\n  utils.check_shape_match(t, tq, axis=-1)\n\n  # Find the index of the first time point.\n  index = jnp.searchsorted(t, tq, side='right')\n  index = jnp.clip(index - 1, 0, t.shape[-1] - 1)\n\n  # Find the index of the last time point.\n  next_index = jnp.minimum(index + 1, t.shape[-1] - 1)\n\n  # Find the interpolation coefficients.\n  index = jnp.expand_dims(index, axis=-1)\n  next_index = jnp.expand_dims(next_index, axis=-1)\n  weight = (tq - t[Ellipsis, index]) / (\n      t[Ellipsis, next_index] - t[Ellipsis, index])\n  weight = jnp.clip(weight, a_min=0.0, a_max=1.0)\n\n  # Interpolate the values.\n  v = v[Ellipsis, index] + weight * (v[Ellipsis, next_index] - v[Ellipsis, index])\n\n  # Extrapolate the values.\n  v = jnp.where(tq < t[0], jnp.zeros_like(v), v)\n  v = jnp.where(tq > t[-1], jnp.zeros_like(v), v)\n\n  return v\n\n"}
{"namespace": "linspline.query", "completion": "  # Check for zero endpoints.\n  check_zero_endpoints(v)\n\n  # Interpolate.\n  return jnp.where(\n      jnp.logical_or(tq < t[0], tq > t[-1]),\n      jnp.zeros_like(tq),\n      jnp.interp(tq, t, v, left=0, right=0),\n  )\n\n"}
{"namespace": "linspline.query", "completion": "  tq = jnp.asarray(tq)\n  t = jnp.asarray(t)\n  v = jnp.asarray(v)\n\n  check_zero_endpoints(v)\n\n  # Ensure that tq is in the range [t[0], t[-1]].\n  tq = jnp.where(tq < t[0], t[0], tq)\n  tq = jnp.where(tq > t[-1], t[-1], tq)\n\n  # Find the indices of the tq values.\n  indices = jnp.searchsorted(t, tq)\n\n  # Find the indices of the left and right neighbors.\n  left_indices = jnp.maximum(indices - 1, 0)\n  right_indices = jnp.minimum(indices, t.shape[-1] - 1)\n\n  # Compute the interpolation weights.\n  left_weights = (tq - t[left_indices]) / (t[right_indices] - t[left_indices])\n  right_weights = 1 - left_weights\n\n  # Interpolate the values.\n  left_values = v[Ellipsis, left_indices]\n  right_values = v[Ellipsis, right_indices]\n  interpolated_values = (\n      left_values * left_weights + right_values * right_weights)\n\n  # Extrapolate the values.\n  # The first and last splines are flat.\n  first_values = v[Ellipsis, 0]\n  last_values = v[Ellipsis, -1]\n  interpolated_values = jnp.where(\n      indices == 0, first_values, interpolated_values)\n  interpolated_values = jnp.where(\n      indices == v.shape[-1] - 1, last_values, interpolated_values)\n\n  return interpolated_values\n\n"}
{"namespace": "linspline.query", "completion": "  # Ensure that the spline starts and ends at 0.\n  check_zero_endpoints(v)\n\n  # Interpolate the spline to the query points.\n  yq = math.linear_interpolation(tq, t, v)\n\n  # Extrapolate the spline to the query points.\n  yq = jnp.where(tq < t[0], jnp.zeros_like(yq), yq)\n  yq = jnp.where(tq > t[-1], jnp.zeros_like(yq), yq)\n\n  return yq\n\n"}
{"namespace": "linspline.query", "completion": "  tq = jnp.atleast_1d(tq)\n  t = jnp.atleast_1d(t)\n  v = jnp.atleast_1d(v)\n  check_zero_endpoints(v)\n\n  def _interp(tq, t, v):\n    \"\"\"Interpolate with a linear spline.\"\"\"\n    # Find the indices of the points where the spline is defined.\n    ti = jnp.searchsorted(t, tq)\n    # If we are beyond the edges of the range, we will extrapolate the spline.\n    # We set the values to 0.\n    ti = jnp.clip(ti, 1, len(t) - 1)\n    # Get the values of the spline at the query points.\n    tq_left = t[ti - 1]\n    tq_right = t[ti]\n    vq = v[ti - 1] + (tq - tq_left) / (tq_right - tq_left) * (\n        v[ti] - v[ti - 1])\n    return vq\n\n  return jax.lax.cond(\n      jnp.all(tq <= t[0]) | jnp.all(tq >= t[-1]), lambda x: jnp.zeros_like(x),\n      _interp, tq, t, v)\n\n"}
{"namespace": "linspline.query", "completion": "  # Check that the input arrays have the right shape.\n  tq = jnp.asarray(tq)\n  t = jnp.asarray(t)\n  v = jnp.asarray(v)\n  assert tq.ndim == 1\n  assert t.ndim == 1\n  assert v.ndim == 2\n  assert v.shape[0] == t.shape[0]\n  assert tq.shape[0] == v.shape[1]\n\n  # Check that the spline is well-defined.\n  check_zero_endpoints(v)\n\n  # Find the indices of the knots that bound each query point.\n  indices = jnp.searchsorted(t, tq)\n  indices = jnp.clip(indices, 0, t.shape[0] - 1)\n\n  # Compute the interpolation weights.\n  weights = math.lerp(t[indices], tq)\n\n  # Compute the interpolated values.\n  values = (weights * v[:, indices]).sum(axis=0)\n\n  # Extrapolate values to 0 at the beginning and end of the spline.\n  return jnp.where(tq < t[0], 0, jnp.where(tq > t[-1], 0, values))\n\n"}
{"namespace": "linspline.query", "completion": "  tq = jnp.asarray(tq)\n  t = jnp.asarray(t)\n  v = jnp.asarray(v)\n  assert tq.ndim == 1\n  assert t.ndim == 1\n  assert v.ndim == 2\n  assert tq.shape[0] == v.shape[0]\n  assert t.shape[0] == v.shape[1]\n  assert jnp.all(t[1:] > t[:-1])\n  assert jnp.all(jnp.diff(t) > 0)\n  assert jnp.all(v >= 0)\n  check_zero_endpoints(v)\n  return jnp.where(\n      jnp.logical_and(tq[Ellipsis, None] >= t[None, ...],\n                      tq[Ellipsis, None] <= t[-1, None]),\n      utils.linear_interpolation(tq[:, None], t, v), 0)\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(x > 0 for x in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if any(i <= 0 for i in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if np.any(v <= 0):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if any(x <= 0 for x in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n\n    elif v <= 0:\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if any(i <= 0 for i in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n    elif v <= 0:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if any(i < 0 for i in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n    elif v < 0:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if np.any(v <= 0):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if any([x <= 0 for x in v]):\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if any(i < 0 for i in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n    else:\n        if v < 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if any(i <= 0 for i in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if np.sum(v < 0) > 0:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if any(x <= 0 for x in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive. Got {v}.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive. Got {v}.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(v_i > 0 for v_i in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must be all positive.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for i in v:\n            if i <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if np.any(v <= 0):\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if any(x <= 0 for x in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if np.any(v <= 0):\n        raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if any(x < 0 for x in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v < 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(i > 0 for i in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive. All values must be positive.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive. All values must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if any(val <= 0 for val in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive. Got {v}.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive. Got {v}.\")\n\n    return v\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # pylint: disable=invalid-name\n\n  # pylint: enable=invalid-name\n\n  # pylint: disable=invalid-name\n\n  # pylint: enable=invalid-name\n\n  # pylint: disable=invalid-name\n\n  # pylint: enable=invalid-name\n\n  # pylint: disable=invalid-name\n\n  # pylint: enable=invalid-name\n\n  # pylint: disable=invalid-name\n\n  # pylint: enable=invalid-name\n\n  # pylint: disable=invalid-name\n\n  # pylint: enable=invalid-name\n\n  # pylint: disable=invalid-name\n\n  # pylint: enable=invalid-name\n\n  # pylint: disable=invalid-name\n\n  # pylint: enable=invalid-name\n\n  # pylint: disable=invalid-name\n\n  # pylint: enable=invalid-name\n\n  # pylint: disable=invalid-name\n\n  # pylint: enable=invalid-name\n\n  # pylint: disable=invalid-name\n\n  # pylint: enable=invalid-name\n\n  # pylint: disable=invalid-name\n\n  # pylint: enable=invalid-name\n\n  # pylint: disable=invalid-name\n\n  # pylint: enable=invalid-name\n\n  # pylint: disable=invalid-name\n\n  # pylint: enable=invalid-name\n\n  # pylint: disable=invalid-name\n\n  # pylint: enable=invalid-name\n\n  # pylint: disable=invalid-name\n\n  # pylint: enable=invalid-name\n\n  # pylint: disable=invalid-name\n\n  # pylint: enable=invalid-name\n\n  # pylint: disable=invalid-name\n\n  # pylint: enable=invalid-name\n\n  # pylint: disable=invalid-name\n\n  # pylint: enable=invalid-name\n\n  # pyl"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Calculate the ray origins in NDC.\n  origins_ndc = xnp.dot(origins, pixtocam)\n  origins_ndc = xnp.dot(origins_ndc, xnp.array([[1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0], [0.0, 0.0, -1.0 / near, 0.0]]))\n\n  # Calculate the ray directions in NDC.\n  directions_ndc = xnp.dot(directions, pixtocam)\n  directions_ndc = xnp.dot(directions_ndc, xnp.array([[1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0], [0.0, 0.0, -1.0 / near, 0.0]]))\n\n  return origins_ndc, directions_ndc\n\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  origins = xnp.asarray(origins)\n  directions = xnp.asarray(directions)\n  pixtocam = xnp.asarray(pixtocam)\n\n  # Get the rays' starting points in NDC.\n  origins_ndc = xnp.matmul(pixtocam, origins.T).T\n\n  # Get the ray directions in NDC.\n  directions_ndc = xnp.matmul(pixtocam, directions.T).T\n\n  # Adjust the rays' starting points to the near plane.\n  origins_ndc = origins_ndc + directions_ndc * near\n\n  return origins_ndc, directions_ndc\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Compute the direction of the rays in NDC.\n  directions_ndc = directions @ pixtocam\n\n  # Compute the origin of the rays in NDC.\n  origins_ndc = xnp.dot(origins, pixtocam)\n  origins_ndc = origins_ndc / origins_ndc[..., -1:]\n  origins_ndc = origins_ndc[..., :-1]\n\n  return origins_ndc, directions_ndc\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  origins = xnp.asarray(origins)\n  directions = xnp.asarray(directions)\n  pixtocam = xnp.asarray(pixtocam)\n\n  # Compute the ray origins in NDC.\n  origins = xnp.dot(pixtocam, xnp.concatenate([origins, xnp.ones_like(origins[:, :1])], axis=-1))\n  origins = origins[:, :3] / origins[:, 3:]\n\n  # Compute the ray directions in NDC.\n  directions = xnp.dot(pixtocam, xnp.concatenate([directions, xnp.zeros_like(directions[:, :1])], axis=-1))\n  directions = directions[:, :3] / directions[:, 3:]\n\n  # Adjust the ray origins to the near plane.\n  origins = origins * near + directions * near * -1\n\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert rays to camera space.\n  ray_origins_cam, ray_dirs_cam = geometry.world_to_camera_rays(origins, directions, pixtocam, xnp)\n\n  # Convert rays to NDC.\n  ray_origins_ndc = ray_origins_cam * near / ray_dirs_cam[:, 2:3]\n  ray_dirs_ndc = ray_dirs_cam * near / ray_dirs_cam[:, 2:3]\n\n  return ray_origins_ndc, ray_dirs_ndc\n\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert ray origins to camera space.\n  origins_cam = xnp.matmul(pixtocam, origins.T).T\n  # Calculate the direction of the rays in camera space.\n  directions_cam = directions\n\n  # Convert ray origins to normalized device coordinates.\n  origins_ndc = origins_cam[:, :2] / origins_cam[:, 2:]\n  # Calculate the direction of the rays in normalized device coordinates.\n  directions_ndc = directions_cam[:, :2] / directions_cam[:, 2:]\n\n  # Adjust ray origins to the near plane.\n  origins_ndc = origins_ndc - directions_ndc * near\n\n  return origins_ndc, directions_ndc\n\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert rays to camera space.\n  origins_cam = xnp.matmul(pixtocam, origins)\n  directions_cam = xnp.matmul(pixtocam, directions)\n\n  # Convert rays to normalized device coordinates.\n  origins_ndc = origins_cam / directions_cam[:, 2:3]\n  origins_ndc = xnp.concatenate([origins_ndc, -near * xnp.ones_like(origins_ndc[:, 2:3])], axis=-1)\n  directions_ndc = directions_cam / directions_cam[:, 2:3]\n  directions_ndc = xnp.concatenate([directions_ndc, -near * xnp.ones_like(directions_ndc[:, 2:3])], axis=-1)\n\n  return origins_ndc, directions_ndc\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert the ray origins to NDC.\n  origins = xnp.dot(pixtocam, xnp.concatenate(\n      [origins, xnp.ones_like(origins[:, :1])], axis=-1).T).T\n  origins = origins / origins[:, 3:]\n  origins = origins[:, :3]\n\n  # Convert the ray directions to NDC.\n  directions = directions / directions[:, 3:]\n  directions = directions[:, :3]\n\n  # Adjust the ray origins to the near plane.\n  origins = origins + directions * near\n\n  # Normalize the ray directions.\n  directions = directions / xnp.linalg.norm(directions, axis=-1, keepdims=True)\n\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # get the ray directions in camera space\n  raydirs_cam = geometry.transform_points(directions, pixtocam, xnp)\n\n  # adjust the ray origins to the near plane\n  rayorigs_cam = origins + raydirs_cam * near\n\n  # get the ray directions in NDC\n  raydirs_ndc = raydirs_cam / raydirs_cam[..., 2:]\n\n  # get the ray origins in NDC\n  rayorigs_ndc = rayorigs_cam / rayorigs_cam[..., 2:]\n\n  return rayorigs_ndc, raydirs_ndc\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Set the ray origins to the near plane\n  origins = xnp.broadcast_to(origins, directions.shape)\n  origins = origins - directions * near\n\n  # Calculate the ray directions in NDC\n  directions = directions / directions[..., 2:]\n  directions = directions @ pixtocam[..., :3, :3].transpose(-1, -2)\n  directions = directions * (1 / directions[..., 2:])\n\n  return origins, directions\n\n\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  origins = xnp.asarray(origins)\n  directions = xnp.asarray(directions)\n  pixtocam = xnp.asarray(pixtocam)\n\n  origins = xnp.reshape(origins, (-1, 3))\n  directions = xnp.reshape(directions, (-1, 3))\n  pixtocam = xnp.reshape(pixtocam, (3, 3))\n\n  # Get the starting points of the rays in NDC.\n  origins = xnp.matmul(pixtocam, xnp.stack([origins, xnp.ones_like(origins[:, 0])], axis=-1))\n  origins = origins[:, :3] / origins[:, 3:]\n\n  # Get the directions of the rays in NDC.\n  directions = xnp.matmul(pixtocam, xnp.stack([directions, xnp.zeros_like(directions[:, 0])], axis=-1))\n  directions = directions[:, :3] / directions[:, 3:] - origins\n\n  # Adjust the ray origins to the near plane.\n  origins = xnp.reshape(origins, (-1, 3))\n  origins = xnp.where(origins[:, 2] < near, xnp.stack([origins[:, 0], origins[:, 1], xnp.full_like(origins[:, 2], near)], axis=-1), origins)\n\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  origins = xnp.asarray(origins, dtype=jnp.float32)\n  directions = xnp.asarray(directions, dtype=jnp.float32)\n  pixtocam = xnp.asarray(pixtocam, dtype=jnp.float32)\n\n  if origins.ndim != 2 or origins.shape[1] != 3:\n    raise ValueError(\n        f'origins must be of shape (N,3), but has shape {origins.shape}.')\n\n  if directions.ndim != 2 or directions.shape[1] != 3:\n    raise ValueError(\n        f'directions must be of shape (N,3), but has shape {directions.shape}.')\n\n  if origins.shape[0] != directions.shape[0]:\n    raise ValueError(\n        f'origins and directions must have the same number of rays, but have shapes {origins.shape} and {directions.shape}.')\n\n  if pixtocam.ndim != 2 or pixtocam.shape[0] != 3 or pixtocam.shape[1] != 3:\n    raise ValueError(\n        f'pixtocam must be of shape (3,3), but has shape {pixtocam.shape}.')\n\n  origins = xnp.concatenate([origins, xnp.ones_like(origins[:, :1])], axis=1)\n  directions = xnp.concatenate(\n      [directions, xnp.zeros_like(directions[:, :1])], axis=1)\n\n  origins = xnp.einsum('ij,nj->ni', pixtocam, origins)\n  directions = xnp.einsum('ij,nj->ni', pixtocam, directions)\n\n  directions = directions / directions[:, 2:3]\n\n  origins = origins[:, :2] / origins[:, 2:3]\n  directions = directions[:, :2] / directions[:, 2:3]"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # pylint: disable=too-many-arguments\n\n  # pylint: disable=too-many-locals\n\n  # pylint: disable=too-many-statements\n\n  if xnp == jnp:\n    origins = jnp.asarray(origins)\n    directions = jnp.asarray(directions)\n    pixtocam = jnp.asarray(pixtocam)\n\n  near = float(near)\n\n  # Transform the rays to the camera space.\n  origins_cam = xnp.matmul(pixtocam, origins.T).T\n  directions_cam = xnp.matmul(pixtocam, directions.T).T\n\n  # Adjust the ray origins to the near plane.\n  origins_cam = origins_cam - directions_cam * near\n\n  # Normalize the ray directions.\n  directions_cam = directions_cam / xnp.linalg.norm(directions_cam, axis=-1, keepdims=True)\n\n  # Transform the rays back to world space.\n  origins = xnp.matmul(pixtocam.T, origins_cam.T).T\n  directions = xnp.matmul(pixtocam.T, directions_cam.T).T\n\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert ray origins to camera space.\n  origins_cam = xnp.dot(origins, pixtocam.T)\n\n  # Convert ray directions to camera space.\n  directions_cam = xnp.dot(directions, pixtocam.T)\n\n  # Calculate the ray origins in NDC.\n  origins_ndc = xnp.array([\n    origins_cam[:, 0] / origins_cam[:, 2],\n    origins_cam[:, 1] / origins_cam[:, 2],\n    xnp.ones_like(origins_cam[:, 2]),\n  ])\n\n  # Calculate the ray directions in NDC.\n  directions_ndc = xnp.array([\n    directions_cam[:, 0] / directions_cam[:, 2],\n    directions_cam[:, 1] / directions_cam[:, 2],\n    xnp.zeros_like(directions_cam[:, 2]),\n  ])\n\n  # Adjust the ray origins to the near plane.\n  origins_ndc = origins_ndc * near\n\n  return origins_ndc, directions_ndc\n\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Unpack the inputs.\n  origins, directions = origins.astype(xnp.float32), directions.astype(xnp.float32)\n  pixtocam = pixtocam.astype(xnp.float32)\n\n  # Convert the rays to camera space.\n  camrays = geometry.rays_from_pixels(origins, directions, pixtocam)\n\n  # Adjust the ray origins to the near plane.\n  camrays = camrays._replace(\n      origins=xnp.broadcast_to(\n          xnp.array([0, 0, near], dtype=xnp.float32),\n          origins.shape,\n      ),\n  )\n\n  # Convert the rays to NDC.\n  return geometry.rays_to_ndc(camrays)\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert rays to NDC.\n  # The near and far planes are set to 1 and -1 to ensure that the rays are\n  # entirely contained within the unit cube.\n  origins_ndc = xnp.dot(pixtocam, xnp.concatenate([origins, -xnp.ones_like(origins[:, 0:1])], axis=1))\n  origins_ndc = origins_ndc[:, :3] / origins_ndc[:, 3:]\n  origins_ndc = origins_ndc * near\n\n  directions_ndc = directions * near\n\n  return origins_ndc, directions_ndc\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  origins = xnp.asarray(origins, dtype=jnp.float32)\n  directions = xnp.asarray(directions, dtype=jnp.float32)\n  pixtocam = xnp.asarray(pixtocam, dtype=jnp.float32)\n\n  # Calculate the rays' depth in NDC.\n  depth = -origins[..., 2]\n\n  # Calculate the rays' starting points in NDC.\n  xy = xnp.einsum(\"...ij,...i->...j\", pixtocam, origins)\n  xy /= depth[..., None]\n\n  # Calculate the rays' directions in NDC.\n  xyz = xnp.einsum(\"...ij,...i->...j\", pixtocam, directions)\n  xyz /= xyz[..., 2][..., None]\n\n  # Adjust the rays' starting points to the near plane.\n  xy[..., 2] = near\n\n  # Adjust the rays' directions to the near plane.\n  xyz[..., 2] = 1.0\n\n  return xy, xyz\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  origins = xnp.asarray(origins)\n  directions = xnp.asarray(directions)\n  pixtocam = xnp.asarray(pixtocam)\n\n  # Compute the perspective projection of the rays.\n  # (1) Project the ray origins to the near plane.\n  # (2) Normalize the ray directions.\n  # (3) Project the ray directions to the near plane.\n  # (4) Normalize the ray directions.\n  origins = xnp.dot(pixtocam, xnp.concatenate([origins, xnp.ones_like(origins[:, :1])], axis=1))\n  origins = origins[:, :3] / origins[:, 3:]\n  origins = origins * near\n  directions = directions / xnp.linalg.norm(directions, axis=-1, keepdims=True)\n  directions = xnp.dot(pixtocam, xnp.concatenate([directions, xnp.zeros_like(directions[:, :1])], axis=1))\n  directions = directions[:, :3] / directions[:, 3:]\n  directions = directions * near\n\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert rays to camera space.\n  origins_cam, directions_cam = utils.transform_rays(origins, directions, pixtocam)\n\n  # Convert rays to NDC.\n  origins_ndc = utils.ndc_rays(origins_cam, directions_cam, near, xnp)\n  directions_ndc = directions_cam\n\n  return origins_ndc, directions_ndc\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Make sure direction vectors are unit.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  return jnp.allclose(jnp.dot(dir1, dir2), 1.0, atol=1e-05)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Make sure direction vectors are unit.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n  return jnp.isclose(jnp.dot(dir1, dir2), 1.0, atol=1e-6)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n  dot_product = jnp.dot(dir1, dir2)\n  return jnp.abs(dot_product) > 1.0 - 1e-6\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Make sure direction vectors are unit.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n  return jnp.isclose(jnp.dot(dir1, dir2), 1.0, atol=1e-6)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Make sure direction vectors are unit.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  return jnp.isclose(jnp.dot(dir1, dir2), 1.0, atol=1e-05)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Make sure direction vectors are unit.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  # If the dot product is 1, then the lines are parallel.\n  return jnp.isclose(jnp.dot(dir1, dir2), 1)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  eps = 1e-6\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n  dot_product = jnp.sum(dir1 * dir2, axis=-1)\n  return jnp.abs(dot_product) > 1 - eps\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Make sure direction vectors are unit.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  # The dot product of two parallel vectors is equal to the magnitude of their\n  # normalized vectors.\n  return jnp.isclose(jnp.dot(dir1, dir2), 1.0, atol=1e-06)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Make sure direction vectors are unit.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  # Compute the dot product of the direction vectors.\n  dot = jnp.dot(dir1, dir2)\n\n  # Check if the dot product is equal to 1 (within numerical precision).\n  return jnp.isclose(dot, 1.0)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-8\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n  return jnp.all(jnp.abs(jnp.sum(dir1 * dir2, axis=-1, keepdims=True)) > 1.0 - epsilon)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Make sure direction vectors are unit.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n  # Compute the dot product of the two direction vectors.\n  dot_product = jnp.sum(dir1 * dir2, axis=-1)\n  # If the dot product is equal to 1, the lines are parallel.\n  return jnp.isclose(dot_product, 1)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n  return jnp.isclose(jnp.dot(dir1, dir2), 1.0)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Make sure direction vectors are unit.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n  # Compute the dot product between the two direction vectors.\n  dot_product = jnp.sum(dir1 * dir2, axis=-1)\n  # Compute the angle between the two direction vectors.\n  angle = jnp.arccos(dot_product)\n  # If the angle is close to zero, then the lines are parallel.\n  return jnp.isclose(angle, 0.0)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Make sure direction vectors are unit.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  # Compute the dot product of the two direction vectors.\n  dot = jnp.sum(dir1 * dir2, axis=-1, keepdims=True)\n\n  # If the dot product is equal to 1, then the lines are parallel.\n  return jnp.isclose(dot, 1.0)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Make sure direction vectors are unit.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  # The dot product between the direction vectors of the two lines.\n  dot_product = jnp.sum(dir1 * dir2, axis=-1, keepdims=True)\n\n  # If the dot product is close to 1, the two lines are parallel.\n  return jnp.isclose(dot_product, 1.0)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Make sure direction vectors are unit.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  # The dot product of the normalized direction vectors should be close to 1.\n  return jnp.abs(jnp.dot(dir1, dir2)) > 1.0 - 1e-6\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Make sure direction vectors are unit.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n  # Compute the dot product of the two direction vectors.\n  dot_product = jnp.sum(dir1 * dir2, axis=-1, keepdims=True)\n  # Return True if the dot product is close to 1, otherwise False.\n  return jnp.isclose(dot_product, 1.0)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Make sure direction vectors are unit.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  # Compute the dot product of the two direction vectors.\n  dot_product = jnp.sum(dir1 * dir2, axis=-1)\n\n  # Check if the dot product is equal to 1.\n  return jnp.isclose(dot_product, 1.0)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Make sure direction vectors are unit.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n  return jnp.allclose(jnp.dot(dir1, dir2), 1, atol=1e-6)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Make sure direction vectors are unit.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  # The dot product of two unit vectors is equal to the cosine of the angle between them.\n  return jnp.abs(jnp.dot(dir1, dir2)) > 1.0 - 1e-6\n\n"}
{"namespace": "common.bleu4_score", "completion": "    # Tokenize the input texts\n    continuation_tokens = jieba.lcut(continuation)\n    reference_tokens = jieba.lcut(reference)\n\n    # Calculate the BLEU-4 score\n    bleu4_score = evaluate.bleu4(\n        continuation_tokens,\n        reference_tokens,\n        with_penalty\n    )\n\n    return bleu4_score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    # Tokenize the input text\n    continuation_tokens = jieba.lcut(continuation)\n    reference_tokens = jieba.lcut(reference)\n\n    # Calculate the BLEU score\n    bleu4_score = evaluate.bleu4_score(\n        continuation_tokens,\n        reference_tokens,\n        with_penalty\n    )\n\n    return bleu4_score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    bleu4_score = evaluate.bleu4_score(\n        continuation,\n        reference,\n        tokenizer = jieba.cut\n    )\n\n    if with_penalty:\n        bleu4_score = evaluate.apply_brevity_penalty(\n            bleu4_score,\n            continuation,\n            reference,\n            tokenizer = jieba.cut\n        )\n\n    return bleu4_score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    # Tokenize the input texts\n    continuation_tokens = jieba.lcut(continuation)\n    reference_tokens = jieba.lcut(reference)\n\n    # Calculate the BLEU-4 score\n    bleu_score = evaluate.bleu_score(continuation_tokens, reference_tokens)\n\n    # Include the brevity penalty in the final score\n    if with_penalty:\n        brevity_penalty = evaluate.brevity_penalty(continuation_tokens, reference_tokens)\n        bleu_score = bleu_score * brevity_penalty\n\n    return bleu_score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    continuation_tokens = jieba.lcut(continuation)\n    reference_tokens = jieba.lcut(reference)\n\n    bleu4_score = evaluate.bleu4_score(continuation_tokens, reference_tokens)\n\n    if with_penalty:\n        continuation_length = len(continuation_tokens)\n        reference_length = len(reference_tokens)\n        penalty = evaluate.brevity_penalty(continuation_length, reference_length)\n        bleu4_score = bleu4_score * penalty\n\n    return bleu4_score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    # Tokenize the input texts\n    continuation_tokens = jieba.lcut(continuation)\n    reference_tokens = jieba.lcut(reference)\n\n    # Calculate the BLEU-4 score\n    bleu4 = evaluate.bleu.compute_bleu(\n        reference_corpus = [reference_tokens],\n        translation_corpus = [continuation_tokens],\n        max_order = 4,\n        smooth = True\n    )\n\n    # Optionally include the brevity penalty in the final score calculation\n    if with_penalty:\n        bleu4 = evaluate.bleu.brevity_penalty(\n            hyp_len = len(continuation_tokens),\n            ref_len = len(reference_tokens),\n            hyp_len_max = len(continuation_tokens),\n            ref_len_max = len(reference_tokens)\n        ) * bleu4\n\n    return bleu4\n\n"}
{"namespace": "common.bleu4_score", "completion": "    # Tokenize the input texts\n    continuation_tokens = jieba.lcut(continuation)\n    reference_tokens = jieba.lcut(reference)\n\n    # Calculate the BLEU-4 score\n    bleu4_score = evaluate.bleu4(continuation_tokens, reference_tokens)\n\n    # Calculate the brevity penalty\n    if with_penalty:\n        continuation_length = len(continuation_tokens)\n        reference_length = len(reference_tokens)\n        penalty = 1.0\n        if continuation_length > reference_length:\n            penalty = math.exp(1 - reference_length / continuation_length)\n        bleu4_score = bleu4_score * penalty\n\n    return bleu4_score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    # Tokenize input texts\n    continuation_tokens = jieba.lcut(continuation)\n    reference_tokens = jieba.lcut(reference)\n\n    # Calculate BLEU-4 score\n    bleu4 = evaluate.bleu4(\n        continuation_tokens,\n        reference_tokens\n    )\n\n    if with_penalty:\n        # Calculate brevity penalty\n        penalty = evaluate.brevity_penalty(\n            continuation_tokens,\n            reference_tokens\n        )\n\n        # Adjust BLEU-4 score for brevity penalty\n        bleu4 = penalty * bleu4\n\n    return bleu4\n\n"}
{"namespace": "common.bleu4_score", "completion": "    # Tokenize the input texts\n    continuation_tokens = jieba.lcut(continuation)\n    reference_tokens = jieba.lcut(reference)\n\n    # Calculate the BLEU-4 score\n    bleu4_score = evaluate.bleu4_score(continuation_tokens, reference_tokens)\n\n    # Include the brevity penalty in the final score calculation\n    if with_penalty:\n        bleu4_score = evaluate.bleu4_penalty(bleu4_score, len(continuation_tokens), len(reference_tokens))\n\n    return bleu4_score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    def tokenizer(text: str) -> list:\n        return jieba.lcut(text)\n\n    return evaluate.bleu4_score(\n        continuation = continuation,\n        reference = reference,\n        tokenizer = tokenizer,\n        with_penalty = with_penalty\n    )\n\n"}
{"namespace": "common.bleu4_score", "completion": "    # Tokenize input texts\n    continuation_tokens = jieba.lcut(continuation)\n    reference_tokens = jieba.lcut(reference)\n\n    # Calculate BLEU-4 score\n    bleu4_score = evaluate.bleu4_score(\n        continuation_tokens,\n        reference_tokens,\n        with_penalty=with_penalty\n    )\n\n    return bleu4_score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    tokenizer = lambda x: jieba.cut(x)\n    bleu4 = evaluate.bleu4(\n        continuation,\n        reference,\n        tokenizer\n    )\n    if with_penalty:\n        return bleu4.score * bleu4.penalty\n    else:\n        return bleu4.score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    # Tokenize the input texts using jieba\n    continuation_tokens = jieba.lcut(continuation)\n    reference_tokens = jieba.lcut(reference)\n\n    # Calculate the BLEU-4 score\n    bleu_score = evaluate.bleu_score(continuation_tokens, reference_tokens)\n\n    # Optionally include the brevity penalty in the final score calculation\n    if with_penalty:\n        brevity_penalty = evaluate.brevity_penalty(continuation_tokens, reference_tokens)\n        bleu_score = bleu_score * brevity_penalty\n\n    return bleu_score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    # Tokenize input texts\n    continuation_tokens = jieba.lcut(continuation)\n    reference_tokens = jieba.lcut(reference)\n\n    # Calculate BLEU-4 score\n    bleu4_score = evaluate.bleu4(\n        continuation_tokens,\n        reference_tokens\n    )\n\n    # Include brevity penalty in score calculation\n    if with_penalty:\n        bleu4_score *= evaluate.brevity_penalty(\n            continuation_tokens,\n            reference_tokens\n        )\n\n    return bleu4_score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    # Tokenize input texts\n    continuation = jieba.lcut(continuation)\n    reference = jieba.lcut(reference)\n\n    # Compute BLEU-4 score\n    bleu4 = evaluate.bleu(continuation, reference)\n\n    # Compute brevity penalty\n    if with_penalty:\n        penalty = evaluate.brevity_penalty(continuation, reference)\n        bleu4 = penalty * bleu4\n\n    return bleu4\n\n"}
{"namespace": "common.bleu4_score", "completion": "    # Tokenize input texts\n    continuation = jieba.cut(continuation, cut_all=False)\n    reference = jieba.cut(reference, cut_all=False)\n\n    # Calculate BLEU-4 score\n    bleu_score = evaluate.bleu_score(continuation, reference)\n\n    # Optionally include brevity penalty in score calculation\n    if with_penalty:\n        # Calculate brevity penalty\n        penalty = evaluate.brevity_penalty(continuation, reference)\n\n        # Adjust BLEU-4 score for brevity penalty\n        bleu_score = bleu_score * penalty\n\n    return bleu_score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    tokenizer = lambda text: jieba.lcut(text)\n    bleu4 = evaluate.bleu4(\n        continuation = continuation,\n        reference = reference,\n        tokenizer = tokenizer\n    )\n    if with_penalty:\n        penalty = evaluate.brevity_penalty(\n            continuation = continuation,\n            reference = reference,\n            tokenizer = tokenizer\n        )\n        bleu4 = bleu4 * penalty\n    return bleu4\n\n"}
{"namespace": "common.bleu4_score", "completion": "    tokenizer = jieba.cut\n    bleu_score = evaluate.bleu_n(\n        continuation = continuation,\n        reference = reference,\n        n = 4,\n        tokenizer = tokenizer,\n        with_penalty = with_penalty\n    )\n    return bleu_score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    # Tokenize input texts\n    continuation = jieba.lcut(continuation)\n    reference = jieba.lcut(reference)\n\n    # Compute BLEU-4 score\n    bleu4_score = evaluate.bleu_n(reference, continuation, n=4)\n\n    # Optionally adjust BLEU-4 score for brevity penalty\n    if with_penalty:\n        continuation_len = len(continuation)\n        reference_len = len(reference)\n        penalty = reference_len / continuation_len if continuation_len > reference_len else 1\n        bleu4_score *= penalty\n\n    return bleu4_score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    def tokenizer(text):\n        return list(jieba.cut(text))\n\n    score = evaluate.bleu_score(\n        continuation,\n        reference,\n        tokenizer,\n        tokenizer,\n        with_penalty=with_penalty\n    )\n\n    return score\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.where(x < eps, value_at_zero, x))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.where(x <= eps, value_at_zero, x))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.where(x <= eps, value_at_zero, x))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.where(x <= eps, value_at_zero, jnp.sqrt(x))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.where(x <= eps, value_at_zero, jnp.sqrt(x))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.where(x < eps, value_at_zero, x))\n\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.where(x < eps, value_at_zero, x))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.where(x < eps, value_at_zero, x))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.where(x < eps, value_at_zero, x))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.where(x <= eps, value_at_zero, x))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.where(x < eps, value_at_zero, jnp.sqrt(x))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.maximum(x, eps))\n\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.where(x <= eps, value_at_zero, x))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.where(x <= eps, value_at_zero, x))\n\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.where(x < eps, value_at_zero, x))\n\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.where(x <= eps, value_at_zero, x))\n\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.maximum(x, eps))\n\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.maximum(x, eps))\n\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.where(x <= eps, value_at_zero, jnp.sqrt(x))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.sqrt(jnp.where(x <= eps, value_at_zero, x))\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / np.diff(t)\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / np.diff(t)\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / np.diff(t)\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / np.diff(t)\n\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / np.diff(t)\n\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  return w / np.diff(t)\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / np.diff(t)\n\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / math.diff(t, axis=-1)\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / math.diff(t)\n\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  return jnp.diff(w) / jnp.diff(t)\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Weight to probability density function.\n  w = w / np.diff(t)\n  return w\n\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return jnp.diff(w) / jnp.diff(t)\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return jnp.diff(w) / jnp.diff(t)\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Weighted step function.\n  y = jnp.cumsum(w * jnp.diff(t, append=t[-1]))\n  return y\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / math.diff(t)\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  # Check that the input vectors are valid.\n  utils.assert_valid_stepfun(t, w)\n  # Convert the weights into a PDF by dividing by the difference between\n  # consecutive elements in the input vector t.\n  return w / np.diff(t)\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / math.diff(t, axis=-1, prepend=0.0, append=1.0)\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w/np.diff(t)\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  # Check if the input is a vector.\n  if len(t.shape) != 1:\n    raise ValueError(\"The input t must be a vector.\")\n  if len(w.shape) != 1:\n    raise ValueError(\"The input w must be a vector.\")\n\n  # Check if the input vectors are the same length.\n  if t.shape[0] != w.shape[0]:\n    raise ValueError(\"The input vectors t and w must be the same length.\")\n\n  # Check if the input vector is empty.\n  if t.shape[0] == 0:\n    raise ValueError(\"The input vectors t and w must be non-empty.\")\n\n  # Check if the input vector is a step function.\n  if not utils.is_increasing(t):\n    raise ValueError(\"The input vector t must be a step function.\")\n\n  # Check if the input vector is a probability distribution.\n  if not utils.is_probability(w):\n    raise ValueError(\"The input vector w must be a probability distribution.\")\n\n  # Check if the input vector is a step function.\n  if not utils.is_increasing(w):\n    raise ValueError(\"The input vector w must be a step function.\")\n\n  # Check if the input vector is a probability distribution.\n  if not utils.is_probability(w):\n    raise ValueError(\"The input vector w must be a probability distribution.\")\n\n  # Check if the input vector is a probability distribution.\n  if not utils.is_probability(w):\n    raise ValueError(\"The input vector w must be a probability distribution.\")\n\n  # Check if the input vector is a probability distribution.\n  if not utils.is_probability(w):\n    raise ValueError(\"The input vector w must be a probability distribution.\")\n\n  # Check if the input vector is a probability distribution.\n  if not utils.is_probability(w):\n    raise ValueError(\"The input vector w must be a probability distribution.\")\n\n  # Check if the input vector is a probability distribution.\n  if not utils.is_probability(w):\n    raise ValueError(\""}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / np.diff(t)\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for filename in filenames:\n            filepath = os.path.join(dirpath, filename)\n            try:\n                total_size += os.path.getsize(filepath)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for file in filenames:\n            try:\n                file_path = os.path.join(dirpath, file)\n                total_size += os.path.getsize(file_path)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for filename in filenames:\n            filepath = os.path.join(dirpath, filename)\n            try:\n                total_size += os.path.getsize(filepath)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for file in filenames:\n            file_path = os.path.join(dirpath, file)\n            try:\n                total_size += os.path.getsize(file_path)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for file in filenames:\n            try:\n                file_size = os.path.getsize(os.path.join(dirpath, file))\n                total_size += file_size\n            except FileNotFoundError:\n                pass\n    return total_size\n\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for file in filenames:\n            try:\n                total_size += os.path.getsize(os.path.join(dirpath, file))\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n\n    for dirpath, dirnames, filenames in os.walk(path):\n        for filename in filenames:\n            filepath = os.path.join(dirpath, filename)\n            try:\n                total_size += os.path.getsize(filepath)\n            except FileNotFoundError:\n                pass\n\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            try:\n                fp = os.path.join(dirpath, f)\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n\n    for dirpath, dirnames, filenames in os.walk(path):\n        for filename in filenames:\n            filepath = os.path.join(dirpath, filename)\n            try:\n                total_size += os.path.getsize(filepath)\n            except FileNotFoundError:\n                pass\n\n    return total_size\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val = val - torch.floor(val / period + offset) * period\n    return val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val = val - torch.floor(val / period + offset) * period\n    return val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val = val - torch.floor(val / period + offset) * period\n    return val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val = val - torch.floor(val / period + offset) * period\n    return val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val = val - torch.floor(val / period + offset) * period\n    return val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val = val - torch.floor(val / period + offset) * period\n    return val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val = val - torch.floor(val / period + offset) * period\n    return val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, torch.Tensor):\n        limited_val = val - torch.floor(val / period + offset) * period\n    else:\n        limited_val = val - np.floor(val / period + offset) * period\n\n    return limited_val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, torch.Tensor):\n        limited_val = val - torch.floor(val / period + offset) * period\n    else:\n        limited_val = val - np.floor(val / period + offset) * period\n\n    return limited_val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, torch.Tensor):\n        limited_val = val - torch.floor(val / period + offset) * period\n    else:\n        limited_val = val - np.floor(val / period + offset) * period\n\n    return limited_val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val = val - torch.floor(val / period + offset) * period\n    return val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, torch.Tensor):\n        limited_val = val - torch.floor(val / period + offset) * period\n    else:\n        limited_val = val - np.floor(val / period + offset) * period\n    return limited_val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val = val - torch.floor(val / period + offset) * period\n    return val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val = val - torch.floor(val / period + offset) * period\n    return val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val = val - torch.floor(val / period + offset) * period\n    return val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val = val - torch.floor(val / period + offset) * period\n    return val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val = val - torch.floor(val / period + offset) * period\n    return val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if not isinstance(val, torch.Tensor):\n        val = torch.from_numpy(val)\n    val = val - torch.floor(val / period + offset) * period\n    return val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val = val - torch.floor(val / period + offset) * period\n    return val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val = val - torch.floor(val / period + offset) * period\n    return val\n\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent, MicroAgent):\n            return {\n                'dynamic_prompt': agent.dynamic_prompt,\n                'purpose': agent.purpose,\n                'purpose_embedding': agent.purpose_embedding.tolist() if isinstance(agent.purpose_embedding, np.ndarray) else agent.purpose_embedding,\n                'depth': agent.depth,\n                'max_depth': agent.max_depth,\n                'usage_count': agent.usage_count,\n                'id': agent.id,\n                'parent_id': agent.parent_id,\n                'working_agent': agent.working_agent,\n                'is_prime': agent.is_prime,\n                'evolve_count': agent.evolve_count,\n                'number_of_code_executions': agent.number_of_code_executions,\n                'last_input': agent.last_input\n            }\n        else:\n            return None\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent.purpose_embedding, np.ndarray):\n            purpose_embedding = agent.purpose_embedding.tolist()\n        else:\n            purpose_embedding = agent.purpose_embedding\n\n        return {\n            'dynamic_prompt': agent.dynamic_prompt,\n            'purpose': agent.purpose,\n            'purpose_embedding': purpose_embedding,\n            'depth': agent.depth,\n            'max_depth': agent.max_depth,\n            'usage_count': agent.usage_count,\n            'id': agent.id,\n            'parent_id': agent.parent_id,\n            'working_agent': agent.working_agent,\n            'is_prime': agent.is_prime,\n            'evolve_count': agent.evolve_count,\n            'number_of_code_executions': agent.number_of_code_executions,\n            'last_input': agent.last_input\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent, MicroAgent):\n            if isinstance(agent.purpose_embedding, np.ndarray):\n                purpose_embedding = agent.purpose_embedding.tolist()\n            else:\n                purpose_embedding = agent.purpose_embedding\n\n            return {\n                \"dynamic_prompt\": agent.dynamic_prompt,\n                \"purpose\": agent.purpose,\n                \"purpose_embedding\": purpose_embedding,\n                \"depth\": agent.depth,\n                \"max_depth\": agent.max_depth,\n                \"usage_count\": agent.usage_count,\n                \"id\": agent.id,\n                \"parent_id\": agent.parent_id,\n                \"working_agent\": agent.working_agent,\n                \"is_prime\": agent.is_prime,\n                \"evolve_count\": agent.evolve_count,\n                \"number_of_code_executions\": agent.number_of_code_executions,\n                \"last_input\": agent.last_input\n            }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        return {\n            'dynamic_prompt': agent.dynamic_prompt,\n            'purpose': agent.purpose,\n            'purpose_embedding': agent.purpose_embedding.tolist(),\n            'depth': agent.depth,\n            'max_depth': agent.max_depth,\n            'usage_count': agent.usage_count,\n            'id': agent.id,\n            'parent_id': agent.parent_id,\n            'working_agent': agent.working_agent,\n            'is_prime': agent.is_prime,\n            'evolve_count': agent.evolve_count,\n            'number_of_code_executions': agent.number_of_code_executions,\n            'last_input': agent.last_input\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent, MicroAgent):\n            if isinstance(agent.purpose_embedding, np.ndarray):\n                purpose_embedding = agent.purpose_embedding.tolist()\n            else:\n                purpose_embedding = agent.purpose_embedding\n            return {\n                \"dynamic_prompt\": agent.dynamic_prompt,\n                \"purpose\": agent.purpose,\n                \"purpose_embedding\": purpose_embedding,\n                \"depth\": agent.depth,\n                \"max_depth\": agent.max_depth,\n                \"usage_count\": agent.usage_count,\n                \"id\": agent.id,\n                \"parent_id\": agent.parent_id,\n                \"working_agent\": agent.working_agent,\n                \"is_prime\": agent.is_prime,\n                \"evolve_count\": agent.evolve_count,\n                \"number_of_code_executions\": agent.number_of_code_executions,\n                \"last_input\": agent.last_input\n            }\n        else:\n            raise TypeError(\"Argument must be of type MicroAgent.\")\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent.purpose_embedding, np.ndarray):\n            purpose_embedding = agent.purpose_embedding.tolist()\n        else:\n            purpose_embedding = agent.purpose_embedding\n\n        return {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent, MicroAgent):\n            return {\n                'dynamic_prompt': agent.dynamic_prompt,\n                'purpose': agent.purpose,\n                'purpose_embedding': agent.purpose_embedding.tolist(),\n                'depth': agent.depth,\n                'max_depth': agent.max_depth,\n                'usage_count': agent.usage_count,\n                'id': agent.id,\n                'parent_id': agent.parent_id,\n                'working_agent': agent.working_agent,\n                'is_prime': agent.is_prime,\n                'evolve_count': agent.evolve_count,\n                'number_of_code_executions': agent.number_of_code_executions,\n                'last_input': agent.last_input\n            }\n        else:\n            return None\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if type(agent) is not MicroAgent:\n            raise TypeError(\"Input argument is not of type MicroAgent.\")\n\n        if agent.purpose_embedding is not None:\n            purpose_embedding = agent.purpose_embedding.tolist()\n        else:\n            purpose_embedding = None\n\n        return {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if not isinstance(agent, MicroAgent):\n            raise TypeError(\"Cannot serialize a non-MicroAgent object.\")\n\n        if agent.purpose_embedding is not None:\n            purpose_embedding = agent.purpose_embedding.tolist()\n        else:\n            purpose_embedding = None\n\n        return {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent, MicroAgent):\n            return {\n                \"dynamic_prompt\": agent.dynamic_prompt,\n                \"purpose\": agent.purpose,\n                \"purpose_embedding\": agent.purpose_embedding.tolist() if isinstance(agent.purpose_embedding, np.ndarray) else agent.purpose_embedding,\n                \"depth\": agent.depth,\n                \"max_depth\": agent.max_depth,\n                \"usage_count\": agent.usage_count,\n                \"id\": agent.id,\n                \"parent_id\": agent.parent_id,\n                \"working_agent\": agent.working_agent,\n                \"is_prime\": agent.is_prime,\n                \"evolve_count\": agent.evolve_count,\n                \"number_of_code_executions\": agent.number_of_code_executions,\n                \"last_input\": agent.last_input\n            }\n        else:\n            raise TypeError(\"Input is not a MicroAgent instance.\")\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent, MicroAgent):\n            if isinstance(agent.purpose_embedding, np.ndarray):\n                purpose_embedding = agent.purpose_embedding.tolist()\n            else:\n                purpose_embedding = agent.purpose_embedding\n\n            return {\n                \"dynamic_prompt\": agent.dynamic_prompt,\n                \"purpose\": agent.purpose,\n                \"purpose_embedding\": purpose_embedding,\n                \"depth\": agent.depth,\n                \"max_depth\": agent.max_depth,\n                \"usage_count\": agent.usage_count,\n                \"id\": agent.id,\n                \"parent_id\": agent.parent_id,\n                \"working_agent\": agent.working_agent,\n                \"is_prime\": agent.is_prime,\n                \"evolve_count\": agent.evolve_count,\n                \"number_of_code_executions\": agent.number_of_code_executions,\n                \"last_input\": agent.last_input\n            }\n        else:\n            raise TypeError(\"Invalid agent type. Agent must be of type MicroAgent.\")\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent, MicroAgent):\n            if isinstance(agent.purpose_embedding, np.ndarray):\n                purpose_embedding = agent.purpose_embedding.tolist()\n            else:\n                purpose_embedding = agent.purpose_embedding\n            return {\n                'dynamic_prompt': agent.dynamic_prompt,\n                'purpose': agent.purpose,\n                'purpose_embedding': purpose_embedding,\n                'depth': agent.depth,\n                'max_depth': agent.max_depth,\n                'usage_count': agent.usage_count,\n                'id': agent.id,\n                'parent_id': agent.parent_id,\n                'working_agent': agent.working_agent,\n                'is_prime': agent.is_prime,\n                'evolve_count': agent.evolve_count,\n                'number_of_code_executions': agent.number_of_code_executions,\n                'last_input': agent.last_input\n            }\n        else:\n            return {}\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent, MicroAgent):\n            return {\n                \"dynamic_prompt\": agent.dynamic_prompt,\n                \"purpose\": agent.purpose,\n                \"purpose_embedding\": agent.purpose_embedding.tolist() if isinstance(agent.purpose_embedding, np.ndarray) else agent.purpose_embedding,\n                \"depth\": agent.depth,\n                \"max_depth\": agent.max_depth,\n                \"usage_count\": agent.usage_count,\n                \"id\": agent.id,\n                \"parent_id\": agent.parent_id,\n                \"working_agent\": agent.working_agent,\n                \"is_prime\": agent.is_prime,\n                \"evolve_count\": agent.evolve_count,\n                \"number_of_code_executions\": agent.number_of_code_executions,\n                \"last_input\": agent.last_input\n            }\n        else:\n            raise TypeError(\"AgentSerializer.to_dict() expects a MicroAgent object as input.\")\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if type(agent) is not MicroAgent:\n            raise TypeError(\"AgentSerializer.to_dict() can only serialize MicroAgent objects.\")\n\n        agent_dict = {}\n        agent_dict[\"dynamic_prompt\"] = agent.dynamic_prompt\n        agent_dict[\"purpose\"] = agent.purpose\n        agent_dict[\"purpose_embedding\"] = agent.purpose_embedding.tolist() if type(agent.purpose_embedding) is np.ndarray else agent.purpose_embedding\n        agent_dict[\"depth\"] = agent.depth\n        agent_dict[\"max_depth\"] = agent.max_depth\n        agent_dict[\"usage_count\"] = agent.usage_count\n        agent_dict[\"id\"] = agent.id\n        agent_dict[\"parent_id\"] = agent.parent_id\n        agent_dict[\"working_agent\"] = agent.working_agent\n        agent_dict[\"is_prime\"] = agent.is_prime\n        agent_dict[\"evolve_count\"] = agent.evolve_count\n        agent_dict[\"number_of_code_executions\"] = agent.number_of_code_executions\n        agent_dict[\"last_input\"] = agent.last_input\n\n        return agent_dict\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent, MicroAgent):\n            if isinstance(agent.purpose_embedding, np.ndarray):\n                purpose_embedding = agent.purpose_embedding.tolist()\n            else:\n                purpose_embedding = agent.purpose_embedding\n            return {\n                'dynamic_prompt': agent.dynamic_prompt,\n                'purpose': agent.purpose,\n                'purpose_embedding': purpose_embedding,\n                'depth': agent.depth,\n                'max_depth': agent.max_depth,\n                'usage_count': agent.usage_count,\n                'id': agent.id,\n                'parent_id': agent.parent_id,\n                'working_agent': agent.working_agent,\n                'is_prime': agent.is_prime,\n                'evolve_count': agent.evolve_count,\n                'number_of_code_executions': agent.number_of_code_executions,\n                'last_input': agent.last_input\n            }\n        else:\n            raise ValueError('Input object must be a MicroAgent instance.')\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent, MicroAgent):\n            if agent.purpose_embedding is not None:\n                purpose_embedding = agent.purpose_embedding.tolist()\n            else:\n                purpose_embedding = None\n\n            return {\n                'dynamic_prompt': agent.dynamic_prompt,\n                'purpose': agent.purpose,\n                'purpose_embedding': purpose_embedding,\n                'depth': agent.depth,\n                'max_depth': agent.max_depth,\n                'usage_count': agent.usage_count,\n                'id': agent.id,\n                'parent_id': agent.parent_id,\n                'working_agent': agent.working_agent,\n                'is_prime': agent.is_prime,\n                'evolve_count': agent.evolve_count,\n                'number_of_code_executions': agent.number_of_code_executions,\n                'last_input': agent.last_input\n            }\n        else:\n            raise ValueError('Input must be a MicroAgent instance.')\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent, MicroAgent):\n            return {\n                \"dynamic_prompt\": agent.dynamic_prompt,\n                \"purpose\": agent.purpose,\n                \"purpose_embedding\": agent.purpose_embedding.tolist(),\n                \"depth\": agent.depth,\n                \"max_depth\": agent.max_depth,\n                \"usage_count\": agent.usage_count,\n                \"id\": agent.id,\n                \"parent_id\": agent.parent_id,\n                \"working_agent\": agent.working_agent,\n                \"is_prime\": agent.is_prime,\n                \"evolve_count\": agent.evolve_count,\n                \"number_of_code_executions\": agent.number_of_code_executions,\n                \"last_input\": agent.last_input\n            }\n        else:\n            raise TypeError(\"AgentSerializer.to_dict() takes in a MicroAgent object.\")\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent, MicroAgent):\n            return {\n                \"dynamic_prompt\": agent.dynamic_prompt,\n                \"purpose\": agent.purpose,\n                \"purpose_embedding\": agent.purpose_embedding.tolist() if isinstance(agent.purpose_embedding, np.ndarray) else agent.purpose_embedding,\n                \"depth\": agent.depth,\n                \"max_depth\": agent.max_depth,\n                \"usage_count\": agent.usage_count,\n                \"id\": agent.id,\n                \"parent_id\": agent.parent_id,\n                \"working_agent\": agent.working_agent,\n                \"is_prime\": agent.is_prime,\n                \"evolve_count\": agent.evolve_count,\n                \"number_of_code_executions\": agent.number_of_code_executions,\n                \"last_input\": agent.last_input\n            }\n        else:\n            raise TypeError(\"AgentSerializer.to_dict() takes a MicroAgent instance as input.\")\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent, MicroAgent):\n            return {\n                \"dynamic_prompt\": agent.dynamic_prompt,\n                \"purpose\": agent.purpose,\n                \"purpose_embedding\": agent.purpose_embedding.tolist(),\n                \"depth\": agent.depth,\n                \"max_depth\": agent.max_depth,\n                \"usage_count\": agent.usage_count,\n                \"id\": agent.id,\n                \"parent_id\": agent.parent_id,\n                \"working_agent\": agent.working_agent,\n                \"is_prime\": agent.is_prime,\n                \"evolve_count\": agent.evolve_count,\n                \"number_of_code_executions\": agent.number_of_code_executions,\n                \"last_input\": agent.last_input\n            }\n        else:\n            return None\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        # Convert purpose embedding to list if necessary\n        if type(agent.purpose_embedding) is np.ndarray:\n            agent.purpose_embedding = agent.purpose_embedding.tolist()\n\n        # Return dictionary representation\n        return {\n            'dynamic_prompt': agent.dynamic_prompt,\n            'purpose': agent.purpose,\n            'purpose_embedding': agent.purpose_embedding,\n            'depth': agent.depth,\n            'max_depth': agent.max_depth,\n            'usage_count': agent.usage_count,\n            'id': agent.id,\n            'parent_id': agent.parent_id,\n            'working_agent': agent.working_agent,\n            'is_prime': agent.is_prime,\n            'evolve_count': agent.evolve_count,\n            'number_of_code_executions': agent.number_of_code_executions,\n            'last_input': agent.last_input\n        }\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # TODO: Implement this method\n\n    raise NotImplementedError\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # We first check to make sure that the lists 'items' and 'weights' are of equal length.\n    if len(items) != len(weights):\n        raise ValueError(\"The lists 'items' and 'weights' must be of equal length.\")\n\n    # We then check to make sure that all weights are positive.\n    if any(weight < 1 for weight in weights):\n        raise ValueError(\"All weights must be positive.\")\n\n    # We then check to make sure that the number of bins is positive.\n    if num_bins < 1:\n        raise ValueError(\"The number of bins must be a positive integer.\")\n\n    # We then check to make sure that the number of bins is not greater than the number of items.\n    if num_bins > len(items):\n        raise ValueError(\"The number of bins cannot be greater than the number of items.\")\n\n    # We then check to make sure that the number of bins is not greater than the total number of weights.\n    if num_bins > sum(weights):\n        raise ValueError(\"The number of bins cannot be greater than the total number of weights.\")\n\n    # We then check to make sure that the number of bins is not greater than the number of unique weights.\n    if num_bins > len(set(weights)):\n        raise ValueError(\"The number of bins cannot be greater than the number of unique weights.\")\n\n    # We then check to make sure that the number of bins is not greater than the number of items with the largest weight.\n    if num_bins > weights.count(max(weights)):\n        raise ValueError(\"The number of bins cannot be greater than the number of items with the largest weight.\")\n\n    # We then check to make sure that the number of bins is not greater than the number of items with the smallest weight.\n    if num_bins > weights.count(min(weights)):\n        raise ValueError(\"The number of bins cannot be greater than the number of items with the smallest weight.\")\n\n    # We then check to make sure that the number of bins is not greater than the number of items with the second largest weight."}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # We first check that the lists 'items' and 'weights' have the same length\n    if len(items) != len(weights):\n        raise ValueError('The lists \\'items\\' and \\'weights\\' must have the same length.')\n\n    # We then check that the number of bins is positive\n    if num_bins <= 0:\n        raise ValueError('The number of bins must be positive.')\n\n    # We then check that all the weights are positive\n    if any(weight <= 0 for weight in weights):\n        raise ValueError('All the weights must be positive.')\n\n    # We then check that the number of items is greater than or equal to the number of bins\n    if len(items) < num_bins:\n        raise ValueError('The number of items must be greater than or equal to the number of bins.')\n\n    # We then check that the number of bins is greater than or equal to the number of items\n    if num_bins < len(items):\n        raise ValueError('The number of bins must be greater than or equal to the number of items.')\n\n    # We then check that the number of bins is greater than or equal to the number of unique weights\n    if len(set(weights)) < num_bins:\n        raise ValueError('The number of bins must be greater than or equal to the number of unique weights.')\n\n    # We then check that the total weight of all the items is greater than or equal to the number of bins\n    if sum(weights) < num_bins:\n        raise ValueError('The total weight of the items must be greater than or equal to the number of bins.')\n\n    # We then check that the total weight of all the items is greater than or equal to the number of unique weights\n    if sum(weights) < len(set(weights)):\n        raise ValueError('The total weight of the items must be greater than or equal to the number of unique weights.')\n\n    # We then check that the total weight of all the items is greater than or equal to the number of bins\n    if sum(weights) < num_bins"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    if len(items) != len(weights):\n        raise ValueError('The lengths of the items and weights lists must be the same.')\n\n    if num_bins < 1:\n        raise ValueError('The number of bins must be greater than or equal to 1.')\n\n    if any(weight < 1 for weight in weights):\n        raise ValueError('All weights must be positive.')\n\n    # Create a dictionary that maps each item to its weight.\n    item_to_weight: Dict[Any, int] = dict(zip(items, weights))\n\n    # Create a dictionary that maps each bin index to its total weight.\n    bin_to_total_weight: Dict[int, int] = defaultdict(int)\n\n    # Create a dictionary that maps each bin index to a list of items that have been placed in that bin.\n    bin_to_items: Dict[int, List[Any]] = defaultdict(list)\n\n    # Sort the items by weight in descending order.\n    sorted_items: List[Any] = sorted(items, key=lambda item: item_to_weight[item], reverse=True)\n\n    # Iteratively place the items into the bins.\n    for item in sorted_items:\n\n        # Find the bin with the lowest total weight.\n        bin_index: int = min(bin_to_total_weight, key=bin_to_total_weight.get)\n\n        # Place the item in the bin.\n        bin_to_items[bin_index].append(item)\n\n        # Update the total weight of the bin.\n        bin_to_total_weight[bin_index] += item_to_weight[item]\n\n    return bin_to_items, bin_to_total_weight\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Create a dictionary that maps each item to its associated weight.\n    item_to_weight: Dict[Any, int] = {item: weight for item, weight in zip(items, weights)}\n\n    # Create a dictionary that maps each bin index to an empty list.\n    bin_to_items: Dict[int, List[Any]] = {bin_index: [] for bin_index in range(num_bins)}\n\n    # Create a dictionary that maps each bin index to the total weight of the items in that bin.\n    bin_to_total_weight: Dict[int, int] = {bin_index: 0 for bin_index in range(num_bins)}\n\n    # Sort the items by their associated weight in descending order.\n    sorted_items: List[Any] = [item for item, _ in sorted(item_to_weight.items(), key=lambda item_weight: item_weight[1], reverse=True)]\n\n    # Iterate through the sorted items.\n    for item in sorted_items:\n\n        # Find the bin with the lowest total weight.\n        bin_index: int = min(bin_to_total_weight, key=bin_to_total_weight.get)\n\n        # Place the item in that bin.\n        bin_to_items[bin_index].append(item)\n\n        # Update the total weight of that bin.\n        bin_to_total_weight[bin_index] += item_to_weight[item]\n\n    return bin_to_items, bin_to_total_weight\n\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # We first check to make sure that the lists 'items' and 'weights' are of the same length.\n    if len(items) != len(weights):\n        raise ValueError('The lists \\'items\\' and \\'weights\\' must be of the same length.')\n\n    # We then check to make sure that the number of bins is positive.\n    if num_bins <= 0:\n        raise ValueError('The number of bins must be a positive integer.')\n\n    # We then check to make sure that all weights are positive.\n    if any(weight < 0 for weight in weights):\n        raise ValueError('All weights must be positive.')\n\n    # We then check to make sure that the number of items is greater than or equal to the number of bins.\n    if len(items) < num_bins:\n        raise ValueError('The number of bins cannot be greater than the number of items.')\n\n    # We then check to make sure that the number of items is greater than or equal to the number of bins.\n    if len(items) < num_bins:\n        raise ValueError('The number of bins cannot be greater than the number of items.')\n\n    # We then check to make sure that all weights are positive.\n    if any(weight < 0 for weight in weights):\n        raise ValueError('All weights must be positive.')\n\n    # We then sort the items by weight in descending order.\n    sorted_items = [item for item, weight in sorted(zip(items, weights), key=lambda x: x[1], reverse=True)]\n\n    # We then sort the weights in descending order.\n    sorted_weights = sorted(weights, reverse=True)\n\n    # We then create a dictionary that maps each item to its associated weight.\n    item_to_weight: Dict[Any, int] = {item: weight for item, weight in zip(items, weights)}\n\n    # We then create a dictionary that maps each bin index to an empty list.\n    bin_to_items: Dict[int, List[Any]] = defaultdict(list)\n\n    # We then create"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Checking if the lists 'items' and 'weights' have the same length\n    if len(items) != len(weights):\n        raise ValueError(\"The lists 'items' and 'weights' must have the same length\")\n\n    # Checking if the number of bins is positive\n    if num_bins <= 0:\n        raise ValueError(\"The number of bins must be positive\")\n\n    # Checking if the weights are positive\n    if any(weight <= 0 for weight in weights):\n        raise ValueError(\"The weights must all be positive\")\n\n    # Sorting the items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Initializing the dictionary that maps each bin index to a list of items that have been placed in that bin\n    bins: Dict[int, List[Any]] = defaultdict(list)\n\n    # Initializing the dictionary that maps each bin index to the total weight of the items in that bin\n    bin_weights: Dict[int, int] = defaultdict(int)\n\n    # Iterating over the sorted items\n    for item, weight in sorted_items:\n\n        # Finding the bin with the lowest total weight\n        min_weight = min(bin_weights.values())\n        min_weight_bin_index = [index for index, value in bin_weights.items() if value == min_weight][0]\n\n        # Placing the item in the bin with the lowest total weight\n        bins[min_weight_bin_index].append(item)\n        bin_weights[min_weight_bin_index] += weight\n\n    # Returning the dictionary that maps each bin index to a list of items that have been placed in that bin and the dictionary that maps each bin index to the total weight of the items in that bin\n    return bins, bin_weights\n\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # We check if the input lists have the same length.\n    if len(items) != len(weights):\n        raise ValueError('The lengths of the two input lists are not the same.')\n\n    # We check if the number of bins is positive.\n    if num_bins <= 0:\n        raise ValueError('The number of bins must be a positive integer.')\n\n    # We check if the weights are all positive.\n    if any(weight <= 0 for weight in weights):\n        raise ValueError('The weights must all be positive.')\n\n    # We check if the total weight is greater than the number of bins.\n    if sum(weights) > num_bins:\n        raise ValueError('The total weight of the items must be less than or equal to the number of bins.')\n\n    # We sort the items by weight in descending order.\n    sorted_items_by_weight: List[Tuple[int, Any]] = sorted(zip(weights, items), key=lambda x: x[0], reverse=True)\n\n    # We initialize the dictionary that maps each bin index to the total weight of the items in that bin.\n    bin_to_total_weight: Dict[int, int] = defaultdict(int)\n\n    # We initialize the dictionary that maps each bin index to a list of items that have been placed in that bin.\n    bin_to_items: Dict[int, List[Any]] = defaultdict(list)\n\n    # We iterate through the sorted items by weight.\n    for weight, item in sorted_items_by_weight:\n\n        # We find the bin with the lowest total weight.\n        bin_with_lowest_weight: int = min(bin_to_total_weight, key=bin_to_total_weight.get)\n\n        # We add the item to the bin with the lowest total weight.\n        bin_to_items[bin_with_lowest_weight].append(item)\n\n        # We update the total weight of the bin with the lowest total weight.\n        bin_to_total_weight[bin_with_lowest_weight] += weight"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Input validity checking\n    if not isinstance(items, list):\n        raise TypeError('Input argument \\'items\\' must be a list.')\n    if not isinstance(weights, list):\n        raise TypeError('Input argument \\'weights\\' must be a list.')\n    if not isinstance(num_bins, int):\n        raise TypeError('Input argument \\'num_bins\\' must be an integer.')\n    if len(items) != len(weights):\n        raise ValueError('The number of items and weights must be the same.')\n    if num_bins <= 0:\n        raise ValueError('The number of bins must be positive.')\n    for weight in weights:\n        if not isinstance(weight, int):\n            raise TypeError('All weights must be integers.')\n        if weight <= 0:\n            raise ValueError('All weights must be positive.')\n    if num_bins > len(items):\n        raise ValueError('The number of bins cannot be greater than the number of items.')\n\n    # Initialize the output\n    bin_to_items: Dict[int, List[Any]] = defaultdict(list)\n    bin_to_weight: Dict[int, int] = defaultdict(int)\n\n    # Sort the items by weight in descending order\n    items_and_weights: List[Tuple[Any, int]] = list(zip(items, weights))\n    items_and_weights.sort(key=lambda x: x[1], reverse=True)\n\n    # Distribute the items into bins greedily\n    for item, weight in items_and_weights:\n        current_min_weight: int = min(bin_to_weight.values())\n        current_min_weight_bin: int = list(bin_to_weight.keys())[list(bin_to_weight.values()).index(current_min_weight)]\n        bin_to_items[current_min_weight_bin].append(item)\n        bin_to_weight[current_min_weight_bin] += weight\n\n    return bin_to_items, bin_to_weight"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Create a copy of the list of items.\n    items_copy: List[Any] = items.copy()\n\n    # Create a copy of the list of weights.\n    weights_copy: List[int] = weights.copy()\n\n    # Create a dictionary that maps each bin index to a list of items that have been placed in that bin.\n    items_per_bin: Dict[int, List[Any]] = defaultdict(list)\n\n    # Create a dictionary that maps each bin index to the total weight of the items in that bin.\n    total_weights_per_bin: Dict[int, int] = defaultdict(int)\n\n    # If the number of bins is less than or equal to zero, then raise a ValueError.\n    if num_bins <= 0:\n        raise ValueError(\"The number of bins cannot be less than or equal to zero.\")\n\n    # If the number of bins is greater than the number of items, then raise a ValueError.\n    if num_bins > len(items):\n        raise ValueError(\"The number of bins cannot be greater than the number of items.\")\n\n    # If the number of bins is greater than the number of weights, then raise a ValueError.\n    if num_bins > len(weights):\n        raise ValueError(\"The number of bins cannot be greater than the number of weights.\")\n\n    # If the number of items is not equal to the number of weights, then raise a ValueError.\n    if len(items) != len(weights):\n        raise ValueError(\"The number of items must be equal to the number of weights.\")\n\n    # If the number of items is zero, then return the two dictionaries.\n    if len(items) == 0:\n        return items_per_bin, total_weights_per_bin\n\n    # Sort the items by their weight in descending order.\n    items_copy.sort(key = lambda item: weights_copy[items.index(item)], reverse = True)\n\n    # For each item in the sorted list of items...\n    for item in items_copy:\n\n        # For each bin index...\n        for"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Check if the lengths of the two lists are equal\n    if len(items) != len(weights):\n        raise ValueError(\"The lengths of the two lists must be equal.\")\n\n    # Check if the number of bins is positive\n    if num_bins <= 0:\n        raise ValueError(\"The number of bins must be positive.\")\n\n    # Check if the total weight is positive\n    if sum(weights) <= 0:\n        raise ValueError(\"The total weight must be positive.\")\n\n    # Check if the weights are all positive\n    if any(weight <= 0 for weight in weights):\n        raise ValueError(\"All weights must be positive.\")\n\n    # Check if the number of bins is greater than the number of items\n    if num_bins < len(items):\n        raise ValueError(\"The number of bins cannot be less than the number of items.\")\n\n    # Sort the items by weight in descending order\n    items = [item for _, item in sorted(zip(weights, items), reverse=True)]\n    weights.sort(reverse=True)\n\n    # Initialize the dictionary that maps each bin index to a list of items that have been placed in that bin\n    bins: Dict[int, List[Any]] = defaultdict(list)\n\n    # Initialize the dictionary that maps each bin index to the total weight of the items in that bin\n    bin_weights: Dict[int, int] = defaultdict(int)\n\n    # Place each item into the bin with the current lowest total weight\n    for i in range(len(items)):\n        current_min_weight = min(bin_weights.values())\n        current_min_weight_bin_index = [key for key, value in bin_weights.items() if value == current_min_weight][0]\n        bins[current_min_weight_bin_index].append(items[i])\n        bin_weights[current_min_weight_bin_index] += weights[i]\n\n    # Return the dictionary that maps each bin index to a list of items that have been placed in that bin and the dictionary that maps each bin index to the total weight of the items"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    if len(items) != len(weights):\n        raise ValueError('The lengths of the \\'items\\' and \\'weights\\' lists must be the same.')\n\n    if num_bins <= 0:\n        raise ValueError('The number of bins must be greater than zero.')\n\n    for weight in weights:\n        if weight <= 0:\n            raise ValueError('Each weight must be positive.')\n\n    # Sort the items and weights by weight in descending order.\n    sorted_items: List[Any] = [item for item, _ in sorted(zip(items, weights), key=lambda x: x[1], reverse=True)]\n    sorted_weights: List[int] = [weight for _, weight in sorted(zip(items, weights), key=lambda x: x[1], reverse=True)]\n\n    # Initialize the dictionary that will map each bin index to a list of items that have been placed in that bin.\n    items_per_bin: Dict[int, List[Any]] = defaultdict(list)\n\n    # Initialize the dictionary that will map each bin index to the total weight of the items in that bin.\n    bin_weights: Dict[int, int] = {}\n\n    # Place each item into the bin with the current lowest total weight.\n    for item, weight in zip(sorted_items, sorted_weights):\n        lowest_weight_bin_index: int = min(bin_weights, key=bin_weights.get) if len(bin_weights) > 0 else 0\n        items_per_bin[lowest_weight_bin_index].append(item)\n        bin_weights[lowest_weight_bin_index] = bin_weights[lowest_weight_bin_index] + weight if lowest_weight_bin_index in bin_weights else weight\n\n    return items_per_bin, bin_weights\n\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # TODO: Write your code here.\n    # The first dictionary maps each bin index to a list of items that have been placed in that bin.\n    # The second dictionary maps each bin index to the total weight of the items in that bin.\n    packed_items: Dict[int, List[Any]] = defaultdict(list)\n    packed_weights: Dict[int, int] = defaultdict(int)\n    # sort the items and weights in descending order\n    sorted_indices = sorted(range(len(items)), key=lambda i: weights[i], reverse=True)\n    sorted_items = [items[i] for i in sorted_indices]\n    sorted_weights = [weights[i] for i in sorted_indices]\n    # greedily place the items into bins\n    for item, weight in zip(sorted_items, sorted_weights):\n        # find the bin with the lowest weight\n        min_weight = min(packed_weights.values())\n        min_weight_bins = [i for i, v in packed_weights.items() if v == min_weight]\n        # if there are multiple bins with the same minimum weight, choose the one with the lowest index\n        bin_index = min_weight_bins[0]\n        packed_items[bin_index].append(item)\n        packed_weights[bin_index] += weight\n    return packed_items, packed_weights\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # We validate the input arguments.\n    if len(items) != len(weights):\n        raise ValueError('The length of the \\'items\\' list and the \\'weights\\' list must be the same.')\n    if num_bins <= 0:\n        raise ValueError('The number of bins must be a positive integer.')\n\n    # We sort the items by weight in descending order.\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # We initialize the bins as empty lists.\n    bins: Dict[int, List[Any]] = defaultdict(list)\n\n    # We initialize the bin weights as empty dictionaries.\n    bin_weights: Dict[int, int] = defaultdict(int)\n\n    # We iterate through the sorted items and place each item in the bin with the current lowest total weight.\n    for item, weight in sorted_items:\n        # We find the bin index of the bin with the current lowest total weight.\n        bin_index = min(bin_weights, key=bin_weights.get)\n        # We add the item to the bin.\n        bins[bin_index].append(item)\n        # We update the bin weight.\n        bin_weights[bin_index] += weight\n\n    # We return the bins and the bin weights.\n    return bins, bin_weights\n\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # We first check to make sure that the number of bins is positive and that the lengths of the 'items' and 'weights' lists are equal.\n    if num_bins <= 0 or len(items) != len(weights):\n        raise ValueError('The number of bins must be positive and the lengths of the \\'items\\' and \\'weights\\' lists must be equal.')\n\n    # We then check to make sure that each weight in the 'weights' list is positive.\n    if any(weight <= 0 for weight in weights):\n        raise ValueError('Each weight in the \\'weights\\' list must be positive.')\n\n    # We then sort the items by weight in descending order.\n    sorted_items_by_weight = sorted(range(len(weights)), key=lambda i: weights[i], reverse=True)\n\n    # We then create a dictionary that maps each item to its index in the 'items' list.\n    item_to_index: Dict[Any, int] = {}\n    for index, item in enumerate(items):\n        item_to_index[item] = index\n\n    # We then create a dictionary that maps each bin index to a list of items that have been placed in that bin.\n    bin_to_items: Dict[int, List[Any]] = defaultdict(list)\n\n    # We then create a dictionary that maps each bin index to the total weight of the items in that bin.\n    bin_to_weight: Dict[int, int] = {}\n\n    # We then place each item in the bin with the current lowest total weight.\n    for item in sorted_items_by_weight:\n\n        # We first find the bin with the current lowest total weight.\n        current_lowest_weight = min(bin_to_weight.values()) if bin_to_weight else 0\n        current_lowest_weight_bins = [bin_index for bin_index, bin_weight in bin_to_weight.items() if bin_weight == current_lowest_weight]\n        current_lowest_weight_bin = min(current_lowest_weight_bins) if current_"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Exception handling START\n\n    if not isinstance(items, list) or not all(isinstance(item, (int, float, str, bool, tuple, list, dict, set, bytes, bytearray)) for item in items):\n        raise TypeError('The parameter \\'items\\' must be a list containing only items of type int, float, str, bool, tuple, list, dict, set, bytes or bytearray.')\n\n    if not isinstance(weights, list) or not all(isinstance(weight, int) for weight in weights):\n        raise TypeError('The parameter \\'weights\\' must be a list containing only items of type int.')\n\n    if not isinstance(num_bins, int) or num_bins <= 0:\n        raise ValueError('The parameter \\'num_bins\\' must be an integer greater than zero.')\n\n    if len(items) != len(weights):\n        raise ValueError('The parameter \\'items\\' and \\'weights\\' must be lists of equal length.')\n\n    # Exception handling END\n\n    # Create a dictionary that maps each item to its associated weight.\n    item_to_weight_map: Dict[Any, int] = dict()\n\n    for i in range(len(items)):\n        item_to_weight_map[items[i]] = weights[i]\n\n    # Create a dictionary that maps each bin to the total weight of the items in that bin.\n    bin_to_weight_map: Dict[int, int] = dict()\n\n    # Create a dictionary that maps each bin to the list of items that have been placed in that bin.\n    bin_to_items_map: Dict[int, List[Any]] = dict()\n\n    # Sort the items by their weight in descending order.\n    items.sort(key = lambda item: item_to_weight_map[item], reverse = True)\n\n    # Place each item into the bin with the current lowest total weight.\n    for item in items:\n\n        # Find the bin with the current lowest total weight.\n        bin_index: int = min(bin_to_weight_map, key = lambda"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # A list of lists, where each list represents the items placed in a particular bin.\n    bins: List[List[Any]] = [[] for _ in range(num_bins)]\n\n    # A dictionary mapping each bin index to the total weight of the items placed in that bin.\n    bin_weights: Dict[int, int] = defaultdict(int)\n\n    # A list of tuples, where each tuple is of the form (weight, item_index).\n    items_and_weights: List[Tuple[int, int]] = list(zip(weights, range(len(items))))\n\n    # Sort the items and weights in descending order by weight.\n    items_and_weights.sort(key=lambda x: x[0], reverse=True)\n\n    # Iteratively place the items into the bins greedily.\n    for weight, item_index in items_and_weights:\n\n        # Find the bin with the lowest weight.\n        min_bin_index: int = bin_weights.popitem(last=False)[0]\n\n        # Place the item into the bin.\n        bins[min_bin_index].append(items[item_index])\n\n        # Update the total weight of the bin.\n        bin_weights[min_bin_index] += weight\n\n    return (bin_weights, bins)\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # TODO: Write your own implementation of the greedy algorithm for packing items into bins.\n\n    # The dictionary that maps each bin index to the total weight of the items in that bin.\n    bin_weights: Dict[int, int] = defaultdict(int)\n\n    # The dictionary that maps each bin index to a list of items that have been placed in that bin.\n    bin_items: Dict[int, List[Any]] = defaultdict(list)\n\n    # The number of items in the input list.\n    num_items: int = len(items)\n\n    # The number of bins in the input list.\n    num_bins: int = num_bins\n\n    # The list of items to be distributed into bins.\n    items: List[Any] = items\n\n    # The list of weights associated with the items in the 'items' list.\n    weights: List[int] = weights\n\n    # The total weight of the items in the 'items' list.\n    total_weight: int = sum(weights)\n\n    # The list of items sorted in descending order by weight.\n    sorted_items: List[Any] = [item for _, item in sorted(zip(weights, items), reverse=True)]\n\n    # The list of weights associated with the items in the 'sorted_items' list.\n    sorted_weights: List[int] = [weight for weight in sorted(weights, reverse=True)]\n\n    # The number of items that can be placed in each bin.\n    bin_size: int = num_items // num_bins\n\n    # The number of items that cannot be placed in each bin.\n    bin_remainder: int = num_items % num_bins\n\n    # The index of the bin that is currently being considered.\n    bin_index: int = 0\n\n    # The index of the item that is currently being considered.\n    item_index: int = 0\n\n    # The current total weight of the items in the bin that is currently being considered.\n    current_bin_weight: int = 0\n\n    # The current list of items in the bin that"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # first, check if the lists 'items' and 'weights' have the same length\n    if len(items) != len(weights):\n        raise ValueError(\"The lists 'items' and 'weights' must have the same length.\")\n\n    # next, check if the number of bins is positive\n    if num_bins <= 0:\n        raise ValueError(\"The number of bins must be a positive integer.\")\n\n    # next, check if the weights are positive\n    if any(weight <= 0 for weight in weights):\n        raise ValueError(\"All weights must be positive.\")\n\n    # next, sort the items by weight in descending order\n    sorted_items = [item for _, item in sorted(zip(weights, items), reverse=True)]\n\n    # next, sort the weights in descending order\n    sorted_weights = sorted(weights, reverse=True)\n\n    # next, initialize a dictionary to map each bin index to the total weight of the items in that bin\n    bins: Dict[int, int] = defaultdict(int)\n\n    # next, initialize a dictionary to map each bin index to a list of items that have been placed in that bin\n    items_in_bin: Dict[int, List[Any]] = defaultdict(list)\n\n    # next, distribute the items into the bins\n    for index, (item, weight) in enumerate(zip(sorted_items, sorted_weights)):\n\n        # find the bin with the lowest total weight\n        bin_index = min(bins, key=bins.get)\n\n        # place the item into the bin\n        items_in_bin[bin_index].append(item)\n\n        # update the total weight of the items in the bin\n        bins[bin_index] += weight\n\n        # increment the bin index\n        index += 1\n\n        # if the bin index is now greater than or equal to the number of bins, then break out of the loop\n        if index >= num_bins:\n            break\n\n    # return the dictionaries that map each bin index to a list of items that have been placed in that bin and to the total"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # First, check if the input lists are empty\n    if len(items) == 0 or len(weights) == 0:\n        raise ValueError('The lists of items and weights cannot be empty.')\n    # Then, check if the number of bins is less than or equal to zero\n    if num_bins <= 0:\n        raise ValueError('The number of bins must be a positive integer.')\n    # Then, check if the number of bins is greater than the number of items\n    if num_bins < len(items):\n        raise ValueError('The number of bins cannot be less than the number of items.')\n    # Then, check if the number of bins is greater than the number of items\n    if len(items) != len(weights):\n        raise ValueError('The lists of items and weights must have the same length.')\n    # Then, check if the weights are not all positive\n    if any(weight <= 0 for weight in weights):\n        raise ValueError('The weights must all be positive.')\n\n    # Create a dictionary that maps each item to its corresponding weight\n    item_to_weight: Dict[Any, int] = dict(zip(items, weights))\n\n    # Create a dictionary that maps each bin to its current total weight\n    bin_to_weight: Dict[int, int] = defaultdict(int)\n\n    # Create a dictionary that maps each bin to a list of items that have been placed in that bin\n    bin_to_items: Dict[int, List[Any]] = defaultdict(list)\n\n    # Sort the items by their associated weight in descending order\n    sorted_items: List[Any] = sorted(items, key=lambda item: item_to_weight[item], reverse=True)\n\n    # Iterate through each item in the list of items\n    for item in sorted_items:\n        # Find the bin with the current lowest total weight\n        current_min_weight: int = min(bin_to_weight.values())\n        current_min_weight_bin: int = min(bin_to_weight, key=bin_to_weight.get)\n        # Place"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        return hashlib.sha256(json.dumps(data).encode(\"utf-8\")).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = {\n            \"func_name\": func_name,\n            \"args\": args,\n            \"kwargs\": kwargs,\n        }\n        data_json = json.dumps(data, sort_keys=True)\n        return hashlib.sha256(data_json.encode(\"utf-8\")).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        data_json = json.dumps(data, sort_keys=True)\n        return hashlib.sha256(data_json.encode()).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = {\n            \"func_name\": func_name,\n            \"args\": args,\n            \"kwargs\": kwargs\n        }\n        data_json = json.dumps(data, sort_keys=True, default=str)\n        return hashlib.sha256(data_json.encode()).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = {\n            \"func_name\": func_name,\n            \"args\": args,\n            \"kwargs\": kwargs\n        }\n\n        return hashlib.sha256(json.dumps(data).encode(\"utf-8\")).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        data_str = json.dumps(data, sort_keys=True)\n        data_bytes = data_str.encode(\"utf-8\")\n        return hashlib.sha256(data_bytes).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        hash_input = json.dumps(\n            {\"func_name\": func_name, \"args\": args, \"kwargs\": kwargs},\n            sort_keys=True,\n        )\n\n        return hashlib.sha256(hash_input.encode(\"utf-8\")).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        input_data = {\n            \"func_name\": func_name,\n            \"args\": args,\n            \"kwargs\": kwargs\n        }\n        input_data_json = json.dumps(input_data, sort_keys=True)\n        input_data_hash = hashlib.sha256(input_data_json.encode()).hexdigest()\n        return input_data_hash\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        # Hash the function name\n        hash_obj = hashlib.sha256()\n        hash_obj.update(func_name.encode(\"utf-8\"))\n\n        # Hash the positional arguments\n        for arg in args:\n            hash_obj.update(arg.encode(\"utf-8\"))\n\n        # Hash the keyword arguments\n        for key, value in kwargs.items():\n            hash_obj.update(key.encode(\"utf-8\"))\n            hash_obj.update(value.encode(\"utf-8\"))\n\n        return hash_obj.hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = [func_name, args, kwargs]\n        data_json = json.dumps(data, sort_keys=True)\n        data_hash = hashlib.sha256(data_json.encode('utf-8')).hexdigest()\n\n        return data_hash\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        # Convert all arguments to a dictionary\n        data = {\n            \"func_name\": func_name,\n            \"args\": args,\n            \"kwargs\": kwargs\n        }\n\n        # Convert the dictionary to a string\n        data_string = json.dumps(data, sort_keys=True)\n\n        # Compute the hash\n        return hashlib.sha256(data_string.encode(\"utf-8\")).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        # Serialize the input arguments to a JSON string\n        json_data = json.dumps({\n            \"func_name\": func_name,\n            \"args\": args,\n            \"kwargs\": kwargs\n        })\n\n        # Compute the SHA-256 hash of the serialized input data\n        hash_object = hashlib.sha256(json_data.encode())\n        return hash_object.hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        # Concatenate the function name, positional arguments, and keyword arguments into a string\n        data = func_name + str(args) + str(kwargs)\n\n        # Compute the SHA-256 hash of the data\n        hash = hashlib.sha256(data.encode(\"utf-8\")).hexdigest()\n\n        return hash\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        # Create a list of the input data.\n        input_data = [func_name]\n        input_data.extend(args)\n        input_data.extend([f\"{k}={v}\" for k, v in kwargs.items()])\n\n        # Convert the input data to JSON and encode it as UTF-8.\n        json_data = json.dumps(input_data).encode(\"utf-8\")\n\n        # Return the SHA-256 hash of the JSON data.\n        return hashlib.sha256(json_data).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        # Hash the function name and its arguments\n        hash_input = (func_name, args, kwargs)\n        hash_input_str = json.dumps(hash_input, sort_keys=True, separators=(',', ':'))\n        hash_input_bytes = hash_input_str.encode()\n        hash_input_hash = hashlib.sha256(hash_input_bytes)\n\n        return hash_input_hash.hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        # Create a string of all the input data.\n        data = [func_name] + [str(arg) for arg in args] + [str(arg) for arg in kwargs.items()]\n        data_str = json.dumps(data)\n\n        # Compute the SHA-256 hash of the data.\n        sha256 = hashlib.sha256()\n        sha256.update(data_str.encode('utf-8'))\n        return sha256.hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        # Create a string representation of the function name, its arguments, and keyword arguments.\n        data = [str(func_name)]\n        data.extend([str(arg) for arg in args])\n        data.extend([str(key) + \":\" + str(value) for key, value in kwargs.items()])\n\n        # Hash the string representation of the function name, its arguments, and keyword arguments.\n        hash_object = hashlib.sha256(\"\".join(data).encode())\n        return hash_object.hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        # Convert the arguments to a dictionary\n        arg_dict = dict(\n            func_name=func_name,\n            args=args,\n            kwargs=kwargs\n        )\n\n        # Serialize the dictionary to JSON\n        json_string = json.dumps(arg_dict, sort_keys=True)\n\n        # Compute the hash\n        return hashlib.sha256(json_string.encode()).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        # Create a list of the positional arguments of the function.\n        positional_arguments = list(args)\n\n        # Create a list of the keyword arguments of the function.\n        keyword_arguments = list(kwargs.items())\n\n        # Sort the list of positional arguments.\n        positional_arguments.sort()\n\n        # Sort the list of keyword arguments.\n        keyword_arguments.sort()\n\n        # Create a list of the positional and keyword arguments.\n        all_arguments = positional_arguments + keyword_arguments\n\n        # Convert the function name to a string.\n        func_name = str(func_name)\n\n        # Create a dictionary with the function name and all the arguments.\n        data_to_hash = {\n            \"func_name\": func_name,\n            \"args\": all_arguments,\n        }\n\n        # Convert the dictionary to a JSON string.\n        data_to_hash = json.dumps(data_to_hash)\n\n        # Create a SHA-256 hash of the JSON string.\n        hash = hashlib.sha256(data_to_hash.encode(\"utf-8\")).hexdigest()\n\n        return hash\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        # We need to hash the function name as well as the arguments to the function.\n        # This is because the function name is not automatically included in the hash.\n        # We could use a closure, but that would require modifying the function signature.\n        # Instead, we just hash the function name as well.\n        data = (func_name, args, kwargs)\n        return hashlib.sha256(json.dumps(data).encode(\"utf-8\")).hexdigest()\n"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Ensure that the polygon is closed.\n    if not np.array_equal(polygon[0], polygon[-1]):\n        polygon = np.vstack((polygon, polygon[0]))\n\n    # Compute the total length of the polygon.\n    total_length = 0\n    for i in range(len(polygon) - 1):\n        point_1 = polygon[i]\n        point_2 = polygon[i + 1]\n        distance = np.linalg.norm(point_1 - point_2)\n        if distance < max_point_distance:\n            total_length += distance\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the distance between each consecutive pair of points in the polygon.\n    distances = np.linalg.norm(np.diff(polygon, axis=0), axis=1)\n\n    # Compute the total length of the polygon, excluding distances above the maximum distance threshold.\n    return np.sum(distances[distances < max_point_distance])"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the total length of the polygon by summing the distances between consecutive points.\n    total_length = 0\n    for point_index in range(polygon.shape[0]):\n\n        # Get the current point.\n        current_point = polygon[point_index]\n\n        # Get the next point.\n        next_point = polygon[(point_index + 1) % polygon.shape[0]]\n\n        # Compute the distance between the current point and the next point.\n        distance = np.linalg.norm(current_point - next_point)\n\n        # Add the distance to the total length if it is below the maximum distance.\n        if distance <= max_point_distance:\n            total_length += distance\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Calculate the length of each arc in the polygon, excluding arcs that are too long.\n    arc_lengths = []\n    for i in range(len(polygon) - 1):\n        point_1 = polygon[i]\n        point_2 = polygon[i + 1]\n        arc_length = np.linalg.norm(point_1 - point_2)\n        if arc_length <= max_point_distance:\n            arc_lengths.append(arc_length)\n\n    # Calculate the total length of the polygon by summing the lengths of its arcs.\n    total_length = np.sum(arc_lengths)\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Get the number of points in the polygon\n    num_points = len(polygon)\n\n    # Initialize the total length to zero\n    total_length = 0\n\n    # Iterate over all pairs of points\n    for point_index in range(num_points):\n\n        # Get the current point\n        current_point = polygon[point_index]\n\n        # Get the next point\n        next_point = polygon[(point_index + 1) % num_points]\n\n        # Compute the distance between the current point and the next point\n        distance = np.linalg.norm(current_point - next_point)\n\n        # If the distance is below the maximum distance, add it to the total length\n        if distance <= max_point_distance:\n            total_length += distance\n\n    # Return the total length\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Initialize total length to zero.\n    total_length = 0\n\n    # Iterate through all points in the polygon.\n    for i in range(1, len(polygon)):\n\n        # Calculate distance between current point and previous point.\n        distance = np.linalg.norm(polygon[i] - polygon[i - 1])\n\n        # Add distance to total length if it is less than the maximum distance.\n        if distance < max_point_distance:\n            total_length += distance\n\n    # Return total length.\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Get the number of points in the polygon\n    num_points = polygon.shape[0]\n\n    # Initialize the total length of the polygon to zero\n    polygon_length = 0\n\n    # Loop through each point in the polygon\n    for point_index in range(num_points):\n\n        # Get the current point\n        current_point = polygon[point_index, :]\n\n        # Get the next point\n        next_point = polygon[(point_index + 1) % num_points, :]\n\n        # Compute the distance between the current point and the next point\n        distance = np.linalg.norm(current_point - next_point)\n\n        # If the distance between the current point and the next point is less than or equal to the maximum point distance, add the distance to the total length of the polygon\n        if distance <= max_point_distance:\n            polygon_length += distance\n\n    # Return the total length of the polygon\n    return polygon_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Initialize total length to zero\n    total_length = 0\n\n    # Iterate over the points in the polygon\n    for i in range(len(polygon)):\n\n        # If this is the first point in the polygon, set the previous point to the current point\n        if i == 0:\n            prev_point = polygon[i]\n\n        # If this is not the first point in the polygon, compute the distance between the current point and the previous point\n        else:\n            distance = np.linalg.norm(polygon[i] - prev_point)\n\n            # If the distance between the current point and the previous point is less than or equal to the maximum point distance, add the distance to the total length\n            if distance <= max_point_distance:\n                total_length += distance\n\n            # Set the previous point to the current point\n            prev_point = polygon[i]\n\n    # Return the total length\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Initialize the total length of the polygon to zero.\n    polygon_length = 0\n\n    # Iterate over the points in the polygon.\n    for i in range(1, len(polygon)):\n\n        # Compute the distance between the current point and the previous point.\n        distance = np.linalg.norm(polygon[i] - polygon[i - 1])\n\n        # If the distance is below the specified maximum distance, add it to the total length.\n        if distance < max_point_distance:\n            polygon_length += distance\n\n    # Return the total length of the polygon.\n    return polygon_length\n\n"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Initialize total length to zero\n    total_length = 0\n\n    # Loop through points in polygon\n    for i in range(len(polygon)):\n\n        # If this is the last point in the polygon, calculate distance between this point and the first point\n        if i == len(polygon) - 1:\n            distance = np.linalg.norm(polygon[i] - polygon[0])\n\n        # Otherwise, calculate distance between this point and the next point\n        else:\n            distance = np.linalg.norm(polygon[i] - polygon[i + 1])\n\n        # If the distance is below the maximum distance, add it to the total length\n        if distance < max_point_distance:\n            total_length += distance\n\n    # Return total length\n    return total_length\n\n"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the length of the polygon by summing the distances between consecutive points.\n    polygon_length = 0\n    for i in range(len(polygon) - 1):\n        polygon_length += np.linalg.norm(polygon[i + 1] - polygon[i])\n\n    # Compute the total length of the polygon, excluding distances that exceed a specified maximum.\n    # The maximum distance between two consecutive points that can be considered part of the same arc.\n    # Points further apart than this threshold are not counted in the total length.\n    max_point_distance = max_point_distance\n    # Compute the total length of the polygon, excluding distances that exceed a specified maximum.\n    # The maximum distance between two consecutive points that can be considered part of the same arc.\n    # Points further apart than this threshold are not counted in the total length.\n    max_point_distance = max_point_distance\n    # Compute the total length of the polygon, excluding distances that exceed a specified maximum.\n    # The maximum distance between two consecutive points that can be considered part of the same arc.\n    # Points further apart than this threshold are not counted in the total length.\n    max_point_distance = max_point_distance\n    # Compute the total length of the polygon, excluding distances that exceed a specified maximum.\n    # The maximum distance between two consecutive points that can be considered part of the same arc.\n    # Points further apart than this threshold are not counted in the total length.\n    max_point_distance = max_point_distance\n    # Compute the total length of the polygon, excluding distances that exceed a specified maximum.\n    # The maximum distance between two consecutive points that can be considered part of the same arc.\n    # Points further apart than this threshold are not counted in the total length.\n    max_point_distance = max_point_distance\n    # Compute the total length of the polygon, excluding distances that exceed a specified maximum.\n    # The maximum distance between two consecutive points that can be considered part of the same arc.\n    # Points further apart than this threshold are not counted in the total length.\n    max_point_distance = max_"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Initialize total length to zero.\n    total_length = 0\n\n    # Iterate through all points in the polygon.\n    for i in range(len(polygon)):\n\n        # If this is the last point in the polygon, then calculate the distance from this point to the first point.\n        if i == len(polygon) - 1:\n            length = np.linalg.norm(polygon[i] - polygon[0])\n\n        # If this is not the last point in the polygon, then calculate the distance from this point to the next point.\n        else:\n            length = np.linalg.norm(polygon[i] - polygon[i + 1])\n\n        # If the distance is below the maximum distance threshold, then add it to the total length.\n        if length <= max_point_distance:\n            total_length += length\n\n    # Return the total length.\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the total length of the polygon, excluding large gaps between points.\n    total_length = 0\n    for i in range(len(polygon) - 1):\n        point_distance = np.linalg.norm(polygon[i + 1] - polygon[i])\n        if point_distance < max_point_distance:\n            total_length += point_distance\n\n    return total_length\n\n"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Get the number of points in the polygon\n    num_points = polygon.shape[0]\n\n    # Initialize the total length\n    total_length = 0\n\n    # Iterate through the points in the polygon\n    for i in range(num_points):\n\n        # Get the current point\n        point_1 = polygon[i]\n\n        # Get the next point\n        point_2 = polygon[(i + 1) % num_points]\n\n        # Calculate the distance between the two points\n        distance = np.linalg.norm(point_1 - point_2)\n\n        # If the distance is below the maximum point distance, add it to the total length\n        if distance < max_point_distance:\n            total_length += distance\n\n    # Return the total length\n    return total_length\n\n"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Initialize the total length of the polygon\n    total_length = 0.0\n\n    # Loop through each point in the polygon\n    for i in range(len(polygon)):\n        # Get the x and y coordinates of the current point\n        x1 = polygon[i, 0]\n        y1 = polygon[i, 1]\n\n        # Get the x and y coordinates of the next point\n        if i + 1 == len(polygon):\n            x2 = polygon[0, 0]\n            y2 = polygon[0, 1]\n        else:\n            x2 = polygon[i + 1, 0]\n            y2 = polygon[i + 1, 1]\n\n        # Calculate the distance between the current point and the next point\n        distance = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n\n        # If the distance is less than or equal to the maximum point distance, add it to the total length\n        if distance <= max_point_distance:\n            total_length += distance\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # If there are less than 3 points in the polygon, the length is 0.\n    if len(polygon) < 3:\n        return 0.0\n\n    # If there are more than 3 points, the length is the sum of the distances between consecutive points.\n    else:\n        # Initialize the length to 0.\n        length = 0.0\n\n        # For each point in the polygon, except the last point, compute the distance between the current point and the next point.\n        for i in range(len(polygon) - 1):\n            # Compute the distance between the current point and the next point.\n            distance = np.linalg.norm(polygon[i] - polygon[i + 1])\n\n            # If the distance between the current point and the next point is below the maximum distance, add the distance to the total length.\n            if distance <= max_point_distance:\n                length += distance\n\n        # Return the total length.\n        return length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # If there is only one point, the length is zero.\n    if len(polygon) == 1:\n        return 0\n\n    # If there are only two points, the length is the distance between them.\n    if len(polygon) == 2:\n        return np.linalg.norm(polygon[0] - polygon[1])\n\n    # Otherwise, calculate the length by summing the distances between consecutive points.\n    length = 0\n    for i in range(len(polygon) - 1):\n        length += np.linalg.norm(polygon[i] - polygon[i + 1])\n\n    # Exclude distances above the maximum threshold.\n    for i in range(len(polygon) - 2):\n        if np.linalg.norm(polygon[i + 1] - polygon[i + 2]) > max_point_distance:\n            length -= np.linalg.norm(polygon[i + 1] - polygon[i + 2])\n\n    return length\n\n"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the distances between consecutive points in the polygon.\n    distances = np.linalg.norm(np.diff(polygon, axis=0), axis=1)\n\n    # Compute the cumulative sum of the distances between consecutive points.\n    cumulative_distances = np.cumsum(distances)\n\n    # Count the number of distances that are greater than the maximum distance threshold.\n    num_distances_above_threshold = np.sum(distances > max_point_distance)\n\n    # Subtract the number of distances above the threshold from the total number of distances.\n    num_distances_below_threshold = len(distances) - num_distances_above_threshold\n\n    # Return the total length of the polygon, considering only distances below the maximum distance threshold.\n    return cumulative_distances[num_distances_below_threshold - 1]\n\n"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Check that the input is a 2-dimensional numpy array.\n    if not isinstance(polygon, np.ndarray) or polygon.ndim != 2:\n        raise ValueError(\"Input polygon must be a 2-dimensional numpy array.\")\n\n    # Check that the input array is of the correct size.\n    if polygon.shape[1] != 2:\n        raise ValueError(\"Input polygon must have exactly two columns.\")\n\n    # Check that the input array is non-empty.\n    if polygon.size == 0:\n        raise ValueError(\"Input polygon must be non-empty.\")\n\n    # Check that the input array contains only integers.\n    if not np.issubdtype(polygon.dtype, np.integer):\n        raise ValueError(\"Input polygon must contain only integers.\")\n\n    # Check that the maximum point distance is a positive integer.\n    if not isinstance(max_point_distance, int) or max_point_distance <= 0:\n        raise ValueError(\"Maximum point distance must be a positive integer.\")\n\n    # Initialize the total length to zero.\n    total_length = 0\n\n    # Initialize the previous point to the first point in the polygon.\n    previous_point = polygon[0]\n\n    # Iterate over the remaining points in the polygon.\n    for point in polygon[1:]:\n\n        # Calculate the distance between the current point and the previous point.\n        distance = np.linalg.norm(point - previous_point)\n\n        # If the distance is less than or equal to the maximum point distance, add the distance to the total length.\n        if distance <= max_point_distance:\n            total_length += distance\n\n        # Set the previous point to the current point.\n        previous_point = point\n\n    # Return the total length of the polygon.\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the total length of the polygon by summing the distances between consecutive points, excluding distances that exceed a specified maximum, to avoid counting large gaps between disjoint arcs as part of the polygon's length.\n    # The first point is compared to the last point in the polygon.\n    # The last point is compared to the second to last point.\n    # The second to last point is compared to the third to last point.\n    # And so on.\n\n    # Initialize the total length to zero.\n    total_length = 0\n\n    # Loop through each point in the polygon.\n    for point_index in range(len(polygon)):\n\n        # If the point is the first point, then compare it to the last point.\n        if point_index == 0:\n            # Get the first point.\n            point = polygon[0]\n            # Get the last point.\n            last_point = polygon[-1]\n            # Calculate the distance between the first point and the last point.\n            point_distance = np.linalg.norm(point - last_point)\n\n            # If the distance is below the maximum distance, then add it to the total length.\n            if point_distance < max_point_distance:\n                total_length += point_distance\n\n        # If the point is not the first point, then compare it to the previous point.\n        else:\n            # Get the current point.\n            point = polygon[point_index]\n            # Get the previous point.\n            previous_point = polygon[point_index - 1]\n            # Calculate the distance between the current point and the previous point.\n            point_distance = np.linalg.norm(point - previous_point)\n\n            # If the distance is below the maximum distance, then add it to the total length.\n            if point_distance < max_point_distance:\n                total_length += point_distance\n\n    # Return the total length.\n    return total_length"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if len(polygons) == 0:\n        return []\n\n    if len(polygons) == 1:\n        return polygons\n\n    areas_ = np.array([area(polygon) for polygon in polygons])\n    max_area = np.max(areas_)\n\n    rel_tr *= max_area\n    abs_tr *= max_area\n\n    return [polygon for polygon, area_ in zip(polygons, areas_) if area_ >= rel_tr or area_ >= abs_tr]\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if len(polygons) == 0:\n        return polygons\n\n    # get the area of the largest polygon\n    largest_polygon_area = area(polygons[0])\n\n    # filter out polygons based on their area\n    filtered_polygons = []\n    for polygon in polygons:\n        polygon_area = area(polygon)\n        if polygon_area >= largest_polygon_area * rel_tr or polygon_area >= abs_tr:\n            filtered_polygons.append(polygon)\n\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    # Calculate the area of the largest polygon\n    max_area = max([area(polygon) for polygon in polygons])\n\n    # Filter polygons based on their area\n    filtered_polygons = []\n    for polygon in polygons:\n        if area(polygon) > max_area * rel_tr or area(polygon) > abs_tr:\n            filtered_polygons.append(polygon)\n\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if len(polygons) == 0:\n        return polygons\n\n    areas = [area(polygon) for polygon in polygons]\n    max_area = np.max(areas)\n\n    if max_area == 0:\n        return []\n\n    rel_tr = rel_tr * max_area\n    abs_tr = abs_tr * max_area\n\n    polygons_filtered = [\n        polygon for polygon, area in zip(polygons, areas) if area > rel_tr or area > abs_tr\n    ]\n\n    return polygons_filtered\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    # Get the largest polygon's area\n    max_area = max(area(polygon) for polygon in polygons)\n\n    # Filter polygons based on their area\n    polygons = [polygon for polygon in polygons if area(polygon) > max_area * rel_tr or area(polygon) > abs_tr]\n\n    return polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if len(polygons) == 0:\n        return polygons\n\n    largest_polygon = max(polygons, key=cv2.contourArea)\n    largest_polygon_area = cv2.contourArea(largest_polygon)\n\n    filtered_polygons = []\n    for polygon in polygons:\n        if abs_tr > 0 and cv2.contourArea(polygon) < abs_tr:\n            continue\n        if rel_tr > 0 and cv2.contourArea(polygon) / largest_polygon_area < rel_tr:\n            continue\n        filtered_polygons.append(polygon)\n\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    # compute the area of the largest polygon\n    max_area = max([area(poly) for poly in polygons])\n\n    # filter polygons\n    polygons = [poly for poly in polygons if area(poly) > max_area * rel_tr or area(poly) > abs_tr]\n\n    return polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    # Calculate the area of the largest polygon\n    largest_polygon_area = max([area(polygon) for polygon in polygons])\n\n    # Filter out polygons whose area is smaller than the absolute threshold or the relative threshold\n    return [polygon for polygon in polygons if area(polygon) >= abs_tr * largest_polygon_area + rel_tr * largest_polygon_area]\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    # Compute the area of the largest polygon in the list\n    max_area = area(max(polygons, key=cv2.contourArea))\n\n    # Filter polygons by their area\n    return [\n        polygon\n        for polygon in polygons\n        if area(polygon) > max_area * rel_tr or area(polygon) > abs_tr\n    ]\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if len(polygons) == 0:\n        return polygons\n\n    # Calculate the area of the largest polygon in the list\n    max_area = max([area(polygon) for polygon in polygons])\n\n    # Filter polygons based on the area\n    return [polygon for polygon in polygons if area(polygon) > rel_tr * max_area and area(polygon) > abs_tr]\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if not polygons:\n        return polygons\n\n    # Get the largest polygon's area\n    largest_area = area(polygons[0])\n\n    # Get the absolute threshold\n    if abs_tr:\n        abs_tr = largest_area * abs_tr\n\n    # Filter out polygons based on their area\n    filtered_polygons = [\n        polygon for polygon in polygons if area(polygon) >= largest_area * rel_tr or area(polygon) >= abs_tr\n    ]\n\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if not polygons:\n        raise VectorizationError(\"No polygons were provided.\")\n\n    if not rel_tr and not abs_tr:\n        raise VectorizationError(\"No area threshold was provided.\")\n\n    if rel_tr and abs_tr:\n        raise VectorizationError(\"Both area thresholds were provided.\")\n\n    if rel_tr:\n        rel_tr = rel_tr\n    else:\n        rel_tr = 0.0\n\n    if abs_tr:\n        abs_tr = abs_tr\n    else:\n        abs_tr = 0.0\n\n    largest_area = area(polygons[0])\n    filtered_polygons = []\n\n    for polygon in polygons:\n        if area(polygon) >= largest_area * rel_tr or area(polygon) >= abs_tr:\n            filtered_polygons.append(polygon)\n\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if len(polygons) == 0:\n        return []\n\n    areas = [area(polygon) for polygon in polygons]\n    max_area = max(areas)\n    rel_tr *= max_area\n    abs_tr *= max_area\n    filtered_polygons = [\n        polygon for polygon, area in zip(polygons, areas) if area >= rel_tr or area >= abs_tr\n    ]\n\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    # Get the areas of the polygons\n    areas = [area(polygon) for polygon in polygons]\n\n    # Get the largest area\n    max_area = max(areas)\n\n    # Filter out polygons\n    filtered_polygons = []\n    for polygon, polygon_area in zip(polygons, areas):\n        if polygon_area > max_area * rel_tr or polygon_area > abs_tr:\n            filtered_polygons.append(polygon)\n\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    # Get the area of the largest polygon in the list\n    max_area = max([area(p) for p in polygons])\n\n    # Filter out polygons whose area is below the threshold\n    filtered_polygons = []\n    for p in polygons:\n        if area(p) >= max_area * rel_tr or area(p) >= abs_tr:\n            filtered_polygons.append(p)\n\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if len(polygons) == 0:\n        return []\n\n    # Get the area of the largest polygon in the list\n    largest_polygon_area = max([area(polygon) for polygon in polygons])\n\n    # Filter out polygons whose area is below the threshold\n    filtered_polygons = [\n        polygon\n        for polygon in polygons\n        if area(polygon) >= rel_tr * largest_polygon_area + abs_tr\n    ]\n\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    # Compute the area of the largest polygon in the list.\n    max_area = area(max(polygons, key=cv2.contourArea))\n\n    # Filter out polygons whose area is below the threshold.\n    polygons = [\n        polygon\n        for polygon in polygons\n        if area(polygon) >= max(max_area * rel_tr, abs_tr)\n    ]\n\n    return polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    # Get the area of the largest polygon in the list\n    max_area = max([area(polygon) for polygon in polygons])\n\n    # Filter out polygons whose area is below the threshold\n    polygons = [\n        polygon\n        for polygon in polygons\n        if (area(polygon) / max_area) >= rel_tr or area(polygon) >= abs_tr\n    ]\n\n    return polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    # Compute the area of the largest polygon\n    max_area = max([area(polygon) for polygon in polygons])\n\n    # Filter out polygons whose area is below either the absolute or relative threshold\n    return [\n        polygon\n        for polygon in polygons\n        if polygon.shape[0] > 2 and area(polygon) / max_area > rel_tr and area(polygon) > abs_tr\n    ]\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if len(polygons) == 0:\n        return polygons\n\n    largest_area = area(polygons[0])\n    for polygon in polygons[1:]:\n        largest_area = max(largest_area, area(polygon))\n\n    rel_tr *= largest_area\n    abs_tr *= largest_area\n\n    filtered_polygons = []\n    for polygon in polygons:\n        if area(polygon) >= rel_tr or area(polygon) >= abs_tr:\n            filtered_polygons.append(polygon)\n\n    return filtered_polygons\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples each worker has processed.\n    samples_per_worker = num_samples_yielded // num_workers\n    samples_remaining = num_samples_yielded % num_workers\n\n    # Calculate the number of samples each worker has processed.\n    samples_per_worker = num_samples_yielded // num_workers\n    samples_remaining = num_samples_yielded % num_workers\n\n    # Calculate the number of batches each worker has processed.\n    batches_per_worker = samples_per_worker // batch_size\n    batches_remaining = samples_per_worker % batch_size\n\n    # Calculate the number of batches each worker has processed.\n    batches_per_worker = samples_per_worker // batch_size\n    batches_remaining = samples_per_worker % batch_size\n\n    # Calculate the number of batches each worker has processed.\n    batches_per_worker = samples_per_worker // batch_size\n    batches_remaining = samples_per_worker % batch_size\n\n    # Calculate the number of batches each worker has processed.\n    batches_per_worker = samples_per_worker // batch_size\n    batches_remaining = samples_per_worker % batch_size\n\n    # Calculate the number of batches each worker has processed.\n    batches_per_worker = samples_per_worker // batch_size\n    batches_remaining = samples_per_worker % batch_size\n\n    # Calculate the number of batches each worker has processed.\n    batches_per_worker = samples_per_worker // batch_size\n    batches_remaining = samples_per_worker % batch_size\n\n    # Calculate the number of batches each worker has processed.\n    batches_per_worker = samples_per_worker // batch_size\n    batches_remaining = samples_per_worker % batch_size\n\n    # Calculate the number of batches each worker has processed.\n    batches_per_worker = samples_per_worker // batch_size"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples each worker has processed.\n    samples_per_worker = num_samples_yielded // num_workers\n    samples_remaining = num_samples_yielded % num_workers\n\n    # Calculate the number of samples each worker has processed.\n    samples_per_worker_batch = samples_per_worker // batch_size\n    samples_remaining_batch = samples_per_worker % batch_size\n\n    # Calculate the number of samples each worker has processed.\n    samples_per_worker = samples_per_worker_batch * batch_size\n    samples_remaining = samples_remaining_batch\n\n    # Calculate the number of samples each worker has processed.\n    samples_per_worker = samples_per_worker + samples_remaining\n\n    # Calculate the number of samples each worker has processed.\n    samples_per_worker_batch = samples_per_worker // batch_size\n    samples_remaining_batch = samples_per_worker % batch_size\n\n    # Calculate the number of samples each worker has processed.\n    samples_per_worker = samples_per_worker_batch * batch_size\n    samples_remaining = samples_remaining_batch\n\n    # Calculate the number of samples each worker has processed.\n    samples_per_worker = samples_per_worker + samples_remaining\n\n    # Calculate the number of samples each worker has processed.\n    samples_per_worker_batch = samples_per_worker // batch_size\n    samples_remaining_batch = samples_per_worker % batch_size\n\n    # Calculate the number of samples each worker has processed.\n    samples_per_worker = samples_per_worker_batch * batch_size\n    samples_remaining = samples_remaining_batch\n\n    # Calculate the number of samples each worker has processed.\n    samples_per_worker_batch = samples_per_worker // batch_size\n    samples_remaining_batch = samples_per_worker % batch_size\n\n    # Calculate the number of samples each worker has processed.\n    samples_per_worker = samples_per_worker_batch *"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # The number of samples that have been yielded per worker\n    num_samples_per_worker = num_samples_yielded // num_workers\n    # The number of samples that have been yielded per batch\n    num_samples_per_batch = num_samples_per_worker // batch_size\n    # The number of batches that have been yielded per worker\n    num_batches_per_worker = num_samples_per_worker // batch_size\n    # The number of samples that have been yielded per batch\n    num_samples_per_batch = num_samples_per_worker // batch_size\n    # The number of samples that have been yielded per batch\n    num_samples_per_batch = num_samples_per_worker // batch_size\n    # The number of batches that have been yielded per worker\n    num_batches_per_worker = num_samples_per_worker // batch_size\n\n    # The number of samples that have been yielded per batch\n    num_samples_per_batch = num_samples_per_worker // batch_size\n    # The number of batches that have been yielded per worker\n    num_batches_per_worker = num_samples_per_worker // batch_size\n\n    # The number of samples that have been yielded per batch\n    num_samples_per_batch = num_samples_per_worker // batch_size\n    # The number of batches that have been yielded per worker\n    num_batches_per_worker = num_samples_per_worker // batch_size\n\n    # The number of samples that have been yielded per batch\n    num_samples_per_batch = num_samples_per_worker // batch_size\n    # The number of batches that have been yielded per worker\n    num_batches_per_worker = num_samples_per_worker // batch_size\n\n    # The number of samples that have been yielded per batch\n    num_samples_per_batch = num_samples_per_worker // batch_size\n    # The number of batches that have been yielded per worker\n    num_batches_per_worker = num_samples"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # The number of samples that each worker has processed\n    indexes = {}\n\n    # The number of samples that each worker has processed\n    samples_per_worker = num_samples_yielded // num_workers\n\n    # The number of samples that each worker has processed\n    samples_per_worker_remaining = num_samples_yielded % num_workers\n\n    # The number of batches that each worker has processed\n    batches_per_worker = samples_per_worker // batch_size\n\n    # The number of batches that each worker has processed\n    batches_per_worker_remaining = samples_per_worker % batch_size\n\n    # The number of batches that each worker has processed\n    batches_per_worker_remaining_per_worker = batches_per_worker_remaining // num_workers\n\n    # The number of batches that each worker has processed\n    batches_per_worker_remaining_per_worker_remaining = batches_per_worker_remaining % num_workers\n\n    # The number of samples that each worker has processed\n    samples_per_worker_remaining_per_worker = samples_per_worker_remaining // num_workers\n\n    # The number of samples that each worker has processed\n    samples_per_worker_remaining_per_worker_remaining = samples_per_worker_remaining % num_workers\n\n    # The number of samples that each worker has processed\n    samples_per_worker_per_worker = samples_per_worker // num_workers\n\n    # The number of samples that each worker has processed\n    samples_per_worker_per_worker_remaining = samples_per_worker % num_workers\n\n    # The number of samples that each worker has processed\n    samples_per_worker_remaining_per_worker_remaining = samples_per_worker_remaining % num_workers\n\n    # The number of samples that each worker has processed\n    samples_per_worker_remaining_per_worker_remaining = samples_per_worker_remaining % num_workers\n\n    # The number of samples that each"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples each worker has processed.\n    samples_per_worker = num_samples_yielded // num_workers\n\n    # Calculate the number of samples each worker is responsible for.\n    samples_per_worker_per_batch = samples_per_worker // batch_size\n\n    # Calculate the number of samples each worker is responsible for, after the division by batch size.\n    samples_per_worker_remainder = samples_per_worker % batch_size\n\n    # Calculate the number of batches each worker is responsible for.\n    batches_per_worker = samples_per_worker_per_batch + (1 if samples_per_worker_remainder > 0 else 0)\n\n    # Calculate the number of samples each worker is responsible for.\n    samples_per_worker = batches_per_worker * batch_size\n\n    # Calculate the number of samples each worker is responsible for, after the division by batch size.\n    samples_per_worker_remainder = samples_per_worker % batch_size\n\n    # Calculate the number of batches each worker is responsible for.\n    batches_per_worker = samples_per_worker // batch_size\n\n    # Calculate the number of samples each worker is responsible for.\n    samples_per_worker = batches_per_worker * batch_size\n\n    # Calculate the number of samples each worker is responsible for, after the division by batch size.\n    samples_per_worker_remainder = samples_per_worker % batch_size\n\n    # Calculate the number of batches each worker is responsible for.\n    batches_per_worker = samples_per_worker // batch_size\n\n    # Calculate the number of samples each worker is responsible for.\n    samples_per_worker = batches_per_worker * batch_size\n\n    # Calculate the number of samples each worker is responsible for, after the division by batch size.\n    samples_per_worker_remainder = samples_per_worker % batch_size\n\n    # Calculate the number of batches each worker is responsible for.\n    batches_per_worker"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # TODO: Implement elastic sampling where the number of workers, ranks can change.\n    # First, we calculate the number of samples that each worker has processed.\n    samples_per_worker = num_samples_yielded // num_workers\n\n    # Then, we calculate the number of samples that each worker has yet to process.\n    remaining_samples = num_samples_yielded % num_workers\n\n    # We calculate the number of batches that each worker has yet to process.\n    remaining_batches = remaining_samples // batch_size\n\n    # We calculate the number of batches that each worker has processed.\n    processed_batches = samples_per_worker // batch_size\n\n    # We calculate the number of samples that each worker has yet to process.\n    remaining_samples = samples_per_worker % batch_size\n\n    # We calculate the number of samples that each worker has yet to process.\n    remaining_samples = samples_per_worker % batch_size\n\n    # We calculate the number of samples that each worker has yet to process.\n    remaining_samples = samples_per_worker % batch_size\n\n    # We calculate the number of samples that each worker has yet to process.\n    remaining_samples = samples_per_worker % batch_size\n\n    # We calculate the number of samples that each worker has yet to process.\n    remaining_samples = samples_per_worker % batch_size\n\n    # We calculate the number of samples that each worker has yet to process.\n    remaining_samples = samples_per_worker % batch_size\n\n    # We calculate the number of samples that each worker has yet to process.\n    remaining_samples = samples_per_worker % batch_size\n\n    # We calculate the number of samples that each worker has yet to process.\n    remaining_samples = samples_per_worker % batch_size\n\n    # We calculate the number of samples that each worker has yet to process.\n    remaining_samples = samples_per_worker % batch_size\n\n    # We calculate the number of samples that each worker has yet to process.\n    remaining_samples = samples_per_worker % batch_size\n\n    # We calculate the number of"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples that each worker has processed, given the total number of samples yielded, the batch size, and the number of workers.\n    num_samples_per_worker = num_samples_yielded // num_workers\n    num_samples_remaining = num_samples_yielded % num_workers\n\n    # Ensure that the distribution of samples among workers is as even as possible, taking into account the division of the total samples by the number of workers and the batch size, and then distributing any remaining samples.\n    samples_per_worker = [num_samples_per_worker + 1 if i < num_samples_remaining else num_samples_per_worker for i in range(num_workers)]\n\n    # Calculate the number of batches that each worker has processed, given the total number of samples yielded, the batch size, and the number of workers.\n    num_batches_per_worker = [int(num / batch_size) for num in samples_per_worker]\n\n    # Ensure that the distribution of batches among workers is as even as possible, taking into account the division of the total samples by the number of workers and the batch size, and then distributing any remaining batches.\n    batches_per_worker = [batch + 1 if i < samples_per_worker[i] % batch_size else batch for i, batch in enumerate(num_batches_per_worker)]\n\n    # Calculate the number of indexes that each worker has processed, given the total number of samples yielded, the batch size, and the number of workers.\n    indexes_per_worker = [batch * batch_size for batch in batches_per_worker]\n\n    # Ensure that the distribution of indexes among workers is as even as possible, taking into account the division of the total samples by the number of workers and the batch size, and then distributing any remaining indexes.\n    indexes_per_worker = [index + 1 if i < batches_per_worker[i] % batch_size else index for i, index in enumerate(indexes_per_worker)]\n\n    # Calculate the number of chunks that each worker has processed, given the total"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples that each worker has processed.\n    samples_per_worker = num_samples_yielded // num_workers\n    samples_remaining = num_samples_yielded % num_workers\n\n    # Calculate the number of batches that each worker has processed.\n    batches_per_worker = samples_per_worker // batch_size\n    batches_remaining = samples_per_worker % batch_size\n\n    # Calculate the number of batches that each worker has processed, including the remaining samples.\n    batches_per_worker_with_remaining_samples = batches_per_worker + batches_remaining // batch_size\n\n    # Calculate the number of samples that each worker has processed, including the remaining samples.\n    samples_per_worker_with_remaining_samples = batches_per_worker_with_remaining_samples * batch_size\n\n    # Calculate the number of samples that each worker has not processed, including the remaining samples.\n    samples_not_processed_with_remaining_samples = samples_per_worker_with_remaining_samples - samples_per_worker\n\n    # Calculate the number of samples that each worker has not processed.\n    samples_not_processed = samples_not_processed_with_remaining_samples - samples_remaining\n\n    # Calculate the number of batches that each worker has not processed.\n    batches_not_processed = samples_not_processed // batch_size\n\n    # Calculate the number of batches that each worker has not processed, including the remaining samples.\n    batches_not_processed_with_remaining_samples = batches_not_processed + samples_remaining // batch_size\n\n    # Calculate the number of samples that each worker has not processed, including the remaining samples.\n    samples_not_processed_with_remaining_samples = batches_not_processed_with_remaining_samples * batch_size\n\n    # Calculate the number of samples that each worker has not processed, including the remaining samples.\n    samples_not_processed = samples_not_process"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples each worker has processed, given the total number of samples yielded, the batch size, and the number of workers.\n    num_samples_per_worker = num_samples_yielded // num_workers\n    num_samples_remaining = num_samples_yielded % num_workers\n\n    # Calculate the number of batches each worker has processed, given the total number of batches yielded, the batch size, and the number of workers.\n    num_batches_per_worker = num_samples_per_worker // batch_size\n    num_batches_remaining = num_samples_per_worker % batch_size\n\n    # Calculate the number of batches each worker has processed, given the total number of batches yielded, the batch size, and the number of workers.\n    num_batches_per_worker = num_samples_per_worker // batch_size\n    num_batches_remaining = num_samples_per_worker % batch_size\n\n    # Create an array of zeros with length equal to the number of workers.\n    num_samples_per_worker = np.zeros(num_workers, dtype=int)\n\n    # Fill the array with the number of batches each worker has processed, given the total number of batches yielded, the batch size, and the number of workers.\n    num_samples_per_worker[:num_batches_per_worker] = batch_size\n\n    # Fill the array with the number of batches each worker has processed, given the total number of batches yielded, the batch size, and the number of workers.\n    num_samples_per_worker[num_batches_per_worker:] = num_batches_remaining\n\n    # Create an array of zeros with length equal to the number of workers.\n    num_samples_per_worker = np.zeros(num_workers, dtype=int)\n\n    # Fill the array with the number of batches each worker has processed, given the total number of batches yielded, the batch size, and the number of workers.\n    num_samples_per_worker[:num_batches"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples that each worker has processed.\n    num_samples_per_worker = num_samples_yielded // num_workers\n\n    # Calculate the number of samples that each worker has processed.\n    num_samples_per_worker_remainder = num_samples_yielded % num_workers\n\n    # Calculate the number of batches that each worker has processed.\n    num_batches_per_worker = num_samples_per_worker // batch_size\n\n    # Calculate the number of batches that each worker has processed.\n    num_batches_per_worker_remainder = num_samples_per_worker % batch_size\n\n    # Initialize the number of samples that each worker has processed.\n    num_samples_per_worker_dict = {}\n\n    # Initialize the number of batches that each worker has processed.\n    num_batches_per_worker_dict = {}\n\n    # Initialize the number of samples that each worker has processed.\n    num_samples_per_worker_dict = {i: 0 for i in range(num_workers)}\n\n    # Initialize the number of batches that each worker has processed.\n    num_batches_per_worker_dict = {i: 0 for i in range(num_workers)}\n\n    # Iterate through all the workers.\n    for i in range(num_workers):\n\n        # If the number of samples that the current worker has processed is less than the number of samples that the current worker has processed, add the batch size to the number of samples that the current worker has processed.\n        if num_samples_per_worker_dict[i] < num_samples_per_worker:\n            num_samples_per_worker_dict[i] += batch_size\n\n        # If the number of batches that the current worker has processed is less than the number of batches that the current worker has processed, add one to the number of batches that the current worker has processed.\n        if num_batches_per_worker_dict[i] < num_batches_per_worker:\n            num_batches_per_worker_dict"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples each worker has processed.\n    samples_per_worker = num_samples_yielded // num_workers\n    remaining_samples = num_samples_yielded % num_workers\n\n    # Calculate the number of batches each worker has processed.\n    batches_per_worker = samples_per_worker // batch_size\n    remaining_batches = samples_per_worker % batch_size\n\n    # Distribute the remaining samples among workers.\n    samples_per_worker = [samples_per_worker + 1 if i < remaining_samples else samples_per_worker for i in range(num_workers)]\n\n    # Distribute the remaining batches among workers.\n    batches_per_worker = [batches_per_worker + 1 if i < remaining_batches else batches_per_worker for i in range(num_workers)]\n\n    # Calculate the number of samples each worker has processed.\n    indexes = [i * batch_size for i in range(samples_per_worker[worker_idx])]\n\n    # Calculate the number of batches each worker has processed.\n    indexes = indexes + [i * batch_size for i in range(batches_per_worker[worker_idx])]\n\n    return indexes\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples each worker has processed.\n    samples_per_worker = num_samples_yielded // num_workers\n\n    # Calculate the number of samples that will be distributed to each worker.\n    samples_per_worker_batch = samples_per_worker // batch_size\n\n    # Calculate the number of batches that will be distributed to each worker.\n    batches_per_worker = batch_size // samples_per_worker_batch\n\n    # Calculate the number of samples that will be distributed to each worker.\n    samples_per_worker_remaining = samples_per_worker % batch_size\n\n    # Calculate the number of batches that will be distributed to each worker.\n    batches_per_worker_remaining = samples_per_worker_remaining // samples_per_worker_batch\n\n    # Calculate the number of samples that will be distributed to each worker.\n    samples_per_worker_remaining_remaining = samples_per_worker_remaining % samples_per_worker_batch\n\n    # Initialize the dictionary that will contain the number of samples that each worker has processed.\n    indexes = {}\n\n    # Calculate the number of samples that each worker has processed.\n    for i in range(num_workers):\n        indexes[i] = samples_per_worker_batch * batches_per_worker + samples_per_worker_remaining_remaining\n\n    # Calculate the number of samples that each worker has processed.\n    for i in range(num_workers):\n        if i == num_workers - 1:\n            break\n        indexes[i] += batches_per_worker * samples_per_worker_batch\n\n    # Calculate the number of samples that each worker has processed.\n    for i in range(num_workers):\n        if i == num_workers - 1:\n            break\n        indexes[i] += samples_per_worker_remaining * batches_per_worker_remaining\n\n    # Calculate the number of samples that each worker has processed.\n    for i in range(num_workers):\n        if i == num_workers"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # get the number of samples that each worker has processed\n    samples_per_worker = [0] * num_workers\n    for i in range(num_workers):\n        samples_per_worker[i] = num_samples_yielded // (num_workers * batch_size)\n\n    # get the number of samples that are left to be processed\n    remainder = num_samples_yielded % (num_workers * batch_size)\n\n    # distribute the remainder among the workers\n    for i in range(remainder):\n        samples_per_worker[i % num_workers] += 1\n\n    return {i: samples_per_worker[i] for i in range(num_workers)}\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    num_samples_per_worker = num_samples_yielded // num_workers\n    num_samples_remaining = num_samples_yielded % num_workers\n\n    if num_samples_per_worker == 0:\n        return {i: 0 for i in range(num_workers)}\n\n    num_batches_per_worker = num_samples_per_worker // batch_size\n    num_batches_remaining = num_samples_per_worker % batch_size\n\n    samples_per_worker = {i: num_batches_per_worker * batch_size for i in range(num_workers)}\n\n    for i in range(num_batches_remaining):\n        samples_per_worker[i] += 1\n\n    for i in range(num_samples_remaining):\n        samples_per_worker[i] += 1\n\n    return samples_per_worker\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples each worker has processed\n    # num_samples_yielded = num_workers * (num_samples_yielded // (num_workers * batch_size)) + min(num_samples_yielded % (num_workers * batch_size), batch_size)\n    num_samples_yielded = num_workers * (num_samples_yielded // (num_workers * batch_size)) + min(\n        num_samples_yielded % (num_workers * batch_size), batch_size\n    )\n\n    # Create a dictionary where each key is a worker index (starting from 0) and its value is the number of samples that worker has processed\n    indexes = {i: 0 for i in range(num_workers)}\n\n    # Get the number of samples that each worker has processed\n    for i in range(num_workers):\n        indexes[i] = num_samples_yielded // num_workers\n\n    # Distribute any remaining samples\n    remaining_samples = num_samples_yielded % num_workers\n    for i in range(remaining_samples):\n        indexes[i % num_workers] += 1\n\n    return indexes\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples each worker has processed.\n    samples_per_worker = num_samples_yielded // num_workers\n    samples_remaining = num_samples_yielded % num_workers\n    samples_per_worker_batch = batch_size // num_workers\n\n    # Calculate the number of samples each worker has processed in a batch.\n    samples_per_worker_batch_remaining = samples_per_worker % batch_size\n\n    # Calculate the number of batches each worker has processed.\n    batches_per_worker = samples_per_worker // batch_size\n    batches_per_worker_remaining = samples_per_worker_remaining // batch_size\n\n    # Calculate the number of samples each worker has processed in the last batch.\n    samples_per_worker_last_batch = samples_per_worker_remaining % batch_size\n\n    # Calculate the number of samples each worker has processed in the last batch.\n    batches_per_worker_last_batch = samples_per_worker_remaining % batch_size\n\n    # Calculate the number of samples each worker has processed.\n    samples_per_worker = samples_per_worker + samples_per_worker_batch\n\n    # Calculate the number of samples each worker has processed.\n    samples_per_worker = samples_per_worker + samples_per_worker_last_batch\n\n    # Calculate the number of batches each worker has processed.\n    batches_per_worker = batches_per_worker + batches_per_worker_remaining\n\n    # Calculate the number of batches each worker has processed.\n    batches_per_worker = batches_per_worker + batches_per_worker_last_batch\n\n    # Calculate the number of samples each worker has processed in a batch.\n    samples_per_worker_batch = batch_size\n\n    # Calculate the number of samples each worker has processed in a batch.\n    samples_per_worker_batch = samples_per_worker_batch + samples_per_worker_batch_remaining\n\n    # Calculate the number of"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples that each worker has processed\n    samples_per_worker = num_samples_yielded // num_workers\n\n    # Calculate the number of batches that each worker has processed\n    batches_per_worker = samples_per_worker // batch_size\n\n    # Calculate the number of samples that each worker has processed, but not including the samples that have been yielded\n    samples_left_over = num_samples_yielded % num_workers\n\n    # Calculate the number of batches that each worker has processed, but not including the batches that have been yielded\n    batches_left_over = samples_left_over // batch_size\n\n    # Calculate the number of samples that each worker has processed\n    samples_per_worker_dict = {\n        worker_idx: samples_per_worker + batches_per_worker * batch_size + batches_left_over * batch_size\n        for worker_idx in range(num_workers)\n    }\n\n    return samples_per_worker_dict\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples each worker has processed.\n    samples_per_worker = num_samples_yielded // num_workers\n\n    # Calculate the number of samples that each worker will process.\n    samples_per_worker_batch = samples_per_worker // batch_size\n\n    # Calculate the number of samples that will be processed by each worker.\n    samples_per_worker_remainder = samples_per_worker % batch_size\n\n    # Initialize a dictionary to store the number of samples each worker has processed.\n    indexes = {}\n\n    # Initialize a counter to keep track of the number of samples processed.\n    counter = 0\n\n    # Iterate over the number of workers.\n    for i in range(num_workers):\n\n        # Calculate the number of samples that will be processed by the current worker.\n        samples_processed = samples_per_worker_batch * batch_size\n\n        # If there are remaining samples, add them to the number of samples that will be processed by the current worker.\n        if i < samples_per_worker_remainder:\n            samples_processed += batch_size\n        else:\n            samples_processed += samples_per_worker_batch\n\n        # Add the number of samples that will be processed by the current worker to the counter.\n        counter += samples_processed\n\n        # Add the number of samples that will be processed by the current worker to the dictionary.\n        indexes[i] = samples_processed\n\n    # Return the dictionary with the number of samples each worker has processed.\n    return indexes\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples each worker has processed.\n    samples_per_worker = num_samples_yielded // num_workers\n\n    # Calculate the number of samples that each worker has processed.\n    samples_yielded_per_worker = [samples_per_worker for i in range(num_workers)]\n\n    # Calculate the number of samples that each worker has processed.\n    # If the number of samples is not evenly divisible by the number of workers,\n    # then the remainder is distributed among the workers.\n    samples_yielded_per_worker[-1] = samples_yielded_per_worker[-1] + (num_samples_yielded % num_workers)\n\n    # Calculate the number of batches that each worker has processed.\n    batches_yielded_per_worker = [samples_yielded_per_worker[i] // batch_size for i in range(num_workers)]\n\n    # Calculate the number of batches that each worker has processed.\n    # If the number of batches is not evenly divisible by the number of workers,\n    # then the remainder is distributed among the workers.\n    batches_yielded_per_worker[-1] = batches_yielded_per_worker[-1] + (samples_yielded_per_worker[-1] % batch_size)\n\n    # Calculate the indexes of each worker's batches.\n    indexes_per_worker = [\n        [i * batch_size + j for j in range(batches_yielded_per_worker[i])] for i in range(num_workers)\n    ]\n\n    # Calculate the indexes of each worker's batches.\n    # If the number of batches is not evenly divisible by the number of workers,\n    # then the remainder is distributed among the workers.\n    indexes_per_worker[-1] = indexes_per_worker[-1] + list(range(num_samples_yielded % batch_size))\n\n    return indexes_per_worker\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples per worker\n    samples_per_worker = num_samples_yielded // num_workers\n\n    # Calculate the number of samples that will be distributed to the remaining workers\n    remaining_samples = num_samples_yielded % num_workers\n\n    # Calculate the number of batches per worker\n    batches_per_worker = samples_per_worker // batch_size\n\n    # Calculate the number of batches that will be distributed to the remaining workers\n    remaining_batches = samples_per_worker % batch_size\n\n    # Calculate the number of samples that will be distributed to the remaining workers\n    remaining_samples = batch_size * remaining_batches\n\n    # Calculate the number of batches that will be distributed to the remaining workers\n    remaining_batches = samples_per_worker % batch_size\n\n    # Calculate the number of samples that will be distributed to the remaining workers\n    remaining_samples = batch_size * remaining_batches\n\n    # Initialize the dictionary\n    indexes = {}\n\n    # Initialize the index\n    index = 0\n\n    # Iterate over the number of workers\n    for worker_index in range(num_workers):\n\n        # Calculate the number of batches that will be distributed to the current worker\n        batches = batches_per_worker\n\n        # Calculate the number of samples that will be distributed to the current worker\n        samples = batch_size * batches\n\n        # Add the number of samples to the dictionary\n        indexes[worker_index] = samples\n\n        # Increase the index\n        index += samples\n\n    # Iterate over the number of remaining samples\n    for i in range(remaining_samples):\n\n        # Calculate the current worker index\n        worker_index = index % num_workers\n\n        # Calculate the number of samples that will be distributed to the current worker\n        if worker_index in indexes:\n            samples = indexes[worker_index]\n        else:\n            samples = 0\n\n        # Add the number of samples to the dictionary\n        indexes[worker_index] = samples + 1\n\n        # In"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    filtered_results = []\n    filtered_metadatas = []\n    for result, value, metadata in zip(results, value, metadatas):\n        if value <= threshold:\n            filtered_results.append(result)\n            filtered_metadatas.append(metadata)\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n\n    filtered_results = []\n    filtered_metadatas = []\n    for result, value, metadata in zip(results, value, metadatas):\n        if value <= threshold:\n            filtered_results.append(result)\n            filtered_metadatas.append(metadata)\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n\n    assert len(results) == len(value) == len(metadatas), \"The results, value, and metadata lists must be the same length.\"\n\n    filtered_results = []\n    filtered_metadata = []\n\n    for result, val, metadata in zip(results, value, metadatas):\n        if val <= threshold:\n            filtered_results.append(result)\n            filtered_metadata.append(metadata)\n\n    return filtered_results, filtered_metadata\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if not isinstance(results, list):\n        raise TypeError(\"The results must be a list.\")\n    if not isinstance(value, list):\n        raise TypeError(\"The value must be a list.\")\n    if not isinstance(threshold, (int, float)):\n        raise TypeError(\"The threshold must be numeric.\")\n    if metadatas is not None and not isinstance(metadatas, list):\n        raise TypeError(\"The metadatas must be a list.\")\n    if not len(results) == len(value):\n        raise ValueError(\"The results and value lists must be the same length.\")\n    if metadatas is not None and not len(results) == len(metadatas):\n        raise ValueError(\"The results and metadatas lists must be the same length.\")\n\n    filtered_results = []\n    filtered_metadatas = []\n    for i in range(len(results)):\n        if value[i] <= threshold:\n            filtered_results.append(results[i])\n            if metadatas is not None:\n                filtered_metadatas.append(metadatas[i])\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    # If no metadata was provided, create a list of None values\n    if metadatas is None:\n        metadatas = [None] * len(results)\n\n    # Filter the results and metadata based on the threshold\n    filtered_results = []\n    filtered_metadatas = []\n    for i, (result, value, metadata) in enumerate(zip(results, value, metadatas)):\n        if value <= threshold:\n            filtered_results.append(result)\n            filtered_metadatas.append(metadata)\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n\n    assert len(results) == len(value) == len(metadatas), 'The length of results, value, and metadata must be the same.'\n\n    filtered_results = []\n    filtered_metadatas = []\n    for result, value, metadata in zip(results, value, metadatas):\n        if value <= threshold:\n            filtered_results.append(result)\n            filtered_metadatas.append(metadata)\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n\n    if len(results) != len(value):\n        raise ValueError(\"The length of the results list must be equal to the length of the value list.\")\n    if len(results) != len(metadatas):\n        raise ValueError(\"The length of the results list must be equal to the length of the metadata list.\")\n\n    filtered_results = []\n    filtered_metadatas = []\n    for result, value, metadata in zip(results, value, metadatas):\n        if value <= threshold:\n            filtered_results.append(result)\n            filtered_metadatas.append(metadata)\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n    if len(results) != len(value):\n        raise ValueError(\"The results and values must have the same length.\")\n    if len(results) != len(metadatas):\n        raise ValueError(\"The results and metadatas must have the same length.\")\n\n    filtered_results = []\n    filtered_metadatas = []\n    for result, value, metadata in zip(results, value, metadatas):\n        if value <= threshold:\n            filtered_results.append(result)\n            filtered_metadatas.append(metadata)\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None for _ in results]\n    if len(results) != len(value) or len(results) != len(metadatas):\n        raise ValueError(\"The length of results, value and metadatas must be the same.\")\n    filtered_results = []\n    filtered_metadatas = []\n    for i, result in enumerate(results):\n        if value[i] <= threshold:\n            filtered_results.append(result)\n            filtered_metadatas.append(metadatas[i])\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if not isinstance(results, list):\n        raise TypeError(\"The results must be a list.\")\n    if not isinstance(value, list):\n        raise TypeError(\"The value must be a list.\")\n    if not isinstance(threshold, (int, float)):\n        raise TypeError(\"The threshold must be a numeric value.\")\n    if not isinstance(metadatas, list) and metadatas is not None:\n        raise TypeError(\"The metadatas must be a list.\")\n    if len(results) != len(value):\n        raise ValueError(\"The results and value lists must be the same length.\")\n    if metadatas is not None and len(results) != len(metadatas):\n        raise ValueError(\"The results and metadatas lists must be the same length.\")\n\n    # If no metadata is provided, create a list of None values.\n    if metadatas is None:\n        metadatas = [None] * len(results)\n\n    # Create a list of tuples containing the results and their associated metadata.\n    results_and_metadata = list(zip(results, metadatas))\n\n    # Filter the results and metadata by the threshold.\n    filtered_results_and_metadata = [\n        result_and_metadata\n        for result_and_metadata in results_and_metadata\n        if result_and_metadata[0] <= threshold\n    ]\n\n    # Extract the filtered results and metadata.\n    filtered_results = [result_and_metadata[0] for result_and_metadata in filtered_results_and_metadata]\n    filtered_metadatas = [result_and_metadata[1] for result_and_metadata in filtered_results_and_metadata]\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if not isinstance(results, list):\n        raise TypeError(\"The results must be a list.\")\n    if not isinstance(value, list):\n        raise TypeError(\"The value must be a list.\")\n    if not isinstance(threshold, (int, float)):\n        raise TypeError(\"The threshold must be a numeric value.\")\n    if not isinstance(metadatas, list) and metadatas is not None:\n        raise TypeError(\"The metadatas must be a list.\")\n    if len(results) != len(value):\n        raise ValueError(\"The length of the results list must be the same as the length of the value list.\")\n    if metadatas is not None and len(results) != len(metadatas):\n        raise ValueError(\"The length of the results list must be the same as the length of the metadatas list.\")\n\n    filtered_results = []\n    filtered_metadatas = []\n\n    for i in range(len(results)):\n        if value[i] <= threshold:\n            filtered_results.append(results[i])\n            if metadatas is not None:\n                filtered_metadatas.append(metadatas[i])\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n\n    if len(results) != len(value):\n        raise ValueError(\"The length of the results list must be the same as the length of the value list.\")\n\n    if len(results) != len(metadatas):\n        raise ValueError(\"The length of the results list must be the same as the length of the metadata list.\")\n\n    # Create a list containing the index of the results that meet the threshold criteria.\n    index_to_keep = [i for i, val in enumerate(value) if val <= threshold]\n\n    # Create a list containing the results that meet the threshold criteria.\n    filtered_results = [results[i] for i in index_to_keep]\n\n    # Create a list containing the metadata that meet the threshold criteria.\n    filtered_metadatas = [metadatas[i] for i in index_to_keep]\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if not isinstance(results, list) or not isinstance(value, list):\n        raise TypeError(\"The arguments must be lists.\")\n    if len(results) != len(value):\n        raise ValueError(\"The length of the two lists must be the same.\")\n    if metadatas is not None:\n        if not isinstance(metadatas, list):\n            raise TypeError(\"The metadatas argument must be a list.\")\n        if len(metadatas) != len(results):\n            raise ValueError(\"The length of the metadatas list must be the same as the length of the results list.\")\n    if threshold < 0:\n        raise ValueError(\"The threshold must be a positive number.\")\n\n    filtered_results = []\n    filtered_metadatas = []\n    for result, value, metadata in zip(results, value, metadatas):\n        if value <= threshold:\n            filtered_results.append(result)\n            filtered_metadatas.append(metadata)\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n\n    filtered_results = []\n    filtered_metadatas = []\n\n    for result, value, metadata in zip(results, value, metadatas):\n        if value <= threshold:\n            filtered_results.append(result)\n            filtered_metadatas.append(metadata)\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n\n    assert len(results) == len(value), \"The length of results and value must be the same.\"\n    assert len(results) == len(metadatas), \"The length of results and metadata must be the same.\"\n\n    filtered_results = []\n    filtered_metadatas = []\n\n    for result, value, metadata in zip(results, value, metadatas):\n        if value <= threshold:\n            filtered_results.append(result)\n            filtered_metadatas.append(metadata)\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n    assert len(results) == len(value) == len(metadatas), \"The length of the results, value, and metadata lists must be the same.\"\n    filtered_results = []\n    filtered_metadatas = []\n    for result, val, metadata in zip(results, value, metadatas):\n        if val <= threshold:\n            filtered_results.append(result)\n            filtered_metadatas.append(metadata)\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    # If no metadata is provided, create a list of None values.\n    if not metadatas:\n        metadatas = [None] * len(results)\n\n    # Create a list of tuples containing the results and their corresponding metadata.\n    result_tuples = list(zip(results, metadatas))\n\n    # Filter the result tuples based on the threshold.\n    filtered_result_tuples = [result_tuple for result_tuple in result_tuples if value <= threshold]\n\n    # If no results meet the threshold criteria, return empty lists.\n    if not filtered_result_tuples:\n        return [], []\n\n    # Otherwise, return the results and metadata.\n    return list(zip(*filtered_result_tuples))\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    # If no metadata is provided, create a list of Nones\n    if not metadatas:\n        metadatas = [None for _ in range(len(results))]\n\n    # Create a list of tuples containing each result, its corresponding value, and its corresponding metadata\n    result_list = list(zip(results, value, metadatas))\n\n    # Filter the list of tuples based on the threshold\n    filtered_result_list = [result for result in result_list if result[1] <= threshold]\n\n    # If no results meet the threshold criteria, return empty lists\n    if len(filtered_result_list) == 0:\n        return [], []\n\n    # Otherwise, return the filtered results and their corresponding metadata\n    filtered_results = [result[0] for result in filtered_result_list]\n    filtered_metadatas = [result[2] for result in filtered_result_list]\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if not results:\n        return [], []\n\n    if metadatas is None:\n        metadatas = [None] * len(results)\n\n    if len(results) != len(value) or len(results) != len(metadatas):\n        raise ValueError(\"The results, value and metadata lists must have the same length.\")\n\n    filtered_results = []\n    filtered_metadatas = []\n\n    for result, value, metadata in zip(results, value, metadatas):\n        if value <= threshold:\n            filtered_results.append(result)\n            filtered_metadatas.append(metadata)\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    # If no metadata is provided, create a list of None values.\n    if metadatas is None:\n        metadatas = [None] * len(results)\n\n    # Create a list of tuples containing the results, values, and metadata.\n    results_with_metadata = list(zip(results, value, metadatas))\n\n    # Filter the results by the threshold.\n    results_filtered = [result for result in results_with_metadata if result[1] <= threshold]\n\n    # If no results meet the threshold criteria, return empty lists.\n    if len(results_filtered) == 0:\n        return [], []\n\n    # Otherwise, return the filtered results and metadata.\n    return list(zip(*results_filtered))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"The input array does not have the shape (_, 2), indicating it does not represent a valid list of polygon points.\")\n\n    return 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if not isinstance(array, np.ndarray):\n        raise TypeError(\"Input array must be a numpy array.\")\n    if array.shape[1] != 2:\n        raise ValueError(\"Input array must have a shape of (_, 2).\")\n\n    area = 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n    return area\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"The input array must have the shape (_, 2), where _ can be any number of points.\")\n\n    return 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(f\"The input array must be of shape (_, 2). The input array has shape {array.shape}.\")\n\n    area = 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n    return area\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(f\"The input array must have a shape (_, 2), indicating a list of polygon points. The input array has a shape of {array.shape}.\")\n\n    return 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(f\"Input array must have the shape (_, 2), indicating a list of polygon points. Got {array.shape}.\")\n\n    area = 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n    return area\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"The input array must have the shape (_, 2), where _ can be any number of points.\")\n\n    # Calculate the area of the polygon using the shoelace formula\n    area = 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n    return area\n\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(f\"The input array must have shape (_, 2), indicating a list of polygon points. The input array has shape {array.shape}.\")\n\n    return 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if not isinstance(array, np.ndarray):\n        raise ValueError('Input array must be a numpy array')\n\n    if array.shape[1] != 2:\n        raise ValueError('Input array must be a 2-dimensional array')\n\n    area_value = 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n    return area_value\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"The input array does not have the shape (_, 2), indicating it does not represent a valid list of polygon points.\")\n\n    return 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"The input array must have the shape (_, 2).\")\n\n    return 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"The input array does not have the shape (_, 2), indicating it does not represent a valid list of polygon points.\")\n\n    # Calculate the area of the polygon\n    area = 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n    return area\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError('Input array must have shape (_, 2)')\n\n    area = 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n    return area\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"The input array must have shape (_, 2), where _ is any number of points.\")\n\n    # Compute the area of the polygon using the shoelace formula.\n    area = 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n    return area\n\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(f'The input array must have the shape (_, 2), indicating a list of polygon points. The input has the shape {array.shape}.')\n\n    x = array[:, 0]\n    y = array[:, 1]\n    area = 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))\n\n    return area\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"The input array must be a list of points with the shape (_, 2).\")\n\n    # Calculate the area of a simple polygon using the Shoelace formula.\n    return 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"The input array must be a list of points in the form (x, y).\")\n\n    x = array[:, 0]\n    y = array[:, 1]\n\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if not isinstance(array, np.ndarray):\n        raise TypeError(f\"Expected type np.ndarray for array, but got {type(array)} instead.\")\n\n    if array.shape[1] != 2:\n        raise ValueError(f\"Expected array of shape (_, 2), but got {array.shape} instead.\")\n\n    return 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    # Checking if the input is valid\n    if array.shape[1] != 2:\n        raise ValueError(\"The input array must have the shape (_, 2), where _ can be any number of points.\")\n\n    # Calculating the area of the polygon\n    return 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(f\"Input array must have shape (_, 2), not {array.shape}\")\n\n    # calculate the area of the polygon using the shoelace formula\n    area_value = 0.5 * np.abs(np.dot(array[:, 0], np.roll(array[:, 1], 1)) - np.dot(array[:, 1], np.roll(array[:, 0], 1)))\n\n    return area_value\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # Find the indices where elements of v should be inserted into a to maintain order.\n    idx_lo = torch.searchsorted(a, v, right=False)\n    idx_hi = torch.searchsorted(a, v, right=True)\n\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    assert a.ndim == v.ndim\n    assert a.shape[-1] == v.shape[-1]\n    assert a.shape[:-1] == v.shape[:-1]\n    assert a.is_cuda\n    assert v.is_cuda\n\n    # a = a.contiguous()\n    # v = v.contiguous()\n\n    # a = a.to(torch.float32)\n    # v = v.to(torch.float32)\n\n    # a = a.to(torch.int64)\n    # v = v.to(torch.int64)\n\n    # a = a.to(torch.int32)\n    # v = v.to(torch.int32)\n\n    # a = a.to(torch.int16)\n    # v = v.to(torch.int16)\n\n    # a = a.to(torch.int8)\n    # v = v.to(torch.int8)\n\n    # a = a.to(torch.uint8)\n    # v = v.to(torch.uint8)\n\n    # a = a.to(torch.int64)\n    # v = v.to(torch.int64)\n\n    # a = a.to(torch.int32)\n    # v = v.to(torch.int32)\n\n    # a = a.to(torch.int16)\n    # v = v.to(torch.int16)\n\n    # a = a.to(torch.int8)\n    # v = v.to(torch.int8)\n\n    # a = a.to(torch.uint8)\n    # v = v.to(torch.uint8)\n\n    # a = a.to(torch.int64)\n    # v = v.to(torch.int64)\n\n    # a = a.to(torch.int32)\n    # v = v."}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # a and v should be 1D tensors with the same number of dimensions\n    assert a.ndim == v.ndim\n\n    # a should be sorted\n    assert torch.all(a[1:] > a[:-1])\n\n    # a and v should have the same number of dimensions\n    assert a.ndim == v.ndim\n\n    # a and v should have the same number of elements in the last dimension\n    assert a.shape[-1] == v.shape[-1]\n\n    # a and v should have the same number of dimensions\n    assert a.ndim == v.ndim\n\n    # a should be sorted\n    assert torch.all(a[1:] > a[:-1])\n\n    # a and v should have the same number of dimensions\n    assert a.ndim == v.ndim\n\n    # a and v should have the same number of elements in the last dimension\n    assert a.shape[-1] == v.shape[-1]\n\n    # a and v should have the same number of dimensions\n    assert a.ndim == v.ndim\n\n    # a should be sorted\n    assert torch.all(a[1:] > a[:-1])\n\n    # a and v should have the same number of dimensions\n    assert a.ndim == v.ndim\n\n    # a and v should have the same number of elements in the last dimension\n    assert a.shape[-1] == v.shape[-1]\n\n    # a and v should have the same number of dimensions\n    assert a.ndim == v.ndim\n\n    # a should be sorted\n    assert torch.all(a[1:] > a[:-1])\n\n    # a and v should have the same number of dimensions\n    assert a.ndim == v.ndim\n\n    # a and v should have the same number of elements in the last dimension\n    assert a.shape[-1] == v.shape[-1]\n\n    # a and v should have the same number of dimensions\n    assert a.ndim == v.ndim\n\n    # a should be sorted\n    assert torch.all(a[1:]"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # a is a 1D tensor\n    # v is a 1D tensor\n\n    # a is sorted\n\n    # a and v have the same shape except for the last dimension\n\n    # idx_lo and idx_hi are 1D tensors\n\n    # idx_lo[i] <= i <= idx_hi[i]\n\n    # idx_lo[i] is the smallest index such that a[idx_lo[i]] <= v[i]\n\n    # idx_hi[i] is the smallest index such that a[idx_hi[i]] > v[i]\n\n    # idx_lo[i] = 0 if v[i] < a[0]\n\n    # idx_lo[i] = len(a) if v[i] > a[len(a) - 1]\n\n    # idx_hi[i] = 0 if v[i] < a[0]\n\n    # idx_hi[i] = len(a) if v[i] > a[len(a) - 1]\n\n    # idx_lo[i] = 0 if v[i] < a[0]\n\n    # idx_lo[i] = len(a) if v[i] > a[len(a) - 1]\n\n    # idx_lo[i] = 0 if v[i] < a[0]\n\n    # idx_lo[i] = len(a) if v[i] > a[len(a) - 1]\n\n    # idx_lo[i] = 0 if v[i] < a[0]\n\n    # idx_lo[i] = len(a) if v[i] > a[len(a) - 1]\n\n    # idx_lo[i] = 0 if v[i] < a[0]\n\n    # idx_lo[i] = len(a) if v[i] > a[len(a) - 1]\n\n    # idx_lo[i] = 0 if v[i] < a[0]\n\n    # idx_lo[i] = len(a)"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    assert torch.all(a.sort()[0] == a)\n    assert torch.all(a.unique().numel() == a.numel())\n    assert v.shape[-1] == a.shape[-1]\n\n    # Find the indices where elements of v should be inserted into a to maintain order.\n    idx_lo = a.searchsorted(v, side='left')\n    idx_hi = a.searchsorted(v, side='right')\n\n    # The indices may lie outside the range of a, in which case we need to adjust them.\n    idx_lo = torch.max(idx_lo, torch.zeros_like(idx_lo))\n    idx_hi = torch.min(idx_hi, torch.tensor([a.shape[-1]]).to(idx_hi))\n\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    a = a.to(v.dtype)\n    return torch.searchsorted(a, v, right=False), torch.searchsorted(a, v, right=True)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # a: shape = [..., N], v: shape = [..., M]\n    N = a.shape[-1]\n    M = v.shape[-1]\n    # mask: shape = [..., M]\n    mask = v >= a[..., -1:]\n    # idx_hi: shape = [..., M]\n    idx_hi = torch.full_like(v, N - 1, dtype=torch.long)\n    # idx_lo: shape = [..., M]\n    idx_lo = torch.full_like(v, 0, dtype=torch.long)\n    # mask_lo: shape = [..., M]\n    mask_lo = mask\n    # mask_hi: shape = [..., M]\n    mask_hi = mask\n    # mask_mid: shape = [..., M]\n    mask_mid = ~(mask_lo | mask_hi)\n    # mask_mid: shape = [..., M]\n    mask_mid = mask_mid & (v > a[..., :-1] + (a[..., 1:] - a[..., :-1]) / N)\n    # mask_mid: shape = [..., M]\n    mask_mid = mask_mid & (v < a[..., 1:] + (a[..., 1:] - a[..., :-1]) / N)\n    # mask_mid: shape = [..., M]\n    mask_mid = mask_mid | (mask_lo & mask_hi)\n    # idx_hi: shape = [..., M]\n    idx_hi = torch.where(mask_hi, idx_hi, torch.sum(mask_mid.int(), dim=-1))\n    # idx_lo: shape = [..., M]\n    idx_lo = torch.where(mask_lo, idx_lo, torch.sum(mask_mid.int(), dim=-1) - 1)\n    # idx_hi: shape = [..., M]\n    idx_hi = torch.where(mask_mid, idx_hi, idx_lo + 1)\n    # idx_lo: shape = [..., M]\n    idx_lo = torch."}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    idx_lo = torch.searchsorted(a, v, right=False)\n    idx_hi = torch.searchsorted(a, v, right=True)\n\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    assert torch.all(a.sort()[0] == a), \"Input tensor a must be sorted in ascending order.\"\n    assert a.ndim == v.ndim, \"Input tensors a and v must have the same number of dimensions.\"\n    assert a.shape[:-1] == v.shape[:-1], \"All dimensions except the last dimension of input tensors a and v must be compatible.\"\n    assert v.shape[-1] == 1, \"The last dimension of input tensor v must have length 1.\"\n    assert a.ndim > 1, \"Input tensors a and v must have at least two dimensions.\"\n\n    # For each element in v, find the first index in a where the element could be inserted while maintaining the sorted order.\n    idx_lo = torch.searchsorted(a, v, right=False)\n    # For each element in v, find the last index in a where the element could be inserted while maintaining the sorted order.\n    idx_hi = torch.searchsorted(a, v, right=True)\n\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    if a.ndim != v.ndim:\n        raise ValueError(\"The number of dimensions of a and v should be the same.\")\n\n    if a.shape[-1] != v.shape[-1]:\n        raise ValueError(\"The last dimension of a and v should be the same.\")\n\n    if a.ndim == 1:\n        # deal with 1D case\n        idx_lo = torch.zeros_like(v, dtype=torch.long)\n        idx_hi = torch.zeros_like(v, dtype=torch.long)\n        for i in range(len(v)):\n            idx_lo[i] = torch.searchsorted(a, v[i], right=False)\n            idx_hi[i] = torch.searchsorted(a, v[i], right=True)\n        return idx_lo, idx_hi\n\n    # deal with higher-order case\n    idx_lo = torch.searchsorted(a, v, right=False)\n    idx_hi = torch.searchsorted(a, v, right=True)\n\n    # deal with edge case\n    idx_hi[idx_hi >= a.shape[-1]] = a.shape[-1]\n    idx_lo[idx_lo >= a.shape[-1]] = a.shape[-1]\n\n    # deal with edge case\n    idx_hi[idx_lo == a.shape[-1]] = a.shape[-1]\n    idx_lo[idx_lo == a.shape[-1]] = a.shape[-1]\n\n    # deal with edge case\n    idx_lo[idx_lo < 0] = 0\n    idx_hi[idx_hi < 0] = 0\n\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # a: (n,)\n    # v: (m,)\n    # idx_lo: (m,)\n    # idx_hi: (m,)\n    assert a.ndim == v.ndim == 1\n    assert a.shape[0] >= v.shape[0]\n    assert torch.all(a.sort()[0] == a)\n    assert torch.all(v.sort()[0] == v)\n    idx_lo = torch.searchsorted(a, v, right=False)\n    idx_hi = torch.searchsorted(a, v, right=True)\n    idx_lo[idx_lo > 0] -= 1\n    idx_hi[idx_hi < a.shape[0]] += 1\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    assert torch.all(a[:-1] <= a[1:])\n\n    device = a.device\n\n    # a is a 1-D tensor\n    # v is a tensor of shape (*, D)\n    # return values are two tensors of shape (*, D)\n\n    m = a.shape[0]\n    n = v.shape[0]\n\n    # initialize idx_lo and idx_hi as idx_lo = 0 and idx_hi = m\n    idx_lo = torch.zeros(n, dtype=torch.long, device=device)\n    idx_hi = (m - 1) * torch.ones(n, dtype=torch.long, device=device)\n\n    for i in range(m):\n        idx_lo += (a[i] >= v[..., i:i + 1])\n        idx_hi -= (a[i] < v[..., i:i + 1])\n\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # a should be sorted, but check just to make sure\n    assert torch.all(a[..., 1:] > a[..., :-1]).item(), \"a should be sorted in increasing order\"\n    assert a.ndim == v.ndim, \"a and v should have the same number of dimensions\"\n    assert a.shape[-1] == v.shape[-1], \"the last dimension of a and v should be the same\"\n    assert a.shape[:-1] == v.shape[:-1], \"the first dimensions of a and v should be the same\"\n    # create idx_lo and idx_hi, which will be the output tensors\n    idx_lo = torch.searchsorted(a, v, right=False)\n    idx_hi = torch.searchsorted(a, v, right=True)\n    # if v is out of bounds, change idx_lo and idx_hi accordingly\n    idx_lo[v < a[..., 0]] = 0\n    idx_hi[v >= a[..., -1]] = a.shape[-1]\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # get the shape of the input tensors\n    v_shape = v.shape\n    a_shape = a.shape\n\n    # reshape the tensors for easier computation\n    v = v.view(-1, 1)\n    a = a.view(-1)\n\n    # get the indices where v should be inserted into a\n    idx_lo = torch.searchsorted(a, v, right=False)\n    idx_hi = torch.searchsorted(a, v, right=True)\n\n    # get the indices where v should be inserted into a, but not including a itself\n    idx_lo = torch.clip(idx_lo - 1, min=0)\n    idx_hi = torch.clip(idx_hi, max=a_shape[-1] - 1)\n\n    # reshape the output tensors to the original shapes\n    idx_lo = idx_lo.reshape(v_shape)\n    idx_hi = idx_hi.reshape(v_shape)\n\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # If a is empty, then v should be inserted before the first element.\n    if a.numel() == 0:\n        return torch.zeros_like(v), torch.zeros_like(v)\n\n    # If v is empty, then no element of v can be inserted into a.\n    if v.numel() == 0:\n        return torch.zeros_like(v), torch.zeros_like(v)\n\n    # If v is a singleton, then it should be inserted into a before the first element of a which is at index 0, or after the last element of a which is at index -1.\n    if v.ndim == 0:\n        if v.item() <= a[0].item():\n            return torch.tensor(0), torch.tensor(0)\n        elif v.item() > a[-1].item():\n            return torch.tensor(-1), torch.tensor(-1)\n        else:\n            return torch.tensor(0), torch.tensor(0)\n\n    # If v is multidimensional, then we recursively call searchsorted on the first dimension of v and a.\n    if v.ndim > 1:\n        return searchsorted(a.view(-1), v.view(-1))\n\n    # If v is a vector, then we use torch.searchsorted to find the indices where elements of v can be inserted into a to maintain order.\n    idx_lo = torch.searchsorted(a, v, right=False)\n    idx_hi = torch.searchsorted(a, v, right=True)\n\n    # If an element of v is less than or equal to the first element of a, then it should be inserted at index 0.\n    idx_lo[v <= a[0]] = 0\n\n    # If an element of v is greater than the last element of a, then it should be inserted at index -1.\n    idx_hi[v >= a[-1]] = len(a)\n\n    # If an element of v is between two elements of a, then it should be inserted between those two elements.\n    idx_"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # The input tensors should be of the same shape, except for the last dimension.\n    assert a.shape[:-1] == v.shape[:-1]\n\n    # The last dimension of a must be at least 1.\n    assert a.shape[-1] >= 1\n\n    # The last dimension of v must be at least 1.\n    assert v.shape[-1] >= 1\n\n    # The last dimension of a and v must be equal, except for the case where v is a single point.\n    if v.shape[-1] == 1:\n        assert a.shape[-1] >= 1\n    else:\n        assert a.shape[-1] == v.shape[-1]\n\n    # The output tensors will be the same shape as v, except for the last dimension, which will be the same as that of a.\n    idx_lo = torch.zeros_like(v)\n    idx_hi = torch.zeros_like(v)\n\n    # We will use a for loop to process the last dimension of a and v one by one.\n    for i in range(v.shape[-1]):\n\n        # If v is a single point, then the indices will be either 0 or a.shape[-1] - 1.\n        if v.shape[-1] == 1:\n            idx_lo[:, i] = 0\n            idx_hi[:, i] = a.shape[-1] - 1\n            continue\n\n        # If v[i] is less than a[0], then idx_lo[i] will be 0 and idx_hi[i] will be 0.\n        if v[..., i] < a[..., 0]:\n            idx_lo[..., i] = 0\n            idx_hi[..., i] = 0\n            continue\n\n        # If v[i] is greater than a[-1], then idx_lo[i] will be a.shape[-1] - 1 and idx_hi[i] will be a.shape[-1] - 1.\n        if v[..., i] > a[..., -1]:\n            idx_lo[...,"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # a is assumed to be sorted in increasing order, while v is the set of query points that need to be inserted into a.\n    assert torch.all(a[..., 1:] > a[..., :-1])\n    assert v.shape[-1] == a.shape[-1]\n    # get the shape of the input tensors\n    shape = [*v.shape, *a.shape]\n    # initialize the output tensors\n    idx_lo = torch.zeros(shape[:-1], dtype=torch.long, device=a.device)\n    idx_hi = torch.zeros(shape[:-1], dtype=torch.long, device=a.device)\n    # iterate over the last dimension of v\n    for i in range(v.shape[-1]):\n        idx_lo[..., i] = torch.searchsorted(a[..., i], v[..., i], right=False)\n        idx_hi[..., i] = torch.searchsorted(a[..., i], v[..., i], right=True)\n    # if any element in v is out of the range of a, set the corresponding idx_lo and idx_hi to either the first or last index of a\n    idx_lo[v[..., -1] > a[..., -1]] = a.shape[-1]\n    idx_hi[v[..., -1] < a[..., -1]] = a.shape[-1]\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    # a: shape [n, d]\n    # v: shape [m, d]\n    # idx_lo: shape [m, d]\n    # idx_hi: shape [m, d]\n\n    # https://github.com/pytorch/pytorch/issues/34208\n    # https://discuss.pytorch.org/t/searchsorted-with-n-dimensional-input/111286\n    # https://github.com/pytorch/pytorch/issues/34208\n\n    assert a.ndim == v.ndim\n    assert a.ndim >= 1\n\n    # find the indices where elements of v should be inserted into a to maintain order\n    # idx_lo is the index of the first element of a greater than or equal to v\n    # idx_hi is the index of the first element of a greater than v\n    # if an element in v is out of the range of a, both idx_lo and idx_hi will point to either the first or last index of a\n    idx_lo = a.searchsorted(v, side='left')\n    idx_hi = a.searchsorted(v, side='right')\n\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    assert a.ndim == v.ndim\n    assert a.shape[:-1] == v.shape[:-1]\n\n    # If a and v are empty, return empty tensors.\n    if a.numel() == 0 or v.numel() == 0:\n        return torch.zeros_like(v), torch.zeros_like(v)\n\n    # If v is a scalar, the result is simple.\n    if v.ndim == 0:\n        return torch.searchsorted(a, v, right=False), torch.searchsorted(a, v, right=True)\n\n    # If a is a scalar, use the same logic as the scalar case.\n    if a.ndim == 0:\n        return searchsorted(torch.tensor([a]), v)\n\n    # If v is a vector, we use torch.searchsorted.\n    if v.ndim == 1:\n        return torch.searchsorted(a, v, right=False), torch.searchsorted(a, v, right=True)\n\n    # If v is a matrix, we use torch.searchsorted for each row.\n    if v.ndim == 2:\n        return torch.searchsorted(a, v, right=False), torch.searchsorted(a, v, right=True)\n\n    # If v is a tensor with 3 or more dimensions, we use torch.searchsorted for each slice along the last dimension.\n    # We use torch.searchsorted to find the indices where each slice in v can be inserted into a to maintain order.\n    # The indices represent the lower and upper bounds where each slice in v can be inserted into a.\n    # The shape of the output tensors is the same as that of v.\n    idx_lo = torch.searchsorted(a, v, right=False)\n    idx_hi = torch.searchsorted(a, v, right=True)\n\n    # If an element in v is out of the range of a, we change the corresponding indices to either the first or last index of a.\n    # idx_lo and idx_hi will point to"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    assert torch.all(a[:-1] <= a[1:]), \"The tensor a should be sorted in ascending order.\"\n    assert torch.all(a[..., -1] >= a[..., :-1]), \"The tensor a should be sorted in ascending order.\"\n    assert a.ndim == v.ndim or a.ndim == v.ndim - 1, \"The number of dimensions of the tensor a should be either one less or equal to that of the tensor v.\"\n    assert a.shape[-1] == v.shape[-1], \"The last dimension of the tensor a should be the same as that of the tensor v.\"\n    assert a.shape[:-1] == v.shape[:-1], \"The first dimensions of the tensor a should be the same as that of the tensor v.\"\n\n    # get the indices where v should be inserted into a to maintain order\n    idx_lo = torch.searchsorted(a, v, right=False)\n    idx_hi = torch.searchsorted(a, v, right=True)\n\n    # if an element in v is out of the range of a, idx_lo and idx_hi will be out of range\n    out_of_range = idx_lo == a.shape[-1]\n    idx_lo[out_of_range] = 0\n    idx_hi[out_of_range] = 1\n\n    # if an element in v is equal to an element in a, idx_lo and idx_hi will be equal\n    idx_lo[idx_lo == idx_hi] = idx_lo[idx_lo == idx_hi] - 1\n    idx_hi[idx_lo == idx_hi] = idx_hi[idx_lo == idx_hi]\n\n    return idx_lo, idx_hi\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]], dtype=float)\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  # Generate the intrinsic matrix.\n  intrinsic_matrix = xnp.array([\n      [fx, 0.0, cx],\n      [0.0, fy, cy],\n      [0.0, 0.0, 1.0],\n  ])\n\n  # Return the intrinsic matrix.\n  return intrinsic_matrix\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([\n      [fx, 0.0, cx],\n      [0.0, fy, cy],\n      [0.0, 0.0, 1.0],\n  ])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array(\n      [\n          [fx, 0, cx],\n          [0, fy, cy],\n          [0, 0, 1],\n      ]\n  )\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx],\n                    [0, fy, cy],\n                    [0, 0, 1]], dtype=np.float32)\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx],\n                    [0, fy, cy],\n                    [0, 0, 1]])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0.0, cx], [0.0, fy, cy], [0.0, 0.0, 1.0]])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0.0, cx], [0.0, fy, cy], [0.0, 0.0, 1.0]])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]], dtype=float)\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  # Create an identity matrix\n  K = xnp.eye(3)\n  # Set the values of the identity matrix to the provided values\n  K[0, 0] = fx\n  K[1, 1] = fy\n  K[0, 2] = cx\n  K[1, 2] = cy\n  # Return the intrinsic matrix\n  return K\n\n"}
{"namespace": "coord.contract", "completion": "  return x / jnp.sqrt(jnp.sum(x ** 2, axis=-1, keepdims=True))\n\n"}
{"namespace": "coord.contract", "completion": "  return x / jnp.sqrt(jnp.sum(x ** 2, axis=-1, keepdims=True))\n\n"}
{"namespace": "coord.contract", "completion": "  return jnp.sqrt(1 + x**2)\n\n"}
{"namespace": "coord.contract", "completion": "  return x * jnp.sqrt(1.0 - x.dot(x) / (1.0 + x.dot(x)))\n\n"}
{"namespace": "coord.contract", "completion": "  return x / jnp.sqrt(1 + jnp.sum(x * x, axis=-1, keepdims=True))\n\n"}
{"namespace": "coord.contract", "completion": "  return x / jnp.sqrt(jnp.sum(x ** 2, axis=-1, keepdims=True))\n\n"}
{"namespace": "coord.contract", "completion": "  return x / jnp.sqrt(jnp.sum(x * x, axis=-1, keepdims=True))\n\n"}
{"namespace": "coord.contract", "completion": "  x_magnitude_squared = jnp.sum(x**2, axis=-1, keepdims=True)\n  return x * jnp.sqrt(1.0 / x_magnitude_squared)\n\n"}
{"namespace": "coord.contract", "completion": "  x_mag_sq = jnp.sum(x * x, axis=-1, keepdims=True)\n  x_mag = jnp.sqrt(x_mag_sq)\n  x_mag_sq_inv = 1.0 / x_mag_sq\n  x_mag_inv = 1.0 / x_mag\n  x_scaled = x * x_mag_sq_inv\n  x_scaled = jnp.where(x_mag > 1.0, x_scaled, x)\n  return x_scaled\n\n"}
{"namespace": "coord.contract", "completion": "  return x * (1 - jnp.sqrt(1 - jnp.sum(x * x, axis=-1, keepdims=True)))\n\n"}
{"namespace": "coord.contract", "completion": "  return x / jnp.sqrt(jnp.sum(x ** 2, axis=-1, keepdims=True))\n\n"}
{"namespace": "coord.contract", "completion": "  return x / jnp.sqrt(1 + jnp.sum(x ** 2, axis=-1, keepdims=True))\n\n"}
{"namespace": "coord.contract", "completion": "  x = jnp.array(x)\n  x_magnitude_squared = jnp.sum(x * x, axis=-1, keepdims=True)\n  x_scaled = x * jnp.sqrt(x_magnitude_squared / (x_magnitude_squared + 1))\n  return x_scaled\n\n"}
{"namespace": "coord.contract", "completion": "  # Contract points towards the origin.\n  x = x * jnp.sqrt(1.0 / jnp.sum(x ** 2, axis=-1, keepdims=True))\n\n  return x\n\n"}
{"namespace": "coord.contract", "completion": "  x_mag_sq = jnp.sum(x ** 2, axis=-1, keepdims=True)\n  x_mag_sq_inv = 1.0 / jnp.sqrt(x_mag_sq)\n  x_contracted = x * x_mag_sq_inv\n  return x_contracted\n\n"}
{"namespace": "coord.contract", "completion": "  return x / jnp.sqrt(jnp.sum(x * x, axis=-1, keepdims=True))\n\n"}
{"namespace": "coord.contract", "completion": "  return x / jnp.sqrt(1 + jnp.sum(x * x, axis=-1, keepdims=True))\n\n"}
{"namespace": "coord.contract", "completion": "  return x / jnp.sqrt(jnp.sum(x ** 2, axis=-1, keepdims=True))\n\n"}
{"namespace": "coord.contract", "completion": "  return x / jnp.sqrt(jnp.sum(x**2, axis=-1, keepdims=True))\n\n"}
{"namespace": "coord.contract", "completion": "  # Calculate the magnitude squared of the input points.\n  x_mag_sq = jnp.sum(x**2, axis=-1, keepdims=True)\n\n  # Scale the magnitude of the points by a factor such that points within a unit distance from the origin are scaled correctly.\n  x_scaled = x * jnp.sqrt(x_mag_sq / (1.0 + x_mag_sq))\n\n  return x_scaled\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"b\", \"kb\", \"mb\", \"gb\", \"tb\", \"pb\"]:\n        if abs(num_bytes) < 1024.0:\n            return f\"{num_bytes:3.1f}{unit}\"\n        num_bytes /= 1024.0\n    raise ValueError(\"Number is too large\")\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    num_bytes = float(num_bytes)\n    magnitude = 0\n    while abs(num_bytes) >= 1000 and magnitude <= 5:\n        magnitude += 1\n        num_bytes /= 1000.0\n    return f\"{num_bytes:.2f}{['', 'K', 'M', 'G', 'T', 'P'][magnitude]}\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"b\", \"kb\", \"mb\", \"gb\", \"tb\", \"pb\"]:\n        if abs(num_bytes) < 1024.0:\n            return f\"{num_bytes:3.1f}{unit}\"\n        num_bytes /= 1024.0\n    raise ValueError(f\"Number is too big: {num_bytes}\")\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    num_bytes = float(num_bytes)\n    if num_bytes < 0:\n        raise ValueError(\"Number of bytes must be non-negative.\")\n    elif num_bytes == 0:\n        return \"0B\"\n\n    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if abs(num_bytes) < 1000.0:\n            return f\"{num_bytes:3.1f}{unit}\"\n        num_bytes /= 1000.0\n\n    return f\"{num_bytes:.1f}PB\"\n\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    # Convert the number of bytes to a human-readable format.\n    for unit in [\"b\", \"kb\", \"mb\", \"gb\", \"tb\", \"pb\"]:\n        if abs(num_bytes) < 1000.0:\n            return f\"{num_bytes:3.1f}{unit}\"\n        num_bytes /= 1000.0\n    raise ValueError(f\"The number of bytes is too large: {num_bytes}\")\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    # Convert the number of bytes into the appropriate unit.\n    for unit in [\"b\", \"kb\", \"mb\", \"gb\", \"tb\", \"pb\"]:\n        if abs(num_bytes) < 1000.0:\n            return f\"{num_bytes:3.1f}{unit}\"\n        num_bytes /= 1000.0\n    raise ValueError(\"Number is too large.\")\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"b\", \"kb\", \"mb\", \"gb\", \"tb\", \"pb\"]:\n        if abs(num_bytes) < 1024.0:\n            return f\"{num_bytes:3.1f}{unit}\"\n        num_bytes /= 1024.0\n    return f\"{num_bytes:.1f}{unit}\"\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    if num_bytes < 0:\n        raise ValueError(\"Number of bytes must be greater than or equal to 0.\")\n\n    if num_bytes == 0:\n        return \"0B\"\n\n    num_bytes_float = float(num_bytes)\n\n    if num_bytes_float < 1024:\n        return f\"{num_bytes_float}B\"\n\n    num_bytes_float /= 1024\n\n    if num_bytes_float < 1024:\n        return f\"{num_bytes_float:.1f}KB\"\n\n    num_bytes_float /= 1024\n\n    if num_bytes_float < 1024:\n        return f\"{num_bytes_float:.1f}MB\"\n\n    num_bytes_float /= 1024\n\n    if num_bytes_float < 1024:\n        return f\"{num_bytes_float:.1f}GB\"\n\n    num_bytes_float /= 1024\n\n    if num_bytes_float < 1024:\n        return f\"{num_bytes_float:.1f}TB\"\n\n    num_bytes_float /= 1024\n\n    return f\"{num_bytes_float:.1f}PB\"\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    if num_bytes < 0:\n        raise ValueError(\"Number of bytes can't be negative.\")\n    elif num_bytes == 0:\n        return \"0B\"\n    else:\n        for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n            if abs(num_bytes) < 1000.0:\n                return f\"{num_bytes:.1f}{unit}\"\n            num_bytes /= 1000.0\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    num_bytes = float(num_bytes)\n    unit_list = [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]\n    if num_bytes == 1:\n        return \"1 B\"\n    if num_bytes < 1:\n        raise ValueError(\"Number of bytes must be greater than 0\")\n\n    for i in range(len(unit_list)):\n        unit = unit_list[i]\n        if num_bytes >= 1000:\n            num_bytes /= 1000\n        else:\n            break\n    return f\"{num_bytes:.2f} {unit}\"\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    if num_bytes < 1024:\n        return f\"{num_bytes}B\"\n    elif num_bytes < 1024 ** 2:\n        return f\"{num_bytes / 1024}KB\"\n    elif num_bytes < 1024 ** 3:\n        return f\"{num_bytes / 1024 / 1024}MB\"\n    elif num_bytes < 1024 ** 4:\n        return f\"{num_bytes / 1024 / 1024 / 1024}GB\"\n    elif num_bytes < 1024 ** 5:\n        return f\"{num_bytes / 1024 / 1024 / 1024 / 1024}TB\"\n    elif num_bytes < 1024 ** 6:\n        return f\"{num_bytes / 1024 / 1024 / 1024 / 1024 / 1024}PB\"\n    else:\n        return f\"{num_bytes / 1024 / 1024 / 1024 / 1024 / 1024 / 1024}EB\"\n\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"b\", \"kb\", \"mb\", \"gb\", \"tb\", \"pb\"]:\n        if abs(num_bytes) < 1024.0:\n            return f\"{num_bytes:3.1f}{unit}\"\n        num_bytes /= 1024.0\n    raise ValueError(f\"The number of bytes is too large to be converted into a human-readable format.\")\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if abs(num_bytes) < 1024.0:\n            return f\"{num_bytes:3.1f}{unit}\"\n        num_bytes /= 1024.0\n    raise ValueError(\"Value is too large to be converted into human-readable format\")\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    num_bytes = float(num_bytes)\n    magnitude = int(math.floor(math.log(num_bytes, 1000)))\n    if magnitude < 0 or magnitude > len(_FORMAT_TO_RATIO.keys()):\n        raise ValueError(f\"The supported units are {_FORMAT_TO_RATIO.keys()}\")\n\n    return f\"{float(num_bytes) / (1000 ** magnitude):.2f}{['B', 'KB', 'MB', 'GB', 'TB', 'PB'][magnitude]}\"\n\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    num_bytes = float(num_bytes)\n    magnitude = int(math.floor(math.log(num_bytes, 1000)))\n    if magnitude <= 0:\n        return f\"{num_bytes} B\"\n    elif magnitude > 1:\n        suffix = \"KB\"\n    else:\n        suffix = \"B\"\n    num_bytes = float(num_bytes) / (1000 ** magnitude)\n    return f\"{num_bytes:.2f} {suffix}\"\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    # If the number of bytes is less than 1000, return a string of the form \"<num> B\"\n    if num_bytes < 1000:\n        return f\"{num_bytes} B\"\n    # If the number of bytes is at least 1000 but less than 1,000,000, return a string of the form \"<num> KB\"\n    elif 1000 <= num_bytes < 1000000:\n        return f\"{num_bytes / 1000} KB\"\n    # If the number of bytes is at least 1,000,000 but less than 1,000,000,000, return a string of the form \"<num> MB\"\n    elif 1000000 <= num_bytes < 1000000000:\n        return f\"{num_bytes / 1000000} MB\"\n    # If the number of bytes is at least 1,000,000,000 but less than 1,000,000,000,000, return a string of the form \"<num> GB\"\n    elif 1000000000 <= num_bytes < 1000000000000:\n        return f\"{num_bytes / 1000000000} GB\"\n    # If the number of bytes is at least 1,000,000,000,000 but less than 1,000,000,000,000,000, return a string of the form \"<num> TB\"\n    elif 1000000000000 <= num_bytes < 1000000000000000:\n        return f\"{num_bytes / 1000000000000} TB\"\n    # If the number of bytes is at least 1"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    if num_bytes == 0:\n        return \"0B\"\n    if num_bytes < 0:\n        raise ValueError(\"Number cannot be negative\")\n    units = [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]\n    size = 1024.0\n    for i in range(len(units) - 1):\n        if (num_bytes / size) < 1:\n            return f\"{num_bytes:.2f}{units[i]}\"\n        num_bytes /= size\n    return f\"{num_bytes:.2f}{units[-1]}\"\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"b\", \"kb\", \"mb\", \"gb\", \"tb\", \"pb\"]:\n        if abs(num_bytes) < 1024.0:\n            return f\"{num_bytes:3.1f}{unit}\"\n        num_bytes /= 1024.0\n    return f\"{num_bytes:3.1f}{unit}\"\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    num_bytes = float(num_bytes)\n    if num_bytes < 0:\n        raise ValueError(\"Only positive values are supported.\")\n    elif num_bytes == 0:\n        return \"0B\"\n    else:\n        for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n            if num_bytes < 1000.0:\n                return f\"{num_bytes:.1f}{unit}\"\n            num_bytes /= 1000.0\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    if num_bytes < 0:\n        raise ValueError(\"Only positive numbers supported\")\n    elif num_bytes == 0:\n        return \"0B\"\n    else:\n        num_bytes = float(num_bytes)\n        units = list(_FORMAT_TO_RATIO.keys())\n        for unit in units[:-1]:\n            if num_bytes < 1000:\n                return f\"{num_bytes:.2f}{unit}\"\n            num_bytes /= 1000\n        return f\"{num_bytes:.2f}{units[-1]}\"\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"\n        This function checks if a given array has a specific number of dimensions. It is designed to be used within Pydantic models to validate the dimensions of array fields.\n\n        Input-Output Arguments\n        :param cls: Type. The class of the model being validated.\n        :param v: np.ndarray. The array being validated.\n        :param field: fields.ModelField. The field of the model that is being validated.\n        :return: np.ndarray. The validated array if it meets the specified number of dimensions.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. Received {v.shape}.\"\n            )\n\n        return v\n\n    return _is_array_n_dimensions\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"\n        This function checks if a given array has a specific number of dimensions. It is designed to be used within Pydantic models to validate the dimensions of array fields.\n\n        Input-Output Arguments\n        :param cls: Type. The class of the model being validated.\n        :param v: np.ndarray. The array being validated.\n        :param field: fields.ModelField. The field of the model that is being validated.\n        :return: np.ndarray. The validated array if it meets the specified number of dimensions.\n        \"\"\"\n\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. Received {len(v.shape)} dimensions.\"\n            )\n\n        return v\n\n    return _is_array_n_dimensions\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"\n        This function checks if a given array has a specific number of dimensions. It is designed to be used within Pydantic models to validate the dimensions of array fields.\n\n        Input-Output Arguments\n        :param cls: Type. The class of the model being validated.\n        :param v: np.ndarray. The array being validated.\n        :param field: fields.ModelField. The field of the model that is being validated.\n        :return: np.ndarray. The validated array if it meets the specified number of dimensions.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. Received {v.shape}.\"\n            )\n\n        return v\n\n    return _is_array_n_dimensions\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n\n        return v\n\n    return _validator\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def is_array_n_dimensions_(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check that the array has the specified number of dimensions.\n\n        Args:\n            cls (type): Class type.\n            v (np.ndarray): Value to check.\n            field (fields.ModelField): Field descriptor.\n\n        Raises:\n            ValueError: Exception raised if array doesn't have the specified number of dimensions.\n\n        Returns:\n            np.ndarray: `v` sent for further processing.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. Received {v.shape}\"\n            )\n\n        return v\n\n    return is_array_n_dimensions_\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. Received {v.shape}.\"\n            )\n\n        return v\n\n    return _validator\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def is_array_n_dimensions_validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"\n        This function checks if a given array has a specific number of dimensions. It is designed to be used within Pydantic models to validate the dimensions of array fields.\n\n        Input-Output Arguments\n        :param cls: Type. The class of the model being validated.\n        :param v: np.ndarray. The array being validated.\n        :param field: fields.ModelField. The field of the model that is being validated.\n        :return: np.ndarray. The validated array if it meets the specified number of dimensions.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. Received {v.shape}.\"\n            )\n\n        return v\n\n    return is_array_n_dimensions_validator\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"\n        This function checks if a given array has a specific number of dimensions. It is designed to be used within Pydantic models to validate the dimensions of array fields.\n\n        Input-Output Arguments\n        :param cls: Type. The class of the model being validated.\n        :param v: np.ndarray. The array being validated.\n        :param field: fields.ModelField. The field of the model that is being validated.\n        :return: np.ndarray. The validated array if it meets the specified number of dimensions.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. Got {len(v.shape)}.\")\n\n        return v\n\n    return _is_array_n_dimensions"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def is_array_n_dimensions_validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"\n        This function checks if a given array has a specific number of dimensions. It is designed to be used within Pydantic models to validate the dimensions of array fields.\n\n        Input-Output Arguments\n        :param cls: Type. The class of the model being validated.\n        :param v: np.ndarray. The array being validated.\n        :param field: fields.ModelField. The field of the model that is being validated.\n        :return: np.ndarray. The validated array if it meets the specified number of dimensions.\n        \"\"\"\n\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. Received {v.shape}\"\n            )\n\n        return v\n\n    return is_array_n_dimensions_validator\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check that array has n dimensions.\n\n        Args:\n            cls (type): Class type.\n            v (np.ndarray): Value to check.\n            field (fields.ModelField): Field descriptor.\n\n        Raises:\n            ValueError: Exception raised if array doesn't have nb_dimensions dimensions.\n\n        Returns:\n            np.ndarray: `v` sent for further processing.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. Received {v.shape}\"\n            )\n\n        return v\n\n    return _is_array_n_dimensions\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check that the array has the specified number of dimensions.\n\n        Args:\n            cls (type): Class type.\n            v (np.ndarray): Value to check.\n            field (fields.ModelField): Field descriptor.\n\n        Raises:\n            ValueError: Exception raised if number of dimensions isn't equal to `nb_dimensions`.\n\n        Returns:\n            np.ndarray: `v` sent for further processing.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. Received {v.shape}\"\n            )\n\n        return v\n\n    return _is_array_n_dimensions\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def is_array_n_dimensions_validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"\n        This function checks if a given array has a specific number of dimensions. It is designed to be used within Pydantic models to validate the dimensions of array fields.\n\n        Input-Output Arguments\n        :param cls: Type. The class of the model being validated.\n        :param v: np.ndarray. The array being validated.\n        :param field: fields.ModelField. The field of the model that is being validated.\n        :return: np.ndarray. The validated array if it meets the specified number of dimensions.\n        \"\"\"\n\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n\n        return v\n\n    return is_array_n_dimensions_validator\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. Received array of shape {v.shape}\"\n            )\n\n        return v\n\n    return _is_array_n_dimensions\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if v.ndim != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions, got {v.ndim}.\"\n            )\n\n        return v\n\n    return _is_array_n_dimensions\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"\n        This function checks if a given array has a specific number of dimensions.\n\n        Input-Output Arguments\n        :param cls: Type. The class of the model being validated.\n        :param v: np.ndarray. The array being validated.\n        :param field: fields.ModelField. The field of the model that is being validated.\n        :return: np.ndarray. The validated array if it meets the specified number of dimensions.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n\n        return v\n\n    return _validator\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"\n        This function validates the dimensionality of an array.\n\n        Input-Output Arguments\n        :param cls: Type. The class of the model being validated.\n        :param v: np.ndarray. The array being validated.\n        :param field: fields.ModelField. The field of the model that is being validated.\n        :return: np.ndarray. The validated array if it meets the specified number of dimensions.\n        \"\"\"\n\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. Received {v.shape}.\"\n            )\n\n        return v\n\n    return _validator\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def is_array_n_dimensions_validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check that array has the specified number of dimensions.\n\n        Args:\n            cls (type): Class type.\n            v (np.ndarray): Value to check.\n            field (fields.ModelField): Field descriptor.\n\n        Raises:\n            ValueError: Exception raised if array doesn't have the specified number of dimensions.\n\n        Returns:\n            np.ndarray: `v` sent for further processing.\n        \"\"\"\n        if v.ndim != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. Got {v.ndim}\")\n\n        return v\n\n    return is_array_n_dimensions_validator\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"\n        This function checks if a given array has a specific number of dimensions. It is designed to be used within Pydantic models to validate the dimensionality of array fields.\n\n        Input-Output Arguments\n        :param cls: Type. The class of the model being validated.\n        :param v: np.ndarray. The array being validated.\n        :param field: fields.ModelField. The field of the model that is being validated.\n        :return: np.ndarray. The validated array if it meets the specified number of dimensions.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. \"\n                f\"Got {len(v.shape)} dimensions.\"\n            )\n\n        return v\n\n    return _is_array_n_dimensions\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def is_array_n_dimensions_validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check that the array has the specified number of dimensions.\"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f'{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. Received {len(v.shape)} dimensions.'\n            )\n\n        return v\n\n    return is_array_n_dimensions_validator\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must be an array with {nb_dimensions} dimensions.\"\n            )\n\n        return v\n\n    return _is_array_n_dimensions\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n\n  r = jnp.sqrt(x**2 + y**2 + z**2)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n  r = jnp.sqrt(x**2 + y**2 + z**2)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n  r = jnp.sqrt(x**2 + y**2 + z**2)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n\n  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n\n  r = jnp.sqrt(x ** 2 + y ** 2 + z ** 2)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n\n  r = jnp.sqrt(x**2 + y**2 + z**2)\n\n  theta = jnp.arccos(z / (r + eps))\n\n  phi = jnp.arctan2(y, x)\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = jnp.split(cartesian_vector, 3, axis=-1)\n\n  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = jnp.split(cartesian_vector, 3, axis=-1)\n  r = jnp.linalg.norm(cartesian_vector, axis=-1)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n  r = jnp.linalg.norm(cartesian_vector, axis=-1)\n  theta = jnp.arccos(z / r)\n  phi = jnp.arctan2(y, x)\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x = cartesian_vector[..., 0]\n  y = cartesian_vector[..., 1]\n  z = cartesian_vector[..., 2]\n\n  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  theta = jnp.arccos(jnp.clip(z / (r + eps), -1.0, 1.0))\n  phi = jnp.arctan2(y, x)\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n  r = jnp.sqrt(x**2 + y**2 + z**2)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n\n  r = jnp.sqrt(x**2 + y**2 + z**2)\n  xy = x + jnp.where(y < 0, -y, y)\n  theta = jnp.where(xy < eps, jnp.pi / 2, jnp.arctan2(xy, z))\n  phi = jnp.where(x < 0, jnp.pi - jnp.arctan2(x, y), jnp.arctan2(y, x))\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = jnp.split(cartesian_vector, 3, axis=-1)\n\n  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n\n  theta = jnp.arccos(z / (r + eps))\n\n  phi = jnp.arctan2(y, x)\n\n  return r, theta, phi\n\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  # Calculate radius\n  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n\n  # Calculate inclination\n  theta = jnp.arccos(jnp.divide(cartesian_vector[..., 2], r + eps))\n\n  # Calculate azimuth\n  phi = jnp.arctan2(cartesian_vector[..., 1], cartesian_vector[..., 0])\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n\n  r = jnp.linalg.norm(cartesian_vector, axis=-1)\n  theta = jnp.arccos(jnp.clip(z / r, -1, 1))\n  phi = jnp.arctan2(y, x)\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x = cartesian_vector[..., 0]\n  y = cartesian_vector[..., 1]\n  z = cartesian_vector[..., 2]\n\n  r = jnp.linalg.norm(cartesian_vector, axis=-1)\n\n  theta = jnp.arccos(z / (r + eps))\n\n  phi = jnp.arctan2(y, x)\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = jnp.split(cartesian_vector, 3, axis=-1)\n\n  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n\n  theta = jnp.arccos(z / (r + eps))\n\n  phi = jnp.arctan2(y, x)\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  # Calculate the radius\n  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n\n  # Calculate the inclination (theta)\n  theta = jnp.arccos(jnp.clip(cartesian_vector[..., 2] / (r + eps), -1, 1))\n\n  # Calculate the azimuth (phi)\n  phi = jnp.arctan2(cartesian_vector[..., 1], cartesian_vector[..., 0])\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  # Ensure that the input is an array.\n  cartesian_vector = jnp.asarray(cartesian_vector)\n\n  # Compute the radius.\n  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n\n  # Compute the inclination (theta).\n  theta = jnp.arccos(\n      jnp.divide(\n          cartesian_vector[..., 2],\n          jnp.maximum(r[..., 0], eps),\n      ),\n  )\n\n  # Compute the azimuth (phi).\n  phi = jnp.arctan2(\n      cartesian_vector[..., 1],\n      cartesian_vector[..., 0],\n  )\n\n  # Return the spherical coordinates.\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = jnp.split(cartesian_vector, 3, axis=-1)\n  r = jnp.linalg.norm(cartesian_vector, axis=-1)\n  # Prevent division by zero.\n  theta = jnp.where(r > eps, jnp.arccos(z / r), jnp.zeros_like(z))\n  phi = jnp.where(\n      jnp.abs(jnp.sin(theta)) > eps,\n      jnp.arctan2(y, x),\n      jnp.where(\n          jnp.abs(x) > eps,\n          jnp.pi / 2.0 * jnp.sign(y),\n          jnp.where(\n              jnp.abs(y) > eps,\n              jnp.pi * jnp.sign(x),\n              jnp.zeros_like(x),\n          ),\n      ),\n  )\n  return r, theta, phi\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[reference], tokenizer=f)\n    return results['rougeL'].mid.fmeasure\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[reference], tokenizer=f)\n    score = results['rougeL']\n    return score.recall\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[reference], tokenizer=f)\n    score = results['rougeL']\n    return score\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rougeL = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rougeL.compute(predictions=[continuation], references=[reference], tokenizer=f)\n    return results['rougeL']\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[reference], tokenizer=f)\n    return results['rougeL'].mid.fmeasure\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[reference], tokenizer=f)\n    return results['rougeL']\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[reference], tokenizer=f)\n    score = results['rougeLsum']\n    return score\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeLsum']\n    return score\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rougeL = evaluate.load('uhgeval/.cache/huggingface/rouge-l')\n    results = rougeL.compute(predictions=[continuation], references=[reference], tokenizer=f)\n    return results['rouge-l']\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[reference], tokenizer=f)\n    return results['rougeL']\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[reference], tokenizer=f)\n    return results['rougeL']\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[reference], tokenizer=f)\n    return results['rougeL']\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[reference], tokenizer=f)\n    score = results['rougeLsum']\n    return score.mid.fmeasure\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[reference], tokenizer=f)\n    score = results['rougeLsum']\n    return score.fmeasure\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeLsum']\n    return score\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[reference], tokenizer=f)\n    score = results['rougeLsum']\n    return score\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[reference], tokenizer=f)\n    score = results['rougeL']\n    return score\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[reference], tokenizer=f)\n    score = results['rougeL']\n    return score\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[reference], tokenizer=f)\n    score = results['rougeL']\n    return score\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[reference], tokenizer=f)\n    return results['rougeL'].mid.recall\n\n"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    obj = pydoc.locate(name)\n\n    if obj is None:\n        try:\n            # Try to locate it as a class\n            obj = pydoc.locate(f\"{name}.{name}\")\n        except Exception:\n            raise ImportError(f\"cannot find {name} or {name}.{name}\")\n\n    return obj"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # Fallback to using standard method to locate the object.\n    try:\n        return pydoc.locate(name)\n    except pydoc.ErrorDuringImport as e:\n        # Fallback to using importlib to locate the object.\n        try:\n            module_name, qualname = name.split(\":\")\n            from importlib import import_module\n            module = import_module(module_name)\n            return getattr(module, qualname)\n        except Exception as e:\n            raise e"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    obj = pydoc.locate(name)\n    if obj is None:\n        try:\n            last_dot_idx = name.rfind(\".\")\n            if last_dot_idx != -1:\n                parent_name, obj_name = name[:last_dot_idx], name[last_dot_idx + 1 :]\n                obj = getattr(locate(parent_name), obj_name)\n        except Exception:\n            raise ImportError(f\"Unable to locate '{name}'.\")\n    return obj"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # Fallback to using standard method to locate the object.\n    try:\n        return pydoc.locate(name)\n    except pydoc.ErrorDuringImport as e:\n        # Fallback to using importlib to locate the object.\n        try:\n            module_name, qualname = name.split(\":\")\n            from importlib import import_module\n\n            module = import_module(module_name)\n            return getattr(module, qualname)\n        except Exception as e:\n            # Raise the original exception.\n            raise e"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # Use the standard method to locate the object.\n    obj = pydoc.locate(name)\n\n    # If not found, try a fallback method.\n    if obj is None:\n        obj = pydoc.locate(f\"{name}.{name}\")\n\n    # If still not found, raise an exception.\n    if obj is None:\n        raise ImportError(f\"Unable to locate object with name '{name}'.\")\n\n    return obj"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # Fallback to the standard method to locate the object.\n    try:\n        return pydoc.locate(name)\n    except pydoc.ErrorDuringImport as e:\n        # Fallback to a slow but reliable method to locate the object.\n        try:\n            module_name, attr_name = name.rsplit(\".\", 1)\n        except ValueError as e:\n            raise ImportError(f\"{name} is not a valid fully-qualified name.\") from e\n        try:\n            module = __import__(module_name, fromlist=[attr_name])\n        except ModuleNotFoundError as e:\n            raise ImportError(f\"No module named '{module_name}'.\") from e\n        try:\n            return getattr(module, attr_name)\n        except AttributeError as e:\n            raise ImportError(f\"The module '{module_name}' has no attribute '{attr_name}'.\") from e"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # Fallback to using standard method to locate the object.\n    try:\n        return pydoc.locate(name)\n    except pydoc.ErrorDuringImport as e:\n        # Fallback to using PydocFallbackLocator to locate the object.\n        try:\n            return pydoc.locate(name, pydoc.PydocFallbackLocator())\n        except pydoc.ErrorDuringImport as e:\n            # Raise the original exception raised by the standard method.\n            raise e"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # Fallback to using standard method to locate the object.\n    try:\n        return pydoc.locate(name)\n    except pydoc.ErrorDuringImport as e:\n        # Fallback to using importlib to locate the object.\n        try:\n            module_name, qualname = name.split(\":\")\n            from importlib import import_module\n\n            module = import_module(module_name)\n            return getattr(module, qualname)\n        except Exception as e:\n            raise ImportError(f\"Failed to locate {name}.\").with_traceback(\n                e.__traceback__\n            )"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # Fallback to using standard method to locate the object.\n    try:\n        return pydoc.locate(name)\n    except pydoc.ErrorDuringImport as e:\n        # Fallback to using PyDocFinder to locate the object.\n        try:\n            return pydoc.locate_global(name)\n        except pydoc.ErrorDuringImport as e:\n            raise ImportError(f\"{name} could not be located: {e}\")"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # Fallback to standard method to locate the object\n    try:\n        return pydoc.locate(name)\n    except pydoc.ErrorDuringImport as e:\n        # Fallback to a slow but reliable method to locate the object\n        # This method also has the benefit of supporting objects in installed packages\n        try:\n            module_name, qualname = name.split(\":\")\n        except ValueError:\n            module_name = name\n            qualname = None\n\n        module = __import__(module_name)\n        for part in module_name.split(\".\")[1:]:\n            module = getattr(module, part)\n\n        if qualname is not None:\n            module_name, qualname = qualname.split(\":\")\n            obj = getattr(module, module_name)\n            for part in qualname.split(\".\"):\n                obj = getattr(obj, part)\n            return obj\n        else:\n            return module"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # The standard method of locating objects.\n    try:\n        return pydoc.locate(name)\n    except pydoc.ErrorDuringImport as e:\n        # Fallback method.\n        try:\n            module_name, name = name.split(\".\", 1)\n            m = __import__(module_name, fromlist=[name])\n            return getattr(m, name)\n        except (ImportError, AttributeError, ValueError):\n            # Raise the original exception from the standard method.\n            raise e"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # Fallback to using standard method to locate the object.\n    try:\n        return pydoc.locate(name)\n    except pydoc.ErrorDuringImport as e:\n        # Fallback to using importlib.\n        try:\n            module_name, qualname = name.split(\":\")\n            from importlib import import_module\n\n            m = import_module(module_name)\n            t = m\n            for attr_name in qualname.split(\".\"):\n                t = getattr(t, attr_name)\n            return t\n        except Exception as e:\n            raise ImportError(f\"Cannot find object with name {name}\") from e\n\n"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # Use the standard method to locate the object.\n    obj = pydoc.locate(name)\n\n    # If not found, try to locate the object using the fallback method.\n    if obj is None:\n        obj = _locate_fallback(name)\n\n    # If the object is still not found, raise an exception.\n    if obj is None:\n        raise ImportError(f\"Unable to locate object with name '{name}'.\")\n\n    return obj\n\n"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # Use the standard method to locate the object.\n    obj = pydoc.locate(name)\n\n    # If the object cannot be located, try to locate it using the fallback method.\n    if obj is None:\n        obj = _locate_fallback(name)\n\n    # If the object is still not located, raise an exception.\n    if obj is None:\n        raise ImportError(f\"Unable to locate object with name '{name}'.\")\n\n    return obj\n\n"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # Fallback to using standard method to locate the object.\n    try:\n        return pydoc.locate(name)\n    except pydoc.ErrorDuringImport as e:\n        # Fallback to using importlib to locate the object.\n        try:\n            module_name, qualname = name.split(\":\")\n            from importlib import import_module\n            module = import_module(module_name)\n            return getattr(module, qualname)\n        except Exception as e:\n            raise ImportError(f\"Failed to locate {name} with either method.\")\n\n"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # Fallback method 1: use \"from module_path import class_name\"\n    try:\n        module_name, class_name = name.rsplit(\".\", 1)\n        module = pydoc.locate(module_name)\n        return getattr(module, class_name)\n    except Exception as e:\n        print(f\"Module {module_name} not found: {e}\")\n\n    # Fallback method 2: use \"from module_path.submodule import class_name\"\n    try:\n        module = pydoc.locate(f\"{module_name}.{class_name}\")\n        return module\n    except Exception as e:\n        print(f\"Module {module_name} not found: {e}\")\n\n    # Fallback method 3: use \"from module_path.submodule import class_name as name\"\n    try:\n        module = pydoc.locate(f\"{module_name}.{class_name}\")\n        for attr, obj in vars(module).items():\n            if obj.__name__ == name:\n                return obj\n        raise Exception(f\"Cannot locate {name}\")\n    except Exception as e:\n        print(f\"Module {module_name} not found: {e}\")"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # Fallbacks are required because:\n    # 1. Python may not be able to import modules containing submodules.\n    # 2. Some objects are not exposed in their modules, such as Python internal classes.\n    #\n    # These fallback methods are copied from PyTorch's Locate class.\n\n    # First, try to use the standard method to find the module.\n    try:\n        obj = pydoc.locate(name)\n    except ImportError:\n        pass\n    else:\n        if obj is not None:\n            return obj\n\n    # If it fails, try to locate the module first.\n    try:\n        module_name, qualname = name.rsplit(\".\", 1)\n    except ValueError:\n        raise ImportError(f\"{name} is not a valid fully-qualified name.\")\n    obj = pydoc.locate(module_name)\n    if obj is None:\n        raise ImportError(f\"Error loading module '{module_name}'\")\n\n    # Get the object from the module.\n    try:\n        obj = getattr(obj, qualname)\n    except AttributeError:\n        raise ImportError(\n            f\"Could not locate '{qualname}' in the module '{module_name}'. \"\n            f\"Please check that the name is correct and the module is installed.\"\n        )\n\n    return obj"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # Use the standard method to attempt to locate the object.\n    try:\n        return pydoc.locate(name)\n    except pydoc.ErrorDuringImport as e:\n        # Fallback: search for the object based on the fully qualified name.\n        modulename, qualname = name.rsplit(\".\", 1)\n        mod = __import__(modulename)\n        try:\n            return getattr(mod, qualname)\n        except AttributeError as e:\n            # Raise the exception again so we have the traceback.\n            raise e from e\n\n"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # Fallback to using standard method to locate the object.\n    obj = pydoc.locate(name)\n    if obj is None:\n        # Fallback to using a heuristic to locate the object.\n        obj = _locate_with_heuristic(name)\n\n    if obj is None:\n        raise ImportError(f\"Cannot locate object with name: {name}\")\n\n    return obj\n\n"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # Fallbacks are only attempted if the default lookup fails.\n    default_lookup = True\n\n    # The default lookup, used only when fallbacks are enabled, is to treat this as\n    # a fully qualified name.\n    default_lookup_success = False\n\n    # Attempt to locate the object by importing the module and then looking up the\n    # attribute on that module.\n    try:\n        obj = pydoc.locate(name)\n    except ImportError:\n        pass\n    else:\n        # We successfully imported the module; we assume the fully qualified name refers to\n        # the module itself and return it.\n        if obj is not None:\n            default_lookup_success = True\n            return obj\n\n    # If we get here, the module was not successfully imported. If this was the\n    # default lookup, i.e. not using fallbacks, we fail.\n    if default_lookup:\n        raise ImportError(f\"Unable to locate object with qualified name {name}.\" f\"\")\n\n    # Fallback 1: Look for the object as a function. This works for classes, functions, and\n    # other callables.\n    try:\n        import builtins\n\n        obj = getattr(builtins, name)\n        default_lookup_success = True\n    except AttributeError:\n        pass\n\n    # Fallback 2: Look for the object in the same module as the caller. This works for\n    # members of that module.\n    if not default_lookup_success:\n        # Narrow down the search for the calling function by going up until we find\n        # a frame with non-__main__ module.\n        frame = inspect.currentframe()\n        while frame:\n            if frame.f_code.co_name != \"<module>\":\n                break\n            frame = frame.f_back\n        if frame:\n            obj = frame.f_globals.get(name, None)\n            if obj:\n                default_lookup_success = True\n\n    if default_lookup_success:\n        return obj\n\n    # Fallback 3: Look for the object in the same module as the type of the caller. This works\n   "}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n\n    return reloaded_module\n\n"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n\n    return reloaded_module\n"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n\n    return reloaded_module\n\n"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n\n    return reloaded_module\n\n"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n\n    return reloaded_module\n\n"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n\n    return reloaded_module\n\n"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n\n    return reloaded_module\n\n"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n\n    return reloaded_module\n\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check that the length of the ids and scores tuples match\n    if len(ids) != len(scores):\n        raise ValueError(\"The ids and scores tuples must be of the same length.\")\n\n    # Check that the length of the ids, scores, and weights tuples match\n    if len(ids) != len(weights):\n        raise ValueError(\"The ids, scores, and weights tuples must be of the same length.\")\n\n    # Check that the sum of the weights equals 1\n    if sum(weights) != 1:\n        raise ValueError(\"The sum of the weights must equal 1.\")\n\n    # Normalize scores\n    for i in range(len(scores)):\n        scores[i] = pd.Series(scores[i]).apply(lambda x: x / max(scores[i])).tolist()\n\n    # Fuse scores\n    fused_scores = []\n    for i in range(len(scores[0])):\n        fused_scores.append(sum([scores[j][i] * weights[j] for j in range(len(scores))]))\n\n    # Select top_k results\n    fused_scores, fused_ids = zip(*sorted(zip(fused_scores, ids[0]), reverse=True)[:top_k])\n\n    return fused_ids, fused_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check that the length of the ids tuple matches the length of the scores tuple\n    assert len(ids) == len(scores)\n\n    # Check that the length of the ids tuple matches the length of the weights tuple\n    assert len(ids) == len(weights)\n\n    # Check that the sum of the weights equals 1\n    assert sum(weights) == 1\n\n    # Normalize scores\n    for i in range(len(scores)):\n        scores[i] = [score / max(scores[i]) for score in scores[i]]\n\n    # Fuse scores\n    fused_scores = []\n    for i in range(len(scores[0])):\n        fused_scores.append(sum([weights[j] * scores[j][i] for j in range(len(scores))]))\n\n    # Select top_k results\n    fused_scores, fused_ids = zip(*sorted(zip(fused_scores, ids[0]), key=lambda x: x[0], reverse=True)[:top_k])\n\n    return fused_ids, fused_scores\n\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check if the weights sum to 1\n    if sum(weights) != 1.0:\n        raise ValueError(\"The sum of the weights must equal 1.\")\n\n    # Check if the length of the weights tuple matches the length of the ids and scores tuples\n    if len(weights) != len(ids) or len(weights) != len(scores):\n        raise ValueError(\"The length of the weights tuple must match the length of the ids and scores tuples.\")\n\n    # Normalize the scores\n    for i in range(len(scores)):\n        scores[i] = [score / sum(scores[i]) for score in scores[i]]\n\n    # Combine the scores\n    combined_scores = [0.0] * len(scores[0])\n    for i in range(len(scores[0])):\n        for j in range(len(scores)):\n            combined_scores[i] += weights[j] * scores[j][i]\n\n    # Select the top_k results\n    combined_scores = pd.Series(combined_scores)\n    combined_scores = combined_scores.sort_values(ascending=False)\n    combined_scores = combined_scores[:top_k]\n\n    # Combine the ids\n    combined_ids = []\n    for i in range(len(ids[0])):\n        if combined_scores[i] > 0:\n            combined_ids.append(ids[0][i])\n\n    return combined_ids, combined_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check if the length of the ids and scores tuples match\n    if len(ids) != len(scores):\n        raise ValueError(\n            \"The length of the ids and scores tuples must match. The length of the ids tuple is {} and the length of the scores tuple is {}.\".format(\n                len(ids), len(scores)))\n\n    # Check if the length of the weights tuple matches the length of the ids and scores tuples\n    if len(weights) != len(ids):\n        raise ValueError(\n            \"The length of the weights tuple must match the length of the ids and scores tuples. The length of the weights tuple is {} and the length of the ids and scores tuples are {} and {} respectively.\".format(\n                len(weights), len(ids), len(scores)))\n\n    # Check if the sum of the weights equals 1\n    if sum(weights) != 1:\n        raise ValueError(\n            \"The sum of the weights must equal 1. The sum of the weights is {}\".format(\n                sum(weights)))\n\n    # Normalize the scores\n    normalized_scores = []\n    for score_list in scores:\n        normalized_scores.append([score / max(score_list) for score in score_list])\n\n    # Combine the scores\n    combined_scores = []\n    for i in range(len(ids[0])):\n        combined_score = 0\n        for j in range(len(ids)):\n            combined_score += normalized_scores[j][i] * weights[j]\n        combined_scores.append(combined_score)\n\n    # Sort the scores and ids\n    combined_scores, combined_ids = zip(\n        *sorted(zip(combined_scores, ids[0]), reverse=True))\n\n    # Select the top k results\n    combined_scores = combined_scores[:top_k]\n    combined_ids = combined_ids[:top_k]\n\n    return combined_ids, combined_scores\n\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check the length of the input arguments\n    if len(ids) != len(scores):\n        raise ValueError(\n            \"The length of the ids tuple must match the length of the scores tuple.\")\n    if len(scores) != len(weights):\n        raise ValueError(\n            \"The length of the scores tuple must match the length of the weights tuple.\")\n\n    # Normalize the scores\n    norm_scores = []\n    for score in scores:\n        norm_scores.append(pd.Series(score).div(sum(score)).tolist())\n\n    # Combine the scores\n    combined_scores = []\n    for i in range(len(ids[0])):\n        combined_scores.append(\n            sum([norm_scores[j][i] * weights[j] for j in range(len(ids))]))\n\n    # Select the top_k results\n    fused_ids = []\n    fused_scores = []\n    for i in range(len(combined_scores)):\n        if combined_scores[i] > 0:\n            fused_ids.append(ids[0][i])\n            fused_scores.append(combined_scores[i])\n    fused_scores, fused_ids = zip(\n        *sorted(zip(fused_scores, fused_ids), reverse=True))\n\n    return fused_ids[:top_k], fused_scores[:top_k]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # check inputs\n    if len(ids) != len(scores):\n        raise ValueError('The length of the ids and scores tuples must match.')\n    if len(ids) != len(weights):\n        raise ValueError('The length of the ids and weights tuples must match.')\n    if sum(weights) != 1:\n        raise ValueError('The sum of the weights must equal 1.')\n\n    # normalize scores\n    scores_normalized = []\n    for score in scores:\n        scores_normalized.append(pd.Series(score).divide(sum(score)).tolist())\n\n    # combine scores\n    scores_combined = []\n    for i in range(len(ids[0])):\n        scores_combined.append(\n            sum([scores_normalized[j][i] * weights[j] for j in range(len(scores_normalized))]))\n\n    # select top_k results\n    top_ids = []\n    top_scores = []\n    for i in range(top_k):\n        top_ids.append(ids[0][scores_combined.index(max(scores_combined))])\n        top_scores.append(max(scores_combined))\n        scores_combined.pop(scores_combined.index(max(scores_combined)))\n        ids[0].pop(scores_combined.index(max(scores_combined)))\n\n    return top_ids, top_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # check if the weights sum up to 1\n    assert sum(weights) == 1, \"The weights must sum up to 1.\"\n\n    # check if the number of ids and scores match\n    assert len(ids) == len(scores), \"The number of ids and scores must match.\"\n\n    # check if the number of ids and weights match\n    assert len(ids) == len(weights), \"The number of ids and weights must match.\"\n\n    # normalize the scores\n    for i in range(len(scores)):\n        scores[i] = pd.Series(scores[i]).apply(lambda x: x / max(scores[i]))\n\n    # combine the scores\n    combined_scores = []\n    for i in range(len(scores[0])):\n        combined_scores.append(sum([scores[j][i] * weights[j] for j in range(len(scores))]))\n\n    # get the top k results\n    combined_scores, combined_ids = zip(*sorted(zip(combined_scores, ids[0]), reverse=True)[:top_k])\n\n    return combined_ids, combined_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # check inputs\n    if len(ids) != len(scores):\n        raise ValueError(\n            \"The length of the ids tuple must match the length of the scores tuple.\")\n    if len(ids) != len(weights):\n        raise ValueError(\n            \"The length of the ids tuple must match the length of the weights tuple.\")\n    if sum(weights) != 1:\n        raise ValueError(\n            \"The sum of the weights must equal 1.\")\n\n    # normalize scores\n    for i in range(len(scores)):\n        scores[i] = pd.Series(scores[i]).apply(lambda x: x / max(scores[i])).tolist()\n\n    # combine scores\n    combined_scores = []\n    for i in range(len(scores[0])):\n        combined_scores.append(\n            sum(scores[j][i] * weights[j] for j in range(len(scores)))\n        )\n\n    # select top_k\n    combined_scores = pd.Series(combined_scores).sort_values(ascending=False)\n    combined_scores = combined_scores.head(top_k)\n\n    # return fused results\n    return (\n        combined_scores.index.tolist(),\n        combined_scores.tolist()\n    )"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check input arguments\n    if len(ids) != len(scores):\n        raise ValueError(\"The length of the ids and scores tuples must match.\")\n    if len(ids) != len(weights):\n        raise ValueError(\"The length of the ids and weights tuples must match.\")\n    if len(scores) != len(weights):\n        raise ValueError(\"The length of the scores and weights tuples must match.\")\n    if sum(weights) != 1:\n        raise ValueError(\"The sum of the weights must equal 1.\")\n    if top_k <= 0:\n        raise ValueError(\"The top_k parameter must be greater than 0.\")\n\n    # Normalize scores\n    for i in range(len(scores)):\n        scores[i] = [score / max(scores[i]) for score in scores[i]]\n\n    # Combine scores\n    combined_scores = []\n    for i in range(len(scores[0])):\n        combined_scores.append(sum([scores[j][i] * weights[j] for j in range(len(scores))]))\n\n    # Select top k results\n    combined_scores = pd.Series(combined_scores)\n    combined_scores = combined_scores.sort_values(ascending=False)\n    combined_scores = combined_scores.head(top_k)\n    combined_scores = combined_scores.reset_index(drop=True)\n\n    # Select top k ids\n    combined_ids = []\n    for i in range(len(ids[0])):\n        if combined_scores[i] in combined_scores.values:\n            combined_ids.append(ids[0][i])\n\n    return combined_ids, combined_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check that the length of the ids and scores tuples match\n    if len(ids) != len(scores):\n        raise ValueError(\n            f\"The length of the ids and scores tuples must match. The length of the ids tuple is {len(ids)} and the length of the scores tuple is {len(scores)}.\"\n        )\n\n    # Check that the length of the ids and weights tuples match\n    if len(ids) != len(weights):\n        raise ValueError(\n            f\"The length of the ids and weights tuples must match. The length of the ids tuple is {len(ids)} and the length of the weights tuple is {len(weights)}.\"\n        )\n\n    # Check that the weights sum to 1\n    if sum(weights) != 1:\n        raise ValueError(\n            f\"The weights must sum to 1. The sum of the weights is {sum(weights)}.\"\n        )\n\n    # Check that the scores are normalized\n    for score_list in scores:\n        if not all(score >= 0 for score in score_list):\n            raise ValueError(\n                f\"The scores must be normalized. The minimum score is {min(score_list)} and the maximum score is {max(score_list)}.\"\n            )\n\n    # Check that the scores are normalized\n    for score_list in scores:\n        if not all(score <= 1 for score in score_list):\n            raise ValueError(\n                f\"The scores must be normalized. The minimum score is {min(score_list)} and the maximum score is {max(score_list)}.\"\n            )\n\n    # Create a dataframe containing the scores and ids\n    df = pd.DataFrame(\n        {\n            \"score\": [score for score_list in scores for score in score_list],\n            \"id\": [id for id_list in ids for id in id_list],\n        }\n    )\n\n    # Normalize the scores\n    df[\"score\"] = df[\"score\"] / df[\"score\"].max()\n\n    # Combine the scores based on the weights\n    df[\"score\"] = df[\"score\"]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # validate input\n    if len(ids) != len(scores):\n        raise ValueError(\"The length of the ids and scores tuples must match.\")\n    if len(weights) != len(ids):\n        raise ValueError(\"The length of the weights tuple must match the length of the ids and scores tuples.\")\n    if sum(weights) != 1:\n        raise ValueError(\"The sum of the weights must equal 1.\")\n\n    # normalize scores\n    norm_scores = []\n    for score_list in scores:\n        norm_scores.append(pd.Series(score_list).div(sum(score_list)))\n\n    # combine scores\n    combined_scores = pd.DataFrame(norm_scores).multiply(weights).sum(axis=0)\n\n    # get top_k results\n    top_ids = []\n    top_scores = []\n    for index in combined_scores.sort_values(ascending=False).head(top_k).index:\n        top_ids.append(ids[index])\n        top_scores.append(combined_scores[index])\n\n    return top_ids, top_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check if the lengths of the input tuples match\n    if len(ids) != len(scores):\n        raise ValueError(\n            \"The length of the ids and scores tuples must match. \"\n            f\"The length of the ids tuple is {len(ids)} and the length of the scores tuple is {len(scores)}.\"\n        )\n\n    # Check if the weights sum to 1\n    if sum(weights) != 1:\n        raise ValueError(\n            \"The weights must sum to 1. \"\n            f\"The sum of the weights is {sum(weights)}.\"\n        )\n\n    # Check if the length of the weights tuple matches the length of the ids and scores tuples\n    if len(weights) != len(ids) or len(weights) != len(scores):\n        raise ValueError(\n            \"The length of the weights tuple must match the length of the ids and scores tuples. \"\n            f\"The length of the weights tuple is {len(weights)}, the length of the ids tuple is {len(ids)}, and the length of the scores tuple is {len(scores)}.\"\n        )\n\n    # Normalize the scores\n    normalized_scores = []\n    for score_list in scores:\n        normalized_scores.append(normalize(score_list))\n\n    # Combine the scores using a convex combination\n    combined_scores = []\n    for i in range(len(ids[0])):\n        score = 0\n        for j in range(len(ids)):\n            score += normalized_scores[j][i] * weights[j]\n        combined_scores.append(score)\n\n    # Select the top_k results\n    top_ids, top_scores = select_top_k(combined_scores, ids, top_k)\n\n    return top_ids, top_scores\n\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check that the length of the ids and scores tuples match\n    if len(ids) != len(scores):\n        raise ValueError(\n            \"The length of the ids and scores tuples must match. The length of the ids tuple is {} and the length of the scores tuple is {}.\".format(\n                len(ids), len(scores)))\n\n    # Check that the length of the weights tuple matches the length of the ids and scores tuples\n    if len(weights) != len(ids) or len(weights) != len(scores):\n        raise ValueError(\n            \"The length of the weights tuple must match the length of the ids and scores tuples. The length of the weights tuple is {} and the length of the ids and scores tuples are {} and {} respectively.\".format(\n                len(weights), len(ids), len(scores)))\n\n    # Check that the sum of the weights tuple is equal to 1\n    if sum(weights) != 1:\n        raise ValueError(\n            \"The sum of the weights tuple must equal 1. The sum of the weights tuple is {}.\".format(\n                sum(weights)))\n\n    # Normalize the scores\n    normalized_scores = []\n    for score_list in scores:\n        normalized_scores.append(\n            [score / sum(score_list) for score in score_list])\n\n    # Combine the scores\n    combined_scores = []\n    for i in range(len(ids[0])):\n        combined_scores.append(\n            sum([score[i] * weight for score, weight in zip(normalized_scores, weights)]))\n\n    # Create a dataframe from the combined scores\n    df = pd.DataFrame({\"id\": ids[0], \"score\": combined_scores})\n\n    # Sort the dataframe by the score column\n    df.sort_values(by=\"score\", ascending=False, inplace=True)\n\n    # Select the top_k results\n    df = df.head(top_k)\n\n    # Return the ids and scores\n    return df[\"id\"].tolist(), df[\"score\"].tolist"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    if len(ids) != len(scores):\n        raise ValueError(\"The length of the ids and scores tuples must match.\")\n\n    if len(ids) != len(weights):\n        raise ValueError(\"The length of the ids and weights tuples must match.\")\n\n    if sum(weights) != 1:\n        raise ValueError(\"The sum of the weights must equal 1.\")\n\n    # Normalize scores\n    normalized_scores = []\n    for score in scores:\n        normalized_score = [float(i) / max(score) for i in score]\n        normalized_scores.append(normalized_score)\n\n    # Fuse scores\n    fused_scores = []\n    for i in range(len(ids[0])):\n        fused_score = 0\n        for j in range(len(ids)):\n            fused_score += weights[j] * normalized_scores[j][i]\n        fused_scores.append(fused_score)\n\n    # Select top_k results\n    fused_scores_df = pd.DataFrame({\"fused_scores\": fused_scores})\n    fused_scores_df = fused_scores_df.sort_values(\n        by=\"fused_scores\", ascending=False)\n    fused_scores_df = fused_scores_df.head(top_k)\n    fused_scores = fused_scores_df[\"fused_scores\"].tolist()\n    fused_ids = [ids[i][j] for i, j in enumerate(fused_scores_df.index)]\n\n    return fused_ids, fused_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check that the number of weights matches the number of ids and scores\n    if len(ids) != len(scores) or len(scores) != len(weights):\n        raise ValueError(\n            \"The number of ids, scores, and weights must all match. The number of ids is {}, the number of scores is {}, and the number of weights is {}\".format(\n                len(ids), len(scores), len(weights)))\n\n    # Check that the sum of the weights is 1\n    if sum(weights) != 1:\n        raise ValueError(\n            \"The sum of the weights must equal 1. The sum of the weights is {}\".format(\n                sum(weights)))\n\n    # Normalize the scores\n    normalized_scores = []\n    for score in scores:\n        normalized_scores.append(pd.Series(score).divide(sum(score)))\n\n    # Combine the scores\n    combined_scores = pd.DataFrame(normalized_scores).dot(weights)\n\n    # Return the top_k results\n    return combined_scores.nlargest(top_k).index.tolist(), combined_scores.nlargest(top_k).tolist()\n\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check if the lengths of the input tuples match\n    if len(ids) != len(scores):\n        raise ValueError(\"The length of the ids tuple must match the length of the scores tuple.\")\n\n    # Check if the weights sum to 1\n    if sum(weights) != 1:\n        raise ValueError(\"The sum of the weights must equal 1.\")\n\n    # Check if the length of the weights tuple matches the length of the ids and scores tuples\n    if len(weights) != len(ids) or len(weights) != len(scores):\n        raise ValueError(\"The length of the weights tuple must match the length of the ids and scores tuples.\")\n\n    # Normalize the scores\n    normalized_scores = []\n    for score in scores:\n        normalized_scores.append(pd.Series(score).div(sum(score)).tolist())\n\n    # Combine the scores\n    combined_scores = []\n    for i in range(len(ids[0])):\n        combined_scores.append(sum(normalized_scores[j][i] * weights[j] for j in range(len(normalized_scores))))\n\n    # Select the top_k results\n    top_results = sorted(enumerate(combined_scores), key=lambda x: x[1], reverse=True)[:top_k]\n\n    # Return the fused ids and scores\n    return ([ids[0][result[0]] for result in top_results], [combined_scores[result[0]] for result in top_results])\n\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check if the length of the ids and scores tuples match\n    if len(ids) != len(scores):\n        raise ValueError(\"The length of the ids and scores tuples must match.\")\n\n    # Check if the length of the ids, scores, and weights tuples match\n    if len(ids) != len(weights):\n        raise ValueError(\"The length of the ids, scores, and weights tuples must match.\")\n\n    # Check if the sum of the weights is equal to 1\n    if sum(weights) != 1:\n        raise ValueError(\"The sum of the weights must equal 1.\")\n\n    # Check if all of the scores are between 0 and 1\n    for score_list in scores:\n        for score in score_list:\n            if score < 0 or score > 1:\n                raise ValueError(\"All of the scores must be between 0 and 1.\")\n\n    # Create a dataframe with the ids, scores, and weights\n    df = pd.DataFrame({\n        \"ids\": ids,\n        \"scores\": scores,\n        \"weights\": weights\n    })\n\n    # Normalize the scores\n    df[\"scores\"] = df[\"scores\"] / df[\"scores\"].max()\n\n    # Combine the scores using a convex combination\n    df[\"scores\"] = df[\"scores\"] * df[\"weights\"]\n\n    # Sum the scores\n    df[\"scores\"] = df[\"scores\"].sum(axis=1)\n\n    # Sort the scores\n    df.sort_values(by=\"scores\", ascending=False, inplace=True)\n\n    # Select the top_k results\n    df = df.head(top_k)\n\n    # Return the ids and scores\n    return df[\"ids\"].values.tolist(), df[\"scores\"].values.tolist()"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check if weights sum to 1\n    if sum(weights) != 1:\n        raise ValueError(\"The sum of the weights must equal 1.\")\n\n    # Check if the length of the ids and scores tuples match\n    if len(ids) != len(scores):\n        raise ValueError(\"The length of the ids and scores tuples must match.\")\n\n    # Check if the length of the ids and weights tuples match\n    if len(ids) != len(weights):\n        raise ValueError(\"The length of the ids and weights tuples must match.\")\n\n    # Check if the length of the scores and weights tuples match\n    if len(scores) != len(weights):\n        raise ValueError(\"The length of the scores and weights tuples must match.\")\n\n    # Combine the scores\n    scores_df = pd.DataFrame(scores, index=ids)\n    scores_df = scores_df.fillna(0)\n    scores_df = scores_df.apply(lambda x: x / x.max(), axis=1)\n    scores_df = scores_df.apply(lambda x: x * weights[scores_df.index.get_loc(x.name)], axis=1)\n    scores_df = scores_df.fillna(0)\n\n    # Combine the ids\n    ids_df = pd.DataFrame(ids)\n    ids_df = ids_df.apply(lambda x: x * weights[ids_df.index.get_loc(x.name)], axis=1)\n    ids_df = ids_df.apply(lambda x: x.apply(lambda y: y if y != 0 else x.name), axis=1)\n    ids_df = ids_df.apply(lambda x: x.apply(lambda y: y if y != 0 else x.name), axis=1)\n\n    # Get the top_k results\n    ids_df = ids_df.apply(lambda x: x.sort_values(ascending=False).head(top_k), axis=1)\n    scores_df = scores_df.apply(lambda x: x.sort_values(asc"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check if the length of the ids and scores tuples match\n    if len(ids) != len(scores):\n        raise ValueError(\n            'The number of ids and scores must match. The length of the ids tuple is {} and the length of the scores tuple is {}'.format(\n                len(ids), len(scores)))\n\n    # Check if the length of the ids, scores, and weights tuples match\n    if len(ids) != len(weights):\n        raise ValueError(\n            'The number of ids, scores, and weights must match. The length of the ids tuple is {} and the length of the scores tuple is {}'.format(\n                len(ids), len(scores)))\n\n    # Check if the sum of the weights is equal to 1\n    if sum(weights) != 1:\n        raise ValueError(\n            'The sum of the weights must equal 1. The sum of the weights is {}'.format(\n                sum(weights)))\n\n    # Check if the length of the scores tuple is equal to 2\n    if len(scores) != 2:\n        raise ValueError(\n            'The length of the scores tuple must be 2. The length of the scores tuple is {}'.format(\n                len(scores)))\n\n    # Check if the length of the ids tuple is equal to 2\n    if len(ids) != 2:\n        raise ValueError(\n            'The length of the ids tuple must be 2. The length of the ids tuple is {}'.format(\n                len(ids)))\n\n    # Check if the length of the weights tuple is equal to 2\n    if len(weights) != 2:\n        raise ValueError(\n            'The length of the weights tuple must be 2. The length of the weights tuple is {}'.format(\n                len(weights)))\n\n    # Convert the scores to a data frame\n    scores_df = pd.DataFrame(scores, index=ids)\n\n    # Normalize the scores\n    scores_df = scores_df.apply(lambda x: x / x.max(), axis=0)\n\n    # Combine the scores\n    scores_df ="}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check if the length of the inputs match\n    if len(ids) != len(scores):\n        raise ValueError(\n            \"The length of the ids and scores tuples must match. Please check your inputs.\")\n\n    # Check if the length of the inputs match\n    if len(ids) != len(weights):\n        raise ValueError(\n            \"The length of the ids and weights tuples must match. Please check your inputs.\")\n\n    # Check if the length of the weights is 2\n    if len(weights) != 2:\n        raise ValueError(\n            \"The length of the weights tuple must be 2. Please check your inputs.\")\n\n    # Check if the sum of the weights is 1\n    if sum(weights) != 1:\n        raise ValueError(\n            \"The sum of the weights must equal 1. Please check your inputs.\")\n\n    # Normalize the scores\n    normalized_scores = [normalize_scores(score) for score in scores]\n\n    # Combine the scores\n    combined_scores = combine_scores(normalized_scores, weights)\n\n    # Select the top_k results\n    top_ids, top_scores = select_top_k(combined_scores, ids, top_k)\n\n    return top_ids, top_scores\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n\n    if percent:\n        x *= 100\n\n    if np.abs(x) < 1e-2:\n        n_decimals = 6\n    elif np.abs(x) < 1e-1:\n        n_decimals = 5\n    elif np.abs(x) < 1e0:\n        n_decimals = 4\n    elif np.abs(x) < 1e1:\n        n_decimals = 3\n    elif np.abs(x) < 1e2:\n        n_decimals = 2\n    elif np.abs(x) < 1e3:\n        n_decimals = 1\n    else:\n        n_decimals = 0\n\n    return f\"{x:.{n_decimals}f}%\" if percent else f\"{x:.{n_decimals}f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n\n    if percent:\n        x *= 100\n        return f\"{x:.2f}%\"\n\n    if x < 1e-2:\n        return f\"{x:.2e}\"\n\n    if x < 10:\n        return f\"{x:.2f}\"\n\n    if x < 100:\n        return f\"{int(x)}\"\n\n    return f\"{int(x)}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n    if percent:\n        x = x * 100\n    if x.is_integer():\n        return f\"{int(x):.0f}%\" if percent else f\"{int(x):.0f}\"\n    if x < 0.01:\n        return f\"{x:.2e}%\" if percent else f\"{x:.2e}\"\n    if x < 1:\n        return f\"{x:.3f}%\" if percent else f\"{x:.3f}\"\n    if x < 10:\n        return f\"{x:.2f}%\" if percent else f\"{x:.2f}\"\n    if x < 100:\n        return f\"{x:.1f}%\" if percent else f\"{x:.1f}\"\n    return f\"{x:.0f}%\" if percent else f\"{x:.0f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n    else:\n        if percent:\n            x *= 100\n            return f\"{x:.2f}%\"\n        else:\n            if x == 0:\n                return f\"{x:.0f}\"\n            else:\n                x_log = np.log10(np.abs(x))\n                if x_log >= 3:\n                    return f\"{x:.0f}\"\n                elif x_log >= 2:\n                    return f\"{x:.1f}\"\n                else:\n                    return f\"{x:.2f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n\n    if percent:\n        x *= 100\n\n    if x == 0:\n        return f\"{x:.0f}%\" if percent else f\"{x:.0f}\"\n\n    x = np.abs(x)\n\n    if x < 1:\n        return f\"{x:.3f}%\" if percent else f\"{x:.3f}\"\n    elif x < 10:\n        return f\"{x:.2f}%\" if percent else f\"{x:.2f}\"\n    elif x < 100:\n        return f\"{x:.1f}%\" if percent else f\"{x:.1f}\"\n    else:\n        return f\"{x:.0f}%\" if percent else f\"{x:.0f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n\n    if percent:\n        x *= 100\n\n    if x >= 1:\n        return f\"{x:.0f}%\" if percent else f\"{x:.0f}\"\n\n    return f\"{x:.2g}%\" if percent else f\"{x:.2g}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n\n    if percent:\n        x *= 100\n\n    if x == 0:\n        return \"0\"\n\n    if x < 1e-3:\n        return f\"{x:.2e}\"\n\n    if x < 1:\n        return f\"{x:.4f}\"\n\n    if x < 10:\n        return f\"{x:.3f}\"\n\n    if x < 100:\n        return f\"{x:.2f}\"\n\n    if x < 1000:\n        return f\"{x:.1f}\"\n\n    return f\"{int(x)}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n\n    if percent:\n        x = x * 100\n\n    if x == 0:\n        return f\"{x:.0f}%\" if percent else f\"{x:.0f}\"\n\n    if x < 1:\n        return f\"{x:.2f}%\" if percent else f\"{x:.2f}\"\n\n    if x < 10:\n        return f\"{x:.1f}%\" if percent else f\"{x:.1f}\"\n\n    return f\"{x:.0f}%\" if percent else f\"{x:.0f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n\n    if percent:\n        x *= 100\n\n    if np.abs(x) < 1e-3:\n        return f\"{x:.4g}%\" if percent else f\"{x:.4g}\"\n    elif np.abs(x) < 1e-2:\n        return f\"{x:.3g}%\" if percent else f\"{x:.3g}\"\n    elif np.abs(x) < 1e-1:\n        return f\"{x:.2g}%\" if percent else f\"{x:.2g}\"\n    elif np.abs(x) < 1e0:\n        return f\"{x:.1g}%\" if percent else f\"{x:.1g}\"\n    else:\n        return f\"{x:.0g}%\" if percent else f\"{x:.0g}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n\n    if percent:\n        x *= 100\n        s = f\"{x:.2f}%\"\n    else:\n        s = str(x)\n\n    if \"e\" in s:\n        return s\n\n    if \".\" in s:\n        s = s.rstrip(\"0\")\n\n    if s[-1] == \".\":\n        s = s[:-1]\n\n    return s\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n\n    if percent:\n        x *= 100\n\n    if x < 1e-2:\n        return f\"{x:.2g}%\" if percent else f\"{x:.2g}\"\n    elif x < 1e0:\n        return f\"{x:.1g}%\" if percent else f\"{x:.1g}\"\n    elif x < 1e4:\n        return f\"{int(x)}\" if percent else f\"{x:.1g}\"\n    else:\n        return f\"{int(x)}\" if percent else f\"{x:.1g}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n\n    if percent:\n        x *= 100\n\n    if x == 0:\n        return f\"{x:.0f}%\" if percent else str(x)\n\n    if x < 1e-2:\n        return f\"{x:.2g}%\" if percent else f\"{x:.2g}\"\n\n    return f\"{x:.1f}%\" if percent else f\"{x:.1f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n\n    x = float(x)\n\n    if percent:\n        x *= 100\n\n    if x == 0:\n        return \"0\"\n\n    if x < 1e-3:\n        return f\"{x:.3f}\"\n\n    if x < 1e-2:\n        return f\"{x:.4f}\"\n\n    if x < 1e0:\n        return f\"{x:.3f}\"\n\n    if x < 1e3:\n        return f\"{x:.2f}\"\n\n    if x < 1e6:\n        return f\"{x:.1f}\"\n\n    return f\"{x:.0f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n\n    if percent:\n        x *= 100\n\n    if x == 0:\n        return \"0.0\"\n\n    if x < 1:\n        return str(round(x, 2))\n\n    if x < 10:\n        return str(round(x, 1))\n\n    return str(round(x))\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n\n    if percent:\n        x *= 100\n\n    if abs(x) < 1e-3:\n        return f\"{x:.3f}%\" if percent else f\"{x:.3f}\"\n    elif abs(x) < 1e0:\n        return f\"{x:.2f}%\" if percent else f\"{x:.2f}\"\n    elif abs(x) < 1e1:\n        return f\"{x:.1f}%\" if percent else f\"{x:.1f}\"\n    else:\n        return f\"{x:.0f}%\" if percent else f\"{x:.0f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n\n    if percent:\n        x *= 100\n        return f\"{x:.2f}%\"\n\n    if x == 0:\n        return \"0\"\n\n    if x < 0.01:\n        return f\"{x:.2e}\"\n\n    if x < 1:\n        return f\"{x:.2f}\"\n\n    if x < 10:\n        return f\"{x:.1f}\"\n\n    return f\"{int(x)}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n    else:\n        if percent:\n            x = x * 100\n        x = float(x)\n        if x == 0:\n            return str(x)\n        else:\n            return f\"{x:.{np.ceil(np.log10(1/x))}f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n    else:\n        if percent:\n            x = x * 100\n        x_str = str(x)\n        if \".\" in x_str:\n            return x_str\n        else:\n            return x_str + \".0\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n    if percent:\n        x *= 100\n        return f\"{x:.2f}%\"\n    if x == 0:\n        return \"0\"\n    if x < 1:\n        return f\"{x:.2f}\".rstrip(\"0\")\n    return f\"{x:.1f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n\n    if percent:\n        x *= 100\n\n    if x == 0:\n        return f\"{x:.0f}%\" if percent else f\"{x:.0f}\"\n\n    if x < 1e-12:\n        return f\"{x:.0e}\"\n\n    if x < 1e-8:\n        return f\"{x:.5f}\"\n\n    if x < 1e-4:\n        return f\"{x:.4f}\"\n\n    if x < 1e-2:\n        return f\"{x:.3f}\"\n\n    if x < 1e0:\n        return f\"{x:.2f}\"\n\n    if x < 1e3:\n        return f\"{x:.1f}\"\n\n    if x < 1e6:\n        return f\"{x:.0f}\"\n\n    if x < 1e9:\n        return f\"{x:.1f}e6\"\n\n    if x < 1e12:\n        return f\"{x:.0f}e6\"\n\n    return f\"{x:.0f}\"\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        free_space = shutil.disk_usage(input_dir).free\n        if free_space < threshold_in_gb * 1e9:\n            sleep(sleep_time)\n        else:\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        disk_usage = shutil.disk_usage(input_dir)\n        if disk_usage.free / 1024 ** 3 < threshold_in_gb:\n            sleep(sleep_time)\n        else:\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        disk_usage = shutil.disk_usage(input_dir)\n        if disk_usage.free < threshold_in_gb * 1024 * 1024 * 1024:\n            sleep(sleep_time)\n        else:\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        _, _, free = shutil.disk_usage(input_dir)\n        if free < threshold_in_gb * 1024 * 1024 * 1024:\n            sleep(sleep_time)\n        else:\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        free_space = shutil.disk_usage(input_dir).free\n        if free_space / 1024 ** 3 < threshold_in_gb:\n            sleep(sleep_time)\n        else:\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        free_space = shutil.disk_usage(input_dir).free\n        if free_space < threshold_in_gb * 1024 ** 3:\n            sleep(sleep_time)\n        else:\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        _, _, free = shutil.disk_usage(input_dir)\n        if free < threshold_in_gb * 1024 * 1024 * 1024:\n            sleep(sleep_time)\n        else:\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        _, _, free = shutil.disk_usage(input_dir)\n        free_gb = free / 1e9\n        if free_gb < threshold_in_gb:\n            sleep(sleep_time)\n        else:\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        free_space = shutil.disk_usage(input_dir).free\n        if free_space < threshold_in_gb * 1024 * 1024 * 1024:\n            sleep(sleep_time)\n        else:\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        disk_usage = shutil.disk_usage(input_dir)\n        if disk_usage.free / 1024 / 1024 / 1024 < threshold_in_gb:\n            sleep(sleep_time)\n        else:\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        disk_usage = shutil.disk_usage(input_dir)\n        free_space = disk_usage.free / 1024 ** 3\n        if free_space >= threshold_in_gb:\n            break\n        sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        disk_usage = shutil.disk_usage(input_dir)\n        if disk_usage.free < threshold_in_gb * 1024 * 1024 * 1024:\n            sleep(sleep_time)\n        else:\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        if shutil.disk_usage(input_dir).free / (1024 ** 3) < threshold_in_gb:\n            sleep(sleep_time)\n        else:\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        disk_usage = shutil.disk_usage(input_dir)\n        free_space = disk_usage.free / (1024 ** 3)\n        if free_space > threshold_in_gb:\n            return\n        sleep(sleep_time)\n\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        if shutil.disk_usage(input_dir).free / (1024 ** 3) < threshold_in_gb:\n            sleep(sleep_time)\n        else:\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        if shutil.disk_usage(input_dir).free / 1024 ** 3 < threshold_in_gb:\n            sleep(sleep_time)\n        else:\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        disk_usage = shutil.disk_usage(input_dir)\n        if disk_usage.free / (1024 ** 3) < threshold_in_gb:\n            sleep(sleep_time)\n        else:\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    if not _BOTO3_AVAILABLE:\n        raise ImportError(\"botocore is required to use this function. Please install it with `pip install botocore`\")\n\n    if not os.path.isdir(input_dir):\n        raise FileNotFoundError(f\"The input directory {input_dir} does not exist.\")\n\n    if threshold_in_gb <= 0:\n        raise ValueError(f\"The threshold {threshold_in_gb} GB is not a valid value. It must be greater than 0.\")\n\n    if sleep_time <= 0:\n        raise ValueError(f\"The sleep time {sleep_time} seconds is not a valid value. It must be greater than 0.\")\n\n    s3 = S3Client(input_dir)\n    obj = parse.urlparse(input_dir)\n    _wait_for_file_to_exist(s3, obj, sleep_time)\n    while True:\n        try:\n            disk_usage = s3.get_disk_usage(obj.netloc)\n            if disk_usage.free_space_in_bytes / 1024 ** 3 < threshold_in_gb:\n                sleep(sleep_time)\n            else:\n                break\n        except Exception:\n            sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        _, _, free = shutil.disk_usage(input_dir)\n        free = free / 1024 ** 3\n        if free < threshold_in_gb:\n            sleep(sleep_time)\n        else:\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        disk_usage = shutil.disk_usage(input_dir)\n        if disk_usage.free / 1024 ** 3 < threshold_in_gb:\n            sleep(sleep_time)\n        else:\n            break\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_div(p, td))\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_div(p, td))\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_div(p, td))\n\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_pdf(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_div(p, td))\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  return p * jnp.diff(t)\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return math.safe_div(p, td)\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_div(p, td))\n\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_div(p, td))\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_div(p, td))\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return math.safe_div(p, td)\n\n\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  return p * jnp.diff(t)\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_div(p, td))\n\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return math.safe_div(p, td)\n\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_div(p, td))\n\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return math.safe_div(p, td)\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return math.safe_div(p, td)\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_div(p, td))\n\n\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return math.safe_div(p, td)\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return math.safe_div(p, td)\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_div(p, td))\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\" \", \"\")\n    return line_text"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Removing all spaces from the input text\n    line_text = line_text.replace(\" \", \"\")\n\n    # Segmenting the text into smaller parts or tokens\n    line_text = line_text.split()\n\n    return line_text"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\" \", \"\")\n    line_text = line_text.replace(\"\\n\", \"\")\n    line_text = line_text.replace(\"\\t\", \"\")\n    line_text = line_text.replace(\"\\r\", \"\")\n    line_text = line_text.replace(\"\\f\", \"\")\n    line_text = line_text.replace(\"\\v\", \"\")\n    line_text = line_text.replace(\"\\b\", \"\")\n    line_text = line_text.replace(\"\\a\", \"\")\n    line_text = line_text.replace(\"\\0\", \"\")\n    line_text = line_text.replace(\"\\1\", \"\")\n    line_text = line_text.replace(\"\\2\", \"\")\n    line_text = line_text.replace(\"\\3\", \"\")\n    line_text = line_text.replace(\"\\4\", \"\")\n    line_text = line_text.replace(\"\\5\", \"\")\n    line_text = line_text.replace(\"\\6\", \"\")\n    line_text = line_text.replace(\"\\7\", \"\")\n    line_text = line_text.replace(\"\\8\", \"\")\n    line_text = line_text.replace(\"\\9\", \"\")\n    line_text = line_text.replace(\"\\10\", \"\")\n    line_text = line_text.replace(\"\\11\", \"\")\n    line_text = line_text.replace(\"\\12\", \"\")\n    line_text = line_text.replace(\"\\13\", \"\")\n    line_text = line_text.replace(\"\\14\", \"\")\n    line_text = line_text.replace(\"\\15\", \"\")\n    line_text = line_text.replace(\"\\16\", \"\")\n    line_text = line_text.replace(\"\\17\", \"\")\n    line_text = line_text.replace(\"\\18\", \"\")\n    line_text = line_text.replace(\"\\19\", \"\")\n    line_text = line_text.replace(\"\\20\", \"\")\n    line_text = line_text.replace(\"\\21\", \"\")\n    line_text = line_text.replace(\"\\22\", \"\")\n    line_text = line_text.replace(\"\\23\", \"\")\n    line_text ="}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Remove all spaces from the input text.\n    line_text = line_text.replace(\" \", \"\")\n\n    # Segment the modified text into smaller parts or tokens.\n    line_tokens = sent_tokenize(line_text)\n\n    # Return the segmented text.\n    return line_tokens"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Remove all spaces from the input text.\n    line_text = line_text.replace(\" \", \"\")\n\n    # Segment the text into smaller parts.\n    line_text = line_text.split()\n\n    # Return the segmented text.\n    return line_text"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Remove all spaces from the input text.\n    line_text = line_text.replace(\" \", \"\")\n\n    # Split the modified text into tokens.\n    line_text = line_text.split()\n\n    # Join the tokens to form the modified text.\n    line_text = \"\".join(line_text)\n\n    return line_text"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Remove all spaces from the input text\n    line_text = line_text.replace(\" \", \"\")\n\n    # Segment the modified text into smaller parts or tokens\n    line_text_tokens = line_text.split()\n\n    # Return the segmented text\n    return line_text_tokens"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Removing all spaces from the input text.\n    line_text = line_text.replace(\" \", \"\")\n    # Splitting the text into smaller parts.\n    line_text = line_text.split()\n    # Returning the segmented text.\n    return line_text"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Removing all spaces from the text\n    line_text = line_text.replace(\" \", \"\")\n\n    # Segmenting the text into tokens\n    line_text_tokens = line_text.split(\"\\n\")\n\n    # Returning the segmented text\n    return line_text_tokens"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Removes all whitespace characters from the input text.\n    line_text = line_text.replace(\" \", \"\")\n\n    # Segment the modified text into smaller parts or tokens.\n    line_text = line_text.split()\n\n    # Return the segmented text.\n    return line_text"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Remove all spaces from the input text\n    line_text = line_text.replace(\" \", \"\")\n    line_text = line_text.replace(\"\\n\", \"\")\n    line_text = line_text.replace(\"\\t\", \"\")\n\n    # Segment the modified text into smaller parts or tokens\n    line_text_list = list(line_text)\n\n    return line_text_list"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Remove all spaces from the input text\n    line_text = line_text.replace(\" \", \"\")\n\n    # Split the modified text into tokens\n    line_text = line_text.split(\",\")\n\n    # Return the modified text\n    return line_text"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\" \", \"\")\n    line_text = line_text.replace(\"\\n\", \"\")\n    line_text = line_text.replace(\"\\t\", \"\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u201d\", \"'\")\n    line_text = line_text.replace(\"\u201c\", \"'\")\n    line_text = line_text.replace(\"-\", \"\")\n    line_text = line_text.replace(\"\u2013\", \"\")\n    line_text = line_text.replace(\"\u2014\", \"\")\n    line_text = line_text.replace(\"\u2014\", \"\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace(\"\u2019\", \"'\")\n    line_text = line_text.replace"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\" \", \"\")\n    line_text = line_text.replace(\"\\n\", \"\")\n    line_text = line_text.replace(\"\\t\", \"\")\n    line_text = line_text.replace(\"-\", \"\")\n    line_text = line_text.replace(\"\u2019\", \"\")\n    line_text = line_text.replace(\"\u2018\", \"\")\n    line_text = line_text.replace(\"\u201c\", \"\")\n    line_text = line_text.replace(\"\u201d\", \"\")\n    line_text = line_text.replace(\"\u201c\", \"\")\n    line_text = line_text.replace(\"\u2022\", \"\")\n    line_text = line_text.replace(\"*\", \"\")\n    line_text = line_text.replace(\"\u2022\", \"\")\n    line_text = line_text.replace(\"\u2022\", \"\")\n    line_text = line_text.replace(\"\u2022\", \"\")\n    line_text = line_text.replace(\"\u2022\", \"\")\n    line_text = line_text.replace(\"\u2022\", \"\")\n    line_text = line_text.replace(\"\u2022\", \"\")\n    line_text = line_text.replace(\"\u2022\", \"\")\n    line_text = line_text.replace(\"\u2022\", \"\")\n    line_text = line_text.replace(\"\u2022\", \"\")\n    line_text = line_text.replace(\"\u2022\", \"\")\n    line_text = line_text.replace(\"\u2022\", \"\")\n    line_text = line_text.replace(\"\u2022\", \"\")\n    line_text = line_text.replace(\"\u2022\", \"\")\n    line_text = line_text.replace(\"\u2022\", \"\")\n    line_text = line_text.replace(\"\u2022\", \"\")\n    line_text = line_text.replace(\"\u2022\", \"\")\n    line_text = line_text.replace(\"\u2022\", \"\")\n    line_text = line_text.replace(\"\u2022\", \"\")\n    line_text = line_text.replace(\"\u2022\", \"\")\n    line_text = line_text.replace(\"\u2022\", \"\")\n    line_text = line_text.replace(\"\u2022\", \"\")\n    line_text = line_text.replace(\"\u2022\", \"\")\n    line_text"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Remove all whitespace characters from the input text and then segment the modified text into smaller parts or tokens.\n    line_text = re.sub(\"\\\\s+\", \"\", line_text)\n\n    # Split the text into smaller parts or tokens.\n    line_text = line_text.split()\n\n    return line_text"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Removing all spaces from the text.\n    line_text = line_text.replace(\" \", \"\")\n    # Splitting the text into tokens.\n    line_text = line_text.split()\n    # Returning the list of tokens.\n    return line_text\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Remove all spaces from the input text.\n    line_text = line_text.replace(\" \", \"\")\n\n    # Segment the modified text into smaller parts or tokens.\n    line_text = line_text.split()\n\n    # Return the segmented text.\n    return line_text\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Remove all whitespace characters from the input text.\n    line_text = line_text.replace(\" \", \"\")\n\n    # Segment the modified text into smaller parts or tokens.\n    line_text = line_text.split()\n\n    return line_text\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Remove all spaces from the input text.\n    line_text = line_text.replace(\" \", \"\")\n\n    # Segment the modified text into smaller parts or tokens.\n    tokens = line_text.split(\",\")\n\n    # Join all tokens back together.\n    line_text = \",\".join(tokens)\n\n    return line_text\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Remove all spaces from the input text.\n    line_text = line_text.replace(\" \", \"\")\n\n    # Segment the text into smaller parts.\n    line_text = line_text.split()\n\n    return line_text\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zeros must not exceed the total number of weights.\")\n\n    weights = np.random.rand(n)\n    weights /= weights.sum()\n\n    if zeros > 0:\n        weights[np.random.choice(n, zeros, replace=False)] = 0\n\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    # Check if the number of zeros is valid\n    if zeros > n:\n        raise ValueError(\"The number of zeros cannot exceed the total number of weights.\")\n\n    # Generate the weights\n    weights = np.random.rand(n)\n\n    # Normalize the weights\n    weights = weights / np.sum(weights)\n\n    # Set the specified number of zeros\n    weights[np.random.choice(n, zeros, replace=False)] = 0\n\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zeros cannot exceed the total number of weights.\")\n\n    if zeros == 0:\n        return np.random.dirichlet(np.ones(n))\n\n    weights = np.zeros(n)\n    weights[:-zeros] = np.random.dirichlet(np.ones(n - zeros))\n    weights[-zeros:] = np.zeros(zeros)\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zeros cannot exceed the total number of weights.\")\n\n    weights = np.random.rand(n)\n\n    if zeros > 0:\n        weights[np.random.choice(n, zeros, replace=False)] = 0\n\n    return weights / np.sum(weights)\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zeros cannot exceed the total number of weights.\")\n    if zeros < 0:\n        raise ValueError(\"The number of zeros must be a non-negative integer.\")\n    if n < 1:\n        raise ValueError(\"The total number of weights must be a positive integer.\")\n    if zeros == 0:\n        return np.random.dirichlet(np.ones(n))\n    else:\n        weights = np.random.dirichlet(np.ones(n - zeros))\n        zeros_indices = np.random.choice(n, zeros, replace=False)\n        weights[zeros_indices] = 0\n        return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zeros cannot be greater than the total number of weights.\")\n\n    if zeros == 0:\n        return np.random.dirichlet(np.ones(n))\n\n    else:\n        non_zero_weights = np.random.dirichlet(np.ones(n - zeros))\n        zero_weights = np.zeros(zeros)\n        return np.concatenate((non_zero_weights, zero_weights))\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zeros cannot exceed the number of weights.\")\n    weights = np.random.rand(n - zeros)\n    weights /= weights.sum()\n    weights = np.append(weights, np.zeros(zeros))\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zeros must not exceed the number of weights\")\n\n    if zeros == 0:\n        return np.random.dirichlet(np.ones(n))\n\n    else:\n        if zeros == n:\n            return np.zeros(n)\n\n        else:\n            weights = np.zeros(n)\n            weights[0:n - zeros] = np.random.dirichlet(np.ones(n - zeros))\n            weights[n - zeros:] = 0\n            return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zeros must be less than or equal to the total number of weights\")\n\n    weights = np.random.rand(n)\n    weights = weights / np.sum(weights)\n    if zeros > 0:\n        weights[np.random.randint(0, n, zeros)] = 0\n\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zeros must not exceed the total number of weights\")\n\n    weights = np.random.rand(n)\n    weights /= weights.sum()\n\n    if zeros > 0:\n        weights[np.random.choice(n, zeros, replace=False)] = 0\n\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zeros must not exceed the total number of weights.\")\n    if zeros < 0:\n        raise ValueError(\"The number of zeros must be a non-negative integer.\")\n    weights = np.random.rand(n)\n    weights = weights / np.sum(weights)\n    if zeros > 0:\n        weights[np.random.choice(n, zeros, replace=False)] = 0\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zeros must not exceed the number of weights.\")\n    if zeros < 0:\n        raise ValueError(\"The number of zeros must be non-negative.\")\n\n    # Generate a vector of random weights\n    weights = np.random.rand(n)\n\n    # Normalize the weights\n    weights = weights / np.sum(weights)\n\n    # Set the specified number of weights to zero\n    if zeros > 0:\n        weights[np.random.choice(n, zeros, replace=False)] = 0\n\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zeros must be smaller than the total number of weights.\")\n    if zeros < 0:\n        raise ValueError(\"The number of zeros must be a non-negative integer.\")\n\n    weights = np.random.random(n)\n    weights = weights / np.sum(weights)\n    if zeros > 0:\n        weights[np.random.choice(n, zeros, replace=False)] = 0\n\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zero weights cannot exceed the total number of weights.\")\n    if zeros < 0:\n        raise ValueError(\"The number of zero weights must be non-negative.\")\n    weights = np.random.rand(n)\n    weights = weights / weights.sum()\n    if zeros > 0:\n        weights[:zeros] = 0\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\n            \"The number of zero-weights must not exceed the total number of weights.\"\n        )\n\n    weights = np.random.rand(n)\n    weights = weights / np.sum(weights)\n    weights[np.random.choice(n, zeros, replace=False)] = 0\n\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"'zeros' must not exceed 'n'.\")\n\n    weights = np.random.rand(n)\n    weights = weights / np.sum(weights)\n\n    if zeros > 0:\n        weights[np.random.randint(0, n, zeros)] = 0\n\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zeros cannot exceed the total number of weights.\")\n    elif zeros < 0:\n        raise ValueError(\"The number of zeros cannot be negative.\")\n    else:\n        weights = np.random.rand(n)\n        weights = weights / np.sum(weights)\n        zeros = np.random.choice(n, zeros, replace=False)\n        weights[zeros] = 0\n        return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError('The number of zeros must be less than or equal to the total number of weights.')\n\n    if zeros == 0:\n        return np.random.dirichlet(np.ones(n))\n\n    else:\n        if zeros > n / 2:\n            weights = np.ones(n)\n            weights[:zeros] = 0\n            np.random.shuffle(weights)\n            return weights / weights.sum()\n\n        else:\n            weights = np.zeros(n)\n            weights[zeros:] = 1\n            np.random.shuffle(weights)\n            return weights / weights.sum()\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"'zeros' must not exceed 'n'\")\n    if zeros < 0:\n        raise ValueError(\"'zeros' must be greater than or equal to zero\")\n\n    # generate random weights\n    weights = np.random.rand(n)\n\n    # normalize weights\n    weights = weights / weights.sum()\n\n    # set zero-weights\n    if zeros > 0:\n        zero_indices = np.random.choice(n, zeros, replace=False)\n        weights[zero_indices] = 0\n\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zeros cannot exceed the total number of weights.\")\n    if zeros < 0:\n        raise ValueError(\"The number of zeros must be a non-negative integer.\")\n    if n <= 0:\n        raise ValueError(\"The total number of weights must be a positive integer.\")\n\n    weights = np.random.rand(n)\n    weights = weights / np.sum(weights)\n    if zeros > 0:\n        weights[np.random.choice(n, zeros, replace=False)] = 0\n    return weights\n\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        module_param = deepcopy(module_dict)\n        return cls(module_type=module_type, module_param=module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        return cls(module_type=module_type, module_param=module_dict)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        return cls(module_type=module_type, module_param=module_dict)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        return cls(**deepcopy(module_dict))"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop(\"module_type\")\n        return cls(module_type, module_dict)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        return cls(module_type, module_dict)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        return cls(module_type=module_type, module_param=module_dict)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        return cls(module_type, module_dict)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        return cls(module_type=module_type, module_param=module_dict)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        return cls(module_dict['module_type'], module_dict['module_param'])\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        return cls(module_type, module_dict)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        return cls(module_type=module_type, module_param=module_dict)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        return cls(module_type=module_type, module_param=module_dict)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        return cls(module_dict[\"module_type\"], module_dict)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        module_param = module_dict\n        return cls(module_type, module_param)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop(\"module_type\")\n        return cls(module_type=module_type, module_param=module_dict)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop(\"module_type\")\n        return cls(module_type, module_dict)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop(\"module_type\")\n        return cls(module_type, module_dict)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        return cls(module_dict['module_type'], module_dict)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        module_param = module_dict\n        return cls(module_type=module_type, module_param=module_param)\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_y, center_x = (bbox[1] + bbox[3]) / 2, (bbox[0] + bbox[2]) / 2\n\n    # Find upper-left corner of the cropping region\n    crop_min_x = max(0, center_x - crop_size[1] / 2)\n    crop_min_y = max(0, center_y - crop_size[0] / 2)\n\n    # Find lower-right corner of the cropping region\n    crop_max_x = min(image_size[1], center_x + crop_size[1] / 2)\n    crop_max_y = min(image_size[0], center_y + crop_size[0] / 2)\n\n    crop_box = (crop_min_x, crop_min_y, crop_max_x, crop_max_y)\n\n    return T.CropTransform(*crop_box)\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_y, center_x = (bbox[1] + bbox[3]) * 0.5, (bbox[0] + bbox[2]) * 0.5\n\n    assert (\n        crop_size[0] > 0 and crop_size[1] > 0\n    ), \"Crop size must be positive.\"\n\n    assert (\n        image_size[0] >= center_y - crop_size[0] * 0.5 and image_size[1] >= center_x - crop_size[1] * 0.5\n    ), \"The crop region cannot be larger than the image size.\"\n\n    top = np.clip(center_y - crop_size[0] * 0.5, 0, image_size[0] - crop_size[0])\n    bottom = np.clip(top + crop_size[0], 0, image_size[0])\n    left = np.clip(center_x - crop_size[1] * 0.5, 0, image_size[1] - crop_size[1])\n    right = np.clip(left + crop_size[1], 0, image_size[1])\n    return T.CropTransform(top, left, bottom - top, right - left)\n\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_yx = (bbox[1] + bbox[3]) * 0.5, (bbox[0] + bbox[2]) * 0.5\n    assert (\n        center_yx[0] <= 1\n    ), \"Center of instance bounding box should be within the image ({0} >= 1)\".format(\n        center_yx[0]\n    )\n    assert (\n        center_yx[1] <= 1\n    ), \"Center of instance bounding box should be within the image ({0} >= 1)\".format(\n        center_yx[1]\n    )\n    assert (\n        image_size[0] > center_yx[0]\n    ), \"Image height should be larger than the center of the instance bounding box ({0} > {1})\".format(\n        image_size[0], center_yx[0]\n    )\n    assert (\n        image_size[1] > center_yx[1]\n    ), \"Image width should be larger than the center of the instance bounding box ({0} > {1})\".format(\n        image_size[1], center_yx[1]\n    )\n\n    # Find upper left corner of the crop\n    crop_size = np.asarray(crop_size)\n    allowed_border = 0\n    for attempt in range(10):\n        mode = \"random\"\n        max_size = tuple(1.0 * image_size)\n        min_size = tuple(0.6 * crop_size)\n        crop = transforms.RandomCrop.get_params(\n            Image.new(\"RGB\", tuple(image_size)), (0, 0), max_size, min_size\n        )\n        crop_coords = (crop[0], crop[1])\n        crop_height = crop[2]\n        crop_width = crop[3]\n        crop_box = BoxMode.convert("}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_y, center_x = (bbox[1] + bbox[3]) * 0.5, (bbox[0] + bbox[2]) * 0.5\n\n    assert (\n        image_size[0] >= center_y and image_size[1] >= center_x\n    ), \"The cropping region exceeds the boundary of the image!\"\n\n    if center_x >= crop_size[1] / 2:\n        box_x1 = max(center_x - crop_size[1] / 2, 0)\n    else:\n        box_x1 = 0\n\n    if center_y >= crop_size[0] / 2:\n        box_y1 = max(center_y - crop_size[0] / 2, 0)\n    else:\n        box_y1 = 0\n\n    if box_x1 + crop_size[1] > image_size[1]:\n        box_x1 = image_size[1] - crop_size[1]\n\n    if box_y1 + crop_size[0] > image_size[0]:\n        box_y1 = image_size[0] - crop_size[0]\n\n    return T.CropTransform(box_x1, box_y1, crop_size[1], crop_size[0])\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_yx = (bbox[1] + bbox[3]) * 0.5, (bbox[0] + bbox[2]) * 0.5\n    assert (\n        center_yx[0] <= 1\n    ), \"Center of instance bounding box should be within the image ({0} >= 1)\".format(\n        center_yx[0]\n    )\n    assert (\n        center_yx[1] <= 1\n    ), \"Center of instance bounding box should be within the image ({0} >= 1)\".format(\n        center_yx[1]\n    )\n\n    # Convert crop_size from float to int type\n    crop_size = np.round(np.array(crop_size))\n    # Compute the top left coordinates of the crop\n    min_yx = np.maximum(np.array(0, 0), np.array(center_yx) - 0.5 * crop_size)\n    max_yx = np.minimum(np.array(image_size), np.array(center_yx) + 0.5 * crop_size)\n    cropped_shape = (max_yx[1] - min_yx[1], max_yx[0] - min_yx[0])\n    return T.CropTransform(*min_yx, cropped_shape[1], cropped_shape[0])\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_yx = (bbox[1] + bbox[3]) * 0.5, (bbox[0] + bbox[2]) * 0.5\n    assert (\n        center_yx[0] <= 1\n    ), \"Center of instance bounding box should be inside of the image ({0})\"\n    assert (\n        center_yx[1] <= 1\n    ), \"Center of instance bounding box should be inside of the image ({0})\".format(center_yx)\n\n    # Find upper-left corner of the crop\n    crop_size = np.asarray(crop_size)\n    center_yx = np.asarray(center_yx)\n    crop_min = np.floor(center_yx - crop_size * 0.5 + 0.5)\n    crop_max = np.ceil(center_yx + crop_size * 0.5 + 0.5)\n    crop_ul = np.maximum(np.zeros_like(crop_min), crop_min)\n    # Find lower-right corner of the crop\n    h_max = int(min(image_size[0], crop_max[0]))\n    w_max = int(min(image_size[1], crop_max[1]))\n    crop_size = np.minimum(crop_size, np.asarray([h_max, w_max], dtype=np.int32) - crop_ul)\n\n    y1, x1 = np.floor(crop_ul).astype(int)\n    y2, x2 = y1 + crop_size[0], x1 + crop_size[1]\n    return T.CropTransform(x1, y1, x2, y2)\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_y, center_x = (bbox[1] + bbox[3]) / 2, (bbox[0] + bbox[2]) / 2\n\n    # Find the largest rotation-free crop size available that's smaller than the\n    # required crop size.\n    assert crop_size[0] <= image_size[0] and crop_size[1] <= image_size[1]\n    crop_height = min(image_size[0], crop_size[0])\n    crop_width = min(image_size[1], crop_size[1])\n\n    after_resize_crop_size = np.array([crop_height, crop_width])\n    center_after_resize = center_y * crop_height / image_size[0], center_x * crop_width / image_size[1]\n\n    # Convert the center point into integer pixel coordinates.\n    center_after_resize = np.round(center_after_resize).astype(int)\n\n    # Do the cropping and return the cropped region.\n    crop_transform = CropTransform(*center_after_resize, after_resize_crop_size[1], after_resize_crop_size[0])\n    return crop_transform\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_yx = (bbox[1] + bbox[3]) * 0.5, (bbox[0] + bbox[2]) * 0.5\n    assert (\n        center_yx[0] <= 1\n    ), \"Center of instance bounding box should be within [0, 1]\"\n    assert (\n        center_yx[1] <= 1\n    ), \"Center of instance bounding box should be within [0, 1]\"\n    assert (\n        image_size[0] >= crop_size[0]\n    ), \"Crop height should be smaller than or equal to image height\"\n    assert (\n        image_size[1] >= crop_size[1]\n    ), \"Crop width should be smaller than or equal to image width\"\n\n    # Find a crop size that does not exclude the center of the bounding box\n    bottom = int(center_yx[0] * image_size[0])\n    right = int(center_yx[1] * image_size[1])\n    available_height = image_size[0] - bottom\n    available_width = image_size[1] - right\n    pad_value = [\n        max(crop_size[0] - available_height, 0),\n        max(crop_size[1] - available_width, 0),\n    ]\n\n    assert (\n        pad_value[0] >= 0 and pad_value[1] >= 0\n    ), \"Crop size must be smaller than image size\"\n\n    crop_size = np.array(crop_size) + pad_value\n    crop_top = np.random.randint(0, image_size[0] - crop_size[0] + 1)\n    crop_left = np.random.randint(0, image_size[1] - crop_size[1] + 1)\n\n    return T.CropTransform(crop_top, crop"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_y, center_x = (bbox[1] + bbox[3]) / 2, (bbox[0] + bbox[2]) / 2\n\n    # Find the amount of vertical/horizontal space that the crop takes up in the image\n    actual_height = bbox[3] - bbox[1]\n    actual_width = bbox[2] - bbox[0]\n\n    # Calculate the scale for height and width of the crop region\n    scaled_height = crop_size[0] / actual_height\n    scaled_width = crop_size[1] / actual_width\n\n    # Calculate the new bounding box co-ordinates\n    new_top_left_y = center_y - (scaled_height * actual_height) / 2\n    new_top_left_x = center_x - (scaled_width * actual_width) / 2\n    new_bottom_right_y = center_y + (scaled_height * actual_height) / 2\n    new_bottom_right_x = center_x + (scaled_width * actual_width) / 2\n\n    # Clip the co-ordinates to ensure they are within the image boundaries\n    new_top_left_y = np.clip(new_top_left_y, 0, image_size[0])\n    new_top_left_x = np.clip(new_top_left_x, 0, image_size[1])\n    new_bottom_right_y = np.clip(new_bottom_right_y, 0, image_size[0])\n    new_bottom_right_x = np.clip(new_bottom_right_x, 0, image_size[1])\n\n    return T.CropTransform(\n        int(new_top_left_x),\n        int(new_top_left_y),\n        int(new_bottom_right_x - new_top_left_x),"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n\n    # expand the bounding box a bit\n    x0, y0, x1, y1 = bbox\n    box_size = (x1 - x0) * (y1 - y0)\n    box_size_half = box_size ** 0.5\n    pad = 0 if box_size_half <= 2 else int(box_size_half)\n    x0 = max(x0 - pad, 0)\n    y0 = max(y0 - pad, 0)\n    x1 = min(x1 + pad, image_size[1])\n    y1 = min(y1 + pad, image_size[0])\n\n    # compute the translation that moves the center of the bbox to the center of the image\n    center = np.array([(x1 + x0) / 2, (y1 + y0) / 2])\n    h, w = crop_size\n    crop_center = np.array([w / 2, h / 2])\n    translation = np.round(crop_center - center).astype(int)\n\n    # crop size needs to be smaller than image size\n    assert (\n        h <= image_size[0] and w <= image_size[1]\n    ), f\"Crop size {(h, w)} is larger than image size {image_size}!\"\n\n    return T.CropTransform(x0, y0, w, h, translation)\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_y, center_x = (bbox[1] + bbox[3]) / 2, (bbox[0] + bbox[2]) / 2\n\n    # Find upper-left corner of crop that will contain the center point\n    crop_top = max(0, center_y - crop_size[0] / 2)\n    crop_left = max(0, center_x - crop_size[1] / 2)\n\n    # Find height and width of crop\n    crop_height = min(crop_size[0], image_size[0])\n    crop_width = min(crop_size[1], image_size[1])\n\n    return T.CropTransform(crop_top, crop_left, crop_height, crop_width)\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_y, center_x = (bbox[1] + bbox[3]) * 0.5, (bbox[0] + bbox[2]) * 0.5\n\n    # convert crop_size to tuple type\n    crop_size = tuple(crop_size)\n\n    # Compute the cropping coordinates and size\n    crop_coords, crop_size = center_crop_coords_and_size(center_y, center_x, crop_size, image_size)\n\n    return CropTransform(*crop_coords, *crop_size)\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_y, center_x = (bbox[1] + bbox[3]) / 2, (bbox[0] + bbox[2]) / 2\n\n    # Find the largest rotation-free crop that fits within the image boundaries.\n    # We do a linear search for the best crop.\n    best_crop = None\n    for aspect_ratio in [0.8, 0.75, 0.5, 0.33, 0.25]:\n        # Crop height and width.\n        crop_height = int(math.ceil(crop_size[0] / aspect_ratio))\n        crop_width = int(math.ceil(crop_size[1] * aspect_ratio))\n        # Crop top-left corner.\n        crop_top = int(round(center_y - crop_height / 2.0))\n        crop_left = int(round(center_x - crop_width / 2.0))\n        # Calculate validity of crop.\n        is_valid = True\n        # Check whether the crop is within image boundaries.\n        is_valid = is_valid and crop_top >= 0 and crop_left >= 0\n        is_valid = is_valid and crop_top + crop_height <= image_size[0]\n        is_valid = is_valid and crop_left + crop_width <= image_size[1]\n        # Check whether the crop contains the center of the bounding box.\n        is_valid = is_valid and center_x >= crop_left and center_x <= crop_left + crop_width\n        is_valid = is_valid and center_y >= crop_top and center_y <= crop_top + crop_height\n        # If crop is valid, stop searching for a better crop.\n        if is_valid:\n            best_crop = (crop_top, crop_"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_y, center_x = (bbox[1] + bbox[3]) * 0.5, (bbox[0] + bbox[2]) * 0.5\n\n    # TODO: better crop augmentation\n    cropsize_min = min(crop_size)\n    cropsize_max = max(crop_size)\n\n    # The center of the crop must lie within the image boundaries, and the crop size must not exceed the image size\n    center_x = min(center_x, image_size[1] - cropsize_min - 1)\n    center_x = max(center_x, cropsize_min)\n    center_y = min(center_y, image_size[0] - cropsize_min - 1)\n    center_y = max(center_y, cropsize_min)\n\n    # The crop must contain at least one valid pixel\n    size = max(\n        min(cropsize_max, image_size[1] - center_x),\n        min(cropsize_max, image_size[0] - center_y),\n    )\n\n    crop_tfm = T.CropTransform(center_x, center_y, size, size)\n\n    return crop_tfm\n\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n\n    # Find the center of the bounding box\n    bbox_center_x = (bbox[0] + bbox[2]) / 2\n    bbox_center_y = (bbox[1] + bbox[3]) / 2\n\n    # Compute the amount of horizontal and vertical space that the crop will take up in the image\n    crop_horizontal_space = crop_size[1]\n    crop_vertical_space = crop_size[0]\n\n    # Compute the amount of horizontal and vertical space that the bounding box takes up in the image\n    bbox_horizontal_space = bbox[2] - bbox[0]\n    bbox_vertical_space = bbox[3] - bbox[1]\n\n    # Compute the horizontal and vertical margins that the crop will be placed at around the bounding box\n    horizontal_margin = (\n        crop_horizontal_space - bbox_horizontal_space\n    ) / 2\n    vertical_margin = (crop_vertical_space - bbox_vertical_space) / 2\n\n    # Compute the top-left corner of the crop in the image\n    crop_x1 = bbox_center_x - horizontal_margin\n    crop_y1 = bbox_center_y - vertical_margin\n\n    # Ensure that the crop region is within the image region\n    crop_x1 = max(0, crop_x1)\n    crop_y1 = max(0, crop_y1)\n\n    # Ensure that the crop region has the desired dimensions\n    crop_x2 = crop_x1 + crop_size[1]\n    crop_y2 = crop_y1 + crop_size[0]\n\n    crop_x1 = min(crop_x1, image_size[1] - crop_size[1])\n    crop_x2 = min(crop_x2, image_size"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n\n    # ensure the instance bounding box is at least partially visible in the crop\n    bbox = _clip_box_to_image(bbox, image_size)\n\n    # expand the bounding box by 20%\n    m = 0.2\n    xmin, ymin, xmax, ymax = bbox\n    h, w = ymax - ymin, xmax - xmin\n    crop_size = np.array(crop_size)\n    bbox_shape = np.array([h, w])\n    padding = (bbox_shape - crop_size) * m\n    ymin, xmin = ymin - padding[0], xmin - padding[1]\n    ymax, xmax = ymax + padding[0], xmax + padding[1]\n    # convert bbox to crop\n    h, w = ymax - ymin, xmax - xmin\n    crop_box = BoxMode.convert((xmin, ymin, xmax, ymax), BoxMode.XYXY_ABS, BoxMode.XYXY_REL)\n\n    return T.CropTransform(*crop_box)\n\n\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_y, center_x = (bbox[1] + bbox[3]) * 0.5, (bbox[0] + bbox[2]) * 0.5\n\n    # We want to crop the largest possible area, but fit it into the requested crop size.\n    # To do so, we find the minimum scale of the crop that fits within the crop size and\n    # also covers the center of the cropping region.\n    scale = min(\n        crop_size[0] / (bbox[3] - bbox[1]),\n        crop_size[1] / (bbox[2] - bbox[0]),\n    )\n\n    # Scale the crop region (a square) by scale.\n    nbr_pixels_to_pad_on_each_side = (scale * max(bbox[2] - bbox[0], bbox[3] - bbox[1]) - (bbox[3] - bbox[1])) / 2\n\n    # Pad it proportionally to the top and left side of the region.\n    y_min = max(0, center_y - nbr_pixels_to_pad_on_each_side)\n    x_min = max(0, center_x - nbr_pixels_to_pad_on_each_side)\n\n    # Update crop size according to the padding\n    crop_size = (\n        min(crop_size[0], (bbox[3] - bbox[1]) * scale),\n        min(crop_size[1], (bbox[2] - bbox[0]) * scale),\n    )\n\n    # Crop coordinates\n    crop_coords = (\n        int(x_min),\n        int(y_min),\n        int(x_min + crop_size[1]),\n        int(y_min + crop_size[0]),\n    )\n\n    return T.CropTransform(*"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n\n    # In case no instance is provided, the cropping region is chosen randomly.\n    if bbox is None:\n        return RandomCrop(crop_size, image_size)\n\n    # Ensure the instance bounding box is within the image boundaries.\n    bbox = bbox.clip(image_size)\n\n    # Ensure the crop region contains the instance bounding box.\n    crop_size = np.asarray(crop_size)\n    bbox_size = np.asarray((bbox[2] - bbox[0], bbox[3] - bbox[1]))\n    crop_center = crop_size / 2\n    crop_center_x = crop_center[1] + (bbox[1] + bbox[3] - crop_center[1] * 2) / 2\n    crop_center_y = crop_center[0] + (bbox[0] + bbox[2] - crop_center[0] * 2) / 2\n\n    # Ensure the crop region has a minimum size.\n    min_size = np.min(bbox_size)\n    crop_size = np.where(\n        crop_size < min_size, (min_size, min_size), crop_size\n    )\n\n    return CropTransform(crop_center_x, crop_center_y, crop_size)\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_y, center_x = (bbox[1] + bbox[3]) / 2, (bbox[0] + bbox[2]) / 2\n\n    # Find the largest rotation-free crop size, so that we can find a crop that contains the center of the instance.\n    crop_size = np.maximum(crop_size, np.ceil(np.array(instance[\"bbox\"][2:])).astype(int))\n\n    crop_size = np.array(crop_size)\n    crop_size = np.ceil(crop_size / 2) * 2\n    crop_size_dwnsamp = crop_size\n\n    for i in range(20):\n        if crop_size[0] <= image_size[0] and crop_size[1] <= image_size[1]:\n            break\n        crop_size /= 2\n\n    # Crop image around the center of the instance\n    crop_corner = (np.array([center_x, center_y]) - crop_size / 2).astype(int)\n    crop_corner[0] = np.clip(crop_corner[0], 0, image_size[1])\n    crop_corner[1] = np.clip(crop_corner[1], 0, image_size[0])\n    crop_size = crop_size.astype(int)\n\n    crop_tl = (crop_corner[1], crop_corner[0])\n    crop_br = (crop_corner[1] + crop_size[1], crop_corner[0] + crop_size[0])\n    crop_tl = (crop_tl[0], crop_tl[1])\n    crop_br = (crop_br[0], crop_br[1])\n\n    crop_tl ="}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    crop_size = np.asarray(crop_size, dtype=np.int32)\n    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_yx = (bbox[1] + bbox[3]) * 0.5, (bbox[0] + bbox[2]) * 0.5\n    assert (\n        center_yx[0] <= 1\n    ), \"Center of bbox should be within [0, 1]\"\n    assert (\n        center_yx[1] <= 1\n    ), \"Center of bbox should be within [0, 1]\"\n\n    # Convert crop_size to float type, in case it is in int type\n    crop_size = crop_size.astype(float)\n\n    # Compute the valid minimum crop size (the minimum size, in pixel, of the remaining area that contains at least one pixel of the original image)\n    min_crop_size = np.sqrt(crop_size)\n\n    # Compute valid center\n    valid_center = center_yx\n\n    # Convert input image size (image_size) to numpy array format\n    image_size_np = np.asarray(image_size, dtype=np.int32)\n\n    # Compute valid crop height and width\n    valid_crop_size = np.minimum(image_size_np, min_crop_size)\n\n    # Compute valid crop top-left corner\n    valid_corner = np.maximum(np.floor(valid_center - valid_crop_size * 0.5), 0)\n\n    # Compute valid crop height and width\n    valid_crop_size = np.minimum(image_size_np - valid_corner, valid_crop_size)\n\n    # Construct and return the CropTransform object\n    return T.CropTransform(*valid_corner, *valid_crop_size)\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Calculate the squared norms of each vector along the last axis.\n  norms = jnp.sum(x * x, axis=-1, keepdims=True)\n\n  # Calculate the norms of each vector along the last axis.\n  # norms = jnp.sqrt(jnp.maximum(norms, grad_eps))\n  norms = jnp.sqrt(norms)\n\n  # Calculate the normalized vectors.\n  # x_normalized = x / norms\n  x_normalized = x / norms\n\n  # Return the normalized vectors.\n  return x_normalized\n\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # L2 normalize\n  norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  norm_clamped = jnp.maximum(norm, grad_eps)\n  x_normalized = x / norm_clamped\n\n  return x_normalized\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Compute the squared norm of the input vector(s).\n  x_norm_sq = jnp.sum(x * x, axis=-1, keepdims=True)\n\n  # Compute the norm of the input vector(s).\n  x_norm = jnp.sqrt(jnp.maximum(x_norm_sq, grad_eps))\n\n  # Compute the normalization constant.\n  const = 1.0 / x_norm\n\n  # Normalize the input vector(s).\n  x_normalized = const * x\n\n  # Return the normalized vector(s).\n  return x_normalized\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  x_norm = jnp.sqrt(jnp.maximum(jnp.sum(x ** 2, axis=-1, keepdims=True), grad_eps))\n  x_normed = x / x_norm\n\n  return x_normed\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Compute the squared norm of the input array\n  x_norm = jnp.sum(x * x, axis=-1, keepdims=True)\n\n  # Compute the sqrt of the squared norm with a minimum value of grad_eps to prevent exploding gradients in the backward pass\n  x_norm_sqrt = jnp.sqrt(jnp.maximum(x_norm, grad_eps))\n\n  # Divide the input array by the norm to normalize it\n  x_normalized = x / x_norm_sqrt\n\n  return x_normalized\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Compute the squared norm of each vector along the last axis\n  x_sqnorm = jnp.sum(x * x, axis=-1, keepdims=True)\n\n  # Compute the norm of each vector along the last axis\n  x_norm = jnp.sqrt(x_sqnorm)\n\n  # Compute the reciprocal of the norm of each vector along the last axis\n  x_invnorm = jnp.where(x_norm == 0.0, 0.0, 1.0 / x_norm)\n\n  # Normalize the input array by dividing it by the norm of each vector along the last axis\n  x_normalized = x * x_invnorm\n\n  # Compute the reciprocal of the squared norm of each vector along the last axis\n  x_invsqnorm = jnp.where(x_sqnorm == 0.0, 0.0, 1.0 / x_sqnorm)\n\n  # Clamp the reciprocal of the squared norm of each vector along the last axis to a minimum value\n  x_invsqnorm_clamped = jnp.maximum(x_invsqnorm, grad_eps)\n\n  # Clamp the reciprocal of the squared norm of each vector along the last axis to a minimum value\n  x_invsqnorm_clamped = jnp.maximum(x_invsqnorm, grad_eps)\n\n  # Clamp the squared norm of each vector along the last axis to a minimum value\n  x_sqnorm_clamped = jnp.maximum(x_sqnorm, grad_eps)\n\n  # Clamp the squared norm of each vector along the last axis to a minimum value\n  x_sqnorm_clamped = jnp.maximum(x_sqnorm, grad_eps)\n\n  # Compute the reciprocal of the squared norm of each vector along the last axis\n  x_invsqnorm = jnp.where(x_sqnorm == 0.0, 0.0, 1.0 / x_sqnorm)\n\n  # Clamp the reciprocal of the squ"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Compute the squared norm of x.\n  x_sq = jnp.sum(x * x, axis=-1, keepdims=True)\n\n  # Compute the norm of x.\n  x_norm = jnp.sqrt(x_sq)\n\n  # Compute the reciprocal of the norm of x.\n  x_norm_rec = jnp.reciprocal(x_norm)\n\n  # Clamp the reciprocal of the norm of x to a minimum value.\n  x_norm_rec_clamped = jnp.maximum(x_norm_rec, grad_eps)\n\n  # Compute the normalization constant.\n  norm_const = x_norm_rec_clamped * x_sq\n\n  # Return the normalized vector.\n  return x * norm_const\n\n\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Compute the squared norm of the input array\n  norm_sq = jnp.sum(x * x, axis=-1, keepdims=True)\n\n  # Compute the norm of the input array\n  norm = jnp.sqrt(jnp.maximum(norm_sq, grad_eps))\n\n  # Compute the normalization constant\n  const = 1.0 / norm\n\n  # Normalize the input array\n  x_normalized = x * const\n\n  return x_normalized\n\n\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Compute the squared norm of the input vector\n  x_norm = jnp.sum(x * x, axis=-1, keepdims=True)\n\n  # Ensure that the squared norm is at least grad_eps, to prevent division by zero during the backward pass\n  x_norm = jnp.maximum(x_norm, grad_eps)\n\n  # Normalize the input vector\n  x_normalized = x / jnp.sqrt(x_norm)\n\n  return x_normalized\n\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Calculate the squared norm of the input array\n  x_norm = jnp.sum(x * x, axis=-1, keepdims=True)\n\n  # Calculate the norm of the input array\n  x_norm = jnp.sqrt(x_norm)\n\n  # Calculate the reciprocal of the norm of the input array\n  x_norm_recip = jnp.reciprocal(x_norm)\n\n  # Calculate the reciprocal of the squared norm of the input array\n  x_norm_recip_sq = jnp.square(x_norm_recip)\n\n  # Calculate the reciprocal of the squared norm of the input array, but with a minimum value of grad_eps\n  x_norm_recip_sq = jnp.maximum(x_norm_recip_sq, grad_eps)\n\n  # Calculate the reciprocal of the norm of the input array, but with a minimum value of grad_eps\n  x_norm_recip = jnp.maximum(x_norm_recip, grad_eps)\n\n  # Normalize the input array\n  x_normalized = x * x_norm_recip\n\n  return x_normalized\n\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Compute the squared norm\n  sq_norm = jnp.sum(x * x, axis=-1, keepdims=True)\n\n  # If the squared norm is close to zero, then set the norm to be 1.\n  # This prevents gradients from blowing up.\n  sq_norm = jnp.where(jnp.logical_or(sq_norm < 0, sq_norm > grad_eps), sq_norm,\n                      grad_eps)\n\n  # Normalize the input vector(s)\n  x_normalized = x / jnp.sqrt(sq_norm)\n\n  return x_normalized\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Compute the squared norm along the last axis\n  sq_norm = jnp.sum(x * x, axis=-1, keepdims=True)\n\n  # Compute the norm along the last axis\n  norm = jnp.sqrt(jnp.maximum(sq_norm, grad_eps))\n\n  # Divide by the norm along the last axis\n  x_unit = x / norm\n\n  return x_unit\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Compute the squared norm\n  sq_norm = jnp.sum(x * x, axis=-1, keepdims=True)\n\n  # Apply the minimum value to the squared norm to prevent exploding gradients\n  sq_norm = jnp.maximum(sq_norm, grad_eps)\n\n  # Return the normalized vector\n  return x / jnp.sqrt(sq_norm)\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Calculate the squared norm of the input vector\n  norm = jnp.sum(x * x, axis=-1, keepdims=True)\n\n  # Calculate the norm of the input vector\n  norm_ = jnp.sqrt(jnp.maximum(norm, grad_eps))\n\n  # Normalize the input vector\n  x_normalized = x / norm_\n\n  return x_normalized\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Compute the squared norm\n  x_norm = jnp.sum(jnp.square(x), axis=-1, keepdims=True)\n\n  # Compute the normalization factor\n  norm_factor = jnp.sqrt(jnp.maximum(x_norm, grad_eps))\n\n  # Divide the input by the norm factor\n  x_unit = x / norm_factor\n\n  return x_unit\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Compute the squared norm of the input vector.\n  x_sqnorm = jnp.sum(x * x, axis=-1, keepdims=True)\n\n  # Compute the norm of the input vector.\n  x_norm = jnp.sqrt(x_sqnorm)\n\n  # Compute the reciprocal of the norm.\n  x_norm_rec = jnp.reciprocal(x_norm)\n\n  # Clamp the reciprocal of the squared norm to a minimum value to prevent\n  # exploding gradients.\n  x_sqnorm_rec_clamped = jnp.maximum(grad_eps / x_sqnorm, x_norm_rec)\n\n  # Compute the normalization of the input vector.\n  x_normalized = x * x_sqnorm_rec_clamped\n\n  return x_normalized\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Compute the squared norm of x.\n  x_norm = jnp.sum(x * x, axis=-1, keepdims=True)\n\n  # Compute the norm of x.\n  x_norm = jnp.sqrt(x_norm)\n\n  # Compute the reciprocal of the norm of x.\n  x_norm_recip = jnp.reciprocal(x_norm)\n\n  # Compute the reciprocal of the maximum of the norm of x, or grad_eps.\n  x_norm_recip = jnp.maximum(x_norm_recip, grad_eps)\n\n  # Return the normalized x.\n  return x * x_norm_recip\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Forward pass\n  x_norm = jnp.sqrt(jnp.maximum(jnp.sum(x**2, axis=-1, keepdims=True), grad_eps))\n  x_unit = x / x_norm\n\n  # Backward pass\n  x_unit_norm = jnp.sqrt(jnp.maximum(jnp.sum(x_unit**2, axis=-1, keepdims=True), grad_eps))\n  grad_x = (1.0 - 1.0 / x_unit_norm) * x_unit / x_unit_norm\n\n  return x_unit, grad_x\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Compute the squared norm of the input vector(s).\n  sq_norm = jnp.sum(jnp.square(x), axis=-1, keepdims=True)\n\n  # Compute the normalization constant for each vector separately.\n  sq_norm_ref = jnp.maximum(sq_norm, grad_eps)\n\n  # Compute the normalization constant for each vector separately.\n  norm = jnp.sqrt(sq_norm_ref)\n\n  # Divide by the normalization constant to normalize the vectors.\n  return x / norm\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Calculate the squared norm for each vector along the last axis\n  norm = jnp.sum(x * x, axis=-1, keepdims=True)\n\n  # Clamp the squared norm to prevent exploding gradients\n  norm = jnp.maximum(norm, grad_eps)\n\n  # Calculate the normalization term for each vector along the last axis\n  norm_term = 1.0 / jnp.sqrt(norm)\n\n  # Perform normalization\n  x_norm = norm_term * x\n\n  # Clamp the norm term to prevent exploding gradients\n  norm_term = jnp.maximum(norm_term, grad_eps)\n\n  return x_norm\n\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_name = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        input_text = \"\"\n        if \":\" in response:\n            input_text = response.split(\"Use Agent[\")[1].split(\"]\")[1].split(\":\")[1].strip()\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_name = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        input_text = \"\"\n        if \":\" in response:\n            input_text = response.split(\"Use Agent[\")[1].split(\"]\")[1].split(\":\")[1]\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_name = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        input_text = response.split(\"Use Agent[\")[1].split(\"]\")[1].split(\":\")[1]\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_name = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        input_text = \"\"\n        if \":\" in response:\n            input_text = response.split(\"Use Agent[\")[1].split(\"]\")[1].split(\":\")[1]\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_name = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        input_text = response.split(\"Use Agent[\")[1].split(\"]\")[1].split(\":\")[1] if \":\" in response else \"\"\n\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_name = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        input_text = response.split(\"Use Agent[\")[1].split(\"]\")[1].split(\":\")[1].strip()\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_name = response.split('Use Agent[')[-1].split(']')[0]\n        input_text = response.split('Use Agent[')[-1].split(']')[1].split(':')[-1].strip()\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        if \"Use Agent[\" in response:\n            agent_name = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n            input_text = response.split(\"Use Agent[\")[1].split(\"]\")[1].split(\":\")[1].strip()\n            return agent_name, input_text\n        else:\n            return \"\", \"\"\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_name = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        input_text = response.split(\"Use Agent[\")[1].split(\"]\")[1].split(\":\")[1]\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_name = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        input_text = response.split(\"Use Agent[\")[1].split(\"]\")[1].split(\":\")[1] if \":\" in response else \"\"\n\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_name = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        input_text = response.split(\"Use Agent[\")[1].split(\"]\")[1].split(\":\")[1].strip()\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_name = response.split('Use Agent[')[1].split(']')[0]\n        input_text = response.split(']')[1].strip()\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_name = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        input_text = response.split(\"Use Agent[\")[1].split(\"]\")[1].split(\":\")[1].strip()\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        start_index = response.index(\"Use Agent[\") + len(\"Use Agent[\")\n        end_index = response.index(\"]\")\n        agent_name = response[start_index:end_index]\n        if \":\" in response:\n            input_text = response[end_index + 1:]\n        else:\n            input_text = \"\"\n\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_name = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        input_text = response.split(\"]\")[1].split(\":\")[1] if \":\" in response else \"\"\n\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_name = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        input_text = response.split(\"Use Agent[\")[1].split(\"]\")[1].split(\":\")[1].strip() if \":\" in response else \"\"\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_name = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        input_text = \"\"\n        if \":\" in response:\n            input_text = response.split(\"Use Agent[\")[1].split(\"]\")[1].split(\":\")[1]\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        if \"Use Agent[\" not in response:\n            raise Exception(\"Agent invocation not found in response.\")\n\n        agent_name_start_index = response.find(\"Use Agent[\") + len(\"Use Agent[\")\n        agent_name_end_index = response.find(\"]\", agent_name_start_index)\n        agent_name = response[agent_name_start_index:agent_name_end_index]\n\n        input_text = \"\"\n        if \":\" in response:\n            input_text_start_index = response.find(\":\") + len(\":\")\n            input_text = response[input_text_start_index:]\n\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_name = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        input_text = response.split(\"Use Agent[\")[1].split(\"]\")[1].split(\":\")[1] if \":\" in response else \"\"\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        # Extract the agent's name from the response string\n        agent_name = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n\n        # Extract the input text from the response string, if it exists\n        input_text = \"\"\n        if \":\" in response:\n            input_text = response.split(\"Use Agent[\")[1].split(\"]\")[1].split(\":\")[1]\n\n        return agent_name, input_text\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    boxes.clip(image_size)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 2, \"Expect segmentation of 2 dimensions, got {}.\".format(\n                        segm.ndim\n                    )\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot convert segmentation of type '{}' to BitMasks!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict, or a full-image segmentation mask \"\n                        \"as a 2D ndarray.\".format(type(segm))\n                    )\n            # torch.from_numpy does not support array with negative stride.\n            masks = BitMasks(\n                torch."}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    boxes.clip(image_size)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 2, \"Expect segmentation of 2 dimensions, got {}.\".format(\n                        segm.ndim\n                    )\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot convert segmentation of type '{}' to BitMasks!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict, or a full-image segmentation mask \"\n                        \"as a 2D ndarray.\".format(type(segm))\n                    )\n            # torch.from_numpy does not support array with negative stride.\n            masks = BitMasks(\n                torch."}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    boxes.clip(image_size)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 2, \"Expect segmentation of 2 dimensions, got {}.\".format(\n                        segm.ndim\n                    )\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot convert segmentation of type '{}' to BitMasks!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict, or a full-image segmentation mask \"\n                        \"as a 2D ndarray.\".format(type(segm))\n                    )\n            # torch.from_numpy does not support array with negative stride.\n            masks = BitMasks(\n                torch."}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    boxes.clip(image_size)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 2, \"Expect segmentation of 2 dimensions, got {}.\".format(\n                        segm.ndim\n                    )\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot convert segmentation of type '{}' to BitMasks!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict, or a full-image segmentation mask \"\n                        \"as a 2D ndarray.\".format(type(segm))\n                    )\n            # torch.from_numpy does not support array with negative stride.\n            masks = BitMasks(\n                torch."}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    target.gt_boxes = Boxes(boxes)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 2, \"Expect segmentation of 2 dimensions, got {}.\".format(\n                        segm.ndim\n                    )\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot convert segmentation of type '{}' to BitMasks!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict, or a full-image segmentation mask \"\n                        \"as a 2D ndarray.\".format(type(segm))\n                    )\n            # torch.from_numpy does not support array with negative stride.\n            masks = BitMasks(\n                torch.stack([torch.from_numpy(np.as"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    boxes.clip(image_size)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 2, \"Expect segmentation of 2 dimensions, got {}.\".format(\n                        segm.ndim\n                    )\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot convert segmentation of type '{}' to BitMasks!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict, or a full-image segmentation mask \"\n                        \"as a 2D ndarray.\".format(type(segm))\n                    )\n            # torch.from_numpy does not support array with negative stride.\n            masks = BitMasks(\n                torch.stack"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    boxes.clip(image_size)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 2, \"Expect segmentation of 2 dimensions, got {}.\".format(\n                        segm.ndim\n                    )\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot convert segmentation of type '{}' to BitMasks!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict, or a full-image segmentation mask \"\n                        \"as a 2D ndarray.\".format(type(segm))\n                    )\n            # torch.from_numpy does not support array with negative stride.\n            masks = BitMasks(\n                torch.stack"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    target.gt_boxes = Boxes(boxes)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"bitmask\":\n            masks = convert_bitmasks_to_masks(segms, *image_size)\n        else:\n            masks = [polygons_to_bitmask(p, *image_size) for p in segms]\n        masks = torch.as_tensor(masks, dtype=torch.uint8)\n        target.gt_masks = BitMasks(masks)\n\n    if len(annos) and \"keypoints\" in annos[0]:\n        kpts = [obj.get(\"keypoints\", []) for obj in annos]\n        target.gt_keypoints = Keypoints(kpts)\n\n    return target\n\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    target.gt_boxes = Boxes(boxes)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"bitmask\":\n            masks = convert_bitmasks_to_masks(segms, *image_size)\n        else:\n            masks = [polygons_to_bitmask(p, *image_size) for p in segms]\n        masks = torch.as_tensor(masks, dtype=torch.uint8)\n        target.gt_masks = BitMasks(masks)\n\n    if len(annos) and \"keypoints\" in annos[0]:\n        kpts = [obj.get(\"keypoints\", []) for obj in annos]\n        target.gt_keypoints = Keypoints(kpts)\n\n    return target\n\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    target.gt_boxes = Boxes(boxes)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"bitmask\":\n            masks = convert_bitmasks_to_masks(segms, *image_size)\n        else:\n            masks = [polygons_to_bitmask(p, *image_size) for p in segms]\n        masks = torch.as_tensor(masks, dtype=torch.uint8)\n        target.gt_masks = BitMasks(masks)\n\n    if len(annos) and \"keypoints\" in annos[0]:\n        kpts = [obj.get(\"keypoints\", []) for obj in annos]\n        target.gt_keypoints = Keypoints(kpts)\n\n    return target\n\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    target.gt_boxes = Boxes(boxes)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"bitmask\":\n            masks = convert_bitmasks_to_masks(segms, *image_size)\n        else:\n            masks = [polygons_to_bitmask(p, *image_size) for p in segms]\n        masks = torch.as_tensor(masks, dtype=torch.uint8)\n        target.gt_masks = BitMasks(masks)\n\n    if len(annos) and \"keypoints\" in annos[0]:\n        kpts = [obj.get(\"keypoints\", []) for obj in annos]\n        target.gt_keypoints = Keypoints(kpts)\n\n    return target\n\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    target.gt_boxes = Boxes(boxes)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"bitmask\":\n            masks = convert_bitmasks_to_masks(segms, *image_size)\n        else:\n            masks = [polygons_to_bitmask(p, *image_size) for p in segms]\n        masks = torch.as_tensor(masks, dtype=torch.uint8)\n        target.gt_masks = BitMasks(masks)\n\n    if len(annos) and \"keypoints\" in annos[0]:\n        kpts = [obj.get(\"keypoints\", []) for obj in annos]\n        target.gt_keypoints = Keypoints(kpts)\n\n    return target\n\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    boxes.clip(image_size)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"bitmask\":\n            masks = convert_bitmasks_to_masks(segms, boxes, image_size)\n        else:\n            masks = [obj[\"segmentation\"] for obj in annos]\n        masks = PolygonMasks(masks)\n        target.gt_masks = masks\n\n    if len(annos) and \"keypoints\" in annos[0]:\n        kpts = [obj.get(\"keypoints\", []) for obj in annos]\n        target.gt_keypoints = Keypoints(kpts)\n\n    return target\n\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    target.gt_boxes = Boxes(boxes)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"bitmask\":\n            masks = convert_bitmasks_to_masks(segms, *image_size)\n        else:\n            masks = [polygons_to_bitmask(p, *image_size) for p in segms]\n        masks = torch.as_tensor(masks, dtype=torch.uint8)\n        target.gt_masks = BitMasks(masks)\n\n    if len(annos) and \"keypoints\" in annos[0]:\n        kpts = [obj.get(\"keypoints\", []) for obj in annos]\n        target.gt_keypoints = Keypoints(kpts)\n\n    return target\n\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    boxes.clip(image_size)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"bitmask\":\n            masks = convert_bitmasks_to_masks(segms, boxes, image_size)\n        else:\n            masks = [obj[\"segmentation\"] for obj in annos]\n            masks = PolygonMasks(masks).polygons\n        if len(masks):\n            masks = BitMasks(torch.stack(masks))\n        else:\n            masks = BitMasks(torch.empty(0, image_size[0], image_size[1], dtype=torch.bool))\n        target.gt_masks = masks\n\n    if len(annos) and \"keypoints\" in annos[0]:\n        kpts = [obj.get(\"keypoints\", []) for obj in annos]\n        target.gt_keypoints = Keypoints(kpts)\n\n    return target\n\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    target.gt_boxes = Boxes(boxes)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"bitmask\":\n            masks = convert_bitmasks_to_masks(segms, *image_size)\n        else:\n            masks = [polygons_to_bitmask(p, *image_size) for p in segms]\n        masks = torch.as_tensor(masks, dtype=torch.uint8)\n        target.gt_masks = BitMasks(masks)\n\n    if len(annos) and \"keypoints\" in annos[0]:\n        kpts = [obj.get(\"keypoints\", []) for obj in annos]\n        target.gt_keypoints = Keypoints(kpts)\n\n    return target\n\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    boxes.clip(image_size)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = BitMasks.from_polygon_masks(segms, *image_size)\n        target.gt_masks = masks\n\n    if len(annos) and \"keypoints\" in annos[0]:\n        kpts = np.array([obj.get(\"keypoints\", []) for obj in annos])\n        target.gt_keypoints = Keypoints(kpts)\n\n    return target\n\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    target.gt_boxes = Boxes(boxes)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"bitmask\":\n            masks = convert_bitmasks_to_masks(segms, *image_size)\n        else:\n            masks = [obj[\"segmentation\"] for obj in annos]\n        # torch.from_numpy does not support array with negative stride.\n        masks = BitMasks(\n            torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n        )\n        target.gt_masks = masks\n\n    if len(annos) and \"keypoints\" in annos[0]:\n        kpts = [obj.get(\"keypoints\", []) for obj in annos]\n        target.gt_keypoints = Keypoints(kpts)\n\n    return target\n\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    boxes.clip(image_size)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"bitmask\":\n            masks = convert_bitmasks_to_masks(segms, boxes, image_size)\n        else:\n            masks = [obj[\"segmentation\"] for obj in annos]\n            masks = PolygonMasks(masks).polygons\n        # Mask encoding methods\n        masks = BitMasks(masks)\n        target.gt_masks = masks\n\n    if len(annos) and \"keypoints\" in annos[0]:\n        kpts = [obj.get(\"keypoints\", []) for obj in annos]\n        target.gt_keypoints = Keypoints(kpts)\n\n    return target\n\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    boxes.clip(image_size)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"bitmask\":\n            masks = convert_bitmasks_to_masks(segms, boxes, image_size)\n        else:\n            masks = [obj[\"segmentation\"] for obj in annos]\n            masks = PolygonMasks(masks).polygons\n        # Mask encoding may ignore some polygons if there are too many\n        # then, filter out the polygons that were ignored\n        if hasattr(boxes, \"nonempty\"):\n            keep_masks = boxes.nonempty().nonzero().view(-1)\n            keep_masks = keep_masks.to(torch.device(masks.device))\n            masks = masks[keep_masks]\n        target.gt_masks = masks\n\n    if len(annos) and \"keypoints\" in annos[0]:\n        kpts = [obj.get(\"keypoints\", []) for obj in annos]\n        target.gt_keypoints = Keypoints(kpts)\n\n    return target\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path(\"~/skfolio_data\").expanduser())\n\n    data_home = Path(data_home)\n    data_home.mkdir(parents=True, exist_ok=True)\n\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    data_home = Path(data_home)\n    data_home.mkdir(parents=True, exist_ok=True)\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    data_home = Path(data_home)\n    data_home.mkdir(parents=True, exist_ok=True)\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\n            \"SKFOLIO_DATA\", Path.home() / \"skfolio_data\"\n        )\n    data_home = Path(data_home)\n    data_home.mkdir(parents=True, exist_ok=True)\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    data_home = Path(data_home)\n\n    if not data_home.exists():\n        data_home.mkdir(parents=True)\n\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\n            \"SKFOLIO_DATA\", Path.home() / \"skfolio_data\"\n        )\n\n    data_home = Path(data_home)\n\n    if not data_home.exists():\n        data_home.mkdir(parents=True, exist_ok=True)\n\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\n            \"SKFOLIO_DATA\", Path.home() / \"skfolio_data\"\n        )\n    data_home = Path(data_home).expanduser()\n    data_home.mkdir(exist_ok=True)\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n\n    data_home = Path(data_home)\n    data_home.mkdir(parents=True, exist_ok=True)\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path(\"~/skfolio_data\").expanduser())\n    data_home = Path(data_home)\n    data_home.mkdir(parents=True, exist_ok=True)\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    data_home = Path(data_home)\n    data_home.mkdir(parents=True, exist_ok=True)\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\n            \"SKFOLIO_DATA\", Path(\"~\", \"skfolio_data\")\n        )\n    data_home = Path(data_home).expanduser()\n\n    if not data_home.exists():\n        data_home.mkdir(parents=True, exist_ok=True)\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\n            \"SKFOLIO_DATA\", Path(\"~\", \"skfolio_data\")\n        )\n    data_home = Path(data_home).expanduser()\n\n    if not data_home.exists():\n        data_home.mkdir(parents=True, exist_ok=True)\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path(\"~/skfolio_data\").expanduser())\n    data_home = Path(data_home)\n    data_home.mkdir(parents=True, exist_ok=True)\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    data_home = Path(data_home).expanduser()\n\n    if not data_home.exists():\n        data_home.mkdir(parents=True, exist_ok=True)\n\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\n            \"SKFOLIO_DATA\", Path.home() / \"skfolio_data\"\n        )\n\n    data_home = Path(data_home)\n    data_home.mkdir(parents=True, exist_ok=True)\n\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    data_home = Path(data_home).expanduser()\n    data_home.mkdir(parents=True, exist_ok=True)\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    data_home = Path(data_home)\n    data_home.mkdir(parents=True, exist_ok=True)\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    data_home = Path(data_home)\n\n    if not data_home.exists():\n        data_home.mkdir(parents=True, exist_ok=True)\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\n            \"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    data_home = Path(data_home)\n    data_home.mkdir(parents=True, exist_ok=True)\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\n            \"SKFOLIO_DATA\", Path.home() / \"skfolio_data\"\n        )\n    data_home = Path(data_home)\n    data_home.mkdir(parents=True, exist_ok=True)\n    return str(data_home)\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    if not isinstance(cov, np.ndarray):\n        raise TypeError(\"cov must be a 2D numpy array\")\n    if cov.ndim != 2:\n        raise ValueError(\"cov must be a 2D numpy array\")\n    if not cov.shape[0] == cov.shape[1]:\n        raise ValueError(\"cov must be a 2D square matrix\")\n    if not np.allclose(cov, cov.T):\n        raise ValueError(\"cov must be a symmetric matrix\")\n\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    corr[corr < -1], corr[corr > 1] = -1, 1\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # Ensure the input is a 2D array\n    if cov.ndim != 2:\n        raise ValueError(\"Input must be a 2D array\")\n\n    # Calculate the standard deviation of each variable\n    std = np.sqrt(np.diag(cov))\n\n    # Calculate the correlation matrix\n    corr = cov / np.outer(std, std)\n\n    # Ensure the correlation matrix is symmetric\n    if not np.allclose(corr, corr.T):\n        raise ValueError(\"Correlation matrix must be symmetric\")\n\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # Ensure cov is a 2D array\n    if cov.ndim != 2:\n        raise ValueError(\"cov must be a 2D array\")\n\n    # Calculate the standard deviation of each variable\n    std = np.sqrt(np.diag(cov))\n\n    # Calculate the correlation matrix\n    corr = cov / np.outer(std, std)\n\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # Ensure cov is a 2D array\n    if cov.ndim != 2:\n        raise ValueError(\"The input must be a 2D array\")\n\n    # Ensure cov is a square matrix\n    if cov.shape[0] != cov.shape[1]:\n        raise ValueError(\"The input must be a square matrix\")\n\n    # Calculate the standard deviations for each variable\n    std = np.sqrt(np.diag(cov))\n\n    # Calculate the correlation matrix\n    corr = cov / np.outer(std, std)\n\n    # Ensure the correlation matrix is symmetric\n    if not np.allclose(corr, corr.T, atol=1e-5):\n        raise ValueError(\"The correlation matrix must be symmetric\")\n\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # Ensure the input is a 2D array\n    if cov.ndim != 2:\n        raise ValueError(\"The input must be a 2D array\")\n\n    # Calculate the standard deviation for each variable\n    std = np.sqrt(np.diag(cov))\n\n    # Calculate the correlation matrix\n    corr = cov / np.outer(std, std)\n\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # Ensure cov is a 2D array\n    if len(cov.shape) != 2:\n        raise ValueError(\"Input must be a 2D array\")\n\n    # Ensure cov is square\n    if cov.shape[0] != cov.shape[1]:\n        raise ValueError(\"Input must be a square matrix\")\n\n    # Calculate standard deviations\n    std = np.sqrt(np.diag(cov))\n\n    # Calculate correlation matrix\n    corr = cov / np.outer(std, std)\n\n    # Ensure correlation matrix is symmetric\n    if not np.allclose(corr, corr.T, atol=1e-5):\n        raise ValueError(\"Correlation matrix is not symmetric\")\n\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    if cov.ndim != 2:\n        raise ValueError(\"The input must be a 2D array\")\n\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    corr[corr < -1], corr[corr > 1] = -1, 1\n\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # Ensure the input is a 2D array\n    if cov.ndim != 2:\n        raise ValueError(\"The input must be a 2D array\")\n    # Calculate the standard deviation for each variable\n    std = np.sqrt(np.diag(cov))\n    # Calculate the correlation matrix\n    corr = cov / np.outer(std, std)\n    # Ensure the correlation matrix is symmetric\n    if not np.allclose(corr, corr.T, atol=1e-5):\n        raise ValueError(\"The correlation matrix must be symmetric\")\n    # Return the correlation matrix and the standard deviation for each variable\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # Check that the input is a 2D array\n    if cov.ndim != 2:\n        raise ValueError(\"The input must be a 2D array\")\n\n    # Calculate the standard deviation for each variable\n    std = np.sqrt(np.diag(cov))\n\n    # Calculate the correlation matrix\n    corr = cov / np.outer(std, std)\n\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # Check if the input is a 2D array.\n    if cov.ndim != 2:\n        raise ValueError(\"The input must be a 2D array.\")\n\n    # Get the standard deviations for each variable.\n    std = np.sqrt(np.diag(cov))\n\n    # Calculate the correlation matrix.\n    corr = cov / np.outer(std, std)\n\n    # Ensure the correlation matrix is symmetric.\n    if not np.allclose(corr, corr.T):\n        raise ValueError(\"The correlation matrix must be symmetric.\")\n\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # Check if the input is a 2D array\n    if len(cov.shape) != 2:\n        raise ValueError(\"The input must be a 2D array\")\n\n    # Calculate the standard deviation for each variable\n    std = np.sqrt(np.diag(cov))\n\n    # Calculate the correlation matrix\n    corr = cov / np.outer(std, std)\n\n    # Ensure the correlation matrix is symmetric\n    if not np.allclose(corr, corr.T, atol=1e-15):\n        raise ValueError(\"The correlation matrix must be symmetric\")\n\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # Ensure the input is a 2D array\n    if len(cov.shape) != 2:\n        raise ValueError(\"The input must be a 2D array.\")\n\n    # Calculate the standard deviations for each variable\n    std = np.sqrt(np.diag(cov))\n\n    # Calculate the correlation matrix\n    corr = cov / np.outer(std, std)\n\n    # Ensure the correlation matrix is symmetric\n    if not np.allclose(corr, corr.T, atol=1e-5):\n        raise ValueError(\"The correlation matrix must be symmetric.\")\n\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert_is_square(cov)\n    assert_is_positive_definite(cov)\n\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    if cov.ndim != 2:\n        raise ValueError(\"Input must be a 2D array\")\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    corr[corr < -1], corr[corr > 1] = -1, 1\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # check if cov is a 2D array\n    if len(cov.shape) != 2:\n        raise ValueError(\"cov must be a 2D array\")\n\n    # check if cov is square\n    if cov.shape[0] != cov.shape[1]:\n        raise ValueError(\"cov must be a square matrix\")\n\n    # get the standard deviations\n    std = np.sqrt(np.diag(cov))\n\n    # check if all standard deviations are non-zero\n    if np.any(std == 0):\n        raise ValueError(\"cov must not have any variables with zero standard deviation\")\n\n    # calculate the correlation matrix\n    corr = cov / np.outer(std, std)\n\n    # check if corr is symmetric\n    if not np.allclose(corr, corr.T):\n        raise ValueError(\"cov must be a symmetric matrix\")\n\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # Check if the input is a 2D array\n    if cov.ndim != 2:\n        raise ValueError(\"The input must be a 2D array\")\n\n    # Calculate the standard deviations for each variable\n    std = np.sqrt(np.diag(cov))\n\n    # Calculate the correlation matrix\n    corr = cov / np.outer(std, std)\n\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    if cov.ndim != 2:\n        raise ValueError(\"Covariance matrix must be a 2D array\")\n\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    if cov.ndim != 2:\n        raise ValueError(\"cov must be a 2D array\")\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    corr[corr < -1], corr[corr > 1] = -1, 1\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    if cov.ndim != 2:\n        raise ValueError(\"The input matrix is not 2-dimensional\")\n\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    if cov.ndim != 2:\n        raise ValueError(\"The input must be a 2D array.\")\n    if cov.shape[0] != cov.shape[1]:\n        raise ValueError(\"The input must be a square matrix.\")\n    if not np.allclose(cov, cov.T):\n        raise ValueError(\"The input must be a symmetric matrix.\")\n\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n\n    return corr, std\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    def _new_train(self, mode=True):\n        return mode\n\n    with ExitStack() as stack:\n        for module in model.modules():\n            stack.enter_context(mock.patch.object(module, \"train\", _new_train))\n        yield\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    def _new_train(self, mode: bool):\n        return mode\n\n    with ExitStack() as stack:\n        for name, _ in model.named_modules():\n            if name == \"\":\n                continue\n            module = getattr(model, name)\n            if hasattr(module, \"training\"):\n                stack.enter_context(mock.patch.object(module, \"training\", _new_train))\n        yield\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    def _new_train(self, mode=True):\n        return mode\n\n    def _new_eval(self, mode=True):\n        return mode\n\n    def _new_train_bn(self, mode=True):\n        return mode\n\n    def _new_eval_bn(self, mode=True):\n        return mode\n\n    def _new_train_fc(self, mode=True):\n        return mode\n\n    def _new_eval_fc(self, mode=True):\n        return mode\n\n    def _new_train_dropout(self, mode=True):\n        return mode\n\n    def _new_eval_dropout(self, mode=True):\n        return mode\n\n    def _new_train_layernorm(self, mode=True):\n        return mode\n\n    def _new_eval_layernorm(self, mode=True):\n        return mode\n\n    def _new_train_embedding(self, mode=True):\n        return mode\n\n    def _new_eval_embedding(self, mode=True):\n        return mode\n\n    def _new_train_embedding_dropout(self, mode=True):\n        return mode\n\n    def _new_eval_embedding_dropout(self, mode=True):\n        return mode\n\n    def _new_train_pos_embedding(self, mode=True):\n        return mode\n\n    def _new_eval_pos_embedding(self, mode=True):\n        return mode\n\n    def _new_train_attention(self, mode=True):\n        return mode\n\n    def _new_eval_attention(self, mode=True):\n        return mode\n\n    def _new_train_self_attention(self, mode=True):\n        return mode\n\n    def _new_eval_self_attention(self, mode=True):\n        return mode\n\n    def _new_train_multihead_attention(self, mode=True):\n        return mode\n\n    def _new_eval_multihead_attention(self, mode=True):\n        return mode\n\n    def"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    def _freeze_training_mode(module):\n        module.training = torch.jit.Final[bool]\n\n    with ExitStack() as stack:\n        for module in model.modules():\n            stack.enter_context(module.train(False))\n            stack.enter_context(module.requires_grad_(False))\n            stack.enter_context(module.apply(_freeze_training_mode))\n        yield\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # Save the original training attribute values\n    training_attrs = {}\n    for name, module in model.named_modules():\n        training_attrs[name] = module.training\n\n    # Temporarily set all submodules' training attributes to constants\n    for name, module in model.named_modules():\n        module.training = torch.jit.Final[bool](module.training)\n\n    yield\n\n    # Revert the training attribute values back to their original values\n    for name, module in model.named_modules():\n        module.training = training_attrs[name]\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    def _freeze_training_mode(module):\n        if hasattr(module, \"training\"):\n            module.training = torch.jit.Final[bool](module.training)\n\n    with ExitStack() as stack:\n        for m in model.modules():\n            stack.enter_context(mock.patch.object(m, \"training\", torch.jit.Final[bool](m.training)))\n        yield\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    def _new_training(obj):\n        return torch.jit.annotate(bool, obj.training)\n\n    with ExitStack() as stack:\n        for m in model.modules():\n            stack.enter_context(mock.patch.object(m, \"training\", _new_training))\n        yield\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    def _freeze_training_mode(module):\n        if hasattr(module, \"training\"):\n            module.training = torch.jit.Final[bool](module.training)\n\n    with ExitStack() as stack:\n        stack.enter_context(\n            mock.patch.object(\n                model,\n                \"train\",\n                new=torch.jit.Final[bool](model.training),\n            )\n        )\n        for name, mod in model.named_modules():\n            stack.enter_context(\n                mock.patch.object(\n                    mod,\n                    \"training\",\n                    new=torch.jit.Final[bool](mod.training),\n                )\n            )\n        yield\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    def _new_training(obj):\n        return obj.training\n\n    with ExitStack() as stack:\n        for m in model.modules():\n            if hasattr(m, \"training\"):\n                ctx = stack.enter_context(mock.patch.object(m, \"training\", side_effect=_new_training))\n        yield\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # Get the original training attribute of the model\n    original_training_attribute = model.training\n\n    # Create a new class definition for the model with the training attribute set to a constant\n    class_definition = type(model)\n    class_definition.training = torch.jit.Final[bool]\n\n    # Set the training attribute of the model to the constant\n    model.training = True\n\n    # Yield control to the context manager\n    yield\n\n    # Set the training attribute of the model back to its original value\n    model.training = original_training_attribute\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # Get a list of all submodules.\n    submodules = list(model.modules())\n\n    # Create a dictionary of the \"training\" attribute for each submodule.\n    # This will be used to restore the attribute values after the context manager exits.\n    training_dict = {}\n    for submodule in submodules:\n        training_dict[submodule] = submodule.training\n\n    # Set the \"training\" attribute of each submodule to a constant.\n    for submodule in submodules:\n        submodule.training = torch.jit.Final[bool](True)\n\n    yield\n\n    # Restore the original values of the \"training\" attribute for each submodule.\n    for submodule, original_training_value in training_dict.items():\n        submodule.training = original_training_value"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # Save the original class definitions of the model's submodules.\n    original_classes = {}\n    for name, submodule in model.named_modules():\n        original_classes[name] = submodule.__class__\n\n    # Annotate the \"training\" attribute of each submodule as a constant.\n    for name, submodule in model.named_modules():\n        submodule.__class__ = torch.jit.annotate(\n            torch.jit.Final[bool],\n            submodule.__class__,\n        )\n\n    yield\n\n    # Restore the original class definitions of the model's submodules.\n    for name, submodule in model.named_modules():\n        submodule.__class__ = original_classes[name]\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    def _new_train(self, mode=True):\n        return mode\n\n    with ExitStack() as stack:\n        for _, m in model.named_modules():\n            if hasattr(m, \"train\"):\n                stack.enter_context(mock.patch.object(m, \"train\", _new_train))\n        yield\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    with ExitStack() as stack:\n        for name, module in model.named_modules():\n            if name in (\"\", \"backbone\", \"backbone.body\"):\n                continue\n            if hasattr(module, \"training\"):\n                stack.enter_context(mock.patch.object(module, \"training\", torch.jit.Final[bool](True)))\n        yield\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    def _new_training(obj):\n        return obj.training\n\n    with ExitStack() as stack:\n        MODULES = [\"detectron2.modeling.backbone\", \"detectron2.modeling.roi_heads\", \"detectron2.modeling.meta_arch\"]\n        ctxs = [stack.enter_context(mock.patch(mod + \".training\")) for mod in MODULES]\n        for m in ctxs:\n            m.side_effect = _new_training\n        yield\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # A list of all submodules of the model to be frozen.\n    submodules = [model]\n    # A list of all submodules that have been frozen.\n    frozen = []\n\n    # Iterate through all submodules of the model, adding them to the list of submodules to be frozen.\n    while len(submodules) > 0:\n        # Retrieve the next submodule to be frozen.\n        submodule = submodules.pop(0)\n        # If the submodule has not already been frozen, freeze it and add it to the list of frozen submodules.\n        if submodule not in frozen:\n            frozen.append(submodule)\n            # If the submodule has a \"training\" attribute, annotate it as a constant.\n            if hasattr(submodule, \"training\"):\n                submodule.training = torch.jit.Final[bool](submodule.training)\n            # If the submodule has a \"model\" attribute, add it to the list of submodules to be frozen.\n            if hasattr(submodule, \"model\"):\n                submodules.append(submodule.model)\n            # If the submodule has a \"predictor\" attribute, add it to the list of submodules to be frozen.\n            if hasattr(submodule, \"predictor\"):\n                submodules.append(submodule.predictor)\n\n    # Yield control back to the caller of the context manager.\n    yield\n\n    # Iterate through all frozen submodules, reverting their class definitions to their original state.\n    for submodule in frozen:\n        # If the submodule has a \"training\" attribute, remove the annotation.\n        if hasattr(submodule, \"training\"):\n            submodule.training = torch.jit.annotations.pop(submodule.training)\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # Get the current training mode of the model.\n    training_mode = model.training\n\n    # Create a list of all submodules in the model.\n    submodules = [module for module in model.modules() if module != model]\n\n    # Iterate through all submodules and modify their class definitions.\n    for module in submodules:\n        # Get the name of the module's class.\n        module_class = type(module)\n\n        # Get the original class definition.\n        module_class_orig = getattr(module_class, \"__original_class\")\n\n        # If the module's class definition has not been modified, continue.\n        if module_class_orig is None:\n            continue\n\n        # Get the original training attribute of the module.\n        training_attr_orig = getattr(module_class_orig, \"__annotations__\")\n\n        # If the module's training attribute has not been modified, continue.\n        if training_attr_orig is None:\n            continue\n\n        # Annotate the original training attribute as a constant.\n        training_attr_orig[\"training\"] = torch.jit.Final[bool]\n\n        # Annotate the module's training attribute as a constant.\n        setattr(module_class, \"training\", torch.jit.Final[bool])\n\n    # Set the training mode of the model to the constant value.\n    model.train(False)\n\n    yield\n\n    # Set the training mode of the model to the original value.\n    model.train(training_mode)\n\n    # Iterate through all submodules and modify their class definitions.\n    for module in submodules:\n        # Get the name of the module's class.\n        module_class = type(module)\n\n        # Get the original class definition.\n        module_class_orig = getattr(module_class, \"__original_class\")\n\n        # If the module's class definition has not been modified, continue.\n        if module_class_orig is None:\n            continue\n\n        # Get the original training attribute of the module.\n        training_attr_orig = getattr(module_class"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # Create a list of all submodules\n    modules = [m for m in model.modules()]\n\n    # Iterate through all submodules and annotate their \"training\" attribute as a constant\n    for m in modules:\n        if hasattr(m, \"training\"):\n            m.__dict__[\"training\"] = torch.jit.Final[bool]\n\n    # Enter context\n    yield\n\n    # Iterate through all submodules and revert their \"training\" attribute to its original type\n    for m in modules:\n        if hasattr(m, \"training\"):\n            del m.__dict__[\"training\"]\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    def _new_train(self, mode: bool):\n        return mode\n\n    with ExitStack() as stack:\n        for name, submodule in model.named_modules():\n            if name == \"\":\n                continue\n            if hasattr(submodule, \"training\"):\n                ctx = stack.enter_context(mock.patch.object(submodule, \"training\", _new_train))\n        yield\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # Save the original training mode of each submodule\n    training_modes = {}\n    for name, module in model.named_modules():\n        if hasattr(module, \"training\"):\n            training_modes[name] = module.training\n\n    # Set the training mode of each submodule to be constant\n    for name, module in model.named_modules():\n        if hasattr(module, \"training\"):\n            module.training = torch.jit.Final[bool]\n\n    # Yield to the context manager\n    yield\n\n    # Revert the training mode of each submodule\n    for name, module in model.named_modules():\n        if hasattr(module, \"training\"):\n            module.training = training_modes[name]\n\n"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[Any]]) -> Dict[str, List[Any]]:\n        \"\"\"Check if shape(field1) equals shape(field2).\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if shape of field1 equals shape of field2.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if shape of field1 equals shape of field2.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if shape of field1 equals shape of field2.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if len(field1) equals len(field2).\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[Any]]) -> Dict[str, List[Any]]:\n        \"\"\"Check if shapes are equal.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[Any]]) -> Dict[str, List[Any]]:\n        \"\"\"Check if shapes of field1 and field2 are equal.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if shape(field1) equals shape(field2).\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[Any]]) -> Dict[str, List[Any]]:\n        \"\"\"Check if shape(field1) equals shape(field2).\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if shape(field1) equals shape(field2).\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[Any]]) -> Dict[str, List[Any]]:\n        \"\"\"Check if len(field1) equals len(field2).\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[Any]]) -> Dict[str, List[Any]]:\n        \"\"\"Check if shape(field1) equals shape(field2).\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[Any]]) -> Dict[str, List[Any]]:\n        \"\"\"Check if shape(field1) equals shape(field2).\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if len(field1) equals len(field2).\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[Any]]) -> Dict[str, List[Any]]:\n        \"\"\"Check if len(field1) equals len(field2).\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[Any]]) -> Dict[str, List[Any]]:\n        \"\"\"Check if shape(field1) equals shape(field2).\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[Any]]) -> Dict[str, List[Any]]:\n        \"\"\"Check if len(field1) equals len(field2).\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator\n\n\n"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if shape of field1 equals shape of field2.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[Any]]) -> Dict[str, List[Any]]:\n        \"\"\"Check if shapes of field1 and field2 match.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator\n\n\n"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[Any]]) -> Dict[str, List[Any]]:\n        \"\"\"Check if shape(field1) equals shape(field2).\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # Initialize metric names and parameters lists\n    metric_names = []\n    metric_params = []\n\n    # Iterate over metrics\n    for metric in metrics:\n\n        # If metric is a dictionary, extract name and parameters\n        if isinstance(metric, dict):\n            metric_names.append(metric['name'])\n            metric_params.append(metric['params'])\n\n        # If metric is a string, extract name and set parameters to None\n        elif isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append(None)\n\n    return metric_names, metric_params\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # Initialize variables\n    metric_names = []\n    metric_params = []\n\n    # Iterate over metrics\n    for metric in metrics:\n\n        # If metric is a string, add it to the list of metric names\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n\n        # If metric is a dictionary, extract metric name and parameters\n        elif isinstance(metric, dict):\n            metric_name = list(metric.keys())[0]\n            metric_params.append(metric[metric_name])\n            metric_names.append(metric_name)\n\n    return metric_names, metric_params\n\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # Initialize variables\n    metric_names: List[str] = []\n    metric_params: List[Dict[str, Any]] = []\n\n    # Loop over all metrics\n    for metric in metrics:\n\n        # If metric is a string, add it to the list of metric names\n        if isinstance(metric, str):\n            metric_names.append(metric)\n\n        # If metric is a dictionary, add it to the list of metric parameters\n        elif isinstance(metric, dict):\n            metric_params.append(metric)\n\n        # Raise an error if metric is neither a string nor a dictionary\n        else:\n            raise TypeError(f\"Metric '{metric}' has to be either a string or a dictionary.\")\n\n    # Return the list of metric names and metric parameters\n    return metric_names, metric_params\n\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # Initialize variables\n    metric_names: List[str] = []\n    metric_params: List[Dict[str, Any]] = []\n\n    # Iterate over metrics\n    for metric in metrics:\n\n        # If metric is a string, add it to the list of metric names\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n\n        # If metric is a dictionary, add it to the list of metric parameters\n        elif isinstance(metric, dict):\n            metric_names.append(metric[\"name\"])\n            metric_params.append(metric)\n\n        # If metric is neither a string nor a dictionary, raise an error\n        else:\n            raise TypeError(f\"Metrics must be either strings or dictionaries, but a {type(metric)} was passed.\")\n\n    # Return list of metric names and list of metric parameters\n    return metric_names, metric_params\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # Check if the input is a list of strings or a list of dictionaries\n    if isinstance(metrics[0], str):\n        # If it is a list of strings, return the list of strings as the first element and an empty list as the second element\n        return metrics, []\n    elif isinstance(metrics[0], dict):\n        # If it is a list of dictionaries, return the list of dictionaries as the second element and an empty list as the first element\n        return [], metrics\n    else:\n        # If the input is neither a list of strings nor a list of dictionaries, raise an error\n        raise TypeError(f\"Input metrics must be a list of strings or a list of dictionaries, not {type(metrics[0])}.\")\n\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # Cast metrics to list if only a single metric is provided\n    if isinstance(metrics, str) or isinstance(metrics, dict):\n        metrics = [metrics]\n\n    # Cast metrics to list if only a single metric is provided\n    if isinstance(metrics, str) or isinstance(metrics, dict):\n        metrics = [metrics]\n\n    # Cast metrics to list if only a single metric is provided\n    if isinstance(metrics, str) or isinstance(metrics, dict):\n        metrics = [metrics]\n\n    # Ensure that all metrics are either strings or dictionaries\n    for metric in metrics:\n        assert isinstance(metric, str) or isinstance(metric, dict), \"Metric must be either a string or a dictionary.\"\n\n    # Get metric names\n    metric_names = []\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n        elif isinstance(metric, dict):\n            metric_names.append(metric[\"name\"])\n\n    # Get metric parameters\n    metric_params = []\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_params.append({\"name\": metric})\n        elif isinstance(metric, dict):\n            metric_params.append(deepcopy(metric))\n\n    return metric_names, metric_params\n\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # If the input is a list of strings, we create a list of dictionaries with the metric name as the only parameter\n    if all(isinstance(metric, str) for metric in metrics):\n        metrics_names = deepcopy(metrics)\n        metrics_params = [{}] * len(metrics)\n\n    # If the input is a list of dictionaries, we extract the metric name and parameters\n    elif all(isinstance(metric, dict) for metric in metrics):\n        metrics_names = [metric[\"name\"] for metric in metrics]\n        metrics_params = deepcopy(metrics)\n\n    else:\n        raise ValueError(\"The input metrics must either be a list of strings or a list of dictionaries.\")\n\n    return metrics_names, metrics_params\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if isinstance(metrics, list):\n        if isinstance(metrics[0], str):\n            metric_names = deepcopy(metrics)\n            metric_params = [{} for _ in range(len(metrics))]\n        elif isinstance(metrics[0], dict):\n            metric_names = [metric['name'] for metric in metrics]\n            metric_params = deepcopy(metrics)\n        else:\n            raise ValueError('Metrics must be either a list of strings or a list of dictionaries')\n    else:\n        raise ValueError('Metrics must be either a list of strings or a list of dictionaries')\n\n    return metric_names, metric_params\n\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # Initialize lists for metric names and parameters\n    metric_names = []\n    metric_params = []\n\n    # Iterate over all metrics\n    for metric in metrics:\n\n        # If the metric is a string, add it to the list of metric names\n        if isinstance(metric, str):\n            metric_names.append(metric)\n\n        # If the metric is a dictionary, extract the metric name and parameters\n        elif isinstance(metric, dict):\n            metric_name = list(metric.keys())[0]\n            metric_params.append(metric[metric_name])\n            metric_names.append(metric_name)\n\n        # If the metric is not a string or dictionary, raise an error\n        else:\n            raise TypeError(f\"Metric {metric} is not a string or dictionary.\")\n\n    return metric_names, metric_params\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # Cast metrics to a list of strings\n    if isinstance(metrics, str):\n        metrics = [metrics]\n\n    # Cast metrics to a list of dictionaries\n    if isinstance(metrics, dict):\n        metrics = [metrics]\n\n    # Ensure that the metrics are a list of strings or dictionaries\n    if not isinstance(metrics, list):\n        raise TypeError(\"Metrics must be a list of strings or dictionaries.\")\n\n    # Ensure that the metrics are a list of strings or dictionaries\n    if not all(isinstance(metric, str) or isinstance(metric, dict) for metric in metrics):\n        raise TypeError(\"Metrics must be a list of strings or dictionaries.\")\n\n    # Cast metrics to a list of dictionaries\n    if all(isinstance(metric, str) for metric in metrics):\n        metrics = [{\"name\": metric} for metric in metrics]\n\n    # Ensure that the metrics are a list of dictionaries\n    if not all(isinstance(metric, dict) for metric in metrics):\n        raise TypeError(\"Metrics must be a list of strings or dictionaries.\")\n\n    # Ensure that the metric names are strings\n    if not all(isinstance(metric[\"name\"], str) for metric in metrics):\n        raise TypeError(\"Metric names must be strings.\")\n\n    # Ensure that the metric parameters are dictionaries\n    if not all(isinstance(metric[\"params\"], dict) for metric in metrics):\n        raise TypeError(\"Metric parameters must be dictionaries.\")\n\n    # Ensure that the metric parameters are dictionaries\n    if not all(isinstance(metric[\"params\"][\"metric_name\"], str) for metric in metrics):\n        raise TypeError(\"Metric parameters must contain a string for the metric name.\")\n\n    # Ensure that the metric parameters are dictionaries\n    if not all(isinstance(metric[\"params\"][\"metric_params\"], dict) for metric in metrics):\n        raise TypeError(\"Metric parameters must contain a dictionary for the metric parameters.\")\n\n    return [metric[\"name\"] for metric in metrics], [metric[\"params\"] for metric in metrics]\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # initialize metric names and parameters lists\n    metric_names = []\n    metric_parameters = []\n\n    # iterate over metrics\n    for metric in metrics:\n\n        # if metric is a string, add it to the list of metric names\n        if isinstance(metric, str):\n            metric_names.append(metric)\n\n        # if metric is a dictionary, extract metric name and parameters\n        elif isinstance(metric, dict):\n\n            # extract metric name\n            metric_name = metric.pop(\"name\")\n\n            # if metric name is not a string, raise an error\n            if not isinstance(metric_name, str):\n                raise TypeError(f\"Metric name should be a string, not a {type(metric_name)}.\")\n\n            # add metric name to the list of metric names\n            metric_names.append(metric_name)\n\n            # add metric parameters to the list of metric parameters\n            metric_parameters.append(metric)\n\n        # if metric is neither a string nor a dictionary, raise an error\n        else:\n            raise TypeError(f\"Metric should be a string or a dictionary, not a {type(metric)}.\")\n\n    # return the list of metric names and parameters\n    return metric_names, metric_parameters\n\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # cast metrics to a list if only a single metric is provided\n    if isinstance(metrics, str):\n        metrics = [metrics]\n\n    # cast metrics to a list if only a single metric is provided\n    if isinstance(metrics, dict):\n        metrics = [metrics]\n\n    # check if the metrics are provided in the correct format\n    for metric in metrics:\n        if isinstance(metric, str):\n            continue\n        if isinstance(metric, dict):\n            if 'metric' in metric.keys():\n                continue\n        raise ValueError(f\"Metrics must either be a string or a dictionary with the key 'metric'.\")\n\n    # extract metric names and parameters\n    metric_names = []\n    metric_params = []\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        if isinstance(metric, dict):\n            metric_names.append(metric['metric'])\n            metric_params.append(metric)\n\n    return metric_names, metric_params\n\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # initialize lists for metric names and parameters\n    metric_names = []\n    metric_params = []\n\n    # loop over all metrics\n    for metric in metrics:\n\n        # check if metric is a string\n        if isinstance(metric, str):\n\n            # append metric name to list\n            metric_names.append(metric)\n\n            # append empty dictionary to list\n            metric_params.append({})\n\n        # check if metric is a dictionary\n        elif isinstance(metric, dict):\n\n            # check if metric name is present\n            if 'name' in metric:\n\n                # append metric name to list\n                metric_names.append(metric['name'])\n\n            # raise error if metric name is not present\n            else:\n                raise ValueError('Metric dictionary must contain a \"name\" key.')\n\n            # check if metric parameters are present\n            if 'params' in metric:\n\n                # append metric parameters to list\n                metric_params.append(metric['params'])\n\n            # append empty dictionary to list if metric parameters are not present\n            else:\n                metric_params.append({})\n\n        # raise error if metric is neither a string nor a dictionary\n        else:\n            raise ValueError('Metrics must be strings or dictionaries.')\n\n    # return list of metric names and list of metric parameters\n    return metric_names, metric_params\n\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # Initialize variables\n    metric_names: List[str] = []\n    metric_params: List[Dict[str, Any]] = []\n\n    # Iterate over metrics\n    for metric in metrics:\n\n        # If the metric is a string, add it to the list of metric names\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n\n        # If the metric is a dictionary, add it to the list of metric parameters\n        elif isinstance(metric, dict):\n            metric_names.append(list(metric.keys())[0])\n            metric_params.append(list(metric.values())[0])\n\n        # If the metric is neither a string nor a dictionary, raise an error\n        else:\n            raise TypeError(\"Metrics must either be a string or a dictionary.\")\n\n    # Return the list of metric names and parameters\n    return metric_names, metric_params\n\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if not isinstance(metrics, list):\n        raise TypeError(\"The metrics parameter must be a list.\")\n\n    if len(metrics) == 0:\n        raise ValueError(\"The metrics parameter must not be empty.\")\n\n    if isinstance(metrics[0], str):\n        metric_names = deepcopy(metrics)\n        metric_parameters = [{} for _ in range(len(metrics))]\n    elif isinstance(metrics[0], dict):\n        metric_names = [metric[\"name\"] for metric in metrics]\n        metric_parameters = deepcopy(metrics)\n    else:\n        raise TypeError(\"The metrics parameter must be a list of strings or dictionaries.\")\n\n    return metric_names, metric_parameters\n\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # If metrics are a list of dictionaries, return them as is\n    if isinstance(metrics, list) and isinstance(metrics[0], dict):\n        return [metric[\"name\"] for metric in metrics], metrics\n\n    # If metrics are a list of strings, create a list of dictionaries\n    elif isinstance(metrics, list) and isinstance(metrics[0], str):\n        return metrics, [{\"name\": metric} for metric in metrics]\n\n    # If metrics are a dictionary, create a list of dictionaries\n    elif isinstance(metrics, dict):\n        return [metric for metric in metrics.keys()], [{\"name\": metric, **metrics[metric]} for metric in metrics.keys()]\n\n    # If metrics are a string, create a list of dictionaries\n    elif isinstance(metrics, str):\n        return [metrics], [{\"name\": metrics}]\n\n    else:\n        raise TypeError(\"Invalid type for metrics. Must be a list of strings or a dictionary.\")\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # if metrics is a list of strings, create a list of dictionaries with default parameters\n    if isinstance(metrics, list) and all(isinstance(metric, str) for metric in metrics):\n        metrics = [{'name': metric, 'params': {}} for metric in metrics]\n    # if metrics is a list of dictionaries, create a list of dictionaries with default parameters\n    elif isinstance(metrics, list) and all(isinstance(metric, dict) for metric in metrics):\n        metrics = [{'name': metric['name'], 'params': metric.get('params', {})} for metric in metrics]\n    # otherwise, raise an error\n    else:\n        raise ValueError('The input argument metrics must be either a list of strings or a list of dictionaries.')\n    return metrics\n\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # Check if the input is a list of strings or a list of dictionaries\n    if not (isinstance(metrics[0], str) or isinstance(metrics[0], dict)):\n        raise TypeError(\"The input must be a list of strings or a list of dictionaries.\")\n\n    # If the input is a list of strings, create a list of dictionaries with the metric name as the only parameter\n    if isinstance(metrics[0], str):\n        metrics = [{\"name\": metric} for metric in metrics]\n\n    # If the input is a list of dictionaries, ensure that the only parameters are \"name\" and \"params\"\n    if isinstance(metrics[0], dict):\n        for metric in metrics:\n            if not (len(metric) == 1 and (\"name\" in metric or \"params\" in metric)):\n                raise ValueError(\"Each metric must contain only the 'name' or 'params' parameter.\")\n            if \"name\" in metric and \"params\" in metric:\n                raise ValueError(\"Each metric can only contain the 'name' or 'params' parameter.\")\n\n    return [metric[\"name\"] for metric in metrics], metrics\n\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if not isinstance(metrics, list):\n        raise TypeError('Input metrics should be a list.')\n\n    if len(metrics) == 0:\n        raise ValueError('Input metrics should not be empty.')\n\n    if isinstance(metrics[0], str):\n        # if metrics are provided as strings, they are assumed to be metric names\n        # and are converted to dictionaries with default parameters\n        metrics_names = deepcopy(metrics)\n        metrics_params = [{'metric_name': metric_name} for metric_name in metrics_names]\n\n    elif isinstance(metrics[0], dict):\n        # if metrics are provided as dictionaries, they are assumed to contain\n        # metric details and are converted to dictionaries with default parameters\n        metrics_names = [metric['metric_name'] for metric in metrics]\n        metrics_params = deepcopy(metrics)\n        for metric_idx, metric_params in enumerate(metrics_params):\n            if 'metric_name' not in metric_params:\n                raise KeyError(f'Metric {metric_idx} does not contain a metric name.')\n            if 'metric_params' not in metric_params:\n                metric_params['metric_params'] = {}\n\n    else:\n        raise TypeError('Input metrics should be either a list of strings or a list of dictionaries.')\n\n    return metrics_names, metrics_params\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # Cast metrics into a list\n    if not isinstance(metrics, list):\n        metrics = [metrics]\n\n    # Check if all metrics are strings\n    if all(isinstance(metric, str) for metric in metrics):\n        # If so, return the list of metric names and an empty list of parameters\n        return metrics, []\n\n    # Otherwise, check if all metrics are dictionaries\n    elif all(isinstance(metric, dict) for metric in metrics):\n        # If so, return the list of metric names and a list of parameters\n        return [metric['name'] for metric in metrics], metrics\n\n    else:\n        # If neither all metrics are strings nor all metrics are dictionaries, raise an error\n        raise TypeError('Metrics must be either strings or dictionaries.')\n\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    if fn == contract:\n      fn_inv = inv_contract\n    elif fn == contract3_isoscale:\n      fn_inv = lambda x: jnp.exp(jnp.log(x) / 2)\n    else:\n      raise ValueError('No inverse provided for function.')\n\n  def t_to_s(t):\n    t = jnp.maximum(t_near, t)\n    t = jnp.minimum(t_far, t)\n    return fn_inv(fn(t))\n\n  def s_to_t(s):\n    return fn(t_to_s(s))\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  # If no inverse function is provided, try to automatically determine it based on a predefined mapping of functions to their inverses.\n  if fn_inv is None:\n    if fn is contract:\n      fn_inv = inv_contract\n    else:\n      raise ValueError('No inverse function provided, and none could be automatically determined.')\n\n  # Define the forward mapping from metric distances to normalized distances.\n  def t_to_s(t):\n    t = jnp.maximum(t_near, t)\n    t = jnp.minimum(t_far, t)\n    return fn_inv(fn(t))\n\n  # Define the backward mapping from normalized distances to metric distances.\n  def s_to_t(s):\n    return fn(t_to_s(s))\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  def t_to_s(t):\n    \"\"\"\n    Maps metric distances to normalized distances in the range [0, 1].\n    \"\"\"\n    return jnp.clip(fn(t), 0, 1)\n\n  def s_to_t(s):\n    \"\"\"\n    Maps normalized distances to metric distances.\n    \"\"\"\n    if fn_inv is None:\n      if fn == jnp.exp:\n        fn_inv = jnp.log\n      elif fn == jnp.sin:\n        fn_inv = jnp.arcsin\n      elif fn == jnp.tan:\n        fn_inv = jnp.arctan\n      elif fn == jnp.sinh:\n        fn_inv = jnp.arcsinh\n      elif fn == jnp.tanh:\n        fn_inv = jnp.arctanh\n      elif fn == jnp.arcsinh:\n        fn_inv = jnp.sinh\n      elif fn == jnp.arcsin:\n        fn_inv = jnp.sin\n      elif fn == jnp.arctanh:\n        fn_inv = jnp.tanh\n      elif fn == jnp.arctan:\n        fn_inv = jnp.tan\n      else:\n        raise ValueError('No inverse function provided for fn={}'.format(fn))\n    return fn_inv(jnp.clip(s, 0, 1) * (t_far - t_near) + t_near)\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    if fn == contract3_isoscale:\n      fn_inv = inv_contract3_isoscale\n    elif fn == contract:\n      fn_inv = inv_contract\n    else:\n      raise ValueError('No inverse provided for fn={}'.format(fn))\n\n  def t_to_s(t):\n    \"\"\"\n    Constructs the forward mapping from metric distances to normalized distances.\n    :param t: Tensor. Represents the metric distances in the metric space.\n    :return: Tensor. Represents the normalized distances in the normalized space.\n    \"\"\"\n    # Clip distances to ensure they fall within a valid range.\n    t = jnp.clip(t, t_near, t_far)\n    # Map distances to the range [0, 1].\n    s = (t - t_near) / (t_far - t_near)\n    # Map distances to the normalized space using the provided function.\n    s = fn(s)\n    return s\n\n  def s_to_t(s):\n    \"\"\"\n    Constructs the backward mapping from normalized distances to metric distances.\n    :param s: Tensor. Represents the normalized distances in the normalized space.\n    :return: Tensor. Represents the metric distances in the metric space.\n    \"\"\"\n    # Map distances from the normalized space using the provided function.\n    s = fn_inv(s)\n    # Map distances from the range [0, 1] to the metric space.\n    t = s * (t_far - t_near) + t_near\n    return t\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    if fn == contract:\n      fn_inv = inv_contract\n    elif fn == contract3_isoscale:\n      fn_inv = lambda x: fn_inv(x)\n    else:\n      raise ValueError('No inverse function provided for fn={fn}')\n\n  def t_to_s(t):\n    t = jnp.maximum(t_near, jnp.minimum(t_far, t))\n    return (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n  def s_to_t(s):\n    return fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t_near))\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    if fn == contract3_isoscale:\n      fn_inv = inv_contract3_isoscale\n    else:\n      raise ValueError(\n          'No inverse provided for fn, and no default inverse found.')\n\n  def t_to_s(t):\n    \"\"\"\n    Maps metric distances to normalized distances in the range [0, 1].\n    \"\"\"\n    return jax.nn.relu(\n        (fn(t_far) - fn(t)) / (fn(t_far) - fn(t_near))\n    )\n\n  def s_to_t(s):\n    \"\"\"\n    Maps normalized distances in the range [0, 1] to metric distances.\n    \"\"\"\n    return fn_inv(t_near) + s * (fn(t_far) - fn_inv(t_near))\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  # Determine the inverse of the function if not provided.\n  if fn_inv is None:\n    if fn == contract3_isoscale:\n      fn_inv = inv_contract3_isoscale\n    else:\n      raise ValueError(f'No inverse found for {fn}.')\n\n  # Define the forward mapping from metric to normalized distances.\n  def t_to_s(t):\n    return fn(t) / (t_far - t_near)\n\n  # Define the backward mapping from normalized to metric distances.\n  def s_to_t(s):\n    return fn_inv(s) * (t_far - t_near)\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  # If no inverse is provided, attempt to construct it automatically.\n  if fn_inv is None:\n    if fn == math.log_map:\n      fn_inv = math.exp_map\n    elif fn == math.exp_map:\n      fn_inv = math.log_map\n    else:\n      raise ValueError(f'No inverse for {fn}')\n\n  def t_to_s(t):\n    return fn_inv(fn(t_near) + (fn(t_far) - fn(t_near)) * (t - t_near) / (t_far - t_near))\n\n  def s_to_t(s):\n    return fn(t_near) + (fn(t_far) - fn(t_near)) * (s - t_near) / (t_far - t_near)\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  # TODO: Add support for non-linear functions.\n  if fn_inv is None:\n    if fn == contract3_isoscale:\n      fn_inv = inv_contract3_isoscale\n    else:\n      raise ValueError(\n          'No inverse provided for function {fn}, and no default inverse '\n          'is available.')\n\n  def t_to_s(t):\n    \"\"\"\n    Maps metric distances to normalized distances in the range [0, 1].\n\n    Input-Output Arguments\n    :param t: Tensor. Represents the metric distances.\n    :return: Tensor. Represents the normalized distances.\n    \"\"\"\n    return jnp.clip(fn(t) - t_near, 0, 1) / (t_far - t_near)\n\n  def s_to_t(s):\n    \"\"\"\n    Maps normalized distances to metric distances.\n\n    Input-Output Arguments\n    :param s: Tensor. Represents the normalized distances.\n    :return: Tensor. Represents the metric distances.\n    \"\"\"\n    return fn_inv(t_near + s * (t_far - t_near))\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    if fn.__name__ in ['contract', 'contract3_isoscale']:\n      fn_inv = inv_contract\n    else:\n      raise ValueError(f'No inverse provided for {fn.__name__}.')\n\n  def t_to_s(t):\n    \"\"\"\n    Maps metric distances to normalized distances in the range [0, 1].\n\n    Input-Output Arguments\n    :param t: Tensor. Represents metric distances in the metric space.\n    :return: Tensor. Represents normalized distances in the range [0, 1].\n    \"\"\"\n    t = jnp.maximum(t_near, t)\n    t = jnp.minimum(t_far, t)\n    s = fn(t)\n    return s\n\n  def s_to_t(s):\n    \"\"\"\n    Maps normalized distances to metric distances in the range [t_near, t_far].\n\n    Input-Output Arguments\n    :param s: Tensor. Represents normalized distances in the range [0, 1].\n    :return: Tensor. Represents metric distances in the metric space.\n    \"\"\"\n    t = fn_inv(s)\n    return t\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  # TODO: Add support for non-linear functions.\n  if fn_inv is None:\n    if fn in [lambda t: t, lambda t: 1 / t]:\n      fn_inv = fn\n    elif fn in [lambda t: jnp.sqrt(t), lambda t: 1 / jnp.sqrt(t)]:\n      fn_inv = lambda s: s**2\n    elif fn in [lambda t: jnp.exp(t), lambda t: jnp.log(t)]:\n      fn_inv = lambda s: jnp.log(s)\n    elif fn in [lambda t: jnp.sin(t), lambda t: jnp.arcsin(t)]:\n      fn_inv = lambda s: jnp.arcsin(s)\n    elif fn in [lambda t: jnp.cos(t), lambda t: jnp.arccos(t)]:\n      fn_inv = lambda s: jnp.arccos(s)\n    else:\n      raise NotImplementedError(\n          'The inverse of the provided function is not supported.')\n\n  def t_to_s(t):\n    return jnp.clip(fn(t), t_near, t_far) / (t_far - t_near)\n\n  def s_to_t(s):\n    return fn_inv(s * (t_far - t_near) + t_near)\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    if fn == contract3_isoscale:\n      fn_inv = inv_contract3_isoscale\n    else:\n      raise NotImplementedError(f'No inverse for {fn}')\n\n  def t_to_s(t):\n    \"\"\"\n    Maps metric distances to normalized distances in the range [0, 1].\n\n    Input-Output Arguments\n    :param t: Tensor. Represents the metric distances to be mapped to normalized distances.\n    :return: Tensor. Represents the normalized distances.\n    \"\"\"\n    return jnp.clip(fn(t), 0, 1)\n\n  def s_to_t(s):\n    \"\"\"\n    Maps normalized distances to metric distances.\n\n    Input-Output Arguments\n    :param s: Tensor. Represents the normalized distances to be mapped to metric distances.\n    :return: Tensor. Represents the metric distances.\n    \"\"\"\n    return fn_inv(jnp.clip(s, 0, 1))\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    if fn in [jnp.sqrt, jnp.exp, jnp.log]:\n      fn_inv = fn\n    elif fn == jnp.square:\n      fn_inv = jnp.sqrt\n    elif fn == jnp.log:\n      fn_inv = jnp.exp\n    elif fn == jnp.exp:\n      fn_inv = jnp.log\n    elif fn == jnp.cbrt:\n      fn_inv = jax.jit(lambda x: jnp.power(x, 3))\n    else:\n      raise ValueError(f'No inverse found for {fn}')\n\n  def t_to_s(t):\n    \"\"\"\n    Constructs a function that maps metric distances to normalized distances in the range [0, 1].\n    :param t: Tensor. Represents the metric distances to be mapped to normalized distances.\n    :return: Tensor. Represents the normalized distances corresponding to the input metric distances.\n    \"\"\"\n    return jnp.clip((fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near)), 0, 1)\n\n  def s_to_t(s):\n    \"\"\"\n    Constructs a function that maps normalized distances to metric distances.\n    :param s: Tensor. Represents the normalized distances to be mapped to metric distances.\n    :return: Tensor. Represents the metric distances corresponding to the input normalized distances.\n    \"\"\"\n    return fn_inv(fn(t_near) + s * (fn(t_far) - fn(t_near)))\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  # Checking if the provided function is a valid callable.\n  if not callable(fn):\n    raise ValueError(f'fn must be callable, is {type(fn)}.')\n\n  # Checking if the provided inverse function is a valid callable.\n  if fn_inv is not None and not callable(fn_inv):\n    raise ValueError(f'fn_inv must be callable, is {type(fn_inv)}.')\n\n  # If the inverse function is not provided, we try to infer it from the provided function.\n  if fn_inv is None:\n    if fn == jnp.exp:\n      fn_inv = jnp.log\n    elif fn == jnp.log:\n      fn_inv = jnp.exp\n    elif fn == jnp.sin:\n      fn_inv = jnp.arcsin\n    elif fn == jnp.arcsin:\n      fn_inv = jnp.sin\n    elif fn == jnp.cos:\n      fn_inv = jnp.arccos\n    elif fn == jnp.arccos:\n      fn_inv = jnp.cos\n    elif fn == jnp.tan:\n      fn_inv = jnp.arctan\n    elif fn == jnp.arctan:\n      fn_inv = jnp.tan\n    elif fn == jnp.sqrt:\n      fn_inv = lambda x: x**2\n    elif fn == lambda x: x**2:\n      fn_inv = jnp.sqrt\n    elif fn == jnp.cbrt:\n      fn_inv = lambda x: x**3\n    elif fn == lambda x: x**3:\n      fn_inv = jnp.cbrt\n    else:\n      raise ValueError(f'Could not infer inverse function for {fn}.')\n\n  # We construct the forward mapping from metric to normalized distances.\n  def t_to_s(t):\n    return fn(jnp.clip(t, t_near, t_far))\n\n  # We construct the backward mapping from normalized to metric distances.\n  def s_to_t(s):\n    return fn"}
{"namespace": "coord.construct_ray_warps", "completion": "  # If no inverse function is provided, try to automatically determine it based on a predefined list of functions and their inverses.\n  if fn_inv is None:\n    if fn == jnp.sqrt:\n      fn_inv = jnp.rsqrt\n    elif fn == jnp.log:\n      fn_inv = jnp.exp\n    elif fn == jnp.exp:\n      fn_inv = jnp.log\n    elif fn == jnp.cbrt:\n      fn_inv = jnp.power(3)\n    elif fn == jnp.power:\n      fn_inv = jnp.power\n    else:\n      raise ValueError(f'No inverse function provided for {fn}')\n\n  # Define a function to map metric distances to normalized distances in the range [0, 1].\n  def t_to_s(t):\n    # Clip distances to a valid range.\n    t = jnp.maximum(t_near, t)\n    t = jnp.minimum(t_far, t)\n    # Map distances to the range [0, 1].\n    s = (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n    return s\n\n  # Define a function to map normalized distances to metric distances.\n  def s_to_t(s):\n    # Map normalized distances to the range [t_near, t_far].\n    t = fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t_near))\n    return t\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    if fn == jnp.sqrt:\n      fn_inv = jnp.rsqrt\n    elif fn == jnp.log:\n      fn_inv = jnp.exp\n    elif fn == jnp.exp:\n      fn_inv = jnp.log\n    elif fn == jnp.cbrt:\n      fn_inv = jnp.power(2, 1 / 3)\n    elif fn == jnp.power:\n      fn_inv = jnp.power\n    else:\n      raise ValueError(f'No inverse for {fn}')\n\n  def t_to_s(t):\n    \"\"\"\n    Maps metric distances to normalized distances in the range [0, 1].\n    \"\"\"\n    t = jnp.maximum(t_near, t)\n    t = jnp.minimum(t_far, t)\n    s = fn(t)\n    return s\n\n  def s_to_t(s):\n    \"\"\"\n    Maps normalized distances to metric distances.\n    \"\"\"\n    t = fn_inv(s)\n    return t\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    if fn.__name__ in ['contract3_isoscale']:\n      fn_inv = inv_contract3_isoscale\n    else:\n      raise ValueError(f'No inverse found for {fn.__name__}')\n\n  def t_to_s(t):\n    \"\"\"\n    Converts metric distances to normalized distances in the range [0, 1].\n    \"\"\"\n    return jnp.clip(fn(t) / t_far, 0, 1)\n\n  def s_to_t(s):\n    \"\"\"\n    Converts normalized distances to metric distances.\n    \"\"\"\n    return fn_inv(t_far * s)\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  # Define a default inverse function for some common functions.\n  if fn_inv is None:\n    if fn == jnp.square:\n      fn_inv = jnp.sqrt\n    elif fn == jnp.sqrt:\n      fn_inv = jnp.square\n    elif fn == jnp.log:\n      fn_inv = jnp.exp\n    elif fn == jnp.exp:\n      fn_inv = jnp.log\n    else:\n      raise ValueError(\n          'No inverse function provided, and no default was found for fn={}')\n\n  # Define the forward mapping from metric to normalized distances.\n  def t_to_s(t):\n    \"\"\"\n    Maps metric distances to normalized distances in the range [0, 1].\n    :param t: Tensor. Represents the metric distances to be mapped to normalized distances.\n    :return: Tensor. Represents the normalized distances.\n    \"\"\"\n    t = jnp.maximum(t_near, t)\n    t = jnp.minimum(t_far, t)\n    return fn(t / t_far)\n\n  # Define the inverse mapping from normalized distances to metric distances.\n  def s_to_t(s):\n    \"\"\"\n    Maps normalized distances to metric distances in the range [t_near, t_far].\n    :param s: Tensor. Represents the normalized distances to be mapped to metric distances.\n    :return: Tensor. Represents the metric distances.\n    \"\"\"\n    return fn_inv(s) * t_far\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    if fn == contract3_isoscale:\n      fn_inv = inv_contract3_isoscale\n    else:\n      raise NotImplementedError(f'No inverse for {fn}')\n\n  def t_to_s(t):\n    \"\"\"\n    Maps metric distances to normalized distances in the range [0, 1].\n    \"\"\"\n    # Clip t to the valid range.\n    t = jnp.maximum(t_near, t)\n    t = jnp.minimum(t_far, t)\n    # Map t to s.\n    return fn_inv(fn(t))\n\n  def s_to_t(s):\n    \"\"\"\n    Maps normalized distances to metric distances in the range [t_near, t_far].\n    \"\"\"\n    # Map s to t.\n    return fn(fn_inv(s))\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  def t_to_s(t):\n    return fn(jnp.clip(t, t_near, t_far))\n\n  def s_to_t(s):\n    if fn_inv is None:\n      fn_inv = inverse_fn(fn)\n    return fn_inv(jnp.clip(s, 0, 1))\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n\n  return jnp.array([x, y, z])\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n\n  return jnp.array([x, y, z])\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.cos(theta) * jnp.sin(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(phi)\n\n  return jnp.array([x, y, z])\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n\n  return jnp.array([x, y, z])\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.array([x, y, z])\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.cos(theta) * jnp.sin(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(phi)\n\n  return jnp.array([x, y, z])\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.cos(theta) * jnp.sin(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(phi)\n  return jnp.array([x, y, z])\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n\n  return jnp.array([x, y, z])\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.cos(theta) * jnp.sin(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(phi)\n  return jnp.array([x, y, z])\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n\n  return jnp.array([x, y, z])\n\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.cos(theta) * jnp.sin(phi)\n  y = r * jnp.sin(theta)\n  z = r * jnp.cos(theta) * jnp.cos(phi)\n\n  return jnp.array([x, y, z])\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.cos(theta) * jnp.sin(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(phi)\n\n  return jnp.stack([x, y, z], axis=-1)\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.cos(theta) * jnp.sin(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(phi)\n  return jnp.array([x, y, z])\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n\n  return jnp.array([x, y, z])\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.array([x, y, z])\n\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.cos(theta) * jnp.sin(phi)\n  y = r * jnp.sin(theta)\n  z = r * jnp.cos(theta) * jnp.cos(phi)\n  return jnp.stack([x, y, z], axis=-1)\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.array([x, y, z])\n\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  # Calculate cartesian coordinates\n  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n\n  return jnp.stack((x, y, z), axis=-1)\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  # Check if the input arguments are numeric type\n  chex.assert_type([r, theta, phi], jnp.inexact)\n\n  # Calculate the cartesian coordinates\n  x = r * jnp.cos(theta) * jnp.cos(phi)\n  y = r * jnp.cos(theta) * jnp.sin(phi)\n  z = r * jnp.sin(theta)\n\n  return jnp.stack([x, y, z], axis=-1)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  check_zero_endpoints(w)\n  return math.trapezoid(t, w)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.sum(w)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.sum(0.5 * (w[Ellipsis, :-1] + w[Ellipsis, 1:]) * (t[Ellipsis, 1:] - t[Ellipsis, :-1]))\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.sum(w[Ellipsis, 1:-1] * (t[Ellipsis, 1:] - t[Ellipsis, :-1])) + (\n      w[Ellipsis, -1] * (t[Ellipsis, -1] - t[Ellipsis, -2]) +\n      w[Ellipsis, 0] * (t[Ellipsis, 1] - t[Ellipsis, 0])) / 2\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n\n  # Check if the data points are valid for the trapezoid rule.\n  check_zero_endpoints(w)\n\n  # Calculate the integral using the trapezoid rule.\n  return (jnp.sum(w[Ellipsis, 1:-1] * (t[Ellipsis, 1:] - t[Ellipsis, :-1])) +\n          (t[Ellipsis, -1] - t[Ellipsis, 0]) * w[Ellipsis, 0] / 2 +\n          (t[Ellipsis, -1] - t[Ellipsis, -2]) * w[Ellipsis, -1] / 2)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  check_zero_endpoints(w)\n  return math.trapezoid(t, w)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.sum(w[1:] + w[:-1]) * (t[1] - t[0]) / 2\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.sum(t[:-1] * (w[:-1] + w[1:]) / 2)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.sum(0.5 * (w[:-1] + w[1:]) * (t[1:] - t[:-1]))\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.sum(w[1:] + w[:-1]) * (t[1] - t[0]) / 2\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  check_zero_endpoints(w)\n  return math.trapezoid(t, w)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return math.trapezoid(t, w)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n\n  # Ensure the input data points are valid for a linear spline.\n  check_zero_endpoints(w)\n\n  # Ensure the input data points are monotonically increasing.\n  if not math.is_monotonic(t):\n    raise ValueError('Input data points must be monotonically increasing.')\n\n  # Compute the integral of the data points using the trapezoid rule.\n  return jnp.sum(w[1:-1] * (t[1:-1] - t[:-2])) + (w[0] + w[-1]) * (t[1] - t[0]) / 2\n\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return math.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.sum(0.5 * (w[:-1] + w[1:]) * (t[1:] - t[:-1]))\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return math.trapezoid(t, w)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return (t[-1] - t[0]) * (w[0] + w[-1]) / 2 + jnp.sum(jnp.diff(t) * (w[:-1] + w[1:]) / 2)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return (t[1:] - t[:-1]) * (w[:-1] + w[1:]) / 2.0\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.sum(w[Ellipsis, :-1] * (t[Ellipsis, 1:] - t[Ellipsis, :-1]))\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n\n  # Ensure the input data points are valid for a linear spline before performing the integration.\n  check_zero_endpoints(w)\n\n  # Ensure the input data points are valid for a linear spline before performing the integration.\n  check_zero_endpoints(w)\n\n  # The trapezoid rule is defined as the average of the differences between the y-coordinates of the data points.\n  return jnp.mean(jnp.diff(w, axis=-1))\n\n\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Normalize scores\n    for i in range(len(scores)):\n        scores[i] = [score / sum(scores[i]) for score in scores[i]]\n\n    # Calculate weighted sum of scores\n    weighted_sum_scores = []\n    for i in range(len(ids[0])):\n        weighted_sum_scores.append(sum([scores[j][i] * weights[j] for j in range(len(scores))]))\n\n    # Get top K IDs and their corresponding scores\n    top_k_ids = [ids[0][i] for i in range(top_k)]\n    top_k_scores = [weighted_sum_scores[i] for i in range(top_k)]\n\n    return top_k_ids, top_k_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Normalize the scores for each category or group\n    normalized_scores = []\n    for score_list in scores:\n        normalized_scores.append([score / sum(score_list) for score in score_list])\n\n    # Calculate the weighted sum of scores for each ID\n    weighted_scores = []\n    for id_list, score_list in zip(ids, normalized_scores):\n        weighted_scores.append([score * weight for score, weight in zip(score_list, weights)])\n\n    # Return the top K IDs and their corresponding weighted scores\n    weighted_scores_df = pd.DataFrame(weighted_scores)\n    weighted_scores_df['sum'] = weighted_scores_df.sum(axis=1)\n    weighted_scores_df = weighted_scores_df.sort_values(by=['sum'], ascending=False)\n    return weighted_scores_df.head(top_k)['sum'].index.tolist(), weighted_scores_df.head(top_k)['sum'].tolist()"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores) == len(weights), \"The length of ids, scores, and weights must be the same.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Normalize scores\n    norm_scores = []\n    for score_list in scores:\n        norm_scores.append(list(map(lambda x: x / sum(score_list), score_list)))\n\n    # Weighted sum of scores\n    weighted_scores = []\n    for i in range(len(ids[0])):\n        weighted_scores.append(sum([norm_scores[j][i] * weights[j] for j in range(len(ids))]))\n\n    # Get top k\n    top_k_ids = []\n    top_k_scores = []\n    for i in range(top_k):\n        top_k_ids.append(ids[0][weighted_scores.index(max(weighted_scores))])\n        top_k_scores.append(weighted_scores[weighted_scores.index(max(weighted_scores))])\n        weighted_scores.pop(weighted_scores.index(max(weighted_scores)))\n\n    return top_k_ids, top_k_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    # Check that the length of the input lists are the same.\n    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of ids and weights must be the same.\"\n\n    # Check that the length of the input lists are greater than 1.\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n\n    # Check that the length of the weights is the same as the length of the input lists.\n    assert len(weights) == len(ids), \"The length of weights must be the same as the length of ids.\"\n\n    # Check that the sum of the weights is 1.\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Check that the top_k is greater than 0.\n    assert top_k > 0, \"top_k must be greater than 0.\"\n\n    # Check that the input lists are not empty.\n    assert len(ids[0]) > 0, \"The length of the input lists must be greater than 0.\"\n\n    # Check that the input lists contain the same number of IDs.\n    assert len(ids[0]) == len(scores[0]), \"The length of the IDs in the first list must be the same as the length of the scores in the first list.\"\n\n    # Check that the input lists contain the same number of IDs.\n    assert len(ids[0]) == len(weights[0]), \"The length of the IDs in the first list must be the same as the length of the weights in the first list.\"\n\n    # Check that the input lists contain the same number of IDs.\n    for i in range(len(ids)):\n        assert len(ids[i]) == len(scores[i]), \"The length of the IDs in the first list must be the same as the length of the scores in the first list.\"\n\n    # Check that the input lists contain the same number of IDs.\n    for i in range(len(ids)):\n        assert len(ids[i]) == len(weights[i]), \""}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    # Check that the length of the input tuples are the same\n    assert len(ids) == len(scores) == len(weights), \"The length of the 'ids', 'scores', and 'weights' tuples must be the same.\"\n\n    # Check that the length of the weights tuple is the same as the length of the scores tuple\n    assert len(weights) == len(scores), \"The length of the 'weights' tuple must be the same as the length of the 'scores' tuple.\"\n\n    # Check that the length of the weights tuple is the same as the length of the ids tuple\n    assert len(weights) == len(ids), \"The length of the 'weights' tuple must be the same as the length of the 'ids' tuple.\"\n\n    # Check that the sum of the weights tuple is equal to 1\n    assert sum(weights) == 1, \"The sum of the 'weights' tuple must be equal to 1.\"\n\n    # Check that the length of the top_k is greater than 0\n    assert top_k > 0, \"The value of 'top_k' must be greater than 0.\"\n\n    # Check that the length of the top_k is less than or equal to the length of the ids tuple\n    assert top_k <= len(ids[0]), \"The value of 'top_k' must be less than or equal to the length of the first element of the 'ids' tuple.\"\n\n    # Check that the length of the top_k is less than or equal to the length of the scores tuple\n    assert top_k <= len(scores[0]), \"The value of 'top_k' must be less than or equal to the length of the first element of the 'scores' tuple.\"\n\n    # Check that the length of the top_k is less than or equal to the length of the weights tuple\n    assert top_k <= len(weights), \"The value of 'top_k' must be less than or equal to the length of the 'weights' tuple.\"\n\n    # Check that the length of the top_k is less than or equal to the length of the scores tuple\n    assert top_k <="}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    # Check input arguments\n    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Calculate weighted sum of scores\n    weighted_scores = []\n    for i in range(len(ids)):\n        weighted_scores.append([])\n        for j in range(len(ids[i])):\n            weighted_scores[i].append(scores[i][j] * weights[i])\n\n    # Normalize scores\n    for i in range(len(ids)):\n        weighted_scores[i] = normalize(weighted_scores[i])\n\n    # Calculate weighted sum of scores\n    weighted_sum_scores = []\n    for i in range(len(ids)):\n        weighted_sum_scores.append([])\n        for j in range(len(ids[i])):\n            weighted_sum_scores[i].append(sum(weighted_scores[i][:j + 1]))\n\n    # Get top K IDs and scores\n    top_k_ids = []\n    top_k_scores = []\n    for i in range(len(ids)):\n        top_k_ids.append([])\n        top_k_scores.append([])\n        for j in range(len(ids[i])):\n            if weighted_sum_scores[i][j] >= weighted_sum_scores[i][-1] - 0.000001:\n                top_k_ids[i].append(ids[i][j])\n                top_k_scores[i].append(weighted_sum_scores[i][j])\n            else:"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Normalize scores\n    for i, score_list in enumerate(scores):\n        scores[i] = [score / sum(score_list) for score in score_list]\n\n    # Weight scores\n    weighted_scores = [scores[i] * weights[i] for i in range(len(scores))]\n\n    # Calculate weighted sum of scores\n    weighted_sum = [0.0] * len(ids[0])\n    for i in range(len(ids[0])):\n        for j in range(len(ids)):\n            weighted_sum[i] += weighted_scores[j][i]\n\n    # Return top k\n    return list(zip(*sorted(zip(ids[0], weighted_sum), key=lambda x: x[1], reverse=True)[:top_k]))"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Normalize the scores for each category or group\n    normalized_scores = []\n    for i in range(len(ids)):\n        normalized_scores.append(normalize(scores[i]))\n\n    # Calculate the weighted sum of scores for each ID\n    weighted_scores = []\n    for i in range(len(ids[0])):\n        weighted_score = 0\n        for j in range(len(ids)):\n            weighted_score += weights[j] * normalized_scores[j][i]\n        weighted_scores.append(weighted_score)\n\n    # Return the top K IDs and their corresponding weighted scores\n    weighted_scores, ids = (list(t) for t in zip(*sorted(zip(weighted_scores, ids[0]), reverse=True)))\n    return ids[:top_k], weighted_scores[:top_k]\n\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    # Assertions\n    assert len(ids) == len(scores) == len(weights), \"The length of ids, scores, and weights must be the same.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n\n    # Initialize\n    id_list = []\n    score_list = []\n\n    # Iterate over each category or group\n    for i in range(len(ids)):\n\n        # Iterate over each ID\n        for j in range(len(ids[i])):\n\n            # Calculate weighted sum of scores\n            weighted_score = scores[i][j] * weights[i]\n\n            # Add ID and weighted score to lists\n            id_list.append(ids[i][j])\n            score_list.append(weighted_score)\n\n    # Normalize scores\n    max_score = max(score_list)\n    min_score = min(score_list)\n    for i in range(len(score_list)):\n        score_list[i] = (score_list[i] - min_score) / (max_score - min_score)\n\n    # Sort IDs and scores by descending weighted score\n    zipped_lists = zip(id_list, score_list)\n    sorted_pairs = sorted(zipped_lists, key=lambda x: x[1], reverse=True)\n    tuples = zip(*sorted_pairs)\n    id_list, score_list = [list(tuple) for tuple in tuples]\n\n    # Return top K IDs and scores\n    return id_list[:top_k], score_list[:top_k]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    # Check that the lengths of the input arguments are consistent.\n    assert len(ids) == len(scores), \"The length of the 'ids' argument and the length of the 'scores' argument must be the same.\"\n    assert len(ids) == len(weights), \"The length of the 'ids' argument and the length of the 'weights' argument must be the same.\"\n\n    # Check that the weights sum to 1.\n    assert abs(sum(weights) - 1) < 0.000001, \"The weights must sum to 1.\"\n\n    # Check that the length of the weights tuple is the same as the length of the ids tuple.\n    assert len(weights) == len(ids), \"The length of the 'weights' argument must be the same as the length of the 'ids' argument.\"\n\n    # Check that the length of the scores tuple is the same as the length of the ids tuple.\n    assert len(scores) == len(ids), \"The length of the 'scores' argument must be the same as the length of the 'ids' argument.\"\n\n    # Check that the length of the scores tuple is the same as the length of the weights tuple.\n    assert len(scores) == len(weights), \"The length of the 'scores' argument must be the same as the length of the 'weights' argument.\"\n\n    # Check that the length of the scores tuple is the same as the length of the weights tuple.\n    assert len(scores) == len(weights), \"The length of the 'scores' argument must be the same as the length of the 'weights' argument.\"\n\n    # Check that the length of the scores tuple is the same as the length of the ids tuple.\n    assert len(scores) == len(ids), \"The length of the 'scores' argument must be the same as the length of the 'ids' argument.\"\n\n    # Check that the length of the scores tuple is the same as the length of the weights tuple.\n    assert len(scores) == len(weights), \"The length of the 'scores' argument must be the same as the length of the 'weights'"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    # Check input types\n    assert isinstance(ids, tuple), \"The input 'ids' must be a tuple.\"\n    assert isinstance(scores, tuple), \"The input 'scores' must be a tuple.\"\n    assert isinstance(weights, tuple), \"The input 'weights' must be a tuple.\"\n    assert isinstance(top_k, int), \"The input 'top_k' must be an integer.\"\n\n    # Check input length\n    assert len(ids) == len(scores), \"The length of the input 'ids' must be the same as the length of the input 'scores'.\"\n    assert len(ids) == len(weights), \"The length of the input 'ids' must be the same as the length of the input 'weights'.\"\n\n    # Check input values\n    assert len(ids) > 0, \"The input 'ids' must contain at least one list.\"\n    assert len(scores) > 0, \"The input 'scores' must contain at least one list.\"\n    assert len(weights) > 0, \"The input 'weights' must contain at least one float.\"\n    assert top_k > 0, \"The input 'top_k' must be greater than 0.\"\n\n    # Check weight values\n    assert sum(weights) == 1, \"The sum of the input 'weights' must be 1.\"\n\n    # Check IDs and scores length\n    assert all([len(id_list) == len(score_list) for id_list, score_list in zip(ids, scores)]), \"The length of each list in the input 'ids' must be the same as the length of each list in the input 'scores'.\"\n\n    # Check IDs and weights length\n    assert all([len(id_list) == len(weight) for id_list, weight in zip(ids, weights)]), \"The length of each list in the input 'ids' must be the same as the length of each input 'weights'.\"\n\n    # Check IDs and scores type\n    assert all([isinstance(id_list, list) for id_list in ids]), \"Each list in the input 'ids' must"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    # Assertions\n    assert len(ids) == len(scores) == len(weights), \"The length of ids, scores, and weights must be the same.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n\n    # Normalize scores\n    norm_scores = []\n    for i in range(len(ids)):\n        norm_scores.append([])\n        for j in range(len(ids[i])):\n            norm_scores[i].append(scores[i][j] / sum(scores[i]))\n\n    # Calculate weighted sum of scores\n    weighted_scores = []\n    for i in range(len(ids)):\n        weighted_scores.append([])\n        for j in range(len(ids[i])):\n            weighted_scores[i].append(norm_scores[i][j] * weights[i])\n\n    # Combine scores\n    combined_scores = []\n    for i in range(len(ids[0])):\n        combined_scores.append(0)\n        for j in range(len(ids)):\n            combined_scores[i] += weighted_scores[j][i]\n\n    # Sort combined scores\n    combined_scores, ids = zip(*sorted(zip(combined_scores, ids[0]), reverse=True))\n\n    return ids[:top_k], combined_scores[:top_k]\n\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores) == len(weights), \"The length of ids, scores, and weights must be the same.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n\n    # Normalize scores\n    for i in range(len(scores)):\n        scores[i] = normalize(scores[i])\n\n    # Calculate weighted sum of scores\n    weighted_scores = []\n    for i in range(len(ids)):\n        weighted_scores.append(list(map(lambda x, y: x * y, scores[i], weights)))\n\n    # Combine scores\n    weighted_scores = list(map(sum, zip(*weighted_scores)))\n\n    # Sort scores\n    weighted_scores, ids = (list(t) for t in zip(*sorted(zip(weighted_scores, ids), reverse=True)))\n\n    # Return top K scores\n    return ids[:top_k], weighted_scores[:top_k]\n\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Normalize the scores of each retrieval result.\n    normalized_scores = normalize_scores(scores)\n\n    # Calculate the weighted sum of scores for each ID.\n    weighted_sum_scores = weighted_sum(ids, normalized_scores, weights)\n\n    # Sort the IDs and their corresponding weighted sums in descending order based on their weighted sum.\n    sorted_ids, sorted_scores = sort_by_weighted_sum(weighted_sum_scores)\n\n    # Return the top K IDs and their corresponding weighted sums.\n    return sorted_ids[:top_k], sorted_scores[:top_k]\n\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    # Normalize the scores.\n    scores_normalized = [normalize_scores(score_list) for score_list in scores]\n\n    # Calculate the weighted sum of scores for each ID.\n    weighted_scores = [calculate_weighted_scores(score_list, weight) for score_list, weight in zip(scores_normalized, weights)]\n\n    # Normalize the weighted scores.\n    weighted_scores_normalized = [normalize_scores(score_list) for score_list in weighted_scores]\n\n    # Calculate the weighted sum of scores for each ID.\n    weighted_scores_sum = [calculate_weighted_scores(score_list, 1.0) for score_list in weighted_scores_normalized]\n\n    # Return the top K IDs and their corresponding weighted scores.\n    return return_top_k(ids, weighted_scores_sum, top_k)\n\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Normalize the scores for each category or group.\n    normalized_scores = [normalize_scores(score_list) for score_list in scores]\n\n    # Calculate the weighted sum of the normalized scores for each category or group.\n    weighted_scores = [weighted_sum(normalized_score_list, weight) for normalized_score_list, weight in\n                       zip(normalized_scores, weights)]\n\n    # Get the top K IDs and corresponding weighted scores.\n    top_k_ids, top_k_weighted_scores = get_top_k(weighted_scores, ids, top_k)\n\n    return top_k_ids, top_k_weighted_scores\n\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    # 1. Normalize the scores for each ID\n    scores_normalized = tuple([normalize_scores(scores_list) for scores_list in scores])\n\n    # 2. Calculate the weighted sum of scores for each ID\n    weighted_scores = tuple([calculate_weighted_scores(scores_list, weights) for scores_list in scores_normalized])\n\n    # 3. Return the top K IDs and their corresponding weighted scores\n    return get_top_k(ids, weighted_scores, top_k)\n\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    # Check that the length of the inputs are all the same\n    assert len(ids) == len(scores) == len(weights), \"The length of the inputs must all be the same.\"\n\n    # Check that the length of the weights is equal to the number of lists in the ids and scores tuples\n    assert len(weights) == len(ids[0]), \"The length of the weights must be equal to the number of lists in the ids and scores tuples.\"\n\n    # Check that the sum of the weights is equal to 1\n    assert sum(weights) == 1, \"The sum of the weights must be equal to 1.\"\n\n    # Check that the top_k value is greater than 0\n    assert top_k > 0, \"The top_k value must be greater than 0.\"\n\n    # Initialize lists for the IDs and scores\n    cc_ids = []\n    cc_scores = []\n\n    # Iterate through each category or group\n    for i in range(len(ids)):\n\n        # Iterate through each ID and score in the category or group\n        for j in range(len(ids[i])):\n\n            # Check if the ID is already in the cc_ids list\n            if ids[i][j] not in cc_ids:\n\n                # If the ID is not in the cc_ids list, add it and initialize its score to 0\n                cc_ids.append(ids[i][j])\n                cc_scores.append(0)\n\n                # Iterate through each category or group\n                for k in range(len(ids)):\n\n                    # If the ID is in the current category or group, add the score to the ID's score in the cc_scores list\n                    if ids[k][j] == ids[i][j]:\n                        cc_scores[cc_ids.index(ids[i][j])] += scores[k][j] * weights[k]\n\n    # Normalize the scores by dividing each score by the sum of all scores\n    cc_scores = [score / sum(cc_scores) for score in cc_scores]\n\n    # Sort"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    # Check that the length of the inputs are all the same.\n    assert len(ids) == len(scores) == len(weights), \"The length of the inputs must be the same.\"\n\n    # Check that the length of the inputs are greater than 1.\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n\n    # Check that the length of the weights is equal to the length of the ids and scores.\n    assert len(weights) == len(ids) == len(scores), \"The length of the weights must be the same as the length of the ids and scores.\"\n\n    # Check that the sum of the weights is equal to 1.\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Check that top_k is greater than 0.\n    assert top_k > 0, \"top_k must be greater than 0.\"\n\n    # Normalize the scores.\n    norm_scores = normalize_scores(scores)\n\n    # Calculate the weighted sum of the scores.\n    weighted_sum_scores = weighted_sum(norm_scores, weights)\n\n    # Sort the IDs by the weighted sum scores in descending order.\n    sorted_ids = sorted(list(zip(ids[0], weighted_sum_scores)), key=lambda x: x[1], reverse=True)\n\n    # Return the top K IDs and their corresponding weighted sum scores.\n    return list(zip(*sorted_ids))[:top_k]\n\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    # Check that the number of weights is equal to the number of scores.\n    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(scores) == len(weights), \"The length of weights must be the same as the length of scores.\"\n\n    # Check that the number of weights is equal to the number of IDs.\n    for i in range(len(ids)):\n        assert len(ids[i]) == len(scores[i]), \"The length of ids[i] and scores[i] must be the same.\"\n\n    # Check that the sum of weights is equal to 1.\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Check that top_k is greater than 0.\n    assert top_k > 0, \"top_k must be greater than 0.\"\n\n    # Check that the number of IDs is greater than 1.\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n\n    # Check that the length of weights is equal to the length of IDs.\n    assert len(weights) == len(ids), \"The length of weights must be the same as the length of ids.\"\n\n    # Check that the length of weights is equal to the length of scores.\n    assert len(weights) == len(scores), \"The length of weights must be the same as the length of scores.\"\n\n    # Initialize a dictionary to store the weighted sum of scores for each ID.\n    weighted_sum = {}\n\n    # Iterate over each set of IDs and scores.\n    for i in range(len(ids)):\n\n        # Iterate over each ID and score in the current set of IDs and scores.\n        for j in range(len(ids[i])):\n\n            # If the ID is already in the dictionary, add the weighted score to the existing weighted score.\n            if ids[i][j] in weighted_sum.keys():\n                weighted_sum[ids[i][j]] += weights[i] * scores[i][j]\n\n            # Otherwise,"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian of the function.\n  jac = jax.jacfwd(fn)(mean)\n\n  # Compute the transformed covariances.\n  fn_cov = jnp.matmul(jnp.matmul(jac, cov), jac.T)\n\n  # Compute the transformed means.\n  fn_mean = fn(mean)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian of the function\n  jacobian = jax.jacfwd(fn)(mean)\n\n  # Compute the linearized function\n  fn_mean = fn(mean)\n\n  # Compute the linearized covariances\n  fn_cov = jnp.matmul(jnp.matmul(jacobian, cov), jacobian.T)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian of the function.\n  jacobian = jax.jacfwd(fn)(mean)\n\n  # Compute the linearized function.\n  fn_mean = fn(mean)\n\n  # Compute the transformed covariances.\n  fn_cov = jnp.matmul(jnp.matmul(jacobian, cov), jacobian, transpose_a=True)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian of the function\n  jacobian = jax.jacfwd(fn)(mean)\n  # Compute the linearized function\n  fn_mean = fn(mean)\n  # Transform the covariances using the Jacobian\n  fn_cov = jnp.einsum('...ij,...jk->...ik', jacobian, cov)\n  fn_cov = jnp.einsum('...ij,...jk->...ik', fn_cov, jacobian)\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Linearize the function around the mean\n  fn_mean = fn(mean)\n\n  # Compute the Jacobian of the function\n  fn_jacobian = jax.jacobian(fn)(mean)\n\n  # Compute the transformed covariances\n  fn_cov = fn_jacobian @ cov @ fn_jacobian.T\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian of the function\n  jacobian = jax.jacfwd(fn)(mean)\n\n  # Transform the covariances using the Jacobian\n  fn_cov = jnp.matmul(jnp.matmul(jacobian, cov), jacobian.T)\n\n  # Transform the means using the Jacobian\n  fn_mean = fn(mean)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian of the function around the mean\n  jacobian = jax.jacobian(fn, argnums=0)\n  jacobian_mean = jacobian(mean)\n\n  # Compute the transformed mean\n  fn_mean = fn(mean)\n\n  # Compute the transformed covariance\n  fn_cov = jnp.matmul(jnp.matmul(jacobian_mean, cov), jacobian_mean.T)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Linearize the function around the mean\n  fn_mean = fn(mean)\n\n  # Get the Jacobian matrix\n  jacobian = jax.jacfwd(fn)(mean)\n\n  # Transform the covariances\n  fn_cov = jnp.einsum('...ij,...jk->...ik', jacobian, cov)\n  fn_cov = jnp.einsum('...ij,...jk->...ik', fn_cov, jacobian)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian of the given function.\n  jac = jax.jacrev(fn)(mean)\n\n  # Compute the linearized function.\n  fn_mean = fn(mean)\n\n  # Compute the linearized covariance.\n  fn_cov = jnp.matmul(jnp.matmul(jac, cov), jac, transpose_a=True)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian of the function at the mean\n  jacobian = jax.jacobian(fn)(mean)\n\n  # Compute the transformed covariances\n  fn_cov = jnp.matmul(jnp.matmul(jacobian, cov), jacobian.T)\n\n  # Compute the transformed means\n  fn_mean = fn(mean)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # The following code is based on the implementation of the Kalman filter in the paper \"A Tutorial on Bayesian Filtering and Smoothing\" by Barber and Wilkinson (2005).\n\n  # The following code is based on the implementation of the Kalman filter in the paper \"A Tutorial on Bayesian Filtering and Smoothing\" by Barber and Wilkinson (2005).\n\n  # The following code is based on the implementation of the Kalman filter in the paper \"A Tutorial on Bayesian Filtering and Smoothing\" by Barber and Wilkinson (2005).\n\n  # The following code is based on the implementation of the Kalman filter in the paper \"A Tutorial on Bayesian Filtering and Smoothing\" by Barber and Wilkinson (2005).\n\n  # The following code is based on the implementation of the Kalman filter in the paper \"A Tutorial on Bayesian Filtering and Smoothing\" by Barber and Wilkinson (2005).\n\n  # The following code is based on the implementation of the Kalman filter in the paper \"A Tutorial on Bayesian Filtering and Smoothing\" by Barber and Wilkinson (2005).\n\n  # The following code is based on the implementation of the Kalman filter in the paper \"A Tutorial on Bayesian Filtering and Smoothing\" by Barber and Wilkinson (2005).\n\n  # The following code is based on the implementation of the Kalman filter in the paper \"A Tutorial on Bayesian Filtering and Smoothing\" by Barber and Wilkinson (2005).\n\n  # The following code is based on the implementation of the Kalman filter in the paper \"A Tutorial on Bayesian Filtering and Smoothing\" by Barber and Wilkinson (2005).\n\n  # The following code is based on the implementation of the Kalman filter in the paper \"A Tutorial on Bayesian Filtering and Smoothing\" by Barber and Wilkinson (2005).\n\n  # The following code is based on the implementation of the Kalman filter in the paper \"A Tutorial on Bayesian Filtering and"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the linearized function\n  fn_mean = fn(mean)\n\n  # Compute the Jacobian\n  J = jax.jacfwd(fn)(mean)\n\n  # Compute the transformed covariances\n  fn_cov = jnp.einsum('...ij,...jk,...lk->...il', J, cov, J)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Calculate the linearized function\n  fn_mean = fn(mean)\n  fn_mean_mean = jnp.mean(fn_mean, axis=-1, keepdims=True)\n  fn_mean_diff = fn_mean - fn_mean_mean\n\n  # Calculate the transformed covariances\n  fn_cov = cov + jnp.matmul(fn_mean_diff[..., None, :], fn_mean_diff[..., None])\n  fn_cov = 0.5 * (fn_cov + fn_cov.T)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian of the function at the mean\n  jacobian = jax.jacfwd(fn)(mean)\n\n  # Compute the covariance of the Jacobian\n  jacobian_cov = jnp.matmul(cov, jnp.transpose(jacobian, (-1, -2)))\n\n  # Compute the mean of the Jacobian\n  jacobian_mean = jnp.matmul(mean, jnp.transpose(jacobian, (-1, -2)))\n\n  # Compute the transformed mean\n  fn_mean = fn(mean)\n\n  # Compute the transformed covariance\n  fn_cov = cov + jacobian_cov - jnp.matmul(fn_mean, jnp.transpose(fn_mean))\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian of the function at the mean\n  jacobian = jax.jacrev(fn)(mean)\n  # Compute the linearized function\n  fn_mean = fn(mean)\n  # Compute the transformed covariances\n  fn_cov = jnp.matmul(jnp.matmul(jacobian, cov), jacobian.T)\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Linearize the function around the mean\n  fn_mean = fn(mean)\n  fn_diff = fn_mean - fn(mean)\n\n  # Transform the covariances\n  fn_cov = cov + fn_diff[:, :, jnp.newaxis] * fn_diff[:, jnp.newaxis, :]\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # The dimension of the means\n  dim = mean.shape[-1]\n\n  # The Jacobian of the function at the mean\n  jac = jax.jacfwd(fn)(mean)\n\n  # The linearized function\n  fn_mean = fn(mean)\n\n  # The linearized covariances\n  fn_cov = jnp.matmul(jnp.matmul(jac, cov), jac, transpose_a=True)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian of the function at the mean\n  jacobian = jax.jacfwd(fn)(mean)\n\n  # Compute the linearized mean\n  fn_mean = fn(mean)\n\n  # Compute the linearized covariance\n  fn_cov = jnp.matmul(jnp.matmul(jacobian, cov), jacobian,\n                      precision=jax.lax.Precision.HIGHEST)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian of the function\n  jacobian = jax.jacrev(fn)(mean)\n  # Compute the linearized function\n  fn_mean = fn(mean)\n  # Transform the covariances\n  fn_cov = jnp.matmul(jnp.matmul(jacobian, cov), jacobian.T)\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # The linearization of a function around a point is given by\n  #\n  #   f(x) = f(x0) + J(x0) * (x - x0)\n  #\n  # where J(x0) is the Jacobian of f at x0.\n  #\n  # If we have a Gaussian distribution with mean x0 and covariance P, then\n  # the covariance of the linearized function is J(x0) * P * J(x0)'.\n  #\n  # We can compute J(x0) using finite differences.\n  #\n  # We can also use the fact that\n  #\n  #   J(x0) * (x - x0) = f(x) - f(x0)\n  #\n  # to compute the covariance of the linearized function.\n  #\n  # We can use the same idea to compute the mean of the linearized function.\n\n  # The Jacobian is computed using finite differences.\n  #\n  # TODO: Replace this with an analytic Jacobian if possible.\n  #\n  # We use the central difference formula.\n  #\n  #   J = (f(x + h) - f(x - h)) / (2 * h)\n  #\n  # where h is a small number.\n  #\n  # We choose h = 1e-5 because that is the smallest representable number in\n  # float32.\n  #\n  # TODO: Make sure this is actually the smallest representable number.\n  #\n  h = 1e-5\n\n  # Compute the function at the mean.\n  fn_mean = fn(mean)\n\n  # Compute the function at x0 + h.\n  x_plus_h = mean + h * jnp.ones_like(mean)\n  fn_plus_h = fn(x_plus_h)\n\n  # Compute the function at x0 - h.\n  x_minus_h = mean - h * jnp.ones_like(mean)\n  fn_minus_h = fn(x_minus_h)\n\n  # Compute the Jacob"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in x:\n        if i.size > 1:\n            yield [i[: i.size // 2], i[i.size // 2 :]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for arr in x:\n        if arr.size > 1:\n            yield [arr[: len(arr) // 2], arr[len(arr) // 2 :]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for arr in x:\n        if len(arr) > 1:\n            yield arr[0::2], arr[1::2]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for arr in x:\n        if len(arr) > 1:\n            yield [arr[: len(arr) // 2], arr[len(arr) // 2 :]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in x:\n        if len(i) > 1:\n            yield np.split(i, 2)\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for arr in x:\n        if arr.size > 1:\n            half = arr.size // 2\n            yield [arr[:half], arr[half:]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in range(len(x)):\n        if len(x[i]) > 1:\n            x_left = x[i][:len(x[i])//2]\n            x_right = x[i][len(x[i])//2:]\n            yield [x_left, x_right]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for arr in x:\n        if arr.size > 1:\n            yield [arr[:len(arr)//2], arr[len(arr)//2:]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in range(len(x)):\n        if len(x[i]) > 1:\n            x[i] = np.array_split(x[i], 2)\n            yield x\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in x:\n        if i.size > 1:\n            yield [i[:len(i) // 2], i[len(i) // 2:]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in range(len(x)):\n        if len(x[i]) > 1:\n            mid = int(len(x[i]) / 2)\n            yield [x[i][:mid], x[i][mid:]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in range(len(x)):\n        if len(x[i]) > 1:\n            yield [x[i][: len(x[i]) // 2], x[i][len(x[i]) // 2 :]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in x:\n        if len(i) > 1:\n            yield [i[:len(i) // 2], i[len(i) // 2:]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in x:\n        if len(i) > 1:\n            yield [i[: len(i) // 2], i[len(i) // 2 :]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in x:\n        if len(i) > 1:\n            yield [i[0:len(i) // 2], i[len(i) // 2:]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in range(len(x)):\n        if len(x[i]) > 1:\n            x1 = x[i][:int(len(x[i])/2)]\n            x2 = x[i][int(len(x[i])/2):]\n            yield [x1, x2]\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    # Iterate through the list of arrays\n    for array in x:\n\n        # If the array has more than one element\n        if array.size > 1:\n\n            # Bisect the array into two halves\n            array_left = array[: len(array) // 2]\n            array_right = array[len(array) // 2 :]\n\n            # Yield the two halves\n            yield [array_left, array_right]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for array in x:\n        if len(array) > 1:\n            yield [array[: len(array) // 2], array[len(array) // 2 :]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in x:\n        if len(i) > 1:\n            yield [i[:len(i)//2], i[len(i)//2:]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in range(len(x)):\n        if len(x[i]) > 1:\n            yield [x[i][:len(x[i])//2], x[i][len(x[i])//2:]]\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2:\n        raise ValueError(\"The matrix must be a 2d-array\")\n    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix is not square.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\n            \"The given matrix is not square. It is {}-dimensional and its shape is {}.\".format(\n                x.ndim, x.shape\n            )\n        )\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix is not square\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The given matrix is not square.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The given matrix is not square.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix is not square\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix is not square\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2:\n        raise ValueError(\"x must be a 2-dimensional array\")\n    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"x must be a square matrix\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be a square matrix\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix is not square.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2:\n        raise ValueError(\"The given matrix is not a 2-dimensional array.\")\n    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The given matrix is not square.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2:\n        raise ValueError(\"The matrix must be 2-dimensional\")\n    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2:\n        raise ValueError(\"The matrix must be a 2D array\")\n    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(f\"The matrix {x} is not square\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2:\n        raise ValueError(\"The matrix is not a 2D array\")\n    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix is not square\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The input matrix must be a square matrix\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(f\"x is not a square matrix. x.shape is {x.shape}\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The given matrix is not square.\")\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded_x = jnp.concatenate([jnp.sin(scaled_x), jnp.cos(scaled_x)], axis=-1)\n  if append_identity:\n    encoded_x = jnp.concatenate([x, encoded_x], axis=-1)\n  return encoded_x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded_x = jnp.concatenate([jnp.sin(scaled_x), jnp.cos(scaled_x)], axis=-1)\n  if append_identity:\n    encoded_x = jnp.concatenate([x, encoded_x], axis=-1)\n  return encoded_x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  # Generate the scales from min_deg to max_deg.\n  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded_x = jnp.concatenate([jnp.sin(scaled_x), jnp.cos(scaled_x)], axis=-1)\n  if append_identity:\n    encoded_x = jnp.concatenate([x, encoded_x], axis=-1)\n  return encoded_x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded_x = jnp.concatenate([jnp.sin(scaled_x), jnp.cos(scaled_x)], axis=-1)\n  if append_identity:\n    encoded_x = jnp.concatenate([x, encoded_x], axis=-1)\n  return encoded_x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n\n  if append_identity:\n    return jnp.concatenate([scaled_x, x], axis=-1)\n  else:\n    return scaled_x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded_x = jnp.concatenate([jnp.sin(scaled_x), jnp.cos(scaled_x)], axis=-1)\n  if append_identity:\n    encoded_x = jnp.concatenate([x, encoded_x], axis=-1)\n  return encoded_x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  # Scale the input\n  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n\n  # Apply sine function\n  encoded_x = jnp.sin(scaled_x)\n\n  # Append the original input\n  if append_identity:\n    encoded_x = jnp.concatenate([x, encoded_x], axis=-1)\n\n  return encoded_x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  # Scale the input\n  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n\n  # Apply sinusoids\n  sin_x = jnp.sin(scaled_x)\n\n  # Optionally append the original input\n  if append_identity:\n    return jnp.concatenate([x, sin_x], axis=-1)\n  else:\n    return sin_x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  # Generate the scales from min_deg to max_deg.\n  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n\n  # Apply the sine function to the scaled input.\n  sin_x = jnp.sin(scaled_x)\n\n  # Concatenate the original input with the encoded features.\n  if append_identity:\n    return jnp.concatenate([x, sin_x], axis=-1)\n  else:\n    return sin_x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  # Generate the scales\n  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n\n  # Scale the input\n  scaled_x = x * scales\n\n  # Apply the sine function\n  sine_x = jnp.sin(scaled_x)\n\n  # Append the original input to the result\n  if append_identity:\n    return jnp.concatenate([x, sine_x], axis=-1)\n  else:\n    return sine_x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  # Generate the scales.\n  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n\n  # Scale the input.\n  scaled_x = x * scales\n\n  # Apply the sine function to the scaled input.\n  sine_x = jnp.sin(scaled_x)\n\n  # Optionally, append the original input to the result.\n  if append_identity:\n    return jnp.concatenate([x, sine_x], axis=-1)\n  else:\n    return sine_x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  # Scale the input.\n  scaled_x = 2.0 ** jnp.arange(min_deg, max_deg) * x\n\n  # Apply a sinusoidal function to the scaled input.\n  sin_x = jnp.sin(scaled_x)\n\n  # Optionally append the original input to the encoded features.\n  if append_identity:\n    encoded_x = jnp.concatenate([x, sin_x], axis=-1)\n  else:\n    encoded_x = sin_x\n\n  return encoded_x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  # Generate the positional encoding scales\n  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n\n  # Apply the sinusoidal function\n  fn_x = jnp.sin(scaled_x)\n\n  # Optionally append the original input\n  if append_identity:\n    fn_x = jnp.concatenate([x, fn_x], axis=-1)\n\n  return fn_x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  # Generate the scales and the encoded features\n  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded_x = jnp.concatenate([jnp.sin(scaled_x), jnp.cos(scaled_x)], axis=-1)\n\n  # Concatenate the original input with the encoded features, if required\n  if append_identity:\n    encoded_x = jnp.concatenate([x, encoded_x], axis=-1)\n\n  return encoded_x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  # Scale the input\n  x_scaled = 2 ** jnp.linspace(min_deg, max_deg, max_deg - min_deg + 1) * x\n  # Apply sine function\n  x_encoded = jnp.sin(x_scaled)\n  # Optionally append the original input to the encoded input\n  if append_identity:\n    x_encoded = jnp.concatenate([x, x_encoded], axis=-1)\n  return x_encoded\n\n"}
{"namespace": "coord.pos_enc", "completion": "  # Generate the scales for the positional encoding\n  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n\n  # Scale the input\n  scaled_x = x[Ellipsis, None, :] * scales[:, None]\n\n  # Apply the sine function\n  encoded_x = jnp.sin(scaled_x)\n\n  # Optionally append the original input\n  if append_identity:\n    encoded_x = jnp.concatenate([x, encoded_x], axis=-1)\n\n  return encoded_x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded_x = jnp.concatenate([jnp.sin(scaled_x), jnp.cos(scaled_x)], axis=-1)\n  if append_identity:\n    encoded_x = jnp.concatenate([x, encoded_x], axis=-1)\n  return encoded_x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  # Scale the input\n  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n\n  # Apply the sine function\n  sin_x = jnp.sin(scaled_x)\n\n  # Concatenate the original input with the encoded features\n  if append_identity:\n    encoded_x = jnp.concatenate([x, sin_x], axis=-1)\n  else:\n    encoded_x = sin_x\n\n  return encoded_x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  # Scaling the input\n  x_scaled = x * 2 ** jnp.arange(min_deg, max_deg)\n\n  # Applying sine function\n  x_encoded = jnp.sin(x_scaled)\n\n  # Optionally appending the original input\n  if append_identity:\n    x_encoded = jnp.concatenate([x, x_encoded], axis=-1)\n\n  return x_encoded\n\n"}
{"namespace": "coord.pos_enc", "completion": "  # Generate the scales for the positional encoding\n  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n\n  # Reshape the input array to be a 2D array\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n\n  # Apply the sine function to the scaled input\n  encoded_x = jnp.sin(scaled_x)\n\n  # Concatenate the original input with the encoded input\n  if append_identity:\n    encoded_x = jnp.concatenate([x, encoded_x], axis=-1)\n\n  return encoded_x\n\n"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if len(field1) equals len(field2).\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                             f\"resp. {len(values[field1])} and {len(values[field2])}\")\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                                 f\"resp. {values[field1][i].shape} and {values[field2][i].shape}\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if len(field1) equals len(field2).\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                             f\"resp. {len(values[field1])} and {len(values[field2])}\")\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                                 f\"resp. {values[field1][i].shape} and {values[field2][i].shape}\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if len(field1) equals len(field2).\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if len(field1) equals len(field2).\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(\n                    f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                    f\"resp. {values[field1][i].shape} and {values[field2][i].shape}\"\n                )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                             f\"resp. {len(values[field1])} and {len(values[field2])}\")\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch. \"\n                                 f\"{field1}[{i}] and {field2}[{i}] shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if len(field1) equals len(field2).\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if len(field1) equals len(field2) and if each corresponding pair of arrays within these lists has the same shape.\"\"\"\n\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                             f\"resp. {len(values[field1])} and {len(values[field2])}\")\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                                 f\"resp. {values[field1][i].shape} and {values[field2][i].shape}\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                             f\"resp. {len(values[field1])} and {len(values[field2])}\")\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n\n        # Check if the two fields have the same length.\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                             f\"resp. {len(values[field1])} and {len(values[field2])}\")\n\n        # Check if each corresponding pair of arrays within the two fields have the same shape.\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch. \"\n                                 f\"{values[field1][i].shape} and {values[field2][i].shape}\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if len(field1) equals len(field2) and if each corresponding pair of arrays within these lists has the same shape.\"\"\"\n\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, resp. {len(values[field1])} and {len(values[field2])}\")\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch, resp. {values[field1][i].shape} and {values[field2][i].shape}\")\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                             f\"resp. {len(values[field1])} and {len(values[field2])}\")\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch. \"\n                                 f\"{field1} array {i} shape {values[field1][i].shape} does not match {field2} array {i} shape {values[field2][i].shape}\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if len(field1) equals len(field2).\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(\n                    f\"{cls.__name__}: {field1} and {field2} shape mismatch at index {i}.\"\n                )\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if len(field1) equals len(field2).\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(\n                    f\"{cls.__name__}: {field1} and {field2} shape mismatch. \"\n                    f\"{field1}[{i}] shape: {values[field1][i].shape}, {field2}[{i}] shape: {values[field2][i].shape}\"\n                )\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if len(field1) equals len(field2).\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                             f\"resp. {len(values[field1])} and {len(values[field2])}\")\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                                 f\"resp. {values[field1][i].shape} and {values[field2][i].shape}\")\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if len(field1) equals len(field2) and if each corresponding pair of arrays within these lists have the same shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, resp. {len(values[field1])} and {len(values[field2])}\")\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch, resp. {values[field1][i].shape} and {values[field2][i].shape}\")\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if len(field1) equals len(field2).\"\"\"\n\n        # Check if both lists have the same length\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                             f\"resp. {len(values[field1])} and {len(values[field2])}\")\n\n        # Check if each corresponding pair of arrays within these lists has the same shape\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                                 f\"resp. {values[field1][i].shape} and {values[field2][i].shape}\")\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"\n        This function checks if two lists of numpy arrays (specified by field names) have the same length and if each corresponding pair of arrays within these lists has the same shape.\n\n        Input-Output Arguments\n        :param cls: type. The class type.\n        :param values: dict. The dictionary of values.\n        :return: dict. The validated values if the check passes.\n\n        \"\"\"\n        # Check if the two lists of numpy arrays have the same length\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                             f\"resp. {len(values[field1])} and {len(values[field2])}\")\n\n        # Check if each corresponding pair of arrays within the two lists have the same shape\n        for idx in range(len(values[field1])):\n            if values[field1][idx].shape != values[field2][idx].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                                 f\"resp. {values[field1][idx].shape} and {values[field2][idx].shape}\")\n\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the mesh using the camera\n        self.render(eglctx, camera)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the mesh\n        self.render(eglctx, camera)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.width, camera.height)\n\n        # Bind the rendering context\n        eglctx.make_current()\n\n        # Bind the mesh's OpenGL buffers\n        self.bind_gl_buffers()\n\n        # Bind the mesh's OpenGL program\n        use_gl_program(self.mesh_program)\n\n        # Bind the mesh's OpenGL uniforms\n        self.bind_gl_uniforms(camera)\n\n        # Render the mesh\n        self.render_mesh()\n\n        # Unbind the mesh's OpenGL buffers\n        self.unbind_gl_buffers()\n\n        # Unbind the mesh's OpenGL program\n        use_gl_program(0)\n\n        # Unbind the rendering context\n        eglctx.release()\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Bind the rendering context\n        eglctx.make_current()\n\n        # Set the viewport\n        gl.glViewport(0, 0, camera.width, camera.height)\n\n        # Set the camera\n        camera.set_uniforms(self.uniforms)\n\n        # Set the uniforms\n        self.uniforms.u_viewInverse = camera.view_inv\n        self.uniforms.u_projInverse = camera.proj_inv\n        self.uniforms.u_viewInverseTranspose = camera.view_inv_t\n        self.uniforms.u_projInverseTranspose = camera.proj_inv_t\n        self.uniforms.u_view = camera.view\n        self.uniforms.u_proj = camera.proj\n        self.uniforms.u_model = glm.mat4(1.0)\n        self.uniforms.u_modelInverse = glm.mat4(1.0)\n        self.uniforms.u_modelInverseTranspose = glm.mat4(1.0)\n        self.uniforms.u_modelInverseTranspose = glm.mat4(1.0)\n        self.uniforms.u_modelView = camera.view * glm.mat4(1.0)\n        self.uniforms.u_modelViewInverse = glm.inverse(camera.view)\n        self.uniforms.u_modelViewInverseTranspose = glm.inverse(camera.view)\n        self.uniforms.u_modelViewProj = camera.proj * camera.view\n        self.uniforms.u_modelViewProjInverse = glm.inverse(camera.proj * camera.view)\n        self.uniforms.u_modelViewProjInverseTranspose = glm.inverse(camera.proj * camera.view)\n        self.uniforms.u_modelViewProjInverseTranspose = glm.inverse(camera.proj * camera.view"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.width, camera.height)\n\n        # Prepare the uniforms\n        self.uniforms.mvp_matrix = camera.get_projection_matrix() @ camera.get_view_matrix()\n        self.uniforms.view_matrix = camera.get_view_matrix()\n        self.uniforms.model_matrix = glm.mat4(1.0)\n        self.uniforms.normal_matrix = glm.mat3(glm.transpose(glm.inverse(self.uniforms.model_matrix)))\n        self.uniforms.model_matrix_inv = glm.mat4(glm.inverse(self.uniforms.model_matrix))\n        self.uniforms.model_matrix_inv_trans = glm.mat4(glm.transpose(self.uniforms.model_matrix_inv))\n        self.uniforms.model_matrix_inv_trans_3x3 = glm.mat3(glm.transpose(self.uniforms.model_matrix_inv))\n        self.uniforms.model_matrix_trans = glm.mat4(glm.transpose(self.uniforms.model_matrix))\n        self.uniforms.model_matrix_trans_3x3 = glm.mat3(glm.transpose(self.uniforms.model_matrix))\n        self.uniforms.model_matrix_rot = glm.mat4(glm.mat3(self.uniforms.model_matrix))\n        self.uniforms.model_matrix_rot_3x3 = glm.mat3(glm.mat3(self.uniforms.model_matrix))\n        self.uniforms.model_matrix_scale = glm.mat4(glm.scale(self.uniforms.model_matrix))\n        self.uniforms.model_matrix_scale_3x3 = glm.mat3(glm.scale(self.uniforms.model_matrix))\n        self.uniforms.model_matrix_scale_inv = glm.mat4"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Setup rendering context\n        eglctx.resize(camera.width, camera.height)\n        eglctx.make_current()\n\n        # Setup camera\n        camera.update_uniforms(self.uniforms)\n        camera.update_matrices()\n\n        # Setup OpenGL\n        gl.glViewport(0, 0, camera.width, camera.height)\n        gl.glClearColor(0.0, 0.0, 0.0, 1.0)\n        gl.glClear(gl.GL_COLOR_BUFFER_BIT | gl.GL_DEPTH_BUFFER_BIT)\n        gl.glEnable(gl.GL_BLEND)\n        gl.glBlendFunc(gl.GL_SRC_ALPHA, gl.GL_ONE_MINUS_SRC_ALPHA)\n        gl.glEnable(gl.GL_LINE_SMOOTH)\n        gl.glHint(gl.GL_LINE_SMOOTH_HINT, gl.GL_NICEST)\n        gl.glEnable(gl.GL_POINT_SMOOTH)\n        gl.glHint(gl.GL_POINT_SMOOTH_HINT, gl.GL_NICEST)\n        gl.glEnable(gl.GL_POLYGON_SMOOTH)\n        gl.glHint(gl.GL_POLYGON_SMOOTH_HINT, gl.GL_NICEST)\n\n        # Setup shaders\n        gl.glUseProgram(self.mesh_program)\n        gl.glUniform1i(gl.glGetUniformLocation(self.mesh_program, \"u_texture\"), 0)\n        gl.glUniform1i(gl.glGetUniformLocation(self.mesh_program, \"u_color_tex\"), 1)\n        gl.glUniform1i(gl.glGetUniformLocation(self.mesh_program, \"u_normal_tex\"), 2)\n        gl.glUniform1i(gl.glGetUniformLocation("}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Setup the OpenGL context\n        gl.glViewport(0, 0, camera.width, camera.height)\n        gl.glClearColor(0.0, 0.0, 0.0, 0.0)\n        gl.glClear(gl.GL_COLOR_BUFFER_BIT | gl.GL_DEPTH_BUFFER_BIT)\n\n        # Setup the camera\n        camera.setup_gl_camera()\n\n        # Setup the uniforms\n        self.uniforms.view_matrix = camera.view_matrix\n        self.uniforms.projection_matrix = camera.projection_matrix\n        self.uniforms.model_matrix = glm.mat4(1.0)\n        self.uniforms.model_matrix = glm.translate(self.uniforms.model_matrix, glm.vec3(0.0, 0.0, 0.0))\n\n        # Setup the shader program\n        use_gl_program(self.mesh_program)\n\n        # Setup the vertex buffer\n        gl.glBindVertexArray(self.vao)\n        gl.glBindBuffer(gl.GL_ARRAY_BUFFER, self.vbo)\n        gl.glBufferData(gl.GL_ARRAY_BUFFER, self.n_verts_bytes, self.verts_data, gl.GL_DYNAMIC_DRAW)\n\n        # Setup the uniforms\n        for i, (name, value) in enumerate(self.uniforms.items()):\n            gl.glUniform1i(gl.glGetUniformLocation(self.mesh_program, name), value)\n\n        # Setup the attributes\n        for i, (name, value) in enumerate(self.attributes.items()):\n            gl.glEnableVertexAttribArray(i)\n            gl.glVertexAttribPointer(i, value[0], value[1], gl.GL_FALSE, self.vert_size * self"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Bind the rendering context and set the viewport\n        eglctx.make_current()\n        gl.glViewport(0, 0, camera.width, camera.height)\n\n        # Clear the color and depth buffers\n        gl.glClearColor(0.0, 0.0, 0.0, 1.0)\n        gl.glClearDepth(1.0)\n        gl.glClear(gl.GL_COLOR_BUFFER_BIT | gl.GL_DEPTH_BUFFER_BIT)\n\n        # Set the camera's projection matrix\n        gl.glMatrixMode(gl.GL_PROJECTION)\n        gl.glLoadIdentity()\n        gl.glMultMatrixf(camera.projection_matrix)\n\n        # Set the camera's view matrix\n        gl.glMatrixMode(gl.GL_MODELVIEW)\n        gl.glLoadIdentity()\n        gl.glMultMatrixf(camera.view_matrix)\n\n        # Enable the depth test\n        gl.glEnable(gl.GL_DEPTH_TEST)\n\n        # Enable the blending\n        gl.glEnable(gl.GL_BLEND)\n        gl.glBlendFunc(gl.GL_SRC_ALPHA, gl.GL_ONE_MINUS_SRC_ALPHA)\n\n        # Render the mesh\n        self.render()\n\n        # Unbind the rendering context\n        eglctx.release()\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # TODO: Add support for other rendering types\n        # TODO: Add support for other rendering devices\n        # TODO: Add support for other rendering contexts\n        # TODO: Add support for other rendering types\n        # TODO: Add support for other rendering devices\n        # TODO: Add support for other rendering contexts\n\n        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Bind the rendering context\n        eglctx.make_current()\n\n        # Bind the vertex array object\n        gl.glBindVertexArray(self.vao)\n\n        # Bind the vertex buffer object\n        gl.glBindBuffer(gl.GL_ARRAY_BUFFER, self.vbo)\n\n        # Bind the index buffer object\n        gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, self.ibo)\n\n        # Bind the uniform buffer object\n        gl.glBindBuffer(gl.GL_UNIFORM_BUFFER, self.ubo)\n\n        # Bind the framebuffer object\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, eglctx.fbo)\n\n        # Clear the framebuffer\n        gl.glClearColor(0, 0, 0, 1)\n        gl.glClear(gl.GL_COLOR_BUFFER_BIT | gl.GL_DEPTH_BUFFER_BIT)\n\n        # Set the viewport\n        gl.glViewport(0, 0, camera.width, camera.height)\n\n        # Set the projection matrix\n        gl.glUniformMatrix4fv(self.uniforms.proj, 1, gl.GL_FALSE, camera.proj_mat.ravel())\n\n        # Set the view matrix\n        gl.glUniformMatrix4fv(self.uniforms.view, 1, gl.GL_FALSE, camera.view_mat.ravel())\n\n        # Set the model matrix\n        gl.glUniformMatrix4fv(self.uniforms.model, 1, gl.GL_FALSE, camera.model_mat.ravel"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context\n        eglctx.resize(camera.width, camera.height)\n\n        # Setup the uniforms\n        self.uniforms.view_matrix = camera.view_matrix\n        self.uniforms.projection_matrix = camera.projection_matrix\n        self.uniforms.model_matrix = camera.model_matrix\n        self.uniforms.eye = camera.eye\n        self.uniforms.fov = camera.fov\n        self.uniforms.z_near = camera.z_near\n        self.uniforms.z_far = camera.z_far\n        self.uniforms.cam_pos = camera.eye\n        self.uniforms.cam_tgt = camera.target\n        self.uniforms.cam_up = camera.up\n        self.uniforms.cam_fov = camera.fov\n        self.uniforms.cam_z_near = camera.z_near\n        self.uniforms.cam_z_far = camera.z_far\n        self.uniforms.cam_width = camera.width\n        self.uniforms.cam_height = camera.height\n        self.uniforms.cam_ndc_to_view = camera.ndc_to_view\n        self.uniforms.cam_view_to_ndc = camera.view_to_ndc\n        self.uniforms.cam_ndc_to_viewport = camera.ndc_to_viewport\n        self.uniforms.cam_viewport_to_ndc = camera.viewport_to_ndc\n        self.uniforms.cam_view_to_world = camera.view_to_world\n        self.uniforms.cam_world_to_view = camera.world_to_view\n        self.uniforms.cam_world_to_view_projection = camera.world_to_view_projection\n\n        # Render the mesh\n        self.render(eglctx, self.mesh_program)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context\n        eglctx.resize(camera.width, camera.height)\n\n        # Setup the camera\n        camera.set_uniforms(self.uniforms)\n\n        # Setup the uniforms\n        self.uniforms.view_matrix = camera.view_matrix\n        self.uniforms.projection_matrix = camera.projection_matrix\n        self.uniforms.model_matrix = camera.model_matrix\n        self.uniforms.view_matrix_inv = camera.view_matrix_inv\n        self.uniforms.projection_matrix_inv = camera.projection_matrix_inv\n        self.uniforms.model_matrix_inv = camera.model_matrix_inv\n\n        # Render the mesh\n        self.render(eglctx)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context\n        eglctx.resize(camera.width, camera.height)\n\n        # Set the OpenGL viewport\n        gl.glViewport(0, 0, camera.width, camera.height)\n\n        # Set the OpenGL camera\n        gl.glMatrixMode(gl.GL_PROJECTION)\n        gl.glLoadIdentity()\n        gl.glOrtho(0, camera.width, camera.height, 0, -1, 1)\n        gl.glMatrixMode(gl.GL_MODELVIEW)\n        gl.glLoadIdentity()\n\n        # Set the OpenGL camera\n        gl.gluLookAt(camera.eye[0], camera.eye[1], camera.eye[2],\n                     camera.center[0], camera.center[1], camera.center[2],\n                     camera.up[0], camera.up[1], camera.up[2])\n\n        # Set the OpenGL perspective\n        gl.gluPerspective(camera.fov, camera.width / camera.height, camera.near, camera.far)\n\n        # Set the OpenGL uniforms\n        self.set_uniforms(camera)\n\n        # Render the Mesh instance\n        self.render(eglctx)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.width, camera.height)\n\n        # Bind the rendering context\n        eglctx.make_current()\n\n        # Clear the framebuffer\n        gl.glClear(gl.GL_COLOR_BUFFER_BIT | gl.GL_DEPTH_BUFFER_BIT)\n\n        # Setup the camera\n        camera.set_uniforms(self.uniforms)\n\n        # Setup the shaders\n        gl.glUseProgram(self.mesh_program)\n\n        # Setup the uniforms\n        self.uniforms.projection = camera.projection_matrix\n        self.uniforms.modelview = camera.modelview_matrix\n        self.uniforms.shade_flat = self.shade_flat\n        self.uniforms.point_radius = self.point_radius\n        self.uniforms.render_normal = self.render_normal\n        self.uniforms.render_type = self.render_type.value\n        self.uniforms.max_verts = self.max_verts\n        self.uniforms.max_faces = self.max_faces\n        self.uniforms.vert_size = self.vert_size\n        self.uniforms.vert_sizes = self.vert_sizes\n        self.uniforms.vert_gl_types = self.vert_gl_types\n        self.uniforms.n_verts_bytes = self.n_verts_bytes\n        self.uniforms.n_faces_bytes = self.n_faces_bytes\n\n        # Setup the vertex buffer\n        gl.glBindBuffer(gl.GL_ARRAY_BUFFER, eglctx.vbo)\n        gl.glBufferData(gl.GL_ARRAY_BUFFER, self.n_verts_bytes, self.verts_data, gl.GL_STATIC_DRAW)\n\n        # Setup the index buffer\n        gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, eglctx.ibo)\n        gl.glBuffer"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Setup the rendering context\n        eglctx.resize(camera.width, camera.height)\n        eglctx.make_current()\n\n        # Setup the shader program\n        gl.glUseProgram(self.mesh_program)\n\n        # Setup the uniforms\n        self.uniforms.mvp = camera.projection @ camera.get_model_view()\n        self.uniforms.mv = camera.get_model_view()\n        self.uniforms.normal_matrix = camera.get_normal_matrix()\n        self.uniforms.shade_flat = self.shade_flat\n        self.uniforms.point_radius = self.point_radius\n        self.uniforms.render_normal = self.render_normal\n        self.uniforms.vert_sizes = self.vert_sizes\n        self.uniforms.n_verts = len(self.verts)\n        self.uniforms.n_faces = len(self.faces)\n        self.uniforms.n_colors = len(self.colors) if len(self.colors) else 0\n        self.uniforms.n_normals = len(self.normals) if len(self.normals) else 0\n        self.uniforms.n_scalars = len(self.scalars) if len(self.scalars) else 0\n        self.uniforms.n_scalars_keys = list(self.scalars.keys()) if len(self.scalars) else []\n        self.uniforms.n_scalars_vals = list(self.scalars.values()) if len(self.scalars) else []\n        self.uniforms.n_scalars_vals_len = [len(v) for v in self.scalars.values()] if len(self.scalars) else []\n        self.uniforms.n_scalars_vals_dtype = [v.dtype for v in self.scalars.values()] if len(self.scalars) else []\n\n        # Setup the buffers\n        gl.glBindVertexArray(self.vao)\n        gl."}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.width, camera.height)\n\n        # Set the viewport\n        gl.glViewport(0, 0, camera.width, camera.height)\n\n        # Set the camera settings\n        camera.set_gl_camera()\n\n        # Clear the color and depth buffers\n        gl.glClearColor(0.0, 0.0, 0.0, 0.0)\n        gl.glClearDepth(1.0)\n        gl.glClear(gl.GL_COLOR_BUFFER_BIT | gl.GL_DEPTH_BUFFER_BIT)\n\n        # Set the shader program\n        gl.glUseProgram(self.mesh_program)\n\n        # Set the uniform values\n        self.uniforms.model = mat4(1.0)\n        self.uniforms.view = camera.view_mat\n        self.uniforms.proj = camera.proj_mat\n        self.uniforms.cam_pos = camera.cam_pos\n        self.uniforms.light_pos = camera.light_pos\n        self.uniforms.light_color = camera.light_color\n        self.uniforms.light_intensity = camera.light_intensity\n        self.uniforms.material_color = camera.material_color\n        self.uniforms.material_shininess = camera.material_shininess\n        self.uniforms.cam_fov = camera.cam_fov\n        self.uniforms.cam_focal_length = camera.cam_focal_length\n        self.uniforms.cam_near_plane = camera.cam_near_plane\n        self.uniforms.cam_far_plane = camera.cam_far_plane\n        self.uniforms.shade_flat = int(self.shade_flat)\n        self.uniforms.render_normal = int(self.render_normal)\n        self.uniforms.point_radius = self.point_radius\n\n        # Set the uniform values\n        for k, v in self.uniforms."}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Set the camera settings\n        self.uniforms.projection = camera.projection_matrix\n        self.uniforms.view = camera.view_matrix\n        self.uniforms.model = camera.model_matrix\n        self.uniforms.normal_matrix = camera.normal_matrix\n        self.uniforms.camera_position = camera.position\n\n        # Render the mesh\n        self.render(eglctx)\n\n        # Clear the rendering context\n        eglctx.make_current()\n        gl.glClearColor(0.0, 0.0, 0.0, 1.0)\n        gl.glClear(gl.GL_COLOR_BUFFER_BIT | gl.GL_DEPTH_BUFFER_BIT)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Setup the rendering context\n        eglctx.resize(camera.width, camera.height)\n        eglctx.make_current()\n        gl.glViewport(0, 0, camera.width, camera.height)\n\n        # Clear the buffer\n        gl.glClearColor(0.0, 0.0, 0.0, 1.0)\n        gl.glClear(gl.GL_COLOR_BUFFER_BIT | gl.GL_DEPTH_BUFFER_BIT)\n\n        # Setup the camera\n        camera.setup_glsl_uniforms()\n\n        # Render the mesh\n        self.render(camera)\n\n        # Read the buffer\n        img = eglctx.read_pixels(camera.width, camera.height, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE)\n\n        # Cleanup\n        eglctx.release()\n\n        return img\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Setup\n        w, h = camera.width, camera.height\n        eglctx.resize(w, h)\n        self.update_uniforms(camera)\n\n        # Render\n        self.render(eglctx)\n\n        # Get the rendered image\n        image = eglctx.read_pixels(w, h, gl.GL_RGBA, gl.GL_FLOAT)\n        image = np.asarray(image, dtype=np.float32).reshape(h, w, 4)\n        return image\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Setup rendering context\n        eglctx.resize(camera.width, camera.height)\n        eglctx.make_current()\n\n        # Setup camera\n        camera.setup_matrices(self.verts.shape[0])\n\n        # Setup uniforms\n        self.uniforms.model_view_mat = camera.model_view_mat\n        self.uniforms.projection_mat = camera.projection_mat\n        self.uniforms.view_mat = camera.view_mat\n        self.uniforms.model_mat = camera.model_mat\n        self.uniforms.camera_mat = camera.camera_mat\n        self.uniforms.camera_pos = camera.camera_pos\n        self.uniforms.fov = camera.fov\n        self.uniforms.near = camera.near\n        self.uniforms.far = camera.far\n        self.uniforms.render_type = self.render_type.value\n        self.uniforms.shade_flat = self.shade_flat\n        self.uniforms.point_radius = self.point_radius\n        self.uniforms.render_normal = self.render_normal\n\n        # Setup buffers\n        gl.glBindBuffer(gl.GL_ARRAY_BUFFER, eglctx.vbo)\n        gl.glBufferData(gl.GL_ARRAY_BUFFER, self.n_verts_bytes, self.verts_data, gl.GL_DYNAMIC_DRAW)\n        gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, eglctx.ibo)\n        gl.glBufferData(gl.GL_ELEMENT_ARRAY_BUFFER, self.n_faces_bytes, self.faces_data, gl.GL_DYNAMIC_DRAW)\n\n        # Setup vertex attributes\n        for i, v_type in enumerate(self.vert_gl_types):\n            gl.glVertexAttribPointer(i, self.vert_sizes[i], v_type, gl.GL_FALSE, self.vert_size * self"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context\n        eglctx.resize(camera.width, camera.height)\n\n        # Set up the OpenGL context\n        gl.glViewport(0, 0, camera.width, camera.height)\n        gl.glClearColor(0.0, 0.0, 0.0, 1.0)\n        gl.glClear(gl.GL_COLOR_BUFFER_BIT | gl.GL_DEPTH_BUFFER_BIT)\n        gl.glEnable(gl.GL_BLEND)\n        gl.glBlendFunc(gl.GL_SRC_ALPHA, gl.GL_ONE_MINUS_SRC_ALPHA)\n\n        # Set up the projection and camera matrices\n        gl.glMatrixMode(gl.GL_PROJECTION)\n        gl.glLoadIdentity()\n        gl.glOrtho(-1, 1, -1, 1, -1, 1)\n        gl.glMatrixMode(gl.GL_MODELVIEW)\n        gl.glLoadIdentity()\n        gl.gluLookAt(0, 0, 1, 0, 0, 0, 0, 1, 0)\n        gl.glMultMatrixf(glm.value_ptr(camera.matrix))\n\n        # Set up the shader program\n        use_gl_program(self.mesh_program)\n\n        # Set up the uniforms\n        self.uniforms.mvp = glm.value_ptr(camera.matrix)\n        self.uniforms.vertex_size = self.vert_size\n        self.uniforms.shade_flat = self.shade_flat\n        self.uniforms.point_radius = self.point_radius\n        self.uniforms.render_normal = self.render_normal\n        self.uniforms.vert_gl_types = self.vert_gl_types\n        self.uniforms.verts_data = self.verts_data\n        self.uniforms.faces_data = self.faces_data\n\n        # Set up the vertex attributes\n        gl.glVertexAtt"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Initialize a new configuration object from the BERT config\n    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        pad_token_id=bert_config.pad_token_id,\n        gradient_checkpointing=bert_config.gradient_checkpointing,\n        position_embedding_type=bert_config.position_embedding_type,\n        use_cache=bert_config.use_cache,\n        bos_token_id=bert_config.bos_token_id,\n        eos_token_id=bert_config.eos_token_id,\n        sep_token_id=bert_config.sep_token_id,\n        decoder_start_token_id=bert_config.sep_token_id,\n        encoder_ffn_dim=bert_config.intermediate_size,\n        encoder_layers=bert_config.num_hidden_layers,\n        encoder_attention_heads=bert_config.num_attention_heads,\n        decoder_ffn_dim=bert_config.intermediate_size,\n        decoder_layers=bert_config.num_hidden_layers,\n        decoder_att"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Create a new NomicBertConfig object from the BERT configuration object.\n    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        pad_token_id=bert_config.pad_token_id,\n        gradient_checkpointing=bert_config.gradient_checkpointing,\n        position_embedding_type=bert_config.position_embedding_type,\n        use_cache=bert_config.use_cache,\n        bos_token_id=bert_config.bos_token_id,\n        eos_token_id=bert_config.eos_token_id,\n        sep_token_id=bert_config.sep_token_id,\n        num_hidden_layers_alpha=bert_config.num_hidden_layers_alpha,\n        num_hidden_layers_beta=bert_config.num_hidden_layers_beta,\n        num_hidden_layers_gamma=bert_config.num_hidden_layers_gamma,\n        num_hidden_layers_delta=bert_config.num_hidden_layers_delta,\n        num_hidden_layers_theta=bert_config.num_hidden_layers_theta,\n        num_hidden_"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Initialize the new configuration object\n    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        pad_token_id=bert_config.pad_token_id,\n        gradient_checkpointing=bert_config.gradient_checkpointing,\n        position_embedding_type=bert_config.position_embedding_type,\n        use_cache=bert_config.use_cache,\n        bos_token_id=bert_config.bos_token_id,\n        eos_token_id=bert_config.eos_token_id,\n        pad_token_id=bert_config.pad_token_id,\n        decoder_start_token_id=bert_config.pad_token_id,\n        output_past=bert_config.output_past,\n        output_attentions=bert_config.output_attentions,\n        output_hidden_states=bert_config.output_hidden_states,\n        num_labels=bert_config.num_labels,\n        is_encoder_decoder=bert_config.is_encoder_decoder,\n        encoder_no_repeat_ngram_size=bert_config."}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        pad_token_id=bert_config.pad_token_id,\n        bos_token_id=bert_config.bos_token_id,\n        eos_token_id=bert_config.eos_token_id,\n        num_hidden_groups=bert_config.num_hidden_groups,\n        num_attention_heads_per_group=bert_config.num_attention_heads_per_group,\n        num_attention_heads_per_partition=bert_config.num_attention_heads_per_partition,\n        num_layers_per_virtual_group=bert_config.num_layers_per_virtual_group,\n        num_layers_per_physical_group=bert_config.num_layers_per_physical_group,\n        num_attention_heads_per_layer=bert_config.num_attention_heads_per_layer,\n        num_intermediate_layers=bert_config.num_intermediate_layers,\n        num_output_hidden_groups=bert_config.num_output_hidden_groups,"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Create new config object\n    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        pad_token_id=bert_config.pad_token_id,\n        num_labels=bert_config.num_labels,\n        num_choices=bert_config.num_labels,\n        num_special_tokens=bert_config.num_special_tokens,\n        num_segments=bert_config.type_vocab_size,\n        num_hidden_layers_nomic=bert_config.num_hidden_layers,\n        num_attention_heads_nomic=bert_config.num_attention_heads,\n        num_hidden_layers_nomic_encoder=bert_config.num_hidden_layers,\n        num_attention_heads_nomic_encoder=bert_config.num_attention_heads,\n        num_hidden_layers_nomic_decoder=bert_config.num_hidden_layers,\n        num_attention_heads_nomic_decoder=bert_config.num_attention_heads,\n        num_hidden_layers_nomic_decoder_encoder=bert"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Create a new config object with the same attributes as the input config object\n    config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        pad_token_id=bert_config.pad_token_id,\n        gradient_checkpointing=bert_config.gradient_checkpointing,\n        position_embedding_type=bert_config.position_embedding_type,\n        use_cache=bert_config.use_cache,\n        bos_token_id=bert_config.bos_token_id,\n        eos_token_id=bert_config.eos_token_id,\n        sep_token_id=bert_config.sep_token_id,\n        decoder_start_token_id=bert_config.eos_token_id,\n        num_labels=bert_config.num_labels,\n        num_decoder_attention_heads=bert_config.num_attention_heads,\n        num_decoder_layers=bert_config.num_hidden_layers,\n        decoder_layerdrop=bert_config.hidden_dropout_prob,\n        decoder_hidden_size=bert_config.hidden_size,\n        decoder"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Initialize a new NomicBertConfig object\n    nomic_bert_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        pad_token_id=bert_config.pad_token_id,\n        num_labels=bert_config.num_labels,\n        output_attentions=bert_config.output_attentions,\n        output_hidden_states=bert_config.output_hidden_states,\n        num_choices=bert_config.num_choices,\n        num_input_blocks=bert_config.num_input_blocks,\n        num_output_blocks=bert_config.num_output_blocks,\n        num_input_layers=bert_config.num_input_layers,\n        num_output_layers=bert_config.num_output_layers,\n        num_input_attention_heads=bert_config.num_input_attention_heads,\n        num_output_attention_heads=bert_config.num_output_attention_heads,\n        num_input_intermediate_size=bert_config.num_input_intermediate_size,\n        num_output_intermediate_size="}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Create a new config object based on the original config object\n    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        pad_token_id=bert_config.pad_token_id,\n        gradient_checkpointing=bert_config.gradient_checkpointing,\n        position_embedding_type=bert_config.position_embedding_type,\n        use_cache=bert_config.use_cache,\n        bos_token_id=bert_config.bos_token_id,\n        eos_token_id=bert_config.eos_token_id,\n        pad_token_id=bert_config.pad_token_id,\n        decoder_start_token_id=bert_config.pad_token_id,\n        sep_token_id=bert_config.sep_token_id,\n        mask_token_id=bert_config.mask_token_id,\n        encoder_ffn_dim=bert_config.intermediate_size,\n        encoder_layers=bert_config.num_hidden_layers,\n        encoder_attention_heads=bert_config.num_attention_heads,\n        decoder_"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Create new config object\n    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        pad_token_id=bert_config.pad_token_id,\n        bos_token_id=bert_config.bos_token_id,\n        eos_token_id=bert_config.eos_token_id,\n        sep_token_id=bert_config.sep_token_id,\n        cls_token_id=bert_config.cls_token_id,\n        mask_token_id=bert_config.mask_token_id,\n        num_labels=bert_config.num_labels,\n        num_choices=bert_config.num_labels,\n        num_regions=100,\n        num_special_tokens=bert_config.num_special_tokens,\n        num_hidden_groups=1,\n        num_attention_head_groups=1,\n        num_attention_heads_per_group=bert_config.num_attention_heads,\n        num_hidden_layers_per_group=bert_config.num_hidden_layers,\n        num_hidden_layers_per_block="}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Instantiate a new configuration object for the Nomic model\n    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        pad_token_id=bert_config.pad_token_id,\n        position_embedding_type=bert_config.position_embedding_type,\n        use_cache=bert_config.use_cache,\n        num_labels=bert_config.num_labels,\n        num_choices=bert_config.num_labels,\n        output_attentions=bert_config.output_attentions,\n        output_hidden_states=bert_config.output_hidden_states,\n        is_encoder_decoder=bert_config.is_encoder_decoder,\n        image_size=bert_config.image_size,\n        patch_size=bert_config.patch_size,\n        num_channels=bert_config.num_channels,\n        num_hidden_layers_patch=bert_config.num_hidden_layers_patch,\n        num_hidden_layers_token=bert_config.num_hidden_layers_token,\n        num_hidden_layers_mlp=bert_config.num_hidden_"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Create a new configuration object\n    nomic_config = NomicBertConfig()\n\n    # Set the vocab size to be the same as the vocab size for the BERT model\n    nomic_config.vocab_size = bert_config.vocab_size\n\n    # Set the embedding dimension to be the same as the hidden size for the BERT model\n    nomic_config.hidden_size = bert_config.hidden_size\n\n    # Set the number of attention heads to be the same as the number of attention heads for the BERT model\n    nomic_config.num_attention_heads = bert_config.num_attention_heads\n\n    # Set the number of hidden layers to be the same as the number of hidden layers for the BERT model\n    nomic_config.num_hidden_layers = bert_config.num_hidden_layers\n\n    # Set the number of decoder layers to be the same as the number of hidden layers for the BERT model\n    nomic_config.num_decoder_layers = bert_config.num_hidden_layers\n\n    # Set the number of decoder attention heads to be the same as the number of attention heads for the BERT model\n    nomic_config.decoder_attention_heads = bert_config.num_attention_heads\n\n    # Set the number of decoder attention heads to be the same as the number of attention heads for the BERT model\n    nomic_config.decoder_attention_heads = bert_config.num_attention_heads\n\n    # Set the number of decoder attention heads to be the same as the number of attention heads for the BERT model\n    nomic_config.decoder_attention_heads = bert_config.num_attention_heads\n\n    # Set the number of decoder attention heads to be the same as the number of attention heads for the BERT model\n    nomic_config.decoder_attention_heads = bert_config.num_attention_heads\n\n    # Set the number of decoder attention heads to be the same as the number of attention heads"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Create new config object\n    nomic_config = NomicBertConfig()\n\n    # Copy over the settings from the original BertConfig object\n    nomic_config.vocab_size = bert_config.vocab_size\n    nomic_config.hidden_size = bert_config.hidden_size\n    nomic_config.num_hidden_layers = bert_config.num_hidden_layers\n    nomic_config.num_attention_heads = bert_config.num_attention_heads\n    nomic_config.hidden_act = bert_config.hidden_act\n    nomic_config.intermediate_size = bert_config.intermediate_size\n    nomic_config.hidden_dropout_prob = bert_config.hidden_dropout_prob\n    nomic_config.attention_probs_dropout_prob = bert_config.attention_probs_dropout_prob\n    nomic_config.max_position_embeddings = bert_config.max_position_embeddings\n    nomic_config.type_vocab_size = bert_config.type_vocab_size\n    nomic_config.initializer_range = bert_config.initializer_range\n    nomic_config.layer_norm_eps = bert_config.layer_norm_eps\n    nomic_config.position_embedding_type = bert_config.position_embedding_type\n\n    # Additional settings\n    nomic_config.use_cache = bert_config.use_cache\n    nomic_config.num_labels = bert_config.num_labels\n    nomic_config.num_choices = bert_config.num_labels\n    nomic_config.num_special_tokens = bert_config.num_special_tokens\n    nomic_config.num_hidden_groups = bert_config.num_hidden_layers // 3\n    nomic_config.num_attention_heads_per_group = nomic_config.num_attention_heads // nomic_config"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Create a new NomicBertConfig object from the provided BertConfig object.\n    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        pad_token_id=bert_config.pad_token_id,\n        position_embedding_type=bert_config.position_embedding_type,\n        use_cache=bert_config.use_cache,\n        output_hidden_states=bert_config.output_hidden_states,\n        output_attentions=bert_config.output_attentions,\n        num_labels=bert_config.num_labels,\n        num_choices=bert_config.num_labels,\n        num_sentence_labels=bert_config.num_labels,\n        num_token_labels=bert_config.num_labels,\n        num_entity_labels=bert_config.num_labels,\n        num_pair_labels=bert_config.num_labels,\n        num_pair_ranking_labels=bert_config.num_labels,\n        num_coref_labels=bert_config.num_labels,\n        num_agreement_labels=bert_config.num_labels,\n        num_entity_"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Create a new configuration object for a Nomic model.\n    nomic_config = NomicBertConfig()\n\n    # Copy the original BERT configuration to the new Nomic configuration.\n    nomic_config.vocab_size = bert_config.vocab_size\n    nomic_config.hidden_size = bert_config.hidden_size\n    nomic_config.num_hidden_layers = bert_config.num_hidden_layers\n    nomic_config.num_attention_heads = bert_config.num_attention_heads\n    nomic_config.intermediate_size = bert_config.intermediate_size\n    nomic_config.hidden_act = bert_config.hidden_act\n    nomic_config.hidden_dropout_prob = bert_config.hidden_dropout_prob\n    nomic_config.attention_probs_dropout_prob = bert_config.attention_probs_dropout_prob\n    nomic_config.max_position_embeddings = bert_config.max_position_embeddings\n    nomic_config.type_vocab_size = bert_config.type_vocab_size\n    nomic_config.initializer_range = bert_config.initializer_range\n    nomic_config.layer_norm_eps = bert_config.layer_norm_eps\n\n    # Additional configurations.\n    nomic_config.num_labels = bert_config.num_labels\n    nomic_config.num_choices = bert_config.num_labels\n    nomic_config.num_tasks = bert_config.num_labels\n    nomic_config.task_embedding_dim = bert_config.hidden_size\n    nomic_config.task_embedding_dropout_prob = bert_config.hidden_dropout_prob\n    nomic_config.task_embedding_layer_norm_eps = bert_config.layer_norm_eps\n    nomic_config.task_embedding_initializer_range = bert_config.initial"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        pad_token_id=bert_config.pad_token_id,\n        num_labels=bert_config.num_labels,\n        num_choices=bert_config.num_labels,\n        output_attentions=bert_config.output_attentions,\n        output_hidden_states=bert_config.output_hidden_states,\n        return_dict=bert_config.return_dict,\n        is_decoder=bert_config.is_decoder,\n        use_cache=bert_config.use_cache,\n        use_bottleneck=False,\n        use_start_token=False,\n        use_end_token=False,\n        use_cls_token=False,\n        use_token_type_ids=bert_config.use_token_type_ids,\n        use_input_mask=bert_config.use_input_mask,\n        use_labels=bert_config.use_labels,\n        use_head_mask=bert_config.use_head_mask,\n        use_pos_embeddings=False,\n        use_action_mask=False,"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Create new configuration object\n    nomic_config = NomicBertConfig()\n\n    # Copy over attributes from original configuration\n    nomic_config.vocab_size = bert_config.vocab_size\n    nomic_config.hidden_size = bert_config.hidden_size\n    nomic_config.num_hidden_layers = bert_config.num_hidden_layers\n    nomic_config.num_attention_heads = bert_config.num_attention_heads\n    nomic_config.hidden_act = bert_config.hidden_act\n    nomic_config.intermediate_size = bert_config.intermediate_size\n    nomic_config.hidden_dropout_prob = bert_config.hidden_dropout_prob\n    nomic_config.attention_probs_dropout_prob = bert_config.attention_probs_dropout_prob\n    nomic_config.max_position_embeddings = bert_config.max_position_embeddings\n    nomic_config.type_vocab_size = bert_config.type_vocab_size\n    nomic_config.initializer_range = bert_config.initializer_range\n    nomic_config.layer_norm_eps = bert_config.layer_norm_eps\n    nomic_config.pad_token_id = bert_config.pad_token_id\n    nomic_config.position_embedding_type = bert_config.position_embedding_type\n\n    # Additional attributes\n    nomic_config.num_types = bert_config.type_vocab_size\n    nomic_config.type_embedding_dim = bert_config.hidden_size\n    nomic_config.type_vocab_size = bert_config.type_vocab_size\n    nomic_config.type_embedding_scale = 1.0\n    nomic_config.type_embedding_trainable = True\n\n    return nomic_config\n\n"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Instantiate a new NomicBertConfig object\n    nomic_config = NomicBertConfig()\n\n    # Copy over the settings from the original BertConfig object\n    nomic_config.__dict__ = bert_config.__dict__.copy()\n\n    # Set the vocab size to the number of tokens in the vocabulary\n    nomic_config.vocab_size = bert_config.vocab_size\n\n    # Set the number of labels to the number of labels in the classification task\n    nomic_config.num_labels = bert_config.num_labels\n\n    # Set the number of objects to the number of objects in the object detection task\n    nomic_config.num_objects = bert_config.num_labels\n\n    # Set the number of object classes to the number of classes in the object classification task\n    nomic_config.num_object_classes = bert_config.num_labels\n\n    # Set the number of object attributes to the number of attributes in the object classification task\n    nomic_config.num_object_attributes = bert_config.num_labels\n\n    # Set the number of object relationships to the number of relationships in the object classification task\n    nomic_config.num_object_relationships = bert_config.num_labels\n\n    # Set the number of object relationships to the number of relationships in the object classification task\n    nomic_config.num_object_relationship_types = bert_config.num_labels\n\n    # Set the number of object relationships to the number of relationships in the object classification task\n    nomic_config.num_object_relationship_directions = bert_config.num_labels\n\n    # Set the number of object relationships to the number of relationships in the object classification task\n    nomic_config.num_object_relationship_polarities = bert_config.num_labels\n\n    # Set the number of object relationships to the number of relationships in the object classification task\n    nomic_config.num_object_relationship_polarity_types = bert_config.num_labels\n\n    # Set the number of object"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Instantiate a new NomicBertConfig object\n    nomic_config = NomicBertConfig()\n\n    # Set the vocabulary size\n    nomic_config.vocab_size = bert_config.vocab_size\n\n    # Set the maximum number of positional embeddings\n    nomic_config.max_position_embeddings = bert_config.max_position_embeddings\n\n    # Set the maximum number of tokens in a sequence\n    nomic_config.max_seq_len = bert_config.max_position_embeddings\n\n    # Set the number of attention heads\n    nomic_config.num_attention_heads = bert_config.num_attention_heads\n\n    # Set the number of hidden layers\n    nomic_config.num_hidden_layers = bert_config.num_hidden_layers\n\n    # Set the number of intermediate hidden layers\n    nomic_config.num_intermediate_hidden_layers = bert_config.num_intermediate_hidden_layers\n\n    # Set the number of BERT layers\n    nomic_config.num_bert_layers = bert_config.num_hidden_layers\n\n    # Set the number of GPT-2 layers\n    nomic_config.num_gpt_layers = bert_config.num_hidden_layers - bert_config.num_intermediate_hidden_layers\n\n    # Set the size of the hidden layers\n    nomic_config.hidden_size = bert_config.hidden_size\n\n    # Set the size of the intermediate hidden layers\n    nomic_config.intermediate_size = bert_config.intermediate_size\n\n    # Set the size of the attention heads\n    nomic_config.attention_head_size = bert_config.attention_head_size\n\n    # Set the size of the attention heads\n    nomic_config.num_attention_heads = bert_config.num_attention_heads\n\n    # Set the size of the attention heads\n    nomic_config.hidden_act = bert_config."}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Instantiate a new NomicBertConfig object\n    nomic_config = NomicBertConfig()\n\n    # Copy over all settings from the original BertConfig\n    nomic_config.__dict__ = bert_config.__dict__.copy()\n\n    # Set the vocab size for the new NomicBertConfig object\n    nomic_config.vocab_size = bert_config.vocab_size + 1\n\n    # Set the max position embedding size for the new NomicBertConfig object\n    nomic_config.max_position_embeddings = 1024\n\n    # Set the type vocab size for the new NomicBertConfig object\n    nomic_config.type_vocab_size = 1\n\n    # Set the initializer range for the new NomicBertConfig object\n    nomic_config.initializer_range = 0.02\n\n    # Set the pad token id for the new NomicBertConfig object\n    nomic_config.pad_token_id = 0\n\n    # Set the eos token id for the new NomicBertConfig object\n    nomic_config.eos_token_id = 0\n\n    # Set the bos token id for the new NomicBertConfig object\n    nomic_config.bos_token_id = 0\n\n    # Set the mask token id for the new NomicBertConfig object\n    nomic_config.mask_token_id = 0\n\n    # Set the max length for the new NomicBertConfig object\n    nomic_config.max_length = 1024\n\n    # Set the max decoder length for the new NomicBertConfig object\n    nomic_config.max_decoder_length = 1024\n\n    # Set the max encoder length for the new NomicBertConfig object\n    nomic_config.max_encoder_length = 1024\n\n    # Set the num layers for the new NomicBertConfig object\n    nomic_config.num_hidden_layers = bert_config.num_hidden_layers\n\n   "}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Convert the BERT configuration to a Nomic configuration.\n    # This is done by copying the attributes from the BERT configuration object to a new Nomic configuration object.\n    nomic_config = NomicBertConfig.from_pretrained(bert_config.to_json_string())\n\n    # Additional configurations for the Nomic model.\n    nomic_config.hidden_dropout_prob = bert_config.hidden_dropout_prob\n    nomic_config.num_attention_heads = bert_config.num_attention_heads\n    nomic_config.num_hidden_layers = bert_config.num_hidden_layers\n    nomic_config.vocab_size = bert_config.vocab_size\n\n    # Set the Nomic model architecture's parameters.\n    nomic_config.architectures = [\"NomicBertForSequenceClassification\"]\n    nomic_config.model_type = \"nomic_bert\"\n\n    return nomic_config\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        # Check if the mesh is visible\n        if not self.visible:\n            return\n\n        # Set up the shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            program = self.point_program\n        else:\n            program = self.mesh_program\n\n        # Set up the shader program\n        use_gl_program(program)\n\n        # Upload the uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind the vertex array object\n        gl.glBindVertexArray(self.vao)\n\n        # Draw the mesh\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, self.n_verts_bytes)\n        elif self.render_type == Mesh.RenderType.LINES:\n            gl.glDrawElements(gl.GL_LINES, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            gl.glDrawElements(gl.GL_TRIANGLES, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            gl.glDrawElements(gl.GL_QUADS, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            gl.glDrawElements(gl.GL_TRIANGLE_STRIP, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n        else:\n            raise NotImplementedError(f'Render type {self.render_type} not implemented')\n\n        # Unbind the vertex array object\n        gl.glBindVertexArray(0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        # check if the mesh is visible\n        if not self.visible:\n            return\n\n        # set up the shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n        else:\n            gl.glUseProgram(self.mesh_program)\n\n        # upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # bind the vertex array object\n        gl.glBindVertexArray(self.vao)\n\n        # draw the mesh\n        if self.render_type == Mesh.RenderType.POINTS:\n            # draw points\n            gl.glDrawArrays(gl.GL_POINTS, 0, self.n_verts_bytes)\n        elif self.render_type == Mesh.RenderType.LINES:\n            # draw lines\n            gl.glDrawElements(gl.GL_LINES, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            # draw triangles\n            gl.glDrawElements(gl.GL_TRIANGLES, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            # draw quads\n            gl.glDrawElements(gl.GL_QUADS, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            # draw triangle strips\n            gl.glDrawElements(gl.GL_TRIANGLE_STRIP, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n\n        # unbind the vertex array object\n        gl.glBindVertexArray(0)\n\n        # unbind the shader program\n        gl.glUseProgram(0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        # Check if the mesh is visible\n        if not self.visible:\n            return\n\n        # Bind the shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n        else:\n            gl.glUseProgram(self.mesh_program)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind the vertex array object\n        gl.glBindVertexArray(self.vao)\n\n        # Draw the mesh\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            gl.glDrawElements(gl.GL_LINES, len(self.faces) * 2, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * 3, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            gl.glDrawElements(gl.GL_QUADS, len(self.faces) * 4, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            gl.glDrawElements(gl.GL_TRIANGLE_STRIP, len(self.faces), gl.GL_UNSIGNED_INT, None)\n        else:\n            raise ValueError(f'Unsupported mesh type: {self.render_type}')\n\n        # Unbind the vertex array object\n        gl.glBindVertexArray(0)\n\n        # Unbind the shader program\n        gl.glUseProgram(0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        # Check if the mesh is visible\n        if not self.visible:\n            return\n\n        # Set up OpenGL state\n        gl.glPushAttrib(gl.GL_ALL_ATTRIB_BITS)\n        common_opengl_options()\n\n        # Bind shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n        else:\n            use_gl_program(self.mesh_program)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind vertex array object\n        gl.glBindVertexArray(self.vao)\n\n        # Draw\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            gl.glDrawElements(gl.GL_LINES, len(self.faces) * 2, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * 3, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            gl.glDrawElements(gl.GL_QUADS, len(self.faces) * 4, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            gl.glDrawElements(gl.GL_TRIANGLE_STRIP, len(self.faces) * 3, gl.GL_UNSIGNED_INT, None)\n\n        # Unbind vertex array object\n        gl.glBindVertexArray(0)\n\n        # Unbind shader program\n        gl.glUseProgram(0)\n\n        # Unset OpenGL state\n        gl"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        # Check if the mesh is visible\n        if not self.visible:\n            return\n\n        # Set up the shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n        else:\n            gl.glUseProgram(self.mesh_program)\n\n        # Upload the uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind the vertex array object\n        gl.glBindVertexArray(self.vao)\n\n        # Draw the mesh\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, self.n_verts_bytes)\n        elif self.render_type == Mesh.RenderType.LINES:\n            gl.glDrawElements(gl.GL_LINES, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            gl.glDrawElements(gl.GL_TRIANGLES, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            gl.glDrawElements(gl.GL_QUADS, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            gl.glDrawElements(gl.GL_TRIANGLE_STRIP, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n        else:\n            raise ValueError(f'Unknown render type: {self.render_type}')\n\n        # Unbind the vertex array object\n        gl.glBindVertexArray(0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        # Check if the mesh is visible\n        if not self.visible:\n            return\n\n        # Set up the shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n        else:\n            use_gl_program(self.mesh_program)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind buffers\n        gl.glBindVertexArray(self.vao)\n\n        # Draw\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            gl.glDrawElements(gl.GL_LINES, len(self.faces) * 2, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * 3, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            gl.glDrawElements(gl.GL_QUADS, len(self.faces) * 4, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            gl.glDrawElements(gl.GL_TRIANGLE_STRIP, len(self.faces), gl.GL_UNSIGNED_INT, None)\n        else:\n            raise NotImplementedError(f'Render type {self.render_type} is not supported')\n\n        # Unbind buffers\n        gl.glBindVertexArray(0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        # Setup shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n        else:\n            use_gl_program(self.mesh_program)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind buffers\n        gl.glBindVertexArray(self.vao)\n\n        # Draw\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, self.n_verts_bytes)\n        elif self.render_type == Mesh.RenderType.LINES:\n            gl.glDrawElements(gl.GL_LINES, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            gl.glDrawElements(gl.GL_TRIANGLES, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            gl.glDrawElements(gl.GL_QUADS, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            gl.glDrawElements(gl.GL_TRIANGLE_STRIP, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n\n        # Unbind buffers\n        gl.glBindVertexArray(0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        # Setup shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n        else:\n            use_gl_program(self.mesh_program)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind buffers\n        self.bind_gl_buffers()\n\n        # Draw\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, self.n_verts_bytes)\n        elif self.render_type == Mesh.RenderType.LINES:\n            gl.glDrawElements(gl.GL_LINES, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            gl.glDrawElements(gl.GL_TRIANGLES, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            gl.glDrawElements(gl.GL_QUADS, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            gl.glDrawElements(gl.GL_TRIANGLE_STRIP, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n\n        # Unbind buffers\n        self.unbind_gl_buffers()\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        # Check if the mesh is visible\n        if not self.visible:\n            return\n\n        # Setup OpenGL state\n        gl.glEnable(gl.GL_DEPTH_TEST)\n        gl.glDepthMask(gl.GL_TRUE)\n        gl.glDepthFunc(gl.GL_LEQUAL)\n        gl.glDepthRange(0.0, 1.0)\n\n        # Setup shader programs\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n        else:\n            use_gl_program(self.mesh_program)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind VAO\n        gl.glBindVertexArray(self.vao)\n\n        # Render\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, self.n_verts_bytes)\n        elif self.render_type == Mesh.RenderType.LINES:\n            gl.glDrawElements(gl.GL_LINES, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            gl.glDrawElements(gl.GL_TRIANGLES, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            gl.glDrawElements(gl.GL_QUADS, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            gl.glDrawElements(gl.GL_TRIANGLE_STRIP, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n        else:\n            raise NotImplementedError(f'Render type: {self"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        # If the mesh is not visible, do not render\n        if not self.visible:\n            return\n\n        # Bind the shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n        else:\n            gl.glUseProgram(self.mesh_program)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind the VAO\n        gl.glBindVertexArray(self.vao)\n\n        # Draw\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, self.n_verts_bytes // self.vert_size)\n        elif self.render_type == Mesh.RenderType.LINES:\n            gl.glDrawElements(gl.GL_LINES, self.n_faces_bytes // self.face_size, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            gl.glDrawElements(gl.GL_TRIANGLES, self.n_faces_bytes // self.face_size, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            gl.glDrawElements(gl.GL_TRIANGLES, self.n_faces_bytes // self.face_size, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            gl.glDrawElements(gl.GL_TRIANGLES, self.n_faces_bytes // self.face_size, gl.GL_UNSIGNED_INT, None)\n        else:\n            raise NotImplementedError(f'Render type {self.render_type} is not supported')\n\n        # Unbind the VAO\n        gl.glBindVertexArray(0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        # Check if the mesh is visible\n        if not self.visible:\n            return\n\n        # Check if the mesh is a point cloud\n        if self.render_type == Mesh.RenderType.POINTS:\n            # Select the point rendering program\n            use_gl_program(self.point_program)\n\n            # Upload uniforms\n            self.upload_gl_uniforms(camera)\n\n            # Bind the vertex array object\n            gl.glBindVertexArray(self.vao)\n\n            # Draw the points\n            gl.glDrawArrays(gl.GL_POINTS, 0, self.n_verts_bytes // self.vert_size)\n\n            # Unbind the vertex array object\n            gl.glBindVertexArray(0)\n\n        # Check if the mesh is a mesh\n        elif self.render_type == Mesh.RenderType.TRIS:\n            # Select the mesh rendering program\n            use_gl_program(self.mesh_program)\n\n            # Upload uniforms\n            self.upload_gl_uniforms(camera)\n\n            # Bind the vertex array object\n            gl.glBindVertexArray(self.vao)\n\n            # Draw the triangles\n            gl.glDrawElements(gl.GL_TRIANGLES, self.n_faces_bytes // self.face_size, gl.GL_UNSIGNED_INT, None)\n\n            # Unbind the vertex array object\n            gl.glBindVertexArray(0)\n\n        # Check if the mesh is a mesh\n        elif self.render_type == Mesh.RenderType.LINES:\n            # Select the mesh rendering program\n            use_gl_program(self.mesh_program)\n\n            # Upload uniforms\n            self.upload_gl_uniforms(camera)\n\n            # Bind the vertex array object\n            gl.glBindVertexArray(self.vao)\n\n            # Draw the lines\n            gl.glDrawElements(gl.GL_LINES, self.n_faces_bytes // self.face_size, gl.GL_UNSIGNED_INT, None)\n\n            # Un"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        # Check if the mesh is visible\n        if not self.visible:\n            return\n\n        # Set up the OpenGL state\n        gl.glEnable(gl.GL_DEPTH_TEST)\n        gl.glDepthFunc(gl.GL_LEQUAL)\n        gl.glDepthMask(gl.GL_TRUE)\n        gl.glEnable(gl.GL_BLEND)\n        gl.glBlendFunc(gl.GL_SRC_ALPHA, gl.GL_ONE_MINUS_SRC_ALPHA)\n\n        # Bind the shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n            self.point_program.set_uniform_1f('point_radius', self.point_radius)\n        else:\n            gl.glUseProgram(self.mesh_program)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind vertex array object\n        gl.glBindVertexArray(self.vao)\n\n        # Set up the OpenGL state\n        gl.glEnable(gl.GL_DEPTH_TEST)\n        gl.glDepthFunc(gl.GL_LEQUAL)\n        gl.glDepthMask(gl.GL_TRUE)\n        gl.glEnable(gl.GL_BLEND)\n        gl.glBlendFunc(gl.GL_SRC_ALPHA, gl.GL_ONE_MINUS_SRC_ALPHA)\n\n        # Bind the shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n            self.point_program.set_uniform_1f('point_radius', self.point_radius)\n        else:\n            gl.glUseProgram(self.mesh_program)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind vertex array object\n        gl.glBindVertexArray(self.vao)\n\n       "}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        # Check if the mesh is visible\n        if not self.visible:\n            return\n\n        # Select the appropriate shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            program = self.point_program\n        else:\n            program = self.mesh_program\n\n        # Bind the program\n        use_gl_program(program)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(program, camera)\n\n        # Bind the vertex array object\n        gl.glBindVertexArray(self.vao)\n\n        # Draw the mesh\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            gl.glDrawElements(gl.GL_LINES, len(self.faces) * 2, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * 3, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * 2, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * 2, gl.GL_UNSIGNED_INT, None)\n        else:\n            raise NotImplementedError\n\n        # Unbind the vertex array object\n        gl.glBindVertexArray(0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        # Check if the mesh is visible\n        if not self.visible:\n            return\n\n        # Set up the shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n        else:\n            use_gl_program(self.mesh_program)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind the vertex array object\n        gl.glBindVertexArray(self.vao)\n\n        # Draw the mesh\n        if self.render_type == Mesh.RenderType.POINTS:\n            # Point rendering\n            gl.glDrawArrays(gl.GL_POINTS, 0, self.n_verts_bytes)\n        elif self.render_type == Mesh.RenderType.LINES:\n            # Lines\n            gl.glDrawElements(gl.GL_LINES, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            # Triangles\n            gl.glDrawElements(gl.GL_TRIANGLES, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            # Quads\n            gl.glDrawElements(gl.GL_QUADS, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            # Triangle strips\n            gl.glDrawElements(gl.GL_TRIANGLE_STRIP, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n\n        # Unbind the vertex array object\n        gl.glBindVertexArray(0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        # Check if the mesh is visible\n        if not self.visible:\n            return\n\n        # Set up the OpenGL state\n        gl.glPolygonMode(gl.GL_FRONT_AND_BACK, gl.GL_FILL)\n        gl.glLineWidth(1.0)\n        gl.glPointSize(self.point_radius)\n\n        # Bind the vertex array object\n        gl.glBindVertexArray(self.vao)\n\n        # Bind the shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n        else:\n            gl.glUseProgram(self.mesh_program)\n\n        # Upload the uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Draw the mesh\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            gl.glDrawElements(gl.GL_LINES, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            gl.glDrawElements(gl.GL_TRIANGLES, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            gl.glDrawElements(gl.GL_TRIANGLES, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            gl.glDrawElements(gl.GL_TRIANGLES, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n        else:\n            raise NotImplementedError(f'Render type {self.render_type} not supported')\n\n        # Un"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        # return if not visible\n        if not self.visible:\n            return\n\n        # set up the shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n        else:\n            use_gl_program(self.mesh_program)\n\n        # upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # bind vertex array object\n        gl.glBindVertexArray(self.vao)\n\n        # draw the mesh\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, self.n_verts_bytes)\n        elif self.render_type == Mesh.RenderType.LINES:\n            gl.glDrawElements(gl.GL_LINES, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            gl.glDrawElements(gl.GL_TRIANGLES, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            gl.glDrawElements(gl.GL_TRIANGLES, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            gl.glDrawElements(gl.GL_TRIANGLES, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n        else:\n            raise NotImplementedError\n\n        # unbind vertex array object\n        gl.glBindVertexArray(0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        # Check if mesh is visible\n        if not self.visible:\n            return\n\n        # Set up OpenGL context\n        with eglctx.make_current() as ctx:\n            # Set up shaders\n            if self.render_type == Mesh.RenderType.POINTS:\n                use_gl_program(self.point_program)\n            else:\n                use_gl_program(self.mesh_program)\n\n            # Set up uniforms\n            self.upload_gl_uniforms(camera)\n\n            # Set up VAO and EBO\n            gl.glBindVertexArray(self.vao)\n            gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, self.ebo)\n\n            # Set up rendering options\n            gl.glEnable(gl.GL_DEPTH_TEST)\n            gl.glDepthMask(gl.GL_TRUE)\n            gl.glDepthFunc(gl.GL_LEQUAL)\n            gl.glDepthRange(0, 1)\n            gl.glEnable(gl.GL_BLEND)\n            gl.glBlendFunc(gl.GL_SRC_ALPHA, gl.GL_ONE_MINUS_SRC_ALPHA)\n\n            # Render\n            if self.render_type == Mesh.RenderType.POINTS:\n                gl.glDrawArrays(gl.GL_POINTS, 0, self.n_verts_bytes)\n            elif self.render_type == Mesh.RenderType.LINES:\n                gl.glDrawElements(gl.GL_LINES, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n            elif self.render_type == Mesh.RenderType.TRIS:\n                gl.glDrawElements(gl.GL_TRIANGLES, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n            elif self.render_type == Mesh.RenderType.QUADS:\n                gl.glDrawElements(gl.GL_TRIANGLES, self.n_"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible: return\n\n        # Set up OpenGL context\n        gl.glUseProgram(self.mesh_program if self.render_type != Mesh.RenderType.POINTS else self.point_program)\n\n        # Set up OpenGL uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Set up OpenGL buffers\n        gl.glBindVertexArray(self.vao)\n\n        # Draw the mesh\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, self.n_verts_bytes)\n        elif self.render_type == Mesh.RenderType.LINES:\n            gl.glDrawElements(gl.GL_LINES, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            gl.glDrawElements(gl.GL_TRIANGLES, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            gl.glDrawElements(gl.GL_QUADS, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            gl.glDrawElements(gl.GL_TRIANGLE_STRIP, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n        else:\n            raise ValueError(f'Unsupported mesh type: {self.render_type}')\n\n        # Unbind buffers\n        gl.glBindVertexArray(0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        # Set up OpenGL state\n        with eglContextManager(self.compute_device) as eglctx:\n            if not self.visible:\n                return\n\n            # Set up OpenGL state\n            gl.glEnable(gl.GL_DEPTH_TEST)\n            gl.glDepthMask(gl.GL_TRUE)\n            gl.glDepthFunc(gl.GL_LEQUAL)\n            gl.glDepthRange(0.0, 1.0)\n            gl.glClear(gl.GL_COLOR_BUFFER_BIT | gl.GL_DEPTH_BUFFER_BIT)\n\n            # Set up the shader program\n            if self.render_type == Mesh.RenderType.POINTS:\n                use_gl_program(self.point_program)\n            else:\n                use_gl_program(self.mesh_program)\n\n            # Set up uniforms\n            self.upload_gl_uniforms(camera)\n\n            # Set up vertex array object\n            gl.glBindVertexArray(self.vao)\n\n            # Set up viewport\n            gl.glViewport(0, 0, camera.W, camera.H)\n\n            # Set up scissor\n            gl.glScissor(0, 0, camera.W, camera.H)\n            gl.glEnable(gl.GL_SCISSOR_TEST)\n\n            # Draw\n            if self.render_type == Mesh.RenderType.POINTS:\n                gl.glDrawArrays(gl.GL_POINTS, 0, self.n_verts_bytes)\n            elif self.render_type == Mesh.RenderType.LINES:\n                gl.glDrawElements(gl.GL_LINES, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n            elif self.render_type == Mesh.RenderType.TRIS:\n                gl.glDrawElements(gl.GL_TRIANGLES, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n            elif self.render_type"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        # TODO: Add a rendering option to render the mesh in a wireframe mode\n        # TODO: Add a rendering option to render the mesh with a different color for each face\n        # TODO: Add a rendering option to render the mesh with a different color for each vertex\n        # TODO: Add a rendering option to render the mesh with a different color for each edge\n        # TODO: Add a rendering option to render the mesh with a different color for each vertex and face\n\n        # Check if the mesh is visible\n        if not self.visible:\n            return\n\n        # Select the appropriate OpenGL program\n        if self.render_type == Mesh.RenderType.POINTS:\n            program = self.point_program\n        else:\n            program = self.mesh_program\n\n        # Upload uniforms\n        self.upload_gl_uniforms(program, camera)\n\n        # Bind vertex array object\n        gl.glBindVertexArray(self.vao)\n\n        # Draw\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, self.n_verts_bytes)\n        elif self.render_type == Mesh.RenderType.LINES:\n            gl.glDrawElements(gl.GL_LINES, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            gl.glDrawElements(gl.GL_TRIANGLES, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            gl.glDrawElements(gl.GL_QUADS, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            gl.glDrawElements(gl.GL_TRIANGLE_STRIP, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n        else"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if not hasattr(self, 'tex'):\n            self.init_texture()\n\n        w = w or self.W\n        h = h or self.H\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n        if ptr.shape[-1] == 3:\n            ptr = np.concatenate([ptr, np.ones((*ptr.shape[:-1], 1), dtype=ptr.dtype) * 255], axis=-1)  # add alpha channel\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if not hasattr(self, 'tex'):\n            self.init_texture()\n\n        w = w or self.W\n        h = h or self.H\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n        if ptr.shape[-1] == 3:\n            ptr = np.concatenate([ptr, np.ones_like(ptr[..., :1]) * 255], axis=-1)  # add alpha channel\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glBindBuffer(gl.GL_PIXEL_UNPACK_BUFFER, self.pbo)\n        gl.glBufferData(gl.GL_PIXEL_UNPACK_BUFFER, w * h * 4 * ptr.itemsize, ptr, gl.GL_STREAM_DRAW)  # GL_STREAM_DRAW\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, None)\n        gl.glBindBuffer(gl.GL_PIXEL_UNPACK_BUFFER, 0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if not hasattr(self, 'tex'):\n            self.init_texture()\n\n        w = w or self.W\n        h = h or self.H\n\n        # Convert from torch.Tensor to numpy.ndarray\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        # Upload the data to the texture\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        w = w or self.W\n        h = h or self.H\n        if ptr.shape[-1] == 3:\n            ptr = np.concatenate([ptr, np.ones_like(ptr[..., :1]) * 255], axis=-1)  # add alpha channel\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        w = w or self.W\n        h = h or self.H\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n        if ptr.shape[-1] == 3:\n            ptr = np.concatenate([ptr, np.ones_like(ptr[..., :1]) * 255], axis=-1)  # add alpha channel\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        if not hasattr(self, 'tex'):\n            self.init_texture()\n\n        if x < 0:\n            x = self.max_W + x\n        if y < 0:\n            y = self.max_H + y\n\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n\n        w = min(self.max_W - x, w)\n        h = min(self.max_H - y, h)\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n\n        if ptr.dtype != np.uint8:\n            ptr = (ptr * 255).astype(np.uint8)\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n        if ptr.dtype == np.float32:\n            ptr = (ptr * 255).astype(np.uint8)\n        elif ptr.dtype != np.uint8:\n            raise ValueError(f'Unsupported dtype: {ptr.dtype}')\n\n        w = w or self.W\n        h = h or self.H\n        if ptr.shape[-1] == 3:\n            ptr = np.concatenate([ptr, np.ones((*ptr.shape[:-1], 1), dtype=np.uint8) * 255], axis=-1)  # add alpha channel\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n        if not isinstance(ptr, np.ndarray):\n            raise TypeError(f'Expected a numpy array or a torch tensor, but got {type(ptr)}')\n\n        w = w or self.W\n        h = h or self.H\n        if ptr.shape[-1] == 3:\n            ptr = np.concatenate([ptr, np.ones_like(ptr[..., :1]) * 255], axis=-1)  # add alpha channel\n\n        # gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        # gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA8, gl.GL_UNSIGNED_BYTE, ptr)\n        # gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        if not isinstance(ptr, np.ndarray):\n            raise TypeError('Only numpy arrays or PyTorch tensors are supported as input.')\n\n        w = w or self.W\n        h = h or self.H\n\n        if ptr.shape[-1] == 3:\n            ptr = np.concatenate([ptr, np.ones_like(ptr[..., :1]) * 255], axis=-1)  # add alpha channel\n\n        # Convert the numpy array to a ctypes pointer\n        ptr = np.ascontiguousarray(ptr, dtype=np.uint8)\n        ptr_p = ptr.ctypes.data_as(ctypes.POINTER(ctypes.c_uint8))\n\n        # Bind the texture to OpenGL\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # Copy the pixel data to the texture\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr_p)\n\n        # Unbind the texture from OpenGL\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        if isinstance(ptr, np.ndarray):\n            if ptr.shape[-1] == 3:\n                ptr = np.concatenate([ptr, np.ones_like(ptr[..., :1]) * 255], axis=-1)  # add alpha channel\n\n            if len(ptr.shape) == 3:\n                ptr = ptr[..., [2, 1, 0, 3]]  # rgb to bgr\n\n            if x == 0 and y == 0 and w == 0 and h == 0:\n                w = self.W\n                h = self.H\n\n            if w == 0: w = self.W\n            if h == 0: h = self.H\n\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n\n        else:\n            raise TypeError(f'Expected input to be a numpy array or a PyTorch tensor, but got {type(ptr)}')\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        # assert isinstance(ptr, np.ndarray) or isinstance(ptr, torch.Tensor), 'Only numpy arrays or PyTorch tensors are supported'\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n        if not hasattr(self, 'tex'):\n            self.init_texture()\n\n        if isinstance(ptr, np.ndarray):\n            w = w or self.W\n            h = h or self.H\n            if ptr.shape[-1] == 3:\n                ptr = np.concatenate([ptr, np.ones_like(ptr[..., :1]) * 255], axis=-1)  # add alpha channel\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        # Convert the input tensor to a numpy array\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n        elif isinstance(ptr, np.ndarray):\n            pass\n        else:\n            raise TypeError(\"The input argument should be either a PyTorch Tensor or a NumPy array.\")\n\n        # Set the width and height if they are not provided\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n\n        # Upload the texture to OpenGL\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if not hasattr(self, 'tex'):\n            self.init_texture()\n\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        if not isinstance(ptr, np.ndarray):\n            raise TypeError('ptr must be a numpy array or a torch tensor')\n\n        if ptr.ndim == 2:\n            if ptr.shape[-1] == 3:\n                ptr = np.concatenate([ptr, np.ones((ptr.shape[0], 1), dtype=ptr.dtype) * 255], axis=-1)  # add alpha channel\n\n        if ptr.ndim != 3 or ptr.shape[-1] != 4:\n            raise ValueError('ptr must be a numpy array of shape (H, W, 4)')\n\n        w = w or self.W\n        h = h or self.H\n\n        if self.use_quad_draw:\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr.tobytes())\n        else:\n            gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, self.fbo)\n            gl.glFramebufferTexture2D(gl.GL_DRAW_FRAMEBUFFER, gl.GL_COLOR_ATTACHMENT0, gl.GL_TEXTURE_2D, self.tex, 0)\n            gl.glClearColor(0, 0, 0, 1)\n            gl.glClear(gl.GL_COLOR_BUFFER_BIT)\n            gl.glBindVertexArray(self.vao)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n        if isinstance(ptr, np.ndarray):\n            ptr = ptr.astype(np.uint8)\n\n        # Get the texture's width and height\n        w = w or self.W\n        h = h or self.H\n\n        # Make sure the texture is bound to the GL_TEXTURE_2D target\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # Set the texture parameters\n        gl.glTexParameteri(gl.GL_TEXTURE_2D, gl.GL_TEXTURE_MAG_FILTER, gl.GL_NEAREST)\n        gl.glTexParameteri(gl.GL_TEXTURE_2D, gl.GL_TEXTURE_MIN_FILTER, gl.GL_NEAREST)\n\n        # Upload the texture data\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n\n        # Unbind the texture\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        if not isinstance(ptr, np.ndarray):\n            raise ValueError('Expected numpy array or torch tensor as input, but got {}'.format(type(ptr)))\n\n        if not hasattr(self, 'tex'):\n            self.init_texture()\n\n        w = w or self.W\n        h = h or self.H\n\n        # The following line is necessary for the texture to be visible in the GUI\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n        if not isinstance(ptr, np.ndarray):\n            raise TypeError('Expected numpy array or torch tensor as input, but got {}'.format(type(ptr)))\n\n        if ptr.ndim == 2:\n            ptr = ptr[..., None]  # add alpha channel\n\n        if ptr.ndim != 3:\n            raise ValueError('Expected numpy array or torch tensor with 3 dimensions, but got {}'.format(ptr.ndim))\n\n        if ptr.shape[-1] != 4:\n            raise ValueError('Expected numpy array or torch tensor with 4 channels, but got {}'.format(ptr.shape[-1]))\n\n        if w == 0: w = self.W\n        if h == 0: h = self.H\n\n        w = min(w, self.W - x)\n        h = min(h, self.H - y)\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n        if not isinstance(ptr, np.ndarray):\n            raise TypeError('Expected a numpy array or a PyTorch tensor, but got a {}.'.format(type(ptr)))\n\n        w = w or self.W\n        h = h or self.H\n\n        # The texture is bound to the current context, so we don't need to bind it to the context before uploading.\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        # Convert the input data source to a numpy array\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        # If width and height are not provided, use the default width and height\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n\n        # Make sure the data source is a numpy array\n        assert isinstance(ptr, np.ndarray), \"The input data source must be a numpy array or a PyTorch tensor.\"\n\n        # If the data source is a grayscale image, convert it to a RGB image\n        if ptr.ndim == 2:\n            ptr = np.stack([ptr, ptr, ptr], axis=2)\n\n        # If the data source is a single channel image, convert it to a RGBA image\n        if ptr.ndim == 3:\n            if ptr.shape[2] == 1:\n                ptr = np.concatenate([ptr, np.ones(ptr.shape[:2] + (3,), dtype=ptr.dtype)], axis=2)\n\n        # Make sure the data source is a RGBA image\n        assert ptr.ndim == 3 and ptr.shape[2] == 4, \"The input data source must be a RGBA image.\"\n\n        # Make sure the data source is in the range [0, 1]\n        assert (ptr >= 0).all() and (ptr <= 1).all(), \"The input data source must be in the range [0, 1].\"\n\n        # Make sure the data source is a 32-bit floating point image\n        assert ptr.dtype == np.float32, \"The input data source must be a 32-bit floating point image.\"\n\n        # Make sure the texture update is within the texture boundaries\n        assert x >= 0 and x + w <= self.W, \"The x-coordinate of the texture update is out of range.\"\n        assert y >= 0 and y + h <= self.H, \"The y-coordinate of the texture update is out of range.\"\n\n        #"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if not hasattr(self, 'tex'):\n            self.init_texture()\n\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        w = w or self.W\n        h = h or self.H\n\n        # Copy the data to the texture\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate inputs\n    if R.ndim != 3 or R.shape[-2:] != (3, 3):\n        raise ValueError(f\"R must be a batch of 3x3 matrices, but got {R.shape}\")\n    if tvec.ndim != 2 or tvec.shape[-1] != 3:\n        raise ValueError(f\"tvec must be a batch of 3D vectors, but got {tvec.shape}\")\n    if camera_matrix.ndim != 2 or camera_matrix.shape[-1] != 3 or camera_matrix.shape[-2] != 3:\n        raise ValueError(f\"camera_matrix must be a batch of 3x3 matrices, but got {camera_matrix.shape}\")\n    if image_size.ndim != 2 or image_size.shape[-1] != 2:\n        raise ValueError(f\"image_size must be a batch of 2D vectors, but got {image_size.shape}\")\n\n    # Ensure inputs are batched\n    batch_dim = max(R.shape[0], tvec.shape[0], camera_matrix.shape[0], image_size.shape[0])\n    R = R.expand(batch_dim, 3, 3)\n    tvec = tvec.expand(batch_dim, 3)\n    camera_matrix = camera_matrix.expand(batch_dim, 3, 3)\n    image_size = image_size.expand(batch_dim, 2)\n\n    # Compute camera position\n    camera_position = -torch.bmm(R.transpose(1, 2), tvec[:, :, None])[:, :, 0]\n\n    # Compute camera rotation\n    camera_rotation = matrix_to_rotation_6d(R)\n\n    # Compute focal length and principal point\n    fx = camera_matrix[:, 0, 0]\n    fy = camera_matrix[:, 1, 1]\n    if torch.abs(fx / fy - 1).max() > 0.01:\n        warn"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate the input arguments\n\n    # Validate R\n    if R.ndim != 3:\n        raise ValueError(f\"R must be a batch of 3x3 matrices. Got {R.shape}.\")\n    if R.shape[-2:] != (3, 3):\n        raise ValueError(f\"R must be a batch of 3x3 matrices. Got {R.shape}.\")\n\n    # Validate tvec\n    if tvec.ndim != 2:\n        raise ValueError(f\"tvec must be a batch of 3D vectors. Got {tvec.shape}.\")\n    if tvec.shape[-1] != 3:\n        raise ValueError(f\"tvec must be a batch of 3D vectors. Got {tvec.shape}.\")\n\n    # Validate camera_matrix\n    if camera_matrix.ndim != 3:\n        raise ValueError(f\"camera_matrix must be a batch of 3x3 matrices. Got {camera_matrix.shape}.\")\n    if camera_matrix.shape[-2:] != (3, 3):\n        raise ValueError(f\"camera_matrix must be a batch of 3x3 matrices. Got {camera_matrix.shape}.\")\n\n    # Validate image_size\n    if image_size.ndim != 2:\n        raise ValueError(f\"image_size must be a batch of 2D vectors. Got {image_size.shape}.\")\n    if image_size.shape[-1] != 2:\n        raise ValueError(f\"image_size must be a batch of 2D vectors. Got {image_size.shape}.\")\n\n    # Validate znear\n    if znear <= 0:\n        raise ValueError(f\"znear must be a positive float. Got {znear}.\")\n\n    # Validate the batch size\n    if R.shape[0] != tvec.shape[0] or R.shape[0] != camera_matrix.shape[0] or R.shape[0] != image_size.shape[0]:\n        raise ValueError(\n            f\"batch size must be equal for all"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Check if the inputs are batched\n    if R.ndim < 3:\n        raise ValueError(\"R must be at least a batch of a single camera.\")\n    if tvec.ndim < 3:\n        raise ValueError(\"tvec must be at least a batch of a single camera.\")\n    if camera_matrix.ndim < 3:\n        raise ValueError(\"camera_matrix must be at least a batch of a single camera.\")\n    if image_size.ndim < 3:\n        raise ValueError(\"image_size must be at least a batch of a single camera.\")\n\n    # Check if the shapes of the inputs are valid\n    if R.shape[:-2] != tvec.shape[:-2]:\n        raise ValueError(\"R and tvec must have the same batch dimensions.\")\n    if R.shape[:-2] != camera_matrix.shape[:-2]:\n        raise ValueError(\"R and camera_matrix must have the same batch dimensions.\")\n    if R.shape[:-2] != image_size.shape[:-2]:\n        raise ValueError(\"R and image_size must have the same batch dimensions.\")\n    if tvec.shape[-2:] != (3, 1):\n        raise ValueError(\"tvec must have shape (*, 3, 1).\")\n    if camera_matrix.shape[-2:] != (3, 3):\n        raise ValueError(\"camera_matrix must have shape (*, 3, 3).\")\n    if image_size.shape[-2:] != (2,):\n        raise ValueError(\"image_size must have shape (*, 2).\")\n\n    # Check if the values of the inputs are valid\n    if (camera_matrix[..., 0, 1] != 0).any():\n        warn_once_about_pulsar_fxfy()\n    if (camera_matrix[..., 0, 0] <= 0).any() or (camera_matrix[..., 1, 1] <= 0).any():\n        raise ValueError(\"camera_matrix must have positive focal lengths.\")\n    if (image_size <= 0).any().any():\n        raise ValueError(\"image"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate input shapes and values\n    if R.ndim != 3:\n        raise ValueError(f\"R must be batched, of shape (N, 3, 3), but has shape {R.shape}.\")\n    if tvec.ndim != 2:\n        raise ValueError(f\"tvec must be batched, of shape (N, 3), but has shape {tvec.shape}.\")\n    if camera_matrix.ndim != 3:\n        raise ValueError(f\"camera_matrix must be batched, of shape (N, 3, 3), but has shape {camera_matrix.shape}.\")\n    if image_size.ndim != 2:\n        raise ValueError(f\"image_size must be batched, of shape (N, 2), but has shape {image_size.shape}.\")\n    if R.shape[0] != tvec.shape[0] or R.shape[0] != camera_matrix.shape[0] or R.shape[0] != image_size.shape[0]:\n        raise ValueError(f\"All input tensors must have the same batch size, but have shapes {R.shape}, {tvec.shape}, {camera_matrix.shape}, and {image_size.shape}.\")\n    if R.shape[1:] != (3, 3):\n        raise ValueError(f\"R must be of shape (N, 3, 3), but has shape {R.shape}.\")\n    if tvec.shape[1:] != (3,):\n        raise ValueError(f\"tvec must be of shape (N, 3), but has shape {tvec.shape}.\")\n    if camera_matrix.shape[1:] != (3, 3):\n        raise ValueError(f\"camera_matrix must be of shape (N, 3, 3), but has shape {camera_matrix.shape}.\")\n    if image_size.shape[1:] != (2,):\n        raise ValueError(f\"image_size must be of shape (N, 2), but has shape {image_size.shape}.\")\n    if znear <= 0:"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate the input arguments\n    assert R.shape[-2:] == (3, 3), \"R must have shape (*, 3, 3).\"\n    assert tvec.shape[-2:] == (3, 1), \"tvec must have shape (*, 3, 1).\"\n    assert camera_matrix.shape[-2:] == (3, 3), \"camera_matrix must have shape (*, 3, 3).\"\n    assert image_size.shape[-2:] == (2,), \"image_size must have shape (*, 2).\"\n\n    # Check if the batch dimensions are empty and add a batch dimension if needed\n    if R.ndimension() == 2:\n        R = R[None]\n    if tvec.ndimension() == 2:\n        tvec = tvec[None]\n    if camera_matrix.ndimension() == 2:\n        camera_matrix = camera_matrix[None]\n    if image_size.ndimension() == 1:\n        image_size = image_size[None]\n\n    # Calculate the camera position\n    cam_pos = -torch.bmm(R.transpose(dim0=-2, dim1=-1), tvec)\n\n    # Calculate the camera rotation\n    cam_rot = matrix_to_rotation_6d(R)\n\n    # Calculate the focal length\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    if fx.mean() / fy.mean() > 1.01 or fx.mean() / fy.mean() < 0.99:\n        warn_once_about_pulsar_fxfy()\n    fx = fx.mean(dim=-1, keepdim=True)\n    fy = fy.mean(dim=-1, keepdim=True)\n    f = (fx + fy) / 2\n\n    # Calculate the principal point\n    px = camera_matrix[..., 0, 2]\n    py = camera_matrix[...,"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate inputs\n    assert R.shape[-2:] == (3, 3)\n    assert tvec.shape[-2:] == (3, 1)\n    assert camera_matrix.shape[-2:] == (3, 3)\n    assert image_size.shape[-2:] == (2,)\n    assert R.shape[:-2] == tvec.shape[:-2] == camera_matrix.shape[:-2] == image_size.shape[:-2]\n\n    # Convert rotation matrix to rotation vector\n    rvec = matrix_to_rotation_6d(R)\n\n    # Extract focal length\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    if fx.mean() / fy.mean() > 1.01 or fx.mean() / fy.mean() < 0.99:\n        warn_once_about_pulsar_fxfy()\n    f = (fx + fy) / 2\n\n    # Extract principal point\n    cx = camera_matrix[..., 0, 2]\n    cy = camera_matrix[..., 1, 2]\n\n    # Extract image size\n    W = image_size[..., 0]\n    H = image_size[..., 1]\n\n    # Compute camera position\n    camera_position = -torch.matmul(R.transpose(-1, -2), tvec)\n\n    # Compute Pulsar camera parameters\n    camera_params = torch.cat(\n        [\n            camera_position,\n            rvec,\n            torch.tensor([[znear]], device=R.device, dtype=R.dtype).expand(rvec.shape[:-1] + (1,)),\n            torch.tensor([[f]], device=R.device, dtype=R.dtype).expand(rvec.shape[:-1] + (1,)),\n            torch.tensor([[cx]], device=R.device, dtype=R.dtype).expand(rvec.shape[:-1] + ("}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate the input arguments\n    assert R.shape[-2:] == (3, 3), \"R must be a batch of 3x3 matrices\"\n    assert tvec.shape[-2:] == (3, 1), \"tvec must be a batch of 3x1 vectors\"\n    assert camera_matrix.shape[-2:] == (3, 3), \"camera_matrix must be a batch of 3x3 matrices\"\n    assert image_size.shape[-2:] == (2, 1), \"image_size must be a batch of 2x1 vectors\"\n    assert znear > 0, \"znear must be positive\"\n\n    # Unpack the inputs\n    batch_size = R.shape[:-2]\n    R = R.reshape(-1, 3, 3)\n    tvec = tvec.reshape(-1, 3, 1)\n    camera_matrix = camera_matrix.reshape(-1, 3, 3)\n    image_size = image_size.reshape(-1, 2, 1)\n\n    # Compute the camera position\n    camera_position = -torch.bmm(R.transpose(1, 2), tvec)\n\n    # Compute the camera rotation\n    camera_rotation = matrix_to_rotation_6d(R)\n\n    # Compute the focal length\n    focal_length_x = camera_matrix[:, 0, 0]\n    focal_length_y = camera_matrix[:, 1, 1]\n    if not torch.allclose(focal_length_x, focal_length_y):\n        warn_once_about_pulsar_fxfy()\n    focal_length = torch.mean(torch.stack([focal_length_x, focal_length_y], dim=1), dim=1)\n\n    # Compute the principal point\n    principal_point_x = camera_matrix[:, 0, 2]\n    principal_point_y = camera_matrix[:, 1, 2]\n    if not torch.allclose(pr"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate inputs\n    assert R.shape[-2:] == (3, 3), \\\n        f\"Invalid rotation shape: {R.shape[-2:]}, expected (3, 3).\"\n    assert tvec.shape[-2:] == (3, 1), \\\n        f\"Invalid translation shape: {tvec.shape[-2:]}, expected (3, 1).\"\n    assert camera_matrix.shape[-2:] == (3, 3), \\\n        f\"Invalid camera matrix shape: {camera_matrix.shape[-2:]}, expected (3, 3).\"\n    assert image_size.shape[-2:] == (2,), \\\n        f\"Invalid image size shape: {image_size.shape[-2:]}, expected (2,).\"\n\n    # Convert rotation matrix to 6D rotation representation\n    R = matrix_to_rotation_6d(R)\n\n    # Compute the camera position\n    camera_position = -torch.bmm(R, tvec)\n\n    # Compute the focal length and principal point\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    px = camera_matrix[..., 0, 2]\n    py = camera_matrix[..., 1, 2]\n\n    # Compute the sensor width\n    sensor_width = torch.max(image_size[..., 0], dim=-1, keepdim=True)[0]\n\n    # Compute the focal length\n    focal_length = torch.sqrt(fx * fy)\n    focal_length = focal_length / znear\n\n    # Compute the principal point\n    principal_point = torch.stack([px / znear, py / znear], dim=-1)\n\n    # Compute the principal point offset\n    principal_point_offset = principal_point - sensor_width / 2\n\n    # Compute the camera parameters\n    camera_params = torch.cat([\n        camera_position,\n        R,\n        focal_length[..., None],\n        principal_point_offset,"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # validate input arguments\n    assert R.shape[-2:] == (3, 3)\n    assert tvec.shape[-2:] == (3, 1)\n    assert camera_matrix.shape[-2:] == (3, 3)\n    assert image_size.shape[-2:] == (2,)\n\n    # get batch dimensions\n    batch_dims = R.shape[:-2]\n\n    # normalize the camera intrinsic matrix\n    camera_matrix = camera_matrix.clone()\n    camera_matrix[..., 0, 0] = camera_matrix[..., 0, 0] / image_size[..., 0:1]\n    camera_matrix[..., 1, 1] = camera_matrix[..., 1, 1] / image_size[..., 1:2]\n\n    # calculate the focal length\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    if fx.numel() > 1 and fx.mean() < fy.mean():\n        warn_once_about_pulsar_fxfy()\n    fx = fx.mean(dim=-1, keepdim=True)\n    fy = fy.mean(dim=-1, keepdim=True)\n    focal_length = (fx + fy) / 2\n\n    # calculate the principal point\n    px = camera_matrix[..., 0, 2:3]\n    py = camera_matrix[..., 1, 2:3]\n    if px.numel() > 1 and px.mean() > py.mean():\n        warn_once_about_pulsar_fxfy()\n    px = px.mean(dim=-1, keepdim=True)\n    py = py.mean(dim=-1, keepdim=True)\n    principal_point = torch.cat([px, py], dim=-1)\n\n    # calculate the sensor width\n    sensor_width = torch.max(camera_matrix[..., 0, 0], camera_matrix[..., 1, "}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate the shapes and values of the input arguments\n    assert R.shape[-2:] == (3, 3)\n    assert tvec.shape[-2:] == (3, 1)\n    assert camera_matrix.shape[-2:] == (3, 3)\n    assert image_size.shape[-2:] == (2,)\n    assert image_size.dtype == torch.float32\n    assert R.dtype == tvec.dtype == camera_matrix.dtype\n\n    # Ensure that all inputs are batched\n    batch_shape = R.shape[:-2]\n    R = R.expand(batch_shape + (3, 3))\n    tvec = tvec.expand(batch_shape + (3, 1))\n    camera_matrix = camera_matrix.expand(batch_shape + (3, 3))\n\n    # Compute the focal length and principal point\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    if fx.mean() / fy.mean() > 1.01 or fx.mean() / fy.mean() < 0.99:\n        warn_once_about_pulsar_fxfy()\n    fx = fx.mean(dim=-1, keepdim=True)\n    fy = fy.mean(dim=-1, keepdim=True)\n    ppx = camera_matrix[..., 0, 2]\n    ppy = camera_matrix[..., 1, 2]\n\n    # Compute the sensor width\n    s_w = torch.sqrt(\n        torch.sum(\n            (camera_matrix[..., 0, :2] - camera_matrix[..., 1, :2]) ** 2,\n            dim=-1,\n            keepdim=True,\n        )\n    )\n\n    # Compute the camera position\n    tvec = -torch.bmm(R, tvec)\n\n    # Compute the rotation\n    R = matrix_to_rotation_6d(R)"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate input arguments\n    if R.shape[-2:] != (3, 3):\n        raise ValueError(\n            \"Input rotation matrix should have shape (*, 3, 3). Got {}\".format(\n                R.shape\n            )\n        )\n    if tvec.shape[-2:] != (3, 1):\n        raise ValueError(\n            \"Input translation vector should have shape (*, 3, 1). Got {}\".format(\n                tvec.shape\n            )\n        )\n    if camera_matrix.shape[-2:] != (3, 3):\n        raise ValueError(\n            \"Input camera matrix should have shape (*, 3, 3). Got {}\".format(\n                camera_matrix.shape\n            )\n        )\n    if image_size.shape[-2:] != (2,):\n        raise ValueError(\n            \"Input image size should have shape (*, 2). Got {}\".format(image_size.shape)\n        )\n\n    # Ensure inputs are batched\n    R, tvec, camera_matrix, image_size = [\n        arg.view(-1, *arg.shape[-2:])\n        for arg in (R, tvec, camera_matrix, image_size)\n    ]\n\n    # Compute camera position and rotation\n    R_pulsar = matrix_to_rotation_6d(R)\n    t_pulsar = -torch.bmm(R_pulsar, tvec)\n\n    # Compute focal length and principal point\n    fx, fy = camera_matrix[..., 0, 0], camera_matrix[..., 1, 1]\n    cx, cy = camera_matrix[..., 0, 2], camera_matrix[..., 1, 2]\n    # Note: Pulsar only supports a single focal lengths. For converting OpenCV\n    # focal lengths, we average them for x and y directions. Note that 6D\n    # representation is not unique.\n    warn_once_about_pulsar_fxfy()\n    f = (fx + fy) / 2\n    c = tor"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate input arguments\n    R, tvec, camera_matrix, image_size = validate_camera_params(R, tvec, camera_matrix, image_size)\n\n    # Compute camera position\n    camera_position = -torch.bmm(R, tvec.unsqueeze(-1)).squeeze(-1)\n\n    # Compute camera rotation\n    camera_rotation = matrix_to_rotation_6d(R)\n\n    # Compute focal length\n    # Note that Pulsar only supports a single focal length. For converting OpenCV focal lengths, we average them for x and y directions. The focal lengths for x and y you provided differ by more than 1%, which means this could introduce a noticeable error.\n    # https://github.com/facebookresearch/pulsar/blob/master/pulsar/transforms/camera_transforms.py#L21\n    warn_once_about_pulsar_fxfy()\n    fx = camera_matrix[:, 0, 0]\n    fy = camera_matrix[:, 1, 1]\n    fx_fy = fx / fy\n    if torch.abs(fx_fy - 1) > 0.01:\n        warn_once_about_pulsar_fxfy()\n    fx = torch.mean(fx)\n    fy = torch.mean(fy)\n\n    # Compute principal point\n    px = camera_matrix[:, 0, 2]\n    py = camera_matrix[:, 1, 2]\n    px_py = px / py\n    if torch.abs(px_py - 1) > 0.01:\n        warn_once_about_pulsar_fxfy()\n    px = torch.mean(px)\n    py = torch.mean(py)\n\n    # Compute sensor width\n    sx = image_size[:, 1]\n    sy = image_size[:, 0]\n    sx_sy = sx / sy\n    if"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate the input arguments\n    assert R.shape[-2:] == (3, 3), \"R must be a batch of 3x3 matrices.\"\n    assert tvec.shape[-2:] == (3, 1), \"tvec must be a batch of 3x1 vectors.\"\n    assert camera_matrix.shape[-2:] == (3, 3), \"camera_matrix must be a batch of 3x3 matrices.\"\n    assert image_size.shape[-2:] == (2,), \"image_size must be a batch of 2D vectors.\"\n    assert R.shape[:-2] == tvec.shape[:-2] == camera_matrix.shape[:-2] == image_size.shape[:-1], \"The shapes of R, tvec, camera_matrix, and image_size must be the same.\"\n    assert image_size.dtype == torch.float32, \"image_size must be a float tensor.\"\n\n    # Ensure that all inputs are batched\n    R = R.view(-1, 3, 3)\n    tvec = tvec.view(-1, 3, 1)\n    camera_matrix = camera_matrix.view(-1, 3, 3)\n    image_size = image_size.view(-1, 2)\n\n    # Calculate the camera position\n    camera_position = -torch.bmm(R.transpose(1, 2), tvec)\n\n    # Calculate the camera rotation\n    camera_rotation = R\n\n    # Calculate the focal length\n    # Note: We use the average of the focal lengths for x and y directions\n    # as Pulsar only supports a single focal length\n    fx = camera_matrix[:, 0, 0]\n    fy = camera_matrix[:, 1, 1]\n    if fx.mean() / fy.mean() > 1.01 or fx.mean() / fy.mean() < 0.99:\n        warn_once_about_pulsar_fxfy()\n    f = (fx.mean() + fy.mean()) /"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate input arguments\n    assert R.shape[-2:] == (3, 3), \"R must be a (B, 3, 3) tensor\"\n    assert tvec.shape[-1:] == (3,), \"tvec must be a (B, 3) tensor\"\n    assert camera_matrix.shape[-2:] == (3, 3), \"camera_matrix must be a (B, 3, 3) tensor\"\n    assert image_size.shape[-1:] == (2,), \"image_size must be a (B, 2) tensor\"\n    assert len(R.shape[:-2]) == len(tvec.shape[:-1]) == len(camera_matrix.shape[:-2]) == len(image_size.shape[:-1])\n\n    # Compute camera position\n    # Note: Pulsar uses a left-handed coordinate system, so we have to negate the z component\n    camera_position = -torch.bmm(R, tvec.unsqueeze(-1)).squeeze(-1)\n\n    # Compute focal length\n    # Note: Pulsar uses a left-handed coordinate system, so we have to negate the focal length\n    fx, fy = camera_matrix[..., 0, 0], camera_matrix[..., 1, 1]\n    fx = fx / image_size[..., 0:1]\n    fy = fy / image_size[..., 1:2]\n    focal_length = -(fx + fy) / 2.0\n    focal_length = focal_length.expand(focal_length.shape[:-1] + (1,))\n\n    # Compute principal point\n    # Note: Pulsar uses a left-handed coordinate system, so we have to negate the x and y components\n    principal_point = -camera_matrix[..., 0:1, 2]\n    principal_point = principal_point.expand(principal_point.shape[:-2] + (1, 2))\n\n    # Compute sensor width\n    # Note: Pulsar uses"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate input arguments\n    assert R.shape[-2:] == (3, 3), \"R must be a batch of 3x3 matrices\"\n    assert tvec.shape[-2:] == (3, 1), \"tvec must be a batch of 3x1 vectors\"\n    assert camera_matrix.shape[-2:] == (3, 3), \"camera_matrix must be a batch of 3x3 matrices\"\n    assert image_size.shape[-2:] == (2, 1), \"image_size must be a batch of 2x1 vectors\"\n    assert znear > 0, \"znear must be a positive scalar\"\n\n    # Ensure input arguments are batched\n    R = R.view(-1, 3, 3)\n    tvec = tvec.view(-1, 3, 1)\n    camera_matrix = camera_matrix.view(-1, 3, 3)\n    image_size = image_size.view(-1, 2, 1)\n\n    # Extract camera intrinsic parameters\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    px = camera_matrix[..., 0, 2]\n    py = camera_matrix[..., 1, 2]\n\n    # Compute the focal length from the camera matrix\n    focal_length = (fx + fy) / 2.0\n\n    # Compute the principal point offset from the camera matrix\n    principal_point_offset = (px - image_size[..., 0, 0] / 2.0, py - image_size[..., 1, 0] / 2.0)\n\n    # Compute the sensor width from the image size\n    sensor_width = image_size[..., 0, 0]\n\n    # Compute the focal length and principal point offset to be used for Pulsar\n    focal_length = focal_length / (znear + 1e-8)\n    principal_point_offset = (\n        principal_point_offset[0] / (sensor_"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate and convert inputs\n    R, tvec, camera_matrix, image_size = [\n        torch.as_tensor(x) for x in [R, tvec, camera_matrix, image_size]\n    ]\n    assert len(R) == len(tvec) == len(camera_matrix) == len(image_size)\n    assert R.shape[-2:] == (3, 3)\n    assert tvec.shape[-2:] == (3, 1)\n    assert camera_matrix.shape[-2:] == (3, 3)\n    assert image_size.shape[-2:] == (2, 1)\n\n    # Get principal point offsets\n    cx = camera_matrix[:, 0, 2]\n    cy = camera_matrix[:, 1, 2]\n\n    # Get focal lengths\n    fx = camera_matrix[:, 0, 0]\n    fy = camera_matrix[:, 1, 1]\n    # Average the focal lengths in x and y directions, since Pulsar only supports a single focal length\n    if torch.any(torch.abs(fx / fy - 1) > 0.01):\n        warn_once_about_pulsar_fxfy()\n    f = (fx + fy) / 2\n\n    # Get sensor width\n    sensor_width = torch.max(image_size[:, 0], dim=-1)[0]\n\n    # Get camera position\n    c = -torch.bmm(R, tvec)\n\n    # Get rotation\n    r = matrix_to_rotation_6d(R)\n\n    # Get camera parameters\n    camera_params = torch.cat(\n        [\n            c,\n            r,\n            f.unsqueeze(-1),\n            cx.unsqueeze(-1),\n            cy.unsqueeze(-1),\n            sensor_width.unsqueeze(-1),\n            znear * torch.ones_like(f),\n        ],\n        dim=-1,\n    )\n\n    return camera_params"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate the input arguments\n    assert R.shape[-2:] == (3, 3)\n    assert tvec.shape[-1:] == (3,)\n    assert camera_matrix.shape[-2:] == (3, 3)\n    assert image_size.shape[-1:] == (2,)\n    assert R.device == tvec.device == camera_matrix.device == image_size.device\n\n    # Compute the camera position\n    camera_position = -torch.bmm(R.transpose(1, 2), tvec[..., None])[..., 0]\n\n    # Compute the camera rotation\n    camera_rotation = matrix_to_rotation_6d(R)\n\n    # Compute the focal length\n    # TODO: Check if the focal lengths are valid\n    fxfy = camera_matrix[..., 0, 0]\n    if not torch.allclose(camera_matrix[..., 0, 1], camera_matrix[..., 1, 0]):\n        warn_once_about_pulsar_fxfy()\n    fxfy = (camera_matrix[..., 0, 0] + camera_matrix[..., 1, 1]) / 2\n\n    # Compute the principal point\n    # TODO: Check if the principal points are valid\n    ppxy = camera_matrix[..., 0:2, 2]\n\n    # Compute the sensor width\n    # TODO: Check if the sensor width is valid\n    sensor_width = (ppxy[..., 0].abs() * 2 / fxfy).clamp(min=0.01)\n\n    # Compute the focal length\n    focal_length = fxfy / (sensor_width / image_size[..., 0:1])\n\n    # Compute the principal point\n    principal_point = ppxy / (sensor_width / image_size[..., 0:1])\n\n    # Compute the near clipping plane distance\n    znear = torch.tensor([znear], device=focal_length.device)\n\n    # Return the camera parameters"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate the inputs\n    assert R.shape[-2:] == (3, 3), \"R must be a batch of 3x3 matrices\"\n    assert tvec.shape[-2:] == (3, 1), \"tvec must be a batch of 3x1 vectors\"\n    assert camera_matrix.shape[-2:] == (3, 3), \"camera_matrix must be a batch of 3x3 matrices\"\n    assert image_size.shape[-2:] == (2, 1), \"image_size must be a batch of 2x1 vectors\"\n\n    # Make sure that the batch dimensions of all inputs are the same\n    batch_dim = R.shape[:-2]\n    assert tvec.shape[:-2] == batch_dim\n    assert camera_matrix.shape[:-2] == batch_dim\n    assert image_size.shape[:-2] == batch_dim\n\n    # Compute the camera position\n    # The camera position is the translation vector of the camera\n    # in the opposite direction\n    camera_position = -tvec\n\n    # Compute the camera rotation\n    # The camera rotation is the inverse of the rotation matrix\n    camera_rotation = affine_inverse(R)\n\n    # Compute the focal length\n    # The focal length is the inverse of the focal length in the camera intrinsic matrix\n    # and the ratio between the image width and the image height\n    # and the near clipping plane distance\n    focal_length = camera_matrix[..., 0, 0] / image_size[..., 0, 0]\n    focal_length = focal_length / image_size[..., 1, 0]\n    focal_length = focal_length / znear\n\n    # Compute the principal point offset\n    # The principal point offset is the inverse of the principal point offset in the camera intrinsic matrix\n    principal_point_offset = -camera_matrix[..., 0, 2] / image_size[..., 0, 0]\n\n    # Compute the sensor width\n    # The sensor width is the inverse of the sensor width in the camera intrinsic matrix\n   "}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate inputs\n    R, tvec, camera_matrix, image_size = [\n        arg.unsqueeze(dim=0) if arg.ndim == 2 else arg for arg in [R, tvec, camera_matrix, image_size]\n    ]\n    assert R.shape[-2:] == (3, 3)\n    assert tvec.shape[-1:] == (3,)\n    assert camera_matrix.shape[-2:] == (3, 3)\n    assert image_size.shape[-1:] == (2,)\n\n    # Compute camera position\n    # Note: We use the translation vector to compute the position of the camera, rather than the translation matrix.\n    # This is because the translation matrix is defined as the negative of the translation vector,\n    # and thus would not be invertible.\n    position = -tvec\n\n    # Compute camera rotation\n    # Note: We use the inverse of the rotation matrix to compute the rotation, rather than the inverse of the translation matrix.\n    # This is because the inverse of the translation matrix is the translation matrix itself,\n    # and thus would not be invertible.\n    rotation = affine_inverse(R)\n\n    # Compute focal length\n    # Note: We use the focal length from the x direction,\n    # and average the focal length in the x and y directions to compute the focal length.\n    # This is because the focal length from the x direction is used to compute the principal point offset,\n    # and thus would not be invertible.\n    fxfy = camera_matrix[..., 0, 0]\n    fx, fy = fxfy[..., 0], fxfy[..., 1]\n    warn_once_about_pulsar_fxfy()\n    focal_length = (fx + fy) / 2\n\n    # Compute principal point offset\n    # Note: We use the principal point offset from the x direction,\n    # and average the principal point offset in the x and y directions to compute the principal point offset.\n    # This is because the principal point offset from the x direction is used to compute the principal point,"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate and ensure that all inputs are batched\n    assert R.dim() >= 2 and R.shape[-2:] == (3, 3)\n    assert tvec.dim() >= 2 and tvec.shape[-2:] == (3, 1)\n    assert camera_matrix.dim() >= 2 and camera_matrix.shape[-2:] == (3, 3)\n    assert image_size.dim() >= 2 and image_size.shape[-2:] == (2, 1)\n\n    # Ensure that the batch size is consistent across all inputs\n    batch_size = R.shape[:-2]\n    for arg in [tvec, camera_matrix, image_size]:\n        assert arg.dim() >= 2 and arg.shape[:-2] == batch_size\n\n    # Compute the camera position and rotation\n    camera_position = -torch.bmm(R.transpose(dim0=-2, dim1=-1), tvec)[:, :, 0]\n    camera_rotation = matrix_to_rotation_6d(R)\n\n    # Compute the focal length and principal point\n    # Note that the focal lengths are computed from the principal points, and the principal points are computed from the focal lengths.\n    # We use the focal lengths to compute the principal points, and then normalize the focal lengths by the image size.\n    # We use the principal points to compute the focal lengths, and then denormalize the principal points by the image size.\n    # The focal length computation is based on the OpenCV implementation.\n    # The principal point computation is based on the Pulsar implementation.\n    # The principal point is the center of the image, and the focal length is the distance from the principal point to the edge of the image.\n    # The focal length is computed as the product of the image size and the focal length, and the principal point is computed as the image size divided by the focal length.\n    # The focal length is divided by the znear to account for the near clipping plane.\n    # The focal length is divided by the image size to normalize it.\n    # The principal"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if self.use_quad_draw:\n            # Set up viewport and scissor box\n            old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n            old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n            gl.glViewport(x, y, w or self.W, h or self.H)\n            gl.glScissor(x, y, w or self.W, h or self.H)\n\n            # Activate the shader program\n            gl.glUseProgram(self.quad_program)\n\n            # Bind the texture\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n            # Draw the quadrilateral\n            gl.glBindVertexArray(self.vao)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n            # Restore the viewport and scissor box\n            gl.glViewport(*old_viewport)\n            gl.glScissor(*old_scissor)\n\n        else:\n            # Set up viewport and scissor box\n            old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n            old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n            gl.glViewport(x, y, w or self.W, h or self.H)\n            gl.glScissor(x, y, w or self.W, h or self.H)\n\n            # Draw the quadrilateral\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glBegin(gl.GL_QUADS)\n            gl.glTexCoord2f(0, 0)\n            gl.glVertex2f(-1, -1)\n            gl.glTexCoord2f(1, 0)\n            gl.glVertex2f(1, -1)\n            gl.glTexCo"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if self.use_quad_draw:\n            # Set up viewport and scissor box\n            old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n            old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n            gl.glScissor(x, y, w or self.W, h or self.H)\n            gl.glViewport(x, y, w or self.W, h or self.H)\n\n            # Draw the quadrilateral\n            gl.glUseProgram(self.quad_program)\n            gl.glBindVertexArray(self.vao)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n            # Restore viewport and scissor box\n            gl.glUseProgram(0)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n            gl.glBindVertexArray(0)\n            gl.glScissor(*old_scissor)\n            gl.glViewport(*old_viewport)\n        else:\n            # Blit the texture to the screen\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)\n            gl.glBlitFramebuffer(x, y, w or self.W, h or self.H,\n                                 0, 0, self.W, self.H,\n                                 gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.visible: return\n\n        if self.use_quad_draw:\n            gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, 0)\n            gl.glViewport(0, 0, self.W, self.H)\n            gl.glScissor(x, y, w or self.W, h or self.H)\n            gl.glEnable(gl.GL_SCISSOR_TEST)\n            gl.glClearColor(0.0, 0.0, 0.0, 0.0)\n            gl.glClear(gl.GL_COLOR_BUFFER_BIT)\n            gl.glUseProgram(self.quad_program)\n            gl.glBindVertexArray(self.vao)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n            gl.glBindVertexArray(0)\n            gl.glDisable(gl.GL_SCISSOR_TEST)\n            gl.glViewport(0, 0, self.max_W, self.max_H)\n            gl.glScissor(0, 0, self.max_W, self.max_H)\n        else:\n            gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, 0)\n            gl.glViewport(x, y, w or self.W, h or self.H)\n            gl.glClearColor(0.0, 0.0, 0.0, 0.0)\n            gl.glClear(gl.GL_COLOR_BUFFER_BIT)\n            gl.glUseProgram(self.quad_program)\n            gl.glBindVertexArray(self.vao)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n            gl.glBindVertexArray(0)\n            gl.glViewport(0, 0, self.max_W, self.max_H)\n            gl.glScissor(0, 0, self.max_W, self"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        # If use_quad_draw is False, it falls back to a simpler blit method for drawing.\n        if not self.use_quad_draw:\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glBegin(gl.GL_QUADS)\n            gl.glTexCoord2f(0.0, 0.0)\n            gl.glVertex2f(x, y)\n            gl.glTexCoord2f(1.0, 0.0)\n            gl.glVertex2f(x + w, y)\n            gl.glTexCoord2f(1.0, 1.0)\n            gl.glVertex2f(x + w, y + h)\n            gl.glTexCoord2f(0.0, 1.0)\n            gl.glVertex2f(x, y + h)\n            gl.glEnd()\n            return\n\n        # Set up a specific viewport and scissor box for rendering.\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        gl.glViewport(x, y, w, h)\n        old_scissor_box = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n        gl.glScissor(x, y, w, h)\n\n        # Activate a shader program.\n        gl.glUseProgram(self.quad_program)\n        self.use_gl_program(self.quad_program)\n\n        # Bind a texture.\n        gl.glActiveTexture(gl.GL_TEXTURE0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glUniform1i(self.uniforms.tex, 0)\n\n        # Draw the quadrilateral using vertex data.\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        # Restore the viewport and"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if self.use_quad_draw:\n            gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, 0)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glViewport(x, y, w, h)\n            gl.glScissor(x, y, w, h)\n            gl.glUseProgram(self.quad_program)\n            gl.glBindVertexArray(self.vao)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n            gl.glBindVertexArray(0)\n            gl.glUseProgram(0)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n            gl.glViewport(0, 0, self.max_W, self.max_H)\n            gl.glScissor(0, 0, self.max_W, self.max_H)\n        else:\n            gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, 0)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glBegin(gl.GL_QUADS)\n            gl.glTexCoord2f(0, 0)\n            gl.glVertex3f(x, y, 0)\n            gl.glTexCoord2f(1, 0)\n            gl.glVertex3f(x + w, y, 0)\n            gl.glTexCoord2f(1, 1)\n            gl.glVertex3f(x + w, y + h, 0)\n            gl.glTexCoord2f(0, 1)\n            gl.glVertex3f(x, y + h, 0)\n            gl.glEnd()\n            gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n            gl.glViewport(0, 0, self.max_W, self.max_H)\n            gl.glScissor(0"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.visible: return\n\n        if self.use_quad_draw:\n            # Set up viewport and scissor box\n            old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n            old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n            gl.glViewport(x, y, w or self.W, h or self.H)\n            gl.glScissor(x, y, w or self.W, h or self.H)\n\n            # Draw the quadrilateral\n            gl.glUseProgram(self.quad_program)\n            gl.glBindVertexArray(self.vao)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n            # Restore viewport and scissor box\n            gl.glViewport(*old_viewport)\n            gl.glScissor(*old_scissor)\n        else:\n            # Blit the texture to the screen\n            old_fbo = gl.glGetIntegerv(gl.GL_FRAMEBUFFER_BINDING)\n            gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, self.fbo)\n            gl.glBlitFramebuffer(x, y, w or self.W, h or self.H,\n                                 x, y, w or self.W, h or self.H,\n                                 gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n            gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, old_fbo)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.visible: return\n\n        if not self.use_quad_draw:\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glBegin(gl.GL_QUADS)\n            gl.glTexCoord2f(0.0, 0.0)\n            gl.glVertex2f(x, y)\n            gl.glTexCoord2f(1.0, 0.0)\n            gl.glVertex2f(x + w, y)\n            gl.glTexCoord2f(1.0, 1.0)\n            gl.glVertex2f(x + w, y + h)\n            gl.glTexCoord2f(0.0, 1.0)\n            gl.glVertex2f(x, y + h)\n            gl.glEnd()\n            return\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glUseProgram(self.quad_program)\n        self.use_gl_program(self.quad_program)\n        gl.glBindVertexArray(self.vao)\n\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, self.fbo)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, 0)\n        gl.glViewport(0, 0, self.max_W, self.max_H)\n        gl.glScissor(0, 0, self.max_W, self.max_H)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.visible: return\n\n        if self.use_quad_draw:\n            # Set up viewport and scissor box\n            old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n            old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n            gl.glViewport(x, y, w or self.W, h or self.H)\n            gl.glScissor(x, y, w or self.W, h or self.H)\n\n            # Activate quad program\n            gl.glUseProgram(self.quad_program)\n            gl.glBindVertexArray(self.vao)\n\n            # Bind texture\n            gl.glActiveTexture(gl.GL_TEXTURE0)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glUniform1i(self.uniforms.tex, 0)\n\n            # Draw\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n            # Restore viewport and scissor box\n            gl.glViewport(*old_viewport)\n            gl.glScissor(*old_scissor)\n\n        else:\n            # Blit to screen\n            old_fbo = gl.glGetIntegerv(gl.GL_DRAW_FRAMEBUFFER_BINDING)\n            gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, self.fbo)\n            gl.glBlitFramebuffer(x, y, w or self.W, h or self.H,\n                                 x, y, w or self.W, h or self.H,\n                                 gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n            gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, old_fbo)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if self.use_quad_draw:\n            # Set up viewport and scissor box\n            old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n            gl.glViewport(x, y, w or self.W, h or self.H)\n            gl.glScissor(x, y, w or self.W, h or self.H)\n\n            # Activate the quad shader program\n            gl.glUseProgram(self.quad_program)\n            gl.glBindVertexArray(self.vao)\n\n            # Bind the texture to the shader program\n            gl.glActiveTexture(gl.GL_TEXTURE0)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glUniform1i(self.uniforms.tex, 0)\n\n            # Draw the quadrilateral\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n            # Restore the viewport and scissor box\n            gl.glViewport(*old_viewport)\n            gl.glScissor(*old_viewport)\n\n        else:\n            # Blit the texture to the screen\n            old_fbo = gl.glGetIntegerv(gl.GL_FRAMEBUFFER_BINDING)\n            gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, self.fbo)\n            gl.glBlitFramebuffer(x, y, w or self.W, h or self.H,\n                                 x, y, w or self.W, h or self.H,\n                                 gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n            gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, old_fbo)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.visible: return\n\n        if self.use_quad_draw:\n            # Setup the viewport and scissor box\n            old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n            old_scissor_box = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n            gl.glViewport(x, y, w or self.W, h or self.H)\n            gl.glScissor(x, y, w or self.W, h or self.H)\n\n            # Activate the quad program\n            gl.glUseProgram(self.quad_program)\n            self.use_gl_program(self.quad_program)\n            gl.glBindVertexArray(self.vao)\n\n            # Bind the texture and draw\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n            # Restore the viewport and scissor box\n            gl.glViewport(*old_viewport)\n            gl.glScissor(*old_scissor_box)\n\n        else:\n            # Setup the viewport and scissor box\n            old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n            old_scissor_box = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n            gl.glViewport(x, y, w or self.W, h or self.H)\n            gl.glScissor(x, y, w or self.W, h or self.H)\n\n            # Draw the quadrilateral\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n            # Restore the viewport and scissor box\n            gl.glViewport(*old_viewport)\n           "}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if self.use_quad_draw:\n            # Save the current viewport and scissor box\n            old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n            old_scissor_box = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n\n            # Set the viewport and scissor box for drawing the quadrilateral\n            gl.glViewport(x, y, w or self.W, h or self.H)\n            gl.glScissor(x, y, w or self.W, h or self.H)\n\n            # Activate the quad program and bind the texture\n            gl.glUseProgram(self.quad_program)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n            # Draw the quadrilateral\n            gl.glBindVertexArray(self.vao)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n            # Restore the viewport and scissor box\n            gl.glViewport(*old_viewport)\n            gl.glScissor(*old_scissor_box)\n        else:\n            # Draw a quad using the blit method\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glBegin(gl.GL_QUADS)\n            gl.glTexCoord2f(0, 1)\n            gl.glVertex2f(x, y)\n            gl.glTexCoord2f(1, 1)\n            gl.glVertex2f(x + w or self.W, y)\n            gl.glTexCoord2f(1, 0)\n            gl.glVertex2f(x + w or self.W, y + h or self.H)\n            gl.glTexCoord2f(0, 0)\n            gl.glVertex2f(x, y + h or self.H)\n            gl.glEnd()\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if self.use_quad_draw:\n            old_fbo = gl.glGetIntegerv(gl.GL_FRAMEBUFFER_BINDING)\n            old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n            old_scissor_box = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n            gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, self.fbo)\n            gl.glViewport(0, 0, self.W, self.H)\n            gl.glScissor(x, y, w or self.W, h or self.H)\n            gl.glUseProgram(self.quad_program)\n            gl.glBindVertexArray(self.vao)\n            gl.glActiveTexture(gl.GL_TEXTURE0)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n            gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, old_fbo)\n            gl.glViewport(*old_viewport)\n            gl.glScissor(*old_scissor_box)\n\n        else:\n            gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, 0)\n            gl.glViewport(x, y, w or self.W, h or self.H)\n            gl.glUseProgram(self.quad_program)\n            gl.glBindVertexArray(self.vao)\n            gl.glActiveTexture(gl.GL_TEXTURE0)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        # If use_quad_draw is False, it falls back to a simpler blit method for drawing.\n        if not self.use_quad_draw:\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glBegin(gl.GL_QUADS)\n            gl.glTexCoord2f(0.0, 0.0)\n            gl.glVertex2f(x, y)\n            gl.glTexCoord2f(1.0, 0.0)\n            gl.glVertex2f(x + w, y)\n            gl.glTexCoord2f(1.0, 1.0)\n            gl.glVertex2f(x + w, y + h)\n            gl.glTexCoord2f(0.0, 1.0)\n            gl.glVertex2f(x, y + h)\n            gl.glEnd()\n            return\n\n        # Set up the viewport and scissor box for rendering.\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        gl.glScissor(x, y, w, h)\n        gl.glViewport(x, y, w, h)\n\n        # Activate a shader program, bind a texture, and draw the quadrilateral.\n        gl.glUseProgram(self.quad_program)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        # Restore the viewport and scissor box to their original sizes.\n        gl.glScissor(*old_scissor)\n        gl.glViewport(*old_viewport)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.visible: return\n\n        # If use_quad_draw is True, we will use OpenGL to draw a quad\n        if self.use_quad_draw:\n            # Set up viewport and scissor box\n            old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n            old_scissor_box = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n            gl.glViewport(x, y, w or self.W, h or self.H)\n            gl.glScissor(x, y, w or self.W, h or self.H)\n\n            # Set up shader program\n            gl.glUseProgram(self.quad_program)\n            gl.glBindVertexArray(self.vao)\n\n            # Bind texture\n            gl.glActiveTexture(gl.GL_TEXTURE0)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glUniform1i(self.uniforms.tex, 0)\n\n            # Draw quad\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n            # Restore viewport and scissor box\n            gl.glViewport(*old_viewport)\n            gl.glScissor(*old_scissor_box)\n\n        # If use_quad_draw is False, we will use blitting to draw a quad\n        else:\n            # Set up viewport and scissor box\n            old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n            old_scissor_box = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n            gl.glViewport(x, y, w or self.W, h or self.H)\n            gl.glScissor(x, y, w or self.W, h or self.H)\n\n            # Draw quad\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.visible: return\n\n        # Draw using the quad program\n        if self.use_quad_draw:\n            # Setup viewport and scissor\n            old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n            gl.glViewport(x, y, w or self.W, h or self.H)\n            gl.glScissor(x, y, w or self.W, h or self.H)\n            gl.glEnable(gl.GL_SCISSOR_TEST)\n\n            # Draw the quad\n            gl.glUseProgram(self.quad_program)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glBindVertexArray(self.vao)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n            # Restore viewport and scissor\n            gl.glUseProgram(0)\n            gl.glBindVertexArray(0)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n            gl.glDisable(gl.GL_SCISSOR_TEST)\n            gl.glViewport(*old_viewport)\n\n        # Draw using blitting\n        else:\n            gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)\n            gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n            gl.glBlitFramebuffer(0, 0, self.W, self.H,\n                                 x, y, w or self.W, h or self.H,\n                                 gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.visible: return\n\n        if not self.use_quad_draw:\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glBegin(gl.GL_QUADS)\n            gl.glTexCoord2f(0, 1)\n            gl.glVertex3f(x, y, 0)\n            gl.glTexCoord2f(1, 1)\n            gl.glVertex3f(x + w, y, 0)\n            gl.glTexCoord2f(1, 0)\n            gl.glVertex3f(x + w, y + h, 0)\n            gl.glTexCoord2f(0, 0)\n            gl.glVertex3f(x, y + h, 0)\n            gl.glEnd()\n            return\n\n        # Save the current viewport and scissor box\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor_box = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n\n        # Set up the viewport and scissor box for drawing\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        # Activate the quad shader program\n        gl.glUseProgram(self.quad_program)\n\n        # Bind the texture\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # Draw the quadrilateral\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        # Restore the viewport and scissor box\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor_box)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.visible:\n            return\n\n        if self.use_quad_draw:\n            # Setup viewport and scissor box\n            gl.glPushAttrib(gl.GL_VIEWPORT_BIT)\n            gl.glPushAttrib(gl.GL_SCISSOR_BIT)\n            gl.glViewport(x, y, w or self.W, h or self.H)\n            gl.glScissor(x, y, w or self.W, h or self.H)\n\n            # Draw quadrilateral\n            gl.glUseProgram(self.quad_program)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glBindVertexArray(self.vao)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n            # Restore viewport and scissor box\n            gl.glPopAttrib()\n            gl.glPopAttrib()\n        else:\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glBindVertexArray(self.vao)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.visible: return\n\n        # Set up viewport and scissor box for drawing\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        gl.glViewport(x, y, w or self.W, h or self.H)\n        gl.glScissor(x, y, w or self.W, h or self.H)\n        gl.glEnable(gl.GL_SCISSOR_TEST)\n\n        # Draw quadrilateral\n        if self.use_quad_draw:\n            gl.glUseProgram(self.quad_program)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glBindVertexArray(self.vao)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n        else:\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glBindVertexArray(self.vao)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        # Restore viewport and scissor box\n        gl.glUseProgram(0)\n        gl.glBindVertexArray(0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n        gl.glDisable(gl.GL_SCISSOR_TEST)\n        gl.glViewport(*old_viewport)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if self.use_quad_draw:\n            gl.glBindVertexArray(self.vao)\n            gl.glUseProgram(self.quad_program)\n            gl.glUniform2f(self.uniforms.tex, 0, 0)  # no texture offset\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glBindBuffer(gl.GL_ARRAY_BUFFER, self.vbo)\n            gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, self.ebo)\n            gl.glViewport(x, y, w, h)\n            gl.glScissor(x, y, w, h)\n            gl.glDrawElements(gl.GL_TRIANGLES, 6, gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            gl.glBindVertexArray(0)\n            gl.glViewport(0, 0, self.max_W, self.max_H)\n            gl.glScissor(0, 0, self.max_W, self.max_H)\n        else:\n            gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)\n            gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n            gl.glBlitFramebuffer(x, y, w, h,\n                                 0, 0, self.max_W, self.max_H,\n                                 gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if self.use_quad_draw:\n            # Setup viewport and scissor box\n            old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n            old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n            gl.glViewport(x, y, w, h)\n            gl.glScissor(x, y, w, h)\n\n            # Activate quad program\n            gl.glUseProgram(self.quad_program)\n            gl.glBindVertexArray(self.vao)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n            # Draw quadrilateral\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n            # Restore viewport and scissor box\n            gl.glScissor(old_scissor[0], old_scissor[1], old_scissor[2], old_scissor[3])\n            gl.glViewport(old_viewport[0], old_viewport[1], old_viewport[2], old_viewport[3])\n        else:\n            # Blit the texture to the screen\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glBlitFramebuffer(x, y, w, h,\n                                 0, 0, self.W, self.H,\n                                 gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n\n    # Adjust R and T to match PyTorch3D's coordinate system\n    R = R.mT\n    T = -T\n\n    # Compute intrinsic matrix for NDC\n    K_ndc = get_ndc_perspective_matrix(K, H, W)\n\n    return H, W, K_ndc, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    K = K.clone()\n    K[..., 0, 2] = (K[..., 0, 2] + 0.5) * 2 / W - 1  # fx\n    K[..., 1, 2] = (K[..., 1, 2] + 0.5) * 2 / H - 1  # fy\n    K[..., 0, 0] = K[..., 0, 0] * 2 / W  # fx\n    K[..., 1, 1] = K[..., 1, 1] * 2 / H  # fy\n    K[..., 0, 1] = K[..., 0, 1] * 2 / W  # cx\n    K[..., 1, 0] = K[..., 1, 0] * 2 / H  # cy\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    # Extract parameters\n    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    # Correct R and T\n    R = R.mT\n    T = -T\n    # Recalculate K for NDC\n    K = get_ndc_perspective_matrix(K, H, W, 1, 1).mT\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n\n    # Adjust R and T to match PyTorch3D's conventions\n    R = R.clone()\n    R[:, :, 1] *= -1\n    T[:, :, 1] *= -1\n\n    # Adjust K to match PyTorch3D's conventions\n    K_inv = torch.linalg.inv(K)\n    K_pytorch3d = torch.zeros_like(K)\n    K_pytorch3d[:, 0, 0] = K_inv[:, 0, 0]\n    K_pytorch3d[:, 1, 1] = K_inv[:, 1, 1]\n    K_pytorch3d[:, 0, 2] = K_inv[:, 0, 2]\n    K_pytorch3d[:, 1, 2] = K_inv[:, 1, 2]\n    K_pytorch3d[:, 2, 2] = K_inv[:, 1, 1]\n\n    return H, W, K_pytorch3d, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    # Extract camera parameters.\n    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n\n    # Adjust rotation matrix.\n    R = R.clone()\n    R[:, :, 1] *= -1\n    R[:, :, 2] *= -1\n\n    # Adjust translation vector.\n    T = T.clone()\n    T[:, 1] *= -1\n    T[:, 2] *= -1\n\n    # Compute camera intrinsic matrix.\n    K = get_ndc_perspective_matrix(K, H, W).to(R.dtype)\n\n    # Return camera parameters.\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    # Extract camera parameters from batch\n    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n\n    # Adjust R and T to match PyTorch3D's coordinate system\n    R = R.clone()\n    T = T.clone()\n    R[:, :, 2] *= -1\n    T[:, 2, :] *= -1\n\n    # Compute camera center in the camera's coordinate system\n    C = -torch.bmm(R.permute(0, 2, 1), T).squeeze(2)\n\n    # Compute intrinsic matrix for NDC\n    K = get_ndc_perspective_matrix(K, H, W)\n\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    # Extract camera parameters\n    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    # Adjust rotation matrix\n    R = R.clone()\n    R[:, :, 1] *= -1  # Flip y-axis\n    R[:, :, 2] *= -1  # Flip z-axis\n    # Adjust translation vector\n    T = T.clone()\n    T[:, :, 1] *= -1  # Flip y-axis\n    T[:, :, 2] *= -1  # Flip z-axis\n    # Calculate intrinsic matrix\n    K_new = get_ndc_perspective_matrix(K, H, W, 1, 1).to(K.dtype)\n    return H, W, K_new, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n\n    # Adjust R and T to match PyTorch3D's coordinate system\n    R = R.clone()\n    T = T.clone()\n    R[:, :, 2] *= -1  # flip z\n    T[:, 2] *= -1  # flip z\n\n    # Compute NDC intrinsic matrix\n    K_ndc = get_ndc_perspective_matrix(K, H, W)\n\n    return H, W, K_ndc, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n\n    # Adjust R and T to match PyTorch3D's conventions\n    R = R.mT\n    T = T.mT\n    C = -R @ T\n\n    # Recalculate K for NDC\n    K = get_ndc_perspective_matrix(K, H, W, n=1, f=1).mT\n\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    # Extract PyTorch3D camera parameters from batch input\n    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n\n    # Adjust rotation matrix to match PyTorch3D's convention\n    # (R, T) is applied on the right (requires a transposed R from OpenCV camera format)\n    # Coordinate system is different from that of OpenCV (cv: right down front, 3d: left up front)\n    # However, the correction has to be down on both T and R... (instead of just R)\n    R = R.transpose(-1, -2)\n    R = R.transpose(-1, -2)\n    T = -R @ T\n    R = R.transpose(-1, -2)\n    T = T.transpose(-1, -2)\n\n    # Compute camera intrinsic matrix for NDC\n    K = get_ndc_perspective_matrix(K, H, W, 1, 1).mT\n\n    # Compute camera center in the camera's coordinate system\n    C = -R @ T\n\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    # Adjust R and T to match PyTorch3D's conventions\n    R = R.mT\n    T = -T\n    # Calculate the camera intrinsic matrix for NDC\n    K = get_ndc_perspective_matrix(K, H, W, 1, 1).to(R.dtype)\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        # Check if the Quad instance has been initialized\n        if not hasattr(self, 'fbo'):\n            self.init_texture()\n\n        # Check if the Quad instance has been initialized\n        if not hasattr(self, 'fbo'):\n            self.init_texture()\n\n        # Check if the Quad instance has been initialized\n        if not hasattr(self, 'fbo'):\n            self.init_texture()\n\n        # Check if the Quad instance has been initialized\n        if not hasattr(self, 'fbo'):\n            self.init_texture()\n\n        # Check if the Quad instance has been initialized\n        if not hasattr(self, 'fbo'):\n            self.init_texture()\n\n        # Check if the Quad instance has been initialized\n        if not hasattr(self, 'fbo'):\n            self.init_texture()\n\n        # Check if the Quad instance has been initialized\n        if not hasattr(self, 'fbo'):\n            self.init_texture()\n\n        # Check if the Quad instance has been initialized\n        if not hasattr(self, 'fbo'):\n            self.init_texture()\n\n        # Check if the Quad instance has been initialized\n        if not hasattr(self, 'fbo'):\n            self.init_texture()\n\n        # Check if the Quad instance has been initialized\n        if not hasattr(self, 'fbo'):\n            self.init_texture()\n\n        # Check if the Quad instance has been initialized\n        if not hasattr(self, 'fbo'):\n            self.init_texture()\n\n        # Check if the Quad instance has been initialized\n        if not hasattr(self, 'fbo'):\n            self.init_texture()\n\n        # Check if the Quad instance has been initialized\n        if not hasattr(self, 'fbo'):\n            self.init_texture()\n\n        # Check if the Quad instance has been initialized\n        if not hasattr(self, 'fbo'):\n            self.init_texture()\n\n        # Check if the Quad instance"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        if not hasattr(self, 'fbo'):\n            self.init_texture()\n\n        # assert self.use_quad_cuda, \"Need to enable cuda-opengl interop to copy from device to device, check creation of this Quad\"\n        w = w or self.W\n        h = h or self.H\n        old = gl.glGetIntegerv(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(x, y, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)  # now self.tex contains the content of the already rendered frame\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        # Check if the Quad instance is initialized\n        if not hasattr(self, 'tex'):\n            self.init_texture()\n\n        # Check if the Quad instance is initialized\n        if not hasattr(self, 'fbo'):\n            self.init_texture()\n\n        # Check if the Quad instance is initialized\n        if not hasattr(self, 'quad_program'):\n            self.compile_shaders()\n\n        # Check if the Quad instance is initialized\n        if not hasattr(self, 'vao'):\n            self.init_texture()\n\n        # Check if the Quad instance is initialized\n        if not hasattr(self, 'quad_program'):\n            self.compile_shaders()\n\n        # Check if the Quad instance is initialized\n        if not hasattr(self, 'uniforms'):\n            self.uniforms = dotdict()\n            self.use_gl_program(self.quad_program)\n\n        # Check if the Quad instance is initialized\n        if not hasattr(self, 'uniforms'):\n            self.uniforms = dotdict()\n            self.use_gl_program(self.quad_program)\n\n        # Check if the Quad instance is initialized\n        if not hasattr(self, 'uniforms'):\n            self.uniforms = dotdict()\n            self.use_gl_program(self.quad_program)\n\n        # Check if the Quad instance is initialized\n        if not hasattr(self, 'uniforms'):\n            self.uniforms = dotdict()\n            self.use_gl_program(self.quad_program)\n\n        # Check if the Quad instance is initialized\n        if not hasattr(self, 'uniforms'):\n            self.uniforms = dotdict()\n            self.use_gl_program(self.quad_program)\n\n        # Check if the Quad instance is initialized\n        if not hasattr(self, 'uniforms'):\n            self.uniforms = dotdict()\n            self.use_gl_program(self.quad_program)\n\n        # Check if the Quad instance is initialized\n        if not hasattr(self, 'uniform"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        if not hasattr(self, 'fbo'):\n            self.init_texture()\n\n        # assert self.use_quad_cuda, \"Need to enable cuda-opengl interop to copy from device to device, check creation of this Quad\"\n        w = w or self.W\n        h = h or self.H\n        old_fbo = gl.glGetIntegerv(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(x, y, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old_fbo)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        if not self.use_quad_cuda:\n            self.upload_to_texture()\n            return\n\n        if not hasattr(self, 'cu_tex'):\n            self.init_texture()\n\n        from cuda import cudart\n        CHECK_CUDART_ERROR(cudart.cudaGraphicsMapResources(1, self.cu_tex, torch.cuda.current_stream().cuda_stream))\n        cu_tex_arr = CHECK_CUDART_ERROR(cudart.cudaGraphicsSubResourceGetMappedArray(self.cu_tex, 0, 0))\n\n        w = w or self.W\n        h = h or self.H\n        buffer = torch.empty((h, w, 4), dtype=torch.uint8, device=self.verts.device)\n\n        CHECK_CUDART_ERROR(cudart.cudaMemcpy2DFromArrayAsync(buffer.data_ptr(),  # dst\n                                                             w * 4 * buffer.element_size(),  # dpitch\n                                                             cu_tex_arr,  # src\n                                                             x * 4 * buffer.element_size(),  # wOffset\n                                                             y,  # hOffset\n                                                             w * 4 * buffer.element_size(),  # width Width of matrix transfer (columns in bytes)\n                                                             h,  # height\n                                                             cudart.cudaMemcpyDeviceToDevice,  # kind\n                                                             torch.cuda.current_stream().cuda_stream))  # stream\n\n        # cv2.imwrite('image.png', buffer.flip(0).detach().cpu().numpy()[..., [2,1,0,3]])\n        CHECK_CUDART_ERROR(cudart.cudaGraphicsUnmapResources(1, self.cu_tex, torch.cuda.current_stream().cuda_stream))\n\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, self.fbo)  # write buffer defaults to 0"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        # Get the current read framebuffer\n        old_fbo = gl.glGetIntegerv(gl.GL_READ_FRAMEBUFFER_BINDING)\n\n        # Bind the Quad instance's framebuffer as the read framebuffer\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n\n        # Copy the pixel block from the Quad instance's framebuffer to the default framebuffer\n        gl.glBlitFramebuffer(x, y, w, h,  # src\n                             x, y, w, h,  # dst\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)  # filter\n\n        # Restore the previously bound read framebuffer\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old_fbo)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        if not hasattr(self, 'fbo'):\n            self.init_texture()\n\n        # assert self.use_quad_cuda, \"Need to enable cuda-opengl interop to copy from device to device, check creation of this Quad\"\n        w = w or self.W\n        h = h or self.H\n        old_fbo = gl.glGetIntegerv(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(x, y, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old_fbo)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        # Get the previous framebuffer object (FBO)\n        old_fbo = gl.glGetIntegerv(gl.GL_READ_FRAMEBUFFER_BINDING)\n\n        # Bind the Quad instance's framebuffer object (FBO)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n\n        # Copy the pixel block from the Quad instance's framebuffer object (FBO) to the default framebuffer\n        gl.glBlitFramebuffer(x, y, w or self.W, h or self.H, x, y, w or self.W, h or self.H, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n\n        # Restore the previous framebuffer object (FBO)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old_fbo)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        if not hasattr(self, 'fbo'):\n            self.init_texture()\n\n        # assert self.use_quad_cuda, \"Need to enable cuda-opengl interop to copy from device to device, check creation of this Quad\"\n        w = w or self.W\n        h = h or self.H\n\n        old_fbo = gl.glGetIntegerv(gl.GL_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)  # read buffer defaults to 0\n        gl.glBlitFramebuffer(x, y, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)  # now self.tex contains the content of the already rendered frame\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, old_fbo)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n\n        if not hasattr(self, 'fbo'):\n            self.init_texture()\n\n        old_fbo = gl.glGetIntegerv(gl.GL_READ_FRAMEBUFFER_BINDING)\n        old_draw_fbo = gl.glGetIntegerv(gl.GL_DRAW_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, old_draw_fbo)\n\n        # gl.glBlitFramebuffer(x, y, w, h,  # source\n        #                      x, y, w, h,  # destination\n        #                      gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)  # filter\n        gl.glBlitFramebuffer(x, y, w, h,  # source\n                             x, y, w, h,  # destination\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)  # filter\n\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old_fbo)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        # Check if the FBO is bound\n        old_fbo = gl.glGetIntegerv(gl.GL_FRAMEBUFFER_BINDING)\n        if old_fbo != self.fbo:\n            gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n\n        # Check if the texture is bound\n        old_tex = gl.glGetIntegerv(gl.GL_TEXTURE_BINDING_2D)\n        if old_tex != self.tex:\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # Check if the viewport is set\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        if old_viewport != (x, y, w, h):\n            gl.glViewport(x, y, w, h)\n\n        # Check if the scissor is set\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n        if old_scissor != (x, y, w, h):\n            gl.glScissor(x, y, w, h)\n\n        # Perform the blit\n        gl.glBlitFramebuffer(0, 0, w, h,  # src\n                             0, 0, w, h,  # dst\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n\n        # Restore the old state\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, old_fbo)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, old_tex)\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        if not hasattr(self, 'fbo'):\n            self.init_texture()\n\n        old_fbo = gl.glGetIntegerv(gl.GL_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)  # read buffer defaults to 0\n\n        w = w or self.W\n        h = h or self.H\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, old_fbo)\n        gl.glBlitFramebuffer(x, y, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)  # now self.tex contains the content of the already rendered framebuffer\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old_fbo)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        if not hasattr(self, 'fbo'):\n            self.init_texture()\n\n        # assert self.use_quad_cuda, \"Need to enable cuda-opengl interop to copy from device to device, check creation of this Quad\"\n        w = w or self.W\n        h = h or self.H\n\n        old_fbo = gl.glGetIntegerv(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glReadBuffer(gl.GL_COLOR_ATTACHMENT0)\n\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, old_fbo)\n        gl.glBlitFramebuffer(x, y, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old_fbo)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        # Setup the framebuffer object (FBO) for the source and destination framebuffer\n        old_fbo = gl.glGetIntegerv(gl.GL_DRAW_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, self.fbo)\n\n        # Setup the source framebuffer object (FBO)\n        old_src_fbo = gl.glGetIntegerv(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old_fbo)\n\n        # Setup the destination framebuffer object (FBO)\n        old_dst_fbo = gl.glGetIntegerv(gl.GL_DRAW_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, self.fbo)\n\n        # Setup the source texture\n        gl.glFramebufferTexture2D(gl.GL_READ_FRAMEBUFFER, gl.GL_COLOR_ATTACHMENT0, gl.GL_TEXTURE_2D, self.tex, 0)\n\n        # Setup the destination texture\n        gl.glFramebufferTexture2D(gl.GL_DRAW_FRAMEBUFFER, gl.GL_COLOR_ATTACHMENT0, gl.GL_TEXTURE_2D, self.tex, 0)\n\n        # Setup the source and destination viewport\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        # Perform the pixel copy operation\n        gl.glBlitFramebuffer(0, 0, w, h,  # src\n                             0, 0, w, h,  # dst\n                             gl.GL_COLOR_BUFFER_BIT,\n                             gl.GL_NEAREST)\n\n        # Restore the previously bound read framebuffer\n        gl.glBindFramebuffer(gl.GL_"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        # gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        # gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)\n        # gl.glBlitFramebuffer(x, y, w, h, x, y, w, h, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        # gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, 0)\n\n        self.copy_to_texture(self.verts_data, x, y, w, h)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        if not hasattr(self, 'fbo'):\n            self.init_texture()\n\n        # Temporarily bind the Quad instance's framebuffer object (FBO) as the read framebuffer\n        old = gl.glGetIntegerv(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n\n        # Perform the pixel copy operation\n        gl.glBlitFramebuffer(x, y, w, h, x, y, w, h, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n\n        # Restore the previously bound read framebuffer\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        if not hasattr(self, 'fbo'):\n            self.init_texture()\n\n        # assert self.use_quad_cuda, \"Need to enable cuda-opengl interop to copy from device to device, check creation of this Quad\"\n        w = w or self.W\n        h = h or self.H\n\n        # gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(x, y, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        # gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old_fbo)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        # TODO: Check if this is necessary\n        # gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        # gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)\n\n        # If no width and height is specified, use the width and height of the Quad instance\n        w = w or self.W\n        h = h or self.H\n\n        # If no x and y coordinates are specified, use the x and y coordinates of the Quad instance\n        x = x or 0\n        y = y or 0\n\n        # Get the width and height of the current viewport\n        _, _, W, H = gl.glGetIntegerv(gl.GL_VIEWPORT)\n\n        # Temporarily set the viewport to the specified coordinates\n        gl.glViewport(x, y, w, h)\n\n        # Temporarily set the scissor box to the specified coordinates\n        gl.glScissor(x, y, w, h)\n\n        # Use the Quad instance's framebuffer object as the read framebuffer\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n\n        # Use the default framebuffer as the draw framebuffer\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)\n\n        # Blit the pixel block from the read framebuffer to the draw framebuffer\n        gl.glBlitFramebuffer(0, 0, w, h,  # src\n                             0, 0, w, h,  # dst\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n\n        # Restore the previous viewport and scissor box\n        gl.glViewport(0, 0, W, H)\n        gl.glScissor(0, 0, W, H)\n\n        # Restore the previously bound read framebuffer\n        # gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.f"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        if not hasattr(self, 'fbo'):\n            self.init_texture()\n\n        old_fbo = gl.glGetIntegerv(gl.GL_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)  # read buffer defaults to 0\n        gl.glBlitFramebuffer(x, y, w or self.W, h or self.H,\n                             x, y, w or self.W, h or self.H,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)  # now self.tex contains the content of the already rendered framebuffer\n        gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, old_fbo)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        if not hasattr(self, 'fbo'):\n            self.init_texture()\n\n        old_fbo = gl.glGetIntegerv(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n\n        w = w or self.W\n        h = h or self.H\n        gl.glBlitFramebuffer(x, y, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old_fbo)\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Sort the source times\n    t1, y1 = t1.sort()\n\n    # Get the indices for the target times in the source times\n    indices = searchsorted(t1, t0)\n\n    # Get the inner and outer measures\n    inner = y1[indices]\n    outer = y1[indices - 1]\n\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    t0 = t0.unsqueeze(-1)\n    t1 = t1.unsqueeze(-1)\n    y1 = y1.unsqueeze(-1)\n\n    inner = (t1 - t0) * y1\n    outer = y1\n\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # t1 = t1.to(t0.device)\n    # y1 = y1.to(t0.device)\n\n    t_diff = t1 - t0\n\n    # t_diff = t_diff.to(t0.device)\n\n    t_diff_abs = torch.abs(t_diff)\n\n    # t_diff_abs = t_diff_abs.to(t0.device)\n\n    t_diff_abs_cumsum = t_diff_abs.cumsum(0)\n\n    # t_diff_abs_cumsum = t_diff_abs_cumsum.to(t0.device)\n\n    y1_cumsum = y1.cumsum(0)\n\n    # y1_cumsum = y1_cumsum.to(t0.device)\n\n    t_diff_abs_cumsum_shifted = t_diff_abs_cumsum[1:]\n\n    # t_diff_abs_cumsum_shifted = t_diff_abs_cumsum_shifted.to(t0.device)\n\n    y1_cumsum_shifted = y1_cumsum[:-1]\n\n    # y1_cumsum_shifted = y1_cumsum_shifted.to(t0.device)\n\n    t_diff_abs_cumsum_shifted_clamped = t_diff_abs_cumsum_shifted.clamp(0, t_diff_abs.shape[0] - 1)\n\n    # t_diff_abs_cumsum_shifted_clamped = t_diff_abs_cumsum_shifted_clamped.to(t0.device)\n\n    y1_cumsum_shifted_clamped = y1_cumsum_shifted[t_diff_abs_cumsum_shifted_clamped]\n\n    # y1_cumsum_shifted_clamped = y1_cumsum_shifted_clamped.to(t"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Get the number of time steps\n    num_steps = t1.shape[0]\n\n    # Get the indices of the target times in the source times\n    indices = searchsorted(t1, t0)\n\n    # Get the cumulative sum of the values\n    cum_sum = y1.cumsum(dim=0)\n\n    # Get the inner measure\n    inner = cum_sum[indices]\n\n    # Get the outer measure\n    outer = cum_sum[indices - 1]\n\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # compute the cumulative sum for the source time (t1) and values (y1)\n    y1_cumsum = torch.cumsum(y1, dim=0)\n    # compute the inner measure for the target time (t0)\n    inner = torch.sum(y1_cumsum * (t0 >= t1).float(), dim=0)\n    # compute the outer measure for the target time (t0)\n    outer = torch.sum(y1_cumsum * (t0 > t1).float(), dim=0)\n\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Sorted indices for the target time (t0)\n    t0_idx = searchsorted(t1, t0)\n\n    # Sorted indices for the source time (t1)\n    t1_idx = torch.arange(t1.shape[0], dtype=t0_idx.dtype, device=t0_idx.device)\n\n    # Inner measure\n    inner = torch.zeros_like(t0, dtype=t1.dtype, device=t1.device)\n    inner[t0_idx] = y1[t1_idx]\n\n    # Outer measure\n    outer = torch.zeros_like(t0, dtype=t1.dtype, device=t1.device)\n    outer[t0_idx] = y1[t1_idx + 1]\n\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Sort the target time\n    t0_sorted, idx = torch.sort(t0)\n\n    # Sort the source time and values\n    t1_sorted, y1_sorted = torch.sort(t1)\n    y1 = y1[idx]\n\n    # Construct the inner measure\n    inner = torch.cumsum(y1_sorted, dim=0)\n\n    # Construct the outer measure\n    outer = torch.zeros_like(inner)\n    outer[1:] = inner[1:] - inner[:-1]\n\n    # Get the indices of the target times\n    idx = searchsorted(t1_sorted, t0_sorted)\n\n    # Get the values of the inner and outer measures\n    inner = inner[idx]\n    outer = outer[idx]\n\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # construct the inner measure\n    inner_measure = t0 - t1\n\n    # construct the outer measure\n    outer_measure = t0.unsqueeze(1) - t1.unsqueeze(0)\n\n    # construct the difference between target and source values\n    y_diff = y1.unsqueeze(1) - y1.unsqueeze(0)\n\n    return inner_measure, outer_measure, y_diff\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Compute the cumulative sum of the source values.\n    y1_cumsum = torch.cumsum(y1, dim=0)\n\n    # Compute the inner measure.\n    inner = torch.zeros_like(t0)\n    for i in range(t0.shape[0]):\n        inner[i] = y1_cumsum[torch.searchsorted(t1, t0[i])]\n\n    # Compute the outer measure.\n    outer = torch.zeros_like(t0)\n    for i in range(t0.shape[0]):\n        outer[i] = y1_cumsum[torch.searchsorted(t1, t0[i], right=True)] - inner[i]\n\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Sort the source time (t1) and values (y1)\n    t1, y1 = t1.sort()\n\n    # Get the index of the target time (t0) in the source time (t1)\n    t1_idx = searchsorted(t1, t0)\n\n    # Get the cumulative sum of the values associated with the source time (t1)\n    y1_cumsum = y1.cumsum(dim=0)\n\n    # Get the inner measure\n    inner = y1_cumsum[t1_idx]\n\n    # Get the outer measure\n    outer = y1_cumsum[t1_idx - 1]\n\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # sort the source times\n    t1_sorted, t1_sorted_idx = t1.sort()\n\n    # sort the target times\n    t0_sorted, t0_sorted_idx = t0.sort()\n\n    # get the cumulative sum of the source values\n    y1_cumsum = y1.cumsum(0)\n\n    # get the cumulative sum of the source times\n    t1_cumsum = t1.cumsum(0)\n\n    # get the cumulative sum of the target times\n    t0_cumsum = t0.cumsum(0)\n\n    # get the inner measure\n    inner = y1_cumsum[t1_sorted_idx] * (t1_sorted - t0_cumsum)\n\n    # get the outer measure\n    outer = y1_cumsum[t1_sorted_idx] * (t1_cumsum - t0_cumsum)\n\n    # return the inner and outer measures\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Interpolate the source values (y1) to the target times (t0)\n    y1_interp = F.interpolate(y1.unsqueeze(1), size=t0.shape, mode='linear', align_corners=True)\n\n    # Compute the inner measure\n    inner = t0 - t1\n\n    # Compute the outer measure\n    outer = t0.unsqueeze(1) - t1.unsqueeze(0)\n\n    return inner, outer, y1_interp\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # t0 = torch.as_tensor(t0, device=y1.device)\n    # t1 = torch.as_tensor(t1, device=y1.device)\n\n    # if t0.ndim != 1:\n    #     t0 = t0.flatten()\n    # if t1.ndim != 1:\n    #     t1 = t1.flatten()\n\n    # t0 = t0.to(y1.device)\n    # t1 = t1.to(y1.device)\n\n    t0 = t0.detach()\n    t1 = t1.detach()\n\n    # t1_is_t0 = (t1 == t0).float()\n    # t1_is_t0 = t1_is_t0.to(y1.device)\n\n    # t1_is_t0 = t1_is_t0.flatten()\n    # t0 = t0.flatten()\n    # t1 = t1.flatten()\n\n    # y1 = y1.flatten()\n\n    # t1_is_t0 = t1_is_t0.to(y1.device)\n    # t0 = t0.to(y1.device)\n    # t1 = t1.to(y1.device)\n    # y1 = y1.to(y1.device)\n\n    # t1_is_t0 = t1_is_t0.to(y1.device)\n    # t0 = t0.to(y1.device)\n    # t1 = t1.to(y1.device)\n    # y1 = y1.to(y1.device)\n\n    # t1_is_t0 = t1_is_t0.to(y1.device)\n    # t0 = t0.to(y1.device)\n    # t1 = t1.to(y1.device)\n    # y1 = y1.to(y1.device)\n\n    # t1_is_t0 ="}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # t1 = t1.squeeze()\n    # t0 = t0.squeeze()\n    # y1 = y1.squeeze()\n\n    # assert len(t1.shape) == 1\n    # assert len(t0.shape) == 1\n    # assert len(y1.shape) == 1\n\n    t1 = t1.squeeze()\n    t0 = t0.squeeze()\n    y1 = y1.squeeze()\n\n    assert len(t1.shape) == 1\n    assert len(t0.shape) == 1\n    assert len(y1.shape) == 1\n\n    assert t1.shape[0] == y1.shape[0]\n\n    t1 = t1.unsqueeze(1)\n    t0 = t0.unsqueeze(1)\n    y1 = y1.unsqueeze(1)\n\n    t1_max = t1.max()\n    t1_min = t1.min()\n\n    t0_max = t0.max()\n    t0_min = t0.min()\n\n    t1_outer = t1.clone()\n    t1_inner = t1.clone()\n    y1_outer = y1.clone()\n    y1_inner = y1.clone()\n\n    t1_outer[t1_outer < t0_min] = t0_min\n    t1_outer[t1_outer > t0_max] = t0_max\n    t1_outer = t1_outer.squeeze(1)\n    y1_outer = y1_outer.squeeze(1)\n\n    t1_inner[t1_inner > t0_min] = t0_min\n    t1_inner[t1_inner < t0_max] = t0_max\n    t1_inner = t1_inner.squeeze(1)\n    y1_inner = y1_inner.squeeze(1)\n\n    return"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Sort the target time\n    t0 = t0.sort()[0]\n\n    # Sort the source time\n    t1 = t1.sort()[0]\n\n    # Sort the source values\n    y1 = y1[t1.argsort()]\n\n    # Get the cumulative sum of the source values\n    y1_cumsum = y1.cumsum(dim=0)\n\n    # Get the cumulative sum of the source time\n    t1_cumsum = t1.cumsum(dim=0)\n\n    # Get the indices of the target time in the source time\n    t0_indices = searchsorted(t1, t0)\n\n    # Get the inner measure\n    inner = y1_cumsum[t0_indices]\n\n    # Get the outer measure\n    outer = y1[-1] - y1_cumsum[t0_indices - 1]\n\n    # Return the inner and outer measures\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # assert t1.ndim == 1\n    # assert t0.ndim == 1\n    # assert y1.ndim == 1\n    # assert t1.shape[0] == y1.shape[0]\n    # assert t0.shape[0] == 1\n    # assert t1.dtype == t0.dtype\n    # assert t1.dtype == y1.dtype\n\n    # t1 = t1.unsqueeze(0)\n    # t0 = t0.unsqueeze(1)\n    # y1 = y1.unsqueeze(1)\n\n    # inner = torch.exp(-((t1 - t0) ** 2) / (2 * sigma ** 2)) * y1\n    # outer = torch.exp(-((t1 ** 2) / (2 * sigma ** 2)))\n\n    # return inner, outer\n\n    t1 = t1.unsqueeze(0)\n    t0 = t0.unsqueeze(1)\n    y1 = y1.unsqueeze(1)\n\n    inner = torch.exp(-((t1 - t0) ** 2) / (2 * sigma ** 2)) * y1\n    outer = torch.exp(-((t1 ** 2) / (2 * sigma ** 2)))\n\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    t0, t1, y1 = t0.squeeze(), t1.squeeze(), y1.squeeze()\n    assert t0.ndim == t1.ndim == y1.ndim == 1, \"t0, t1, and y1 must be 1-dimensional.\"\n    assert t0.shape[0] == t1.shape[0] == y1.shape[0], \"t0, t1, and y1 must have the same length.\"\n    assert t0.min() >= t1.min(), \"t0 must be greater than or equal to t1.\"\n    assert t0.max() <= t1.max(), \"t0 must be less than or equal to t1.\"\n\n    t0 = t0.view(-1, 1)\n    t1 = t1.view(-1, 1)\n    y1 = y1.view(-1, 1)\n\n    t_diff = t1 - t0\n    t_diff_sort, t_diff_indices = t_diff.sort(dim=0)\n\n    y_sort = y1[t_diff_indices]\n\n    y_cumsum = y_sort.cumsum(dim=0)\n\n    y_cumsum_diff = y_cumsum[1:] - y_cumsum[:-1]\n\n    t_diff_cumsum = t_diff_sort.cumsum(dim=0)\n\n    t_diff_cumsum_diff = t_diff_cumsum[1:] - t_diff_cumsum[:-1]\n\n    y_cumsum_diff_div_tdiff_cumsum_diff = y_cumsum_diff / t_diff_cumsum_diff\n\n    inner_measure = y_cumsum_diff_div_tdiff_cumsum_diff * t_diff_sort\n\n    outer_measure = y_cumsum_diff_div_tdiff_cumsum_diff * t_diff_sort.flip(dims=(0,))\n\n    return inner_"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Find the indices where the target time (t0) is located relative to the source times (t1).\n    idx = searchsorted(t1, t0)\n    idx = torch.maximum(torch.zeros_like(idx), idx)\n    idx = torch.minimum(torch.ones_like(idx) * (t1.shape[0] - 1), idx)\n    idx = idx.type(torch.long)\n\n    # Construct the inner measure.\n    inner = y1[idx]\n\n    # Construct the outer measure.\n    outer = y1[idx + 1] if idx < t1.shape[0] - 1 else y1[idx]\n\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    t0 = t0.unsqueeze(1)\n    t1 = t1.unsqueeze(0)\n    y1 = y1.unsqueeze(0)\n\n    # Compute the cumulative sum of the values\n    c1 = torch.cumsum(y1, dim=0)\n\n    # Compute the inner measure\n    inner_measure = c1[torch.searchsorted(t1, t0), torch.arange(t0.size(1))]\n\n    # Compute the outer measure\n    outer_measure = c1[torch.searchsorted(t1, t0, right=True), torch.arange(t0.size(1))] - inner_measure\n\n    return inner_measure, outer_measure\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # TODO: check for correctness\n\n    t0 = t0.unsqueeze(-1)\n    t1 = t1.unsqueeze(-1)\n\n    y1 = y1.unsqueeze(-1)\n\n    inner = (t0 - t1) * y1\n    outer = (t0.max(t1)[0] - t0.min(t1)[0]) * y1.sum(-1)\n\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # calculate inner and outer measures\n    w_inner, w_outer = inner_outer(t, t_env, w_env)\n\n    # calculate loss\n    loss = (w - w_inner) ** 2 / (w_outer + eps)\n\n    return loss.mean()\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # calculate inner and outer measures\n    y0_inner, y0_outer = inner_outer(t, t_env, w_env)\n\n    # calculate loss\n    y0_outer = torch.maximum(y0_outer, eps)\n    loss = 0.5 * (y0_inner / y0_outer) ** 2\n\n    return loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # calculate the inner and outer measures\n    w_inner, w_outer = inner_outer(t, t_env, w_env)\n\n    # calculate the loss\n    loss = (w - w_inner) * (w - w_inner) / (w_outer + eps) + w_outer * (w_outer + eps) / 2\n\n    return loss.mean()\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # calculate the inner and outer measures\n    y0_inner, y0_outer = inner_outer(t, t_env, w_env)\n\n    # calculate the loss\n    loss = (y0_outer - y0_inner) ** 2\n    loss = (w * loss).sum(dim=-1)\n    loss = loss / (w_env.sum(dim=-1) + eps)\n    loss = loss.mean()\n\n    return loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # calculate the inner and outer measures\n    w_inner, w_outer = inner_outer(t, t_env, w_env)\n\n    # calculate the loss\n    loss = (w_outer - w_inner) ** 2\n    loss = torch.mean(loss)\n    return loss\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # calculate the inner and outer measures\n    y0_inner, y0_outer = inner_outer(t, t_env, w_env)\n\n    # calculate the loss\n    loss = 0.5 * (y0_outer - y0_inner) ** 2\n\n    # scale by the weights\n    loss = (w * loss).sum(dim=-1)\n\n    # prevent division by zero\n    loss = loss / (y0_outer ** 2 + eps)\n\n    return loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # calculate the inner and outer measures\n    y_inner, y_outer = inner_outer(t, t_env, w_env)\n\n    # calculate the loss\n    loss = (y_outer - y_inner) * (w - w_env)\n\n    # scale the loss\n    loss = torch.sum(loss, dim=-1)\n    loss = torch.mean(loss)\n\n    return loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # assert t.shape[-1] == w.shape[-1] + 1\n    # assert t_env.shape[-1] == w_env.shape[-1] + 1\n\n    # calculate the inner and outer weights\n    w_inner, w_outer = inner_outer(t, t_env, w_env)\n\n    # calculate the half-quadratic loss\n    loss = (w - w_inner) ** 2 / (w_outer + eps)\n\n    return loss\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # calculate inner and outer measures\n    y_inner, y_outer = inner_outer(t, t_env, w_env)\n\n    # calculate the loss\n    return (y_outer - y_inner).square().mean()\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # calculate inner and outer measures\n    y_inner, y_outer = inner_outer(t, t_env, w_env)\n    # calculate the loss\n    loss = (y_inner - w) ** 2 / (y_outer + eps) + w ** 2 / 2\n    return loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # calculate the inner and outer measures\n    y0_inner, y0_outer = inner_outer(t, t_env, w_env)\n\n    # calculate the loss\n    y0_outer = torch.where(y0_outer <= eps, torch.ones_like(y0_outer), y0_outer)\n    y0_inner = torch.where(y0_inner <= eps, torch.ones_like(y0_inner), y0_inner)\n    return 0.5 * (y0_inner / y0_outer) * (w - w_env) ** 2\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # calculate inner and outer measures\n    y_inner, y_outer = inner_outer(t, t_env, w_env)\n\n    # calculate loss\n    loss = 0.5 * (y_outer ** 2) + (y_inner ** 2)\n\n    # calculate scaled loss\n    scale = (w ** 2).sum(dim=-1, keepdim=True)\n    loss = loss.sum(dim=-1) / (scale + eps)\n\n    return loss\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # ensure that the input tensors are the same shape\n    assert t.shape == w.shape\n    assert t_env.shape == w_env.shape\n\n    # ensure that the input tensors are the correct shape\n    assert t.shape[-1] == w.shape[-1] + 1\n    assert t_env.shape[-1] == w_env.shape[-1] + 1\n\n    # ensure that the input tensors are the same length\n    assert t.shape[-1] == t_env.shape[-1]\n\n    # calculate the inner and outer measures\n    w_inner, w_outer = inner_outer(t, t_env, w_env)\n\n    # calculate the loss\n    loss = (w_outer - w_inner) ** 2 / (2 * (w + eps))\n\n    return loss.mean()\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    t_env, w_env = t_env.unsqueeze(0), w_env.unsqueeze(0)\n    t, w = t.unsqueeze(0), w.unsqueeze(0)\n    t_env, w_env = matchup_channels(t_env, w_env)\n    t, w = matchup_channels(t, w)\n\n    # calculate inner and outer weights\n    w_inner, w_outer = inner_outer(t, t_env, w_env)\n\n    # calculate loss\n    loss = (w_outer - w_inner) ** 2\n\n    # scale loss\n    loss = 0.5 * loss / (w ** 2 + eps)\n\n    # sum loss\n    loss = loss.sum(dim=-1)\n\n    return loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    y0_inner, y0_outer = inner_outer(t, t_env, w_env)\n\n    y0_inner, y0_outer = y0_inner.to(t.dtype), y0_outer.to(t.dtype)\n\n    y0_outer = y0_outer + eps\n    y0_inner = y0_inner + eps\n\n    loss = (w - y0_outer) ** 2 / 2 * y0_outer + w * torch.log(y0_outer) - (w - y0_inner) ** 2 / 2 * y0_inner - w * torch.log(y0_inner)\n\n    return loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    t = t.unsqueeze(-1)\n    w = w.unsqueeze(-1)\n    t_env = t_env.unsqueeze(-1)\n    w_env = w_env.unsqueeze(-1)\n\n    # ensure that the tensors are sorted\n    t_env, w_env = torch.sort(torch.cat([t_env, t], dim=-1), dim=-1)\n    t, w = torch.sort(torch.cat([t, t_env], dim=-1), dim=-1)\n    w_env = w_env[..., 1:]\n\n    # calculate the inner and outer measures\n    y_inner, y_outer = inner_outer(t, t_env, w_env)\n\n    # calculate the loss\n    loss = (y_inner - w) ** 2 / (y_outer + eps)\n    loss = loss[..., 1:-1]\n    loss = torch.sum(loss, dim=-1)\n\n    return loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # assert t.shape[-1] == w.shape[-1] + 1\n    # assert t_env.shape[-1] == w_env.shape[-1] + 1\n\n    # y_env = torch.cat([torch.zeros_like(w_env[..., :1]), torch.cumsum(w_env, dim=-1)], dim=-1)\n    # idx_lo, idx_hi = searchsorted(t_env, t)\n\n    # y_env_lo = torch.take_along_dim(y_env, idx_lo, dim=-1)\n    # y_env_hi = torch.take_along_dim(y_env, idx_hi, dim=-1)\n\n    # y_env_inner = torch.where(idx_hi[..., :-1] <= idx_lo[..., 1:], y_env_lo[..., 1:] - y_env_hi[..., :-1], 0)\n    # y_env_outer = y_env_hi[..., 1:] - y_env_lo[..., :-1]\n\n    # y_env_inner = torch.cat([y_env_inner[..., 0:1], y_env_inner], dim=-1)\n    # y_env_outer = torch.cat([y_env_outer[..., 0:1], y_env_outer], dim=-1)\n\n    # y_env_inner = y_env_inner.reshape(y_env_outer.shape)\n    # y_env_outer = y_env_outer.reshape(y_env_outer.shape)\n\n    # y_env_outer = torch.cat([y_env_outer[..., 0:1], y_env_outer], dim=-1)\n\n    # w_env_outer = torch.take_along_dim(w_env, idx_lo, dim=-1)\n    # w_env_inner = torch.where(idx_hi[..., :-1] <= idx_lo[..., 1:], w_env_lo[..., 1:]"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    y_inner, y_outer = inner_outer(t, t_env, w_env)\n    y_inner, y_outer = y_inner.detach(), y_outer.detach()\n\n    y_outer_l1 = torch.abs(y_outer)\n    y_inner_l1 = torch.abs(y_inner)\n\n    y_outer_l2 = y_outer ** 2\n    y_inner_l2 = y_inner ** 2\n\n    y_outer_huber = torch.where(y_outer < eps, eps * y_outer, eps * (y_outer ** 0.5))\n    y_inner_huber = torch.where(y_inner < eps, eps * y_inner, eps * (y_inner ** 0.5))\n\n    y_outer_ssim = torch.where(y_outer < eps, 1.0, torch.exp(-0.125 * y_outer))\n    y_inner_ssim = torch.where(y_inner < eps, 1.0, torch.exp(-0.125 * y_inner))\n\n    y_outer_ssimae = torch.abs(y_outer_ssim - 0.5)\n    y_inner_ssimae = torch.abs(y_inner_ssim - 0.5)\n\n    y_outer_slog = torch.where(y_outer < eps, eps * y_outer, torch.log(y_outer + eps))\n    y_inner_slog = torch.where(y_inner < eps, eps * y_inner, torch.log(y_inner + eps))\n\n    y_outer_si = torch.where(y_outer < eps, eps * y_outer, torch.log(y_outer + eps) / y_outer)\n    y_inner_si = torch.where(y_inner < eps, eps * y_inner, torch.log(y_inner +"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    y0_inner, y0_outer = inner_outer(t, t_env, w_env)\n    y0_outer = torch.clamp(y0_outer, min=eps)\n\n    return (w - y0_inner / y0_outer).square().mean()\n\n\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    t_env = t_env.unsqueeze(-1)\n    w_env = w_env.unsqueeze(-1)\n\n    t = t.unsqueeze(-2)\n    w = w.unsqueeze(-2)\n\n    y_inner, y_outer = inner_outer(t, t_env, w_env)\n\n    # ensure that the loss is always positive\n    # this is to prevent the loss from being negative when the upper envelope is smaller than the target\n    # this is especially important when the upper envelope is smaller than the target\n    # because the loss function is scaled by the difference between the target and the upper envelope\n    # the loss can be negative if the upper envelope is smaller than the target\n    # this is a problem because the loss function is then scaled by a negative number\n    # this is a problem because the loss function is then multiplied by a negative number\n    # this is a problem because the loss function is then added to the loss function\n    # this is a problem because the loss function is then subtracted from the loss function\n    # this is a problem because the loss function is then added to the loss function\n    # this is a problem because the loss function is then subtracted from the loss function\n    # this is a problem because the loss function is then added to the loss function\n    # this is a problem because the loss function is then subtracted from the loss function\n    # this is a problem because the loss function is then added to the loss function\n    # this is a problem because the loss function is then subtracted from the loss function\n    # this is a problem because the loss function is then added to the loss function\n    # this is a problem because the loss function is then subtracted from the loss function\n    # this is a problem because the loss function is then added to the loss function\n    # this is a problem because the loss function is then subtracted from the loss function\n    # this is a problem because the loss function is then added to the loss function\n    # this is a problem because the loss function is then subtracted from the loss function\n    # this is a problem because the loss function is then added to the loss function\n    # this is a problem because the"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    # accepts t.shape[-1] = w.shape[-1] + 1\n\n    # calculate the inter-interval loss\n    inter_interval_loss = (w[..., 1:] - w[..., :-1]).abs().mean()\n\n    # calculate the intra-interval loss\n    intra_interval_loss = (t[..., 1:] - t[..., :-1]).abs().mean()\n\n    # combine the inter-interval and intra-interval losses\n    distortion_loss = inter_interval_loss + intra_interval_loss\n\n    return distortion_loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    t_env, w_env = matchup_channels(t[..., 1:], w[..., 1:])\n\n    # inter-interval loss\n    inter_loss = lossfun_outer(t[..., 1:], w_env, t_env, w_env)\n\n    # intra-interval loss\n    intra_loss = lossfun_outer(t[..., :-1], w[..., :-1], t[..., :-1], w[..., :-1])\n\n    # total loss\n    dist_loss = inter_loss + intra_loss\n\n    return dist_loss.mean()\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    # accepts t.shape[-1] = w.shape[-1] + 1\n    t, w = matchup_channels(t, w)\n\n    # inter-interval loss\n    inter_loss = (w[..., 1:] - w[..., :-1]).abs().mean()\n\n    # intra-interval loss\n    intra_loss = (t[..., 1:] - t[..., :-1]).abs().mean()\n\n    return inter_loss + intra_loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    # accepts t.shape[-1] = w.shape[-1] + 1\n    t, w = matchup_channels(t, w)\n\n    # Compute the inter-interval loss\n    inter_loss = (w[..., 1:] - w[..., :-1]).pow(2).mean()\n\n    # Compute the intra-interval loss\n    intra_loss = (w[..., 1:] + w[..., :-1]).pow(2).mean()\n\n    # Combine the two losses\n    loss = inter_loss + intra_loss\n\n    return loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    # accepts t.shape[-1] = w.shape[-1] + 1\n    t, w = matchup_channels(t, w)\n    \"\"\"The proposal weight should be an upper envelope on the nerf weight.\"\"\"\n    y0_inner, y0_outer = inner_outer(t, t, w)\n\n    # Inter-interval loss\n    # We assume y0_inner <= y0_outer. We don't penalize y0_inner because it's\n    # more effective to pull y0_outer up than it is to push y0_inner down.\n    # Scaled half-quadratic loss that gives a constant gradient at y0_outer = 0.\n    loss_inter = (y0_outer - y0_inner).clip(0.).pow(2) / (y0_outer + 1e-6)\n\n    # Intra-interval loss\n    # We assume y0_inner <= y0_outer. We don't penalize y0_inner because it's\n    # more effective to pull y0_outer up than it is to push y0_inner down.\n    # Scaled half-quadratic loss that gives a constant gradient at y0_outer = 0.\n    loss_intra = (y0_outer - y0_inner).clip(0.).pow(2) / (y0_outer + 1e-6)\n\n    # Combine the inter-interval and intra-interval losses\n    loss = loss_inter + loss_intra\n\n    return loss.mean()\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    # accepts t.shape[-1] = w.shape[-1] + 1\n    t, w = matchup_channels(t, w)\n\n    # Calculate the inter-interval loss.\n    inter_loss = torch.abs(w[..., 1:] - w[..., :-1])\n\n    # Calculate the intra-interval loss.\n    intra_loss = torch.abs(w[..., 1:] - w[..., :-1])\n\n    # Combine the inter-interval and intra-interval losses.\n    distortion_loss = (inter_loss + intra_loss) / 2\n\n    return distortion_loss.mean()\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    # accepts t.shape[-1] = w.shape[-1] + 1\n    t, w = matchup_channels(t, w)\n\n    # calculate the inter-interval loss\n    t_inter, w_inter = inner_outer(t, t, w)\n    loss_inter = (w_inter * (t_inter[..., 1:] - t_inter[..., :-1])).mean()\n\n    # calculate the intra-interval loss\n    t_intra, w_intra = inner_outer(t, t[..., :-1], w[..., :-1])\n    loss_intra = (w_intra * (t_intra[..., 1:] - t_intra[..., :-1])).mean()\n\n    # combine the inter-interval and intra-interval losses\n    loss_distortion = loss_inter + loss_intra\n\n    return loss_distortion\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    # accepts t.shape[-1] = w.shape[-1] + 1\n    t, w = matchup_channels(t, w)\n    t_env, w_env = t[..., :-1], w[..., :-1]\n    t_env_next, w_env_next = t[..., 1:], w[..., 1:]\n\n    # compute the inter-interval loss\n    inter_loss = torch.abs(w_env - w_env_next)\n\n    # compute the intra-interval loss\n    intra_loss = torch.abs(w_env - w_env_next) * (t_env_next - t_env)\n\n    # combine the inter-interval and intra-interval losses\n    return (inter_loss + intra_loss).mean()\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    # accepts t.shape[-1] = w.shape[-1] + 1\n    t, w = matchup_channels(t, w)\n\n    # compute the inter-interval loss\n    inter_loss = torch.mean(torch.abs(w[..., 1:] - w[..., :-1]))\n\n    # compute the intra-interval loss\n    intra_loss = torch.mean(torch.abs(w[..., 1:] + w[..., :-1] - 2 * w[..., 1:-1]))\n\n    # combine the inter-interval and intra-interval losses\n    return inter_loss + intra_loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    t_env, w_env = t[..., :-1], w[..., :-1]\n    t_env_next, w_env_next = t[..., 1:], w[..., 1:]\n\n    # Calculate the inter-interval loss\n    inter_loss = lossfun_outer(t_env, w_env, w_env_next)\n    # Calculate the intra-interval loss\n    intra_loss = lossfun_outer(t_env, w_env, w_env)\n\n    # Combine the inter-interval and intra-interval losses\n    return inter_loss + intra_loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n\n    # calculate the inter-interval loss\n    t_outer, w_outer = inner_outer(t, t, w)\n    # calculate the intra-interval loss\n    t_inner, w_inner = inner_outer(t, t, w)\n    # calculate the total loss\n    return (w_outer.clamp_min(0.) * (t_outer - t_inner).pow(2) / (w_inner + 1e-6)).mean()\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    # accepts t.shape[-1] = w.shape[-1] + 1\n    t, w = matchup_channels(t, w)\n    t_ = t[..., 1:]\n    t_ = torch.cat([torch.zeros_like(t[..., :1]), t_], dim=-1)\n    w_ = w[..., 1:]\n    w_ = torch.cat([torch.zeros_like(w[..., :1]), w_], dim=-1)\n    w_ = torch.cat([w_[..., 1:], w_[..., :1]], dim=-1)\n\n    # inter-interval loss\n    inter_loss = torch.abs(t_[..., 1:] - t_[..., :-1] - (w_[..., 1:] + w_[..., :-1]) / 2)\n    inter_loss = torch.sum(inter_loss * w[..., :-1], dim=-1) / torch.sum(w[..., :-1], dim=-1)\n\n    # intra-interval loss\n    intra_loss = torch.abs(t_[..., 1:] - t_[..., :-1] - w_[..., 1:] / 2)\n    intra_loss = torch.sum(intra_loss * w[..., 1:], dim=-1) / torch.sum(w[..., 1:], dim=-1)\n\n    return inter_loss + intra_loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    # accepts t.shape[-1] = w.shape[-1] + 1\n    t, w = matchup_channels(t, w)\n    # Calculate the inter-interval loss\n    inter_loss = (w[..., 1:] - w[..., :-1]).pow(2).mean()\n    # Calculate the intra-interval loss\n    intra_loss = (w[..., 1:] + w[..., :-1]).pow(2).mean()\n    # Combine the inter-interval and intra-interval losses\n    total_loss = inter_loss + intra_loss\n\n    return total_loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    t_env, w_env = t[..., :-1], w[..., :-1]\n    t_next, w_next = t[..., 1:], w[..., 1:]\n\n    # compute the inner and outer weights\n    w_inner, w_outer = inner_outer(t_next, t_env, w_env)\n\n    # compute the inter-interval loss\n    loss_int = w_outer.pow(2) / (w_next + 1e-6)\n\n    # compute the intra-interval loss\n    loss_intra = w_inner.pow(2) / (w_next + 1e-6)\n\n    # combine the inter-interval and intra-interval losses\n    return (loss_int + loss_intra).mean()\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    # accepts t.shape[-1] = w.shape[-1] + 1\n    t, w = matchup_channels(t, w)\n    t_env, w_env = t[..., 1:-1], w[..., 1:-1]\n    t_lo, t_hi = t[..., :-1], t[..., 1:]\n    w_lo, w_hi = w[..., :-1], w[..., 1:]\n\n    # calculate the intra-interval loss\n    intra_loss = (w_lo * (t_lo - t_env).pow(2) / (t_lo + 1e-10)).sum(-1)\n    # calculate the inter-interval loss\n    inter_loss = (w_env * (t_env - t_hi).pow(2) / (t_hi + 1e-10)).sum(-1)\n\n    # combine the inter-interval and intra-interval losses\n    return (intra_loss + inter_loss).mean()\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    # accepts t.shape[-1] = w.shape[-1] + 1\n    t, w = matchup_channels(t, w)\n\n    # Inter-interval loss\n    # The inter-interval loss is computed for each interval in the target tensor.\n    # The inter-interval loss is calculated as the difference between the\n    # cumulative sum of the weights in the interval and the cumulative sum of\n    # the weights in the environment tensor.\n    t_env, w_env = matchup_channels(t[..., 1:-1], w[..., 1:-1])\n    _, w_outer = inner_outer(t[..., 1:-1], t_env, w_env)\n    w_outer = torch.cat([torch.zeros_like(w_outer[..., :1]), w_outer], dim=-1)\n    inter_loss = (w_outer - w[..., 1:-1]).clip(0.).pow(2) / (w_env + 1e-6)\n\n    # Intra-interval loss\n    # The intra-interval loss is computed for each interval in the target tensor.\n    # The intra-interval loss is calculated as the difference between the\n    # cumulative sum of the weights in the interval and the cumulative sum of\n    # the weights in the environment tensor.\n    t_env, w_env = matchup_channels(t[..., :-2], w[..., :-2])\n    _, w_inner = inner_outer(t[..., :-2], t_env, w_env)\n    w_inner = torch.cat([w_inner, torch.zeros_like(w_inner[..., -1:])], dim=-1)\n    intra_loss = (w_inner - w[..., :-2]).clip(0.).pow(2) / (w_env + 1e-6)\n\n    # Combine inter-interval and intra-interval losses\n    # The combined loss is the sum of the inter-interval and intra-interval losses.\n    loss = inter_loss + intra_loss\n\n    return loss.mean()\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    # accepts t.shape[-1] = w.shape[-1] + 1\n    t, w = matchup_channels(t, w)\n\n    # Compute the inter-interval loss\n    # Compute the difference between adjacent weights\n    w_diff = torch.diff(w, dim=-1)\n    # Compute the squared difference between adjacent weights\n    w_diff_sq = w_diff.pow(2)\n    # Compute the cumulative sum of the squared difference between adjacent weights\n    w_diff_cumsum = torch.cumsum(w_diff_sq, dim=-1)\n    # Compute the difference between adjacent targets\n    t_diff = torch.diff(t, dim=-1)\n    # Compute the squared difference between adjacent targets\n    t_diff_sq = t_diff.pow(2)\n    # Compute the cumulative sum of the squared difference between adjacent targets\n    t_diff_cumsum = torch.cumsum(t_diff_sq, dim=-1)\n    # Compute the inter-interval loss\n    loss_intra = t_diff_cumsum / (w_diff_cumsum + 1e-10)\n    # Compute the intra-interval loss\n    loss_inter = t_diff_sq / (w_diff + 1e-10)\n    # Combine both inter-interval and intra-interval losses\n    loss_distortion = loss_intra + loss_inter\n\n    return loss_distortion.mean()\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    # accepts t.shape[-1] = w.shape[-1] + 1\n    # Inter-interval loss\n    # The inter-interval loss is calculated for each pair of consecutive intervals in the target tensor.\n    # The loss is calculated by taking the difference between the target values in the two intervals and multiplying it by the corresponding weight.\n    # The loss is then summed over all intervals to produce the inter-interval loss.\n    inter_interval_loss = torch.sum(torch.abs(t[..., 1:] - t[..., :-1]) * w[..., :-1])\n\n    # Intra-interval loss\n    # The intra-interval loss is calculated for each interval in the target tensor.\n    # The loss is calculated by taking the difference between the target values in the interval and multiplying it by the corresponding weight.\n    # The loss is then summed over all intervals to produce the intra-interval loss.\n    intra_interval_loss = torch.sum(torch.abs(t[..., 1:] - t[..., :-1]) * w[..., 1:])\n\n    # Total distortion loss\n    # The total distortion loss is the sum of the inter-interval and intra-interval loss.\n    distortion_loss = inter_interval_loss + intra_interval_loss\n\n    return distortion_loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    # accepts t.shape[-1] = w.shape[-1] + 1\n    t, w = matchup_channels(t, w)\n    t_env, w_env = matchup_channels(t[..., :-1], w[..., :-1])\n\n    # get the inner and outer weights\n    y0_inner, y0_outer = inner_outer(t, t_env, w_env)\n\n    # compute the inter-interval loss\n    y_inner = y0_inner[..., 1:] - y0_inner[..., :-1]\n    y_outer = y0_outer[..., 1:] - y0_outer[..., :-1]\n    loss_inter_int = torch.mean(torch.abs(y_outer - y_inner))\n\n    # compute the intra-interval loss\n    y0_inner_diff = y0_inner[..., 1:] - y0_inner[..., :-1]\n    y0_outer_diff = y0_outer[..., 1:] - y0_outer[..., :-1]\n    y0_inner_diff_abs = torch.abs(y0_inner_diff)\n    y0_outer_diff_abs = torch.abs(y0_outer_diff)\n    y0_inner_diff_sign = torch.sign(y0_inner_diff)\n    y0_outer_diff_sign = torch.sign(y0_outer_diff)\n\n    # calculate the intra-interval loss\n    loss_intra_int = torch.mean(y0_inner_diff_abs * y0_outer_diff_sign +\n                                y0_outer_diff_abs * y0_inner_diff_sign)\n\n    # return the combined loss\n    return loss_inter_int + loss_intra_int\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    t_lo, t_hi = inner_outer(t, t, w)\n\n    # Inter-interval loss\n    # The inter-interval loss is the sum of the square differences between the\n    # upper and lower envelope values.\n    inter_loss = (t_hi - t_lo).pow(2)\n\n    # Intra-interval loss\n    # The intra-interval loss is the sum of the square differences between the\n    # weighted average of the upper envelope and the weighted average of the\n    # lower envelope.\n    intra_loss = (t_lo * (w_lo / w).clamp(0., 1.) + t_hi * (w_hi / w).clamp(0., 1.) - t).pow(2)\n\n    # Total loss\n    # The total loss is the sum of the inter-interval and intra-interval losses.\n    return (inter_loss + intra_loss).mean()\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(torch.tensor(ps).to(t.device), cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(ps, cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    w = integrate_weights(w)\n    return interpolate(torch.tensor(ps).to(t.device), w, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(torch.tensor(ps).to(t.device), cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n\n    w = integrate_weights(w)\n\n    ps = torch.tensor(ps, dtype=t.dtype, device=t.device)\n\n    return interpolate(ps, w, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(ps, cw[..., :-1], t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    p = torch.tensor(ps)\n    return interpolate(p, cw[..., :-1], t[..., :-1])\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(torch.tensor(ps, device=t.device).unsqueeze(-1), cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    p = torch.tensor(ps)\n    return interpolate(p[..., None], cw[..., :-1], t[..., :-1])\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    w = integrate_weights(w)\n    ps = torch.tensor(ps)\n    return interpolate(ps, w[..., :-1], w[..., :-1])\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(ps, cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(ps, cw[..., :-1], t[..., :-1])\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw0 = integrate_weights(w)\n    pts = torch.tensor(ps, device=t.device)\n    return interpolate(pts, cw0, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n\n    cw0 = integrate_weights(w)\n\n    cw = interpolate(torch.tensor(ps).float(), cw0, cw)\n\n    return interpolate(cw, cw0, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(torch.tensor(ps).to(t.device), cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n\n    cw0 = integrate_weights(w)\n\n    ps = torch.tensor(ps, dtype=t.dtype, device=t.device)\n\n    return interpolate(ps, cw0, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n\n    cw = integrate_weights(w)\n    cw = cw.to(t.dtype)\n    cw = cw.to(t.device)\n\n    ps = torch.tensor(ps, dtype=t.dtype, device=t.device)\n    ps = ps.unsqueeze(-1)\n    ps = ps.expand(ps.shape[:-1] + (t.shape[-1],))\n\n    return interpolate(ps, cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n\n    cw = integrate_weights(w)\n    cw0 = cw[..., :-1]\n    cw1 = cw[..., 1:]\n    t0 = t[..., :-1]\n    t1 = t[..., 1:]\n\n    p0 = torch.tensor(ps, dtype=t.dtype, device=t.device)\n    p1 = torch.tensor(ps, dtype=t.dtype, device=t.device)\n    p0 = p0.unsqueeze(-1)\n    p1 = p1.unsqueeze(-1)\n\n    cw0_p0 = cw0 * p0\n    cw0_p1 = cw0 * p1\n    cw1_p0 = cw1 * p0\n    cw1_p1 = cw1 * p1\n\n    cw0_p0_cw1_p1 = cw0_p0 + cw1_p1\n    cw0_p1_cw1_p0 = cw0_p1 + cw1_p0\n\n    t0_cw0_p0 = t0 * cw0_p0\n    t0_cw0_p1 = t0 * cw0_p1\n    t1_cw1_p0 = t1 * cw1_p0\n    t1_cw1_p1 = t1 * cw1_p1\n\n    t0_cw0_p0_t1_cw1_p1 = t0_cw0_p0 + t1_cw1_p1\n    t0_cw0_p1_t1_cw1_p0 = t0_cw0_p1 + t1_cw1_p0\n\n    t0_cw0_p0_t1_cw1_p1_cw0_p1_t1_cw1_p0 = t0_cw0_p0_t1_"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    w = integrate_weights(w)\n    return interpolate(torch.tensor(ps).to(w), w, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n\n    w = integrate_weights(w)\n\n    ps = torch.tensor(ps, device=w.device)\n    p = (ps * (w.shape[-1] - 1)).long()\n    p = torch.clamp(p, 0, w.shape[-1] - 1)\n\n    return interpolate(ps, w[..., p], t[..., p])\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n\n    # Generate uniform samples.\n    u = torch.rand(num_samples, *w.shape[:-1], device=w.device)\n\n    # Invert the CDF to get the samples.\n    t_new = invert_cdf(u, t, w)\n\n    # Perturb the samples.\n    if perturb:\n        if single_jitter:\n            jitter = torch.rand_like(t_new)\n        else:\n            jitter = torch.rand(num_samples, *w.shape[:-1], device=w.device)\n        t_new += jitter\n\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n    t = t.flatten()\n    w = w.flatten()\n\n    # Compute the PDF and CDF for each weight vector.\n    cw = integrate_weights(w)\n    # Generate uniform samples from the unit interval.\n    u = torch.rand(num_samples, device=t.device)\n    # Invert the CDF to get the samples.\n    t_new = invert_cdf(u, t, w)\n\n    if perturb:\n        # Perturb the samples to avoid sample clustering at bin boundaries.\n        if single_jitter:\n            # Apply the same jitter to every sample along each dimension.\n            jitter = torch.rand(num_samples, device=t.device)\n            t_new = t_new + jitter\n        else:\n            # Apply independent jitter to each sample.\n            jitter = torch.rand(num_samples, t.shape[-1], device=t.device)\n            t_new = t_new + jitter\n\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Ensure that t and w have the same number of dimensions\n    t, w = matchup_channels(t, w)\n\n    # Ensure that the weights sum to 1\n    w = w / torch.sum(w, dim=-1, keepdim=True)\n\n    # Ensure that t is sorted\n    t = torch.sort(t, dim=-1)[0]\n\n    # Compute the CDF\n    cw = integrate_weights(w)\n\n    # Generate uniform samples\n    u = torch.rand(num_samples, *t.shape[:-1], device=t.device)\n\n    # Perturb the uniform samples\n    if perturb:\n        if single_jitter:\n            u = u + torch.rand(1, device=t.device) / num_samples\n        else:\n            u = u + torch.rand(num_samples, device=t.device) / num_samples\n\n    # Invert the CDF\n    t_new = invert_cdf(u, t, w)\n\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # matchup channel dimension\n    t, w = matchup_channels(t, w)\n\n    # initialize samples\n    u = torch.rand(num_samples, dtype=t.dtype, device=t.device)\n\n    # apply perturbation\n    if perturb:\n        if single_jitter:\n            u = u + torch.rand(num_samples, dtype=t.dtype, device=t.device) / num_samples\n        else:\n            u = u + torch.rand(num_samples, num_samples, dtype=t.dtype, device=t.device) / num_samples\n\n    # generate samples\n    t_new = invert_cdf(u, t, w)\n\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Compute the PDF and CDF for each weight vector.\n    cw = integrate_weights(w)\n\n    # Generate uniform samples from the unit interval.\n    u = torch.rand(num_samples, device=t.device)\n\n    # Invert the CDF to get the samples.\n    t_new = invert_cdf(u, t, w)\n\n    # Perturb the samples if requested.\n    if perturb:\n        # Compute the PDF and CDF for each weight vector.\n        cw = integrate_weights(w)\n\n        # Generate uniform samples from the unit interval.\n        u = torch.rand(num_samples, device=t.device)\n\n        # Invert the CDF to get the samples.\n        t_new_perturb = invert_cdf(u, t, w)\n\n        # Apply perturbation to the samples.\n        if single_jitter:\n            t_new += (t_new_perturb - t_new) * torch.randn(1, device=t.device)\n        else:\n            t_new += (t_new_perturb - t_new) * torch.randn(t_new.shape, device=t.device)\n\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n    # Compute the CDF for each weight vector.\n    cw = integrate_weights(w)\n    # Generate uniform samples over the unit interval.\n    u = torch.rand(num_samples, dtype=t.dtype, device=t.device)\n    # Invert the CDF to get the samples.\n    t_new = invert_cdf(u, t, w)\n    # Perturb the samples if requested.\n    if perturb:\n        # Generate random perturbations uniformly distributed over the unit interval.\n        epsilon = torch.rand_like(t_new) if single_jitter else torch.rand(num_samples, t.shape[-1], dtype=t.dtype, device=t.device)\n        # Perturb the samples.\n        t_new += epsilon\n    # Clip the samples to the domain of the PDF.\n    t_new = torch.clamp(t_new, t[0], t[-1])\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n    # Compute the PDF and CDF for each weight vector.\n    cw = integrate_weights(w)\n    # Generate uniform samples.\n    u = torch.rand(num_samples, device=t.device)\n    # Invert the CDF to get the samples.\n    t_new = invert_cdf(u, t, w)\n    # Perturb the samples if requested.\n    if perturb:\n        if single_jitter:\n            # Apply a single jitter to every sample along each dimension.\n            t_new = t_new + (torch.rand(num_samples, device=t.device) - 0.5) * (t[..., 1:] - t[..., :-1])\n        else:\n            # Apply a different jitter to every sample along each dimension.\n            t_new = t_new + (torch.rand(num_samples, device=t.device) - 0.5) * (t[..., 1:] - t[..., :-1])[..., None]\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Check if inputs are tensors.\n    if not torch.is_tensor(t):\n        raise TypeError('Input t must be a torch.Tensor.')\n    if not torch.is_tensor(w):\n        raise TypeError('Input w must be a torch.Tensor.')\n\n    # Check if inputs are one-dimensional.\n    if len(t.shape) != 1:\n        raise ValueError('Input t must be one-dimensional.')\n    if len(w.shape) != 1:\n        raise ValueError('Input w must be one-dimensional.')\n\n    # Check if inputs are the same size.\n    if t.shape[-1] != w.shape[-1]:\n        raise ValueError('Input tensors t and w must be the same size.')\n\n    # Check if inputs are non-empty.\n    if t.nelement() == 0:\n        raise ValueError('Input tensors t and w must be non-empty.')\n    if w.nelement() == 0:\n        raise ValueError('Input tensors t and w must be non-empty.')\n\n    # Check if inputs are non-negative.\n    if torch.any(t < 0):\n        raise ValueError('Input t must be non-negative.')\n    if torch.any(w < 0):\n        raise ValueError('Input w must be non-negative.')\n\n    # Check if inputs are non-zero.\n    if torch.any(t == 0):\n        raise ValueError('Input t must be non-zero.')\n    if torch.any(w == 0):\n        raise ValueError('Input w must be non-zero.')\n\n    # Check if number of samples is valid.\n    if num_samples <= 0:\n        raise ValueError('Number of samples must be positive.')\n\n    # Check if perturbation is valid.\n    if not isinstance(perturb, bool):\n        raise TypeError('Input perturb must be a bool.')\n\n    # Check if jittering is valid.\n    if not isinstance(single_jitter, bool):\n        raise TypeError('Input"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Check inputs\n    assert t.ndim == 1, \"t must be 1-dimensional.\"\n    assert w.ndim == 1, \"w must be 1-dimensional.\"\n    assert t.shape[-1] == w.shape[-1], \"t and w must have the same number of elements.\"\n    assert num_samples > 0, \"num_samples must be greater than zero.\"\n\n    # Compute the CDF\n    cw = integrate_weights(w)\n\n    # Generate random numbers in [0, 1)\n    u = torch.rand(num_samples, device=t.device)\n\n    # Invert the CDF\n    t_new = invert_cdf(u, t, w)\n\n    # Optionally apply jitter\n    if perturb:\n        if single_jitter:\n            # Generate random numbers in [0, 1)\n            v = torch.rand(num_samples, device=t.device)\n            # Add jitter to the samples\n            t_new += v\n        else:\n            # Generate random numbers in [0, 1)\n            v = torch.rand(num_samples, t.shape[-1], device=t.device)\n            # Add jitter to the samples\n            t_new += v\n\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # If the input tensors are not on the same device, move them to the same device.\n    t, w = matchup_channels(t, w)\n    # If the input tensors are not on the same device, move them to the same device.\n    if t.device != w.device:\n        t = t.to(w.device)\n\n    # If the number of samples is less than the number of bins, raise an error.\n    if num_samples < t.shape[-1]:\n        raise ValueError('The number of samples must be at least the number of bins.')\n\n    # If the number of samples is greater than the number of bins, raise a warning.\n    if num_samples > t.shape[-1]:\n        print('The number of samples is greater than the number of bins.')\n\n    # If the input tensors are not the same shape, raise an error.\n    if t.shape != w.shape:\n        raise ValueError('The input tensors must be the same shape.')\n\n    # If the input tensors are not 1D, raise an error.\n    if len(t.shape) != 1:\n        raise ValueError('The input tensors must be 1D.')\n\n    # If the input tensors are not on the same device, raise an error.\n    if t.device != w.device:\n        raise ValueError('The input tensors must be on the same device.')\n\n    # If the input tensors are not on the same dtype, raise an error.\n    if t.dtype != w.dtype:\n        raise ValueError('The input tensors must be on the same dtype.')\n\n    # If the input tensors are not on the same dtype, raise an error.\n    if t.dtype != torch.float32:\n        raise ValueError('The input tensors must be torch.float32.')\n\n    # If the input tensors are not on the same dtype, raise an error.\n    if not t.requires_grad:\n        raise ValueError('The input tensors must be differentiable.')\n\n    # If the input tensors"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Checks\n    assert t.ndim == 1\n    assert t.shape[-1] >= 2\n    assert t.shape == w.shape\n    assert num_samples >= 1\n    assert perturb is False or perturb is True\n    assert single_jitter is False or single_jitter is True\n\n    # Reshape tensors to be compatible with vmap\n    t = t.reshape([-1, t.shape[-1]])\n    w = w.reshape([-1, w.shape[-1]])\n\n    # Generate samples\n    u = torch.rand(num_samples, dtype=t.dtype, device=t.device)\n    u = u.reshape([-1, num_samples])\n    t_new = invert_cdf(u, t, w)\n\n    # Apply perturbation\n    if perturb:\n        if single_jitter:\n            t_new += torch.rand_like(t_new) / num_samples\n        else:\n            t_new += torch.rand_like(t_new) / num_samples\n            t_new = t_new.reshape([-1, num_samples])\n            t_new = t_new.permute([1, 0])\n            t_new = t_new.reshape([-1, ])\n\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Validate input arguments\n    assert t.ndim == 1\n    assert w.ndim == 1\n    assert t.shape[0] == w.shape[0]\n    assert num_samples > 0\n\n    # Compute the CDF from the PDF\n    cw = integrate_weights(w)\n\n    # Generate uniform samples from the unit interval\n    u = torch.rand(num_samples, device=t.device)\n\n    # Invert the CDF to obtain the samples\n    t_new = interpolate(u, cw, t)\n\n    if perturb:\n        # Perturb the samples to avoid sample clustering at bin boundaries\n        if single_jitter:\n            # Perturb each sample in each dimension\n            jitter = torch.rand_like(t_new)\n        else:\n            # Perturb each sample in a different dimension\n            jitter = torch.rand_like(t_new[0])\n            jitter = jitter.unsqueeze(0).expand(num_samples, -1)\n        t_new += jitter\n\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Matchup the shapes of t and w.\n    t, w = matchup_channels(t, w)\n\n    # Compute the cumulative sum of w, assuming all weight vectors sum to 1.\n    cw = integrate_weights(w)\n\n    # Generate uniform samples in [0, 1).\n    u = torch.rand(num_samples, dtype=t.dtype, device=t.device)\n\n    # If perturb is True, apply perturbation to the sampling process to avoid sample clustering at bin boundaries.\n    if perturb:\n        # Generate uniform samples in [0, 1).\n        v = torch.rand(num_samples, dtype=t.dtype, device=t.device)\n        # If single_jitter is True, apply the same jitter to every sample along each dimension. If False, apply independent jitter to each sample.\n        if single_jitter:\n            v = v + torch.rand(1, dtype=t.dtype, device=t.device)\n        else:\n            v = v + torch.rand(num_samples, dtype=t.dtype, device=t.device)\n        # Normalize the perturbation values to [0, 1).\n        v = v - torch.min(v)\n        v = v / torch.max(v)\n        # Invert the CDF to map the perturbation values back to the original uniform distribution.\n        u = u + v\n        # Normalize the perturbation values to [0, 1).\n        u = u - torch.min(u)\n        u = u / torch.max(u)\n\n    # Interpolate into the integrated weights according to u.\n    t_new = interpolate(u, cw, t)\n\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Check that the input tensors have the correct shape.\n    if t.ndim != 1:\n        raise ValueError(f\"t must be 1-dimensional, not {t.ndim}-dimensional.\")\n    if w.ndim != 1:\n        raise ValueError(f\"w must be 1-dimensional, not {w.ndim}-dimensional.\")\n    if t.shape != w.shape:\n        raise ValueError(f\"t and w must have the same shape, not {t.shape} and {w.shape}.\")\n    if num_samples <= 0:\n        raise ValueError(f\"num_samples must be positive, not {num_samples}.\")\n\n    # Ensure that the tensors are on the same device.\n    if t.device != w.device:\n        raise ValueError(f\"t and w must be on the same device, not {t.device} and {w.device}.\")\n\n    # Compute the CDF of the PDF.\n    cw = integrate_weights(w)\n\n    # Generate uniform random samples in [0, 1).\n    u = torch.rand(num_samples, device=t.device)\n\n    # Invert the CDF to get samples from the PDF.\n    t_new = invert_cdf(u, t, w)\n\n    # If requested, apply perturbation to the samples.\n    if perturb:\n        if single_jitter:\n            # Apply the same jitter to every sample along each dimension.\n            jitter = torch.rand(num_samples, device=t.device)\n            t_new += jitter * (t[1:] - t[:-1])\n        else:\n            # Apply independent jitter to each sample along each dimension.\n            jitter = torch.rand(num_samples, t.shape[-1], device=t.device)\n            t_new += jitter * (t[1:] - t[:-1])\n\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Match up the dimensions of the tensors.\n    t, w = matchup_channels(t, w)\n\n    # Compute the PDF and CDF for each weight vector.\n    cw = integrate_weights(w)\n    cw = cw.reshape(cw.shape[:-1] + (cw.shape[-1] + 1,))\n    cdf = torch.cat([cw[..., 0:1], cw[..., 1:] + cw[..., :-1]], dim=-1)\n\n    # Generate uniform samples from [0, 1).\n    u = torch.rand(num_samples, device=t.device)\n\n    # Invert the CDF to get the samples.\n    if perturb:\n        # Add a small amount of uniform noise to each sample to avoid sample clustering at bin boundaries.\n        if single_jitter:\n            # Add the same amount of noise to every sample along each dimension.\n            u = u + torch.rand(num_samples, device=t.device) / num_samples\n        else:\n            # Add independent noise to each sample along each dimension.\n            u = u + torch.rand_like(u)\n    t_new = invert_cdf(u, t, w)\n\n    # Return the samples.\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Ensure t and w are the same shape.\n    t, w = matchup_channels(t, w)\n\n    # Ensure t is one-dimensional.\n    if t.ndim > 1:\n        t = t.squeeze()\n\n    # Ensure t and w are the same shape.\n    if t.shape != w.shape:\n        raise ValueError(\"t and w must be the same shape.\")\n\n    # Ensure t is sorted.\n    if not torch.all(t[..., 1:] >= t[..., :-1]):\n        raise ValueError(\"t must be sorted.\")\n\n    # Ensure that w sums to 1 along the last dimension.\n    if not torch.allclose(torch.sum(w, dim=-1), torch.ones_like(w[..., 0])):\n        raise ValueError(\"w must sum to 1 along the last dimension.\")\n\n    # Ensure that the number of samples is positive.\n    if num_samples <= 0:\n        raise ValueError(\"num_samples must be positive.\")\n\n    # Ensure perturb is boolean.\n    if not isinstance(perturb, bool):\n        raise TypeError(\"perturb must be boolean.\")\n\n    # Ensure single_jitter is boolean.\n    if not isinstance(single_jitter, bool):\n        raise TypeError(\"single_jitter must be boolean.\")\n\n    # Compute the CDF of the PDF.\n    cw = integrate_weights(w)\n\n    # Compute the PDF of the PDF.\n    pdf = w / cw\n\n    # Ensure that the PDF integrates to 1.\n    if not torch.allclose(torch.sum(pdf, dim=-1), torch.ones_like(pdf[..., 0])):\n        raise ValueError(\"PDF must integrate to 1.\")\n\n    # Compute the CDF of the PDF.\n    cw = integrate_weights(w)\n\n    # Compute the PDF of the PDF.\n    pdf = w / cw\n\n    # Ensure that the PDF integrates to 1.\n    if not tor"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Check if the weights sum to 1.\n    assert torch.allclose(w.sum(dim=-1), torch.ones_like(w.sum(dim=-1)))\n\n    # Check if the input tensors have the correct shape.\n    assert t.ndim == w.ndim + 1\n\n    # Check if the input tensors are sorted.\n    assert torch.all(t[..., 1:] > t[..., :-1])\n\n    # Check if the input tensors have the same shape.\n    assert t.shape == w.shape\n\n    # Check if the number of samples is positive.\n    assert num_samples > 0\n\n    # Check if the perturbation flag is valid.\n    assert isinstance(perturb, bool)\n\n    # Check if the jitter flag is valid.\n    assert isinstance(single_jitter, bool)\n\n    # Create a tensor of uniform random samples.\n    u = torch.rand(num_samples, dtype=t.dtype, device=t.device)\n\n    # Invert the CDF to generate samples.\n    t_new = invert_cdf(u, t, w)\n\n    # Perturb the samples.\n    if perturb:\n        if single_jitter:\n            jitter = torch.rand_like(t_new)\n        else:\n            jitter = torch.rand(t_new.shape, dtype=t.dtype, device=t.device)\n        t_new += jitter\n\n    # Return the samples.\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # check input arguments\n    if not isinstance(num_samples, int):\n        raise TypeError('num_samples must be an integer.')\n    if num_samples <= 0:\n        raise ValueError('num_samples must be greater than 0.')\n    if not isinstance(t, torch.Tensor):\n        raise TypeError('t must be a torch.Tensor.')\n    if not isinstance(w, torch.Tensor):\n        raise TypeError('w must be a torch.Tensor.')\n    if not t.ndim == 1:\n        raise ValueError('t must be a 1D tensor.')\n    if not w.ndim == 1:\n        raise ValueError('w must be a 1D tensor.')\n    if not t.shape[0] == w.shape[0]:\n        raise ValueError('t and w must have the same number of elements.')\n    if not (t[1:] >= t[:-1]).all():\n        raise ValueError('t must be monotonically increasing.')\n    if not (w >= 0).all():\n        raise ValueError('w must be non-negative.')\n    if not (w <= 1).all():\n        raise ValueError('w must be less than or equal to 1.')\n    if not isinstance(perturb, bool):\n        raise TypeError('perturb must be a bool.')\n    if not isinstance(single_jitter, bool):\n        raise TypeError('single_jitter must be a bool.')\n\n    # check if w sums to 1\n    if not torch.allclose(w.sum(), torch.tensor(1.)):\n        w = w / w.sum()\n\n    # create a uniform random sample\n    u = torch.rand(num_samples, dtype=t.dtype, device=t.device)\n\n    # get the indices of the bins to which the samples belong\n    idx_lo, idx_hi = searchsorted(t, u)\n\n    # get the indices of the bins to which the samples belong\n    idx_lo, idx_hi = searchsorted(t, u)"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Ensure that t is a 2D tensor.\n    assert t.ndim == 2\n    # Ensure that t is sorted.\n    assert torch.all(t[:, 1:] >= t[:, :-1])\n    # Ensure that w is a 2D tensor.\n    assert w.ndim == 2\n    # Ensure that the number of samples is positive.\n    assert num_samples > 0\n    # Ensure that the number of samples is less than the number of bins.\n    assert num_samples < t.shape[0]\n    # Ensure that the number of samples is less than the number of bins.\n    assert num_samples < w.shape[0]\n\n    # Compute the CDF of the PDF.\n    cw = integrate_weights(w)\n    # Compute the inverse CDF of the PDF.\n    u = torch.rand(num_samples, device=t.device)\n    t_new = invert_cdf(u, t, cw)\n    # Compute the bin index for each sample.\n    idx_lo, idx_hi = searchsorted(t, t_new)\n    # Compute the distance from the lower bin edge.\n    t_lo = t[idx_lo]\n    t_hi = t[idx_hi]\n    s = (t_new - t_lo) / (t_hi - t_lo + 1e-8)\n    # Compute the perturbation.\n    if perturb:\n        if single_jitter:\n            # Apply the same jitter to every sample along each dimension.\n            jitter = torch.rand(num_samples, device=t.device)\n            s += jitter\n        else:\n            # Apply independent jitter to each sample along each dimension.\n            jitter = torch.rand(num_samples, t.shape[1], device=t.device)\n            s += jitter\n    # Compute the sampled values.\n    return s\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Match up the dimensions of t and w\n    t, w = matchup_channels(t, w)\n    # Reshape tensors to be compatible with vmap\n    t = t.reshape(-1, t.shape[-1])\n    w = w.reshape(-1, w.shape[-1])\n    # Compute the PDF and CDF for each weight vector.\n    cw = integrate_weights(w)\n    # Draw uniform random samples from the unit interval.\n    u = torch.rand(num_samples, w.shape[0], device=t.device)\n    # Invert the CDF to get the samples.\n    t_new = invert_cdf(u, t, w)\n    # Optionally apply perturbation to the samples.\n    if perturb:\n        # Compute the bin indices for each sample.\n        idx_lo, idx_hi = searchsorted(t, t_new)\n        # Compute the width of the bins.\n        bin_width = t[..., 1:] - t[..., :-1]\n        # Compute the width of the bins to the left of the sample.\n        bin_width_left = t[..., 1:] - t_new\n        # Compute the width of the bins to the right of the sample.\n        bin_width_right = t_new - t[..., :-1]\n        # Compute the left and right offset.\n        left_offset = bin_width_left / bin_width\n        right_offset = bin_width_right / bin_width\n        # Compute the perturbation.\n        perturbation = (left_offset - right_offset) / 2\n        # Optionally apply independent jitter to each sample.\n        if not single_jitter:\n            perturbation = perturbation.unsqueeze(-1)\n        # Apply the perturbation.\n        t_new = t_new + perturbation\n    # Reshape the samples to the original shape of t.\n    t_new = t_new.reshape(t.shape[:-1] + (num_samples,))\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # Compute the dilated time steps.\n    t_dilated = t + dilation\n\n    # Clip the dilated time steps.\n    t_dilated = torch.clamp(t_dilated, domain[0], domain[1])\n\n    # Compute the adjusted weights.\n    w_dilated = w * (t_dilated[..., 1:] - t_dilated[..., :-1])\n\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # Dilate the time steps.\n    t_dilated = (t + dilation).clamp(*domain)\n\n    # Adjust the weights to match the dilated time steps.\n    w_dilated = weight_to_pdf(t_dilated, w)\n\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # Dilate the time steps.\n    t_dilated = t + dilation\n\n    # Clip the dilated time steps.\n    t_dilated = torch.clamp(t_dilated, min=domain[0], max=domain[1])\n\n    # Adjust the weights to match the dilated time steps.\n    w_dilated = w * (t_dilated[..., 1:] - t_dilated[..., :-1]).clip(torch.finfo(t.dtype).eps)\n\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # Get the dilated time steps.\n    t_dilated = t + (t[1:] - t[:-1]) * dilation\n\n    # Clip the dilated time steps.\n    t_dilated = torch.clamp(t_dilated, domain[0], domain[1])\n\n    # Get the dilated weights.\n    w_dilated = w * (t_dilated[1:] - t_dilated[:-1])\n\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # Dilate the time steps.\n    t_dilated = torch.nn.functional.max_pool1d(t.unsqueeze(1), dilation, return_indices=True)[1].squeeze(1)\n\n    # Clip the dilated time steps.\n    t_dilated = torch.clamp(t_dilated, domain[0], domain[1])\n\n    # Adjust the weights to match the dilated time steps.\n    w_dilated = torch.zeros_like(t_dilated)\n    for i in range(t_dilated.shape[0]):\n        w_dilated[i] = torch.sum(w[i, t_dilated[i] == t[i]])\n\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t_dilated = t * dilation\n    t_dilated = t_dilated.clamp(min=domain[0], max=domain[1])\n    w_dilated = w / dilation\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # preparing for size change\n    sh = t.shape[:-1]\n    t = t.reshape(-1, t.shape[-1])\n    w = w.reshape(-1, w.shape[-1])\n\n    # assuming sampling in s space\n    if t.shape[-1] != w.shape[-1] + 1:\n        t = torch.cat([t, torch.ones_like(t[..., -1:])], dim=-1)\n\n    # dilation\n    t_dilated = t.clone()\n    t_dilated[..., 1:] = t_dilated[..., 1:] + dilation\n\n    # clipping\n    t_dilated = torch.clamp(t_dilated, domain[0], domain[1])\n\n    # adjusting weights\n    w_dilated = w.clone()\n    w_dilated[..., 1:] = w_dilated[..., 1:] * (t[..., 1:] - t[..., :-1]) / (t_dilated[..., 1:] - t_dilated[..., :-1])\n\n    # preparing for size change\n    t_dilated = t_dilated.reshape(sh)\n    w_dilated = w_dilated.reshape(sh)\n\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # preparing for size change\n    t = t.reshape(-1, t.shape[-1])\n    w = w.reshape(-1, w.shape[-1])\n\n    # assuming sampling in s space\n    if t.shape[-1] != w.shape[-1] + 1:\n        t = torch.cat([t, torch.ones_like(t[..., -1:])], dim=-1)\n\n    # dilation\n    t_dilated = t.clone()\n    t_dilated[:, 1:] += dilation\n\n    # clipping\n    t_dilated = torch.clamp(t_dilated, domain[0], domain[1])\n\n    # adjusting weights\n    w_dilated = w.clone()\n    w_dilated[:, 1:] *= dilation\n\n    # preparing for size change\n    t_dilated = t_dilated.reshape(w.shape[:-1] + (t.shape[-1],))\n    w_dilated = w_dilated.reshape(w.shape)\n\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # Compute the dilation factor for each time step.\n    dilation_factor = (t[..., 1:] - t[..., :-1]) * dilation\n\n    # Compute the dilated time steps.\n    t_dilated = t[..., :-1] + dilation_factor\n\n    # Clip the dilated time steps.\n    t_dilated = torch.clamp(t_dilated, min=domain[0], max=domain[1])\n\n    # Compute the adjusted weights.\n    w_dilated = w / dilation_factor\n\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # TODO: Check for negative weights and throw an error.\n\n    # TODO: Check for non-positive dilation and throw an error.\n\n    # TODO: Check for non-positive dilation and throw an error.\n\n    # TODO: Check for non-positive dilation and throw an error.\n\n    # TODO: Check for non-positive dilation and throw an error.\n\n    # TODO: Check for non-positive dilation and throw an error.\n\n    # TODO: Check for non-positive dilation and throw an error.\n\n    # TODO: Check for non-positive dilation and throw an error.\n\n    # TODO: Check for non-positive dilation and throw an error.\n\n    # TODO: Check for non-positive dilation and throw an error.\n\n    # TODO: Check for non-positive dilation and throw an error.\n\n    # TODO: Check for non-positive dilation and throw an error.\n\n    # TODO: Check for non-positive dilation and throw an error.\n\n    # TODO: Check for non-positive dilation and throw an error.\n\n    # TODO: Check for non-positive dilation and throw an error.\n\n    # TODO: Check for non-positive dilation and throw an error.\n\n    # TODO: Check for non-positive dilation and throw an error.\n\n    # TODO: Check for non-positive dilation and throw an error.\n\n    # TODO: Check for non-positive dilation and throw an error.\n\n    # TODO: Check for non-positive dilation and throw an error.\n\n    # TODO: Check for non-positive dilation and throw an error.\n\n    # TODO: Check for non-positive dilation and throw an error.\n\n    # TODO: Check for non-positive dilation and throw an error.\n\n    # TODO: Check for non-positive dilation and throw an error.\n\n    # TODO: Check for non-positive dilation and throw an error.\n\n    # TODO: Check for non-positive dilation and throw an error.\n\n    # TODO: Check for non-"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # preparing for size change\n    sh = t.shape[:-1]\n    t = t.reshape(-1, t.shape[-1])\n    w = w.reshape(-1, w.shape[-1])\n\n    # assuming sampling in s space\n    if t.shape[-1] != w.shape[-1] + 1:\n        t = torch.cat([t, torch.ones_like(t[..., -1:])], dim=-1)\n\n    # dilation\n    t = t.unsqueeze(-1)\n    t = F.max_pool1d(t, dilation, dilation)\n    t = t.squeeze(-1)\n\n    # clipping\n    t = torch.clamp(t, domain[0], domain[1])\n\n    # adjusting weights\n    w = (w * (t[..., 1:] - t[..., :-1])).sum(dim=-1)\n\n    # preparing for size change\n    t = t.reshape(sh)\n    w = w.reshape(sh)\n\n    return t, w\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # preparing for size change\n    sh = *t.shape[:-1], w.shape[-1]\n    t = t.reshape(-1, t.shape[-1])\n    w = w.reshape(-1, w.shape[-1])\n\n    # assuming sampling in s space\n    if t.shape[-1] != w.shape[-1] + 1:\n        t = torch.cat([t, torch.ones_like(t[..., -1:])], dim=-1)\n\n    # dilation\n    t_dilated = torch.cat([t[..., 0:1], t[..., 1:] + dilation], dim=-1)\n\n    # clipping\n    t_clipped = torch.clip(t_dilated, domain[0], domain[1])\n\n    # preparing for size change\n    t_clipped = t_clipped.reshape(sh)\n    w_clipped = w[..., 0] * (t_clipped[..., 0] <= t[..., 0]) + \\\n        w[..., 1:] * (t_clipped[..., 1:] <= t[..., 1:])\n\n    return t_clipped, w_clipped\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # Adjust the time steps and weights based on the dilation.\n    t_dilated = t * dilation\n    w_dilated = w / dilation\n\n    # Clip the dilated time steps.\n    t_dilated = torch.clamp(t_dilated, domain[0], domain[1])\n\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # preparing for size change\n    sh = *t.shape[:-1], 1\n    t = t.reshape(-1, t.shape[-1])\n    w = w.reshape(-1, w.shape[-1])\n\n    # assuming sampling in s space\n    if t.shape[-1] != w.shape[-1] + 1:\n        t = torch.cat([t, torch.ones_like(t[..., -1:])], dim=-1)\n\n    # dilate\n    t = t.unsqueeze(-1)\n    t = torch.cat([t[..., 0:1] - (dilation - 1), t, t[..., -1:] + (dilation - 1)], dim=-1)\n    t = t.reshape(-1, t.shape[-1])\n    w = w.unsqueeze(-1)\n    w = torch.cat([w[..., 0:1], w, w[..., -1:]], dim=-1)\n    w = w.reshape(-1, w.shape[-1])\n\n    # clip\n    t = t.clamp(*domain)\n\n    # preparing for size change\n    t = t.reshape(sh)\n    w = w.reshape(sh)\n\n    return t, w\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # preparing for size change\n    sh = *t.shape[:-1], int(t.shape[-1] / dilation)\n    t = t.reshape(-1, t.shape[-1])\n    w = w.reshape(-1, w.shape[-1])\n\n    # assuming sampling in s space\n    if t.shape[-1] != w.shape[-1] + 1:\n        t = torch.cat([t, torch.ones_like(t[..., -1:])], dim=-1)\n\n    # eps = torch.finfo(torch.float32).eps\n    eps = 1e-8\n\n    # Dilate the time steps.\n    t_dilated = t.unsqueeze(-1).expand(-1, -1, dilation)\n    t_dilated = t_dilated.reshape(-1, dilation)\n    t_dilated = t_dilated.sort()[0]\n\n    # Clip the dilated time steps.\n    t_dilated = torch.cat([domain[0] * torch.ones_like(t_dilated[..., :1]), t_dilated, domain[1] * torch.ones_like(t_dilated[..., -1:])], dim=-1)\n    t_dilated = t_dilated.clip(domain[0], domain[1])\n\n    # Adjust the weights to match the dilated time steps.\n    w_dilated = weight_to_pdf(t_dilated, w)\n\n    # preparing for size change\n    t_dilated = t_dilated.reshape(sh)\n    w_dilated = w_dilated.reshape(sh)\n\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # Checking input arguments\n    assert t.ndim == w.ndim + 1\n    assert t.shape[-1] == w.shape[-1] + 1\n    assert t.ndim == 2\n    assert dilation > 0\n\n    # Performing dilation\n    t_dilated = t.unsqueeze(0).unsqueeze(0)\n    w_dilated = w.unsqueeze(0).unsqueeze(0)\n    t_dilated = F.max_pool1d(t_dilated, kernel_size=dilation, stride=dilation, return_indices=True)[1]\n    w_dilated = F.max_pool1d(w_dilated, kernel_size=dilation, stride=dilation, return_indices=True)[1]\n    t_dilated = t_dilated.squeeze(0).squeeze(0)\n    w_dilated = w_dilated.squeeze(0).squeeze(0)\n\n    # Clipping dilated time steps\n    t_dilated = t_dilated.clamp(domain[0], domain[1])\n\n    # Adjusting weights to match the dilated time steps\n    w_dilated = w_dilated.clamp(0, 1)\n    w_dilated = w_dilated / w_dilated.sum(dim=-1, keepdim=True)\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # Check that the input tensors are non-negative and of the same size.\n    assert torch.all(t >= 0)\n    assert t.shape == w.shape\n\n    # Dilate the time steps by the specified dilation parameter.\n    t_dilated = t * dilation\n\n    # Clip the dilated time steps to the specified domain.\n    t_dilated = torch.clamp(t_dilated, domain[0], domain[1])\n\n    # Compute the new weights to match the dilated time steps.\n    w_dilated = weight_to_pdf(t_dilated, w)\n\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # preparing for size change\n    t = t.reshape(-1, t.shape[-1])\n    w = w.reshape(-1, w.shape[-1])\n\n    # assuming sampling in s space\n    if t.shape[-1] != w.shape[-1] + 1:\n        t = torch.cat([t, torch.ones_like(t[..., -1:])], dim=-1)\n\n    # eps = torch.finfo(torch.float32).eps\n    eps = 1e-8\n\n    # Dilate the time steps.\n    # t_dilated = torch.max(t.reshape(t.shape[:-1] + (1, t.shape[-1])), dim=-1)[0]\n    t_dilated = torch.max(t.reshape(t.shape[:-1] + (1, t.shape[-1])), dim=-1, keepdim=True)[0]\n    t_dilated = t_dilated.reshape(t.shape[:-1] + (1,))\n\n    # Clip the dilated time steps.\n    t_dilated = torch.clip(t_dilated, domain[0], domain[1])\n\n    # Adjust the weights to match the dilated time steps.\n    w_adjusted = w / (t[..., 1:] - t[..., :-1]).clip(eps) * (t_dilated[..., 1:] - t_dilated[..., :-1]).clip(eps)\n\n    # preparing for size change\n    t_dilated = t_dilated.reshape(t.shape[:-1] + (1,))\n    w_adjusted = w_adjusted.reshape(w.shape)\n\n    return t_dilated, w_adjusted\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # check if t and w have the same shape\n    if t.shape != w.shape:\n        raise ValueError(\"t and w must have the same shape.\")\n\n    # check if t is a step function\n    if not torch.allclose(t[..., 1:], t[..., :-1]):\n        raise ValueError(\"t must be a step function.\")\n\n    # check if t is sorted in ascending order\n    if not torch.all(t[..., 1:] > t[..., :-1]):\n        raise ValueError(\"t must be sorted in ascending order.\")\n\n    # check if dilation is positive\n    if dilation <= 0:\n        raise ValueError(\"dilation must be positive.\")\n\n    # check if domain is a tuple of two floats\n    if not isinstance(domain, tuple) or len(domain) != 2:\n        raise ValueError(\"domain must be a tuple of two floats.\")\n\n    # check if domain is sorted\n    if not domain[0] < domain[1]:\n        raise ValueError(\"domain must be sorted.\")\n\n    # check if domain is non-negative\n    if not domain[0] >= 0:\n        raise ValueError(\"domain must be non-negative.\")\n\n    # check if dilation is a scalar\n    if not isinstance(dilation, float) or not isinstance(dilation, int):\n        raise ValueError(\"dilation must be a scalar.\")\n\n    # check if t is non-negative\n    if not torch.all(t >= 0):\n        raise ValueError(\"t must be non-negative.\")\n\n    # check if t is non-increasing\n    if not torch.all(t[..., 1:] <= t[..., :-1]):\n        raise ValueError(\"t must be non-increasing.\")\n\n    # check if t is non-decreasing\n    if not torch.all(t[..., 1:] >= t[..., :-1]):\n        raise ValueError(\"t must be non-decreasing.\")\n\n    # check if t is non-negative\n    if not torch.all(t >= 0):"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # Ensure t and w have the same shape\n    t, w = matchup_channels(t, w)\n\n    # Compute the dilated time steps\n    t_dilated = t.unsqueeze(1) + (torch.arange(1, t.shape[-1] + 1, device=t.device, dtype=t.dtype) * dilation).unsqueeze(0)\n\n    # Clip the dilated time steps to the specified domain\n    t_dilated = torch.clamp(t_dilated, domain[0], domain[1])\n\n    # Compute the adjusted weights\n    w_dilated = (w / dilation).unsqueeze(1) * (t_dilated.unsqueeze(0) - t.unsqueeze(1))\n\n    # Ensure the first and last time steps are included\n    w_dilated[..., 0] = w_dilated[..., 0] + w[..., 0]\n    w_dilated[..., -1] = w_dilated[..., -1] + w[..., -1]\n\n    # Ensure the weights sum to 1\n    w_dilated = w_dilated / w_dilated.sum(dim=-1, keepdim=True)\n\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # check if the query times are in the range of the step function\n    if torch.any(tq < t[0]) or torch.any(tq > t[-1]):\n        raise ValueError('The query times must be in the range of the step function.')\n\n    # check if the query times are in the range of the step function\n    if torch.any(tq < t[0]) or torch.any(tq > t[-1]):\n        raise ValueError('The query times must be in the range of the step function.')\n\n    # check if the step function is non-decreasing\n    if torch.any(t[1:] - t[:-1] < 0):\n        raise ValueError('The step function must be non-decreasing.')\n\n    # check if the step function is non-decreasing\n    if torch.any(y[1:] - y[:-1] < 0):\n        raise ValueError('The step function values must be non-decreasing.')\n\n    # check if the step function is non-decreasing\n    if torch.any(t[1:] - t[:-1] < 0):\n        raise ValueError('The step function must be non-decreasing.')\n\n    # check if the step function is non-decreasing\n    if torch.any(y[1:] - y[:-1] < 0):\n        raise ValueError('The step function values must be non-decreasing.')\n\n    # check if the step function is non-decreasing\n    if torch.any(t[1:] - t[:-1] < 0):\n        raise ValueError('The step function must be non-decreasing.')\n\n    # check if the step function is non-decreasing\n    if torch.any(y[1:] - y[:-1] < 0):\n        raise ValueError('The step function values must be non-decreasing.')\n\n    # check if the step function is non-decreasing\n    if torch.any(t[1:] - t[:-1] < "}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # TODO: handle the case where tq is a scalar\n\n    # If the query times are the same as the step times, return the step values.\n    if torch.all(tq == t):\n        return y\n\n    # If the query times are outside the range of the step times, return the outside value.\n    if tq.min() < t.min() or tq.max() > t.max():\n        return outside_value * torch.ones_like(tq)\n\n    # If the query times are outside the range of the step times, return the outside value.\n    if tq.min() < t.min() or tq.max() > t.max():\n        return outside_value * torch.ones_like(tq)\n\n    # If the query times are exactly the same as the step times, return the step values.\n    if torch.all(tq == t):\n        return y\n\n    # If the query times are outside the range of the step times, return the outside value.\n    if tq.min() < t.min() or tq.max() > t.max():\n        return outside_value * torch.ones_like(tq)\n\n    # If the query times are outside the range of the step times, return the outside value.\n    if tq.min() < t.min() or tq.max() > t.max():\n        return outside_value * torch.ones_like(tq)\n\n    # If the query times are outside the range of the step times, return the outside value.\n    if tq.min() < t.min() or tq.max() > t.max():\n        return outside_value * torch.ones_like(tq)\n\n    # If the query times are outside the range of the step times, return the outside value.\n    if tq.min() < t.min() or tq.max() > t.max():\n        return outside_value * torch.ones_like(tq)\n\n    # If the query times are outside the range of the step times, return the outside value.\n    if tq.min()"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # If a query time matches a step change, the function returns an outside value; otherwise, it interpolates the value at the query time based on the step function.\n    # if tq is not None:\n    #     tq = tq.unsqueeze(-1)\n    #     t = t.unsqueeze(-1)\n    #     y = y.unsqueeze(-1)\n\n    #     # If a query time matches a step change, the function returns an outside value; otherwise, it interpolates the value at the query time based on the step function.\n    #     # If a query time matches a step change, the function returns an outside value; otherwise, it interpolates the value at the query time based on the step function.\n    #     # if tq is not None:\n    #     #     tq = tq.unsqueeze(-1)\n    #     #     t = t.unsqueeze(-1)\n    #     #     y = y.unsqueeze(-1)\n    #     #\n    #     #     # If a query time matches a step change, the function returns an outside value; otherwise, it interpolates the value at the query time based on the step function.\n    #     #     # If a query time matches a step change, the function returns an outside value; otherwise, it interpolates the value at the query time based on the step function.\n    #     #     # if tq is not None:\n    #     #     #     tq = tq.unsqueeze(-1)\n    #     #     #     t = t.unsqueeze(-1)\n    #     #     #     y = y.unsqueeze(-1)\n    #     #\n    #     #     # If a query time matches a step change, the function returns an outside value; otherwise, it interpolates the value at the query time based on the step function.\n    #     #     # If a query time matches a step change, the function returns an outside value; otherwise, it interpolates the value at the query time based on the step function.\n    #     #     # if tq is not None:\n    #     #     #"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Check for query times that match step change times.\n    outside_mask = tq[..., None] == t[..., None, :]\n\n    # If a query time matches a step change, return the outside value.\n    y_query = torch.where(outside_mask, torch.full_like(y, outside_value), y)\n\n    # If a query time does not match a step change, interpolate the value.\n    y_query = interpolate(tq[..., None, :], t[..., None, :], y[..., None, :])\n\n    return y_query\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # tq: [..., N]\n    # t: [..., M]\n    # y: [..., M]\n    # outside_value: scalar\n\n    # tq[..., None, :] - t[..., None, :] -> [..., N, M]\n    # tq[..., None, :] <= t[..., None, :] -> [..., N, M]\n    # torch.any(tq[..., None, :] <= t[..., None, :], dim=-1) -> [..., N]\n    # torch.where(torch.any(tq[..., None, :] <= t[..., None, :], dim=-1), y, outside_value) -> [..., N]\n    # torch.any(tq[..., None, :] <= t[..., None, :], dim=-1) -> [..., N]\n    # torch.where(torch.any(tq[..., None, :] <= t[..., None, :], dim=-1), y, outside_value) -> [..., N]\n    return torch.where(torch.any(tq[..., None, :] <= t[..., None, :], dim=-1), y, outside_value)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # make sure query times are in ascending order\n    tq = tq.sort()[0]\n\n    # find the indices of the query times in t\n    tq_idx = torch.searchsorted(t, tq)\n\n    # make sure that query times are not outside the range of t\n    tq_idx = torch.clamp(tq_idx, 0, t.shape[0] - 1)\n\n    # find the indices of the query times in t\n    tq_idx_prev = tq_idx - 1\n\n    # find the indices of the query times in t\n    tq_idx_next = tq_idx + 1\n\n    # find the query times that match the step change times\n    tq_match = tq[tq_idx == tq_idx_prev]\n\n    # find the query times that match the step change times\n    tq_match_next = tq[tq_idx_next == tq_idx]\n\n    # find the query times that are not in the range of t\n    tq_outside = tq[tq_idx == 0]\n    tq_outside_next = tq[tq_idx == t.shape[0] - 1]\n\n    # find the query times that are not in the range of t\n    tq_outside = torch.cat((tq_outside, tq_outside_next))\n\n    # find the query times that match the step change times\n    tq_match = torch.cat((tq_match, tq_match_next))\n\n    # find the query times that are not in the range of t\n    tq_outside = torch.unique(tq_outside)\n\n    # find the query times that match the step change times\n    tq_match = torch.unique(tq_match)\n\n    # find the query times that are not in the range of t\n    yq_outside = torch.ones_like(tq_outside) * outside_value\n\n    # find the query times that match the step change"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    t, y = matchup_channels(t, y)\n    # preparing for size change\n    tq = tq.reshape(-1, tq.shape[-1])\n    t = t.reshape(-1, t.shape[-1])\n    y = y.reshape(-1, y.shape[-1])\n    # preparing for size change\n    tq = tq.reshape(-1, tq.shape[-1])\n    t = t.reshape(-1, t.shape[-1])\n    y = y.reshape(-1, y.shape[-1])\n\n    # interpolate\n    t_new = interpolate(tq, t, y)\n\n    # find outside value\n    outside_value = torch.as_tensor(outside_value, device=t.device, dtype=t.dtype)\n    t_new = torch.where(tq[..., None] == t[..., 1:-1], outside_value, t_new)\n\n    # preparing for size change\n    t_new = t_new.reshape(tq.shape[:-1] + (t.shape[-1],))\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Initialize output tensor\n    yq = torch.full(tq.shape, outside_value, device=t.device)\n\n    # Sort the times and values\n    t, y = torch.sort(torch.cat([t, y], dim=-1), dim=-1)\n\n    # Find the indices of the query times in the sorted list of times\n    tq_indices = torch.searchsorted(t, tq)\n\n    # Handle the case where the query time matches a step change time\n    yq[tq_indices == 0] = y[0]\n    yq[tq_indices == t.shape[-1]] = y[-1]\n\n    # Handle the case where the query time is in between two step change times\n    yq[tq_indices > 0] = y[tq_indices[tq_indices > 0] - 1]\n    yq[tq_indices < t.shape[-1]] = y[tq_indices[tq_indices < t.shape[-1]]]\n\n    return yq\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # If the query times are not sorted, sort them.\n    if not torch.all(tq <= t):\n        raise ValueError('Query times must be sorted.')\n\n    # If the query times are not a subset of the step function times, raise an error.\n    if not torch.all(torch.logical_or(tq <= t[0], tq >= t[-1])):\n        raise ValueError('Query times must be a subset of the step function times.')\n\n    # If the query times match the step function times, return the step function values.\n    if torch.all(tq == t):\n        return y\n\n    # If the query times are outside times, return the outside value.\n    if torch.all(tq > t[-1]):\n        return outside_value * torch.ones_like(tq)\n    if torch.all(tq < t[0]):\n        return outside_value * torch.ones_like(tq)\n\n    # If the query times are inside times, return the interpolated values.\n    tq = tq.unsqueeze(1)\n    t = t.unsqueeze(0)\n    y = y.unsqueeze(0)\n    return torch.sum(y * (tq >= t), dim=1) / torch.sum((tq >= t), dim=1)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Find the indices of the query times that match the step function times.\n    idx = torch.searchsorted(t, tq)\n\n    # Make sure the indices are within the range of step function times.\n    idx = torch.clamp(idx, 0, t.shape[0] - 1)\n\n    # Find the indices of the query times that are outside the range of step function times.\n    idx_outside = torch.where(tq < t[0])[0]\n    idx_outside = torch.cat([idx_outside, torch.where(tq > t[-1])[0]], dim=0)\n\n    # Find the indices of the query times that are within the range of step function times.\n    idx_inside = torch.where(tq >= t[0])[0]\n    idx_inside = torch.cat([idx_inside, torch.where(tq <= t[-1])[0]], dim=0)\n\n    # Find the values of the step function at the query times that match the step function times.\n    yq_outside = torch.ones(idx_outside.shape[0], dtype=tq.dtype, device=tq.device) * outside_value\n    yq_inside = y[idx]\n\n    # Find the values of the step function at the query times that are outside the range of step function times.\n    yq_outside = torch.ones(idx_outside.shape[0], dtype=tq.dtype, device=tq.device) * outside_value\n\n    # Find the values of the step function at the query times that are within the range of step function times.\n    yq_inside = y[idx]\n\n    # Concatenate the values of the step function at the query times that match the step function times with the values of the step function at the query times that are outside the range of step function times.\n    yq = torch.cat([yq_outside, yq_inside], dim=0)\n\n    return yq\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Ensure that t is sorted.\n    t, y = torch.sort(torch.stack([t, y], dim=-1), dim=-2)\n\n    # Find the indices of the step changes.\n    i = torch.searchsorted(t, tq, right=True)\n\n    # Find the indices of the step changes to the left and right of each query time.\n    i_lo = torch.max(torch.zeros_like(i), i - 1)\n    i_hi = torch.min(i, t.shape[-1] - 1)\n\n    # Compute the fractional distance between the step change at i_lo and the step change at i_hi.\n    t_lo = t[..., i_lo]\n    t_hi = t[..., i_hi]\n    t_diff = t_hi - t_lo\n    frac = (tq - t_lo) / t_diff.clip(torch.finfo(t.dtype).eps)\n\n    # Interpolate between the step changes.\n    y_lo = y[..., i_lo]\n    y_hi = y[..., i_hi]\n    y_interp = (1 - frac) * y_lo + frac * y_hi\n\n    # If the query time matches a step change, use the outside value.\n    y_out = torch.where(tq == t_lo, y_hi, y_interp)\n    y_out = torch.where(tq == t_hi, y_lo, y_out)\n\n    return y_out\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Ensure that the query times are sorted.\n    tq = torch.sort(tq, dim=-1)[0]\n    # Ensure that the step function times are sorted.\n    t = torch.sort(t, dim=-1)[0]\n    # Ensure that the step function times are sorted.\n    y = y.sort(dim=-1)[0]\n\n    # Find the indices of the step function times that are less than or equal to the query times.\n    idx = torch.searchsorted(t, tq, right=True)\n    # Ensure that the indices are in range.\n    idx = torch.clamp(idx, 0, t.shape[-1] - 1)\n\n    # Find the indices of the step function times that are greater than or equal to the query times.\n    idx_next = torch.clamp(idx + 1, 0, t.shape[-1] - 1)\n\n    # Find the query times that match the step function times exactly.\n    match = t[idx] == tq\n\n    # Find the query times that do not match the step function times exactly.\n    not_match = ~match\n\n    # Find the step function values at the query times that match the step function times exactly.\n    y_match = y[idx[match]]\n\n    # Find the step function values at the query times that do not match the step function times exactly.\n    y_not_match = y[idx_next[not_match]]\n\n    # Find the step function times that do not match the query times exactly.\n    t_not_match = t[idx_next[not_match]]\n\n    # Interpolate the step function values at the query times that do not match the step function times exactly.\n    y_interp = interpolate(tq[not_match], t[idx[not_match]], y[idx[match]])\n\n    # Combine the step function values that match the step function times exactly with the interpolated values.\n    y_out = torch.where(match, y_match, y_interp)\n\n    # Combine the step function values that match the step function times"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # check inputs\n    assert tq.ndim == t.ndim == y.ndim == 1\n    assert t.shape[0] == y.shape[0] + 1\n    assert tq.shape[0] == y.shape[0]\n    assert t.shape[0] == tq.shape[0]\n\n    # check if query times match step change times\n    matches = tq == t\n\n    # if query times match step change times, return outside values\n    if matches.sum() > 0:\n        yq = y.clone()\n        yq[matches] = outside_value\n\n    # otherwise, interpolate values\n    else:\n        yq = interpolate(tq, t, y)\n\n    return yq\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # If the query times are the same as the step function times, return the step function values.\n    if torch.all(tq == t):\n        return y\n\n    # If the query times are outside the step function range, return the outside value.\n    if tq[0] < t[0] or tq[-1] > t[-1]:\n        return torch.full(tq.shape, outside_value, device=t.device)\n\n    # If the query times are inside the step function range, return the interpolated values.\n    if torch.all(tq >= t[0]) and torch.all(tq <= t[-1]):\n        # Find the indices of the query times in the step function times.\n        t_idx = torch.searchsorted(t, tq)\n\n        # If the query times are exactly on a step change, return the outside value.\n        outside_idx = (t_idx == 0) | (t_idx == len(t))\n        t_idx[outside_idx] = -1\n\n        # If the query times are in between step changes, return the interpolated values.\n        inside_idx = ~outside_idx\n        t_idx[inside_idx] -= 1\n\n        # Look up the interpolated values.\n        yq = y[t_idx] + (tq - t[t_idx]) / (t[t_idx + 1] - t[t_idx]) * (\n                y[t_idx + 1] - y[t_idx])\n\n        # If the query times are outside the step function range, return the outside value.\n        yq[outside_idx] = outside_value\n\n        # Return the interpolated values.\n        return yq\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Input validation\n    if tq.shape != t.shape:\n        raise ValueError('tq and t must have the same shape.')\n    if y.shape != t.shape:\n        raise ValueError('y and t must have the same shape.')\n\n    # Find the indices of the query times that match step change times.\n    idx = torch.nonzero(tq == t, as_tuple=True)\n    if idx[0].nelement() > 0:\n        # If there are matches, replace the query times with the outside values.\n        tq[idx] = outside_value\n\n    # Interpolate the query times.\n    return interpolate(tq, t, y)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Make sure tq, t, and y have the same number of dimensions.\n    assert tq.ndim == t.ndim == y.ndim\n\n    # Make sure tq is monotonically increasing.\n    assert torch.all(tq[1:] >= tq[:-1])\n\n    # Make sure tq is less than or equal to the maximum t.\n    assert torch.all(tq <= t[-1])\n\n    # Make sure t is monotonically increasing.\n    assert torch.all(t[1:] >= t[:-1])\n\n    # Make sure tq is less than or equal to the maximum t.\n    assert torch.all(tq <= t[-1])\n\n    # Make sure that t and y have the same number of elements.\n    assert t.shape[-1] == y.shape[-1]\n\n    # Make sure that tq is less than or equal to t.\n    assert torch.all(tq <= t[-1])\n\n    # Make sure that tq is greater than or equal to t[0].\n    assert torch.all(tq >= t[0])\n\n    # If tq is empty, return an empty tensor.\n    if tq.shape[-1] == 0:\n        return torch.empty(tq.shape[:-1] + (0,))\n\n    # If t and y are empty, return an empty tensor.\n    if t.shape[-1] == 0:\n        return torch.empty(tq.shape[:-1] + (0,))\n\n    # Find the indices of the first step change times that are less than or equal to the query times.\n    idx = torch.searchsorted(t, tq, right=True)\n\n    # If the query time is equal to the step change time, return the outside value.\n    idx = torch.where(tq == t[idx], idx.new_tensor(t.shape[0]), idx)\n\n    # If the index is zero, return the outside value.\n    idx = torch.where(idx == 0, idx.new_tensor(1), idx"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Match up the dimensions of the inputs.\n    tq, t, y = matchup_channels(tq, t, y)\n\n    # Make sure that the step function is sorted.\n    t, y = torch.sort(torch.cat([t, y], dim=-1), dim=-1)\n\n    # Find the indices of the query times.\n    idx = torch.searchsorted(t, tq)\n\n    # The query times match a step change time.\n    idx_step = (idx == t.shape[-1]).nonzero()\n\n    # The query times are outside of the step function's range.\n    idx_outside = (idx == 0).nonzero()\n\n    # The query times are inside the step function's range.\n    idx_inside = (idx > 0) & (idx < t.shape[-1]).nonzero()\n\n    # The query times match a step change time.\n    if idx_step.numel() > 0:\n        tq_step = tq[idx_step[:, 0], idx_step[:, 1]]\n        yq_step = outside_value\n\n    # The query times are outside of the step function's range.\n    if idx_outside.numel() > 0:\n        tq_outside = tq[idx_outside[:, 0], idx_outside[:, 1]]\n        yq_outside = outside_value\n\n    # The query times are inside the step function's range.\n    if idx_inside.numel() > 0:\n        tq_inside = tq[idx_inside[:, 0], idx_inside[:, 1]]\n        yq_inside = interpolate(tq_inside, t, y)\n\n    # Concatenate the outside and inside values.\n    if idx_step.numel() > 0:\n        tq_concat = torch.cat([tq_step, tq_inside], dim=-1)\n        yq_concat = torch.cat([yq_step, yq_inside], dim=-1)\n    elif idx"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Check the shapes of the input tensors.\n    if tq.ndim != 1:\n        raise ValueError('tq must be a vector.')\n    if t.ndim != 1:\n        raise ValueError('t must be a vector.')\n    if y.ndim != 1:\n        raise ValueError('y must be a vector.')\n    if t.shape[0] != y.shape[0]:\n        raise ValueError('t and y must have the same length.')\n    if tq.shape[0] == 0:\n        raise ValueError('tq must have at least one element.')\n\n    # Check the values of the input tensors.\n    if t.shape[0] < 2:\n        raise ValueError('t must have at least two elements.')\n    if t.min() > tq.min():\n        raise ValueError('t must start at a value smaller than any query time.')\n    if t.max() < tq.max():\n        raise ValueError('t must end at a value larger than any query time.')\n    if t[0] != tq.min():\n        raise ValueError('t must start at the smallest query time.')\n    if t[-1] != tq.max():\n        raise ValueError('t must end at the largest query time.')\n\n    # Check the value of the outside_value argument.\n    if outside_value is not None:\n        if not isinstance(outside_value, (int, float)):\n            raise ValueError('outside_value must be numeric.')\n\n    # Compute the interpolated or outside values of the step function at the query times.\n    outside_mask = (tq[None, :] == t[:, None])\n    outside_values = outside_value * torch.ones(outside_mask.shape, device=t.device, dtype=t.dtype)\n    inside_mask = ~outside_mask\n    if inside_mask.sum() > 0:\n        inside_values = torch.interp(tq[None, inside_mask].flatten(), t[:, None].flatten(),"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # tq, t, y = map(torch.as_tensor, (tq, t, y))\n    # t, y = matchup_channels(t, y)\n\n    # find the index of the first time tq is larger than t\n    idx = torch.searchsorted(t, tq, right=True)\n    idx = torch.where(idx < t.shape[-1], idx, t.shape[-1] - 1)\n    idx = idx.clip(0, t.shape[-1] - 1)\n\n    # if the query time exactly matches a step change time, return the outside value\n    outside = torch.where(t[..., idx] == tq, outside_value, torch.nan)\n\n    # otherwise, interpolate the value at the query time\n    # this is the same as torch.where(t[..., idx] != tq,\n    #                                (t[..., idx] - tq) / (t[..., idx] - t[..., idx - 1]) * (y[..., idx] - y[..., idx - 1]) + y[..., idx - 1],\n    #                                outside)\n    # but avoids nans\n    t_diff = t[..., idx] - tq\n    t_diff_prev = t[..., idx - 1] - tq\n    t_diff_ratio = t_diff / (t_diff + t_diff_prev)\n    y_diff = y[..., idx] - y[..., idx - 1]\n    y_interp = t_diff_ratio * y_diff + y[..., idx - 1]\n    y_interp = torch.where(t_diff_prev == 0, outside, y_interp)\n\n    return y_interp\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # check shapes\n    assert tq.shape == t.shape\n    assert tq.shape == y.shape\n    assert t.shape == y.shape\n    assert t.ndim == 1\n    assert tq.ndim == 1\n    assert t.ndim == y.ndim\n\n    # check values\n    assert t.min() <= tq.min()\n    assert t.max() >= tq.max()\n\n    # find indices of tq\n    idx_lo, idx_hi = searchsorted(t, tq)\n\n    # set values outside the range of t to outside_value\n    idx_lo = torch.clamp(idx_lo, 0, t.shape[0] - 1)\n    idx_hi = torch.clamp(idx_hi, 0, t.shape[0] - 1)\n\n    # set values at the query times that match step change times to outside_value\n    idx_match = torch.where(tq == t[idx_lo])\n    idx_lo[idx_match] = idx_hi[idx_match] = idx_match\n\n    # interpolate\n    x = tq - t[idx_lo]\n    y_lo = y[idx_lo]\n    y_hi = y[idx_hi]\n    y_q = (y_hi - y_lo) * x + y_lo\n\n    # set values at the query times that match step change times to outside_value\n    y_q[idx_match] = outside_value\n\n    return y_q\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # prepare for size change\n    t = t.reshape(-1, t.shape[-1])\n    w = w.reshape(-1, w.shape[-1])\n\n    # anneal slope is 10 by default\n    # anneal_slope = 10.0\n\n    # prepare for size change\n    t = t.reshape(-1, t.shape[-1])\n    w = w.reshape(-1, w.shape[-1])\n\n    # prepare for size change\n    t = t.reshape(-1, t.shape[-1])\n    w = w.reshape(-1, w.shape[-1])\n\n    # prepare for size change\n    t = t.reshape(-1, t.shape[-1])\n    w = w.reshape(-1, w.shape[-1])\n\n    # prepare for size change\n    t = t.reshape(-1, t.shape[-1])\n    w = w.reshape(-1, w.shape[-1])\n\n    # prepare for size change\n    t = t.reshape(-1, t.shape[-1])\n    w = w.reshape(-1, w.shape[-1])\n\n    # prepare for size change\n    t = t.reshape(-1, t.shape[-1])\n    w = w.reshape(-1, w.shape[-1])\n\n    # prepare for size change\n    t = t.reshape(-1, t.shape[-1])\n    w = w.reshape(-1, w.shape[-1])\n\n    # prepare for size change\n    t = t.reshape(-1, t.shape[-1])\n    w = w.reshape(-1, w.shape[-1])\n\n    # prepare for size change\n    t = t.reshape(-1, t.shape[-1])\n    w = w.reshape(-1, w.shape[-1])\n\n    # prepare for size change\n    t = t.reshape(-1, t.shape[-1])\n    w = w.reshape(-1, w.shape[-1])\n\n    # prepare for size change"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # calculate the adjusted weights\n    w_adj = w * (1 - torch.exp(-anneal_slope * train_frac))\n\n    # handle cases where adjacent intervals have zero distance\n    w_adj[..., 1:] = torch.where(\n        (t[..., 1:] - t[..., :-1]) == 0,\n        0,\n        w_adj[..., 1:]\n    )\n\n    # softmax to ensure stability in computation\n    w_adj = torch.softmax(w_adj, dim=-1)\n\n    return w_adj\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    # preparing for size change\n    sh = *t.shape[:-1], w.shape[-1]\n    t = t.reshape(-1, t.shape[-1])\n    w = w.reshape(-1, w.shape[-1])\n\n    # calculate the adjusted weights\n    w_adjusted = (1 - (1 / (1 + torch.exp(-anneal_slope * (train_frac - 0.5))))) * w\n\n    # softmax the adjusted weights\n    w_adjusted = torch.softmax(w_adjusted, dim=-1)\n\n    # prepare for size change\n    w_adjusted = w_adjusted.reshape(sh)\n\n    return w_adjusted\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # adjust weights based on training fraction and annealing slope\n    weights = w * (1 - train_frac) ** anneal_slope\n\n    # ensure stability in computation by handling cases where adjacent intervals have zero distance, setting their weight to zero, and preventing NaN values by using a softmax operation on the adjusted weights\n    weights[..., 1:] = torch.where(\n        torch.abs(t[..., 1:] - t[..., :-1]) <= eps,\n        torch.zeros_like(weights[..., 1:]),\n        weights[..., 1:]\n    )\n    weights = torch.softmax(weights, dim=-1)\n\n    return weights\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # preparing for size change\n    t = t.reshape(-1, t.shape[-1])\n    w = w.reshape(-1, w.shape[-1])\n\n    # compute the bias function\n    bias = torch.exp(-anneal_slope * train_frac)\n\n    # compute the adjusted weights\n    w_adj = bias * w\n\n    # prevent NaN values\n    w_adj = torch.softmax(w_adj, dim=-1)\n\n    # prevent adjacent intervals with zero distance\n    w_adj[..., 1:] = torch.where(\n        (t[..., 1:] - t[..., :-1]) > eps,\n        w_adj[..., 1:],\n        0\n    )\n\n    # preparing for size change\n    w_adj = w_adj.reshape(*w.shape)\n\n    return w_adj\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # match up the shapes\n    t, w = matchup_channels(t, w)\n\n    # calculate the bias function\n    bias = (1 - train_frac) ** anneal_slope\n\n    # calculate the adjusted weights\n    w_adj = w * bias\n\n    # prevent NaNs and ensure stability by setting adjacent intervals with zero distance to zero\n    w_adj[..., 1:][(t[..., 1:] - t[..., :-1]).abs() < eps] = 0\n    w_adj[..., :-1][(t[..., 1:] - t[..., :-1]).abs() < eps] = 0\n\n    # softmax the adjusted weights\n    w_adj = torch.softmax(w_adj, dim=-1)\n\n    # return the adjusted weights\n    return w_adj\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # TODO: add support for 2D tensors\n\n    # TODO: add support for 1D tensors\n\n    # TODO: add support for 0D tensors\n\n    # TODO: add support for non-float tensors\n\n    # TODO: add support for non-torch tensors\n\n    # TODO: add support for non-tensor inputs\n\n    # TODO: add support for non-tensor outputs\n\n    # TODO: add support for non-torch outputs\n\n    # TODO: add support for non-float outputs\n\n    # TODO: add support for non-float inputs\n\n    # TODO: add support for non-float anneal_slope\n\n    # TODO: add support for non-float train_frac\n\n    # TODO: add support for non-float eps\n\n    # TODO: add support for non-float dilation\n\n    # TODO: add support for non-float domain\n\n    # TODO: add support for non-bool renormalize\n\n    # TODO: add support for non-bool single_jitter\n\n    # TODO: add support for non-bool perturb\n\n    # TODO: add support for non-bool deterministic_center\n\n    # TODO: add support for non-bool use_gpu_resampling\n\n    # TODO: add support for non-bool use_gpu_resampling\n\n    # TODO: add support for non-bool use_gpu_resampling\n\n    # TODO: add support for non-bool use_gpu_resampling\n\n    # TODO: add support for non-bool use_gpu_resampling\n\n    # TODO: add support for non-bool use_gpu_resampling\n\n    # TODO: add support for non-bool use_gpu_resampling\n\n    # TODO: add support for non-bool use_gpu_resampling\n\n    # TODO: add support for non-bool use_gpu_resampling\n\n    # TODO: add support for non-bool use_gpu_resampling\n\n    # TODO: add support for non-bool use_gpu_resampling\n\n    # TODO: add support"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    # preparing for size change\n    sh = *t.shape[:-1], w.shape[-1]\n    t = t.reshape(-1, t.shape[-1])\n    w = w.reshape(-1, w.shape[-1])\n\n    # adjust weights based on training fraction and anneal slope\n    w_adj = w * torch.exp(-anneal_slope * (1 - train_frac) * t[..., 1:-1])\n\n    # handle adjacent intervals with zero distance\n    w_adj[..., 1:-1] = torch.where(\n        (t[..., 2:] - t[..., 1:-1]) == 0,\n        0,\n        w_adj[..., 1:-1]\n    )\n\n    # prevent NaN values by using softmax\n    w_adj = torch.softmax(w_adj, dim=-1)\n\n    # preparing for size change\n    w_adj = w_adj.reshape(sh)\n    return w_adj\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # preparing for size change\n    t = t.reshape(-1, t.shape[-1])\n    w = w.reshape(-1, w.shape[-1])\n\n    # assuming sampling in s space\n    if t.shape[-1] != w.shape[-1] + 1:\n        t = torch.cat([t, torch.ones_like(t[..., -1:])], dim=-1)\n\n    # eps = torch.finfo(torch.float32).eps\n\n    # Calculate the annealing function.\n    anneal_func = (anneal_slope / (anneal_slope + torch.exp(-anneal_slope * train_frac)))\n\n    # Calculate the adjusted weights.\n    w_adj = anneal_func * w\n\n    # Calculate the softmax of the adjusted weights.\n    w_adj_softmax = torch.softmax(w_adj, dim=-1)\n\n    # Calculate the weighted sum of the adjusted weights.\n    w_adj_sum = torch.sum(w_adj_softmax * w, dim=-1)\n\n    # Calculate the adjusted weights.\n    w_adj_norm = w_adj_sum.unsqueeze(-1)\n\n    # Calculate the softmax of the adjusted weights.\n    w_adj_norm_softmax = torch.softmax(w_adj_norm, dim=-1)\n\n    # Calculate the weighted sum of the adjusted weights.\n    w_adj_norm_sum = torch.sum(w_adj_norm_softmax * w, dim=-1)\n\n    # Calculate the adjusted weights.\n    w_adj_norm_norm = w_adj_norm_sum.unsqueeze(-1)\n\n    # Calculate the softmax of the adjusted weights.\n    w_adj_norm_norm_softmax = torch.softmax(w_adj_norm_norm, dim=-1)\n\n    # Calculate the weighted sum of the adjusted weights.\n    w"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # get the number of intervals\n    n = w.shape[-1]\n\n    # get the time step\n    t_step = t[..., 1:] - t[..., :-1]\n\n    # get the annealing factor\n    anneal_factor = torch.exp(-anneal_slope * train_frac)\n\n    # get the adjusted weights\n    w_adj = anneal_factor * w\n\n    # get the adjusted weights\n    w_adj_t = t.new_zeros(t.shape[:-1] + (n + 1,))\n    w_adj_t[..., :-1] = t_step * w_adj\n\n    # get the adjusted weights\n    w_adj_t = w_adj_t.softmax(dim=-1)\n\n    return w_adj_t\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # ensure that t and w have the same number of dimensions\n    if t.ndim != w.ndim:\n        raise ValueError(f\"t and w must have the same number of dimensions, but t has {t.ndim} and w has {w.ndim}.\")\n\n    # ensure that t has one more dimension than w\n    if t.ndim != w.ndim + 1:\n        raise ValueError(f\"t must have one more dimension than w, but t has {t.ndim} and w has {w.ndim}.\")\n\n    # ensure that t has the correct shape\n    if t.shape[-1] != w.shape[-1] + 1:\n        raise ValueError(f\"t must have one more dimension than w, but t has shape {t.shape} and w has shape {w.shape}.\")\n\n    # ensure that t is sorted\n    if not torch.all(t[..., 1:] > t[..., :-1]):\n        raise ValueError(f\"t must be sorted in increasing order, but t is {t}.\")\n\n    # ensure that t is a float\n    if not t.dtype in [torch.float16, torch.float32, torch.float64]:\n        raise ValueError(f\"t must be a float tensor, but t is of type {t.dtype}.\")\n\n    # ensure that w is a float\n    if not w.dtype in [torch.float16, torch.float32, torch.float64]:\n        raise ValueError(f\"w must be a float tensor, but w is of type {w.dtype}.\")\n\n    # ensure that train_frac is a float\n    if not isinstance(train_frac, float):\n        raise ValueError(f\"train_frac must be a float, but train_frac is of type {type(train_frac)}.\")\n\n    # ensure that train_frac is between 0 and 1\n    if train_frac < 0 or train_frac > 1:\n        raise ValueError(f\"train_frac must be between 0 and 1, but train"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    # t: [..., num_bins + 1]\n    # w: [..., num_bins]\n    # train_frac: [1]\n\n    # Compute the weights for the annealing process.\n    # Compute the time deltas for the annealing process.\n    t_deltas = t[..., 1:] - t[..., :-1]\n    # Compute the weights for the annealing process.\n    w_anneal = torch.exp(-anneal_slope * t_deltas * train_frac)\n    # Compute the adjusted weights.\n    w_adj = w * w_anneal\n    # Compute the softmax of the adjusted weights.\n    w_adj_softmax = torch.softmax(w_adj, dim=-1)\n    # Compute the adjusted weights.\n    w_adj = w_adj_softmax * w\n    # Return the adjusted weights.\n    return w_adj\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # anneal weights\n    t, w = matchup_channels(t, w)\n    t0 = t[..., :-1]\n    t1 = t[..., 1:]\n    t_mid = (t0 + t1) / 2\n    t_diff = t1 - t0\n    w_adj = w * (1 - train_frac ** anneal_slope)\n    w_adj = w_adj * torch.exp(-((t_mid - t_mid[..., 0]) / t_diff[..., 0]) ** 2)\n    w_adj = w_adj / torch.sum(w_adj, dim=-1, keepdim=True).clip(eps)\n    return w_adj\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # convert t and w to float64 for better precision\n    t = t.double()\n    w = w.double()\n\n    # ensure that t and w are the same size\n    if t.shape[-1] != w.shape[-1] + 1:\n        raise ValueError(\"t and w must have the same number of bins\")\n\n    # ensure that t and w are sorted\n    if not torch.all(t[..., 1:] - t[..., :-1] >= 0):\n        raise ValueError(\"t and w must be sorted\")\n\n    # ensure that t and w are non-negative\n    if torch.any(t < 0):\n        raise ValueError(\"t must be non-negative\")\n\n    # ensure that w sums to 1\n    if torch.any(torch.abs(torch.sum(w, dim=-1) - 1) > eps):\n        raise ValueError(\"w must sum to 1\")\n\n    # ensure that w is non-negative\n    if torch.any(w < 0):\n        raise ValueError(\"w must be non-negative\")\n\n    # ensure that train_frac is a float\n    if not isinstance(train_frac, float):\n        raise TypeError(\"train_frac must be a float\")\n\n    # ensure that train_frac is between 0 and 1\n    if train_frac < 0 or train_frac > 1:\n        raise ValueError(\"train_frac must be between 0 and 1\")\n\n    # ensure that anneal_slope is a float\n    if not isinstance(anneal_slope, float):\n        raise TypeError(\"anneal_slope must be a float\")\n\n    # ensure that anneal_slope is greater than 0\n    if anneal_slope <= 0:\n        raise ValueError(\"anneal_slope must be greater than 0\")\n\n    # ensure that eps is a float\n    if not isinstance(eps, float):\n        raise TypeError(\"eps must be a float\")\n\n    # ensure that eps is greater than 0\n   "}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # set up variables\n    t, w = matchup_channels(t, w)\n    t = t[..., :-1]\n    t_max = torch.max(t)\n    t_min = torch.min(t)\n    t_range = t_max - t_min\n    t_mid = (t_max + t_min) / 2\n    w_max = torch.max(w)\n    w_min = torch.min(w)\n    w_range = w_max - w_min\n    w_mid = (w_max + w_min) / 2\n    t_train = t_mid + train_frac * t_range\n    w_train = w_mid + train_frac * w_range\n    t_train = t_train.clip(t_min, t_max)\n    w_train = w_train.clip(w_min, w_max)\n    t_train_idx = torch.searchsorted(t, t_train)\n    t_train_idx = t_train_idx.clip(0, t.shape[-1] - 1)\n    t_train_idx = t_train_idx.long()\n    t_train_idx = t_train_idx.unsqueeze(-1)\n    t_train_idx = t_train_idx.expand(t.shape[:-1] + (1,))\n    t_train = t_train.unsqueeze(-1)\n    t_train = t_train.expand(t.shape[:-1] + (1,))\n    t_train_idx_next = t_train_idx + 1\n    t_train_idx_next = t_train_idx_next.clip(0, t.shape[-1] - 1)\n    t_train_idx_next = t_train_idx_next.long()\n    t_train_idx_next = t_train_idx_next.unsqueeze(-1)\n    t_train_idx_next = t_train_idx_next.expand(t.shape[:-1] + (1"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # set up the annealing function\n    anneal_func = torch.exp(-anneal_slope * train_frac)\n\n    # set up the time tensor\n    t_len = t.shape[-1]\n    t_expand = t[..., None].expand(t.shape[:-1] + (t_len,))\n\n    # set up the weight tensor\n    w_len = w.shape[-1]\n    w_expand = w[..., None].expand(w.shape[:-1] + (w_len,))\n\n    # set up the weight mask\n    w_mask = torch.zeros_like(w_expand)\n    w_mask[..., :-1] = (t_expand[..., 1:] - t_expand[..., :-1]).clip(eps)\n\n    # set up the weight mask\n    w_mask = torch.zeros_like(w_expand)\n    w_mask[..., :-1] = (t_expand[..., 1:] - t_expand[..., :-1]).clip(eps)\n\n    # set up the annealing function\n    anneal_func = torch.exp(-anneal_slope * train_frac)\n\n    # set up the weight mask\n    w_mask = torch.zeros_like(w_expand)\n    w_mask[..., :-1] = (t_expand[..., 1:] - t_expand[..., :-1]).clip(eps)\n\n    # apply the annealing function to the weights\n    w_anneal = w_expand * anneal_func * w_mask\n\n    # apply the softmax function to the weights\n    w_anneal_softmax = torch.softmax(w_anneal, dim=-1)\n\n    # return the adjusted weights\n    return w_anneal_softmax\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # add a small epsilon to prevent division by zero and log of zero in computations\n    eps = torch.finfo(torch.float32).eps ** 2\n\n    # make sure the time tensor has the same shape as the weights tensor\n    t = t.reshape(-1, t.shape[-1])\n\n    # calculate the annealing factor\n    anneal_factor = (anneal_slope * train_frac) ** 2\n\n    # calculate the adjusted weights\n    w_adj = w * torch.exp(-anneal_factor * (t[..., 1:] - t[..., :-1]).clip(eps))\n\n    # handle adjacent intervals with zero distance\n    w_adj[..., 1:][(t[..., 1:] - t[..., :-1]).clip(eps) == 0] = 0\n\n    # softmax the adjusted weights to ensure stability\n    w_adj = torch.softmax(w_adj, dim=-1)\n\n    return w_adj\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # get the number of bins\n    num_bins = w.shape[-1]\n\n    # create a tensor of the bin edges\n    bin_edges = torch.linspace(0, 1, num_bins + 1, device=t.device, dtype=t.dtype)\n\n    # get the indices of the bins that the time values are in\n    bin_indices = torch.bucketize(t, bin_edges) - 1\n\n    # create a tensor of the bin centers\n    bin_centers = torch.linspace(0, 1, num_bins, device=t.device, dtype=t.dtype)\n\n    # get the bin centers of the bins that the time values are in\n    bin_centers = bin_centers[bin_indices]\n\n    # create a tensor of the bin widths\n    bin_widths = bin_edges[1:] - bin_edges[:-1]\n\n    # create a tensor of the bin heights\n    bin_heights = torch.ones_like(bin_centers)\n\n    # create a tensor of the training fraction\n    train_frac = torch.tensor([train_frac], device=t.device, dtype=t.dtype)\n\n    # create a tensor of the annealing slope\n    anneal_slope = torch.tensor([anneal_slope], device=t.device, dtype=t.dtype)\n\n    # calculate the annealing factor\n    anneal_factor = 1 / (1 + torch.exp(-anneal_slope * (train_frac - bin_centers)))\n\n    # calculate the adjusted weights\n    w_adj = (anneal_factor * bin_heights) / (bin_widths + eps)\n\n    # ensure stability by setting adjacent bins with zero distance to zero\n    w_adj[..., 1:] *= (bin_widths[..., :-1] > 0)\n    w_adj[..., :-1] *= (bin_widths[..., 1:] > 0)"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # Compute the bias function.\n    bias = 1 / (1 + torch.exp(-anneal_slope * (train_frac - 0.5)))\n\n    # Compute the adjusted weights.\n    w_adj = w * bias\n\n    # Compute the softmax of the adjusted weights.\n    w_adj_softmax = torch.softmax(w_adj, dim=-1)\n\n    # Compute the final weights.\n    w_adj_softmax = w_adj_softmax.clip(eps)\n    w_final = (w_adj_softmax * w).sum(dim=-1)\n\n    return w_final\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    # assuming s space\n    if t.shape[-1] != w.shape[-1] + 1:\n        t = torch.cat([t, torch.ones_like(t[..., -1:])], dim=-1)\n\n    # get the indices of the intervals\n    # the first interval is at the beginning of the sequence, the last is at the end\n    # the rest are in between\n    t_idx = torch.arange(t.shape[-1], device=t.device)\n    t_idx = t_idx.reshape(1, -1)\n\n    # get the weights of the intervals\n    w_idx = w[..., t_idx]\n\n    # get the time values of the intervals\n    t_idx = t[..., t_idx]\n\n    # get the time values of the adjacent intervals\n    t_idx_adj = t[..., t_idx - 1]\n    t_idx_adj = torch.cat([t_idx_adj, t_idx_adj[:, -1:]], dim=-1)\n\n    # get the difference between the time values of the adjacent intervals\n    dt = t_idx_adj - t_idx\n\n    # get the annealing function\n    anneal = 1 / (1 + anneal_slope * dt)\n\n    # get the adjusted weights\n    w_adj = anneal * w_idx\n\n    # get the adjusted weights of the adjacent intervals\n    w_adj_adj = w_idx[..., 1:]\n    w_adj_adj = torch.cat([w_adj_adj, w_adj_adj[:, -1:]], dim=-1)\n\n    # get the adjusted weights of the intervals\n    w_adj = w_adj + anneal * w_adj_adj\n\n    # get the adjusted weights of the intervals\n    w_adj = w_adj / (torch.sum(w_adj, dim=-1, keepdim=True) + eps)\n\n    # get the adjusted weights of the intervals\n    w_"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, dict):\n        if \"meta\" in batch:\n            return batch\n        else:\n            return {k: to_cuda(v, device, ignore_list) for k, v in batch.items()}\n    elif isinstance(batch, list) or isinstance(batch, tuple):\n        return [to_cuda(v, device, ignore_list) for v in batch]\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device=device)\n    elif isinstance(batch, dict) and \"meta\" not in batch:\n        return {k: to_cuda(batch[k], device=device) for k in batch}\n    elif isinstance(batch, (tuple, list)):\n        if ignore_list:\n            return batch\n        else:\n            return [to_cuda(e, device=device) for e in batch]\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, dict):\n        return batch.__class__({k: to_cuda(sample, device=device, ignore_list=k == \"meta\") for k, sample in batch.items()})\n    elif isinstance(batch, (tuple, list)):\n        return batch.__class__([to_cuda(sample, device=device, ignore_list=ignore_list) for sample in batch])\n    elif isinstance(batch, (int, float, str)):\n        return batch\n    else:\n        raise TypeError(f\"batch must contain tensors, numbers, strs, dicts or lists; found {type(batch)}\")\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device=device, non_blocking=True)\n    elif isinstance(batch, dict):\n        return batch.__class__({k: to_cuda(sample, device=device, ignore_list=True) for k, sample in batch.items() if k != \"meta\"})\n    elif isinstance(batch, (tuple, list)):\n        return batch.__class__([to_cuda(sample, device=device, ignore_list=True) for sample in batch])\n    elif ignore_list:\n        return batch\n    else:\n        raise TypeError((\"batch must contain tensors, numbers, dicts or lists; found {}\"\n                         .format(type(batch))))\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, dict):\n        if \"meta\" in batch:\n            return batch\n        else:\n            return {k: to_cuda(v, device=device, ignore_list=True) for k, v in batch.items() if not ignore_list}\n    elif isinstance(batch, list) or isinstance(batch, tuple):\n        return [to_cuda(v, device=device, ignore_list=True) for v in batch]\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, dict):\n        if \"meta\" in batch:\n            return batch\n        else:\n            return {k: to_cuda(batch[k], device=device, ignore_list=ignore_list) for k in batch}\n    elif isinstance(batch, list) or isinstance(batch, tuple):\n        return [to_cuda(item, device=device, ignore_list=ignore_list) for item in batch]\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, dict):\n        return {k: to_cuda(v, device=device, ignore_list=ignore_list) for k, v in batch.items() if k != \"meta\"}\n    elif isinstance(batch, list) or isinstance(batch, tuple):\n        return [to_cuda(v, device=device, ignore_list=ignore_list) for v in batch]\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, dict):\n        return {k: to_cuda(batch[k], device=device, ignore_list=ignore_list) for k in batch.keys()}\n    elif isinstance(batch, list):\n        return [to_cuda(b, device=device, ignore_list=ignore_list) for b in batch]\n    elif isinstance(batch, tuple):\n        return tuple([to_cuda(b, device=device, ignore_list=ignore_list) for b in batch])\n    elif isinstance(batch, set):\n        return set([to_cuda(b, device=device, ignore_list=ignore_list) for b in batch])\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, dict):\n        if \"meta\" in batch:\n            return batch\n        elif ignore_list:\n            return batch\n        else:\n            return {k: to_cuda(v, device=device, ignore_list=ignore_list) for k, v in batch.items()}\n    elif isinstance(batch, list) or isinstance(batch, tuple):\n        return [to_cuda(v, device=device, ignore_list=ignore_list) for v in batch]\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, dict) and \"meta\" not in batch:\n        return {k: to_cuda(v, device=device, ignore_list=ignore_list) for k, v in batch.items()}\n    elif isinstance(batch, (tuple, list)):\n        return [to_cuda(e, device=device, ignore_list=ignore_list) for e in batch]\n    elif ignore_list:\n        return batch\n    else:\n        return to_cuda(batch[0], device=device, ignore_list=ignore_list)\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, list) or isinstance(batch, tuple):\n        return [to_cuda(t, device, ignore_list) for t in batch]\n    elif isinstance(batch, dict) and not \"meta\" in batch:\n        return {k: to_cuda(batch[k], device, ignore_list) for k in batch}\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n\n    if isinstance(batch, dict):\n        if \"meta\" in batch:\n            return batch\n        return {k: to_cuda(v, device, ignore_list) for k, v in batch.items()}\n\n    if isinstance(batch, list):\n        if ignore_list:\n            return batch\n        return [to_cuda(v, device, ignore_list) for v in batch]\n\n    if isinstance(batch, tuple):\n        if ignore_list:\n            return batch\n        return tuple([to_cuda(v, device, ignore_list) for v in batch])\n\n    if isinstance(batch, np.ndarray):\n        return torch.from_numpy(batch).to(device)\n\n    if isinstance(batch, (int, float)):\n        return torch.tensor(batch).to(device)\n\n    if isinstance(batch, str):\n        return batch\n\n    raise NotImplementedError(f\"Unknown batch type {type(batch)}\")\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device=device)\n    elif isinstance(batch, dict):\n        if \"meta\" in batch:\n            return batch\n        else:\n            return {k: to_cuda(batch[k], device=device) for k in batch}\n    elif isinstance(batch, (tuple, list)):\n        if ignore_list:\n            return batch\n        else:\n            return [to_cuda(d, device=device) for d in batch]\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, dict):\n        return {k: v.to(device) for k, v in batch.items() if k != \"meta\"}\n    elif isinstance(batch, (tuple, list)):\n        if ignore_list:\n            return batch\n        else:\n            return [to_cuda(b, device) for b in batch]\n    else:\n        raise TypeError(\"batch must contain tensors, dicts or lists; found {type(batch)}\")\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, dict):\n        return {k: to_cuda(batch[k], device=device, ignore_list=k == \"meta\") for k in batch}\n    elif isinstance(batch, (tuple, list)):\n        return type(batch)([to_cuda(e, device=device, ignore_list=ignore_list) for e in batch])\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, dict):\n        if \"meta\" in batch.keys():\n            return batch\n        else:\n            return {k: to_cuda(batch[k], device=device) for k in batch}\n    elif isinstance(batch, list):\n        if ignore_list:\n            return batch\n        else:\n            return [to_cuda(b, device=device) for b in batch]\n    elif isinstance(batch, tuple):\n        if ignore_list:\n            return batch\n        else:\n            return tuple([to_cuda(b, device=device) for b in batch])\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device=device)\n    elif isinstance(batch, dict) and not any([k == \"meta\" for k in batch.keys()]):\n        return {k: to_cuda(batch[k], device=device, ignore_list=ignore_list) for k in batch}\n    elif isinstance(batch, (tuple, list)):\n        return [to_cuda(d, device=device, ignore_list=ignore_list) for d in batch]\n    elif isinstance(batch, (int, float, str)):\n        return batch\n    else:\n        raise TypeError(f\"Unsupported batch type {type(batch)}\")\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, dict) and not batch.get(\"meta\", None):\n        return {k: to_cuda(v, device=device) for k, v in batch.items()}\n    elif isinstance(batch, (tuple, list)):\n        return [to_cuda(v, device=device) for v in batch]\n    elif isinstance(batch, str):\n        return batch\n    elif ignore_list:\n        return [to_cuda(v, device=device) for v in batch]\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device=device)\n    elif isinstance(batch, dict) and not \"meta\" in batch:\n        return {k: to_cuda(batch[k], device=device, ignore_list=ignore_list) for k in batch}\n    elif isinstance(batch, (tuple, list)):\n        if ignore_list:\n            return batch\n        else:\n            return [to_cuda(e, device=device, ignore_list=ignore_list) for e in batch]\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device=device)\n    elif isinstance(batch, dict):\n        # If it's a dictionary, we want to iterate through the values\n        if \"meta\" in batch:\n            # There's a special \"meta\" key that's supposed to remain on the CPU\n            # and not be moved to the GPU device\n            batch_no_cpu = {k: v for k, v in batch.items() if k != \"meta\"}\n            # Move all the other values to the GPU\n            batch_no_cpu = to_cuda(batch_no_cpu, device=device)\n            # Put the `meta` key back in with the original values\n            batch_no_cpu[\"meta\"] = batch[\"meta\"]\n            # Return the updated dictionary\n            return batch_no_cpu\n        else:\n            return {k: to_cuda(v, device=device) for k, v in batch.items()}\n    elif isinstance(batch, (tuple, list)):\n        # If it's a tuple or a list, we can just iterate through them\n        return [to_cuda(d, device=device) for d in batch]\n    else:\n        raise TypeError(f\"Unable to cast object of type {type(batch)} to CUDA tensor\")\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # adjust the dimension of the faces tensor to match the batch dimension of the vertices tensor\n    f = f.expand(v.shape[:-1] + f.shape[-1:])\n\n    # gather the vertices forming each face\n    v_f = multi_gather(v, f, dim=dim)\n\n    # compute the normals of the faces\n    n = torch.cross(v_f[:, :, 1] - v_f[:, :, 0], v_f[:, :, 2] - v_f[:, :, 0], dim=-1)\n\n    # reshape the normals to match the original faces tensor structure\n    n = n.reshape(*f.shape)\n\n    return n\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # adjust the dimension of the faces tensor to match the batch dimension of the vertices tensor\n    if f.ndim < v.ndim:\n        f = f.expand(v.shape[:-2] + (-1,))\n\n    # compute the normals of the faces\n    v_0 = v.gather(dim, multi_indexing(f[..., 0], v.shape, dim))\n    v_1 = v.gather(dim, multi_indexing(f[..., 1], v.shape, dim))\n    v_2 = v.gather(dim, multi_indexing(f[..., 2], v.shape, dim))\n    n = torch.cross(v_1 - v_0, v_2 - v_0, dim=-1)\n\n    # reshape the result to maintain the original faces tensor structure with additional dimensions for batch processing\n    return n.reshape(*f.shape[:-2], *n.shape[-2:])\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # adjust the dimension of the faces tensor to match the batch dimension of the vertices tensor\n    if f.ndimension() < v.ndimension():\n        f = f.expand(v.shape[:-2] + f.shape[-2:])\n    # compute the normals of the faces w.r.t the vertices\n    v0, v1, v2 = v[f[..., 0], :], v[f[..., 1], :], v[f[..., 2], :]\n    n = torch.cross(v1 - v0, v2 - v0)\n    # reshape the result to maintain the original faces tensor structure with additional dimensions for batch processing\n    return n.reshape(*f.shape[:-2], *n.shape[-1:])\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # v: B, V, 3\n    # f: B, F, 3\n    # v_f: B, F, 3, 3\n    v_f = multi_gather(v, f, dim=dim)\n    # v_f: B, F, 3, 3\n    v_f_norm = v_f.norm(dim=-1, keepdim=True)\n    # v_f_norm: B, F, 3, 1\n    v_f_norm_cross = torch.cross(v_f[..., 0, :], v_f[..., 1, :], dim=-1)\n    # v_f_norm_cross: B, F, 3\n    v_f_norm_cross_norm = v_f_norm_cross.norm(dim=-1, keepdim=True)\n    # v_f_norm_cross_norm: B, F, 1\n    v_f_norm_cross_norm_norm = v_f_norm_cross_norm.norm(dim=-1, keepdim=True)\n    # v_f_norm_cross_norm_norm: B, F, 1, 1\n    v_f_norm_cross_norm_norm_norm = v_f_norm_cross_norm_norm.norm(dim=-1, keepdim=True)\n    # v_f_norm_cross_norm_norm_norm: B, F, 1, 1, 1\n    v_f_norm_cross_norm_norm_norm_norm = v_f_norm_cross_norm_norm_norm.norm(dim=-1, keepdim=True)\n    # v_f_norm_cross_norm_norm_norm_norm: B, F, 1, 1, 1, 1\n    v_f_norm_cross_norm = v_f_norm_cross_norm / v_f_norm_cross_norm_norm\n    # v_f_norm_cross_norm: B, F, 3\n    v_f_norm_cross_norm_norm = v_f_norm_cross_norm"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # adjust the dimension of the faces tensor to match the batch dimension of the vertices tensor\n    f = f.expand(v.shape[:-2] + f.shape[-2:])\n\n    # gather the vertices forming the faces\n    v_f = v.gather(dim, multi_indexing(f, v.shape, dim))\n\n    # compute the normals of the faces\n    n = torch.cross(v_f[:, 1, :] - v_f[:, 0, :], v_f[:, 2, :] - v_f[:, 0, :], dim=-1)\n    n = n / (torch.norm(n, dim=-1, keepdim=True) + 1e-6)\n\n    # reshape the result to maintain the original faces tensor structure with additional dimensions for batch processing\n    return n.reshape(*f.shape[:-2], 3, 3)\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # TODO: add some comments\n\n    # expand the faces tensor to match the batch dimension of the vertices tensor\n    f = f.expand(v.shape[0], *f.shape[1:])\n\n    # gather the vertices forming the faces\n    vf = multi_gather(v, f, dim=dim)\n\n    # compute the normals of the faces\n    n = torch.cross(vf[:, :, 1, :] - vf[:, :, 0, :], vf[:, :, 2, :] - vf[:, :, 0, :], dim=-1)\n\n    # reshape the normals to match the original faces tensor structure\n    n = n.reshape(*f.shape[:-1], *n.shape[1:])\n\n    return n\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # get the number of batches in the vertices tensor\n    n_batches = v.shape[0]\n\n    # expand the faces tensor to match the batch dimension of the vertices tensor\n    if f.shape[0] != n_batches:\n        f = f.expand(n_batches, *f.shape[1:])\n\n    # compute the normals of the faces\n    v_i = multi_gather(v, f, dim=dim)\n    v_j = multi_gather(v, f + 1, dim=dim)\n    v_k = multi_gather(v, f + 2, dim=dim)\n    v_ij = v_i - v_j\n    v_jk = v_j - v_k\n    v_normals = torch.cross(v_ij, v_jk, dim=dim)\n    v_normals = v_normals / (v_normals.norm(dim=dim, keepdim=True) + 1e-8)\n\n    # reshape the normals tensor to match the original faces tensor structure\n    return v_normals.reshape(n_batches, *f.shape[1:])\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # adjust the shape of the faces tensor to match the batch dimension of the vertices tensor\n    f_shape = f.shape\n    if f.ndim < v.ndim:\n        f = f.expand(v.shape[:-2] + f_shape[-2:])\n    elif f.ndim > v.ndim:\n        raise RuntimeError('The faces tensor contains more dimensions than the vertices tensor.')\n\n    # compute the normals of the faces\n    v_0, v_1, v_2 = v.index_select(dim, f[..., 0]), v.index_select(dim, f[..., 1]), v.index_select(dim, f[..., 2])\n    normals = torch.cross(v_1 - v_0, v_2 - v_0)\n\n    # reshape the normals to match the original faces tensor structure\n    normals = normals.reshape(*f_shape[:-1], *normals.shape[-1:])\n\n    return normals\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # adjust the dimension of the faces tensor to match the batch dimension of the vertices tensor\n    if v.ndim - f.ndim == 1:\n        f = f.unsqueeze(0)\n    if v.ndim - f.ndim == -1:\n        f = f.unsqueeze(-1)\n\n    # compute the normals of the faces\n    v_f = multi_gather(v, f, dim=dim)  # B, P, 3, 3\n    v_f = v_f.permute(0, 1, 3, 2)  # B, P, 3, 3\n    v_f = v_f - v_f.mean(dim=-2, keepdim=True)\n    n = torch.cross(v_f[:, :, 1, :], v_f[:, :, 2, :], dim=-1)\n    n = n / (n.norm(dim=-1, keepdim=True) + 1e-8)\n\n    # reshape the result to maintain the original faces tensor structure with additional dimensions for batch processing\n    n = n.permute(0, 1, 3, 2)\n    n = n.reshape(*f.shape[:-1], *n.shape[1:])\n    return n\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # expand faces to match the batch dimension of the vertices\n    if len(f.shape) < len(v.shape):\n        f = f.expand(v.shape[:-2] + f.shape)\n\n    # compute the normals of the faces\n    v_f = multi_gather(v, f, dim)\n    v_f = v_f.reshape(*v_f.shape[:-2], 3, 3, *v_f.shape[-1:])\n    n = torch.cross(v_f[..., 1, :] - v_f[..., 0, :], v_f[..., 2, :] - v_f[..., 0, :], dim=-1)\n\n    # return the faces normals\n    return n\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # adjust the dimensions of the faces tensor to match the batch dimension of the vertices tensor\n    if f.ndim < v.ndim:\n        f = f[(slice(None),) * (v.ndim - f.ndim) + (Ellipsis,)]\n\n    # compute the normals of the faces with respect to the vertices\n    n = torch.cross(v.gather(dim, f[..., 1, :]) - v.gather(dim, f[..., 0, :]), v.gather(dim, f[..., 2, :]) - v.gather(dim, f[..., 0, :]), dim=-1)\n\n    # reshape the normals to match the original faces tensor with additional dimensions for batch processing\n    return n.reshape(*f.shape[:-2], 3, 3)\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # compute normals of the triangles\n    v_a = v.gather(dim, multi_indexing(f[:, :, 0], v.shape, dim))\n    v_b = v.gather(dim, multi_indexing(f[:, :, 1], v.shape, dim))\n    v_c = v.gather(dim, multi_indexing(f[:, :, 2], v.shape, dim))\n    n = torch.cross(v_b - v_a, v_c - v_a, dim=-1)\n    n = n / (n.norm(dim=-1, keepdim=True) + 1e-8)\n\n    # adjust the shape of the faces tensor to match the batch dimension of the vertices tensor\n    f = f.expand(v.shape[:-1])\n    return n.gather(dim, multi_indexing(f, n.shape, dim))\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # adjust the dimension of the faces tensor to match the batch dimension of the vertices tensor if necessary\n    if len(f.shape) < len(v.shape):\n        f = f[(slice(None),) * (len(f.shape) - len(v.shape)) + (slice(None),)]\n\n    # compute the normals of the faces\n    v1 = v[f[..., 0], :]\n    v2 = v[f[..., 1], :]\n    v3 = v[f[..., 2], :]\n    n = torch.cross(v2 - v1, v3 - v1)\n    n = n / (torch.norm(n, dim=-1, keepdim=True) + 1e-10)\n\n    # adjust the dimension of the normals tensor to match the dimension of the faces tensor\n    if len(n.shape) > len(f.shape):\n        n = n[(slice(None),) * (len(n.shape) - len(f.shape)) + (slice(None),)]\n\n    # reshape the normals tensor to maintain the structure of the original faces tensor with additional dimensions for batch processing\n    n = n.reshape(*f.shape[:-1], *n.shape[len(f.shape):])\n\n    return n\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # compute the normals of the triangles\n    v_0, v_1, v_2 = v.index_select(dim=dim, index=f[:, 0]), v.index_select(dim=dim, index=f[:, 1]), v.index_select(dim=dim, index=f[:, 2])\n    normals = torch.cross(v_1 - v_0, v_2 - v_0)\n\n    # adjust the dimensions of the faces tensor to match the batch dimension of the vertices tensor\n    f_shape = f.shape\n    if f.ndim > v.ndim:\n        f = f.expand(v.shape[:-1] + f.shape[-1:])\n    elif f.ndim < v.ndim:\n        f = f.expand(v.shape[:-1] + f.shape)\n\n    # reshape the result to maintain the original faces tensor structure with additional dimensions for batch processing\n    f = f.reshape(v.shape[:-1] + f_shape[-1:])\n    normals = normals.reshape(v.shape[:-1] + normals.shape[-1:])\n\n    return normals\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # adjust the dimension of the faces tensor to match the batch dimension of the vertices tensor if necessary\n    if f.ndim < v.ndim:\n        f = f[(None,) * (v.ndim - f.ndim)]\n\n    # compute the normals of the faces\n    n = v.gather(dim=dim, index=f)\n    n = n[:, 1] - n[:, 0]\n    n = n[:, :, 1] - n[:, :, 0]\n    n = torch.nn.functional.normalize(n, dim=-1)\n\n    # reshape the result to match the structure of the original faces tensor\n    n = n.transpose(-1, -2)\n    n = n.reshape(*f.shape[:-1], 3, 3)\n\n    return n\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # check if the faces tensor has the same batch dimension as the vertices tensor\n    if v.ndim - f.ndim == 1:\n        # if not, expand the faces tensor to match the batch dimension of the vertices tensor\n        f = f.expand(*v.shape[:-2], *f.shape[-2:])\n\n    # compute the normals of the faces\n    v_0 = v.gather(dim, multi_indexing(f[..., 0], v.shape, dim))\n    v_1 = v.gather(dim, multi_indexing(f[..., 1], v.shape, dim))\n    v_2 = v.gather(dim, multi_indexing(f[..., 2], v.shape, dim))\n    normals = torch.cross(v_1 - v_0, v_2 - v_0, dim=-1)\n\n    # reshape the normals to match the original faces tensor structure\n    return normals.reshape(*f.shape[:-2], 3, 3)\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # we need to expand the faces tensor to match the batch dimension of the vertices tensor\n    # if the batch dimension is not the same, we need to expand the faces tensor to match the batch dimension of the vertices tensor\n    if f.ndimension() < v.ndimension():\n        f = f.expand(v.shape[:-2])\n    # compute the normals of the triangles\n    n = torch.cross(v[..., f[..., 1, :] - 1, :] - v[..., f[..., 0, :] - 1, :],\n                    v[..., f[..., 2, :] - 1, :] - v[..., f[..., 0, :] - 1, :], dim=-1)\n    # gather the normals of the triangles\n    n = multi_gather(n, f[..., 0, :], dim=dim)\n    # reshape the normals to match the original faces tensor structure\n    n = n.view(-1, *f.shape[:-2], 3, 3)\n    return n\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # expand the faces tensor to match the batch dimension of the vertices tensor\n    f = multi_expand(f, v, dim=dim)\n    # compute the normals of the faces with respect to the vertices\n    n = torch.cross(v[f[:, 1]] - v[f[:, 0]], v[f[:, 2]] - v[f[:, 0]], dim=-1)\n    # reshape the normals tensor to match the structure of the original faces tensor\n    return n.reshape(*f.shape[:-2], 3, 3)\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # get the shape of the vertices tensor\n    sh = v.shape\n    # expand the faces tensor to match the batch dimension of the vertices tensor\n    if v.ndim > f.ndim:\n        f = f.expand(*sh[:-1], *f.shape[-2:])\n    # reshape the faces tensor to match the structure of the vertices tensor\n    f = f.reshape(*sh[:-1], *f.shape[-2:])\n    # compute the normals of the faces\n    normals = torch.cross(v[..., f[..., 1, :], :] - v[..., f[..., 0, :], :],\n                          v[..., f[..., 2, :], :] - v[..., f[..., 0, :], :], dim=-1)\n    # gather the normals\n    normals = multi_gather(normals, f, dim)\n    # return the gathered normals\n    return normals\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # check if f is already expanded to match the batch dimension of v\n    if len(f.shape) < len(v.shape):\n        f = f[(...,) + (None,) * (len(v.shape) - len(f.shape))]\n\n    # gather the vertices\n    v_f = multi_gather(v, f, dim=dim)\n\n    # compute the normals\n    n_f = torch.cross(v_f[:, :, 1, :] - v_f[:, :, 0, :], v_f[:, :, 2, :] - v_f[:, :, 0, :], dim=-1)\n\n    # reshape the result\n    return n_f.permute(0, 1, 3, 2).contiguous()\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):  # numpy and others\n        batch = np.expand_dims(batch, axis=0)\n    else:\n        pass  # do nothing here, used for typed in to_x for methods\n        # FIXME: Incosistent behavior here, might lead to undebuggable bugs\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):  # numpy and others\n        batch = np.expand_dims(batch, 0)\n    else:\n        pass  # do nothing here, used for typed in to_x for methods\n        # FIXME: Incosistent behavior here, might lead to undebuggable bugs\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):  # numpy and others\n        batch = np.expand_dims(batch, axis=0)\n    else:\n        batch = torch.as_tensor(batch).unsqueeze(0)\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):  # numpy and others\n        batch = np.expand_dims(batch, axis=0)\n    else:\n        pass  # do nothing here, used for typed in to_x for methods\n        # FIXME: Incosistent behavior here, might lead to undebuggable bugs\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):  # numpy and others\n        batch = np.expand_dims(batch, 0)\n    else:\n        batch = torch.as_tensor(batch).unsqueeze(0)\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = batch[None, ...]\n    else:\n        batch = torch.as_tensor(batch)[None, ...]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):  # numpy and others\n        batch = np.expand_dims(batch, 0)\n    else:\n        pass  # do nothing here, used for typed in to_x for methods\n        # FIXME: Incosistent behavior here, might lead to undebuggable bugs\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):  # numpy and others\n        batch = np.expand_dims(batch, axis=0)\n    else:\n        pass  # do nothing here, used for typed in to_x for methods\n        # FIXME: Incosistent behavior here, might lead to undebuggable bugs\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):  # numpy and others\n        batch = batch[np.newaxis, ...]\n    else:\n        pass  # do nothing here, used for typed in to_x for methods\n        # FIXME: Incosistent behavior here, might lead to undebuggable bugs\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch[None, ...]\n    elif isinstance(batch, np.ndarray):\n        batch = np.expand_dims(batch, axis=0)\n    else:\n        pass\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):  # numpy and others\n        batch = np.expand_dims(batch, 0)\n    else:\n        batch = torch.as_tensor(batch).unsqueeze(0)\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):  # numpy and others\n        batch = np.expand_dims(batch, axis=0)\n    else:\n        batch = torch.as_tensor(batch).unsqueeze(0)\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):\n        batch = np.expand_dims(batch, axis=0)\n    else:\n        batch = torch.as_tensor(batch).unsqueeze(0)\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):  # numpy and others\n        batch = np.expand_dims(batch, axis=0)\n    else:\n        pass  # do nothing here, used for typed in to_x for methods\n        # FIXME: Incosistent behavior here, might lead to undebuggable bugs\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):  # numpy and others\n        batch = batch[None, ...]\n    else:\n        pass  # do nothing here, used for typed in to_x for methods\n        # FIXME: Incosistent behavior here, might lead to undebuggable bugs\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch[None, ...]\n    elif isinstance(batch, np.ndarray):  # numpy and others\n        batch = batch[None, ...]\n    else:\n        batch = torch.as_tensor(batch)[None, ...]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch[None]\n    elif isinstance(batch, np.ndarray):  # numpy and others\n        batch = batch[None]\n    else:\n        batch = torch.as_tensor(batch)[None]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = batch[None]\n    else:\n        batch = torch.as_tensor(batch)[None]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = batch[None, ...]\n    else:\n        pass\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):  # numpy and others\n        batch = batch[None, ...]\n    else:\n        batch = np.asarray(batch)[None, ...]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Convert camera parameters to tensors\n        H = torch.tensor(self.H, dtype=torch.float32)\n        W = torch.tensor(self.W, dtype=torch.float32)\n        K = torch.tensor(self.K, dtype=torch.float32)\n        R = torch.tensor(self.R, dtype=torch.float32)\n        T = torch.tensor(self.T, dtype=torch.float32)\n        n = torch.tensor(self.n, dtype=torch.float32)\n        f = torch.tensor(self.f, dtype=torch.float32)\n        t = torch.tensor(self.t, dtype=torch.float32)\n        v = torch.tensor(self.v, dtype=torch.float32)\n        bounds = torch.tensor(self.bounds, dtype=torch.float32)\n\n        # Convert GUI related elements to tensors\n        origin = torch.tensor(self.origin, dtype=torch.float32)\n        world_up = torch.tensor(self.world_up, dtype=torch.float32)\n        movement_speed = torch.tensor(self.movement_speed, dtype=torch.float32)\n        drag_coeff_mult = torch.tensor(self.drag_coeff_mult, dtype=torch.float32)\n        constant_drag = torch.tensor(self.constant_drag, dtype=torch.float32)\n        mass = torch.tensor(self.mass, dtype=torch.float32)\n        moment_of_inertia = torch.tensor(self.moment_of_inertia, dtype=torch.float32)\n        movement_torque = torch.tensor(self.movement_torque, dtype=torch.float32)\n        angular_friction = torch.tensor(self.angular_friction, dtype=torch.float32)\n        constant_torque = torch.tensor("}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n        batch.origin = self.origin\n        batch.world_up = self.world_up\n        batch.movement_speed = self.movement_speed\n        batch.movement_force = self.movement_force\n        batch.drag_coeff_mult = self.drag_coeff_mult\n        batch.constant_drag = self.constant_drag\n        batch.mass = self.mass\n        batch.moment_of_inertia = self.moment_of_inertia\n        batch.movement_torque = self.movement_torque\n        batch.angular_friction = self.angular_friction\n        batch.constant_torque = self.constant_torque\n        batch.min_interval = self.min_interval\n        batch.pause_physics = self.pause_physics\n        batch.min_interval = self.min_interval\n\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n\n        # Camera parameters\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n\n        # GUI related elements\n        batch.origin = self.origin\n        batch.world_up = self.world_up\n        batch.movement_speed = self.movement_speed\n        batch.movement_force = self.movement_force\n        batch.drag_coeff_mult = self.drag_coeff_mult\n        batch.constant_drag = self.constant_drag\n        batch.mass = self.mass\n        batch.moment_of_inertia = self.moment_of_inertia\n        batch.movement_torque = self.movement_torque\n        batch.angular_friction = self.angular_friction\n        batch.constant_torque = self.constant_torque\n        batch.min_interval = self.min_interval\n        batch.pause_physics = self.pause_physics\n\n        # Internal states\n        batch.is_dragging = self.is_dragging\n        batch.about_origin = self.about_origin\n        batch.is_panning = self.is_panning\n        batch.drag_start = self.drag_start\n\n        # Internal states to facilitate moving with mass\n        batch.force = self.force\n        batch.speed = self.speed\n        batch.acc = self.acc\n        batch.drag_coeff_mult = self.drag_coeff_mult\n        batch.movement_force = self.movement_force\n        batch.constant_drag = self.constant_drag\n        batch.pause_physics = self.pause_physics\n        batch.min_interval = self.min_interval\n\n        batch.torque = self.torque\n        batch.moment_of_inertia = self.moment"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n\n        batch.origin = torch.tensor(self.origin, dtype=torch.float32)\n        batch.world_up = torch.tensor(self.world_up, dtype=torch.float32)\n        batch.movement_speed = torch.tensor(self.movement_speed, dtype=torch.float32)\n        batch.movement_force = torch.tensor(self.movement_force, dtype=torch.float32)\n        batch.drag_coeff_mult = torch.tensor(self.drag_coeff_mult, dtype=torch.float32)\n        batch.constant_drag = torch.tensor(self.constant_drag, dtype=torch.float32)\n        batch.mass = torch.tensor(self.mass, dtype=torch.float32)\n        batch.moment_of_inertia = torch.tensor(self.moment_of_inertia, dtype=torch.float32)\n        batch.movement_torque = torch.tensor(self.movement_torque, dtype=torch.float32)\n        batch.angular_friction = torch.tensor(self.angular_friction, dtype=torch.float32)\n        batch.constant_torque = torch.tensor(self.constant_torque, dtype=torch.float32)\n        batch.min_interval = torch.tensor(self.min_interval, dtype=torch.float32)\n        batch.pause_physics = torch.tensor(self.pause_physics, dtype=torch.float32)\n\n        batch.torque = torch.tensor(self.torque, dtype=torch.float"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n        batch.origin = self.origin\n        batch.world_up = self.world_up\n        batch.movement_speed = self.movement_speed\n        batch.movement_force = self.movement_force\n        batch.drag_coeff_mult = self.drag_coeff_mult\n        batch.constant_drag = self.constant_drag\n        batch.mass = self.mass\n        batch.moment_of_inertia = self.moment_of_inertia\n        batch.movement_torque = self.movement_torque\n        batch.angular_friction = self.angular_friction\n        batch.constant_torque = self.constant_torque\n        batch.min_interval = self.min_interval\n        batch.pause_physics = self.pause_physics\n\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Camera parameters\n        H = self.H\n        W = self.W\n        K = self.K\n        R = self.R\n        T = self.T\n        n = self.n\n        f = self.f\n        t = self.t\n        v = self.v\n        bounds = self.bounds\n\n        # Camera update hyperparameters\n        origin = self.origin\n        world_up = self.world_up\n        movement_speed = self.movement_speed\n        movement_force = self.movement_force\n        drag_coeff_mult = self.drag_coeff_mult\n        constant_drag = self.constant_drag\n        mass = self.mass\n        moment_of_inertia = self.moment_of_inertia\n        movement_torque = self.movement_torque\n        angular_friction = self.angular_friction\n        constant_torque = self.constant_torque\n        min_interval = self.min_interval\n        pause_physics = self.pause_physics\n\n        # Internal states to facilitate camera position change\n        is_dragging = self.is_dragging\n        about_origin = self.about_origin\n        is_panning = self.is_panning\n        drag_start = self.drag_start\n\n        # Internal states to facilitate moving with mass\n        mass = self.mass\n        force = self.force\n        speed = self.speed\n        acc = self.acc\n        drag_coeff_mult = self.drag_coeff_mult\n        movement_force = self.movement_force\n        constant_drag = self.constant_drag\n        pause_physics = self.pause_physics\n        min_interval = self.min_interval\n\n        torque = self.torque\n        angular_speed = self.angular_speed\n        angular_acc = self.angular_acc\n        angular_friction = self.angular_friction\n        constant_torque = self.constant_torque\n        movement_torque = self.movement_torque\n\n        # Batch (network input parameters)\n        batch = dotdict()"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H = self.H\n        batch.W = self.W\n        batch.K = self.K\n        batch.R = self.R\n        batch.T = self.T\n        batch.n = self.n\n        batch.f = self.f\n        batch.t = self.t\n        batch.v = self.v\n        batch.bounds = self.bounds\n\n        batch.origin = self.origin\n        batch.world_up = self.world_up\n        batch.movement_speed = self.movement_speed\n        batch.movement_force = self.movement_force\n        batch.drag_coeff_mult = self.drag_coeff_mult\n        batch.constant_drag = self.constant_drag\n        batch.mass = self.mass\n        batch.moment_of_inertia = self.moment_of_inertia\n        batch.movement_torque = self.movement_torque\n        batch.angular_friction = self.angular_friction\n        batch.constant_torque = self.constant_torque\n        batch.min_interval = self.min_interval\n        batch.pause_physics = self.pause_physics\n\n        batch.force = self.force\n        batch.speed = self.speed\n        batch.acc = self.acc\n        batch.torque = self.torque\n        batch.angular_speed = self.angular_speed\n        batch.angular_acc = self.angular_acc\n\n        batch.meta = dotdict()\n        batch.meta.H = batch.H\n        batch.meta.W = batch.W\n        batch.meta.K = batch.K\n        batch.meta.R = batch.R\n        batch.meta.T = batch.T\n        batch.meta.n = batch.n\n        batch.meta.f = batch.f\n        batch.meta.t = batch.t\n        batch.meta.v = batch.v\n        batch.meta.bounds = batch.bounds\n\n        batch.meta.origin = batch.origin\n        batch.meta.world_up = batch.world"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Camera parameters\n        H = self.H\n        W = self.W\n        K = self.K\n        R = self.R\n        T = self.T\n        n = self.n\n        f = self.f\n        t = self.t\n        v = self.v\n        bounds = self.bounds\n\n        # GUI related elements\n        origin = self.origin\n        world_up = self.world_up\n        movement_speed = self.movement_speed\n        movement_force = self.movement_force\n        drag_coeff_mult = self.drag_coeff_mult\n        constant_drag = self.constant_drag\n        mass = self.mass\n        moment_of_inertia = self.moment_of_inertia\n        movement_torque = self.movement_torque\n        angular_friction = self.angular_friction\n        constant_torque = self.constant_torque\n        min_interval = self.min_interval\n        pause_physics = self.pause_physics\n\n        # Batch (network input parameters)\n        batch = dotdict()\n        batch.H = H\n        batch.W = W\n        batch.K = K\n        batch.R = R\n        batch.T = T\n        batch.n = n\n        batch.f = f\n        batch.t = t\n        batch.v = v\n        batch.bounds = bounds\n\n        # Internal states to facilitate camera position change\n        batch.is_dragging = self.is_dragging\n        batch.about_origin = self.about_origin\n        batch.is_panning = self.is_panning\n        batch.drag_start = self.drag_start\n\n        # Internal states to facilitate moving with mass\n        batch.mass = mass\n        batch.force = self.force\n        batch.speed = self.speed\n        batch.acc = self.acc\n        batch.drag_coeff_mult = drag_coeff_mult\n        batch.movement_force = movement_force\n        batch.constant_drag = constant_drag\n        batch.pause_physics = pause_physics"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n        batch.origin, batch.world_up = self.origin, self.world_up\n        batch.movement_speed, batch.movement_force, batch.drag_coeff_mult = self.movement_speed, self.movement_force, self.drag_coeff_mult\n        batch.mass, batch.force, batch.speed, batch.acc = self.mass, self.force, self.speed, self.acc\n        batch.torque, batch.moment_of_inertia, batch.angular_speed, batch.angular_acc = self.torque, self.moment_of_inertia, self.angular_speed, self.angular_acc\n        batch.pause_physics, batch.min_interval = self.pause_physics, self.min_interval\n\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Camera parameters\n        batch = dotdict()\n        batch.H = self.H\n        batch.W = self.W\n        batch.K = torch.tensor(self.K).float()\n        batch.R = torch.tensor(self.R).float()\n        batch.T = torch.tensor(self.T).float()\n        batch.n = self.n\n        batch.f = self.f\n        batch.t = self.t\n        batch.v = self.v\n        batch.bounds = torch.tensor(self.bounds).float()\n\n        # GUI related elements\n        batch.origin = torch.tensor(self.origin).float()\n        batch.world_up = torch.tensor(self.world_up).float()\n        batch.movement_speed = self.movement_speed\n        batch.movement_force = self.movement_force\n        batch.drag_coeff_mult = self.drag_coeff_mult\n        batch.constant_drag = self.constant_drag\n        batch.mass = self.mass\n        batch.moment_of_inertia = self.moment_of_inertia\n        batch.movement_torque = self.movement_torque\n        batch.angular_friction = self.angular_friction\n        batch.constant_torque = self.constant_torque\n        batch.min_interval = self.min_interval\n        batch.pause_physics = self.pause_physics\n\n        # Meta parameters\n        batch.meta = dotdict()\n        batch.meta.H = self.H\n        batch.meta.W = self.W\n        batch.meta.K = torch.tensor(self.K).float()\n        batch.meta.R = torch.tensor(self.R).float()\n        batch.meta.T = torch.tensor(self.T).float()\n        batch.meta.n = self.n\n        batch.meta.f = self.f\n        batch.meta.t = self.t\n        batch.meta.v = self.v\n        batch.meta.bounds = torch.tensor("}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # The batch format\n        batch = dotdict()\n\n        # Camera parameters\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n\n        # Camera GUI related elements\n        batch.origin = self.origin\n        batch.world_up = self.world_up\n        batch.movement_speed = self.movement_speed\n        batch.movement_force = self.movement_force\n        batch.drag_coeff_mult = self.drag_coeff_mult\n        batch.constant_drag = self.constant_drag\n        batch.mass = self.mass\n        batch.moment_of_inertia = self.moment_of_inertia\n        batch.movement_torque = self.movement_torque\n        batch.angular_friction = self.angular_friction\n        batch.constant_torque = self.constant_torque\n        batch.min_interval = self.min_interval\n        batch.pause_physics = self.pause_physics\n\n        # Camera GUI related elements\n        batch.is_dragging = self.is_dragging\n        batch.about_origin = self.about_origin\n        batch.is_panning = self.is_panning\n        batch.drag_start = self.drag_start\n\n        # Internal states to facilitate camera position change\n        batch.force = self.force\n        batch.speed = self.speed\n        batch.acc = self.acc\n        batch.drag_coeff_mult = self.drag_coeff_mult\n        batch.movement_force = self.movement_force\n        batch.constant_drag = self.constant_drag\n        batch.pause_physics = self.pause_physics\n        batch.min_interval = self.min_interval\n\n        batch.torque = self.torque\n        batch.moment_of_"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n\n        batch.H = self.H\n        batch.W = self.W\n        batch.K = self.K\n        batch.R = self.R\n        batch.T = self.T\n        batch.n = self.n\n        batch.f = self.f\n        batch.t = self.t\n        batch.v = self.v\n        batch.bounds = self.bounds\n\n        batch.origin = self.origin\n        batch.world_up = self.world_up\n        batch.movement_speed = self.movement_speed\n        batch.movement_force = self.movement_force\n        batch.drag_coeff_mult = self.drag_coeff_mult\n        batch.constant_drag = self.constant_drag\n        batch.mass = self.mass\n        batch.moment_of_inertia = self.moment_of_inertia\n        batch.movement_torque = self.movement_torque\n        batch.angular_friction = self.angular_friction\n        batch.constant_torque = self.constant_torque\n        batch.min_interval = self.min_interval\n        batch.pause_physics = self.pause_physics\n\n        batch.front = self.front\n        batch.center = self.center\n        batch.right = self.right\n        batch.down = self.down\n        batch.speed = self.speed\n        batch.acc = self.acc\n        batch.torque = self.torque\n        batch.angular_speed = self.angular_speed\n        batch.angular_acc = self.angular_acc\n\n        batch.w2c = self.w2c\n        batch.c2w = self.c2w\n        batch.gl_ext = self.gl_ext\n        batch.gl_ixt = self.gl_ixt\n        batch.ext = self.ext\n        batch.w2p = self.w2p\n        batch.V = self.V\n        batch.ixt = self.ixt\n\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Batch (network input parameters)\n        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n\n        # Meta (GUI related elements)\n        meta = dotdict()\n        meta.origin = self.origin\n        meta.world_up = self.world_up\n        meta.movement_speed = self.movement_speed\n        meta.movement_force = self.movement_force\n        meta.drag_coeff_mult = self.drag_coeff_mult\n        meta.constant_drag = self.constant_drag\n        meta.mass = self.mass\n        meta.moment_of_inertia = self.moment_of_inertia\n        meta.movement_torque = self.movement_torque\n        meta.angular_friction = self.angular_friction\n        meta.constant_torque = self.constant_torque\n        meta.min_interval = self.min_interval\n        meta.pause_physics = self.pause_physics\n\n        # Combine into a single batch\n        batch.meta = meta\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Batch (network input parameters)\n        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n        batch.origin = self.origin\n        batch.world_up = self.world_up\n        batch.movement_speed = self.movement_speed\n        batch.movement_force = self.movement_force\n        batch.drag_coeff_mult = self.drag_coeff_mult\n        batch.constant_drag = self.constant_drag\n        batch.mass = self.mass\n        batch.moment_of_inertia = self.moment_of_inertia\n        batch.movement_torque = self.movement_torque\n        batch.angular_friction = self.angular_friction\n        batch.constant_torque = self.constant_torque\n        batch.min_interval = self.min_interval\n        batch.pause_physics = self.pause_physics\n        batch.slider_width = 0.01\n        batch.i = 0\n        batch.will_delete = []\n\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Batch (network input parameters)\n        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n\n        # Internal states to facilitate camera position change\n        batch.is_dragging = self.is_dragging\n        batch.about_origin = self.about_origin\n        batch.is_panning = self.is_panning\n        batch.drag_start = self.drag_start\n\n        # Internal states to facilitate moving with mass\n        batch.mass = self.mass\n        batch.force = self.force\n        batch.speed = self.speed\n        batch.acc = self.acc\n        batch.drag_coeff_mult = self.drag_coeff_mult\n        batch.movement_force = self.movement_force\n        batch.constant_drag = self.constant_drag\n        batch.pause_physics = self.pause_physics\n        batch.min_interval = self.min_interval\n\n        batch.torque = self.torque\n        batch.moment_of_inertia = self.moment_of_inertia\n        batch.angular_speed = self.angular_speed\n        batch.angular_acc = self.angular_acc\n        batch.angular_friction = self.angular_friction\n        batch.constant_torque = self.constant_torque\n        batch.movement_torque = self.movement_torque\n\n        # Meta parameters\n        batch.origin = self.origin\n        batch.world_up = self.world_up\n        batch.movement_speed = self.movement_speed\n\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Convert to tensors\n        H = torch.tensor(self.H)\n        W = torch.tensor(self.W)\n        K = torch.tensor(self.K)\n        R = torch.tensor(self.R)\n        T = torch.tensor(self.T)\n        n = torch.tensor(self.n)\n        f = torch.tensor(self.f)\n        t = torch.tensor(self.t)\n        v = torch.tensor(self.v)\n        bounds = torch.tensor(self.bounds)\n        origin = torch.tensor(self.origin)\n        world_up = torch.tensor(self.world_up)\n        speed = torch.tensor(self.movement_speed)\n        mass = torch.tensor(self.mass)\n        force = torch.tensor(self.force)\n        speed = torch.tensor(self.speed)\n        acc = torch.tensor(self.acc)\n        drag_coeff_mult = torch.tensor(self.drag_coeff_mult)\n        movement_force = torch.tensor(self.movement_force)\n        pause_physics = torch.tensor(self.pause_physics)\n        min_interval = torch.tensor(self.min_interval)\n        torque = torch.tensor(self.torque)\n        angular_speed = torch.tensor(self.angular_speed)\n        angular_acc = torch.tensor(self.angular_acc)\n        angular_friction = torch.tensor(self.angular_friction)\n        constant_torque = torch.tensor(self.constant_torque)\n        movement_torque = torch.tensor(self.movement_torque)\n        moment_of_inertia = torch.tensor(self.moment_of_inertia)\n\n        # Convert to batch\n        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Parameters\n        H, W = self.H, self.W\n        K = self.K\n        R = self.R\n        T = self.T\n        n, f = self.n, self.f\n        t, v = self.t, self.v\n        bounds = self.bounds\n\n        # GUI\n        origin = self.origin\n        world_up = self.world_up\n        movement_speed = self.movement_speed\n        drag_coeff_mult = self.drag_coeff_mult\n        constant_drag = self.constant_drag\n        mass = self.mass\n        moment_of_inertia = self.moment_of_inertia\n        movement_torque = self.movement_torque\n        angular_friction = self.angular_friction\n        constant_torque = self.constant_torque\n        min_interval = self.min_interval\n        pause_physics = self.pause_physics\n\n        # Batch\n        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = H, W, K, R, T, n, f, t, v, bounds\n        batch.origin = origin\n        batch.world_up = world_up\n        batch.movement_speed = movement_speed\n        batch.drag_coeff_mult = drag_coeff_mult\n        batch.constant_drag = constant_drag\n        batch.mass = mass\n        batch.moment_of_inertia = moment_of_inertia\n        batch.movement_torque = movement_torque\n        batch.angular_friction = angular_friction\n        batch.constant_torque = constant_torque\n        batch.min_interval = min_interval\n        batch.pause_physics = pause_physics\n\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # The actual parameters\n        H = self.H\n        W = self.W\n        K = self.K\n        R = self.R\n        T = self.T\n        n = self.n\n        f = self.f\n        t = self.t\n        v = self.v\n        bounds = self.bounds\n\n        # The GUI related parameters\n        origin = self.origin\n        world_up = self.world_up\n        movement_speed = self.movement_speed\n        movement_force = self.movement_force\n        drag_coeff_mult = self.drag_coeff_mult\n        constant_drag = self.constant_drag\n        mass = self.mass\n        moment_of_inertia = self.moment_of_inertia\n        movement_torque = self.movement_torque\n        angular_friction = self.angular_friction\n        constant_torque = self.constant_torque\n        min_interval = self.min_interval\n        pause_physics = self.pause_physics\n\n        # The batch\n        batch = dotdict()\n        batch.H = H\n        batch.W = W\n        batch.K = K\n        batch.R = R\n        batch.T = T\n        batch.n = n\n        batch.f = f\n        batch.t = t\n        batch.v = v\n        batch.bounds = bounds\n\n        batch.origin = origin\n        batch.world_up = world_up\n        batch.movement_speed = movement_speed\n        batch.movement_force = movement_force\n        batch.drag_coeff_mult = drag_coeff_mult\n        batch.constant_drag = constant_drag\n        batch.mass = mass\n        batch.moment_of_inertia = moment_of_inertia\n        batch.movement_torque = movement_torque\n        batch.angular_friction = angular_friction\n        batch.constant_torque = constant_torque\n        batch.min_interval = min_interval\n        batch.pause_physics = pause_physics\n\n        # The meta\n        meta = dot"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Convert to tensor\n        H, W, K, R, T, n, f, t, v, bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n        origin, world_up = self.origin, self.world_up\n        movement_speed, movement_force, drag_coeff_mult, constant_drag, mass, moment_of_inertia, movement_torque, angular_friction, constant_torque, min_interval = self.movement_speed, self.movement_force, self.drag_coeff_mult, self.constant_drag, self.mass, self.moment_of_inertia, self.movement_torque, self.angular_friction, self.constant_torque, self.min_interval\n        pause_physics, is_dragging, about_origin, is_panning = self.pause_physics, self.is_dragging, self.about_origin, self.is_panning\n        drag_start, drag_start_front, drag_start_down, drag_start_right, drag_start_center, drag_start_origin, drag_start_world_up = self.drag_start, self.drag_start_front, self.drag_start_down, self.drag_start_right, self.drag_start_center, self.drag_start_origin, self.drag_start_world_up\n        drag_ymin, drag_ymax = self.drag_ymin, self.drag_ymax\n\n        # Convert to tensor\n        H = torch.tensor(H, dtype=torch.float32)\n        W = torch.tensor(W, dtype=torch.float32)\n        K = torch.tensor(K, dtype=torch.float32)\n        R = torch.tensor(R, dtype=torch.float32)\n        T = torch.tensor(T, dtype=torch.float32)\n        n = torch.tensor(n, dtype=torch.float"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Camera parameters\n        H, W, K, R, T, n, f, t, v, bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n\n        # Camera state\n        origin, world_up = self.origin, self.world_up\n\n        # Camera GUI parameters\n        movement_speed, movement_force, drag_coeff_mult, constant_drag, mass, moment_of_inertia, movement_torque, angular_friction, constant_torque, angular_friction, pause_physics, min_interval = self.movement_speed, self.movement_force, self.drag_coeff_mult, self.constant_drag, self.mass, self.moment_of_inertia, self.movement_torque, self.angular_friction, self.constant_torque, self.angular_friction, self.pause_physics, self.min_interval\n\n        # Camera GUI state\n        is_dragging, about_origin, is_panning = self.is_dragging, self.about_origin, self.is_panning\n        drag_start, drag_start_front, drag_start_down, drag_start_right, drag_start_center, drag_start_origin, drag_start_world_up = self.drag_start, self.drag_start_front, self.drag_start_down, self.drag_start_right, self.drag_start_center, self.drag_start_origin, self.drag_start_world_up\n        drag_ymin, drag_ymax = self.drag_ymin, self.drag_ymax\n\n        # Camera GUI state\n        center, front, right, down, world_up, origin = self.center, self.front, self.right, self.down, self.world_up, self.origin\n\n        # Convert to tensors\n        H, W, K, R, T, n, f, t, v, bounds = to_tensor([H, W, K, R, T, n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working() and not agent.is_prime():\n            agent_dict = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(agent_dict)\n\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            agent_dict = AgentSerializer(agent).to_dict()\n            self.persistence.save_agent(agent_dict)\n\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            agent_serializer = AgentSerializer(agent)\n            agent_dict = agent_serializer.serialize()\n            self.persistence.save_agent(agent_dict)\n\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if not agent.is_working():\n            return\n\n        if agent.is_prime():\n            return\n\n        agent_dict = AgentSerializer.serialize(agent)\n        self.persistence.save_agent(agent_dict)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working() and not agent.is_prime():\n            serializer = AgentSerializer(agent)\n            serialized_agent = serializer.serialize()\n            self.persistence.save_agent(serialized_agent)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working() and not agent.is_prime():\n            agent_dict = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(agent_dict)\n\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working() and not agent.is_prime():\n            agent_state = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(agent.id, agent_state)\n\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if not agent.is_working() or agent.is_prime():\n            return\n\n        agent_dict = AgentSerializer.serialize_agent(agent)\n        self.persistence.save_agent(agent_dict)\n\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working() and not agent.is_prime():\n            agent_serializer = AgentSerializer(agent)\n            agent_dict = agent_serializer.to_dict()\n            self.persistence.save_agent(agent_dict)\n\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            agent_dict = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(agent_dict)\n\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working() and not agent.is_prime():\n            agent_dict = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(agent_dict)\n\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working() and not agent.is_prime():\n            agent_serializer = AgentSerializer(agent)\n            agent_state = agent_serializer.get_agent_state()\n            self.persistence.save_agent(agent.id, agent_state)\n\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        # Check if the agent is a working agent\n        if agent.is_working_agent():\n            # Check if the agent is a prime agent\n            if not agent.is_prime_agent():\n                # Serialize the agent state\n                agent_state = AgentSerializer(agent)\n                # Save the agent state\n                self.persistence.save_agent(agent_state)\n\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working() and not agent.is_prime():\n            self.persistence.save_agent(agent.id, AgentSerializer.serialize(agent))\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working and not agent.is_prime:\n            agent_dict = AgentSerializer(agent).to_dict()\n            self.persistence.save_agent(agent_dict)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working and not agent.is_prime:\n            self.persistence.save_agent(AgentSerializer(agent).to_representation(agent))\n\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if not agent.is_working:\n            return\n\n        if agent.is_prime:\n            return\n\n        agent_serializer = AgentSerializer(agent)\n        agent_dict = agent_serializer.to_dict()\n\n        self.persistence.save_agent(agent_dict)\n\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        # If the agent is a working agent and not a prime agent, we save its state.\n        if agent.is_working() and not agent.is_prime():\n            serializer = AgentSerializer(agent)\n            state = serializer.serialize()\n            self.persistence.save_agent(state)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        # Serialize the agent's state\n        agent_serializer = AgentSerializer(agent)\n        agent_serialized = agent_serializer.serialize_agent()\n\n        # If the agent is a working agent, save its state\n        if agent.is_working_agent() and not agent.is_prime_agent():\n            self.persistence.save_agent(agent_serialized)\n\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        # TODO: Add a check to see if the agent is a working agent.\n        # TODO: Add a check to see if the agent is a prime agent.\n        # TODO: Add a check to see if the agent is a working agent and not a prime agent.\n\n        # Serialize the agent's state\n        agent_state = AgentSerializer.serialize(agent)\n\n        # Save the agent's state\n        self.persistence.save_agent(agent_state)\n"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            similarities = [cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0] if agent.purpose_embedding is not None else -np.inf for agent in self.agents]\n            if not similarities:\n                return None, -np.inf\n            return self.agents[np.argmax(similarities)], np.max(similarities)\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            similarities = [cosine_similarity([e1], [purpose_embedding])[0][0] for e1 in self.agents]\n            if similarities:\n                max_similarity = max(similarities)\n                if max_similarity > 0.999:\n                    return None, max_similarity\n                else:\n                    return self.agents[np.argmax(similarities)], max_similarity\n            else:\n                return None, -np.inf\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            similarities = [cosine_similarity([e1], [purpose_embedding])[0][0] for e1 in self.agents]\n            if not similarities:\n                return None, -np.inf\n            else:\n                return self.agents[np.argmax(similarities)], np.max(similarities)\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            similarities = [cosine_similarity([e1], [purpose_embedding])[0][0] for e1 in self.agents]\n            if similarities:\n                max_similarity = max(similarities)\n                if max_similarity > 0.999:\n                    return self.agents[similarities.index(max_similarity)], max_similarity\n            return None, -np.inf\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            similarities = [cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0] for agent in self.agents if agent.purpose_embedding is not None]\n            if not similarities:\n                return None, -np.inf\n            return self.agents[np.argmax(similarities)], np.max(similarities)\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            similarities = [cosine_similarity([e1], [e2])[0][0] for e1 in [purpose_embedding] for e2 in [agent.purpose_embedding for agent in self.agents]]\n            if not similarities:\n                return None, -np.inf\n            return self.agents[np.argmax(similarities)], np.max(similarities)\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")\n\n"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            similarities = [cosine_similarity([e1], [purpose_embedding])[0][0] for e1 in self.agents[0].purpose_embedding]\n            if similarities:\n                return self.agents[np.argmax(similarities)], np.max(similarities)\n            else:\n                return None, -np.inf\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")\n\n\n"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            similarities = [cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0] for agent in self.agents if agent.purpose_embedding is not None]\n            if not similarities:\n                return None, -np.inf\n            return self.agents[np.argmax(similarities)], np.max(similarities)\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")\n\n"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if not isinstance(purpose_embedding, np.ndarray):\n                raise ValueError(\"purpose_embedding must be a numpy array\")\n\n            similarities = [cosine_similarity([e1], [purpose_embedding])[0][0] for e1 in self.agents]\n            if not similarities:\n                return None, -np.inf\n\n            return self.agents[np.argmax(similarities)], np.max(similarities)\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")\n\n"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            similarities = []\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                similarities.append((agent, similarity))\n\n            if not similarities:\n                return None, -np.inf\n\n            return max(similarities, key=lambda x: x[1])\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")\n\n"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            similarities = [cosine_similarity([e1], [purpose_embedding])[0][0] for e1 in self.agents]\n            if similarities:\n                return self.agents[np.argmax(similarities)], np.max(similarities)\n            else:\n                return None, -np.inf\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")\n\n"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            similarities = [cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0] for agent in self.agents]\n            if similarities:\n                max_similarity = max(similarities)\n                if max_similarity > 0.999:\n                    return self.agents[similarities.index(max_similarity)], max_similarity\n            return None, -np.inf\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")\n\n"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            similarities = [cosine_similarity([e1], [purpose_embedding])[0][0] for e1 in self.agents]\n            if len(similarities) == 0:\n                return None, -np.inf\n            return self.agents[np.argmax(similarities)], np.max(similarities)\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")\n\n"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            similarities = [cosine_similarity([e1], [e2])[0][0] for e1 in [purpose_embedding] for e2 in [agent.purpose_embedding for agent in self.agents if agent.purpose_embedding is not None]]\n            if similarities:\n                closest_agent = self.agents[np.argmax(similarities)]\n                return closest_agent, np.max(similarities)\n            else:\n                return None, -np.inf\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")\n\n"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            similarities = [cosine_similarity([e1], [purpose_embedding])[0][0] for e1 in self.agents if e1.purpose_embedding is not None]\n            if not similarities:\n                return None, -np.inf\n            return self.agents[np.argmax(similarities)], np.max(similarities)\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")\n"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            similarities = [cosine_similarity([e1], [e2])[0][0] for e1 in self.agents for e2 in self.agents]\n            if similarities:\n                max_similarity = max(similarities)\n                if max_similarity > 0.999:\n                    return None, max_similarity\n\n                max_similarity_index = np.argmax(similarities)\n                return self.agents[max_similarity_index // len(self.agents)], max_similarity\n            else:\n                return None, -np.inf\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")\n\n"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            similarities = []\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                similarities.append((agent, similarity))\n\n            similarities = sorted(similarities, key=lambda x: x[1], reverse=True)\n            if len(similarities) > 0:\n                return similarities[0]\n            else:\n                return None, -np.inf\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")\n\n\n"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            similarities = [cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0] for agent in self.agents if agent.purpose_embedding is not None]\n            if not similarities:\n                return None, -np.inf\n            max_similarity = max(similarities)\n            max_index = similarities.index(max_similarity)\n            return self.agents[max_index], max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")\n\n"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            similarities = [cosine_similarity([e1], [purpose_embedding])[0][0] for e1 in self.agents]\n            if not similarities:\n                return None, -np.inf\n            return max(zip(self.agents, similarities), key=lambda x: x[1])\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")\n\n"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            similarities = [cosine_similarity([e1], [purpose_embedding])[0][0] for e1 in self.agents if e1.purpose_embedding is not None]\n            if similarities:\n                highest_similarity = max(similarities)\n                if highest_similarity > 0.999:\n                    return None, highest_similarity\n\n                return self.agents[np.argmax(similarities)], highest_similarity\n            else:\n                return None, -np.inf\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")\n\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            openai_api_wrapper=self.openai_wrapper,\n            agent_persistence_manager=self.agent_persistence\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            name=PRIME_NAME,\n            prompt=PRIME_PROMPT,\n            weight=PRIME_AGENT_WEIGHT,\n            is_prime=True,\n            is_prime_only=True,\n            is_prime_only_initial_turn=True,\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            PRIME_PROMPT,\n            PRIME_NAME,\n            PRIME_AGENT_WEIGHT,\n            prime=True,\n            prime_only=True\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            name=PRIME_NAME,\n            prompt=PRIME_PROMPT,\n            weight=PRIME_AGENT_WEIGHT,\n            flags={\"prime\": True},\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            name=PRIME_NAME,\n            prompt=PRIME_PROMPT,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        # Create the prime agent\n        prime_agent = MicroAgent(\n            name=PRIME_NAME,\n            prompt=PRIME_PROMPT,\n            weight=PRIME_AGENT_WEIGHT,\n            flags={\n                \"prime\": True,\n                \"prime_only\": True,\n                \"prime_only_for_training\": True,\n                \"prime_only_for_testing\": True,\n            },\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            openai_api_wrapper=self.openai_wrapper,\n            agent_persistence_manager=self.agent_persistence\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            prime_agent=True,\n            examples=EXAMPLES,\n            prompt_engineering_system_prompt=PROMPT_ENGINEERING_SYSTEM_PROMPT,\n            prompt_engineering_template=PROMPT_ENGINEERING_TEMPLATE,\n        )\n\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        self.agents.append(\n            MicroAgent(\n                prompt=PRIME_PROMPT,\n                name=PRIME_NAME,\n                weight=PRIME_AGENT_WEIGHT,\n                prime=True,\n                # TODO: Add the remaining flag\n            )\n        )\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            name=PRIME_NAME,\n            prompt=PRIME_PROMPT,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            prime_agent=True,\n            openai_api_wrapper=self.openai_wrapper,\n            agent_persistence_manager=self.agent_persistence\n        )\n\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            name=PRIME_NAME,\n            prompt=PRIME_PROMPT,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            prime_agent=True,\n        )\n\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            persistence_manager=self.agent_persistence\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            # TODO: This is a temporary flag that is not used in the current implementation.\n            # This flag is used to indicate that this agent is the prime agent.\n            # This flag is used to indicate that this agent is the prime agent.\n            # This flag is used to indicate that this agent is the prime agent.\n            prime_agent=True,\n            openai_api=self.openai_wrapper,\n            agent_persistence_manager=self.agent_persistence\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            prime_agent=True,\n            agent_persistence_manager=self.agent_persistence,\n            openai_wrapper=self.openai_wrapper\n        )\n\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            PRIME_PROMPT,\n            PRIME_NAME,\n            PRIME_AGENT_WEIGHT,\n            prime_agent=True\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        # Create prime agent\n        prime_agent = MicroAgent(\n            name=PRIME_NAME,\n            prompt=PRIME_PROMPT,\n            weight=PRIME_AGENT_WEIGHT,\n            flags={\n                \"prime\": True,\n                \"prime_agent\": True\n            }\n        )\n\n        # Add to agent list\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        self.agents.append(\n            MicroAgent(\n                prompt=PRIME_PROMPT,\n                name=PRIME_NAME,\n                weight=PRIME_AGENT_WEIGHT,\n                prime=True,\n                prime_agent=True,\n                openai_api=self.openai_wrapper,\n                agent_persistence_manager=self.agent_persistence,\n            )\n        )\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        # Create prime agent\n        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n        )\n\n        # Add prime agent to list\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            name=PRIME_NAME,\n            prompt=PRIME_PROMPT,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            prime_agent=True,\n            persistence=self.agent_persistence\n        )\n        prime_agent.start()\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is not None:\n            return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is not None:\n            return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is None:\n            return None\n        return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is not None:\n            return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is None:\n            return None\n        return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is None:\n            return None\n        return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n\n        if serialized_agent is None:\n            return None\n\n        return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is not None:\n            return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n        return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is not None:\n            return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n        return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is not None:\n            agent = AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n            return agent\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is not None:\n            return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n\n        return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n\n        if serialized_agent:\n            return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite(1000)\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is not None:\n            return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "        serialized_agent = self.persistence.load_agent(agent.id)\n\n        if serialized_agent is not None:\n            agent = AgentSerializer.deserialize(serialized_agent, agent.lifecycle, agent.openai_wrapper)\n\n        return agent"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is not None:\n            agent = AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n            return agent\n        return None\n\n    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        serialized_agents = self.persistence.load_all_agents()\n        agents = []\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n            agents.append(agent)\n        return agents\n\n    def load_all_agents_for_purpose(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agents = self.persistence.load_all_agents_for_purpose(purpose)\n        agents = []\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n            agents.append(agent)\n        return agents\n\n    def load_all_agents_for_purpose_and_lifecycle(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agents = self.persistence.load_all_agents_for_purpose_and_lifecycle(purpose, agent_lifecycle)\n        agents = []\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n            agents.append(agent)\n        return agents\n\n    def load_all_agents_for_purpose_and_lifecycle_and_agent_type(self, purpose, agent_lifecycle, agent_type, openai_wrapper):\n        serialized_agents = self.persistence.load_all_agents_for_purpose_and_lifecycle"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite(return_copy=True)\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads an agent with a specified purpose from the database. If an agent with the given purpose is found, it is deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param purpose: str, The purpose of the agent to be loaded. It is used to identify the agent in the database.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: An instance of the deserialized agent if found, otherwise None.\n        \"\"\"\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is None:\n            return None\n\n        return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is not None:\n            agent = AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n            return agent\n        else:\n            return None\n\n    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        serialized_agents = self.persistence.load_all_agents()\n        agents = []\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n            agents.append(agent)\n        return agents\n\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is not None:\n            return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n        else:\n            return None\n\n\n    def save_and_load_agent(self, agent):\n        \"\"\"\n        Serialize and save the agent state if it is a working agent and not a prime agent.\n        Then, load the agent from the database.\n        \"\"\"\n\n        self.save_agent(agent)\n        return self.load_agent(agent.purpose, agent.agent_lifecycle, agent.openai_wrapper)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "        def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n            serialized_agent = self.persistence.load_agent(purpose)\n            if serialized_agent is not None:\n                return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n            return None\n\n        \"\"\"\n        Loads all agents from the database. If agents with the given purpose are found, they are deserialized and returned in a list; otherwise, an empty list is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param purpose: str, The purpose of the agents to be loaded. It is used to identify the agents in the database.\n        :param agent_lifecycle: The lifecycle state of the agents. It is passed to the deserializer to properly initialize the agents.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agents with OpenAI functionalities.\n        :return: A list of the deserialized agents if found, otherwise an empty list.\n        \"\"\"\n\n        def load_agents(self, purpose, agent_lifecycle, openai_wrapper):\n            serialized_agents = self.persistence.load_agents(purpose)\n            if serialized_agents is not None:\n                return [AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper) for serialized_agent in serialized_agents]\n            return []\n\n        \"\"\"\n        Loads the best agent with the given purpose from the database. If an agent with the given purpose is found, it is deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param purpose: str, The purpose of the agent to be loaded. It is used to identify the agent in the database.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "        # @memoize_to_sqlite(self.persistence, \"load_agent\")\n        def load_agent(purpose, agent_lifecycle, openai_wrapper):\n            serialized_agent = self.persistence.load_agent(purpose)\n            if serialized_agent is None:\n                return None\n\n            return AgentSerializer.deserialize(\n                serialized_agent, agent_lifecycle, openai_wrapper\n            )\n\n        return load_agent(\n            agent.purpose, agent.lifecycle, agent.openai_wrapper\n        )\n\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        serialized_agents = self.persistence.fetch_all_agents()\n        agents = []\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            agents.append(agent)\n\n        return agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        serialized_agents = self.persistence.fetch_all_agents()\n        agents = []\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            agents.append(agent)\n        return agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    @memoize_to_sqlite\n    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads all agents from the database and returns a list of these agents if they are successfully loaded. Each agent is loaded based on its purpose, utilizing the provided agent lifecycle and OpenAI wrapper for the loading process.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param agent_lifecycle: The lifecycle manager for agents, used to manage the state and transitions of an agent throughout its lifecycle.\n        :param openai_wrapper: An interface or wrapper for OpenAI functionalities, used to interact with OpenAI services or models in the process of loading an agent.\n        :return: list. A list of agents that have been successfully loaded from the database.\n        \"\"\"\n        serialized_agents = self.persistence.fetch_all_agents()\n        agents = []\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            agents.append(agent)\n        return agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        serialized_agents = self.persistence.fetch_all_agents()\n        if serialized_agents:\n            return [\n                AgentSerializer.from_dict(\n                    serialized_agent, agent_lifecycle, openai_wrapper\n                )\n                for serialized_agent in serialized_agents\n            ]\n\n        return []"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        serialized_agents = self.persistence.fetch_all_agents()\n        agents = []\n        for serialized_agent in serialized_agents:\n            agents.append(\n                AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper))\n\n        return agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    @memoize_to_sqlite\n    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        serialized_agents = self.persistence.fetch_all_agents()\n        if serialized_agents:\n            agents = []\n            for serialized_agent in serialized_agents:\n                agents.append(AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper))\n            return agents\n\n        return []"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        agents = []\n        for serialized_agent in self.persistence.fetch_all_agents():\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            agents.append(agent)\n\n        return agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    def load_agents(self, agent_lifecycle, openai_wrapper):\n        serialized_agents = self.persistence.fetch_all_agents()\n        agents = []\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            agents.append(agent)\n        return agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    @memoize_to_sqlite\n    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Load all agents from the database and return a list of these agents if they are successfully loaded. Each agent is loaded based on its purpose, utilizing the provided agent lifecycle and OpenAI wrapper for the loading process.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param agent_lifecycle: The lifecycle manager for agents, used to manage the state and transitions of an agent throughout its lifecycle.\n        :param openai_wrapper: An interface or wrapper for OpenAI functionalities, used to interact with OpenAI services or models in the process of loading an agent.\n        :return: list. A list of agents that have been successfully loaded from the database.\n        \"\"\"\n\n        serialized_agents = self.persistence.fetch_all_agents()\n        agents = []\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if agent:\n                agents.append(agent)\n\n        return agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        serialized_agents = self.persistence.fetch_all_agents()\n        if serialized_agents:\n            return [\n                AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n                for serialized_agent in serialized_agents\n            ]\n\n        return []\n\n    def load_all_agents_for_purpose(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agents = self.persistence.fetch_all_agents_for_purpose(purpose)\n        if serialized_agents:\n            return [\n                AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n                for serialized_agent in serialized_agents\n            ]\n\n        return []\n\n    def load_all_agents_for_purpose_and_state(\n        self, purpose, state, agent_lifecycle, openai_wrapper\n    ):\n        serialized_agents = self.persistence.fetch_all_agents_for_purpose_and_state(\n            purpose, state\n        )\n        if serialized_agents:\n            return [\n                AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n                for serialized_agent in serialized_agents\n            ]\n\n        return []"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    @memoize_to_sqlite\n    def load_agents(self, agent_lifecycle, openai_wrapper):\n        serialized_agents = self.persistence.fetch_all_agents()\n        agents = []\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            agents.append(agent)\n\n        return agents\n\n    def remove_all_agents(self):\n        \"\"\"\n        Remove all agents from the database.\n        \"\"\"\n        self.persistence.remove_all_agents()"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads all agents from the database and returns a list of these agents if they are successfully loaded. Each agent is loaded based on its purpose, utilizing the provided agent lifecycle and OpenAI wrapper for the loading process.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param agent_lifecycle: The lifecycle manager for agents, used to manage the state and transitions of an agent throughout its lifecycle.\n        :param openai_wrapper: An interface or wrapper for OpenAI functionalities, used to interact with OpenAI services or models in the process of loading an agent.\n        :return: list. A list of agents that have been successfully loaded from the database.\n        \"\"\"\n        serialized_agents = self.persistence.fetch_all_agents()\n        loaded_agents = []\n        for serialized_agent in serialized_agents:\n            loaded_agents.append(AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper))\n        return loaded_agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    @memoize_to_sqlite\n    def load_agents(self, agent_lifecycle, openai_wrapper):\n        serialized_agents = self.persistence.fetch_all_agents()\n        agents = []\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            agents.append(agent)\n\n        return agents\n\n    def remove_all_agents(self):\n        self.persistence.remove_all_agents()"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        serialized_agents = self.persistence.fetch_all_agents()\n\n        agents = []\n\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            agents.append(agent)\n\n        return agents\n\n    def load_all_agents_with_purpose(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agents = self.persistence.fetch_all_agents_with_purpose(purpose)\n\n        agents = []\n\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            agents.append(agent)\n\n        return agents\n\n    def load_all_agents_with_purpose_and_working(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agents = self.persistence.fetch_all_agents_with_purpose_and_working(purpose)\n\n        agents = []\n\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            agents.append(agent)\n\n        return agents\n\n    def load_all_agents_with_purpose_and_working_and_not_prime(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agents = self.persistence.fetch_all_agents_with_purpose_and_working_and_not_prime(purpose)\n\n        agents = []\n\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            agents.append(agent)\n\n        return agents\n\n    def load_all_agents_with_purpose_and_working"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        serialized_agents = self.persistence.fetch_all_agents()\n        agents = []\n        for serialized_agent in serialized_agents:\n            try:\n                agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n                agents.append(agent)\n            except:\n                print(\"Could not load agent.\")\n        return agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        serialized_agents = self.persistence.fetch_all_agents()\n        loaded_agents = []\n        for serialized_agent in serialized_agents:\n            try:\n                loaded_agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n                loaded_agents.append(loaded_agent)\n            except Exception as e:\n                print(f\"Failed to load agent: {e}\")\n        return loaded_agents\n\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        serialized_agents = self.persistence.fetch_all_agents()\n        agents = []\n        for serialized_agent in serialized_agents:\n            try:\n                agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n                agents.append(agent)\n            except Exception as e:\n                print(f\"Error loading agent with id {serialized_agent['id']}\")\n                print(e)\n\n        return agents\n\n    def load_all_agents_with_purpose(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agents = self.persistence.fetch_all_agents_with_purpose(purpose)\n        agents = []\n        for serialized_agent in serialized_agents:\n            try:\n                agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n                agents.append(agent)\n            except Exception as e:\n                print(f\"Error loading agent with id {serialized_agent['id']}\")\n                print(e)\n\n        return agents\n\n    def load_all_agents_with_purpose_and_state(self, purpose, state, agent_lifecycle, openai_wrapper):\n        serialized_agents = self.persistence.fetch_all_agents_with_purpose_and_state(purpose, state)\n        agents = []\n        for serialized_agent in serialized_agents:\n            try:\n                agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n                agents.append(agent)\n            except Exception as e:\n                print(f\"Error loading agent with id {serialized_agent['id']}\")\n                print(e)\n\n        return agents\n\n    def load_all_agents_with_purpose_and_state_and_not_prime(self, purpose, state, agent_lifecycle, openai_wrapper):\n        serialized_"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        serialized_agents = self.persistence.fetch_all_agents()\n        agents = []\n        for serialized_agent in serialized_agents:\n            agents.append(\n                AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper))\n\n        return agents\n\n    def save_agent_state(self, agent):\n        \"\"\"\n        Serialize and save the agent state if it is a working agent and not a prime agent.\n        \"\"\"\n        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(serialized_agent)\n\n    def load_agent_state(self, purpose, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Load an agent with the given purpose from the database.\n        \"\"\"\n        serialized_agent = self.persistence.fetch_agent(purpose)\n        if serialized_agent:\n            return AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n\n        return None\n\n    def load_all_agent_states(self, agent_lifecycle, openai_wrapper):\n        serialized_agents = self.persistence.fetch_all_agents()\n        agents = []\n        for serialized_agent in serialized_agents:\n            agents.append(\n                AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper))\n\n        return agents\n\n    def load_agent_states_from_purposes(self, purposes, agent_lifecycle, openai_wrapper):\n        serialized_agents = self.persistence.fetch_agents_from_purposes(purposes)\n        agents = []\n        for serialized_agent in serialized_agents:\n            agents.append(\n                AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper))\n\n        return agents\n\n    def load_all_"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        agents = []\n        serialized_agents = self.persistence.fetch_all_agents()\n        for serialized_agent in serialized_agents:\n            try:\n                agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n                agents.append(agent)\n            except Exception as e:\n                print(e)\n\n        return agents\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        serialized_agents = self.persistence.fetch_all_agents()\n        agents = []\n        for serialized_agent in serialized_agents:\n            try:\n                agents.append(AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper))\n            except Exception as e:\n                print(f\"Failed to load agent {serialized_agent['id']}. Reason: {e}\")\n\n        return agents\n\n    def save_agent_response(self, agent_response):\n        \"\"\"\n        Save the agent response in the database.\n        \"\"\"\n        self.persistence.save_agent_response(agent_response)\n\n    def load_agent_response(self, agent_id, prompt):\n        \"\"\"\n        Load the agent response from the database.\n        \"\"\"\n        return self.persistence.fetch_agent_response(agent_id, prompt)\n\n    def load_all_agent_responses(self, agent_id):\n        \"\"\"\n        Load all agent responses from the database.\n        \"\"\"\n        return self.persistence.fetch_all_agent_responses(agent_id)\n\n    def remove_agent_response(self, agent_response):\n        \"\"\"\n        Remove the agent response from the database.\n        \"\"\"\n        self.persistence.remove_agent_response(agent_response)\n\n    def remove_all_agent_responses(self, agent_id):\n        \"\"\"\n        Remove all agent responses from the database.\n        \"\"\"\n        self.persistence.remove_all_agent_responses(agent_id)\n\n    def save_agent_feedback(self, agent_feedback):\n        \"\"\"\n        Save the agent feedback in the database.\n        \"\"\"\n        self.persistence.save_agent_feedback(agent_feedback)\n\n    def load_agent_feedback(self, agent_id, prompt):\n        \"\"\"\n        Load the agent feedback from the database.\n        \"\"\"\n        return self.persistence.fetch_agent_feedback(agent_id, prompt)\n\n    def load_"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(\"Error saving agent: %s\", e)\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(e)\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error saving agent: {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error while saving agent: {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error while saving agent {agent.id}: {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error saving agent: {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as error:\n            logger.error(f\"Error saving agent {agent.name} - {error}\")\n            raise error\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save(agent)\n        except Exception as e:\n            logger.exception(e)\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error saving agent {agent.id}. Error: {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(e)\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error saving agent {agent.id} with purpose {agent.purpose} and depth {agent.depth}: {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save(agent)\n        except Exception as e:\n            logger.exception(f\"Error saving agent {agent.id} to persistence.\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error saving agent {agent.name} with id {agent.id} and purpose {agent.purpose}.\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Exception occurred during saving of agent {agent.name} with id {agent.id}.\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(\"Error saving agent %s\", agent.name)\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error saving agent: {agent.name}\")\n            logger.exception(e)\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(e)\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error while saving agent: {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error saving agent {agent.name} to persistence layer. Error: {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error saving agent {agent.name} with id {agent.id}.\", exc_info=True)\n            raise e\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        # Cleanup agents\n        self.cleanup_agents()\n\n        # Return agents\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        # Cleanup\n        self.cleanup_agents()\n        # Return\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.agent_lifecycle.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT.format(goal, sample_input)\n        prompt = prompt + \"\\n\" + PROMPT_ENGINEERING_TEMPLATE\n        prompt = prompt + \"\\n\" + EXAMPLES\n\n        return prompt"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT.format(goal=goal, example=sample_input)\n        prompt += PROMPT_ENGINEERING_TEMPLATE.format(goal=goal, example=sample_input)\n        prompt += EXAMPLES\n\n        return prompt"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT.format(\n            PROMPT_ENGINEERING_TEMPLATE,\n            goal,\n            sample_input,\n            EXAMPLES\n        )\n        try:\n            return self.openai_wrapper.get_completion(prompt)\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\"\n"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = f\"{EXAMPLES}\\n{goal}\\n{sample_input}\\n{PROMPT_ENGINEERING_SYSTEM_PROMPT}\\n\"\n        try:\n            chat_completion = self.openai_wrapper.get_completion(prompt)\n            return f\"{prompt}{chat_completion}\"\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\"\n"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = f\"{goal}\\n\\n\"\n        prompt += f\"{EXAMPLES}\\n\\n\"\n        prompt += f\"{sample_input}\\n\\n\"\n        prompt += f\"{PRIMITIVE_TEMPLATE}\\n\\n\"\n        prompt += f\"{ENGINEERING_TEMPLATE}\\n\\n\"\n        prompt += f\"{ENGINEERING_SYSTEM_PROMPT}\\n\\n\"\n\n        try:\n            return self.openai_wrapper.get_completion(prompt)\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT.format(\n            goal=goal,\n            sample_input=sample_input,\n            examples=EXAMPLES\n        )\n        try:\n            chat_completion = self.openai_wrapper.complete(prompt)\n            return PROMPT_ENGINEERING_TEMPLATE.format(\n                goal=goal,\n                sample_input=sample_input,\n                examples=chat_completion\n            )\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\"\n\n"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT.format(goal=goal, sample_input=sample_input)\n        prompt = prompt.replace(\"  \", \" \")\n        prompt = prompt.replace(\" ,\", \",\")\n        prompt = prompt.replace(\" .\", \".\")\n        prompt = prompt.replace(\" ?\", \"?\")\n        prompt = prompt.replace(\" !\", \"!\")\n        prompt = prompt.replace(\" :\", \":\")\n        prompt = prompt.replace(\" ;\", \";\")\n        prompt = prompt.replace(\" -\", \"-\")\n        prompt = prompt.replace(\" '\", \"'\")\n        prompt = prompt.replace(\" n't\", \"n't\")\n        prompt = prompt.replace(\" 's\", \"'s\")\n        prompt = prompt.replace(\" 'm\", \"'m\")\n        prompt = prompt.replace(\" 're\", \"'re\")\n        prompt = prompt.replace(\" 'd\", \"'d\")\n        prompt = prompt.replace(\" 'll\", \"'ll\")\n        prompt = prompt.replace(\" 've\", \"'ve\")\n        prompt = prompt.replace(\" 'm\", \"'m\")\n        prompt = prompt.replace(\" 're\", \"'re\")\n        prompt = prompt.replace(\" 'd\", \"'d\")\n        prompt = prompt.replace(\" 'll\", \"'ll\")\n        prompt = prompt.replace(\" 've\", \"'ve\")\n        prompt = prompt.replace(\" 'm\", \"'m\")\n        prompt = prompt.replace(\" 're\", \"'re\")\n        prompt = prompt.replace(\" 'd\", \"'d\")\n        prompt = prompt.replace(\" 'll\", \"'ll\")\n        prompt = prompt.replace(\" 've\", \"'ve\")\n        prompt = prompt.replace(\" 'm\", \"'m\")\n        prompt = prompt.replace(\" 're\", \"'re\")\n        prompt = prompt.replace(\" 'd\", \"'d\")\n        prompt = prompt.replace(\" 'll\", \"'ll\")\n        prompt = prompt.replace(\" 've\", \"'ve\")\n        prompt = prompt.replace(\" 'm\", \"'m\")\n        prompt = prompt.replace(\" 're\", \"'re\")\n        prompt = prompt.replace(\" 'd\", \"'d\")"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT.format(\n            EXAMPLES,\n            goal,\n            sample_input\n        )\n        try:\n            response = self.openai_wrapper.complete(prompt)\n            return response.choices[0].text\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = \"\"\n\n        try:\n            prompt = f\"{goal} {EXAMPLES}\\n\\n\"\n            prompt += f\"{PRIMITIVE_PROMPT}\\n\\n\"\n            prompt += f\"{PRIMITIVE_NAME}\\n\\n\"\n            prompt += f\"{PRIM_EXAMPLES}\\n\\n\"\n            prompt += f\"{PRIM_PROMPT}\\n\\n\"\n            prompt += f\"{PRIM_NAME}\\n\\n\"\n            prompt += f\"{PRIM_EXAMPLES}\\n\\n\"\n            prompt += f\"{PRIM_PROMPT}\\n\\n\"\n            prompt += f\"{PRIM_NAME}\\n\\n\"\n            prompt += f\"{PRIM_EXAMPLES}\\n\\n\"\n            prompt += f\"{PRIM_PROMPT}\\n\\n\"\n            prompt += f\"{PRIM_NAME}\\n\\n\"\n            prompt += f\"{PRIM_EXAMPLES}\\n\\n\"\n            prompt += f\"{PRIM_PROMPT}\\n\\n\"\n            prompt += f\"{PRIM_NAME}\\n\\n\"\n            prompt += f\"{PRIM_EXAMPLES}\\n\\n\"\n            prompt += f\"{PRIM_PROMPT}\\n\\n\"\n            prompt += f\"{PRIM_NAME}\\n\\n\"\n            prompt += f\"{PRIM_EXAMPLES}\\n\\n\"\n            prompt += f\"{PRIM_PROMPT}\\n\\n\"\n            prompt += f\"{PRIM_NAME}\\n\\n\"\n            prompt += f\"{PRIM_EXAMPLES}\\n\\n\"\n            prompt += f\"{PRIM_PROMPT}\\n\\n\"\n            prompt += f\"{PRIM_NAME}\\n\\n\"\n            prompt += f\"{PRIM_EXAMPLES}\\n\\n\"\n            prompt += f\"{PRIM_PROMPT}\\n\\n\"\n            prompt += f\"{PRIM_NAME}\\n\\n\"\n            prompt += f\"{PRIM_EXAMPLES}\\n\\n\"\n           "}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = \"\"\n        try:\n            prompt = self._generate_prompt(goal, sample_input)\n            prompt = self._generate_chat_completion(prompt)\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n\n        return prompt\n"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT.format(goal, sample_input, EXAMPLES)\n        prompt_completion = self.openai_wrapper.complete(prompt)\n\n        if prompt_completion.status_code != 200:\n            logger.error(f\"Error in generating prompt: {prompt_completion.status_code}\")\n            return \"\"\n\n        prompt = PROMPT_ENGINEERING_TEMPLATE.format(prompt_completion.text, goal, sample_input)\n        prompt_completion = self.openai_wrapper.complete(prompt)\n\n        if prompt_completion.status_code != 200:\n            logger.error(f\"Error in generating prompt: {prompt_completion.status_code}\")\n            return \"\"\n\n        return prompt_completion.text"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt_engineering_system_prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT.format(goal, sample_input)\n        prompt_engineering_template = PROMPT_ENGINEERING_TEMPLATE.format(goal, sample_input)\n        prompt_examples = EXAMPLES.format(goal, sample_input)\n\n        prompt = f\"{prompt_engineering_system_prompt}\\n{prompt_engineering_template}\\n{prompt_examples}\"\n        try:\n            return self.openai_wrapper.get_completion(prompt, engine=\"davinci\", temperature=0.5, max_tokens=200, top_p=1.0, frequency_penalty=0.5, presence_penalty=0.5, stop=[\"\\n\"])\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = self._generate_llm_prompt_from_template(goal, sample_input)\n            prompt = self.openai_wrapper.get_completion(prompt)\n            return prompt\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\"\n"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        # Generate the prompt for the LLM\n        prompt = self._generate_llm_prompt_from_template(goal, sample_input)\n        # Get the chat completion from the LLM\n        try:\n            chat_completion = self.openai_wrapper.get_completion(prompt)\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\"\n        # Return the chat completion\n        return chat_completion\n"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT.format(goal, sample_input)\n        prompt += PROMPT_ENGINEERING_TEMPLATE\n        prompt += EXAMPLES\n\n        try:\n            prompt = self.openai_wrapper.get_completion(prompt, engine=\"davinci-codex\")\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            prompt = \"\"\n\n        return prompt\n"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT.format(goal, sample_input)\n        prompt = prompt.replace(\"\\n\\n\", \"\\n\")\n        prompt = prompt.replace(\"\\n\\n\", \"\\n\")\n\n        try:\n            chat_completion = self.openai_wrapper.get_completion(prompt, engine=\"davinci\", temperature=0.7, max_tokens=100, top_p=1, frequency_penalty=0.7, presence_penalty=0.7, stop=[\"\\n\\n\", \"\\n---\\n\"])\n            chat_completion = chat_completion.replace(\"\\n\\n\", \"\\n\")\n            chat_completion = chat_completion.replace(\"\\n\\n\", \"\\n\")\n            return chat_completion\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = f\"{goal}\\n{sample_input}\\n\"\n        prompt += PROMPT_ENGINEERING_SYSTEM_PROMPT\n        prompt += PROMPT_ENGINEERING_TEMPLATE\n        prompt += EXAMPLES\n\n        try:\n            response = self.openai_wrapper.get_completion(prompt, engine=\"davinci-codex\")\n            return response\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\"\n\n"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT.format(goal=goal, example=sample_input, prompt_template=PROMPT_ENGINEERING_TEMPLATE)\n        try:\n            chat_completion = self.openai_wrapper.get_completion(prompt)\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\"\n        return chat_completion\n"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = self._generate_llm_prompt_with_goal(goal, sample_input)\n        prompt_completion = self.openai_wrapper.get_completion(prompt)\n        if prompt_completion:\n            return prompt + prompt_completion\n        else:\n            logger.error(\"Error in generating prompt with OpenAI wrapper.\")\n            return \"\"\n"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT.format(goal, sample_input)\n        prompt += \"\\n\" + PROMPT_ENGINEERING_TEMPLATE\n        prompt += \"\\n\" + EXAMPLES\n        prompt += \"\\n\" + goal\n        prompt += \"\\n\" + sample_input\n        prompt += \"\\n\" + \"Q: What is the purpose of this system?\"\n        prompt += \"\\n\" + \"A: \"\n\n        try:\n            prompt = self.openai_wrapper.get_completion(prompt)\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            prompt = \"\"\n\n        return prompt\n\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"\"\"\n                INSERT INTO agents (id, purpose, data)\n                VALUES (?, ?, ?)\n                ON CONFLICT (id) DO UPDATE SET data = ?\n            \"\"\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict), json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"\"\"\n                INSERT OR REPLACE INTO agents (id, purpose, data)\n                VALUES (?, ?, ?)\n            \"\"\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"\"\"\n                INSERT OR REPLACE INTO agents (id, purpose, data)\n                VALUES (:id, :purpose, :data)\n            \"\"\", agent_dict)\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"\"\"\n                INSERT INTO agents (id, purpose, data) VALUES (?, ?, ?)\n                ON CONFLICT (id) DO UPDATE SET data = ?\n            \"\"\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict), json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"\"\"\n                INSERT INTO agents\n                (id, purpose, data)\n                VALUES (?, ?, ?)\n                ON CONFLICT(id) DO UPDATE SET data=?\n            \"\"\", (agent_dict[\"id\"], agent_dict[\"purpose\"], json.dumps(agent_dict), json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"\"\"\n                INSERT INTO agents (\n                    id,\n                    purpose,\n                    data\n                ) VALUES (\n                    ?, ?, ?\n                )\n                ON CONFLICT(id) DO UPDATE SET\n                    purpose = excluded.purpose,\n                    data = excluded.data\n            \"\"\", (agent_dict[\"id\"], agent_dict[\"purpose\"], json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"\"\"\n                INSERT OR REPLACE INTO agents (id, purpose, data)\n                VALUES (?, ?, ?)\n            \"\"\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))\n\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"REPLACE INTO agents VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"\"\"\n                INSERT INTO agents (id, purpose, data)\n                VALUES (?, ?, ?)\n                ON CONFLICT (id) DO UPDATE SET data = excluded.data\n            \"\"\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"\"\"\n                INSERT INTO agents (id, purpose, data)\n                VALUES (?, ?, ?)\n                ON CONFLICT(id) DO UPDATE SET data = ?\n            \"\"\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict), json.dumps(agent_dict)))\n\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"\"\"\n                INSERT INTO agents (id, purpose, data) VALUES (?, ?, ?)\n                ON CONFLICT(id) DO UPDATE SET data = ?\n            \"\"\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict), json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"\"\"\n                INSERT INTO agents (id, purpose, data)\n                VALUES (?, ?, ?)\n                ON CONFLICT (id) DO UPDATE SET data=excluded.data\n            \"\"\", (agent_dict[\"id\"], agent_dict[\"purpose\"], json.dumps(agent_dict)))\n\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"\"\"\n                INSERT INTO agents (id, purpose, data)\n                VALUES (?, ?, ?)\n                ON CONFLICT(id) DO UPDATE SET data = ?\n            \"\"\", (\n                agent_dict['id'],\n                agent_dict['purpose'],\n                json.dumps(agent_dict),\n                json.dumps(agent_dict),\n            ))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"\"\"\n                INSERT INTO agents (id, purpose, data)\n                VALUES (:id, :purpose, :data)\n                ON CONFLICT(id) DO UPDATE SET data=:data\n            \"\"\", agent_dict)\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"INSERT OR REPLACE INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict[\"id\"], agent_dict[\"purpose\"], json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"INSERT OR REPLACE INTO agents VALUES (?, ?, ?)\", (agent_dict[\"id\"], agent_dict[\"purpose\"], json.dumps(agent_dict)))\n\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        # Serialize the agent's data to a JSON string.\n        agent_data = json.dumps(agent_dict)\n\n        # Try to update the existing record.\n        try:\n            with sqlite3.connect(self.filename) as conn:\n                conn.execute(\"UPDATE agents SET data = ? WHERE id = ?\", (agent_data, agent_dict['id']))\n        # If the record doesn't exist, insert a new record.\n        except sqlite3.OperationalError:\n            with sqlite3.connect(self.filename) as conn:\n                conn.execute(\"INSERT INTO agents VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], agent_data))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"\"\"\n                INSERT INTO agents (id, purpose, data)\n                VALUES (?, ?, ?)\n                ON CONFLICT(id) DO UPDATE SET purpose=excluded.purpose, data=excluded.data\n            \"\"\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict['data'])))\n\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        # Serialize the agent's information into a JSON string.\n        serialized_agent_data = json.dumps(agent_dict)\n\n        # Connect to the database.\n        with sqlite3.connect(self.filename) as conn:\n            # Insert or update the agent's record in the database.\n            conn.execute(\"\"\"\n                INSERT INTO agents (id, purpose, data)\n                VALUES (?, ?, ?)\n                ON CONFLICT (id) DO UPDATE SET data = ?\n            \"\"\", (agent_dict['id'], agent_dict['purpose'], serialized_agent_data, serialized_agent_data))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        # Convert the agent dictionary into a JSON string.\n        json_agent_dict = json.dumps(agent_dict)\n\n        # Create a tuple containing the agent's ID and JSON string.\n        agent_tuple = (agent_dict[\"id\"], agent_dict[\"purpose\"], json_agent_dict)\n\n        # Open a connection to the SQLite database.\n        with sqlite3.connect(self.filename) as conn:\n            # Execute the SQL command to insert or update the agent's record in the database.\n            conn.execute(\"\"\"\n                INSERT INTO agents (id, purpose, data)\n                VALUES (?, ?, ?)\n                ON CONFLICT(id) DO UPDATE SET data=?\n            \"\"\", agent_tuple * 2)\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE id = ?\", (purpose,))\n            result = cursor.fetchone()\n            if result is None:\n                return None\n            else:\n                return json.loads(result[0])"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT data FROM agents WHERE id = ?\", (purpose,))\n            result = cursor.fetchone()\n            if result is None:\n                return None\n            return json.loads(result[0])"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE id = ?\", (purpose,))\n            data = cursor.fetchone()\n            if data is None:\n                return None\n            else:\n                return json.loads(data[0])"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE id = ?\", (purpose,))\n            row = cursor.fetchone()\n            if row is None:\n                return None\n            return json.loads(row[0])"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE id = ?\", (purpose,))\n            data = cursor.fetchone()\n            if data:\n                return json.loads(data[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE id = ?\", (purpose,))\n            result = cursor.fetchone()\n            if result:\n                return json.loads(result[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE id = ?\", (purpose,))\n            data = cursor.fetchone()\n            if data is None:\n                return None\n            return json.loads(data[0])"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT data FROM agents WHERE id = ?\", (purpose,))\n            data = cursor.fetchone()\n            if data is not None:\n                return json.loads(data[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE id = ?\", (purpose,))\n            data = cursor.fetchone()\n            if data is None:\n                return None\n            else:\n                return json.loads(data[0])"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE id = ?\", (purpose,))\n            result = cursor.fetchone()\n            if result is not None:\n                return json.loads(result[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\n                \"SELECT data FROM agents WHERE id = ?\",\n                (purpose,)\n            )\n            data = cursor.fetchone()\n            if data:\n                return json.loads(data[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE id = ?\", (purpose,))\n            result = cursor.fetchone()\n            if result is None:\n                return None\n            else:\n                return json.loads(result[0])"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE id = ?\", (purpose,))\n            agent_data = cursor.fetchone()\n            if agent_data is None:\n                return None\n            return json.loads(agent_data[0])"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE id = ?\", (purpose,))\n            row = cursor.fetchone()\n\n            if row is None:\n                return None\n\n            return json.loads(row[0])"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\n                \"SELECT data FROM agents WHERE id = ?\", (purpose,)\n            )\n            data = cursor.fetchone()\n            if data is None:\n                return None\n            else:\n                return json.loads(data[0])"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT data FROM agents WHERE id = ?\", (purpose,))\n            data = cursor.fetchone()\n            if data:\n                return json.loads(data[0])\n            else:\n                return None\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE id = ?\", (purpose,))\n            data = cursor.fetchone()\n            if data is not None:\n                return json.loads(data[0])\n            else:\n                return None\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT data FROM agents WHERE id = ?\", (purpose,))\n            result = cursor.fetchone()\n            if result is None:\n                return None\n            else:\n                return json.loads(result[0])\n\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\n                \"SELECT data FROM agents WHERE id = ?\",\n                (purpose,)\n            )\n            result = cursor.fetchone()\n            if result is None:\n                return None\n            else:\n                return json.loads(result[0])\n\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\n                \"SELECT data FROM agents WHERE id = ?\",\n                (purpose,)\n            )\n            result = cursor.fetchone()\n            if result is None:\n                return None\n            return json.loads(result[0])\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]\n\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [purpose[0] for purpose in cursor.fetchall()]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]\n\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [purpose[0] for purpose in cursor.fetchall()]\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            return [row[0] for row in cursor.fetchall()]\n\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        with self.connection:\n            cursor = self.connection.cursor()\n            cursor.execute(\"SELECT result FROM cache WHERE hash=?\", (arg_hash,))\n            result_set = cursor.fetchone()\n            if result_set is None:\n                return None\n            return json.loads(result_set[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"SELECT result FROM cache WHERE hash=?\",\n            (arg_hash,),\n        )\n        result = cursor.fetchone()\n        if result is None:\n            return None\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash=?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result is None:\n            return None\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash = ?\", (arg_hash,))\n        row = cursor.fetchone()\n        cursor.close()\n\n        if row is None:\n            return None\n\n        return json.loads(row[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"SELECT result FROM cache WHERE hash=?\", (arg_hash,)\n        )\n        result = cursor.fetchone()\n        if result is None:\n            return None\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"SELECT result FROM cache WHERE hash=?\",\n            (arg_hash,)\n        )\n        result = cursor.fetchone()\n        if result is None:\n            return None\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash = ?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result is None:\n            return None\n\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"SELECT result FROM cache WHERE hash=?\", (arg_hash,)\n        )\n        row = cursor.fetchone()\n        cursor.close()\n        if row is None:\n            return None\n        return json.loads(row[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash=?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result is None:\n            return None\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash=?\", (arg_hash,))\n        row = cursor.fetchone()\n        if row is None:\n            return None\n        return json.loads(row[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cur = self.connection.cursor()\n        cur.execute(\"SELECT result FROM cache WHERE hash=?\", (arg_hash,))\n        result = cur.fetchone()\n        cur.close()\n\n        if result is None:\n            return None\n\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash=?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result is None:\n            return None\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        # Fetch the result from the cache\n        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash = ?\", (arg_hash,))\n        result_row = cursor.fetchone()\n\n        # If the result is found, load it from JSON format and return it\n        if result_row is not None:\n            result = json.loads(result_row[0])\n            return result\n\n        return None\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash=?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result is None:\n            return None\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"SELECT result FROM cache WHERE hash = ?\",\n            (arg_hash,),\n        )\n        result = cursor.fetchone()\n        if result is None:\n            return None\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n        )\n        row = cursor.fetchone()\n        if row is None:\n            return None\n        return json.loads(row[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"SELECT result FROM cache WHERE hash=?\",\n            (arg_hash,),\n        )\n        result = cursor.fetchone()\n        if result is not None:\n            return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash=?\", (arg_hash,))\n        row = cursor.fetchone()\n        if row is None:\n            return None\n\n        return json.loads(row[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cur = self.connection.cursor()\n        cur.execute(\"SELECT result FROM cache WHERE hash = ?\", (arg_hash,))\n        row = cur.fetchone()\n        if row is None:\n            return None\n\n        return json.loads(row[0])\n\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"SELECT result FROM cache WHERE hash=?\", (arg_hash,)\n        )\n        result = cursor.fetchone()\n        if result is None:\n            return None\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache VALUES (?, ?)\", (arg_hash, json.dumps(result))\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        result_json = json.dumps(result)\n        with self.connection:\n            self.connection.execute(\n                \"INSERT INTO cache VALUES (?, ?)\", (arg_hash, result_json)\n            )"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache VALUES (?, ?)\", (arg_hash, json.dumps(result))\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"INSERT INTO cache VALUES (?, ?)\", (arg_hash, json.dumps(result)))\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        serialized_result = json.dumps(result)\n        with self.connection:\n            self.connection.execute(\n                \"INSERT INTO cache VALUES (?, ?)\", (arg_hash, serialized_result)\n            )"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        serialized_result = json.dumps(result)\n        with self.connection:\n            self.connection.execute(\n                \"INSERT INTO cache VALUES (?, ?)\", (arg_hash, serialized_result)\n            )"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        result_json = json.dumps(result)\n        self.connection.execute(\n            \"INSERT INTO cache VALUES (?, ?)\", (arg_hash, result_json)\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        result_json = json.dumps(result)\n        self.connection.execute(\n            \"INSERT INTO cache VALUES (?, ?)\", (arg_hash, result_json)\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        serialized_result = json.dumps(result)\n        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache VALUES (?, ?)\", (arg_hash, serialized_result)\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        result = json.dumps(result)\n        self.connection.execute(\n            \"INSERT INTO cache VALUES (?, ?)\", (arg_hash, result)\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        serialized_result = json.dumps(result)\n\n        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache VALUES (?, ?)\", (arg_hash, serialized_result)\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        # Serialize the result to JSON\n        result_json = json.dumps(result)\n\n        # Insert a new row into the cache table\n        self.connection.execute(\n            \"INSERT INTO cache VALUES (?, ?)\",\n            (arg_hash, result_json)\n        )\n\n        # Save the changes to disk\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        # Convert the result to JSON format\n        result_json = json.dumps(result)\n\n        # Insert a new row into the 'cache' table\n        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, result_json)\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        # Serialize the result to JSON format\n        result_serialized = json.dumps(result)\n\n        # Insert the result into the cache\n        self.connection.execute(\n            \"INSERT INTO cache VALUES (?, ?)\", (arg_hash, result_serialized)\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()\n\n"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        # Serialize the result to JSON format\n        result_serialized = json.dumps(result)\n\n        # Insert the argument hash and result into the database\n        self.connection.execute(\n            \"INSERT INTO cache VALUES (?, ?)\", (arg_hash, result_serialized)\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        serialized_result = json.dumps(result)\n        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache VALUES (?, ?)\", (arg_hash, serialized_result)\n        )\n        self.connection.commit()\n\n"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        # serialize the result to JSON\n        result_json = json.dumps(result)\n\n        # insert the hash and result into the database\n        with self.connection:\n            cursor = self.connection.cursor()\n            cursor.execute(\n                \"INSERT INTO cache VALUES (?, ?)\",\n                (arg_hash, result_json)\n            )\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update the global configuration parameters with the provided arguments.\n    CONFIG.update(vars(args))\n\n    # Update the global configuration parameters with the provided arguments.\n    CONFIG.update(vars(args))\n\n    # Update the global configuration parameters with the provided arguments.\n    CONFIG.update(vars(args))\n\n    # Update the global configuration parameters with the provided arguments.\n    CONFIG.update(vars(args))\n\n    # Update the global configuration parameters with the provided arguments.\n    CONFIG.update(vars(args))\n\n    # Update the global configuration parameters with the provided arguments.\n    CONFIG.update(vars(args))\n\n    # Update the global configuration parameters with the provided arguments.\n    CONFIG.update(vars(args))\n\n    # Update the global configuration parameters with the provided arguments.\n    CONFIG.update(vars(args))\n\n    # Update the global configuration parameters with the provided arguments.\n    CONFIG.update(vars(args))\n\n    # Update the global configuration parameters with the provided arguments.\n    CONFIG.update(vars(args))\n\n    # Update the global configuration parameters with the provided arguments.\n    CONFIG.update(vars(args))\n\n    # Update the global configuration parameters with the provided arguments.\n    CONFIG.update(vars(args))\n\n    # Update the global configuration parameters with the provided arguments.\n    CONFIG.update(vars(args))\n\n    # Update the global configuration parameters with the provided arguments.\n    CONFIG.update(vars(args))\n\n    # Update the global configuration parameters with the provided arguments.\n    CONFIG.update(vars(args))\n\n    # Update the global configuration parameters with the provided arguments.\n    CONFIG.update(vars(args))\n\n    # Update the global configuration parameters with the provided arguments.\n    CONFIG.update(vars(args))\n\n    # Update the global configuration parameters with the provided arguments.\n    CONFIG.update(vars(args))\n\n    # Update the global configuration parameters with the provided arguments.\n    CONFIG.update(vars(args))\n\n    # Update the global configuration parameters with the provided arguments.\n    CONFIG.update(vars(args))"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments.\n    CONFIG.update(vars(args))\n\n    # Set the quiet mode flag.\n    CONFIG.quiet_mode = quiet_mode\n\n    # Set the quiet mode flag.\n    CONFIG.quiet_mode = quiet_mode\n\n    # Set the quiet mode flag.\n    CONFIG.quiet_mode = quiet_mode\n\n    # Set the quiet mode flag.\n    CONFIG.quiet_mode = quiet_mode\n\n    # Set the quiet mode flag.\n    CONFIG.quiet_mode = quiet_mode\n\n    # Set the quiet mode flag.\n    CONFIG.quiet_mode = quiet_mode\n\n    # Set the quiet mode flag.\n    CONFIG.quiet_mode = quiet_mode\n\n    # Set the quiet mode flag.\n    CONFIG.quiet_mode = quiet_mode\n\n    # Set the quiet mode flag.\n    CONFIG.quiet_mode = quiet_mode\n\n    # Set the quiet mode flag.\n    CONFIG.quiet_mode = quiet_mode\n\n    # Set the quiet mode flag.\n    CONFIG.quiet_mode = quiet_mode\n\n    # Set the quiet mode flag.\n    CONFIG.quiet_mode = quiet_mode\n\n    # Set the quiet mode flag.\n    CONFIG.quiet_mode = quiet_mode\n\n    # Set the quiet mode flag.\n    CONFIG.quiet_mode = quiet_mode\n\n    # Set the quiet mode flag.\n    CONFIG.quiet_mode = quiet_mode\n\n    # Set the quiet mode flag.\n    CONFIG.quiet_mode = quiet_mode\n\n    # Set the quiet mode flag.\n    CONFIG.quiet_mode = quiet_mode\n\n    # Set the quiet mode flag.\n    CONFIG.quiet_mode = quiet_mode\n\n    # Set the quiet mode flag.\n    CONFIG.quiet_mode = quiet_mode\n\n    # Set the quiet mode flag.\n    CONFIG.quiet_mode = quiet_mode\n\n    # Set the quiet mode flag.\n    CONFIG.quiet"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update the global configuration with the provided arguments\n    CONFIG.update(vars(args))\n\n    # If quiet mode is enabled, redirect the standard output to a file\n    if quiet_mode:\n        with open('assets/output.txt', 'w') as f:\n            with redirect_stdout(f):\n                CommandLine.execute()\n    else:\n        CommandLine.execute()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    CONFIG.update(vars(args))\n    CONFIG.update(ARGS)\n\n    # If quiet mode is enabled, redirect the standard output to a file\n    if quiet_mode:\n        if not os.path.exists(CONFIG['record_dir']):\n            os.makedirs(CONFIG['record_dir'])\n        log_file = os.path.join(CONFIG['record_dir'], 'log.txt')\n        with open(log_file, 'w') as f:\n            with redirect_stdout(f):\n                CommandLine(deepcopy(CONFIG)).run()\n    else:\n        CommandLine(deepcopy(CONFIG)).run()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update the global configuration parameters with the provided arguments.\n    CONFIG.update(vars(args))\n\n    # Set the quiet mode flag.\n    CONFIG.quiet_mode = quiet_mode\n\n    # If quiet mode is enabled, redirect the standard output to a file.\n    if quiet_mode:\n        with open(os.path.join(CONFIG.record_dir, 'output.txt'), 'w') as f:\n            with redirect_stdout(f):\n                CommandLine.execute_command_line_process(args)\n    else:\n        CommandLine.execute_command_line_process(args)\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    CONFIG.update(vars(args))\n\n    # If quiet mode is enabled, redirect the standard output to a file\n    if quiet_mode:\n        with open(os.path.join(CONFIG['record_dir'], 'output.txt'), 'w') as f:\n            with redirect_stdout(f):\n                CommandLine.execute()\n    else:\n        CommandLine.execute()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update the global configuration parameters with the provided arguments\n    CONFIG.update(args.__dict__)\n\n    # Create a command line object\n    command_line = CommandLine()\n\n    # Create a list of command line parameters\n    command_line_params = []\n\n    # Add the task parameter\n    command_line_params.append(CommandLineParam(name=\"task\", value=CONFIG['task']))\n\n    # Add the upload files parameter\n    command_line_params.append(CommandLineParam(name=\"upload_files\", value=CONFIG['upload_files']))\n\n    # Add the model parameter\n    command_line_params.append(CommandLineParam(name=\"model\", value=CONFIG['model']))\n\n    # Add the record directory parameter\n    command_line_params.append(CommandLineParam(name=\"record_dir\", value=CONFIG['record_dir']))\n\n    # Add the mode parameter\n    command_line_params.append(CommandLineParam(name=\"mode\", value=CONFIG['mode']))\n\n    # Add the quiet parameter\n    command_line_params.append(CommandLineParam(name=\"quiet\", value=CONFIG['quiet']))\n\n    # Add the max subtask chain length parameter\n    command_line_params.append(CommandLineParam(name=\"max_subtask_chain_length\", value=CONFIG['max_subtask_chain_length']))\n\n    # Add the enable ask human for help parameter\n    command_line_params.append(CommandLineParam(name=\"enable_ask_human_for_help\", value=CONFIG['enable_ask_human_for_help']))\n\n    # Add the max plan refine chain length parameter\n    command_line_params.append(CommandLineParam(name=\"max_plan_refine_chain_length\", value=CONFIG['max_plan_refine_chain_length']))\n\n    # Add the max plan tree depth parameter\n    command_line_params.append(CommandLineParam(name=\"max_plan_tree_depth\", value=CONFIG['max_plan_tree_depth']))\n\n    # Add the max plan tree width parameter\n    command_line_params.append(CommandLineParam(name=\"max_"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update the global configuration parameters with the provided arguments.\n    for key in dir(args):\n        if key.startswith(\"_\"):\n            continue\n        if key == \"config_file\":\n            continue\n        if key == \"quiet\":\n            continue\n        if key == \"upload_files\":\n            continue\n        if key == \"record_dir\":\n            continue\n        if key == \"mode\":\n            continue\n        if key == \"task\":\n            continue\n        if key == \"model\":\n            continue\n        if key == \"max_subtask_chain_length\":\n            continue\n        if key == \"enable_ask_human_for_help\":\n            continue\n        if key == \"max_plan_refine_chain_length\":\n            continue\n        if key == \"max_plan_tree_depth\":\n            continue\n        if key == \"max_plan_tree_width\":\n            continue\n        if key == \"max_retry_times\":\n            continue\n        if key == \"upload_files\":\n            continue\n        if key == \"record_dir\":\n            continue\n        if key == \"mode\":\n            continue\n        if key == \"task\":\n            continue\n        if key == \"model\":\n            continue\n        if key == \"max_subtask_chain_length\":\n            continue\n        if key == \"enable_ask_human_for_help\":\n            continue\n        if key == \"max_plan_refine_chain_length\":\n            continue\n        if key == \"max_plan_tree_depth\":\n            continue\n        if key == \"max_plan_tree_width\":\n            continue\n        if key == \"max_retry_times\":\n            continue\n        if key == \"upload_files\":\n            continue\n        if key == \"record_dir\":\n            continue\n        if key == \"mode\":\n            continue\n        if key == \"task\":\n            continue\n        if key == \"model\":\n            continue\n        if key == \"max_subtask_chain_length\":\n            continue\n        if key == \"enable_ask_human_for_help\":\n            continue\n        if key == \"max_plan_ref"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments.\n    CONFIG.update(vars(args))\n\n    # Redirect the standard output to a file if quiet mode is enabled.\n    if quiet_mode:\n        with open(os.path.join(CONFIG['record_dir'], 'output.txt'), 'w') as f:\n            with redirect_stdout(f):\n                CommandLine(CONFIG).execute()\n    else:\n        CommandLine(CONFIG).execute()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update the global configuration with the provided arguments\n    CONFIG.update(vars(args))\n\n    # If quiet mode is enabled, redirect the standard output to a file\n    if quiet_mode:\n        with open(os.path.join(CONFIG['record_dir'], 'output.txt'), 'w') as f:\n            with redirect_stdout(f):\n                CommandLine(CONFIG).run()\n    else:\n        CommandLine(CONFIG).run()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    CONFIG.update(deepcopy(ARGS))\n    CONFIG.update(vars(args))\n\n    # If quiet mode is enabled, redirect the standard output to a file\n    if quiet_mode:\n        with open(\"output.txt\", \"w\") as f:\n            with redirect_stdout(f):\n                CommandLine.execute_command_line()\n    else:\n        CommandLine.execute_command_line()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update the global configuration parameters with the provided arguments.\n    CONFIG.update(vars(args))\n\n    # If quiet mode is enabled, redirect the standard output to a file.\n    if quiet_mode:\n        with open(os.path.join(CONFIG['record_dir'], 'output.txt'), 'w') as f:\n            with redirect_stdout(f):\n                CommandLine(CONFIG).run()\n    else:\n        CommandLine(CONFIG).run()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    CONFIG.update(vars(args))\n\n    # Redirect standard output to a file if quiet mode is enabled\n    if quiet_mode:\n        with open('output.txt', 'w') as f:\n            with redirect_stdout(f):\n                CommandLine().execute()\n    else:\n        CommandLine().execute()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update configuration parameters with the provided arguments.\n    for key in vars(args):\n        if key in CONFIG:\n            CONFIG[key] = vars(args)[key]\n\n    # If quiet mode is enabled, redirect the standard output to a file.\n    if quiet_mode:\n        with open(os.path.join(CONFIG['record_dir'], 'agent.log'), 'w') as f:\n            with redirect_stdout(f):\n                CommandLine.execute()\n    else:\n        CommandLine.execute()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    CONFIG.update(vars(args))\n\n    # If quiet mode is enabled, redirect the standard output to a file\n    if quiet_mode:\n        with open(os.path.join(CONFIG[\"record_dir\"], \"xagent.log\"), 'w') as f:\n            with redirect_stdout(f):\n                CommandLine.execute(CONFIG[\"task\"], CONFIG)\n    else:\n        CommandLine.execute(CONFIG[\"task\"], CONFIG)\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update configuration parameters with the provided arguments\n    CONFIG.update(vars(args))\n\n    # If quiet mode is enabled, redirect the standard output to a file\n    if quiet_mode:\n        with open('assets/execution_log.txt', 'w') as f:\n            with redirect_stdout(f):\n                CommandLine.execute()\n    else:\n        CommandLine.execute()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    CONFIG.update(vars(args))\n\n    # Create a directory to record the execution logs if one does not exist\n    if not os.path.exists(CONFIG['record_dir']):\n        os.makedirs(CONFIG['record_dir'])\n\n    # Redirect the standard output to a file if quiet mode is enabled\n    if quiet_mode:\n        with open(os.path.join(CONFIG['record_dir'], 'execution.log'), 'w') as f:\n            with redirect_stdout(f):\n                CommandLine.execute(ARGS)\n    else:\n        CommandLine.execute(ARGS)\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update the global configuration parameters.\n    if args.max_subtask_chain_length is not None:\n        CONFIG.max_subtask_chain_length = args.max_subtask_chain_length\n    if args.enable_ask_human_for_help is not None:\n        CONFIG.enable_ask_human_for_help = args.enable_ask_human_for_help\n    if args.max_plan_refine_chain_length is not None:\n        CONFIG.max_plan_refine_chain_length = args.max_plan_refine_chain_length\n    if args.max_plan_tree_depth is not None:\n        CONFIG.max_plan_tree_depth = args.max_plan_tree_depth\n    if args.max_plan_tree_width is not None:\n        CONFIG.max_plan_tree_width = args.max_plan_tree_width\n    if args.max_retry_times is not None:\n        CONFIG.max_retry_times = args.max_retry_times\n\n    # Set the quiet mode flag.\n    ARGS.quiet_mode = quiet_mode\n\n    # If quiet mode is enabled, redirect the standard output to a file.\n    if quiet_mode:\n        with open(os.path.join(ARGS.record_dir, 'XAgent.log'), 'w') as f:\n            with redirect_stdout(f):\n                CommandLine.run(args.task, args.upload_files, args.model, args.record_dir, args.mode)\n    else:\n        CommandLine.run(args.task, args.upload_files, args.model, args.record_dir, args.mode)\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update the global configuration parameters with the provided arguments.\n    CONFIG.update(vars(args))\n    # If quiet mode is enabled, redirect the standard output to a file.\n    if quiet_mode:\n        # Create the directory for the task execution logs if it does not exist.\n        if not os.path.exists(CONFIG['record_dir']):\n            os.makedirs(CONFIG['record_dir'])\n        # Create a unique filename for the task execution log.\n        filename = os.path.join(CONFIG['record_dir'], f'{CONFIG[\"task\"]}_{CONFIG[\"model\"]}.txt')\n        # Redirect the standard output to the file.\n        with open(filename, 'w') as f:\n            with redirect_stdout(f):\n                # Execute the command line process.\n                execute_command_line(CONFIG)\n    else:\n        # Execute the command line process.\n        execute_command_line(CONFIG)\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    for key, value in vars(args).items():\n        if value is not None:\n            CONFIG[key] = value\n\n    # If quiet mode is enabled, redirect the standard output to a file\n    if quiet_mode:\n        # Create a file to store the standard output\n        with open(CONFIG['record_dir'] + '/' + CONFIG['task'] + '.txt', 'w') as f:\n            with redirect_stdout(f):\n                # Execute the command line process\n                CommandLine.execute()\n    else:\n        # Execute the command line process\n        CommandLine.execute()\n\n"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_ap"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_ap"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_ap"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_ap"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_ap"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_ap"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_ap"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_ap"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.Completion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs ="}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or self._last_time is None or time() - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or self._last_time is None or time() - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or self._last_time is None or time() - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or self._last_time is None or time() - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or self._last_time is None or time() - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or self._last_time is None or (time() - self._last_time) > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or self._last_time is None or (time() - self._last_time) > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or self._last_time is None or (time() - self._last_time) > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or self._last_time is None or (time() - self._last_time) > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or self._last_time is None or (time() - self._last_time) > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or self._last_time is None or (time() - self._last_time) > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (time() - self._last_time) > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or self._last_time is None or time() - self._last_time >= self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or self._last_time is None or time() - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client\n\n"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if not self._client or self._last_time is None or (time() - self._last_time) > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or self._last_time is None or time() - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client\n"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or self._last_time is None or time() - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client\n"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (time() - self._last_time) > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client\n"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or self._last_time is None or time() - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client\n"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or self._last_time is None or time() - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"The `state_dict` method is not supported in a DataLoader worker process. \"\n                \"Please use the `state_dict` method in the main process.\"\n            )\n\n        if self.cache is None:\n            self.worker_env = _WorkerEnv.detect()\n            self.cache = self._create_cache(worker_env=self.worker_env)\n            self.shuffler = self._create_shuffler(self.cache)\n\n        state: Dict[str, Any] = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path if self.input_dir.path else self.input_dir.url,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The `state_dict` method should not be called from a DataLoader worker process.\")\n\n        state: Dict[str, Any] = {}\n\n        state[\"num_samples_yielded\"] = num_samples_yielded\n        state[\"num_workers\"] = num_workers\n        state[\"batch_size\"] = batch_size\n        state[\"current_epoch\"] = self.current_epoch\n        state[\"input_dir\"] = self.input_dir\n        state[\"item_loader\"] = self.item_loader\n        state[\"shuffle\"] = self.shuffle\n        state[\"drop_last\"] = self.drop_last\n        state[\"seed\"] = self.seed\n        state[\"distributed_env\"] = self.distributed_env\n        state[\"shuffler\"] = self.shuffler\n        state[\"serializers\"] = self.serializers\n        state[\"max_cache_size\"] = self.max_cache_size\n\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"The `state_dict` method is not supposed to be called from a DataLoader worker process.\"\n            )\n\n        return {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path if self.input_dir.path else self.input_dir.url,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise ValueError(\"state_dict cannot be called from a DataLoader worker process.\")\n\n        return {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader is not None else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"`state_dict` cannot be called from a DataLoader worker process.\")\n\n        self._state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path if self.input_dir.path else self.input_dir.url,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader is not None else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n        return self._state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"state_dict cannot be called from a DataLoader worker process.\")\n\n        self._state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir,\n            \"item_loader\": self.item_loader,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n\n        return self._state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise ValueError(\n                \"The `state_dict` method cannot be called from a DataLoader worker process.\"\n            )\n\n        self._state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"distributed_world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n\n        return self._state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise ValueError(\"state_dict cannot be called from a DataLoader worker process.\")\n\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path if self.input_dir.path else self.input_dir.url,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"StreamingDataset.state_dict() cannot be called from a DataLoader worker process.\"\n            )\n\n        state: Dict[str, Any] = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path if self.input_dir.path else self.input_dir.url,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n\n        self._state_dict = state\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"state_dict() cannot be called from a DataLoader worker process. \"\n                \"Please use state_dict() only from the main process.\"\n            )\n\n        self._state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir,\n            \"item_loader\": self.item_loader,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"distributed_env\": self.distributed_env,\n            \"shuffle\": self.shuffle,\n        }\n\n        return self._state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise ValueError(\"`state_dict` cannot be called from a DataLoader worker process.\")\n\n        return {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"distributed_env\": self.distributed_env,\n            \"shuffle\": self.shuffle,\n        }\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        assert self.worker_env is not None\n        assert self.cache is not None\n        assert self.shuffler is not None\n\n        state: Dict[str, Any] = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir,\n            \"item_loader\": self.item_loader.state_dict(),\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n\n        self._state_dict = state\n\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"StreamingDataset.state_dict() cannot be called from a DataLoader worker process.\"\n            )\n\n        return {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader is not None else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"distributed_env\": self.distributed_env.state_dict(),\n            \"shuffle\": self.shuffle,\n        }\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        assert _is_in_dataloader_worker() == False, \"state_dict should be called from the main process.\"\n        return {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader is not None else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        assert _is_in_dataloader_worker() == False\n        self._state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path if self.input_dir.path else self.input_dir.url,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"distributed_env\": self.distributed_env.state_dict(),\n            \"shuffle\": self.shuffle,\n        }\n        return self._state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"state_dict() cannot be called from a DataLoader worker process.\")\n\n        state = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir,\n            \"item_loader\": self.item_loader,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"distributed_env\": self.distributed_env,\n            \"shuffle\": self.shuffle,\n        }\n\n        if self.cache is not None:\n            state[\"cache\"] = self.cache.state_dict()\n\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        # If the state dict has been reloaded, don't override the current epoch\n        # The StreamingDataloader would clean this out\n        if self._state_dict is None:\n            self.current_epoch = 1\n\n        # Create the state dict\n        state: Dict[str, Any] = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir,\n            \"item_loader\": self.item_loader,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n\n        # Save the state dict\n        self._state_dict = state\n\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"Cannot call `state_dict` from a DataLoader worker process. \"\n                \"This method should only be called from the main process.\"\n            )\n        if self.cache is None:\n            self.worker_env = _WorkerEnv.detect()\n            self.cache = self._create_cache(worker_env=self.worker_env)\n            self.shuffler = self._create_shuffler(self.cache)\n        return {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir,\n            \"item_loader\": self.item_loader,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"distributed_env\": self.distributed_env,\n            \"shuffle\": self.shuffle,\n        }\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        # We can't create the state dict in the worker process\n        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"Cannot call state_dict() from a dataloader worker process. \"\n                \"Please call state_dict() from the main process.\"\n            )\n\n        state = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir,\n            \"item_loader\": self.item_loader.state_dict(),\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if not _is_in_dataloader_worker():\n            if self.cache is None:\n                self.worker_env = _WorkerEnv.detect()\n                self.cache = self._create_cache(worker_env=self.worker_env)\n                self.shuffler = self._create_shuffler(self.cache)\n            state = {\n                \"num_samples_yielded\": num_samples_yielded,\n                \"num_workers\": num_workers,\n                \"batch_size\": batch_size,\n                \"current_epoch\": self.current_epoch,\n                \"input_dir\": self.input_dir,\n                \"item_loader\": self.item_loader,\n                \"drop_last\": self.drop_last,\n                \"seed\": self.seed,\n                \"world_size\": self.distributed_env.world_size,\n                \"shuffle\": self.shuffle,\n            }\n            if self.cache._reader._state_dict:\n                state[\"reader\"] = self.cache._reader._state_dict\n            return state\n        else:\n            raise RuntimeError(\n                \"The `state_dict` method should only be called from the main process.\"\n            )\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if self._state_dict is not None:\n            raise RuntimeError(\"The method `load_state_dict` should only be called once.\")\n\n        self._state_dict = state_dict\n\n        self.input_dir = Dir(state_dict[\"input_dir_path\"], state_dict[\"input_dir_url\"])\n        self.drop_last = state_dict[\"drop_last\"]\n        self.seed = state_dict[\"seed\"]\n        self.shuffle = state_dict[\"shuffle\"]\n\n        self.cache = self._create_cache(worker_env=_WorkerEnv.detect())\n        self.shuffler = self._create_shuffler(self.cache)\n\n        self.current_epoch = state_dict[\"current_epoch\"]\n\n        # Handle restart\n        chunks_per_replica, intervals_per_replica = self.shuffler.get_chunks_and_intervals_per_ranks(\n            self.distributed_env, self.current_epoch\n        )\n        chunks_replica = chunks_per_replica[self.distributed_env.global_rank % self.distributed_env.world_size]\n        intervals_replica = intervals_per_replica[self.distributed_env.global_rank % self.distributed_env.world_size]\n\n        # Handle restart\n        chunks_per_replica, intervals_per_replica = self.shuffler.get_chunks_and_intervals_per_ranks(\n            self.distributed_env, self.current_epoch\n        )\n        chunks_replica = chunks_per_replica[self.distributed_env.global_rank % self.distributed_env.world_size]\n        intervals_replica = intervals_per_replica[self.distributed_env.global_rank % self.distributed_env.world_size]\n\n        self.worker_chunks = []\n        self.worker_intervals = []\n\n        for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if self._state_dict is not None:\n            raise RuntimeError(\"The method `load_state_dict` should only be called once.\")\n\n        if not isinstance(state_dict, dict):\n            raise ValueError(f\"State dictionary must be a dictionary. Found {state_dict}\")\n\n        if not isinstance(state_dict[\"num_samples_yielded\"], int):\n            raise ValueError(f\"State dictionary must contain an integer for `num_samples_yielded`. Found {state_dict['num_samples_yielded']}\")\n\n        if not isinstance(state_dict[\"num_workers\"], int):\n            raise ValueError(f\"State dictionary must contain an integer for `num_workers`. Found {state_dict['num_workers']}\")\n\n        if not isinstance(state_dict[\"batch_size\"], int):\n            raise ValueError(f\"State dictionary must contain an integer for `batch_size`. Found {state_dict['batch_size']}\")\n\n        if not isinstance(state_dict[\"current_epoch\"], int):\n            raise ValueError(f\"State dictionary must contain an integer for `current_epoch`. Found {state_dict['current_epoch']}\")\n\n        if not isinstance(state_dict[\"input_dir_path\"], str):\n            raise ValueError(f\"State dictionary must contain a string for `input_dir_path`. Found {state_dict['input_dir_path']}\")\n\n        if not isinstance(state_dict[\"input_dir_url\"], str):\n            raise ValueError(f\"State dictionary must contain a string for `input_dir_url`. Found {state_dict['input_dir_url']}\")\n\n        if not isinstance(state_dict[\"drop_last\"], bool):\n            raise ValueError(f\"State dictionary must contain a boolean for `drop_last`. Found {state_dict['drop_last']}\")\n\n        if not isinstance(state_dict[\"seed\"], int):\n            raise ValueError(f\"State dictionary must contain an integer for `seed`. Found {state_dict['seed']}\")\n\n        if not isinstance(state_dict[\"world_size"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        if self._state_dict is not None:\n            raise RuntimeError(\"The method `load_state_dict` should only be called once.\")\n\n        self._state_dict = state_dict\n        self.input_dir = Dir(path=state_dict[\"input_dir_path\"], url=state_dict[\"input_dir_url\"])\n        self.item_loader = (\n            BaseItemLoader.load_from_state_dict(state_dict[\"item_loader\"])\n            if state_dict[\"item_loader\"] is not None\n            else None\n        )\n        self.drop_last = state_dict[\"drop_last\"]\n        self.seed = state_dict[\"seed\"]\n        self.distributed_env = _DistributedEnv(\n            world_size=state_dict[\"world_size\"],\n            global_rank=state_dict[\"world_size\"],\n        )\n        self.shuffle = state_dict[\"shuffle\"]\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        if self._state_dict is not None:\n            raise RuntimeError(\"The method `load_state_dict` can only be called once.\")\n\n        self._state_dict = state_dict\n\n        input_dir_path = state_dict[\"input_dir_path\"]\n        input_dir_url = state_dict[\"input_dir_url\"]\n\n        if _should_replace_path(input_dir_path):\n            cache_path = _try_create_cache_dir(input_dir_path)\n            if cache_path is not None:\n                input_dir_path = cache_path\n\n        self.input_dir = Dir(input_dir_path, input_dir_url)\n\n        self.item_loader = (\n            BaseItemLoader.load_state_dict(state_dict[\"item_loader\"])\n            if state_dict[\"item_loader\"] is not None\n            else None\n        )\n\n        self.drop_last = state_dict[\"drop_last\"]\n        self.seed = state_dict[\"seed\"]\n        self.distributed_env = _DistributedEnv.detect()\n        self.shuffle = state_dict[\"shuffle\"]\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._state_dict = state_dict\n\n        if \"input_dir_path\" in state_dict:\n            self.input_dir.path = state_dict[\"input_dir_path\"]\n            self.input_dir.url = state_dict[\"input_dir_url\"]\n\n        if \"item_loader\" in state_dict:\n            self.item_loader.load_state_dict(state_dict[\"item_loader\"])\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._state_dict = state_dict\n        self.current_epoch = state_dict[\"current_epoch\"]\n        self.input_dir = Dir(path=state_dict[\"input_dir_path\"], url=state_dict[\"input_dir_url\"])\n        self.item_loader = (\n            BaseItemLoader.load_state_dict(state_dict[\"item_loader\"]) if state_dict[\"item_loader\"] else None\n        )\n        self.drop_last = state_dict[\"drop_last\"]\n        self.seed = state_dict[\"seed\"]\n        self.distributed_env = _DistributedEnv(\n            world_size=state_dict[\"world_size\"],\n            global_rank=state_dict[\"world_size\"],\n            local_rank=state_dict[\"world_size\"],\n        )\n        self.shuffle = state_dict[\"shuffle\"]\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._state_dict = state_dict\n\n        input_dir_path = state_dict[\"input_dir_path\"]\n        input_dir_url = state_dict[\"input_dir_url\"]\n\n        if _should_replace_path(input_dir_path):\n            cache_path = _try_create_cache_dir(input_dir=input_dir_path if input_dir_path else input_dir_url)\n            if cache_path is not None:\n                input_dir_path = cache_path\n\n        self.input_dir = Dir(input_dir_path)\n\n        self.item_loader = (\n            BaseItemLoader.load_state_dict(state_dict[\"item_loader\"]) if state_dict[\"item_loader\"] else None\n        )\n\n        self.drop_last = state_dict[\"drop_last\"]\n        self.seed = state_dict[\"seed\"]\n        self.distributed_env.world_size = state_dict[\"world_size\"]\n        self.shuffle = state_dict[\"shuffle\"]\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._state_dict = state_dict\n\n        input_dir_path = state_dict[\"input_dir_path\"]\n        input_dir_url = state_dict[\"input_dir_url\"]\n        if _should_replace_path(input_dir_path):\n            if input_dir_url is not None:\n                cache_path = _try_create_cache_dir(input_dir_url)\n                if cache_path is not None:\n                    input_dir_path = cache_path\n            if input_dir_path is not None:\n                self.input_dir.path = input_dir_path\n\n        self.distributed_env = _DistributedEnv.detect()\n        self.worker_env = _WorkerEnv.detect()\n\n        self.cache = self._create_cache(worker_env=self.worker_env)\n        self.shuffler = self._create_shuffler(self.cache)\n\n        self.current_epoch = state_dict[\"current_epoch\"]\n        self.has_triggered_download = True\n\n        self.min_items_per_replica = None\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `state_dict` should only be called in the main process.\")\n\n        if self._state_dict is not None:\n            self._state_dict[\"num_samples_yielded\"] = state_dict[\"num_samples_yielded\"]\n            return\n\n        self._state_dict = state_dict\n        self.input_dir = Dir(\n            path=state_dict[\"input_dir_path\"] if state_dict[\"input_dir_path\"] else state_dict[\"input_dir_url\"],\n        )\n        self.drop_last = state_dict[\"drop_last\"]\n        self.seed = state_dict[\"seed\"]\n        self.distributed_env = _DistributedEnv.detect()\n\n        self.cache = self._create_cache(worker_env=_WorkerEnv.detect())\n        self.shuffler = self._create_shuffler(self.cache)\n\n        self.worker_env = _WorkerEnv.detect()\n\n        chunks_per_replica, intervals_per_replica = self.shuffler.get_chunks_and_intervals_per_ranks(\n            self.distributed_env, self.current_epoch\n        )\n        chunks_replica = chunks_per_replica[self.distributed_env.global_rank % self.distributed_env.world_size]\n        intervals_replica = intervals_per_replica[self.distributed_env.global_rank % self.distributed_env.world_size]\n\n        chunks_per_replica, intervals_per_replica = self.shuffler.get_chunks_and_intervals_per_ranks(\n            self.distributed_env, self.current_epoch\n        )\n        chunks_replica = chunks_per_replica[self.distributed_env.global_rank % self.distributed_env.world_size]\n        intervals_replica = intervals_per_replica[self.distributed_env.global_rank % self"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._state_dict = state_dict\n        self.input_dir = Dir(state_dict[\"input_dir_url\"], state_dict[\"input_dir_path\"])\n        self.item_loader = BaseItemLoader.load_state_dict(state_dict[\"item_loader\"]) if state_dict[\"item_loader\"] else None\n        self.drop_last = state_dict[\"drop_last\"]\n        self.seed = state_dict[\"seed\"]\n        self.distributed_env = _DistributedEnv(state_dict[\"world_size\"])\n        self.shuffle = state_dict[\"shuffle\"]\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if self._state_dict is not None:\n            raise RuntimeError(\"The method `load_state_dict` should only be called once.\")\n\n        self._state_dict = state_dict\n\n        if self.input_dir.path != state_dict[\"input_dir_path\"]:\n            raise RuntimeError(\n                f\"The input directory path has changed. The current value is {self.input_dir.path} \"\n                f\"and the saved value is {state_dict['input_dir_path']}.\"\n            )\n\n        if self.input_dir.url != state_dict[\"input_dir_url\"]:\n            raise RuntimeError(\n                f\"The input directory url has changed. The current value is {self.input_dir.url} \"\n                f\"and the saved value is {state_dict['input_dir_url']}.\"\n            )\n\n        if self.drop_last != state_dict[\"drop_last\"]:\n            raise RuntimeError(\n                f\"The `drop_last` parameter has changed. The current value is {self.drop_last} \"\n                f\"and the saved value is {state_dict['drop_last']}.\"\n            )\n\n        if self.seed != state_dict[\"seed\"]:\n            raise RuntimeError(\n                f\"The `seed` parameter has changed. The current value is {self.seed} \"\n                f\"and the saved value is {state_dict['seed']}.\"\n            )\n\n        if self.distributed_env.world_size != state_dict[\"world_size\"]:\n            raise RuntimeError(\n                f\"The world size has changed. The current value is {self.distributed_env.world_size} \"\n                f\"and the saved value is {state_dict['world_size']}.\"\n            )\n\n        if self.shuffle != state_dict[\"shuffle\"]:\n            raise RuntimeError(\n                f\"The `shuffle` parameter has changed. The current value is {self.shuffle} \"\n                f\"and the saved value is {state_dict['shuffle']}.\"\n            )\n\n        if self.item_loader"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        if self._state_dict is not None:\n            raise RuntimeError(\"The method `load_state_dict` should only be called once.\")\n\n        self._state_dict = state_dict\n\n        self.input_dir = Dir(path=state_dict[\"input_dir_path\"], url=state_dict[\"input_dir_url\"])\n        self.drop_last = state_dict[\"drop_last\"]\n        self.seed = state_dict[\"seed\"]\n        self.shuffle = state_dict[\"shuffle\"]\n        self.distributed_env = _DistributedEnv.detect()\n\n        self.worker_env = _WorkerEnv.detect()\n        self.cache = self._create_cache(worker_env=self.worker_env)\n        self.shuffler = self._create_shuffler(self.cache)\n\n        self.num_chunks = None\n        self.worker_chunks = []\n        self.worker_intervals = []\n        self.current_indexes = []\n        self.chunk_index = 0\n        self.global_index = state_dict[\"num_samples_yielded\"]\n        self.index = 0\n        self.has_triggered_download = False\n        self.last_time = time()\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        if self._state_dict is not None:\n            raise RuntimeError(\"The method `load_state_dict` should only be called once.\")\n\n        self._state_dict = state_dict\n        self._validate_state_dict()\n\n        self.current_epoch = state_dict[\"current_epoch\"]\n        self.input_dir = Dir(state_dict[\"input_dir_path\"] if state_dict[\"input_dir_path\"] else state_dict[\"input_dir_url\"])\n        self.drop_last = state_dict[\"drop_last\"]\n        self.seed = state_dict[\"seed\"]\n        self.shuffle = state_dict[\"shuffle\"]\n\n        if state_dict[\"item_loader\"] is not None:\n            self.item_loader = BaseItemLoader.load_from_state_dict(state_dict[\"item_loader\"])\n\n        self.cache = self._create_cache(worker_env=_WorkerEnv.detect())\n        self.shuffler = self._create_shuffler(self.cache)\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._state_dict = state_dict\n        self.input_dir.path = state_dict[\"input_dir_path\"]\n        self.input_dir.url = state_dict[\"input_dir_url\"]\n        self.current_epoch = state_dict[\"current_epoch\"]\n        self.drop_last = state_dict[\"drop_last\"]\n        self.seed = state_dict[\"seed\"]\n        self.shuffle = state_dict[\"shuffle\"]\n\n        if self.item_loader is not None:\n            self.item_loader.load_state_dict(state_dict[\"item_loader\"])\n\n        self.cache = self._create_cache(worker_env=_WorkerEnv.detect())\n        self.shuffler = self._create_shuffler(self.cache)\n\n        self.worker_env = _WorkerEnv.detect()\n        self.worker_chunks = []\n        self.worker_intervals = []\n\n        for i, (chunk_index, chunk_interval) in enumerate(zip(self.cache._chunks, self.cache._intervals)):\n            if i % self.worker_env.world_size != self.worker_env.rank:\n                continue\n            self.worker_chunks.append(chunk_index)\n            self.worker_intervals.append(chunk_interval)\n\n        self.num_chunks = len(self.worker_chunks)\n\n        self.current_indexes = []\n        self.chunk_index = 0\n        self.global_index = 0\n        self.index = 0\n\n        self.has_triggered_download = False\n        self.last_time = time()\n\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._state_dict = state_dict\n        self.current_epoch = state_dict[\"current_epoch\"]\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        if self._state_dict is not None:\n            raise RuntimeError(\"The method `load_state_dict` should only be called once.\")\n\n        self._state_dict = state_dict\n\n        self.input_dir.path = state_dict[\"input_dir_path\"]\n        self.input_dir.url = state_dict[\"input_dir_url\"]\n        self.item_loader.load_state_dict(state_dict[\"item_loader\"]) if self.item_loader else None\n        self.drop_last = state_dict[\"drop_last\"]\n        self.seed = state_dict[\"seed\"]\n        self.current_epoch = state_dict[\"current_epoch\"]\n        self.distributed_env.world_size = state_dict[\"world_size\"]\n        self.shuffle = state_dict[\"shuffle\"]\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if self._state_dict is not None:\n            raise RuntimeError(\"The method `load_state_dict` should only be called once.\")\n\n        self._state_dict = state_dict\n\n        if self.input_dir.path != state_dict[\"input_dir_path\"]:\n            raise RuntimeError(\n                \"The input directory has changed. Please use the same input directory as when you saved the state.\"\n            )\n\n        if self.input_dir.url != state_dict[\"input_dir_url\"]:\n            raise RuntimeError(\n                \"The input directory has changed. Please use the same input directory as when you saved the state.\"\n            )\n\n        if self.drop_last != state_dict[\"drop_last\"]:\n            raise RuntimeError(\n                \"The `drop_last` flag has changed. Please use the same `drop_last` flag as when you saved the state.\"\n            )\n\n        if self.seed != state_dict[\"seed\"]:\n            raise RuntimeError(\n                \"The seed has changed. Please use the same seed as when you saved the state.\"\n            )\n\n        if self.shuffle != state_dict[\"shuffle\"]:\n            raise RuntimeError(\n                \"The shuffle flag has changed. Please use the same shuffle flag as when you saved the state.\"\n            )\n\n        if self.distributed_env.world_size != state_dict[\"world_size\"]:\n            raise RuntimeError(\n                \"The world size has changed. Please use the same world size as when you saved the state.\"\n            )\n\n        self.current_epoch = state_dict[\"current_epoch\"]\n\n        self.item_loader = BaseItemLoader.load_state_dict(state_dict[\"item_loader\"]) if state_dict[\"item_loader\"] else None\n\n        self.cache = self._create_cache(worker_env=_WorkerEnv.detect())\n        self.shuffler = self._create_shuffler(self.cache)\n\n        self.num_chunks = None\n        self.worker_chunks = []\n        self.worker_intervals = []\n        self.current_index"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if self._state_dict is not None:\n            raise RuntimeError(\"The method `load_state_dict` should only be called once.\")\n\n        self._state_dict = state_dict\n        self.input_dir = Dir(state_dict[\"input_dir_path\"] if state_dict[\"input_dir_path\"] else state_dict[\"input_dir_url\"])\n        self.item_loader = (\n            BaseItemLoader.load_state_dict(state_dict[\"item_loader\"]) if state_dict[\"item_loader\"] else None\n        )\n        self.drop_last = state_dict[\"drop_last\"]\n        self.seed = state_dict[\"seed\"]\n        self.distributed_env = _DistributedEnv(\n            world_size=state_dict[\"world_size\"], rank=0, local_rank=0, global_rank=0\n        )\n        self.worker_env = _WorkerEnv(rank=0, world_size=1)\n        self.current_epoch = state_dict[\"current_epoch\"]\n        self.shuffle = state_dict[\"shuffle\"]\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._state_dict = state_dict\n\n        if self.input_dir.path != state_dict[\"input_dir_path\"]:\n            raise ValueError(\n                f\"The provided input_dir path {self.input_dir.path} does not match the path {state_dict['input_dir_path']} in the state dict.\"\n                \" Please ensure that the dataset you are trying to load has been optimised with the same input_dir.\"\n            )\n\n        if self.input_dir.url != state_dict[\"input_dir_url\"]:\n            raise ValueError(\n                f\"The provided input_dir url {self.input_dir.url} does not match the url {state_dict['input_dir_url']} in the state dict.\"\n                \" Please ensure that the dataset you are trying to load has been optimised with the same input_dir.\"\n            )\n\n        if self.item_loader is not None and state_dict[\"item_loader\"] is not None:\n            self.item_loader.load_state_dict(state_dict[\"item_loader\"])\n\n        self.drop_last = state_dict[\"drop_last\"]\n        self.seed = state_dict[\"seed\"]\n        self.distributed_env = _DistributedEnv.detect()\n        self.current_epoch = state_dict[\"current_epoch\"]\n\n        self.worker_env = _WorkerEnv.detect()\n        self.cache = self._create_cache(worker_env=self.worker_env)\n        self.shuffler = self._create_shuffler(self.cache)\n\n        # Handle restart\n        if self._state_dict:\n            self._validate_state_dict()\n            state: Dict[str, Any] = self._state_dict\n            self.current_epoch = state[\"current_epoch\"]\n\n        chunks_per_replica, intervals_per_replica = self.shuffler.get_ch"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if self._state_dict is not None:\n            raise RuntimeError(\"The method `load_state_dict` can only be called once.\")\n\n        self._state_dict = state_dict\n\n        if self.input_dir.path is None:\n            self.input_dir.path = self._state_dict[\"input_dir_path\"]\n            self.input_dir.url = self._state_dict[\"input_dir_url\"]\n\n        if self.item_loader is None:\n            self.item_loader = BaseItemLoader.load_state_dict(self._state_dict[\"item_loader\"])\n\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if not self._state_dict:\n            raise ValueError(\"The state dict is None.\")\n\n        state: Dict[str, Any] = self._state_dict\n\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                f\"The input directory path in the state dict {state['input_dir_path']} does not match the current input directory path {self.input_dir.path}.\"\n            )\n\n        if state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The input directory URL in the state dict {state['input_dir_url']} does not match the current input directory URL {self.input_dir.url}.\"\n            )\n\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The shuffle in the state dict {state['shuffle']} does not match the current shuffle {self.shuffle}.\"\n            )\n\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\n                f\"The drop_last in the state dict {state['drop_last']} does not match the current drop_last {self.drop_last}.\"\n            )\n\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\n                f\"The seed in the state dict {state['seed']} does not match the current seed {self.seed}.\"\n            )\n\n        if state[\"world_size\"] != self.distributed_env.world_size:\n            raise ValueError(\n                f\"The world size in the state dict {state['world_size']} does not match the current world size {self.distributed_env.world_size}.\"\n            )\n\n        if state[\"num_workers\"] != self.worker_env.world_size:\n            raise ValueError(\n                f\"The num_workers in the state dict {state['num_workers']} does not match the current num_workers {self.worker_env.world_size}.\"\n            )\n\n        if state[\"batch"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state: Dict[str, Any] = self._state_dict\n\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The shuffle parameter in the state dict does not match the current state of the StreamingDataset instance. \"\n                f\"The state dict has shuffle={state['shuffle']} while the current state has shuffle={self.shuffle}.\"\n            )\n\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\n                f\"The drop_last parameter in the state dict does not match the current state of the StreamingDataset instance. \"\n                f\"The state dict has drop_last={state['drop_last']} while the current state has drop_last={self.drop_last}.\"\n            )\n\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\n                f\"The seed parameter in the state dict does not match the current state of the StreamingDataset instance. \"\n                f\"The state dict has seed={state['seed']} while the current state has seed={self.seed}.\"\n            )\n\n        if state[\"world_size\"] != self.distributed_env.world_size:\n            raise ValueError(\n                f\"The world_size parameter in the state dict does not match the current state of the StreamingDataset instance. \"\n                f\"The state dict has world_size={state['world_size']} while the current state has world_size={self.distributed_env.world_size}.\"\n            )\n\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                f\"The input_dir_path parameter in the state dict does not match the current state of the StreamingDataset instance. \"\n                f\"The state dict has input_dir_path={state['input_dir_path']} while the current state has input_dir_path={self.input_dir.path}.\"\n            )\n\n        if state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The input_"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict is None:\n            raise ValueError(\"The state dictionary is None.\")\n\n        state: Dict[str, Any] = self._state_dict\n\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The shuffle parameter in the state dictionary is {state['shuffle']} but the current value of the shuffle parameter is {self.shuffle}.\"\n            )\n\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\n                f\"The drop_last parameter in the state dictionary is {state['drop_last']} but the current value of the drop_last parameter is {self.drop_last}.\"\n            )\n\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\n                f\"The seed parameter in the state dictionary is {state['seed']} but the current value of the seed parameter is {self.seed}.\"\n            )\n\n        if state[\"world_size\"] != self.distributed_env.world_size:\n            raise ValueError(\n                f\"The world_size parameter in the state dictionary is {state['world_size']} but the current value of the world_size parameter is {self.distributed_env.world_size}.\"\n            )\n\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                f\"The input directory path in the state dictionary is {state['input_dir_path']} but the current value of the input directory path is {self.input_dir.path}.\"\n            )\n\n        if state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The input directory URL in the state dictionary is {state['input_dir_url']} but the current value of the input directory URL is {self.input_dir.url}.\"\n            )\n\n        if state[\"item_loader\"] != self.item_loader.state_dict():\n            raise ValueError(\n                f\"The item_loader state dictionary in the state dictionary is {state['item_loader']} but the"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict is None:\n            return\n\n        state: Dict[str, Any] = self._state_dict\n\n        if state[\"input_dir_path\"] != self.input_dir.path or state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The input directory path or URL does not match the one in the state dictionary. \"\n                f\"The current input directory path is {self.input_dir.path} and the URL is {self.input_dir.url}. \"\n                f\"The input directory path in the state dictionary is {state['input_dir_path']} and the URL is {state['input_dir_url']}.\"\n            )\n\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The shuffle parameter does not match the one in the state dictionary. \"\n                f\"The current shuffle parameter is {self.shuffle}. \"\n                f\"The shuffle parameter in the state dictionary is {state['shuffle']}.\"\n            )\n\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\n                f\"The drop_last parameter does not match the one in the state dictionary. \"\n                f\"The current drop_last parameter is {self.drop_last}. \"\n                f\"The drop_last parameter in the state dictionary is {state['drop_last']}.\"\n            )\n\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\n                f\"The seed parameter does not match the one in the state dictionary. \"\n                f\"The current seed parameter is {self.seed}. \"\n                f\"The seed parameter in the state dictionary is {state['seed']}.\"\n            )\n\n        if state[\"world_size\"] != self.distributed_env.world_size:\n            raise ValueError(\n                f\"The world size does not match the one in the state dictionary. \"\n                f\"The current world size is {self.distributed_env.world_size}. \"\n                f\"The world size in the state dictionary is {state['world_"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict is None:\n            raise ValueError(\"The state dictionary is None\")\n\n        state: Dict[str, Any] = self._state_dict\n\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                f\"The input directory path in the state dictionary {state['input_dir_path']} does not match the current input directory path {self.input_dir.path}\"\n            )\n\n        if state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The input directory URL in the state dictionary {state['input_dir_url']} does not match the current input directory URL {self.input_dir.url}\"\n            )\n\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The shuffle parameter in the state dictionary {state['shuffle']} does not match the current shuffle parameter {self.shuffle}\"\n            )\n\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\n                f\"The drop_last parameter in the state dictionary {state['drop_last']} does not match the current drop_last parameter {self.drop_last}\"\n            )\n\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\n                f\"The seed parameter in the state dictionary {state['seed']} does not match the current seed parameter {self.seed}\"\n            )\n\n        if state[\"world_size\"] != self.distributed_env.world_size:\n            raise ValueError(\n                f\"The world size in the state dictionary {state['world_size']} does not match the current world size {self.distributed_env.world_size}\"\n            )\n\n        if self.item_loader is not None:\n            if state[\"item_loader\"] is None:\n                raise ValueError(\n                    \"The item loader in the state dictionary is None, but the item loader in the current StreamingDataset instance is not None\"\n                )\n            self.item_loader.load_state_dict(state[\""}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state: Dict[str, Any] = self._state_dict\n\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                f\"The state dictionary was created with input_dir_path={state['input_dir_path']} but the current instance has input_dir_path={self.input_dir.path}\"\n            )\n\n        if state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The state dictionary was created with input_dir_url={state['input_dir_url']} but the current instance has input_dir_url={self.input_dir.url}\"\n            )\n\n        if state[\"item_loader\"] is not None and self.item_loader is not None:\n            if state[\"item_loader\"] != self.item_loader.state_dict():\n                raise ValueError(\n                    f\"The state dictionary was created with item_loader={state['item_loader']} but the current instance has item_loader={self.item_loader.state_dict()}\"\n                )\n\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The state dictionary was created with shuffle={state['shuffle']} but the current instance has shuffle={self.shuffle}\"\n            )\n\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\n                f\"The state dictionary was created with drop_last={state['drop_last']} but the current instance has drop_last={self.drop_last}\"\n            )\n\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\n                f\"The state dictionary was created with seed={state['seed']} but the current instance has seed={self.seed}\"\n            )\n\n        if state[\"world_size\"] != self.distributed_env.world_size:\n            raise ValueError(\n                f\"The state dictionary was created with world_size={state['world_size']} but the current instance has world_size={self.distributed_env.world_size}\"\n            )"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `validate_state_dict` should only be called in the main process.\")\n\n        if self._state_dict is None:\n            raise ValueError(\"The state dictionary is empty.\")\n\n        state: Dict[str, Any] = self._state_dict\n\n        if self.worker_env is None:\n            raise ValueError(\"The worker environment is empty.\")\n\n        if self.cache is None:\n            raise ValueError(\"The cache is empty.\")\n\n        if self.shuffle is None:\n            raise ValueError(\"The shuffle flag is empty.\")\n\n        if state[\"input_dir_path\"] != self.input_dir.path or state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                \"The input directory path and URL mismatch between the state dictionary and the current state of the StreamingDataset instance.\"\n            )\n\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\n                \"The seed mismatch between the state dictionary and the current state of the StreamingDataset instance.\"\n            )\n\n        if state[\"item_loader\"] != self.item_loader.state_dict() if self.item_loader else None:\n            raise ValueError(\n                \"The item loader state mismatch between the state dictionary and the current state of the StreamingDataset instance.\"\n            )\n\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\n                \"The drop last flag mismatch between the state dictionary and the current state of the StreamingDataset instance.\"\n            )\n\n        if state[\"world_size\"] != self.distributed_env.world_size:\n            raise ValueError(\n                \"The world size mismatch between the state dictionary and the current state of the StreamingDataset instance.\"\n            )\n\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                \"The shuffle flag mismatch between the state dictionary and the current state of the StreamingDataset instance.\"\n            )\n\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        # validate the input directory\n        if self._state_dict[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                f\"The input directory path in the state dictionary `{self._state_dict['input_dir_path']}` does not match the current input directory path `{self.input_dir.path}`.\"\n            )\n        if self._state_dict[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The input directory URL in the state dictionary `{self._state_dict['input_dir_url']}` does not match the current input directory URL `{self.input_dir.url}`.\"\n            )\n\n        # validate the item loader state\n        if self._state_dict[\"item_loader\"] and self.item_loader:\n            self.item_loader.load_state_dict(self._state_dict[\"item_loader\"])\n\n        # validate the shuffle, drop_last, seed and world_size\n        if self._state_dict[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The shuffle flag in the state dictionary `{self._state_dict['shuffle']}` does not match the current shuffle flag `{self.shuffle}`.\"\n            )\n        if self._state_dict[\"drop_last\"] != self.drop_last:\n            raise ValueError(\n                f\"The drop_last flag in the state dictionary `{self._state_dict['drop_last']}` does not match the current drop_last flag `{self.drop_last}`.\"\n            )\n        if self._state_dict[\"seed\"] != self.seed:\n            raise ValueError(\n                f\"The seed in the state dictionary `{self._state_dict['seed']}` does not match the current seed `{self.seed}`.\"\n            )\n        if self._state_dict[\"world_size\"] != self.distributed_env.world_size:\n            raise ValueError(\n                f\"The world size in the state dictionary `{self._state_dict['world_size']}` does not match the current world size `{self.distributed_env.world_size}`.\""}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `_validate_state_dict` should only be called in the main process.\")\n\n        if self._state_dict is None:\n            return\n\n        state: Dict[str, Any] = self._state_dict\n\n        if self.shuffle != state[\"shuffle\"]:\n            raise ValueError(f\"Shuffle should be {self.shuffle} but found {state['shuffle']}\")\n\n        if self.drop_last != state[\"drop_last\"]:\n            raise ValueError(f\"Drop last should be {self.drop_last} but found {state['drop_last']}\")\n\n        if self.seed != state[\"seed\"]:\n            raise ValueError(f\"Seed should be {self.seed} but found {state['seed']}\")\n\n        if self.distributed_env.world_size != state[\"world_size\"]:\n            raise ValueError(f\"World size should be {self.distributed_env.world_size} but found {state['world_size']}\")\n\n        if self.input_dir.path != state[\"input_dir_path\"]:\n            raise ValueError(\n                f\"Input directory path should be {self.input_dir.path} but found {state['input_dir_path']}\"\n            )\n\n        if self.input_dir.url != state[\"input_dir_url\"]:\n            raise ValueError(\n                f\"Input directory URL should be {self.input_dir.url} but found {state['input_dir_url']}\"\n            )\n\n        if self.item_loader and self.item_loader.state_dict():\n            if self.item_loader.state_dict() != state[\"item_loader\"]:\n                raise ValueError(\n                    f\"Item loader state should be {self.item_loader.state_dict()} but found {state['item_loader']}\"\n                )\n\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict is None:\n            raise ValueError(\"The state dictionary is None\")\n\n        state: Dict[str, Any] = self._state_dict\n\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                f\"The input_dir_path in the state dictionary {state['input_dir_path']} does not match the current input_dir_path {self.input_dir.path}.\"\n            )\n\n        if state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The input_dir_url in the state dictionary {state['input_dir_url']} does not match the current input_dir_url {self.input_dir.url}.\"\n            )\n\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The shuffle in the state dictionary {state['shuffle']} does not match the current shuffle {self.shuffle}.\"\n            )\n\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\n                f\"The drop_last in the state dictionary {state['drop_last']} does not match the current drop_last {self.drop_last}.\"\n            )\n\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\n                f\"The seed in the state dictionary {state['seed']} does not match the current seed {self.seed}.\"\n            )\n\n        if state[\"world_size\"] != self.distributed_env.world_size:\n            raise ValueError(\n                f\"The world_size in the state dictionary {state['world_size']} does not match the current world_size {self.distributed_env.world_size}.\"\n            )\n\n        if self.item_loader:\n            if state[\"item_loader\"] is None:\n                raise ValueError(\n                    \"The item_loader in the state dictionary is None. This is not expected.\"\n                )\n            if state[\"item_loader\"] != self.item_loader.state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        if self._state_dict is None:\n            raise ValueError(\"The state dictionary is empty.\")\n\n        state: Dict[str, Any] = self._state_dict\n\n        if self.worker_env is None:\n            raise ValueError(\"The worker environment is not set.\")\n\n        if self.cache is None:\n            raise ValueError(\"The cache is not set.\")\n\n        if self.shuffle is None:\n            raise ValueError(\"The shuffle is not set.\")\n\n        if self.drop_last is None:\n            raise ValueError(\"The drop_last is not set.\")\n\n        if self.seed is None:\n            raise ValueError(\"The seed is not set.\")\n\n        if self.item_loader is None:\n            raise ValueError(\"The item_loader is not set.\")\n\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                f\"The input directory path mismatch. The state dictionary has {state['input_dir_path']} \"\n                f\"and the current StreamingDataset instance has {self.input_dir.path}\"\n            )\n\n        if state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The input directory URL mismatch. The state dictionary has {state['input_dir_url']} \"\n                f\"and the current StreamingDataset instance has {self.input_dir.url}\"\n            )\n\n        if state[\"item_loader\"] != self.item_loader.state_dict():\n            raise ValueError(\n                f\"The item_loader mismatch. The state dictionary has {state['item_loader']} \"\n                f\"and the current StreamingDataset instance has {self.item_loader.state_dict()}\"\n            )\n\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\n                f\"The drop_last mismatch. The state dictionary has {state['drop_"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `validate_state_dict` should only be called in the main process.\")\n\n        if self._state_dict is None:\n            raise ValueError(\"The state dictionary is None.\")\n\n        state: Dict[str, Any] = self._state_dict\n\n        # Validate the input directory path and URL\n        input_dir_path = state[\"input_dir_path\"]\n        input_dir_url = state[\"input_dir_url\"]\n\n        if self.input_dir.path != input_dir_path and self.input_dir.url != input_dir_url:\n            raise ValueError(\n                f\"The input directory path and URL in the state dictionary do not match the current state of the StreamingDataset instance.\"\n                f\"The input directory path in the state dictionary is {input_dir_path} and the input directory URL is {input_dir_url}.\"\n                f\"The input directory path and URL in the current state of the StreamingDataset instance is {self.input_dir.path} and {self.input_dir.url}.\"\n            )\n\n        # Validate the seed\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\n                f\"The seed in the state dictionary does not match the current state of the StreamingDataset instance.\"\n                f\"The seed in the state dictionary is {state['seed']} and the seed in the current state of the StreamingDataset instance is {self.seed}.\"\n            )\n\n        # Validate the item_loader state\n        if state[\"item_loader\"] != self.item_loader.state_dict() if self.item_loader else None:\n            raise ValueError(\n                f\"The item loader state in the state dictionary does not match the current state of the StreamingDataset instance.\"\n                f\"The item loader state in the state dictionary is {state['item_loader']} and the item loader state in the current state of the StreamingDataset instance is {self.item_loader.state_dict() if self.item_loader else None}.\"\n            )\n\n        #"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `_validate_state_dict` should only be called in the main process.\")\n\n        if self._state_dict is None:\n            raise ValueError(\"The state dictionary is empty.\")\n\n        state: Dict[str, Any] = self._state_dict\n\n        if state[\"input_dir_path\"] != self.input_dir.path or state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The input directory path or URL does not match. Found {state['input_dir_path']} and {state['input_dir_url']} in the state dictionary but {self.input_dir.path} and {self.input_dir.url} in the current state of the StreamingDataset.\"\n            )\n\n        if state[\"item_loader\"] != self.item_loader.state_dict() if self.item_loader else None:\n            raise ValueError(\n                f\"The item loader does not match. Found {state['item_loader']} in the state dictionary but {self.item_loader.state_dict() if self.item_loader else None} in the current state of the StreamingDataset.\"\n            )\n\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The shuffle flag does not match. Found {state['shuffle']} in the state dictionary but {self.shuffle} in the current state of the StreamingDataset.\"\n            )\n\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\n                f\"The drop_last flag does not match. Found {state['drop_last']} in the state dictionary but {self.drop_last} in the current state of the StreamingDataset.\"\n            )\n\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\n                f\"The seed does not match. Found {state['seed']} in the state dictionary but {self.seed} in the current state of the StreamingDataset.\"\n            )\n\n        if state[\"world_"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict is None:\n            raise ValueError(\"The state dictionary cannot be None.\")\n\n        state: Dict[str, Any] = self._state_dict\n\n        if self.worker_env is None:\n            raise ValueError(\"The worker environment cannot be None.\")\n\n        if self.cache is None:\n            raise ValueError(\"The cache cannot be None.\")\n\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                f\"The input directory path mismatch. Expected: {state['input_dir_path']}. Got: {self.input_dir.path}\"\n            )\n\n        if state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The input directory URL mismatch. Expected: {state['input_dir_url']}. Got: {self.input_dir.url}\"\n            )\n\n        if self.item_loader is not None:\n            if state[\"item_loader\"] is None:\n                raise ValueError(\"The state dictionary cannot be None.\")\n\n            if state[\"item_loader\"] != self.item_loader.state_dict():\n                raise ValueError(\n                    \"The item loader state mismatch. Expected: {state['item_loader']}. Got: {self.item_loader.state_dict()}\"\n                )\n        else:\n            if state[\"item_loader\"] is not None:\n                raise ValueError(\"The state dictionary cannot be None.\")\n\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The shuffle parameter mismatch. Expected: {state['shuffle']}. Got: {self.shuffle}\"\n            )\n\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\n                f\"The drop_last parameter mismatch. Expected: {state['drop_last']}. Got: {self.drop_last}\"\n            )\n\n        if state[\"seed\"] != self.seed:\n            raise ValueError(f\"The seed parameter mismatch. Expected: {state['seed']}. Got: {self."}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict is None:\n            raise ValueError(\n                \"The state dict is None. Please call the `state_dict` method on the StreamingDataset instance before calling the `load_state_dict` method.\"\n            )\n\n        state: Dict[str, Any] = self._state_dict\n\n        # Validate the seed\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\n                \"The seed in the state dict does not match the current seed. Please check the state dict.\"\n            )\n\n        # Validate the shuffle\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                \"The shuffle in the state dict does not match the current shuffle. Please check the state dict.\"\n            )\n\n        # Validate the drop_last\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\n                \"The drop_last in the state dict does not match the current drop_last. Please check the state dict.\"\n            )\n\n        # Validate the input directory path\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                \"The input directory path in the state dict does not match the current input directory path. Please check the state dict.\"\n            )\n\n        # Validate the input directory URL\n        if state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                \"The input directory URL in the state dict does not match the current input directory URL. Please check the state dict.\"\n            )\n\n        # Validate the item loader\n        if state[\"item_loader\"] != self.item_loader.state_dict() if self.item_loader else None:\n            raise ValueError(\n                \"The item loader in the state dict does not match the current item loader. Please check the state dict.\"\n            )\n\n        # Validate the number of workers\n        if state[\"num_workers\"] != self.distributed_env.world_size:\n            raise ValueError(\n                \"The number of workers in the state dict does not match the current number"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `_validate_state_dict` should only be called in the main process.\")\n\n        if self._state_dict is None:\n            raise ValueError(\"The state dictionary is empty.\")\n\n        state: Dict[str, Any] = self._state_dict\n\n        if self.distributed_env.world_size != state[\"world_size\"]:\n            raise ValueError(\n                f\"The distributed environment has changed. The world size is {self.distributed_env.world_size} \"\n                f\"while the state dictionary has {state['world_size']}\"\n            )\n\n        if self.input_dir.path != state[\"input_dir_path\"] or self.input_dir.url != state[\"input_dir_url\"]:\n            raise ValueError(\n                f\"The input directory has changed. The path is {self.input_dir.path} \"\n                f\"while the state dictionary has {state['input_dir_path']}.\"\n            )\n\n        if self.item_loader is not None and self.item_loader.state_dict() != state[\"item_loader\"]:\n            raise ValueError(\n                f\"The item loader has changed. The state dict is {self.item_loader.state_dict()} \"\n                f\"while the state dictionary has {state['item_loader']}\"\n            )\n\n        if self.drop_last != state[\"drop_last\"]:\n            raise ValueError(\n                f\"The drop last flag has changed. The current flag is {self.drop_last} \"\n                f\"while the state dictionary has {state['drop_last']}\"\n            )\n\n        if self.seed != state[\"seed\"]:\n            raise ValueError(\n                f\"The seed has changed. The current seed is {self.seed} \"\n                f\"while the state dictionary has {state['seed']}\"\n            )\n\n        if self.shuffle != state[\"shuffle\"]:\n            raise ValueError(\n                f\"The shuffle flag has changed. The current flag is {self.shuffle} \"\n                f\"while"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state: Dict[str, Any] = self._state_dict\n\n        # validate the input directory\n        input_dir_path = state[\"input_dir_path\"]\n        input_dir_url = state[\"input_dir_url\"]\n        if _should_replace_path(input_dir_path):\n            if input_dir_path != self.input_dir.path:\n                raise ValueError(\n                    f\"The input directory path {input_dir_path} in the state dictionary does not match the current input directory path {self.input_dir.path}\"\n                )\n        else:\n            if input_dir_url != self.input_dir.url:\n                raise ValueError(\n                    f\"The input directory url {input_dir_url} in the state dictionary does not match the current input directory url {self.input_dir.url}\"\n                )\n\n        # validate the shuffle\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The shuffle {state['shuffle']} in the state dictionary does not match the current shuffle {self.shuffle}\"\n            )\n\n        # validate the seed\n        if state[\"seed\"] != self.seed:\n            raise ValueError(f\"The seed {state['seed']} in the state dictionary does not match the current seed {self.seed}\")\n\n        # validate the item_loader\n        if self.item_loader is not None:\n            if state[\"item_loader\"] is None:\n                raise ValueError(\n                    \"The item_loader is not None in the state dictionary but None in the current StreamingDataset instance.\"\n                )\n            else:\n                self.item_loader.load_state_dict(state[\"item_loader\"])\n        else:\n            if state[\"item_loader\"] is not None:\n                raise ValueError(\n                    \"The item_loader is None in the state dictionary but not None in the current StreamingDataset instance.\"\n                )\n\n        # validate the drop_last\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\n                f\"The drop_last {"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `validate_state_dict` should only be called in the main process.\")\n\n        if self._state_dict is None:\n            return\n\n        state: Dict[str, Any] = self._state_dict\n\n        # check if the state dictionary is valid\n        if not isinstance(state, dict):\n            raise ValueError(f\"The state dictionary is not a valid dictionary. Found {type(state)}\")\n\n        # check if the state dictionary has the required keys\n        required_keys = [\"num_samples_yielded\", \"num_workers\", \"batch_size\", \"current_epoch\", \"input_dir_path\", \"input_dir_url\", \"item_loader\", \"drop_last\", \"seed\", \"world_size\", \"shuffle\"]\n        for key in required_keys:\n            if key not in state:\n                raise ValueError(f\"The state dictionary is missing the key {key}.\")\n\n        # check if the state dictionary is valid\n        if not isinstance(state[\"num_samples_yielded\"], int):\n            raise ValueError(f\"The state dictionary contains an invalid value for the key `num_samples_yielded`. Found {type(state['num_samples_yielded'])}\")\n\n        if not isinstance(state[\"num_workers\"], int):\n            raise ValueError(f\"The state dictionary contains an invalid value for the key `num_workers`. Found {type(state['num_workers'])}\")\n\n        if not isinstance(state[\"batch_size\"], int):\n            raise ValueError(f\"The state dictionary contains an invalid value for the key `batch_size`. Found {type(state['batch_size'])}\")\n\n        if not isinstance(state[\"current_epoch\"], int):\n            raise ValueError(f\"The state dictionary contains an invalid value for the key `current_epoch`. Found {type(state['current_epoch'])}\")\n\n        if not isinstance(state[\"input_dir_path\"], str):\n            raise ValueError(f\"The state dictionary contains an invalid"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if not self._state_dict:\n            raise ValueError(\"The state dictionary is empty.\")\n\n        if not self.worker_env:\n            raise ValueError(\"The worker environment is not initialized.\")\n\n        if not self.cache:\n            raise ValueError(\"The cache is not initialized.\")\n\n        if self.cache.serializers is None:\n            raise ValueError(\"The cache serializers are not initialized.\")\n\n        if self.cache.input_dir is None:\n            raise ValueError(\"The cache input_dir is not initialized.\")\n\n        if self.cache.input_dir.path is None and self.cache.input_dir.url is None:\n            raise ValueError(\"The cache input_dir path and url are not initialized.\")\n\n        if self.cache.input_dir.path and self.cache.input_dir.url:\n            raise ValueError(\"The cache input_dir path and url cannot be both initialized.\")\n\n        if self.cache.item_loader is None:\n            raise ValueError(\"The cache item_loader is not initialized.\")\n\n        if self.cache.item_loader.state_dict() is None:\n            raise ValueError(\"The cache item_loader state_dict is not initialized.\")\n\n        if self.shuffle is None:\n            raise ValueError(\"The shuffle is not initialized.\")\n\n        if self.distributed_env.world_size is None:\n            raise ValueError(\"The distributed_env world_size is not initialized.\")\n\n        if self.distributed_env.global_rank is None:\n            raise ValueError(\"The distributed_env global_rank is not initialized.\")\n\n        if self.distributed_env.local_rank is None:\n            raise ValueError(\"The distributed_env local_rank is not initialized.\")\n\n        if self.distributed_env.node_rank is None:\n            raise ValueError(\"The distributed_env node_rank is not initialized.\")\n\n        if self.distributed_env.num_nodes is None:\n            raise ValueError(\"The distributed_env num_nodes is not initialized.\")\n\n        if self.distributed_env.world_size is None:\n            raise ValueError(\"The distributed_env"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict is None:\n            raise ValueError(\n                \"The state dictionary is None. Please provide a valid state dictionary to validate.\"\n            )\n\n        if self.worker_env is None:\n            raise ValueError(\"The worker environment is None. Please provide a valid worker environment to validate.\")\n\n        if self.cache is None:\n            raise ValueError(\"The cache is None. Please provide a valid cache to validate.\")\n\n        state: Dict[str, Any] = self._state_dict\n\n        # Validate the input directory path and URL\n        input_dir_path = state[\"input_dir_path\"]\n        input_dir_url = state[\"input_dir_url\"]\n        if input_dir_path != self.input_dir.path or input_dir_url != self.input_dir.url:\n            raise ValueError(\n                f\"The input directory path and URL mismatch. The current values are: {self.input_dir.path} and {self.input_dir.url}. The values in the state dictionary are: {input_dir_path} and {input_dir_url}.\"\n            )\n\n        # Validate the item_loader state\n        item_loader_state = state[\"item_loader\"]\n        if item_loader_state:\n            if not self.item_loader:\n                raise ValueError(\n                    \"The item loader is None. Please provide a valid item loader to validate.\"\n                )\n            self.item_loader.load_state_dict(item_loader_state)\n\n        # Validate the shuffle, drop_last, seed, and world_size parameters\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The shuffle parameter mismatch. The current value is {self.shuffle}. The value in the state dictionary is {state['shuffle']}.\"\n            )\n\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\n                f\"The drop_last parameter mismatch. The current value is {self.drop_last}. The value in the state dictionary is {state['drop_last']}.\"\n            )"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    # If the input directory is None, we use an empty string as the input directory.\n    if input_dir is None:\n        input_dir = \"\"\n\n    # If the input directory is empty, we use an empty string as the input directory.\n    if input_dir == \"\":\n        input_dir = \"\"\n\n    # If the input directory is not empty, we use it as the input directory.\n    if input_dir != \"\":\n        input_dir = input_dir\n\n    # If the input directory is not empty, we use it as the input directory.\n    if input_dir != \"\":\n        input_dir = input_dir\n\n    # If the input directory is not empty, we use it as the input directory.\n    if input_dir != \"\":\n        input_dir = input_dir\n\n    # If the input directory is not empty, we use it as the input directory.\n    if input_dir != \"\":\n        input_dir = input_dir\n\n    # If the input directory is not empty, we use it as the input directory.\n    if input_dir != \"\":\n        input_dir = input_dir\n\n    # If the input directory is not empty, we use it as the input directory.\n    if input_dir != \"\":\n        input_dir = input_dir\n\n    # If the input directory is not empty, we use it as the input directory.\n    if input_dir != \"\":\n        input_dir = input_dir\n\n    # If the input directory is not empty, we use it as the input directory.\n    if input_dir != \"\":\n        input_dir = input_dir\n\n    # If the input directory is not empty, we use it as the input directory.\n    if input_dir != \"\":\n        input_dir = input_dir\n\n    # If the input directory is not empty, we use it as the input directory.\n    if input_dir != \"\":\n        input_dir = input_dir\n\n    # If the input directory is not empty, we use it as the input directory.\n    if input_dir != \"\":\n        input_dir = input_dir\n\n    # If the input directory"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Hash the input directory\n    input_dir_hash = hashlib.sha256(input_dir.encode(\"utf-8\")).hexdigest()\n\n    # Create a cache directory\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, input_dir_hash)\n\n    # Create the cache directory if it does not exist\n    if not os.path.exists(cache_dir):\n        try:\n            os.makedirs(cache_dir)\n        except Exception as e:\n            logger.error(f\"Failed to create cache directory at {cache_dir}. Error: {e}\")\n            return None\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Hash the input directory\n    input_dir_hash = hashlib.sha256(input_dir.encode(\"utf-8\")).hexdigest()\n\n    # If the environment variables are not set, create the cache directory in the default location.\n    if os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\") is None and os.getenv(\"DATA_OPTIMIZER_GLOBAL_RANK\") is None:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, input_dir_hash)\n    # Otherwise, create the cache directory in the specified location.\n    else:\n        cache_dir = os.path.join(os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\"), input_dir_hash)\n\n    try:\n        os.makedirs(cache_dir, exist_ok=True)\n        return cache_dir\n    except:\n        return None\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.md5(input_dir.encode(\"utf-8\")).hexdigest())\n    try:\n        os.makedirs(cache_dir, exist_ok=True)\n    except Exception:\n        return None\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Hash the input directory\n    input_dir_hash = hashlib.sha256(input_dir.encode(\"utf-8\")).hexdigest()\n\n    # Get the cache directory path\n    cache_dir_path = os.path.join(_DEFAULT_CACHE_DIR, input_dir_hash)\n\n    # Create the cache directory\n    try:\n        os.makedirs(cache_dir_path, exist_ok=True)\n    except Exception:\n        return None\n\n    return cache_dir_path\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.md5(input_dir.encode(\"utf-8\")).hexdigest())\n    if not os.path.exists(cache_dir):\n        try:\n            os.makedirs(cache_dir)\n        except:\n            return None\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Hash the input directory\n    input_dir_hash = hashlib.sha1(input_dir.encode(\"utf-8\")).hexdigest()\n\n    # Create a cache directory\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, input_dir_hash)\n\n    # If the cache directory already exists, return the path to the cache directory.\n    if os.path.isdir(cache_dir):\n        return cache_dir\n\n    # If the cache directory does not exist, create the cache directory.\n    try:\n        os.makedirs(cache_dir)\n        return cache_dir\n    except Exception:\n        return None\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    # Hash the input directory\n    input_dir_hash = hashlib.md5(input_dir.encode() if input_dir else \"\".encode()).hexdigest()\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, input_dir_hash)\n\n    # Create the cache directory\n    try:\n        os.makedirs(cache_dir, exist_ok=True)\n    except Exception as e:\n        logger.error(f\"Failed to create cache directory {cache_dir}.\")\n        logger.error(e)\n        return None\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Hash the input directory\n    input_dir_hash = hashlib.sha256(input_dir.encode()).hexdigest()\n\n    # Create the cache directory\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, input_dir_hash)\n    try:\n        if not os.path.exists(cache_dir):\n            os.makedirs(cache_dir)\n    except Exception as e:\n        logger.error(f\"Failed to create cache directory: {cache_dir}\")\n        logger.error(e)\n        return None\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Hash the input directory\n    input_dir_hash = hashlib.sha1(input_dir.encode(\"utf-8\")).hexdigest()\n\n    # Create a unique directory name\n    cache_dir_name = f\"litdata-cache-{input_dir_hash}\"\n\n    # Create the cache directory\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, cache_dir_name)\n\n    try:\n        os.makedirs(cache_dir, exist_ok=True)\n    except Exception as e:\n        logger.warn(f\"Could not create cache directory: {cache_dir}\")\n        return None\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    cache_dir = _DEFAULT_CACHE_DIR\n\n    if input_dir is None:\n        input_dir = \"\"\n\n    # If the environment variables are set, create the cache directory in the specified location.\n    if os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\"):\n        cache_dir = os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\")\n\n    # If the environment variables are not set, create the cache directory in the default location.\n    if not os.path.exists(cache_dir):\n        try:\n            os.makedirs(cache_dir)\n        except Exception:\n            return None\n\n    # Generate a unique directory name by hashing the input directory.\n    input_dir_hash = hashlib.md5(input_dir.encode(\"utf-8\")).hexdigest()\n\n    cache_path = os.path.join(cache_dir, input_dir_hash)\n\n    return cache_path\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Create a unique directory name by hashing the input directory.\n    input_dir_hash = hashlib.md5(input_dir.encode(\"utf-8\")).hexdigest()\n\n    # If certain environment variables are not set, it creates the cache directory in a default location; otherwise, it creates it in a specified location.\n    if os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\") is None:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, input_dir_hash)\n    else:\n        cache_dir = os.path.join(os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\"), input_dir_hash)\n\n    # Create the cache directory.\n    try:\n        os.makedirs(cache_dir, exist_ok=True)\n    except OSError as e:\n        print(f\"Error: {e}\")\n        return None\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Generate a unique directory name based on the input directory provided.\n    input_dir_hash = hashlib.sha256(input_dir.encode(\"utf-8\")).hexdigest()\n\n    # Try to create a cache directory in a default location.\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, input_dir_hash)\n    try:\n        os.makedirs(cache_dir)\n    except Exception:\n        # Try to create a cache directory in a specified location.\n        if os.environ.get(\"DATA_OPTIMIZER_CACHE_DIR\") is not None:\n            cache_dir = os.path.join(os.environ.get(\"DATA_OPTIMIZER_CACHE_DIR\"), input_dir_hash)\n            try:\n                os.makedirs(cache_dir)\n            except Exception:\n                return None\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    # If the input directory is None, we hash an empty string\n    if input_dir is None:\n        input_dir = \"\"\n\n    # Hash the input directory\n    hashed_input_dir = hashlib.md5(input_dir.encode(\"utf-8\")).hexdigest()\n\n    # Get the default cache directory path\n    default_cache_dir_path = os.path.join(_DEFAULT_CACHE_DIR, hashed_input_dir)\n\n    # Get the cache directory path from the environment variables\n    cache_dir_path = os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\")\n\n    # If the cache directory path is not set, use the default cache directory path\n    if cache_dir_path is None:\n        cache_dir_path = default_cache_dir_path\n    else:\n        # If the cache directory path is set, but the directory does not exist, raise an error\n        if not os.path.exists(cache_dir_path):\n            raise ValueError(\n                f\"The cache directory path `{cache_dir_path}` is not valid. \"\n                \"Please set the `DATA_OPTIMIZER_CACHE_DIR` environment variable to a valid directory path.\"\n            )\n\n    # Create the cache directory\n    os.makedirs(cache_dir_path, exist_ok=True)\n\n    # Return the cache directory path\n    return cache_dir_path\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Create a unique directory name by hashing the input directory\n    hash_object = hashlib.md5(input_dir.encode())\n    cache_dir_name = hash_object.hexdigest()\n\n    # If certain environment variables are not set, it creates the cache directory in a default location\n    if os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\") is None:\n        cache_dir_path = os.path.join(_DEFAULT_CACHE_DIR, cache_dir_name)\n    # Otherwise, it creates it in a specified location\n    else:\n        cache_dir_path = os.path.join(os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\"), cache_dir_name)\n\n    # Create the cache directory\n    try:\n        os.makedirs(cache_dir_path)\n    except OSError as e:\n        # If the directory already exists, do nothing\n        if e.errno != errno.EEXIST:\n            raise\n\n    return cache_dir_path\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    hash_object = hashlib.sha1(input_dir.encode())\n    hex_dig = hash_object.hexdigest()\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hex_dig)\n\n    # TODO: Handle the case where the cache directory already exists.\n    # TODO: Handle the case where the cache directory cannot be created.\n    try:\n        os.makedirs(cache_dir)\n    except OSError:\n        pass\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Hash the input directory to create a unique directory name.\n    cache_dir_name = hashlib.md5(input_dir.encode(\"utf-8\")).hexdigest()\n\n    # Create the cache directory in a default location if the environment variables are not set.\n    if os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\") is None:\n        cache_dir_path = os.path.join(_DEFAULT_CACHE_DIR, cache_dir_name)\n    else:\n        cache_dir_path = os.path.join(os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\"), cache_dir_name)\n\n    try:\n        # Create the cache directory if it doesn't exist.\n        if not os.path.exists(cache_dir_path):\n            os.makedirs(cache_dir_path)\n\n        # Check if the cache directory has been created.\n        if os.path.exists(cache_dir_path):\n            return cache_dir_path\n\n    except Exception as e:\n        print(f\"Error: {e}\")\n        return None\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Create a hash of the input directory\n    hash = hashlib.sha256(input_dir.encode(\"utf-8\")).hexdigest()\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hash)\n\n    # Attempt to create the cache directory\n    try:\n        os.makedirs(cache_dir, exist_ok=True)\n    except Exception:\n        return None\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Hash the input directory\n    input_dir_hash = hashlib.md5(input_dir.encode(\"utf-8\")).hexdigest()\n\n    # Create a cache directory\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, input_dir_hash)\n\n    # If the cache directory exists, return the path to the cache directory\n    if os.path.exists(cache_dir):\n        return cache_dir\n\n    # If the cache directory doesn't exist, try to create it\n    try:\n        os.makedirs(cache_dir)\n    except Exception as e:\n        logger.warning(f\"Could not create the cache directory: {cache_dir}\")\n        logger.warning(f\"Error: {e}\")\n        return None\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Get the unique hash of the input directory.\n    input_dir_hash = hashlib.md5(input_dir.encode(\"utf-8\")).hexdigest()\n\n    # Get the path to the cache directory.\n    cache_path = os.path.join(_DEFAULT_CACHE_DIR, input_dir_hash)\n\n    # Attempt to create the cache directory.\n    try:\n        os.makedirs(cache_path, exist_ok=True)\n    except OSError as e:\n        logger.warning(f\"The cache directory `{cache_path}` could not be created. Error: {e}\")\n        return None\n\n    return cache_path\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if not remote_filepath.startswith(\"s3://\"):\n            raise ValueError(\"The remote file path must be an S3 URL.\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        scheme, netloc, path = parse.urlsplit(remote_filepath)[:3]\n\n        if self._s5cmd_available:\n            with FileLock(local_filepath + \".lock\", timeout=30):\n                if not os.path.exists(local_filepath):\n                    subprocess.run(\n                        [\n                            \"s5cmd\",\n                            \"cp\",\n                            \"--no-progress\",\n                            f\"{scheme}://{netloc}{path}\",\n                            local_filepath,\n                        ],\n                        check=True,\n                    )\n        else:\n            with FileLock(local_filepath + \".lock\", timeout=30):\n                if not os.path.exists(local_filepath):\n                    self._client.download_file(netloc, path, local_filepath)\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if not remote_filepath.startswith(\"s3://\"):\n            raise ValueError(\"Remote file path must be an S3 URL\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        parsed_remote_filepath = parse.urlparse(remote_filepath)\n        s3_bucket = parsed_remote_filepath.netloc\n        s3_key = parsed_remote_filepath.path[1:]\n\n        lock_filepath = f\"{local_filepath}.lock\"\n        with FileLock(lock_filepath):\n            if self._s5cmd_available:\n                s5cmd_args = [\"s5cmd\", \"cp\", f\"s3://{s3_bucket}/{s3_key}\", local_filepath]\n                subprocess.run(s5cmd_args, check=True)\n            else:\n                self._client.download_file(s3_bucket, s3_key, local_filepath)\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if not remote_filepath.startswith(\"s3://\"):\n            raise ValueError(\n                \"The remote file path must be a valid S3 URL starting with 's3://'.\"\n            )\n\n        if os.path.exists(local_filepath):\n            return\n\n        try:\n            with FileLock(local_filepath + \".lock\", timeout=120):\n                if self._s5cmd_available:\n                    self._download_file_s5cmd(remote_filepath, local_filepath)\n                else:\n                    self._download_file_boto3(remote_filepath, local_filepath)\n\n        except Timeout:\n            raise Timeout(\n                \"Another process is currently downloading the file. Please try again later.\"\n            )\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if not remote_filepath.startswith(\"s3://\"):\n            raise ValueError(\"remote_filepath must be a valid S3 URL\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        parsed_url = parse.urlparse(remote_filepath)\n        bucket_name = parsed_url.netloc\n        s3_key = parsed_url.path.lstrip(\"/\")\n\n        if self._s5cmd_available:\n            self._download_file_s5cmd(bucket_name, s3_key, local_filepath)\n        else:\n            self._download_file_boto3(bucket_name, s3_key, local_filepath)\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        # Parse the remote filepath\n        parsed_remote_filepath = parse.urlparse(remote_filepath)\n\n        # Check if the remote filepath is an S3 URL\n        if parsed_remote_filepath.scheme != \"s3\":\n            raise ValueError(f\"Remote filepath {remote_filepath} does not use the 's3' scheme.\")\n\n        # Check if the local file already exists\n        if os.path.exists(local_filepath):\n            return\n\n        # Acquire a lock on the local file\n        with FileLock(local_filepath + \".lock\", timeout=60):\n\n            # Check if the local file already exists\n            if os.path.exists(local_filepath):\n                return\n\n            # Download the file\n            if self._s5cmd_available:\n                subprocess.run(\n                    [\n                        \"s5cmd\",\n                        \"cp\",\n                        f\"s3://{parsed_remote_filepath.netloc}{parsed_remote_filepath.path}\",\n                        local_filepath,\n                    ]\n                )\n            else:\n                self._client.download_file(\n                    parsed_remote_filepath.netloc,\n                    parsed_remote_filepath.path[1:],\n                    local_filepath,\n                )\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if not remote_filepath.startswith(\"s3://\"):\n            raise ValueError(\"The remote file path must use the s3 scheme.\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        scheme, bucket, path = self._parse_s3_url(remote_filepath)\n\n        lock_path = f\"{local_filepath}.lock\"\n        with FileLock(lock_path, timeout=120):\n            if self._s5cmd_available:\n                self._download_file_s5cmd(remote_filepath, local_filepath)\n            else:\n                self._download_file_boto3(remote_filepath, local_filepath)\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        # check if the file already exists\n        if os.path.isfile(local_filepath):\n            return\n\n        # check if the remote file path is an S3 URL\n        if not remote_filepath.startswith(\"s3://\"):\n            raise ValueError(\"The remote file path must be an S3 URL.\")\n\n        # check if s5cmd is available\n        if self._s5cmd_available:\n            # download the file using s5cmd\n            s5cmd_args = [\n                \"s5cmd\",\n                \"cp\",\n                remote_filepath,\n                local_filepath,\n            ]\n            subprocess.run(s5cmd_args, check=True)\n\n        else:\n            # download the file using boto3\n            with FileLock(local_filepath + \".lock\", timeout=10):\n                self._client.download_file(remote_filepath, local_filepath)\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        # check if the remote file path is an S3 URL\n        url_components = parse.urlparse(remote_filepath)\n        if url_components.scheme != \"s3\":\n            raise ValueError(f\"The remote file path {remote_filepath} is not an S3 URL.\")\n\n        # check if the local file already exists\n        if os.path.exists(local_filepath):\n            return\n\n        # create the local directory if it does not exist\n        local_dir = os.path.dirname(local_filepath)\n        if not os.path.exists(local_dir):\n            os.makedirs(local_dir)\n\n        # acquire a file lock\n        lock = FileLock(local_filepath + \".lock\", timeout=120)\n        try:\n            lock.acquire()\n\n            # download the file using s5cmd if available\n            if self._s5cmd_available:\n                s5cmd_command = f\"s5cmd cp {remote_filepath} {local_filepath}\"\n                subprocess.run(s5cmd_command.split(), check=True)\n\n            # download the file using boto3 if s5cmd is not available\n            else:\n                self._client.download_file(url_components.netloc, url_components.path[1:], local_filepath)\n\n        except Timeout:\n            raise Timeout(f\"The file lock for {local_filepath} could not be acquired.\")\n\n        finally:\n            lock.release()\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        # Check if the remote filepath is an S3 URL\n        parsed_remote_filepath = parse.urlparse(remote_filepath)\n        if parsed_remote_filepath.scheme != \"s3\":\n            raise ValueError(\"The remote file path must be an S3 URL.\")\n\n        # Check if the local file already exists\n        if os.path.exists(local_filepath):\n            return\n\n        # Acquire a file lock\n        lock_path = local_filepath + \".lock\"\n        lock = FileLock(lock_path)\n        try:\n            lock.acquire(timeout=60)\n        except Timeout:\n            raise Timeout(\"Could not acquire a file lock.\")\n\n        # Download the file\n        if self._s5cmd_available:\n            subprocess.check_call(\n                [\n                    \"s5cmd\",\n                    \"get\",\n                    f\"s3://{parsed_remote_filepath.netloc}{parsed_remote_filepath.path}\",\n                    local_filepath,\n                ]\n            )\n        else:\n            self._client.download_file(\n                parsed_remote_filepath.netloc,\n                parsed_remote_filepath.path[1:],\n                local_filepath,\n            )\n\n        # Release the file lock\n        lock.release()\n\n        # Delete the lock file\n        os.remove(lock_path)\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        # check if the remote file path is an S3 URL\n        parsed_s3_url = parse.urlparse(remote_filepath)\n        if parsed_s3_url.scheme != \"s3\":\n            raise ValueError(\n                \"The remote file path must be an S3 URL. The scheme must be 's3'.\"\n            )\n\n        # check if the file already exists\n        if os.path.exists(local_filepath):\n            return\n\n        # acquire a file lock\n        lock_path = local_filepath + \".lock\"\n        lock = FileLock(lock_path)\n        try:\n            lock.acquire(timeout=1)\n        except Timeout:\n            raise Timeout(\n                \"The file lock could not be acquired. The file may be in the process of being downloaded by another process.\"\n            )\n\n        # download the file\n        if self._s5cmd_available:\n            # download the file using s5cmd\n            s5cmd_args = [\"s5cmd\", \"cp\", remote_filepath, local_filepath]\n            subprocess.run(s5cmd_args)\n        else:\n            # download the file using boto3\n            self._client.download_file(parsed_s3_url.netloc, parsed_s3_url.path[1:], local_filepath)\n\n        # release the file lock\n        lock.release()\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        # Check if the remote file path is an S3 URL\n        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(\n                \"The remote file path must be an S3 URL (i.e. use the 's3' scheme)\"\n            )\n\n        # Check if the file already exists\n        if os.path.exists(local_filepath):\n            return\n\n        # Acquire a lock on the local file path\n        lock = FileLock(local_filepath + \".lock\")\n        try:\n            lock.acquire(timeout=60)\n        except Timeout:\n            raise Timeout(\n                \"The lock on the local file path could not be acquired within 60 seconds\"\n            )\n\n        # Download the file\n        if self._s5cmd_available:\n            # If s5cmd is available, use it to download the file\n            s5cmd_args = [\"s5cmd\", \"cp\", remote_filepath, local_filepath]\n            subprocess.run(s5cmd_args, check=True)\n        else:\n            # Otherwise, use the boto3 library to download the file\n            self._client.download_file(parsed_url.netloc, parsed_url.path[1:], local_filepath)\n\n        # Release the lock\n        lock.release()\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        # Parse the remote file path\n        parsed_url = parse.urlparse(remote_filepath)\n        s3_scheme = \"s3\"\n        if parsed_url.scheme != s3_scheme:\n            raise ValueError(f\"The remote file path must use the {s3_scheme} scheme.\")\n        bucket = parsed_url.netloc\n        key = parsed_url.path[1:]\n\n        # Check if the local file already exists\n        if os.path.exists(local_filepath):\n            return\n\n        # Acquire a lock on the local file path\n        lock_path = local_filepath + \".lock\"\n        lock = FileLock(lock_path)\n        try:\n            lock.acquire(timeout=60)\n        except Timeout:\n            raise Timeout(f\"Could not acquire lock on {local_filepath} after 60 seconds.\")\n\n        # Download the file\n        if self._s5cmd_available:\n            cmd = f\"s5cmd cp s3://{bucket}/{key} {local_filepath}\"\n            subprocess.run(cmd, shell=True, check=True)\n        else:\n            self._client.download_file(bucket, key, local_filepath)\n\n        # Release the lock\n        lock.release()\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if not remote_filepath.startswith(\"s3://\"):\n            raise ValueError(\"Remote file path must be an S3 URL.\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        scheme, bucket, path, _, _, _ = parse.urlparse(remote_filepath)\n\n        if self._s5cmd_available:\n            self._download_file_s5cmd(bucket, path, local_filepath)\n        else:\n            self._download_file_boto3(bucket, path, local_filepath)\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if not remote_filepath.startswith(\"s3://\"):\n            raise ValueError(\"Remote file path must be an S3 URL.\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        # create directory if it does not exist\n        local_dir = os.path.dirname(local_filepath)\n        if not os.path.exists(local_dir):\n            os.makedirs(local_dir)\n\n        # get the bucket name and the key\n        parsed_url = parse.urlparse(remote_filepath)\n        bucket_name = parsed_url.netloc\n        key = parsed_url.path[1:]\n\n        # get the lock path\n        lock_path = local_filepath + \".lock\"\n\n        # acquire the lock\n        lock = FileLock(lock_path)\n        try:\n            lock.acquire(timeout=60)\n        except Timeout:\n            raise Timeout(\"Could not acquire lock on {}\".format(lock_path))\n\n        # download the file\n        if self._s5cmd_available:\n            command = [\"s5cmd\", \"get\", \"s3://{}/{}\".format(bucket_name, key), local_filepath]\n            subprocess.run(command, check=True)\n        else:\n            self._client.download_file(bucket_name, key, local_filepath)\n\n        # release the lock\n        lock.release()\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if not remote_filepath.startswith(\"s3://\"):\n            raise ValueError(\n                f\"The remote file path {remote_filepath} is not a valid S3 URL.\"\n            )\n\n        if os.path.exists(local_filepath):\n            return\n\n        # Create the local directory if it does not exist\n        local_dir = os.path.dirname(local_filepath)\n        if not os.path.exists(local_dir):\n            os.makedirs(local_dir)\n\n        # Acquire a file lock\n        lock = FileLock(local_filepath + \".lock\")\n        try:\n            lock.acquire(timeout=600)\n        except Timeout:\n            raise Timeout(\n                f\"Could not acquire a file lock on {local_filepath} after 10 minutes.\"\n            )\n\n        if self._s5cmd_available:\n            # Download the file using s5cmd\n            s3_bucket = parse.urlparse(remote_filepath).netloc\n            s3_key = parse.urlparse(remote_filepath).path.lstrip(\"/\")\n            s5cmd_args = [\"s5cmd\", \"get\", s3_bucket, s3_key, local_filepath]\n            s5cmd_process = subprocess.run(s5cmd_args, capture_output=True)\n            if s5cmd_process.returncode != 0:\n                raise ValueError(\n                    f\"s5cmd failed to download {remote_filepath} to {local_filepath}.\"\n                )\n        else:\n            # Download the file using boto3\n            self._client.download_file(remote_filepath, local_filepath)\n\n        # Release the file lock\n        lock.release()\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        # Parse the S3 URL\n        parsed_s3_url = parse.urlparse(remote_filepath)\n\n        # Check if the remote file path is an S3 URL\n        if parsed_s3_url.scheme != \"s3\":\n            raise ValueError(\n                \"The remote file path must be an S3 URL. The given remote file path is: {}\".format(\n                    remote_filepath\n                )\n            )\n\n        # Check if the local file already exists\n        if os.path.exists(local_filepath):\n            return\n\n        # Get the S3 bucket name and the S3 key\n        bucket_name = parsed_s3_url.netloc\n        key = parsed_s3_url.path[1:]\n\n        # Get the file lock\n        lock = FileLock(local_filepath + \".lock\")\n        try:\n            lock.acquire(timeout=600)\n        except Timeout:\n            raise Timeout(\n                \"The file lock for the local file {} could not be acquired within 10 minutes.\".format(\n                    local_filepath\n                )\n            )\n\n        # Download the file using s5cmd if available\n        if self._s5cmd_available:\n            cmd = [\n                \"s5cmd\",\n                \"cp\",\n                \"s3://{}/{}\".format(bucket_name, key),\n                local_filepath,\n            ]\n            subprocess.run(cmd, check=True)\n        else:\n            self._client.download_file(bucket_name, key, local_filepath)\n\n        # Release the file lock\n        lock.release()\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        # Check if the remote file path is an S3 URL\n        if not remote_filepath.startswith(\"s3://\"):\n            raise ValueError(\"Remote file path must be a valid S3 URL\")\n\n        # Parse the S3 URL\n        s3_parsed = parse.urlparse(remote_filepath)\n\n        # Check if the local file already exists\n        if os.path.exists(local_filepath):\n            return\n\n        # Create the local file path directory if it does not exist\n        local_dir = os.path.dirname(local_filepath)\n        if not os.path.exists(local_dir):\n            os.makedirs(local_dir)\n\n        # Acquire a file lock for the local file\n        lock_path = local_filepath + \".lock\"\n        lock = FileLock(lock_path)\n        try:\n            with lock.acquire(timeout=10):\n                # Download the file using s5cmd\n                if self._s5cmd_available:\n                    cmd = [\"s5cmd\", \"cp\", s3_parsed.netloc + s3_parsed.path, local_filepath]\n                    subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n                # Download the file using boto3\n                else:\n                    self._client.download_file(s3_parsed.netloc, s3_parsed.path[1:], local_filepath)\n        except Timeout:\n            raise Timeout(\"Could not acquire lock on {}\".format(local_filepath))\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        # Parse the S3 URL\n        url = parse.urlparse(remote_filepath)\n\n        # Check if the remote file path is a valid S3 URL\n        if url.scheme != \"s3\":\n            raise ValueError(\"The remote file path is not a valid S3 URL.\")\n\n        # Check if the local file already exists\n        if os.path.isfile(local_filepath):\n            return\n\n        # Acquire a file lock\n        lock_filepath = os.path.join(self._cache_dir, \".{}.lock\".format(os.path.basename(local_filepath)))\n        lock = FileLock(lock_filepath)\n        try:\n            with lock.acquire(timeout=30):\n                # Check if the local file already exists\n                if os.path.isfile(local_filepath):\n                    return\n\n                # Download the file using s5cmd\n                if self._s5cmd_available:\n                    subprocess.run([\"s5cmd\", \"cp\", \"--recursive\", \"--quiet\", remote_filepath, local_filepath])\n                else:\n                    self._client.download_file(url.netloc, url.path[1:], local_filepath)\n        except Timeout:\n            raise Timeout(\"The file lock could not be acquired.\")\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        # Check if the remote file path is an S3 URL\n        if not remote_filepath.startswith(\"s3://\"):\n            raise ValueError(\n                \"The remote file path must be an S3 URL with the s3:// scheme.\"\n            )\n\n        # Check if the local file already exists\n        if os.path.exists(local_filepath):\n            return\n\n        # Check if s5cmd is available\n        if self._s5cmd_available:\n            # Parse the S3 URL\n            parsed_url = parse.urlparse(remote_filepath)\n            # Create the S3 path\n            s3_path = \"s3://{}/{}\".format(parsed_url.netloc, parsed_url.path[1:])\n            # Create the local path\n            local_path = os.path.dirname(local_filepath)\n            # Create the local file name\n            local_filename = os.path.basename(local_filepath)\n            # Create the s5cmd command\n            s5cmd_cmd = \"s5cmd get {} {}\".format(s3_path, local_path)\n            # Append the file name to the s5cmd command\n            s5cmd_cmd += \" --include {}\".format(local_filename)\n            # Append the S3 credentials to the s5cmd command\n            s5cmd_cmd += \" --key {} --secret {}\".format(\n                self._client.access_key, self._client.secret_key\n            )\n            # Append the S3 region to the s5cmd command\n            s5cmd_cmd += \" --region {}\".format(self._client.region)\n\n            # Run the s5cmd command\n            subprocess.run(s5cmd_cmd, shell=True, check=True)\n\n        # If s5cmd is not available, use the boto3 library\n        else:\n            # Create the S3 path\n            s3_path = \"s3://{}/{}\".format(\n                parsed_url.netloc, parsed_url.path[1:]\n            )\n            # Create the local path\n            local_path = os.path.dirname(local"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if not remote_filepath.startswith(\"s3://\"):\n            raise ValueError(\"remote_filepath must be an S3 URL\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        scheme, netloc, path = parse.urlparse(remote_filepath)\n        if scheme != \"s3\":\n            raise ValueError(\"remote_filepath must be an S3 URL\")\n\n        # Create a lockfile to prevent multiple processes from downloading the same file at the same time\n        lockfile = os.path.join(self._cache_dir, \".\" + os.path.basename(local_filepath) + \".lock\")\n        lock = FileLock(lockfile)\n\n        try:\n            with lock.acquire(timeout=60):\n                if self._s5cmd_available:\n                    self._s5cmd_download(remote_filepath, local_filepath)\n                else:\n                    self._boto3_download(remote_filepath, local_filepath)\n        except Timeout:\n            raise Timeout(f\"Could not acquire lock on {lockfile}\")\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # The number of chunks per worker\n    num_chunks_per_worker = len(chunks_replica) // num_workers\n\n    # The number of workers that have one more chunk than the rest\n    num_extra_workers = len(chunks_replica) % num_workers\n\n    # The number of chunks per extra worker\n    num_chunks_per_extra_worker = num_chunks_per_worker + 1\n\n    # The number of chunks per worker\n    num_chunks_per_worker = len(chunks_replica) // num_workers\n\n    # The number of workers that have one more chunk than the rest\n    num_extra_workers = len(chunks_replica) % num_workers\n\n    # The number of chunks per extra worker\n    num_chunks_per_extra_worker = num_chunks_per_worker + 1\n\n    # The number of chunks per worker\n    num_chunks_per_worker = len(chunks_replica) // num_workers\n\n    # The number of workers that have one more chunk than the rest\n    num_extra_workers = len(chunks_replica) % num_workers\n\n    # The number of chunks per extra worker\n    num_chunks_per_extra_worker = num_chunks_per_worker + 1\n\n    # The number of chunks per worker\n    num_chunks_per_worker = len(chunks_replica) // num_workers\n\n    # The number of workers that have one more chunk than the rest\n    num_extra_workers = len(chunks_replica) % num_workers\n\n    # The number of chunks per extra worker\n    num_chunks_per_extra_worker = num_chunks_per_worker + 1\n\n    # The number of chunks per worker\n    num_chunks_per_worker = len(chunks_replica) // num_workers\n\n    # The number of workers that have one more chunk than the rest\n    num_extra_workers = len(chunks"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # The number of chunks and intervals are equal\n    assert len(chunks_replica) == len(intervals_replica)\n\n    # The number of workers is equal to the world size\n    assert num_workers == worker_env.world_size\n\n    # The number of chunks is equal to the number of intervals\n    assert len(chunks_replica) == len(intervals_replica)\n\n    # The number of chunks is greater than zero\n    assert len(chunks_replica) > 0\n\n    # The number of workers is greater than zero\n    assert num_workers > 0\n\n    # The number of intervals is greater than zero\n    assert len(intervals_replica) > 0\n\n    # The number of workers is equal to the world size\n    assert num_workers == worker_env.world_size\n\n    # The number of chunks is equal to the number of intervals\n    assert len(chunks_replica) == len(intervals_replica)\n\n    # The number of chunks is greater than zero\n    assert len(chunks_replica) > 0\n\n    # The number of workers is greater than zero\n    assert num_workers > 0\n\n    # The number of intervals is greater than zero\n    assert len(intervals_replica) > 0\n\n    # The number of chunks is equal to the number of intervals\n    assert len(chunks_replica) == len(intervals_replica)\n\n    # The number of chunks is greater than zero\n    assert len(chunks_replica) > 0\n\n    # The number of workers is greater than zero\n    assert num_workers > 0\n\n    # The number of intervals is greater than zero\n    assert len(intervals_replica) > 0\n\n    # The number of chunks is equal to the number of intervals\n    assert len(chunks_replica) == len(intervals_replica)\n\n    # The number of chunks is greater than zero\n    assert len(chunks_replica) > 0\n\n    # The number of workers is greater than zero"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # Compute the number of chunks per worker\n    num_chunks_per_worker = len(chunks_replica) // num_workers\n\n    # Compute the number of workers that have one more chunk than the others\n    num_workers_with_one_more_chunk = len(chunks_replica) % num_workers\n\n    # Compute the number of chunks assigned to each worker\n    num_chunks_per_worker += 1 if worker_env.rank < num_workers_with_one_more_chunk else 0\n\n    # Compute the number of chunks assigned to the first worker\n    num_chunks_per_first_worker = num_chunks_per_worker + 1 if worker_env.rank == 0 else num_chunks_per_worker\n\n    # Compute the number of chunks assigned to the last worker\n    num_chunks_per_last_worker = num_chunks_per_worker if worker_env.rank == num_workers - 1 else num_chunks_per_worker + 1\n\n    # Compute the number of chunks assigned to the current worker\n    num_chunks_per_current_worker = (\n        num_chunks_per_first_worker\n        if worker_env.rank == 0\n        else num_chunks_per_last_worker\n        if worker_env.rank == num_workers - 1\n        else num_chunks_per_worker\n    )\n\n    # Compute the number of chunks assigned to the previous worker\n    num_chunks_per_previous_worker = (\n        num_chunks_per_last_worker\n        if worker_env.rank == 0\n        else num_chunks_per_worker\n        if worker_env.rank == num_workers - 1\n        else num_chunks_per_worker + 1\n    )\n\n    # Compute the number of chunks assigned to the next worker\n    num_chunks_per_next_worker = (\n        num_chunks_per_worker\n        if worker_env.rank == 0\n       "}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # The number of chunks\n    num_chunks = len(chunks_replica)\n\n    # The number of intervals\n    num_intervals = len(intervals_replica)\n\n    # The number of intervals per chunk\n    num_intervals_per_chunk = num_intervals // num_chunks\n\n    # The number of intervals that are left over after dividing the number of intervals by the number of chunks\n    num_intervals_left_over = num_intervals % num_chunks\n\n    # The number of chunks per worker\n    num_chunks_per_worker = num_chunks // num_workers\n\n    # The number of chunks that are left over after dividing the number of chunks by the number of workers\n    num_chunks_left_over = num_chunks % num_workers\n\n    # The number of workers that will have an additional chunk\n    num_workers_with_extra_chunk = num_chunks_left_over\n\n    # The number of workers that will have an additional interval\n    num_workers_with_extra_interval = num_intervals_left_over\n\n    # The number of intervals that are assigned to each worker that has an extra interval\n    num_extra_intervals_per_worker = num_intervals_left_over // num_workers_with_extra_interval\n\n    # The number of intervals that are left over after dividing the number of extra intervals by the number of workers with extra intervals\n    num_extra_intervals_left_over = num_intervals_left_over % num_workers_with_extra_interval\n\n    # The number of chunks that are assigned to each worker that has an extra chunk\n    num_extra_chunks_per_worker = num_chunks_left_over // num_workers_with_extra_chunk\n\n    # The number of chunks that are left over after dividing the number of extra chunks by the number of workers with extra chunks\n    num_extra_chunks_left_over = num_chunks_left_over % num_workers_with_extra_chunk\n\n    # The"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # We need to associate the chunks and intervals to the workers\n    # The logic is as follows:\n    # 1. We need to associate the chunks and intervals to the workers\n    # 2. We need to associate the chunks and intervals to the workers\n    # 3. We need to associate the chunks and intervals to the workers\n    # 4. We need to associate the chunks and intervals to the workers\n\n    assert num_workers > 0\n    assert len(chunks_replica) == len(intervals_replica)\n\n    # We need to associate the chunks and intervals to the workers\n    # We need to associate the chunks and intervals to the workers\n    # We need to associate the chunks and intervals to the workers\n    # We need to associate the chunks and intervals to the workers\n\n    workers_chunks: Dict[int, List[int]] = {}\n    workers_intervals: Dict[int, List[Any]] = {}\n\n    # We need to associate the chunks and intervals to the workers\n    # We need to associate the chunks and intervals to the workers\n    # We need to associate the chunks and intervals to the workers\n    # We need to associate the chunks and intervals to the workers\n\n    # We need to associate the chunks and intervals to the workers\n    # We need to associate the chunks and intervals to the workers\n    # We need to associate the chunks and intervals to the workers\n    # We need to associate the chunks and intervals to the workers\n\n    # We need to associate the chunks and intervals to the workers\n    # We need to associate the chunks and intervals to the workers\n    # We need to associate the chunks and intervals to the workers\n    # We need to associate the chunks and intervals to the workers\n\n    # We need to associate the chunks and intervals to the workers\n    # We need to associate the chunks and intervals to the workers\n    # We need to associate the chunks and intervals to the workers\n    # We need to associate the chunks and intervals to the workers\n\n    # We need to associate the chunks and intervals to the workers\n    # We need to associate the chunks and intervals to the"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    assert num_workers > 0\n    assert len(chunks_replica) == len(intervals_replica)\n\n    num_chunks = len(chunks_replica)\n\n    # The intervals are divided into equal chunks based on the number of workers.\n    chunks_per_worker = num_chunks // num_workers\n\n    # The last worker gets an extra chunk if the number of chunks is not divisible by the number of workers.\n    extra_chunk = num_chunks % num_workers\n\n    # The intervals are divided into equal chunks based on the number of workers.\n    chunks_per_worker = num_chunks // num_workers\n\n    # The last worker gets an extra chunk if the number of chunks is not divisible by the number of workers.\n    extra_chunk = num_chunks % num_workers\n\n    # The intervals are divided into equal chunks based on the number of workers.\n    chunks_per_worker = num_chunks // num_workers\n\n    # The last worker gets an extra chunk if the number of chunks is not divisible by the number of workers.\n    extra_chunk = num_chunks % num_workers\n\n    # The intervals are divided into equal chunks based on the number of workers.\n    chunks_per_worker = num_chunks // num_workers\n\n    # The last worker gets an extra chunk if the number of chunks is not divisible by the number of workers.\n    extra_chunk = num_chunks % num_workers\n\n    # The intervals are divided into equal chunks based on the number of workers.\n    chunks_per_worker = num_chunks // num_workers\n\n    # The last worker gets an extra chunk if the number of chunks is not divisible by the number of workers.\n    extra_chunk = num_chunks % num_workers\n\n    # The intervals are divided into equal chunks based on the number of workers.\n    chunks_per_worker = num_chunks // num_workers\n\n    # The last worker gets an extra chunk if the number of chunks is not divisible by"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # The number of chunks to be distributed among the workers.\n    num_chunks = len(chunks_replica)\n\n    # The number of chunks to be distributed to each worker.\n    chunks_per_worker = num_chunks // num_workers\n\n    # The number of chunks that are left over after distributing the chunks among the workers.\n    chunks_remainder = num_chunks % num_workers\n\n    # The number of chunks that are assigned to the current worker.\n    chunks_worker = chunks_per_worker + (1 if chunks_remainder > worker_env.rank else 0)\n\n    # The number of workers to be distributed among.\n    world_size = worker_env.world_size\n\n    # The number of workers to be distributed among.\n    workers_per_rank = world_size // num_workers\n\n    # The number of workers that are left over after distributing the workers among the ranks.\n    workers_remainder = world_size % num_workers\n\n    # The number of workers that are assigned to the current rank.\n    workers_rank = workers_per_rank + (1 if workers_remainder > worker_env.rank else 0)\n\n    # The number of workers that are assigned to the current rank.\n    workers_rank = workers_per_rank + (1 if workers_remainder > worker_env.rank else 0)\n\n    # The number of chunks that are assigned to the current rank.\n    chunks_rank = chunks_worker * workers_rank\n\n    # The number of chunks that are left over after distributing the chunks among the ranks.\n    chunks_remainder_rank = chunks_rank - chunks_worker\n\n    # The number of chunks that are assigned to the current rank.\n    chunks_rank = chunks_worker * workers_rank\n\n    # The number of chunks that are left over after distributing the chunks among the ranks.\n    chunks_remainder_rank = chunks_rank - chunks_worker\n\n    # The number of chunks that"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # We need to make sure that the lengths of chunks_replica and intervals_replica are the same.\n    assert len(chunks_replica) == len(intervals_replica)\n\n    # We need to make sure that the length of intervals_replica is not zero.\n    assert len(intervals_replica) > 0\n\n    # We need to make sure that the length of intervals_replica is not greater than the length of chunks_replica.\n    assert len(intervals_replica) <= len(chunks_replica)\n\n    # We need to make sure that the length of chunks_replica is not greater than the total number of workers.\n    assert len(chunks_replica) <= num_workers\n\n    # We need to make sure that the length of intervals_replica is not greater than the total number of workers.\n    assert len(intervals_replica) <= num_workers\n\n    # We need to make sure that the length of intervals_replica is not greater than the length of chunks_replica.\n    assert len(intervals_replica) <= len(chunks_replica)\n\n    # We need to make sure that the length of intervals_replica is not greater than the total number of workers.\n    assert len(intervals_replica) <= num_workers\n\n    # We need to make sure that the total number of workers is not zero.\n    assert num_workers > 0\n\n    # We need to make sure that the total number of workers is not greater than the length of chunks_replica.\n    assert num_workers <= len(chunks_replica)\n\n    # We need to make sure that the total number of workers is not greater than the length of intervals_replica.\n    assert num_workers <= len(intervals_replica)\n\n    # We need to make sure that the length of intervals_replica is not greater than the length of chunks_replica.\n    assert len(intervals_replica) <= len(chunks_replica)\n\n    # We need to make sure that the length of intervals_replica is not greater than the"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # TODO: Implement elastic sampling where the number of workers, ranks can change.\n    workers_chunks = {}\n    workers_intervals = {}\n\n    for i in range(num_workers):\n        worker_index = (worker_env.rank + i) % num_workers\n        workers_chunks[worker_index] = []\n        workers_intervals[worker_index] = []\n\n    for i, chunk_index in enumerate(chunks_replica):\n        worker_index = (worker_env.rank + i) % num_workers\n        workers_chunks[worker_index].append(chunk_index)\n        workers_intervals[worker_index].append(intervals_replica[i])\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # The logic below is based on the following assumptions:\n    # 1. The number of chunks and intervals are equal.\n    # 2. The chunks and intervals are distributed among the workers in a round-robin fashion.\n    # 3. The number of workers is equal to the world size defined in the worker environment.\n    # 4. The number of workers is divisible by the world size defined in the worker environment.\n\n    # The following logic is used to distribute chunks and intervals among the workers:\n    # 1. The number of chunks is divided by the world size defined in the worker environment.\n    # 2. The number of intervals is divided by the world size defined in the worker environment.\n    # 3. The chunk and interval indices are distributed among the workers in a round-robin fashion.\n\n    # The logic below is based on the following assumptions:\n    # 1. The number of chunks and intervals are equal.\n    # 2. The chunks and intervals are distributed among the workers in a round-robin fashion.\n    # 3. The number of workers is equal to the world size defined in the worker environment.\n    # 4. The number of workers is divisible by the world size defined in the worker environment.\n\n    # The following logic is used to distribute chunks and intervals among the workers:\n    # 1. The number of chunks is divided by the world size defined in the worker environment.\n    # 2. The number of intervals is divided by the world size defined in the worker environment.\n    # 3. The chunk and interval indices are distributed among the workers in a round-robin fashion.\n\n    # The logic below is based on the following assumptions:\n    # 1. The number of chunks and intervals are equal.\n    # 2. The chunks and intervals are distributed among the workers in a round-robin fashion.\n    # 3. The number of workers is equal to the world size defined in the worker environment.\n    # 4. The number of workers is divisible by the world size defined in the worker environment.\n\n    # The following logic is used to distribute chunks and intervals among the workers:\n    # 1"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # Distribute the chunks among the workers\n    workers_chunks: Dict[int, List[int]] = {}\n    for i in range(num_workers):\n        workers_chunks[i] = []\n\n    for i in range(len(chunks_replica)):\n        workers_chunks[i % num_workers].append(chunks_replica[i])\n\n    # Distribute the intervals among the workers\n    workers_intervals: Dict[int, List[Any]] = {}\n    for i in range(num_workers):\n        workers_intervals[i] = []\n\n    for i in range(len(intervals_replica)):\n        workers_intervals[i % num_workers].append(intervals_replica[i])\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    assert num_workers == worker_env.world_size\n\n    workers_chunks: Dict[int, List[int]] = {}\n    workers_intervals: Dict[int, List[Any]] = {}\n\n    for i in range(num_workers):\n        workers_chunks[i] = []\n        workers_intervals[i] = []\n\n    for chunk_index, chunk_interval in zip(chunks_replica, intervals_replica):\n        worker_index = (chunk_index + worker_env.global_rank) % num_workers\n        workers_chunks[worker_index].append(chunk_index)\n        workers_intervals[worker_index].append(chunk_interval)\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    workers_chunks = {}\n    workers_intervals = {}\n\n    for i in range(num_workers):\n        worker_index = (worker_env.rank + i) % num_workers\n        workers_chunks[worker_index] = []\n        workers_intervals[worker_index] = []\n\n    for i in range(len(chunks_replica)):\n        worker_index = (worker_env.rank + i) % num_workers\n        workers_chunks[worker_index].append(chunks_replica[i])\n        workers_intervals[worker_index].append(intervals_replica[i])\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    if num_workers < 1:\n        raise ValueError(f\"The number of workers should be greater than 0. Found {num_workers}.\")\n\n    if len(chunks_replica) != len(intervals_replica):\n        raise ValueError(\n            f\"The number of chunks and intervals should be the same. Found {len(chunks_replica)} and {len(intervals_replica)} respectively.\"\n        )\n\n    if len(chunks_replica) < num_workers:\n        raise ValueError(\n            f\"The number of chunks and workers should be the same or greater than the number of workers. Found {len(chunks_replica)} and {num_workers} respectively.\"\n        )\n\n    if worker_env.rank < 0 or worker_env.rank >= num_workers:\n        raise ValueError(\n            f\"The worker rank should be a valid index in the range [0, num_workers). Found {worker_env.rank} and {num_workers} respectively.\"\n        )\n\n    if worker_env.world_size < 1:\n        raise ValueError(f\"The world size should be greater than 0. Found {worker_env.world_size}.\")\n\n    if num_workers % worker_env.world_size != 0:\n        raise ValueError(\n            f\"The number of workers should be divisible by the world size. Found {num_workers} and {worker_env.world_size} respectively.\"\n        )\n\n    num_chunks_per_worker = num_workers // worker_env.world_size\n    num_chunks_per_worker_remainder = num_workers % worker_env.world_size\n\n    # Calculate the number of chunks assigned to each worker\n    num_chunks_per_worker_list = [num_chunks_per_worker] * worker_env.world_size\n    for i in range(num_chunks_per_worker_remainder):\n        num_chunks_per_worker_list[i] += 1\n\n    # Calculate the"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # Determine the number of chunks per worker.\n    chunks_per_worker = len(chunks_replica) // num_workers\n\n    # Determine the number of chunks that are left over.\n    chunks_left_over = len(chunks_replica) % num_workers\n\n    # Determine the number of chunks that each worker should receive.\n    chunks_per_worker_list = [chunks_per_worker for _ in range(num_workers)]\n\n    # Assign the left over chunks to the first `chunks_left_over` workers.\n    for i in range(chunks_left_over):\n        chunks_per_worker_list[i] += 1\n\n    # Create a list of workers.\n    workers = list(range(num_workers))\n\n    # Create a list of intervals.\n    intervals = intervals_replica\n\n    # Create a list of chunks.\n    chunks = chunks_replica\n\n    # Create a dictionary that maps each worker to their assigned chunks.\n    workers_chunks = {}\n\n    # Create a dictionary that maps each worker to their assigned intervals.\n    workers_intervals = {}\n\n    # Create a list of tuples that map each worker to their assigned chunks.\n    workers_chunks_list = []\n\n    # Create a list of tuples that map each worker to their assigned intervals.\n    workers_intervals_list = []\n\n    # Create a list of tuples that map each worker to their assigned chunks and intervals.\n    workers_chunks_intervals_list = []\n\n    # Create a list of tuples that map each worker to their assigned chunks and intervals.\n    workers_chunks_intervals_list = []\n\n    # Create a list of tuples that map each worker to their assigned chunks and intervals.\n    workers_chunks_intervals_list = []\n\n    # Create a list of tuples that map each worker to their assigned chunks and intervals.\n    workers_chunks_intervals_list = []\n\n    # Create a list of tuples that map each worker"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    if worker_env.world_size == 1:\n        return {0: chunks_replica}, {0: intervals_replica}\n\n    chunks_per_worker = len(chunks_replica) // worker_env.world_size\n    workers_chunks = {}\n    workers_intervals = {}\n    for i in range(worker_env.world_size):\n        start_index = i * chunks_per_worker\n        end_index = (i + 1) * chunks_per_worker\n        if i == worker_env.world_size - 1:\n            end_index = len(chunks_replica)\n        workers_chunks[i] = chunks_replica[start_index:end_index]\n        workers_intervals[i] = intervals_replica[start_index:end_index]\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    assert len(chunks_replica) == len(intervals_replica)\n\n    workers_chunks: Dict[int, List[int]] = {}\n    workers_intervals: Dict[int, List[Any]] = {}\n\n    for i in range(num_workers):\n        workers_chunks[i] = []\n        workers_intervals[i] = []\n\n    for i in range(len(chunks_replica)):\n        worker_index = (worker_env.rank + i * worker_env.world_size) % num_workers\n        workers_chunks[worker_index].append(chunks_replica[i])\n        workers_intervals[worker_index].append(intervals_replica[i])\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # If the number of workers is 1, then return the original chunk and interval replicas\n    if num_workers == 1:\n        return chunks_replica, intervals_replica\n\n    # If the number of workers is more than 1, then distribute the chunks and intervals based on the worker environment\n    if worker_env.world_size == 1:\n        # If the world size is 1, then return the original chunk and interval replicas\n        return chunks_replica, intervals_replica\n\n    if worker_env.world_size == num_workers:\n        # If the world size is equal to the number of workers, then return the original chunk and interval replicas\n        return chunks_replica, intervals_replica\n\n    # If the world size is more than 1 and the number of workers is more than 1, then distribute the chunks and intervals based on the worker environment\n    workers_chunks = {}\n    workers_intervals = {}\n    for i in range(worker_env.world_size):\n        # If the world size is equal to the number of workers, then return the original chunk and interval replicas\n        if i % num_workers == 0:\n            workers_chunks[i] = chunks_replica\n            workers_intervals[i] = intervals_replica\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    assert num_workers == worker_env.world_size\n    assert len(chunks_replica) == len(intervals_replica)\n    assert len(chunks_replica) % num_workers == 0\n\n    num_chunks = len(chunks_replica)\n    chunks_per_worker = num_chunks // num_workers\n    chunks_per_worker_remainder = num_chunks % num_workers\n\n    workers_chunks = {}\n    workers_intervals = {}\n\n    for worker_index in range(num_workers):\n        # The first worker_index chunks are distributed evenly across the workers\n        # The last worker_index chunks are distributed among the remaining workers\n        num_chunks_per_worker = chunks_per_worker + 1 if worker_index < chunks_per_worker_remainder else chunks_per_worker\n        chunks_worker = chunks_replica[chunks_per_worker * worker_index : chunks_per_worker * (worker_index + 1)]\n        intervals_worker = intervals_replica[chunks_per_worker * worker_index : chunks_per_worker * (worker_index + 1)]\n\n        workers_chunks[worker_index] = chunks_worker\n        workers_intervals[worker_index] = intervals_worker\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # create a dictionary of workers and their assigned chunks\n    workers_chunks = {}\n\n    # create a dictionary of workers and their assigned intervals\n    workers_intervals = {}\n\n    # iterate through the workers and assign chunks and intervals to them\n    for worker_rank in range(worker_env.world_size):\n\n        # get the chunk indices assigned to the current worker\n        chunks_assigned_to_worker = chunks_replica[worker_rank::worker_env.world_size]\n\n        # get the intervals corresponding to the chunks assigned to the current worker\n        intervals_assigned_to_worker = intervals_replica[worker_rank::worker_env.world_size]\n\n        # add the chunks and intervals assigned to the current worker to the dictionaries\n        workers_chunks[worker_rank] = chunks_assigned_to_worker\n        workers_intervals[worker_rank] = intervals_assigned_to_worker\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[len(\"local:\") :]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[len(\"local:\") :]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[len(\"local:\") :]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[len(\"local:\") :]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[len(\"local:\") :]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[len(\"local:\") :]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[5:]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[5:]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[5:]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[5:]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath.replace(\"local:\", \"\")\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath.replace(\"local:\", \"\")\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath.replace(\"local:\", \"\")\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[len(\"local:\") :]\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[5:]\n\n        super().download_file(remote_filepath, local_filepath)\n\n"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        # If the remote file path contains the prefix \"local:\", then remove it.\n        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[len(\"local:\") :]\n\n        # Call the superclass's download_file method to download the file from the modified remote file path to the specified local file path.\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[len(\"local:\") :]\n\n        super().download_file(remote_filepath, local_filepath)\n\n"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[len(\"local:\") :]\n\n        super().download_file(remote_filepath, local_filepath)\n\n"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath.replace(\"local:\", \"\")\n\n        super().download_file(remote_filepath, local_filepath)\n\n"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[len(\"local:\") :]\n\n        super().download_file(remote_filepath, local_filepath)\n\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        buffer = io.BytesIO()\n        item.save(buffer, format=\"png\")\n        buffer.seek(0)\n        return buffer.read(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        buffer = io.BytesIO()\n        item.save(buffer, \"PNG\")\n        return (buffer.getvalue(), None)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        if not _PIL_AVAILABLE:\n            raise ImportError(\"You need to install PIL or Pillow to use this feature.\")\n\n        buffer = io.BytesIO()\n        item.save(buffer, item.format)\n        return buffer.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        return item.tobytes(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        if not _PIL_AVAILABLE:\n            raise ImportError(\"To use this feature, please install PIL.\")\n        if not isinstance(item, Image.Image):\n            raise TypeError(\"Expected type PIL.Image.Image but got {}\".format(type(item)))\n        buffer = io.BytesIO()\n        item.save(buffer, item.format)\n        return buffer.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        buffer = io.BytesIO()\n        item.save(buffer, item.format)\n        return buffer.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        if not isinstance(item, Image.Image):\n            raise TypeError(f\"Expected PIL.Image.Image but got {type(item)}\")\n\n        buffer = io.BytesIO()\n        item.save(buffer, format=\"png\")\n        return buffer.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        if not _PIL_AVAILABLE:\n            raise RuntimeError(\"pillow is not available\")\n\n        if not isinstance(item, Image.Image):\n            raise TypeError(f\"item should be a PIL Image, got {type(item)}\")\n\n        buffer = io.BytesIO()\n        item.save(buffer, format=\"PNG\")\n        return buffer.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        if not _PIL_AVAILABLE:\n            raise ImportError(\"Please, pip install PIL\")\n\n        if not isinstance(item, Image.Image):\n            raise TypeError(f\"Expected PIL.Image.Image but got {type(item)}\")\n\n        with io.BytesIO() as buffer:\n            item.save(buffer, format=\"png\")\n            return buffer.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        buffer = io.BytesIO()\n        item.save(buffer, format=\"png\")\n        return buffer.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        buffer = io.BytesIO()\n        item.save(buffer, item.format)\n        return buffer.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        buffer = io.BytesIO()\n        item.save(buffer, \"png\")\n        return buffer.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        buffer = io.BytesIO()\n        item.save(buffer, item.format)\n        return buffer.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        buffer = io.BytesIO()\n        item.save(buffer, format=\"png\")\n        return buffer.getvalue(), None\n\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        if not _PIL_AVAILABLE:\n            raise ModuleNotFoundError(\"The PILSerializer requires PIL which is not installed!\")\n\n        if not isinstance(item, Image.Image):\n            raise TypeError(f\"The item to serialize must be a PIL Image, but got {type(item)}\")\n\n        buffer = io.BytesIO()\n        item.save(buffer, item.format)\n        return buffer.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        if not _PIL_AVAILABLE:\n            raise ModuleNotFoundError(\n                \"The `pillow` library is required to use the `PILSerializer`.\"\n            )\n\n        if not isinstance(item, Image.Image):\n            raise TypeError(\n                f\"The `item` argument must be a PIL Image object, not {type(item)}.\"\n            )\n\n        buffer = io.BytesIO()\n        item.save(buffer, format=\"png\")\n\n        return buffer.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        buffer = io.BytesIO()\n        item.save(buffer, \"PNG\")\n        return buffer.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        if not isinstance(item, Image.Image):\n            raise TypeError(\"Expected a PIL Image object.\")\n        if item.mode not in (\"L\", \"RGB\", \"RGBA\"):\n            raise TypeError(\"Expected a PIL Image object with mode 'L', 'RGB', or 'RGBA'.\")\n        if item.mode == \"L\":\n            mode_len = 1\n        else:\n            mode_len = 2\n        buffer = io.BytesIO()\n        item.save(buffer, format=\"raw\", bytesperchannel=item.mode.channels * item.mode.depth)\n        return buffer.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        if not _PIL_AVAILABLE:\n            raise ImportError(\"Pillow is not installed, please install it with `pip install Pillow`.\")\n\n        if not isinstance(item, Image.Image):\n            raise TypeError(f\"Input must be a PIL Image object, got {type(item)}\")\n\n        if isinstance(item, GifImageFile):\n            raise TypeError(\"GifImageFile is not supported by PILSerializer.\")\n\n        image_data = item.tobytes()\n        width, height = item.size\n        mode = item.mode\n        return image_data, f\"{width} {height} {mode}\".encode(\"utf-8\")\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        if not isinstance(item, Image.Image):\n            raise TypeError(f\"The input item is not of type PIL.Image.Image, got {type(item)}\")\n        if not item.mode:\n            raise ValueError(\"The input image has no mode\")\n        if not item.size:\n            raise ValueError(\"The input image has no size\")\n\n        # serialize image data\n        with io.BytesIO() as buffer:\n            item.save(buffer, item.mode)\n            return buffer.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            with open(item.filename, \"rb\") as f:\n                data = f.read()\n        else:\n            data = encode_jpeg(pil_to_tensor(item).numpy())\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            with open(item.filename, \"rb\") as f:\n                data = f.read()\n        else:\n            data = item.tobytes(\"jpeg\", \"RGB\")\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            with open(item.filename, \"rb\") as f:\n                data = f.read()\n        else:\n            data = encode_jpeg(item)\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            with open(item.filename, \"rb\") as f:\n                data = f.read()\n        else:\n            data = item.tobytes()\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            with open(item.filename, \"rb\") as f:\n                data = f.read()\n        else:\n            data = encode_jpeg(pil_to_tensor(item).numpy(), quality=95)\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            with open(item.filename, \"rb\") as f:\n                data = f.read()\n        else:\n            data = encode_jpeg(pil_to_tensor(item).numpy())\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            with open(item.filename, \"rb\") as f:\n                data = f.read()\n        else:\n            data = item.tobytes()\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            with open(item.filename, \"rb\") as f:\n                raw = f.read()\n        else:\n            raw = item.tobytes()\n        return raw, None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            return item.fp.read(), None\n        elif isinstance(item, Image.Image):\n            buffer = io.BytesIO()\n            item.save(buffer, format=\"JPEG\")\n            return buffer.getvalue(), None\n        else:\n            raise TypeError(\"Only JPEG image type is supported\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if not isinstance(item, Image.Image):\n            raise TypeError(f\"The item is not an instance of Image class or its subclasses. Got {type(item)}\")\n        if isinstance(item, JpegImageFile) and item.filename is not None:\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        with io.BytesIO() as f:\n            item.save(f, format=\"jpeg\")\n            return f.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if not isinstance(item, Image.Image):\n            raise TypeError(\"Image must be a PIL Image.\")\n        if isinstance(item, JpegImageFile):\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        with io.BytesIO() as f:\n            item.save(f, format=\"JPEG\")\n            return f.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if not isinstance(item, Image.Image):\n            raise TypeError(\"The item to be serialized should be an instance of Image class or its subclasses.\")\n\n        if isinstance(item, JpegImageFile):\n            if item.filename is not None and os.path.exists(item.filename):\n                with open(item.filename, \"rb\") as f:\n                    return f.read(), None\n\n        with io.BytesIO() as buffer:\n            item.save(buffer, format=\"JPEG\")\n            return buffer.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if not isinstance(item, Image.Image):\n            raise TypeError(\"The item is not an instance of Image class.\")\n        if isinstance(item, JpegImageFile):\n            if item.filename:\n                with open(item.filename, \"rb\") as f:\n                    return f.read(), None\n            else:\n                raise TypeError(\"The item is not an instance of Image class.\")\n        else:\n            buffer = io.BytesIO()\n            item.save(buffer, format=\"JPEG\")\n            return buffer.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if not isinstance(item, Image.Image):\n            raise TypeError(\"item should be an instance of Image class or its subclasses.\")\n\n        if isinstance(item, JpegImageFile):\n            with open(item.filename, \"rb\") as f:\n                data = f.read()\n        else:\n            data = item.tobytes(\"jpeg\", \"RGB\")\n\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if not isinstance(item, Image.Image):\n            raise TypeError(\"The item should be an instance of Image class or its subclasses.\")\n\n        if isinstance(item, JpegImageFile) and os.path.exists(item.filename):\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n\n        if item.format == \"JPEG\":\n            with tempfile.TemporaryFile() as f:\n                item.save(f, \"JPEG\")\n                f.seek(0)\n                return f.read(), None\n\n        raise TypeError(\"The item should be an instance of Image class or its subclasses.\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if not isinstance(item, Image.Image):\n            raise TypeError(f\"Expected an instance of Image class, but got {type(item)}\")\n\n        if isinstance(item, JpegImageFile):\n            # Read the file directly\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        else:\n            # Convert the image into JPEG format in memory\n            with io.BytesIO() as buffer:\n                item.save(buffer, \"JPEG\", quality=95)\n                return buffer.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            with open(item.filename, \"rb\") as f:\n                data = f.read()\n        else:\n            data = item.tobytes(\"jpeg\", \"RGB\")\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if not isinstance(item, Image.Image):\n            raise TypeError(\"The item should be an instance of Image class or its subclasses.\")\n\n        if isinstance(item, JpegImageFile) and item.filename:\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n\n        with io.BytesIO() as buffer:\n            item.save(buffer, format=\"JPEG\")\n            return buffer.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if not isinstance(item, Image.Image):\n            raise TypeError(\"Unsupported image type: {}\".format(type(item)))\n\n        if isinstance(item, JpegImageFile) and item.filename is not None:\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n\n        if item.mode not in [\"L\", \"RGB\", \"CMYK\"]:\n            item = item.convert(\"RGB\")\n\n        with io.BytesIO() as buffer:\n            item.save(buffer, format=\"jpeg\")\n            return buffer.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if not isinstance(item, Image.Image):\n            raise TypeError(\"The input item should be an instance of Image class or its subclasses.\")\n        if isinstance(item, JpegImageFile):\n            return item.tobytes(), None\n        else:\n            # Converting the image to JPEG format in memory\n            with tempfile.TemporaryFile() as fp:\n                item.save(fp, \"JPEG\")\n                fp.seek(0)\n                data = fp.read()\n            return data, None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        data = io.BytesIO(data)\n        ints = np.frombuffer(data.read(12), dtype=np.uint32)\n        width, height, mode_length = ints\n        mode = data.read(mode_length).decode(\"utf-8\")\n        raw = data.read()\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        if not _PIL_AVAILABLE:\n            raise ImportError(\"PIL is not available.\")\n\n        data = io.BytesIO(data)\n        ints = np.frombuffer(data.read(12), np.uint32)\n        width, height, mode_length = ints\n        mode = data.read(mode_length).decode(\"utf-8\")\n        raw = data.read()\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        f = io.BytesIO(data)\n        ints = np.frombuffer(f.read(12), dtype=np.uint32)\n        width, height, mode_len = ints\n        mode = f.read(mode_len)\n        raw = f.read()\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_length = ints\n        mode = data[12 : 12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_length = ints\n        mode = data[12 : 12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        data = io.BytesIO(data)\n        ints = np.frombuffer(data.read(12), np.uint32)\n        width, height, mode_length = ints\n        mode = data.read(mode_length).decode(\"utf-8\")\n        raw = data.read()\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_len = ints\n        mode = data[12 : 12 + mode_len].decode(\"utf-8\")\n        raw = data[12 + mode_len :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        data = io.BytesIO(data)\n        ints = np.frombuffer(data.read(12), np.uint32)\n        width, height, mode_len = ints\n        mode = data.read(mode_len).decode(\"utf-8\")\n        raw = data.read()\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        data = io.BytesIO(data)\n        ints = np.frombuffer(data.read(12), np.uint32)\n        width, height, mode_length = ints\n        mode = data.read(mode_length).decode(\"utf-8\")\n        raw = data.read()\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        data = io.BytesIO(data)\n        ints = np.frombuffer(data.read(12), np.uint32)\n        width, height, mode_length = ints\n        mode = data.read(mode_length).decode(\"utf-8\")\n        raw = data.read()\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        width, height, mode_size = np.frombuffer(data[:12], np.uint32)\n        mode = data[12 : 12 + mode_size].decode(\"utf-8\")\n        raw = data[12 + mode_size :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        stream = io.BytesIO(data)\n        ints = np.frombuffer(stream.read(12), np.uint32)\n        width, height, mode_len = ints\n        mode = stream.read(mode_len).decode(\"utf-8\")\n        raw = stream.read()\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        if _PIL_AVAILABLE:\n            ints = np.frombuffer(data, np.uint32, 3, 0)\n            width, height, mode_len = ints\n            mode = data[12:12 + mode_len].decode(\"utf-8\")\n            raw = data[12 + mode_len:]\n            return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        data = io.BytesIO(data)\n        ints = np.frombuffer(data.read(12), np.uint32)\n        width, height, mode_len = ints\n        mode = data.read(mode_len)\n        raw = data.read()\n        return Image.frombytes(mode.decode(\"utf-8\"), (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        f = io.BytesIO(data)\n        ints = np.frombuffer(f.read(12), np.uint32)\n        width, height, mode_length = ints\n        mode = f.read(mode_length)\n        raw = f.read()\n        return Image.frombytes(mode.decode(\"utf-8\"), (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        # Extract the width, height, and mode size from the data.\n        width, height, mode_size = np.frombuffer(data[:12], dtype=np.uint32)\n\n        # Extract the mode string.\n        mode = data[12: 12 + mode_size]\n\n        # Extract the raw image data.\n        raw = data[12 + mode_size:]\n\n        # Reconstruct the image.\n        return Image.frombytes(mode.decode(\"utf-8\"), (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_len = ints\n        mode = data[12 : 12 + mode_len].decode(\"utf-8\")\n        raw = data[12 + mode_len :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        if not _PIL_AVAILABLE:\n            raise ImportError(\n                \"PIL is not installed and is required to use this feature. Please install with 'pip install Pillow'.\"\n            )\n\n        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_size = ints\n        mode = data[12 : 12 + mode_size].decode(\"utf-8\")\n        raw = data[12 + mode_size :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        if not _PIL_AVAILABLE:\n            raise RuntimeError(\n                \"pillow is not installed and is required to deserialize PIL images. Please install with 'pip install pillow'\"\n            )\n\n        ints = np.frombuffer(data, np.uint32, 3, 0)\n        width, height, mode_length = ints\n        mode = data[12 : 12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        if not _PIL_AVAILABLE:\n            raise ModuleNotFoundError(\n                \"The PILSerializer requires PIL, please install it by running pip install Pillow\"\n            )\n        stream = io.BytesIO(data)\n        ints = np.frombuffer(stream.read(12), dtype=np.uint32)\n        width, height, mode_length = ints\n        mode = stream.read(mode_length).decode(\"utf-8\")\n        raw = stream.read()\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 4\n        dtype_indice = np.frombuffer(data[:idx], np.uint32)[0]\n        idx2 = idx + 4\n        shape = tuple(np.frombuffer(data[idx:idx2], np.uint32))\n        idx3 = idx2 + np.prod(shape) * _NUMPY_DTYPES_MAPPING[dtype_indice].itemsize\n        return torch.from_numpy(np.frombuffer(data[idx2:idx3], _NUMPY_DTYPES_MAPPING[dtype_indice])).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 4\n        dtype_indice = int.from_bytes(data[:idx], byteorder=\"big\")\n        idx2 = idx + 4\n        shape = tuple(int.from_bytes(data[idx:idx2], byteorder=\"big\") for idx in range(idx2, idx2 + 4 * len(item.shape), 4))\n        idx3 = idx2 + 4 * len(item.shape)\n        raw = data[idx3:]\n        return torch.from_numpy(np.frombuffer(raw, dtype=_NUMPY_DTYPES_MAPPING[dtype_indice]).reshape(shape))\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 4\n        dtype_indice = int.from_bytes(data[:idx], byteorder=\"big\")\n        idx2 = idx + 4\n        num_dims = int.from_bytes(data[idx:idx2], byteorder=\"big\")\n        idx3 = idx2 + 4 * num_dims\n        shape = tuple(int.from_bytes(data[idx2 + i * 4 : idx2 + (i + 1) * 4], byteorder=\"big\") for i in range(num_dims))\n        data = data[idx3:]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        return torch.from_numpy(np.frombuffer(data, dtype=dtype).reshape(shape))\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 4\n        dtype_indice = np.frombuffer(data[:idx], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        idx2 = idx + 4\n        num_dims = np.frombuffer(data[idx:idx2], np.uint32)[0]\n        idx3 = idx2 + 4 * num_dims\n        shape = np.frombuffer(data[idx2:idx3], np.uint32)\n        shape = tuple(shape)\n        idx4 = idx3\n        array = np.frombuffer(data[idx3:], dtype=dtype).reshape(shape)\n        return torch.from_numpy(array)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 4\n        dtype_indice = np.frombuffer(data[:idx], np.uint32)[0]\n        idx2 = idx + 4\n        num_dims = np.frombuffer(data[idx:idx2], np.uint32)[0]\n        idx3 = idx2 + 4 * num_dims\n        shape = tuple(np.frombuffer(data[idx2:idx3], np.uint32))\n        idx4 = idx3\n        array = np.frombuffer(data[idx3:idx4], _NUMPY_DTYPES_MAPPING[dtype_indice])\n        return torch.from_numpy(array).view(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 4\n        dtype_indice = int.from_bytes(data[:idx], byteorder=\"big\")\n        idx2 = idx + 4\n        shape = tuple(int.from_bytes(data[idx:idx2], byteorder=\"big\") for idx in range(idx2, idx2 + 4 * len(data[idx2:]), 4))\n        idx3 = idx2 + 4 * len(data[idx2:])\n        raw_data = data[idx3:]\n        return torch.from_numpy(np.frombuffer(raw_data, dtype=_NUMPY_DTYPES_MAPPING[dtype_indice]).reshape(shape))\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 0\n        dtype_indice = np.frombuffer(data[idx : idx + 4], np.uint32)[0]\n        idx += 4\n        num_dims = np.frombuffer(data[idx : idx + 4], np.uint32)[0]\n        idx += 4\n        shape = []\n        for _ in range(num_dims):\n            dim = np.frombuffer(data[idx : idx + 4], np.uint32)[0]\n            shape.append(dim)\n            idx += 4\n        dtype = list(_TORCH_DTYPES_MAPPING.keys())[dtype_indice]\n        return torch.from_numpy(np.frombuffer(data[idx:], dtype=dtype).reshape(shape))\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 0\n        dtype_indice = int.from_bytes(data[idx : idx + 4], byteorder=\"big\")\n        idx += 4\n        shape_length = int.from_bytes(data[idx : idx + 4], byteorder=\"big\")\n        idx += 4\n        shape = []\n        for _ in range(shape_length):\n            shape.append(int.from_bytes(data[idx : idx + 4], byteorder=\"big\"))\n            idx += 4\n\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        tensor = torch.from_numpy(np.frombuffer(data[idx:], dtype=dtype).reshape(*shape))\n        return tensor\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 0\n        dtype_indice = np.frombuffer(data[idx : idx + 4], np.uint32)[0]\n        idx += 4\n        shape = []\n        num_dims = np.frombuffer(data[idx : idx + 4], np.uint32)[0]\n        idx += 4\n        for _ in range(num_dims):\n            dim = np.frombuffer(data[idx : idx + 4], np.uint32)[0]\n            shape.append(dim)\n            idx += 4\n        raw = data[idx:]\n        return torch.from_numpy(np.frombuffer(raw, _NUMPY_DTYPES_MAPPING[dtype_indice]).reshape(*shape))\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 0\n        dtype_indice = int.from_bytes(data[idx : idx + 4], \"big\")\n        idx += 4\n        shape_length = int.from_bytes(data[idx : idx + 4], \"big\")\n        idx += 4\n        shape = tuple(int.from_bytes(data[idx : idx + 4], \"big\") for _ in range(shape_length))\n        idx += 4 * shape_length\n        raw = data[idx:]\n        return torch.from_numpy(np.frombuffer(raw, dtype=_NUMPY_DTYPES_MAPPING[dtype_indice]).reshape(shape))\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 4\n        dtype_indice = int.from_bytes(data[:idx], byteorder=\"big\")\n        idx2 = idx + 4\n        num_dims = int.from_bytes(data[idx:idx2], byteorder=\"big\")\n        idx3 = idx2\n        shape = []\n        for _ in range(num_dims):\n            idx3 += 4\n            shape.append(int.from_bytes(data[idx3 - 4 : idx3], byteorder=\"big\"))\n        idx4 = idx3 + np.prod(shape) * _NUMPY_DTYPES_MAPPING[dtype_indice].itemsize\n        tensor = torch.from_numpy(np.frombuffer(data[idx3:idx4], dtype=_NUMPY_DTYPES_MAPPING[dtype_indice])).reshape(shape)\n        return tensor\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 0\n        dtype_indice = np.frombuffer(data[idx : idx + 4], np.uint32)[0]\n        idx += 4\n        shape_length = np.frombuffer(data[idx : idx + 4], np.uint32)[0]\n        idx += 4\n        shape = [np.frombuffer(data[idx : idx + 4], np.uint32)[0] for _ in range(shape_length)]\n        idx += shape_length * 4\n        raw_data = data[idx:]\n        dtype = list(_TORCH_DTYPES_MAPPING.keys())[dtype_indice]\n        return torch.from_numpy(np.frombuffer(raw_data, dtype=dtype).reshape(shape))\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 0\n        dtype_indice = np.frombuffer(data[idx : idx + 4], np.uint32)[0]\n        idx += 4\n        shape_length = np.frombuffer(data[idx : idx + 4], np.uint32)[0]\n        idx += 4\n        shape = []\n        for _ in range(shape_length):\n            shape.append(np.frombuffer(data[idx : idx + 4], np.uint32)[0])\n            idx += 4\n\n        raw_data = data[idx:]\n        dtype = list(_TORCH_DTYPES_MAPPING.keys())[dtype_indice]\n        return torch.from_numpy(np.frombuffer(raw_data, dtype=dtype).reshape(shape))\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 0\n        dtype_indice = int.from_bytes(data[idx : idx + 4], byteorder=\"big\")\n        idx += 4\n        shape_length = int.from_bytes(data[idx : idx + 4], byteorder=\"big\")\n        idx += 4\n        shape = []\n        for _ in range(shape_length):\n            shape.append(int.from_bytes(data[idx : idx + 4], byteorder=\"big\"))\n            idx += 4\n\n        tensor = torch.from_numpy(np.frombuffer(data[idx:], dtype=_NUMPY_DTYPES_MAPPING[dtype_indice])).reshape(*shape)\n        return tensor\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 4\n        dtype_indice = np.frombuffer(data[:idx], np.uint32)[0]\n        idx2 = idx + 4\n        num_dims = np.frombuffer(data[idx:idx2], np.uint32)[0]\n        idx3 = idx2 + 4 * num_dims\n        shape = tuple(np.frombuffer(data[idx2:idx3], np.uint32))\n        idx4 = idx3\n        if dtype_indice == 0:\n            return torch.from_numpy(np.frombuffer(data[idx4:], np.float32).reshape(shape))\n        elif dtype_indice == 1:\n            return torch.from_numpy(np.frombuffer(data[idx4:], np.int64).reshape(shape))\n        elif dtype_indice == 2:\n            return torch.from_numpy(np.frombuffer(data[idx4:], np.int32).reshape(shape))\n        elif dtype_indice == 3:\n            return torch.from_numpy(np.frombuffer(data[idx4:], np.int16).reshape(shape))\n        elif dtype_indice == 4:\n            return torch.from_numpy(np.frombuffer(data[idx4:], np.uint8).reshape(shape))\n        elif dtype_indice == 5:\n            return torch.from_numpy(np.frombuffer(data[idx4:], np.uint16).reshape(shape))\n        elif dtype_indice == 6:\n            return torch.from_numpy(np.frombuffer(data[idx4:], np.uint32).reshape(shape))\n        elif dtype_indice == 7:\n            return torch.from_numpy(np.frombuffer(data[idx4:], np.uint64).reshape(shape))\n        elif dtype_indice == 8:\n            return torch.from_numpy(np.frombuffer(data[idx4:], np.bool).reshape(shape))\n        elif"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 4\n        dtype_indice = np.frombuffer(data[:idx], np.uint32)[0]\n        idx2 = idx + 4\n        shape_len = np.frombuffer(data[idx:idx2], np.uint32)[0]\n        idx3 = idx2 + 4 * shape_len\n        shape = tuple(np.frombuffer(data[idx2:idx3], np.uint32))\n        data = data[idx3:]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        return torch.as_tensor(np.frombuffer(data, dtype).reshape(shape))\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 0\n        dtype_indice = int.from_bytes(data[idx : idx + 4], byteorder=\"big\")\n        idx += 4\n        num_dimensions = int.from_bytes(data[idx : idx + 4], byteorder=\"big\")\n        idx += 4\n        shape = []\n        for _ in range(num_dimensions):\n            shape.append(int.from_bytes(data[idx : idx + 4], byteorder=\"big\"))\n            idx += 4\n        tensor_dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        num_bytes = np.prod(shape) * tensor_dtype.itemsize\n        raw_data = data[idx : idx + num_bytes]\n        return torch.from_numpy(np.frombuffer(raw_data, dtype=tensor_dtype).reshape(shape))\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 4\n        dtype_indice = np.frombuffer(data[:idx], np.uint32)[0]\n        idx2 = idx + 4\n        num_dims = np.frombuffer(data[idx:idx2], np.uint32)[0]\n        idx3 = idx2 + 4 * num_dims\n        shape = tuple(np.frombuffer(data[idx2:idx3], np.uint32))\n        idx4 = idx3\n        if dtype_indice in _NUMPY_DTYPES_MAPPING:\n            dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n            tensor = np.frombuffer(data[idx3:], dtype=dtype).reshape(shape)\n        else:\n            raise ValueError(f\"Unsupported dtype: {dtype_indice}\")\n        return torch.from_numpy(tensor)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 4\n        dtype_indice = int.from_bytes(data[:idx], \"big\")\n        idx2 = idx + 4\n        num_dims = int.from_bytes(data[idx:idx2], \"big\")\n        idx3 = idx2 + 4 * num_dims\n        shape = tuple(int.from_bytes(data[idx2 + 4 * i : idx2 + 4 * (i + 1)], \"big\") for i in range(num_dims))\n        idx4 = idx3\n        if dtype_indice < len(_NUMPY_DTYPES_MAPPING):\n            # numpy dtype\n            numpy_dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n            size = np.dtype(numpy_dtype).itemsize\n            for dim in shape:\n                idx4 += dim * size\n        else:\n            # torch dtype\n            torch_dtype = _TORCH_DTYPES_MAPPING[dtype_indice - len(_NUMPY_DTYPES_MAPPING)]\n            size = torch.empty(0, dtype=torch_dtype).element_size()\n            for dim in shape:\n                idx4 += dim * size\n\n        return torch.from_numpy(np.frombuffer(data[idx3:idx4], dtype=numpy_dtype).reshape(shape))\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 4\n        dtype_indice = int.from_bytes(data[:idx], byteorder=\"big\")\n        idx2 = idx + 4\n        num_dims = int.from_bytes(data[idx:idx2], byteorder=\"big\")\n        idx3 = idx2\n        shape = []\n        for _ in range(num_dims):\n            idx3 = idx3 + 4\n            dim_size = int.from_bytes(data[idx3 - 4 : idx3], byteorder=\"big\")\n            shape.append(dim_size)\n        dtype = list(_TORCH_DTYPES_MAPPING.keys())[dtype_indice]\n        itemsize = int(np.dtype(dtype).str[2:])\n        num_elems = int(np.prod(shape))\n        num_bytes = num_elems * itemsize\n        raw_data = data[idx3:]\n        assert len(raw_data) == num_bytes, f\"Expected {num_bytes} bytes, found {len(raw_data)} bytes.\"\n        if dtype in _NUMPY_DTYPES_MAPPING:\n            array = np.frombuffer(raw_data, dtype=_NUMPY_DTYPES_MAPPING[dtype])\n            return torch.from_numpy(array).reshape(shape)\n        else:\n            return torch.from_numpy(np.frombuffer(raw_data, dtype=np.uint8).view(dtype)).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        if not isinstance(item, torch.Tensor):\n            raise TypeError(f\"The provided item should be of type {torch.Tensor}. Found {item}.\")\n\n        dtype_index = self._dtype_to_indices[item.dtype]\n        dtype_index = np.array(dtype_index, np.uint8)\n        dtype_index = dtype_index.tobytes()\n\n        shape = np.array(item.shape, np.uint32)\n        shape = shape.tobytes()\n\n        data = item.numpy().tobytes()\n\n        return dtype_index + shape + data, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_index = self._dtype_to_indices[item.dtype]\n        dtype_bytes = dtype_index.to_bytes(4, byteorder=\"big\")\n        shape_bytes = b\"\".join(i.to_bytes(4, byteorder=\"big\") for i in item.shape)\n        data_bytes = item.numpy().tobytes()\n        return dtype_bytes + shape_bytes + data_bytes, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = item.dtype\n        shape = item.shape\n        data = item.numpy().tobytes()\n        return (\n            dtype.encode(\"utf-8\") + b\"_\" + str(shape).encode(\"utf-8\") + b\"_\" + data,\n            None,\n        )\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        # get the dtype index\n        dtype_index = self._dtype_to_indices.get(item.dtype)\n        if dtype_index is None:\n            raise ValueError(f\"The tensor's dtype {item.dtype} is not supported.\")\n\n        # get the shape\n        shape = item.shape\n        # get the raw data\n        raw = item.numpy().tobytes()\n\n        # concatenate the dtype index, shape, and raw data\n        ints = np.array([dtype_index, *shape], np.uint32)\n        return ints.tobytes() + raw, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        # Serialize the tensor's dtype, shape, and raw data\n        dtype_index = self._dtype_to_indices[item.dtype]\n        dtype_bytes = dtype_index.to_bytes(1, byteorder=\"big\")\n        shape_bytes = b\"\".join(dim.to_bytes(4, byteorder=\"big\") for dim in item.shape)\n        data_bytes = item.numpy().tobytes()\n        return dtype_bytes + shape_bytes + data_bytes, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        # Serialize the tensor's data type\n        dtype_index = self._dtype_to_indices[item.dtype]\n        dtype_bytes = dtype_index.to_bytes(length=1, byteorder=\"big\", signed=False)\n\n        # Serialize the tensor's shape\n        shape_bytes = b\"\"\n        for shape_dim in item.shape:\n            shape_dim_bytes = shape_dim.to_bytes(length=8, byteorder=\"big\", signed=False)\n            shape_bytes += shape_dim_bytes\n\n        # Serialize the tensor's raw data\n        data_bytes = item.numpy().tobytes()\n\n        # Concatenate the serialized data\n        serialized_bytes = dtype_bytes + shape_bytes + data_bytes\n        return serialized_bytes, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        if not isinstance(item, torch.Tensor):\n            raise TypeError(f\"The provided item should be of type {torch.Tensor}. Found {item}.\")\n\n        if not item.is_contiguous():\n            item = item.contiguous()\n\n        dtype_code = self._dtype_to_indices[item.dtype]\n        dtype_code = dtype_code.to_bytes(1, byteorder=\"big\")\n        shape_code = np.array(item.shape, dtype=np.int32).tobytes()\n        data_code = item.numpy().tobytes()\n        return dtype_code + shape_code + data_code, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        # get the dtype index\n        dtype_index = self._dtype_to_indices[item.dtype]\n\n        # get the shape\n        shape = item.shape\n\n        # get the raw data\n        raw = item.numpy().tobytes()\n\n        # create the bytes object\n        ints = np.array([dtype_index, *shape], np.uint32)\n        return ints.tobytes() + raw, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        # Extract the tensor's dtype, shape, and raw data.\n        dtype = item.dtype\n        shape = item.shape\n        data = item.numpy().tobytes()\n\n        # Serialize the tensor's dtype, shape, and raw data into a bytes object.\n        indices = self._dtype_to_indices[dtype]\n        dtype_bytes = bytes([indices])\n        shape_bytes = shape.to_bytes(8, byteorder=\"little\")\n        data_bytes = data\n\n        # Combine the serialized tensor components into a single bytes object.\n        return dtype_bytes + shape_bytes + data_bytes, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        if not isinstance(item, torch.Tensor):\n            raise TypeError(f\"The provided item should be of type {torch.Tensor}. Found {item}.\")\n\n        # Serialize the dtype\n        dtype_code = self._dtype_to_indices[item.dtype]\n        dtype_code = np.frombuffer(np.array([dtype_code], dtype=np.uint8), dtype=np.uint8)\n\n        # Serialize the shape\n        shape = np.array(item.shape, dtype=np.uint32)\n\n        # Serialize the raw data\n        raw_data = item.numpy().tobytes()\n\n        # Concatenate the dtype, shape, and raw data\n        return dtype_code.tobytes() + shape.tobytes() + raw_data, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        if not isinstance(item, torch.Tensor):\n            raise TypeError(f\"The provided item should be of type {torch.Tensor}. Found {item}.\")\n\n        # write the dtype\n        dtype_code = self._dtype_to_indices[item.dtype]\n        dtype_code = np.asarray(dtype_code, dtype=np.uint8)\n        dtype_code = dtype_code.tobytes()\n\n        # write the shape\n        shape = np.asarray(item.shape, dtype=np.uint32)\n        shape = shape.tobytes()\n\n        # write the data\n        data = item.tobytes()\n\n        return dtype_code + shape + data, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        if item.is_quantized:\n            item = item.dequantize()\n        if item.dtype not in _NUMPY_DTYPES_MAPPING:\n            raise ValueError(f\"The provided item dtype {item.dtype} isn't supported.\")\n        dtype_index = self._dtype_to_indices[item.dtype]\n        dtype_index = np.array(dtype_index, np.uint8)\n        shape = np.array(item.shape, np.uint32)\n        data = item.numpy()\n        return (dtype_index.tobytes() + shape.tobytes() + data.tobytes(), None)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        # get the dtype index\n        dtype_index = self._dtype_to_indices[item.dtype]\n\n        # get the shape as a bytes object\n        shape_bytes = item.shape.tobytes()\n\n        # get the raw data as a bytes object\n        raw_bytes = item.numpy().tobytes()\n\n        # combine the bytes objects into a single bytes object\n        combined_bytes = dtype_index + shape_bytes + raw_bytes\n\n        return combined_bytes, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        # Check that the input is a tensor\n        if not isinstance(item, torch.Tensor):\n            raise TypeError(f\"The provided item should be of type {torch.Tensor}. Found {item}.\")\n\n        # Get the dtype index\n        dtype_index = self._dtype_to_indices[item.dtype]\n\n        # Serialize the tensor data\n        data = item.numpy().tobytes()\n\n        # Serialize the tensor shape\n        shape = item.shape\n        shape_bytes = bytearray(4 * len(shape))\n        np.asarray(shape, dtype=np.uint32).tobytes(shape_bytes)\n\n        # Serialize the tensor dtype\n        dtype_bytes = bytearray(4)\n        np.asarray([dtype_index], dtype=np.uint32).tobytes(dtype_bytes)\n\n        # Combine the serialized data\n        return dtype_bytes + shape_bytes + data, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        # Save the tensor dtype\n        dtype_code = self._dtype_to_indices[item.dtype]\n\n        # Save the tensor shape\n        shape = item.shape\n        shape_bytes = np.array(shape, dtype=np.uint32).tobytes()\n\n        # Save the raw data\n        data_bytes = item.numpy().tobytes()\n\n        # Concatenate the dtype code, shape, and raw data into a single binary object\n        return dtype_code + shape_bytes + data_bytes, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        # Serialize the tensor's shape and dtype\n        shape = np.array(item.shape, np.uint32)\n        dtype_index = self._dtype_to_indices[item.dtype]\n        dtype_index = np.array(dtype_index, np.uint8)\n\n        # Serialize the tensor's raw data\n        item_bytes = item.numpy().tobytes()\n\n        # Concatenate the four serialized objects\n        return shape.tobytes() + dtype_index + item_bytes, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        # check if the tensor is a ByteTensor\n        if item.dtype == torch.uint8:\n            return item.numpy().tobytes(), None\n\n        # check if the tensor is a contiguous tensor\n        if not item.is_contiguous():\n            item = item.contiguous()\n\n        # get the dtype and shape of the tensor\n        dtype_index = self._dtype_to_indices[item.dtype]\n        shape = item.shape\n\n        # serialize the tensor data\n        data = item.numpy().tobytes()\n\n        # serialize the tensor metadata\n        metadata = np.array([dtype_index, *shape], dtype=np.uint32)\n        metadata = metadata.tobytes()\n\n        # combine the tensor metadata and data into a single bytes object\n        return metadata + data, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        # Serialize the tensor's shape and dtype\n        shape = item.shape\n        dtype_index = self._dtype_to_indices[item.dtype]\n\n        # Serialize the tensor's raw data\n        buffer = io.BytesIO()\n        item.numpy().tofile(buffer)\n        raw_data = buffer.getvalue()\n\n        # Concatenate the data together\n        data = bytes(dtype_index.to_bytes(2, byteorder=\"big\"))\n        data += bytes(len(shape).to_bytes(4, byteorder=\"big\"))\n        for size in shape:\n            data += bytes(size.to_bytes(4, byteorder=\"big\"))\n        data += raw_data\n\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        # Get the dtype of the tensor.\n        dtype = item.dtype\n\n        # Get the shape of the tensor.\n        shape = item.shape\n\n        # Get the raw data from the tensor.\n        raw_data = item.numpy().tobytes()\n\n        # Create a buffer to hold the serialized data.\n        serialized_data = io.BytesIO()\n\n        # Serialize the tensor data.\n        np.save(serialized_data, raw_data, allow_pickle=False)\n\n        # Get the serialized data as a bytes object.\n        serialized_data = serialized_data.getvalue()\n\n        # Get the dtype's index in the mapping.\n        dtype_index = self._dtype_to_indices[dtype]\n\n        # Get the shape's index in the mapping.\n        shape_index = self._dtype_to_indices[shape]\n\n        # Create a bytes object to hold the serialized data.\n        serialized_data = bytearray(16)\n\n        # Write the dtype index to the first 4 bytes.\n        serialized_data[0:4] = dtype_index.to_bytes(4, byteorder=\"big\")\n\n        # Write the shape index to the next 4 bytes.\n        serialized_data[4:8] = shape_index.to_bytes(4, byteorder=\"big\")\n\n        # Write the serialized data to the next 12 bytes.\n        serialized_data[8:16] = serialized_data\n\n        # Return the serialized data and None.\n        return serialized_data, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        if item.is_quantized:\n            item = item.dequantize()\n\n        # Note: torch.save returns a buffer protocol object, which is not compatible with the Python 3 pickle protocol.\n        # Instead, we directly serialize the raw tensor data with the pickle protocol.\n        data = pickle.dumps(item, protocol=pickle.HIGHEST_PROTOCOL)\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except RuntimeError:\n                pass\n\n        return pil_to_tensor(Image.open(io.BytesIO(data)))\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        try:\n            # try to decode as a JPEG with torchvision\n            if _TORCH_VISION_AVAILABLE:\n                return decode_jpeg(data)\n        except RuntimeError:\n            # fallback to PIL\n            pass\n\n        return pil_to_tensor(Image.open(io.BytesIO(data)))\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        try:\n            if _TORCH_VISION_AVAILABLE:\n                return decode_jpeg(data)\n        except RuntimeError:\n            pass\n\n        if _PIL_AVAILABLE:\n            return pil_to_tensor(Image.open(io.BytesIO(data)))\n\n        raise TypeError(\"The provided data cannot be deserialized as a JPEG image.\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                image = decode_jpeg(data)\n                image = pil_to_tensor(image).permute(1, 2, 0)\n                return image\n            except RuntimeError:\n                pass\n\n        return Image.open(io.BytesIO(data))\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except RuntimeError:\n                pass\n\n        return pil_to_tensor(Image.open(io.BytesIO(data)))\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                image = decode_jpeg(torch.ByteTensor(data))\n                return image\n            except RuntimeError:\n                pass\n\n        return pil_to_tensor(Image.open(io.BytesIO(data)))\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except RuntimeError:\n                pass\n\n        return pil_to_tensor(Image.open(io.BytesIO(data)))\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except RuntimeError:\n                pass\n\n        return pil_to_tensor(Image.open(io.BytesIO(data)))\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        try:\n            if _TORCH_VISION_AVAILABLE:\n                return decode_jpeg(data)\n        except RuntimeError:\n            pass\n\n        if not _PIL_AVAILABLE:\n            raise ImportError(\"To deserialize a JPEG image, PIL must be installed.\")\n\n        return pil_to_tensor(Image.open(io.BytesIO(data)))\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        try:\n            # try to decode the data as a JPEG\n            image = decode_jpeg(torch.tensor(data).permute(2, 0, 1).unsqueeze(0))\n        except RuntimeError:\n            # if the decoding fails, fall back to using PIL\n            image = Image.open(io.BytesIO(data))\n\n        if _TORCH_VISION_AVAILABLE:\n            # if torchvision is available, convert the image to a tensor\n            return pil_to_tensor(image)\n\n        return image\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        try:\n            # try to decode as a JPEG\n            img = decode_jpeg(torch.tensor(data).to(torch.uint8))\n        except RuntimeError:\n            # fall back to using PIL\n            img = Image.open(io.BytesIO(data))\n\n        if _TORCH_VISION_AVAILABLE:\n            return pil_to_tensor(img)\n        return img\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        try:\n            # Try to decode the data as a JPEG image.\n            # If torchvision is available, it returns a decoded JPEG image.\n            # If torchvision is not available, it raises a RuntimeError, which is handled by the except clause.\n            return decode_jpeg(data)\n        except RuntimeError:\n            # If torchvision is not available, use PIL to deserialize the data.\n            item = Image.open(io.BytesIO(data))\n            if _TORCH_VISION_AVAILABLE:\n                return pil_to_tensor(item)\n            return item\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        try:\n            # try to decode the data as a JPEG image\n            img = decode_jpeg(data)\n            img = pil_to_tensor(img)\n            return img\n        except RuntimeError:\n            # if the decoding fails, it means the data is actually a PNG with a JPEG extension\n            img = Image.open(io.BytesIO(data))\n            return img\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        try:\n            # try to decode the data using torchvision's decoder\n            return decode_jpeg(data)\n        except RuntimeError:\n            # if the decoding fails, it's probably a PNG with a JPEG extension\n            # so we use PIL to deserialize the data\n            if not _PIL_AVAILABLE:\n                raise ImportError(\"To use this feature, please install PIL.\")\n            item = Image.open(io.BytesIO(data))\n            return pil_to_tensor(item)\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        try:\n            # try to decode the data as a JPEG image using torchvision\n            return decode_jpeg(data)\n        except RuntimeError:\n            # if torchvision is not available or the data is not a JPEG image, try to decode it as a PNG image using PIL\n            return pil_to_tensor(Image.open(io.BytesIO(data)))\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE:\n            raise RuntimeError(\"The torchvision library is required to deserialize the JPEG image.\")\n\n        try:\n            # try to decode the data as a JPEG image\n            return decode_jpeg(data)\n        except RuntimeError:\n            # if the data is actually a PNG with a JPEG extension, use PIL to deserialize the data\n            return pil_to_tensor(Image.open(io.BytesIO(data)))\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except RuntimeError:\n                pass\n\n        if _PIL_AVAILABLE:\n            return pil_to_tensor(Image.open(io.BytesIO(data)))\n\n        raise RuntimeError(\"Failed to deserialize the data as a JPEG image. Please make sure that torchvision is available to fall back to using PIL.\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        try:\n            # try to decode the image as a JPEG\n            if _TORCH_VISION_AVAILABLE:\n                # decode the image using torchvision\n                img = decode_jpeg(data)\n                # convert the image to a tensor\n                img = pil_to_tensor(img)\n                return img\n        except RuntimeError:\n            # if decoding fails, fallback to using PIL\n            pass\n\n        # deserialize the image using PIL\n        img = Image.open(io.BytesIO(data))\n        if _TORCH_VISION_AVAILABLE:\n            # convert the image to a tensor\n            img = pil_to_tensor(img)\n        return img\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        try:\n            # try to deserialize as a JPEG image\n            if _TORCH_VISION_AVAILABLE:\n                return decode_jpeg(data)\n            else:\n                raise RuntimeError\n        except RuntimeError:\n            # if the decoding fails, fall back to using PIL\n            if _PIL_AVAILABLE:\n                item = Image.open(io.BytesIO(data))\n                if _TORCH_VISION_AVAILABLE:\n                    return pil_to_tensor(item)\n                else:\n                    return item\n            else:\n                raise RuntimeError(\n                    \"Cannot deserialize the image. Please make sure that PyTorch's torchvision is available.\"\n                )\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        try:\n            # attempt to decode the data using torchvision\n            if _TORCH_VISION_AVAILABLE:\n                return decode_jpeg(data)\n        except RuntimeError:\n            # fall back to PIL if torchvision fails\n            pass\n\n        # deserialize the data using PIL\n        return pil_to_tensor(Image.open(io.BytesIO(data)))\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[self._dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[self._dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[self._dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        data = item.numpy().tobytes(order=\"C\")\n        return data, f\"no_header_tensor:{self._dtype_to_indices[self._dtype]}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        data = item.numpy().tobytes(order=\"C\")\n        return data, f\"no_header_tensor:{self._dtype_to_indices[self._dtype]}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_tensor:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        data = item.numpy().tobytes(order=\"C\")\n        return data, f\"no_header_tensor:{self._dtype_to_indices[self._dtype]}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        data = item.numpy().tobytes(order=\"C\")\n        return data, f\"no_header_tensor:{self._dtype_to_indices[self._dtype]}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        if not isinstance(item, torch.Tensor):\n            raise TypeError(f\"The provided item should be of type {torch.Tensor}. Found {item}.\")\n        if self._dtype is None:\n            raise ValueError(\"The NoHeaderTensorSerializer should be setup before being used.\")\n        return item.numpy().tobytes(order=\"C\"), f\"no_header_tensor:{self._dtype_to_indices[self._dtype]}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        data = item.numpy().tobytes(order=\"C\")\n        return data, f\"no_header_tensor:{self._dtype_to_indices[self._dtype]}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        data = item.numpy().tobytes(order=\"C\")\n        return data, f\"no_header_tensor:{self._dtype_to_indices[self._dtype]}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[self._dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        data = item.numpy().tobytes(order=\"C\")\n        return data, f\"no_header_tensor:{self._dtype_to_indices[self._dtype]}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"The NoHeaderTensorSerializer has not been setup.\")\n\n        data = item.numpy().tobytes(order=\"C\")\n        return data, f\"no_header_tensor:{self._dtype_to_indices[self._dtype]}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"The serializer is not properly setup. Please call `setup` before calling `serialize`.\")\n        return item.numpy().tobytes(order=\"C\"), f\"no_header_tensor:{self._dtype_to_indices[self._dtype]}\"\n\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"The data format is not set. Please call setup() first.\")\n        if not isinstance(item, torch.Tensor):\n            raise TypeError(f\"The provided item should be of type {torch.Tensor}. Found {item}.\")\n        return item.numpy().tobytes(order=\"C\"), f\"no_header_tensor:{self._dtype_to_indices[self._dtype]}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        if not isinstance(item, torch.Tensor):\n            raise TypeError(\"NoHeaderTensorSerializer can only serialize torch.Tensor objects.\")\n\n        if self._dtype is None:\n            raise ValueError(\"NoHeaderTensorSerializer can only serialize torch.Tensor objects.\")\n\n        return item.numpy().tobytes(order=\"C\"), f\"no_header_tensor:{self._dtype_to_indices[self._dtype]}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"The NoHeaderTensorSerializer has not been setup yet.\")\n\n        return item.numpy().tobytes(order=\"C\"), f\"no_header_tensor:{self._dtype_to_indices[self._dtype]}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"The serializer is not initialized. Call setup() before using the serializer.\")\n        if not isinstance(item, torch.Tensor):\n            raise TypeError(f\"The provided item should be of type {torch.Tensor}. Found {type(item)}.\")\n        return item.numpy().tobytes(order=\"C\"), f\"no_header_tensor:{self._dtype_to_indices[self._dtype]}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        tensor = torch.frombuffer(data, dtype=self._dtype)\n        return tensor\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        tensor = torch.frombuffer(data, dtype=self._dtype)\n        return tensor\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        tensor = torch.frombuffer(data, dtype=self._dtype)\n        return tensor\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        tensor = torch.frombuffer(data, dtype=self._dtype)\n        return tensor\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        tensor = torch.frombuffer(data, dtype=self._dtype)\n        return tensor\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        tensor = torch.frombuffer(data, dtype=self._dtype)\n        return tensor\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"The NoHeaderTensorSerializer must have a predefined data type (_dtype) for the tensor.\")\n        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        tensor = torch.frombuffer(data, dtype=self._dtype)\n        return tensor\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"The NoHeaderTensorSerializer must be setup with a data type before calling deserialize.\")\n        tensor = torch.frombuffer(data, dtype=self._dtype)\n        return tensor\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"The data type must be set before calling the deserialize function.\")\n        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        tensor = torch.frombuffer(data, dtype=self._dtype)\n        shape = tensor.shape\n        return torch.reshape(tensor, shape)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"The data type must be defined in the setup method.\")\n        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        if not self._dtype:\n            raise ValueError(\"The data type must be specified before calling this function.\")\n\n        tensor = torch.frombuffer(data, dtype=self._dtype)\n        return tensor\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"The data type must be set in the setup method.\")\n        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"The data type of the tensor is not set. Please call setup() first.\")\n        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"NoHeaderTensorSerializer is not setup\")\n        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"The data type of the tensor must be specified before calling deserialize().\")\n        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        tensor = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        shape = tuple(shape)\n        if tensor.shape == shape:\n            return tensor\n        return tensor.reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        return array.reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        tensor = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        shape = tuple(shape)\n        if tensor.shape == shape:\n            return tensor\n        return tensor.reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        return array.reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        tensor = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        shape = tuple(shape)\n        if tensor.shape == shape:\n            return tensor\n        return np.reshape(tensor, shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        tensor = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        shape = tuple(shape)\n        if tensor.shape == shape:\n            return tensor\n        return tensor.reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        tensor = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        shape = np.shape(tensor)\n        if shape == tuple(shape):\n            return tensor\n        return np.reshape(tensor, shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        return np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_streaming,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n        else:\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_combined,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_streaming,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n        else:\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_combined,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_streaming,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n        else:\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_combined,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = {\n            \"dataset\": self.dataset.state_dict(),\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded_streaming\": self._num_samples_yielded_streaming,\n            \"latest_worker_idx\": self._latest_worker_idx,\n        }\n\n        if isinstance(self.dataset, CombinedStreamingDataset):\n            state[\"num_samples_yielded_combined\"] = self._num_samples_yielded_combined\n\n        return state\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            return {\n                \"dataset\": deepcopy(self.dataset.state_dict()),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_streaming,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n        else:\n            return {\n                \"dataset\": deepcopy(self.dataset.state_dict()),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_combined,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state_dict = {\n            \"dataset\": self.dataset,\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded\": self._num_samples_yielded_streaming,\n            \"latest_worker_idx\": self._latest_worker_idx,\n        }\n\n        if isinstance(self.dataset, CombinedStreamingDataset):\n            state_dict[\"num_samples_yielded\"] = self._num_samples_yielded_combined\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            state_dict = {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_streaming,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n        else:\n            state_dict = {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_combined,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = {\n            \"dataset\": self.dataset,\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded_streaming\": self._num_samples_yielded_streaming,\n            \"latest_worker_idx\": self._latest_worker_idx,\n        }\n\n        if isinstance(self.dataset, CombinedStreamingDataset):\n            state[\"num_samples_yielded_combined\"] = deepcopy(self._num_samples_yielded_combined)\n\n        return state\n\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state_dict = {}\n        state_dict[\"dataset\"] = self.dataset.state_dict()\n        state_dict[\"current_epoch\"] = self.current_epoch\n        state_dict[\"num_samples_yielded_streaming\"] = self._num_samples_yielded_streaming\n        state_dict[\"num_samples_yielded_combined\"] = self._num_samples_yielded_combined\n        state_dict[\"latest_worker_idx\"] = self._latest_worker_idx\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            state_dict = {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_streaming,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n        else:\n            state_dict = {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_combined,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = {\n            \"dataset\": self.dataset.state_dict(),\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded_streaming\": self._num_samples_yielded_streaming,\n            \"num_samples_yielded_combined\": self._num_samples_yielded_combined,\n            \"latest_worker_idx\": self._latest_worker_idx,\n        }\n\n        return state\n\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state_dict = {\n            \"dataset\": self.dataset.state_dict(),\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded_streaming\": self._num_samples_yielded_streaming,\n            \"latest_worker_idx\": self._latest_worker_idx,\n        }\n\n        if isinstance(self.dataset, CombinedStreamingDataset):\n            state_dict[\"num_samples_yielded_combined\"] = deepcopy(self._num_samples_yielded_combined)\n\n        return state_dict\n\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state_dict = {}\n        state_dict[\"dataset\"] = self.dataset.state_dict()\n        state_dict[\"current_epoch\"] = self.current_epoch\n        state_dict[\"num_samples_yielded_streaming\"] = self._num_samples_yielded_streaming\n        state_dict[\"num_samples_yielded_combined\"] = self._num_samples_yielded_combined\n        state_dict[\"latest_worker_idx\"] = self._latest_worker_idx\n\n        return state_dict\n\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state_dict = {}\n\n        state_dict[\"dataset\"] = self.dataset.state_dict()\n        state_dict[\"current_epoch\"] = self.current_epoch\n        state_dict[\"num_samples_yielded_streaming\"] = self._num_samples_yielded_streaming\n        state_dict[\"num_samples_yielded_combined\"] = deepcopy(self._num_samples_yielded_combined)\n        state_dict[\"latest_worker_idx\"] = self._latest_worker_idx\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state_dict = {\n            \"dataset\": self.dataset,\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded_streaming\": self._num_samples_yielded_streaming,\n            \"latest_worker_idx\": self._latest_worker_idx,\n        }\n\n        if isinstance(self.dataset, CombinedStreamingDataset):\n            state_dict[\"num_samples_yielded_combined\"] = deepcopy(self._num_samples_yielded_combined)\n\n        return state_dict\n\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = {\n            \"dataset\": self.dataset,\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded_streaming\": self._num_samples_yielded_streaming,\n            \"latest_worker_idx\": self._latest_worker_idx,\n        }\n\n        if isinstance(self.dataset, CombinedStreamingDataset):\n            state[\"num_samples_yielded_combined\"] = deepcopy(self._num_samples_yielded_combined)\n\n        return state\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = {\n            \"dataset\": self.dataset.state_dict(),\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded_streaming\": self._num_samples_yielded_streaming,\n            \"latest_worker_idx\": self._latest_worker_idx,\n        }\n\n        if isinstance(self.dataset, CombinedStreamingDataset):\n            state[\"num_samples_yielded_combined\"] = deepcopy(self._num_samples_yielded_combined)\n\n        return state\n\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state_dict = {\n            \"dataset\": self.dataset,\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded\": self._num_samples_yielded_streaming\n            if isinstance(self.dataset, StreamingDataset)\n            else self._num_samples_yielded_combined,\n            \"latest_worker_idx\": self._latest_worker_idx,\n        }\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = {\n            \"dataset\": self.dataset,\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded_streaming\": self._num_samples_yielded_streaming,\n            \"latest_worker_idx\": self._latest_worker_idx,\n        }\n\n        if isinstance(self.dataset, CombinedStreamingDataset):\n            state[\"num_samples_yielded_combined\"] = deepcopy(self._num_samples_yielded_combined)\n\n        return state\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state_dict = {}\n        state_dict[\"dataset\"] = self.dataset.state_dict()\n        state_dict[\"current_epoch\"] = self.current_epoch\n        state_dict[\"num_samples_yielded\"] = self._num_samples_yielded_streaming\n        state_dict[\"latest_worker_idx\"] = self._latest_worker_idx\n        return state_dict\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise ModuleNotFoundError(\n                \"TorchVision is not installed, please install it with command: `pip install torchvision`.\"\n            )\n\n        with tempfile.NamedTemporaryFile(delete=False) as f:\n            f.write(data)\n            video = _read_video(f.name)\n\n        return video\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise ImportError(\"Torchvision is not installed, please install it by running `pip install torchvision`.\")\n        tmp_file = tempfile.NamedTemporaryFile(suffix=\".mp4\")\n        tmp_file.write(data)\n        tmp_file.seek(0)\n        return tmp_file\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise RuntimeError(\"TorchVision is not available. Please install torchvision to use this functionality.\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\") as f:\n            f.write(data)\n            f.flush()\n            return _read_video(f.name, pts_unit=\"sec\")\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise RuntimeError(\n                \"To deserialize videos, you must have av installed. \"\n                \"Please install with `pip install av`\"\n            )\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\") as f:\n            f.write(data)\n            f.seek(0)\n            video, _, info = read_video(f.name)\n            video = video.permute(0, 3, 1, 2)\n            video = video.float()\n            video /= 255\n\n        return video\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise RuntimeError(\"TorchVision is not available on this platform\")\n\n        if not _TORCH_AVAILABLE:\n            raise RuntimeError(\"Torch is not available on this platform\")\n\n        with tempfile.NamedTemporaryFile(\"wb\", suffix=\".mp4\") as f:\n            f.write(data)\n            f.seek(0)\n            video, _, info = read_video(f.name, pts_unit=\"sec\")\n            video = video.permute(0, 3, 1, 2)\n            video = torch.from_numpy(video)\n            video = video.float().div(255)\n            return video, info\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise RuntimeError(\n                \"TorchVision is not available on this platform. Please install torchvision to use the VideoSerializer.\"\n            )\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\") as f:\n            f.write(data)\n            f.seek(0)\n            video, _, info = read_video(f.name)\n\n        return video, f\"video:{info['video_codec_name']}\"\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise ImportError(\n                \"To deserialize videos, please install the torchvision and av dependencies with 'pip install torchvision av'\"\n            )\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\") as f:\n            f.write(data)\n            f.seek(0)\n            video, _, info = read_video(f.name)\n            video = video.permute(0, 3, 1, 2)\n            video = video.float()\n            video = video / 255\n            return video\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE:\n            raise ImportError(\"Torchvision is not installed and is required to deserialize the video.\")\n        if not _AV_AVAILABLE:\n            raise ImportError(\"PyAV is not installed and is required to deserialize the video.\")\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\") as f:\n            f.write(data)\n            f.flush()\n            video = torch.ops.image.read_video(f.name, 0, 0, -1, -1)\n            return video\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise RuntimeError(\"The torchvision library is not available. Please install torchvision to use this feature.\")\n\n        # Write the data to a temporary file\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\") as f:\n            f.write(data)\n            # Read the video\n            video, _, info = read_video(f.name, pts_unit=\"sec\")\n\n        # Return the video object\n        return video\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise ModuleNotFoundError(\"Torchvision is not installed, please install it with pip install torchvision\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\") as f:\n            f.write(data)\n            f.seek(0)\n            video, audio_sample_rate, audio_channels = torch.ops.torchvision._read_video(\n                f.name,\n                # video_width=0,\n                # video_height=0,\n                # video_min_dimension=0,\n                # video_max_dimension=0,\n                # video_pts_range=(0, -1),\n                # video_timebase_numerator=0,\n                # video_timebase_denominator=0,\n                # audio_samples_per_raw_sample=0,\n                # audio_channels=0,\n                # audio_pts_range=(0, -1),\n                # audio_timebase_numerator=0,\n                # audio_timebase_denominator=0,\n                # seek_frame_margin=0.25,\n                # read_video_stream=None,\n                # read_audio_stream=None,\n                # video_frames_fps=None,\n                # video_start_pts=None,\n                # video_end_pts=None,\n                # audio_start_pts=None,\n                # audio_end_pts=None,\n            )\n        return video\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise ImportError(\"The torchvision library is not installed. Please install torchvision before using this function.\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\") as tmp_file:\n            tmp_file.write(data)\n            tmp_file.seek(0)\n            return torch.load(tmp_file)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise ImportError(\n                \"To deserialize videos, please install torchvision with: pip install torchvision\"\n            )\n        if not _TORCH_AVAILABLE:\n            raise ImportError(\n                \"To deserialize videos, please install torch with: pip install torch\"\n            )\n\n        # Write the data to a temporary file\n        f = tempfile.NamedTemporaryFile(suffix=\".mp4\")\n        f.write(data)\n        f.seek(0)\n        # Use torchvision's read_video function to deserialize the video file into a video object\n        video, _, info = read_video(f.name, pts_unit=\"sec\")\n        f.close()\n        return video, info\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise ImportError(\"Torchvision and/or av dependencies are not installed and are required to load video data.\")\n\n        tmp_file = tempfile.NamedTemporaryFile(suffix=\".mp4\")\n        tmp_file.write(data)\n        tmp_file.flush()\n        video_tensor, _, info = read_video(tmp_file.name, pts_unit=\"sec\")\n        tmp_file.close()\n        return video_tensor, f\"video:{info['video_fps']}\"\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise ImportError(\"The torchvision library is not available.\")\n\n        tmp_file = tempfile.NamedTemporaryFile(suffix=\".mp4\")\n        tmp_file.write(data)\n        tmp_file.seek(0)\n        video, audio, info = torch.ops.torchvision.read_video(\n            tmp_file.name,\n            start_pts=0,\n            end_pts=None,\n            pts_unit=\"pts\",\n            read_audio=True,\n            read_video=True,\n            video_pts_range=(0, None),\n            video_timebase_numerator=1,\n            video_timebase_denominator=1,\n            audio_pts_range=(0, None),\n            audio_timebase_numerator=1,\n            audio_timebase_denominator=1,\n            pixel_format=None,\n        )\n        tmp_file.close()\n        return video\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise ImportError(\"Please, install torchvision and av to support video serialization.\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\") as f:\n            f.write(data)\n            f.seek(0)\n            video, _, info = decode_video(f.name, pts_unit=\"sec\")\n        return video, f\"video:{info['video_fps']}\"\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise ImportError(\"Please, install torchvision and av to use the VideoSerializer.\")\n\n        _, file_extension = os.path.splitext(filepath)\n        file_extension = file_extension.replace(\".\", \"\").lower()\n        if file_extension not in VideoSerializer._EXTENSIONS:\n            raise ValueError(\n                f\"The provided file extension is not supported. Please provide a file with one of the following extensions: {VideoSerializer._EXTENSIONS}\"\n            )\n        temp_file = tempfile.NamedTemporaryFile(suffix=f\".{file_extension}\")\n        temp_file.write(data)\n        temp_file.seek(0)\n        return temp_file\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE:\n            raise ModuleNotFoundError(\n                \"Torchvision is not installed and is required to use the VideoSerializer.\"\n                \"Please install torchvision by running 'pip install torchvision'.\"\n            )\n        if not _AV_AVAILABLE:\n            raise ModuleNotFoundError(\n                \"PyAV is not installed and is required to use the VideoSerializer.\"\n                \"Please install PyAV by running 'pip install av'.\"\n            )\n\n        # write the data to a temporary file\n        temp_file = tempfile.NamedTemporaryFile(suffix=\".mp4\")\n        temp_file.write(data)\n        temp_file.seek(0)\n        # use torchvision's read_video function to deserialize the video file into a video object\n        video, _, info = decode_video(temp_file.name)\n        video = video.permute(0, 3, 1, 2)\n        video = video.float()\n        video /= 255\n        video = video.unsqueeze(0)\n        return video, None\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise RuntimeError(\"TorchVision is not available on this platform\")\n        if not _TORCH_AVAILABLE:\n            raise RuntimeError(\"PyTorch is not available on this platform\")\n\n        tmp_file = tempfile.NamedTemporaryFile()\n        tmp_file.write(data)\n        tmp_file.flush()\n        video_array, _, info = torch.ops.video_reader.read_video_from_memory(\n            tmp_file.name, 0, 0, 0, 0, 0\n        )\n        tmp_file.close()\n        return video_array, info\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise ImportError(\n                \"To use the VideoSerializer, you must install the torchvision and av dependencies in the image-classification-pytorch-lightning-train-project template.\"\n            )\n\n        with tempfile.NamedTemporaryFile(delete=False) as f:\n            f.write(data)\n            f.seek(0)\n            video = torch.load(f.name)\n        return video\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise ImportError(\"Torchvision is not installed, please install torchvision by running `pip install torchvision`\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".\" + self._EXTENSIONS[0]) as f:\n            f.write(data)\n            f.seek(0)\n            video, audio, info = torch.ops.torchvision.read_video(\n                f.name,\n                start_pts=0,\n                end_pts=None,\n                pts_unit=\"pts\",\n                channels_first=False,\n            )\n        return video\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while not self.filled:\n            sleep(0.1)\n        return self.write_chunks_index()"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self.filled:\n            return []\n\n        while self._should_write():\n            self.write_chunk()\n\n        self.write_chunks_index()\n        self._is_done = True\n        return [os.path.join(self._cache_dir, f) for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self.filled:\n            return []\n\n        while self._should_write():\n            self.write_chunk()\n\n        self.write_chunks_index()\n        self._is_done = True\n        return [os.path.join(self._cache_dir, f) for f in os.listdir(self._cache_dir) if f.endswith(\".bin\")]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        # Write any remaining chunks\n        while self._should_write():\n            self.write_chunk()\n\n        # Write the index file\n        self.write_chunks_index()\n\n        # Mark the writing process as complete\n        self._is_done = True\n\n        # Return the list of written chunks\n        return [os.path.join(self._cache_dir, f) for f in os.listdir(self._cache_dir) if f.endswith(\".bin\")]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        # Finalize the writing process by writing any remaining chunks to files and generating an index file\n        if not self.filled:\n            while self._should_write():\n                self.write_chunk()\n            self.write_chunks_index()\n        self._is_done = True\n        return [os.path.join(self._cache_dir, f) for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self.filled:\n            return []\n\n        # Write any remaining chunks\n        while self._should_write():\n            self.write_chunk()\n\n        # Write the index file\n        index_filepath = self.write_chunks_index()\n\n        # Mark the writing process as complete\n        self._is_done = True\n\n        return [index_filepath]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        # Check if the writing process is already marked as complete\n        if self.filled:\n            return []\n\n        # Write any remaining chunks of data to files\n        while self._should_write():\n            self.write_chunk()\n\n        # Generate an index file for the chunks\n        index_filepath = self.write_chunks_index()\n\n        # Mark the writing process as complete\n        self._is_done = True\n\n        # Return the file paths to the written chunks\n        return [os.path.join(self._cache_dir, f) for f in os.listdir(self._cache_dir) if f.endswith(\".bin\")]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        # Write any remaining chunks\n        while self._should_write():\n            self.write_chunk()\n\n        # Write the index file\n        index_filepath = self.write_chunks_index()\n\n        # Mark the writer as done\n        self._is_done = True\n\n        # Return the list of written chunks\n        return [os.path.join(self._cache_dir, filename) for filename in os.listdir(self._cache_dir)]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if not self.filled:\n            while self._should_write():\n                self.write_chunk()\n            self.write_chunks_index()\n            self._is_done = True\n        return [os.path.join(self._cache_dir, f) for f in os.listdir(self._cache_dir) if f.endswith(\".bin\")]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self.filled:\n            warnings.warn(\"The writing process is already done. No need to call `done` again.\")\n            return []\n\n        filepaths = []\n        while self._should_write():\n            filepath = self.write_chunk()\n            filepaths.append(filepath)\n\n        filepath = self.write_chunks_index()\n        if filepath:\n            filepaths.append(filepath)\n\n        self._is_done = True\n        return filepaths\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self.filled:\n            return []\n\n        # Write the remaining items to a chunk\n        if self._serialized_items:\n            self.write_chunk(on_done=True)\n\n        # Write the index file\n        index_file = self.write_chunks_index()\n\n        # Mark the writing process as complete\n        self._is_done = True\n\n        return [index_file]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        # Write any remaining chunks to files\n        while self._should_write():\n            self.write_chunk()\n\n        # Write the index file\n        index_filepath = self.write_chunks_index()\n\n        # Mark the writing process as complete\n        self._is_done = True\n\n        # Return the list of filepaths\n        return [index_filepath]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        # Write any remaining chunks\n        while self._should_write():\n            self.write_chunk()\n\n        # Write the chunks index file\n        self.write_chunks_index()\n\n        # Mark the writing process as complete\n        self._is_done = True\n\n        # Return the list of written chunks\n        return [os.path.join(self._cache_dir, f\"chunk-{self.rank}-{i}.bin\") for i in range(self._chunk_index)]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self.filled:\n            warnings.warn(\"The writing process is already completed. The function will return an empty list.\")\n            return []\n\n        # Write the remaining chunks to file\n        while self._should_write():\n            self.write_chunk()\n\n        # Write the index file\n        index_filepath = self.write_chunks_index()\n\n        # Mark the writing process as complete\n        self._is_done = True\n\n        return [index_filepath]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self.filled:\n            return []\n\n        if self._min_index is None:\n            return []\n\n        filepath = self.write_chunk(on_done=True)\n        self.write_chunks_index()\n        self._is_done = True\n        return [filepath]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self.filled:\n            return []\n        if self._is_done:\n            return []\n        while self._should_write():\n            self.write_chunk()\n        self.write_chunks_index()\n        self._is_done = True\n        return [os.path.join(self._cache_dir, f) for f in os.listdir(self._cache_dir) if f.endswith(\".bin\")]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self.filled:\n            warnings.warn(\n                f\"The writer is already done. The writer has written {len(self._chunks_info)} chunks to {self._cache_dir}.\",\n                UserWarning,\n            )\n            return []\n\n        while self._should_write():\n            self.write_chunk()\n\n        self.write_chunks_index()\n        self._is_done = True\n        return [os.path.join(self._cache_dir, f) for f in os.listdir(self._cache_dir) if f.endswith(\".bin\")]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        # Write any remaining chunks\n        while self._should_write():\n            self.write_chunk()\n\n        # Write the chunks index\n        self.write_chunks_index()\n\n        # Mark the writing process as complete\n        self._is_done = True\n\n        return [os.path.join(self._cache_dir, f) for f in os.listdir(self._cache_dir)]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        # Write the remaining chunks to files\n        while self._should_write():\n            self.write_chunk()\n\n        # Write the index file\n        filepath = self.write_chunks_index()\n\n        # Mark the writing process as complete\n        self._is_done = True\n\n        return filepath\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self.filled:\n            warnings.warn(\"The writing process is already marked as complete.\")\n            return []\n\n        while self._should_write():\n            self.write_chunk()\n\n        filepath = self.write_chunks_index()\n        self._is_done = True\n        return [filepath]\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.restore = True\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"], self._latest_worker_idx)\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined[self._latest_worker_idx] = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.restore = True\n        else:\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {self.dataset}.\"\n            )\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.restore = True\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.restore = True\n        else:\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {self.dataset}.\"\n            )\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(\n                obj[\"dataset\"], self._num_samples_yielded_streaming, self.num_workers, self.batch_size\n            )\n            self.current_epoch = obj[\"current_epoch\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self.restore = True\n\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(\n                obj[\"dataset\"], self.num_workers, self.batch_size, obj[\"num_samples_yielded\"]\n            )\n            self.current_epoch = obj[\"current_epoch\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self.restore = True\n\n        else:\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {self.dataset}.\"\n            )\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        else:\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {self.dataset}.\"\n            )\n\n        if self.restore:\n            self.restore = False\n        else:\n            self.restore = True\n\n        self.dataset._set_use_streaming_dataloader(self.restore)\n\n        if self.restore:\n            self._num_samples_yielded_streaming = 0\n            self._num_samples_yielded_combined = {}\n            self._latest_worker_idx = 0\n            self._worker_idx = cycle(list(range(self.num_workers if self.num_workers > 0 else 1)))\n            self._worker_idx_iter = iter(self._worker_idx)\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if not isinstance(self.dataset, (StreamingDataset, CombinedStreamingDataset)):\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {self.dataset}.\"\n            )\n\n        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n\n            if self.current_epoch > 0:\n                self.restore = True\n        else:\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n\n            if self.current_epoch > 0:\n                self.restore = True\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if not isinstance(self.dataset, (StreamingDataset, CombinedStreamingDataset)):\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {self.dataset}.\"\n            )\n\n        self.current_epoch = obj[\"current_epoch\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n        self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n        self.dataset.load_state_dict(obj[\"dataset\"])\n\n        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.set_epoch(self.current_epoch)\n            self.dataset.set_num_samples_yielded(self._num_samples_yielded_streaming)\n            self.dataset.set_latest_worker_idx(self._latest_worker_idx)\n        else:\n            self.dataset.set_epoch(self.current_epoch)\n            self.dataset.set_num_samples_yielded(self._num_samples_yielded_combined)\n            self.dataset.set_latest_worker_idx(self._latest_worker_idx)\n            self.dataset._set_use_streaming_dataloader(True)\n\n        self.restore = True\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(\n                obj[\"dataset\"],\n                self._num_samples_yielded_streaming,\n                self.num_workers,\n                self.batch_size,\n            )\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.restore = True\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(\n                obj[\"dataset\"],\n                self._num_samples_yielded_combined,\n                self.num_workers,\n                self.batch_size,\n            )\n            self.current_epoch = obj[\"current_epoch\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.restore = True\n        else:\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {self.dataset}.\"\n            )\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            assert self.batch_size\n            self.dataset.load_state_dict(\n                obj[\"dataset\"], self._num_samples_yielded_streaming, self.num_workers, self.batch_size\n            )\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"], self.num_workers, self.batch_size)\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        else:\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {self.dataset}.\"\n            )\n\n        if self.restore:\n            self.restore = False\n        else:\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self._worker_idx = cycle(list(range(self.num_workers if self.num_workers > 0 else 1)))\n            self._worker_idx_iter = iter(self._worker_idx)\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        else:\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {self.dataset}.\"\n            )\n\n        self.restore = True\n\n        if self._profile_batches:\n            if self._profile_dir is None:\n                self._profile_dir = os.getcwd()\n\n            from viztracer import VizTracer\n\n            tracer = VizTracer(output_file=os.path.join(self._profile_dir, \"result.json\"), verbose=0)\n            tracer.start()\n\n            # Reload to remove the patching\n            reloaded_worker = reload(worker)\n            create_fetcher = _DatasetKind.create_fetcher\n            fetcher = None\n\n            def create_fetcher_fn(*args: Any, **kwargs: Any) -> \"_BaseDatasetFetcher\":\n                nonlocal fetcher\n                fetcher = create_fetcher(*args, **kwargs)\n                return fetcher\n\n            _DatasetKind.create_fetcher = create_fetcher_fn  # type: ignore\n\n            reloaded_worker._worker_loop(\n                _DatasetKind.Map,\n                self.dataset,\n                self._index_queues[self._latest_worker"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.restore = True\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.restore = True\n        else:\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {self.dataset}.\"\n            )\n\n        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.set_epoch(self.current_epoch)\n            self.dataset._set_use_streaming_dataloader(True)\n            self.dataset._set_num_samples_yielded(self._num_samples_yielded_streaming)\n            self.dataset._set_latest_worker_idx(self._latest_worker_idx)\n\n            self.dataset._set_use_streaming_dataloader(True)\n            self.dataset._set_num_samples_yielded(self._num_samples_yielded_streaming)\n            self.dataset._set_latest_worker_idx(self._latest_worker_idx)\n\n            if self.num_workers > 0:\n                self._index_queues = [torch.multiprocessing.get_context(self.multiprocessing_context).SimpleQueue() for _ in range(self.num_workers)]\n                self._workers = [\n                    torch."}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self._worker_idx_iter = iter(self._worker_idx)\n            self.restore = True\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self._worker_idx_iter = iter(self._worker_idx)\n            self.restore = True\n        else:\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {self.dataset}.\"\n            )\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        else:\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {type(self.dataset)}.\"\n            )\n\n        if self.restore:\n            self.restore = False\n        else:\n            self.restore = True\n            self._num_samples_yielded_streaming = 0\n            self._num_samples_yielded_combined = {}\n            self._latest_worker_idx = 0\n\n        if isinstance(self.dataset, StreamingDataset):\n            self.dataset._set_use_streaming_dataloader(False)\n            self.dataset.set_epoch(self.current_epoch)\n            self.dataset._set_use_streaming_dataloader(True)\n\n        self.dataset._set_use_streaming_dataloader(False)\n        self.dataset.set_epoch(self.current_epoch)\n        self.dataset._set_use_streaming_dataloader(True)\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            assert self.batch_size\n            self.dataset.load_state_dict(\n                obj[\"dataset\"], self._num_samples_yielded_streaming, self.num_workers, self.batch_size\n            )\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.restore = True\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            assert self.batch_size\n            self.dataset.load_state_dict(\n                obj[\"dataset\"], self.num_workers, self.batch_size, obj[\"num_samples_yielded\"]\n            )\n            self.current_epoch = obj[\"current_epoch\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.restore = True\n        else:\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {self.dataset}.\"\n            )\n\n        if self.restore:\n            if isinstance(self.dataset, StreamingDataset):\n                self._index_sampler = self.dataset._sampler\n                self._sampler_iter = iter(self._index_sampler)\n            else:\n                self._sampler_iter = iter(self._index_sampler)\n\n            if isinstance(self.dataset, CombinedStreamingDataset):\n                self._sampler_iter = cycle(self._sampler_iter)\n\n            self._iterator = _StreamingMultiProcessingDataLoaderIter(self)\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            assert self.batch_size\n            self.dataset.load_state_dict(obj[\"dataset\"], self._num_samples_yielded_streaming, self.num_workers, self.batch_size)\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"], self.num_workers, self.batch_size, obj[\"num_samples_yielded\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        else:\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {self.dataset}.\"\n            )\n\n        if self.restore:\n            self.restore = False\n            self.dataset._set_use_streaming_dataloader(False)\n            self.dataset._set_use_combined_dataset(False)\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            assert self.batch_size\n            self.dataset.load_state_dict(\n                obj[\"dataset\"], self._num_samples_yielded_streaming, self.num_workers, self.batch_size\n            )\n        else:\n            self.dataset.load_state_dict(\n                obj[\"dataset\"], self.num_workers, self.batch_size, obj[\"num_samples_yielded\"]\n            )\n\n        self.current_epoch = obj[\"current_epoch\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n        self._num_samples_yielded_streaming = 0\n        self.restore = True\n\n        if isinstance(self.dataset, StreamingDataset):\n            self.dataset._set_use_streaming_dataloader(False)\n\n        if self._profile_batches:\n            from viztracer import VizTracer\n\n            if self._profile_dir is None:\n                output_file = os.path.join(os.getcwd(), \"result.json\")\n            else:\n                output_file = os.path.join(self._profile_dir, \"result.json\")\n\n            if os.path.exists(output_file):\n                os.remove(output_file)\n\n            tracer = VizTracer(output_file=output_file, verbose=0)\n            tracer.start()\n\n        if self.num_workers > 0:\n            self._iterator = _StreamingMultiProcessingDataLoaderIter(self)\n        else:\n            self._iterator = _SingleProcessDataLoaderIter(self)\n\n        if self._profile_batches:\n            self._iterator._worker_loop = _ProfileWorkerLoop(self._profile_batches, self._profile_dir)\n\n        if self._profile_batches:\n            tracer.stop()\n            tracer.save()\n            print("}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            assert self.batch_size\n            self.dataset.load_state_dict(\n                obj[\"dataset\"],\n                self._num_samples_yielded_streaming,\n                self.num_workers,\n                self.batch_size,\n            )\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        else:\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n\n        if self.restore:\n            self.restore = False\n\n        self.dataset._set_use_streaming_dataloader(False)\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self._worker_idx = cycle(list(range(self.num_workers if self.num_workers > 0 else 1)))\n            self._worker_idx_iter = iter(self._worker_idx)\n            self.restore = True\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self._worker_idx = cycle(list(range(self.num_workers if self.num_workers > 0 else 1)))\n            self._worker_idx_iter = iter(self._worker_idx)\n            self.restore = True\n        else:\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {self.dataset}.\"\n            )\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            assert self.batch_size\n            self.dataset.load_state_dict(\n                obj[\"dataset\"], self._num_samples_yielded_streaming, self.num_workers, self.batch_size\n            )\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(\n                obj[\"dataset\"], self.num_workers, self.batch_size, obj[\"num_samples_yielded\"]\n            )\n        else:\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {self.dataset}.\"\n            )\n\n        self.current_epoch = obj[\"current_epoch\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        self._worker_idx = cycle(list(range(self.num_workers if self.num_workers > 0 else 1)))\n        self._worker_idx_iter = iter(self._worker_idx)\n        self.restore = True\n\n        if self._profile_batches:\n            from viztracer import VizTracer\n\n            if self._profile_dir is None:\n                self._profile_dir = os.getcwd()\n\n            if not os.path.exists(self._profile_dir):\n                os.makedirs(self._profile_dir)\n\n            tracer = VizTracer(output_file=os.path.join(self._profile_dir, \"result.json\"), verbose=0)\n            tracer.start()\n            self._worker_loop = _ProfileWorkerLoop(self._profile_batches, self._profile_dir)\n\n            self._worker_loop = _ProfileWorkerLoop(self._profile_batches, self._profile_dir)\n            self._worker_loop = _ProfileWorkerLoop(self._profile_batches, self._profile_dir)\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            assert self.batch_size\n            self.dataset.load_state_dict(\n                obj[\"dataset\"],\n                self._num_samples_yielded_streaming,\n                self.num_workers,\n                self.batch_size,\n            )\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        else:\n            self.dataset.load_state_dict(\n                obj[\"dataset\"],\n                self._latest_worker_idx,\n                self.num_workers,\n                self.batch_size,\n                obj[\"num_samples_yielded\"],\n            )\n            self.current_epoch = obj[\"current_epoch\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.restore = True\n\n        if self.num_workers > 0:\n            self.dataset._set_use_streaming_dataloader(True)\n\n        if self._profile_batches:\n            self._profile_batches = self._profile_batches if isinstance(self._profile_batches, int) else 1\n            if self._profile_dir is None:\n                self._profile_dir = os.path.join(os.getcwd(), \"profiling\")\n\n            if not os.path.exists(self._profile_dir):\n                os.makedirs(self._profile_dir)\n\n            from torch.utils.data._utils import worker\n\n            worker._worker_loop = _ProfileWorkerLoop(self._profile_batches, self._profile_dir)\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(\n                obj[\"dataset\"], self._num_samples_yielded_streaming, self.num_workers, self.batch_size\n            )\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"], self.num_workers, self.batch_size)\n        else:\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {self.dataset}.\"\n            )\n\n        self.current_epoch = obj[\"current_epoch\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n        self._num_samples_yielded_streaming = obj[\"num_samples_yielded_streaming\"]\n\n        if self.restore:\n            self.restore = False\n        else:\n            self.restore = True\n            self._num_samples_yielded_streaming = 0\n            self._num_samples_yielded_combined = {}\n\n        if isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset._set_use_streaming_dataloader(True)\n\n        self.dataset.set_epoch(self.current_epoch)\n\n        if self.num_workers > 0:\n            self.dataset._worker_init_fn = self._worker_init_fn\n            self.dataset._worker_init_fn_args = (self._latest_worker_idx,)\n\n        if self.num_workers > 1:\n            self.sampler = CacheBatchSampler(\n                len(self.dataset),\n                self.num_workers,\n                self._latest_worker_idx,\n                self.num_workers,\n                self.batch_size,\n                False,\n                False"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        if self._iterator is None:\n            state_dict = {}\n            for i, dataset in enumerate(self._datasets):\n                state_dict[f\"{__NUM_SAMPLES_YIELDED_KEY__}_{i}\"] = num_samples_yielded[i]\n                state_dict[f\"{__SAMPLES_KEY__}_{i}\"] = dataset.state_dict(num_workers, batch_size)\n            return state_dict\n\n        return self._iterator.state_dict(num_workers, batch_size)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                state_dict = {}\n                for i, dataset in enumerate(self._datasets):\n                    state_dict[f\"dataset_{i}\"] = dataset.state_dict(num_workers, batch_size, num_samples_yielded[i])\n                return state_dict\n\n        return self._iterator.state_dict(num_workers, batch_size)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                return {\n                    __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                }\n        else:\n            return self._iterator.state_dict(num_workers, batch_size)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        if num_samples_yielded is None:\n            return self._iterator.state_dict(num_workers, batch_size)\n\n        state_dict = {}\n        state_dict[__NUM_SAMPLES_YIELDED_KEY__] = num_samples_yielded\n        state_dict[__SAMPLES_KEY__] = []\n        for i, dataset in enumerate(self._datasets):\n            state_dict[__SAMPLES_KEY__].append(dataset.state_dict(num_workers, batch_size, num_samples_yielded[i]))\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        if num_samples_yielded is None:\n            num_samples_yielded = self._iterator.num_samples_yielded\n\n        state_dict = {}\n        for idx, dataset in enumerate(self._datasets):\n            state_dict[f\"{__NUM_SAMPLES_YIELDED_KEY__}_{idx}\"] = num_samples_yielded[idx]\n            state_dict[f\"{__SAMPLES_KEY__}_{idx}\"] = dataset.state_dict(num_workers, batch_size)\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        state_dict = {}\n\n        if self._iterator is None:\n            state_dict = self._iterator.state_dict(num_workers, batch_size, num_samples_yielded)\n        else:\n            state_dict = self._iterator.state_dict()\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        if self._iterator is None:\n            state_dict = {}\n            for i, dataset in enumerate(self._datasets):\n                state_dict[f\"{__NUM_SAMPLES_YIELDED_KEY__}_{i}\"] = num_samples_yielded[i]\n                state_dict[f\"{__SAMPLES_KEY__}_{i}\"] = dataset.state_dict(num_workers, batch_size)\n            return state_dict\n\n        return self._iterator.state_dict(num_workers, batch_size)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        if self._iterator is None:\n            return self._iterator.state_dict(num_workers, batch_size, num_samples_yielded)\n        else:\n            return self._iterator.state_dict(num_workers, batch_size)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                state_dict = {}\n                for i, dataset in enumerate(self._datasets):\n                    state_dict[f\"{__NUM_SAMPLES_YIELDED_KEY__}_{i}\"] = num_samples_yielded[i]\n                    state_dict[f\"{__SAMPLES_KEY__}_{i}\"] = dataset.state_dict(num_workers, batch_size)\n                return state_dict\n        else:\n            return self._iterator.state_dict(num_workers, batch_size)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        if self._iterator is None:\n            return self._iterator.state_dict(num_workers, batch_size, num_samples_yielded)\n\n        return self._iterator.state_dict(num_workers, batch_size)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        if num_samples_yielded is not None:\n            self._num_samples_yielded = num_samples_yielded\n\n        state_dict = {}\n\n        if self._iterator is not None:\n            state_dict = self._iterator.state_dict(num_workers, batch_size)\n        else:\n            state_dict = {}\n            for i, dataset in enumerate(self._datasets):\n                state_dict[f\"{__SAMPLES_KEY__}{i}\"] = dataset.state_dict()\n            state_dict[__NUM_SAMPLES_YIELDED_KEY__] = self._num_samples_yielded\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None and num_samples_yielded is None:\n            return {}\n        elif self._iterator is None:\n            return self._iterator.state_dict(num_workers, batch_size, num_samples_yielded)\n        else:\n            return self._iterator.state_dict(num_workers, batch_size)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None and num_samples_yielded is None:\n            return {}\n        elif self._iterator is None:\n            return {\n                __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                __SAMPLES_KEY__: [d.state_dict(num_workers, batch_size) for d in self._datasets],\n            }\n        else:\n            return self._iterator.state_dict(num_workers, batch_size)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                return {\n                    __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                    __SAMPLES_KEY__: self._iterator.samples,\n                }\n        else:\n            return self._iterator.state_dict(num_workers, batch_size)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                return {\n                    __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                }\n        else:\n            return self._iterator.state_dict(num_workers, batch_size)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        if self._iterator is None:\n            return self._iterator.state_dict(num_workers, batch_size, num_samples_yielded)\n\n        return self._iterator.state_dict(num_workers, batch_size)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        if self._iterator is None:\n            return {\n                __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                __SAMPLES_KEY__: [dataset.state_dict(num_workers, batch_size) for dataset in self._datasets],\n            }\n\n        return self._iterator.state_dict(num_workers, batch_size)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        if self._iterator is not None:\n            return self._iterator.state_dict(num_workers, batch_size)\n\n        state_dict = {}\n        for i, dataset in enumerate(self._datasets):\n            state_dict[f\"{i}\"] = dataset.state_dict(num_workers, batch_size, num_samples_yielded[i])\n        return state_dict\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None and num_samples_yielded is None:\n            return {}\n\n        if self._iterator is None:\n            return self._iterator.state_dict(num_workers, batch_size, num_samples_yielded)\n\n        return self._iterator.state_dict(num_workers, batch_size)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None and num_samples_yielded is None:\n            return {}\n        elif self._iterator is None:\n            return self._iterator.state_dict(num_workers, batch_size, num_samples_yielded)\n        else:\n            return self._iterator.state_dict(num_workers, batch_size)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            return _state_dict(self._datasets, num_samples_yielded, num_workers, batch_size)\n        return self._iterator.load_state_dict(state_dict)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            if __NUM_SAMPLES_YIELDED_KEY__ in state_dict:\n                self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n            return\n        self._iterator.load_state_dict(state_dict)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n            for dataset in self._datasets:\n                dataset.load_state_dict(state_dict[__SAMPLES_KEY__])\n            return\n        self._iterator.load_state_dict(state_dict)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n            self._datasets = state_dict[__SAMPLES_KEY__]\n            return\n\n        self._iterator.load_state_dict(state_dict)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n            for dataset in self._datasets:\n                dataset.load_state_dict(state_dict[dataset.name])\n            return\n        self._iterator.load_state_dict(state_dict)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n            for dataset in self._datasets:\n                dataset.load_state_dict(state_dict[__SAMPLES_KEY__][dataset.name])\n        else:\n            self._iterator.load_state_dict(state_dict)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is not None:\n            self._iterator.load_state_dict(state_dict)\n            return\n\n        num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n        samples = state_dict[__SAMPLES_KEY__]\n\n        for dataset, sample in zip(self._datasets, samples):\n            dataset.load_state_dict(sample)\n\n        self._num_samples_yielded = num_samples_yielded\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            self._num_samples_yielded = state_dict[_NUM_SAMPLES_YIELDED_KEY__]\n            for dataset in self._datasets:\n                dataset.load_state_dict(state_dict[_SAMPLES_KEY__])\n            return\n        self._iterator.load_state_dict(state_dict)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            if not state_dict:\n                return\n            self._num_samples_yielded = state_dict[_NUM_SAMPLES_YIELDED_KEY__]\n            self._iterator = _CombinedDatasetIterator(\n                self._datasets,\n                self._seed,\n                self._weights,\n                self._use_streaming_dataloader,\n                self._num_samples_yielded,\n            )\n        self._iterator.load_state_dict(state_dict)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            self._num_samples_yielded = state_dict[_NUM_SAMPLES_YIELDED_KEY__]\n            for dataset in self._datasets:\n                dataset.load_state_dict(state_dict[_SAMPLES_KEY__])\n            return\n\n        self._iterator.load_state_dict(state_dict)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n            for dataset in self._datasets:\n                dataset.load_state_dict(state_dict[__SAMPLES_KEY__][type(dataset).__name__])\n            return\n\n        self._iterator.load_state_dict(state_dict)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        self._iterator = _CombinedDatasetIterator.load_state_dict(self._datasets, state_dict)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n            for dataset in self._datasets:\n                dataset.load_state_dict(state_dict[__SAMPLES_KEY__][dataset.name])\n            return\n        self._iterator.load_state_dict(state_dict)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            self._num_samples_yielded = state_dict.get(__NUM_SAMPLES_YIELDED_KEY__, None)\n            for dataset in self._datasets:\n                dataset.load_state_dict(state_dict[dataset.dataset_name])\n            return\n        self._iterator.load_state_dict(state_dict)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n            for dataset in self._datasets:\n                dataset.load_state_dict(state_dict[__SAMPLES_KEY__][dataset.get_name()])\n            return\n        self._iterator.load_state_dict(state_dict)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n            for dataset in self._datasets:\n                dataset.load_state_dict(state_dict[__SAMPLES_KEY__][dataset.name])\n            return\n        self._iterator.load_state_dict(state_dict)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n            for dataset in self._datasets:\n                dataset.load_state_dict(state_dict[__SAMPLES_KEY__][dataset.dataset_name])\n\n        else:\n            self._iterator.load_state_dict(state_dict)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        self._num_samples_yielded = state_dict.get(__NUM_SAMPLES_YIELDED_KEY__, None)\n\n        for dataset in self._datasets:\n            dataset.load_state_dict(state_dict[dataset.name])\n\n        if self._iterator is not None:\n            self._iterator.load_state_dict(state_dict)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n            for dataset in self._datasets:\n                dataset.load_state_dict(state_dict[__SAMPLES_KEY__][type(dataset)])\n        else:\n            self._iterator.load_state_dict(state_dict)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            if __NUM_SAMPLES_YIELDED_KEY__ not in state_dict:\n                return\n            self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n            return\n        self._iterator.load_state_dict(state_dict)\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, str):\n        if dir_path.startswith(\"s3://\"):\n            return Dir(url=dir_path)\n        elif dir_path.startswith(\"s3\"):\n            return Dir(url=f\"s3://{dir_path}\")\n        elif dir_path.startswith(\"https://\"):\n            return Dir(url=dir_path)\n        elif dir_path.startswith(\"https\"):\n            return Dir(url=f\"https://{dir_path}\")\n        elif dir_path.startswith(\"gs://\"):\n            return Dir(url=dir_path)\n        elif dir_path.startswith(\"gs\"):\n            return Dir(url=f\"gs://{dir_path}\")\n        elif dir_path.startswith(\"sftp://\"):\n            return Dir(url=dir_path)\n        elif dir_path.startswith(\"sftp\"):\n            return Dir(url=f\"sftp://{dir_path}\")\n        elif dir_path.startswith(\"s3-compatible://\"):\n            return Dir(url=dir_path)\n        elif dir_path.startswith(\"s3-compatible\"):\n            return Dir(url=f\"s3-compatible://{dir_path}\")\n        elif dir_path.startswith(\"gs-compatible://\"):\n            return Dir(url=dir_path)\n        elif dir_path.startswith(\"gs-compatible\"):\n            return Dir(url=f\"gs-compatible://{dir_path}\")\n        elif dir_path.startswith(\"sftp-compatible://\"):\n            return Dir(url=dir_path)\n        elif dir_path.startswith(\"sftp-compatible\"):\n            return Dir(url=f\"sftp-compatible://{dir_path}\")\n        elif dir_path.startswith(\"wasbs://\"):\n            return Dir(url=dir_path)\n        elif dir_path.startswith(\"wasbs\"):\n            return Dir(url=f\"wasbs://{dir_path}\")\n        elif dir_path.startswith(\"wasbs://\"):\n            return Dir(url="}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n\n    if isinstance(dir_path, str):\n        dir_path = Dir(path=dir_path)\n\n    if dir_path.path is None:\n        return Dir()\n\n    if dir_path.path.startswith(\"s3://\"):\n        return dir_path\n\n    if dir_path.path.startswith(\"https://\"):\n        return dir_path\n\n    if dir_path.path.startswith(\"gs://\"):\n        return dir_path\n\n    if dir_path.path.startswith(\"sftp://\"):\n        return dir_path\n\n    if dir_path.path.startswith(\"ftp://\"):\n        return dir_path\n\n    if dir_path.path.startswith(\"http://\"):\n        return dir_path\n\n    if dir_path.path.startswith(\"file://\"):\n        return dir_path\n\n    if dir_path.path.startswith(\"gs://\"):\n        return dir_path\n\n    if dir_path.path.startswith(\"sftp://\"):\n        return dir_path\n\n    if dir_path.path.startswith(\"ftp://\"):\n        return dir_path\n\n    if dir_path.path.startswith(\"http://\"):\n        return dir_path\n\n    if dir_path.path.startswith(\"file://\"):\n        return dir_path\n\n    return dir_path\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n\n    if isinstance(dir_path, str):\n        dir_path = Dir(path=dir_path)\n\n    if dir_path.url is not None:\n        return dir_path\n\n    if dir_path.path is None:\n        return dir_path\n\n    if dir_path.path.startswith(\"s3://\"):\n        dir_path.url = dir_path.path\n        dir_path.path = None\n        return dir_path\n\n    if dir_path.path.startswith(\"s3-\"):\n        dir_path.url = dir_path.path\n        dir_path.path = None\n        return dir_path\n\n    if dir_path.path.startswith(\"s3\"):\n        raise ValueError(\n            f\"Invalid S3 path: {dir_path.path}. S3 paths must start with 's3://' or 's3-'.\"\n        )\n\n    if dir_path.path.startswith(\"s3://\"):\n        raise ValueError(\n            f\"Invalid S3 path: {dir_path.path}. S3 paths must start with 's3://' or 's3-'.\"\n        )\n\n    if dir_path.path.startswith(\"s3-\"):\n        raise ValueError(\n            f\"Invalid S3 path: {dir_path.path}. S3 paths must start with 's3://' or 's3-'.\"\n        )\n\n    if dir_path.path.startswith(\"s3://\"):\n        raise ValueError(\n            f\"Invalid S3 path: {dir_path.path}. S3 paths must start with 's3://' or 's3-'.\"\n        )\n\n    if dir_path.path.startswith(\"s3://\"):\n        raise ValueError(\n            f\"Invalid S3 path: {dir_path.path}. S3 paths must start with 's3://' or 's3-'.\"\n        )\n\n    if dir_path.path.startswith(\"s3://\"):\n        raise ValueError("}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n\n    if isinstance(dir_path, str):\n        dir_path = Dir(path=dir_path)\n\n    if dir_path.path is None:\n        return Dir()\n\n    # Check if path is a local path.\n    if not dir_path.path.startswith(\"s3://\"):\n        return dir_path\n\n    # Check if path is a local path.\n    if dir_path.path.startswith(\"s3://\"):\n\n        # Check if path is a project path.\n        if dir_path.path.startswith(\"s3://project-data/\"):\n            return dir_path\n\n        # Check if path is a project path.\n        if dir_path.path.startswith(\"s3://project-output/\"):\n            return dir_path\n\n        # Check if path is a project path.\n        if dir_path.path.startswith(\"s3://project-input/\"):\n            return dir_path\n\n        # Check if path is a project path.\n        if dir_path.path.startswith(\"s3://project-output/\"):\n            return dir_path\n\n        # Check if path is a project path.\n        if dir_path.path.startswith(\"s3://project-input/\"):\n            return dir_path\n\n        # Check if path is a project path.\n        if dir_path.path.startswith(\"s3://project-input/\"):\n            return dir_path\n\n        # Check if path is a project path.\n        if dir_path.path.startswith(\"s3://project-input/\"):\n            return dir_path\n\n        # Check if path is a project path.\n        if dir_path.path.startswith(\"s3://project-input/\"):\n            return dir_path\n\n        # Check if path is a project path.\n        if dir_path.path.startswith(\"s3://project-input/\"):\n            return dir_path\n\n        # Check if path is a project path.\n        if dir_path.path.startswith(\"s3://project-input/\"):\n           "}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n\n    if isinstance(dir_path, str):\n        if dir_path.startswith(\"s3://\"):\n            return Dir(url=dir_path)\n        else:\n            return Dir(path=dir_path)\n\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    raise ValueError(f\"Unable to resolve dir_path {dir_path}\")\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n\n    if isinstance(dir_path, str):\n        if dir_path.startswith(\"s3://\"):\n            return Dir(url=dir_path)\n        else:\n            return Dir(path=dir_path)\n    elif isinstance(dir_path, Dir):\n        return dir_path\n    else:\n        raise ValueError(f\"Unsupported directory path format: {dir_path}\")\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"studio://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"studio-project://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"studio-project-artifact://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"studio-project-artifacts://\"):\n        return Dir(url=dir_path)\n\n    return Dir(path=dir_path)\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"s3fs://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"https://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"gs://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"wasbs://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"sftp://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"gsiftp://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"file://\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"https://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"http://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"ftp://\"):\n        return Dir(url=dir_path)\n\n    return Dir(path=dir_path)\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n\n    if isinstance(dir_path, str):\n        dir_path = Dir(path=dir_path)\n\n    if dir_path.path is None:\n        return Dir()\n\n    if dir_path.path.startswith(\"s3://\"):\n        return dir_path\n\n    if dir_path.path.startswith(\"s3\"):\n        return Dir(path=\"s3://\" + dir_path.path)\n\n    if dir_path.path.startswith(\"s3://\"):\n        return Dir(path=dir_path.path)\n\n    if dir_path.path.startswith(\"s3://\"):\n        return Dir(path=dir_path.path)\n\n    if dir_path.path.startswith(\"s3://\"):\n        return Dir(path=dir_path.path)\n\n    if dir_path.path.startswith(\"s3://\"):\n        return Dir(path=dir_path.path)\n\n    return dir_path\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n\n    if isinstance(dir_path, str):\n        if dir_path.startswith(\"s3://\"):\n            return Dir(url=dir_path)\n        else:\n            return Dir(path=dir_path)\n    elif isinstance(dir_path, Dir):\n        if dir_path.url is not None:\n            return dir_path\n        else:\n            return Dir(path=dir_path.path)\n    else:\n        raise TypeError(\n            f\"The dir_path argument must be of type str or Dir, but is of type {type(dir_path)}.\"\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n\n    if isinstance(dir_path, str):\n        dir_path = Dir(path=dir_path)\n\n    if dir_path.path is None:\n        return Dir()\n\n    # Check if the path is a local path.\n    if os.path.exists(dir_path.path):\n        return dir_path\n\n    # Check if the path is a S3 URL.\n    if dir_path.path.startswith(\"s3://\"):\n        return dir_path\n\n    # Check if the path is a project path.\n    if dir_path.path.startswith(\"project://\"):\n        return dir_path\n\n    # Check if the path is a studio path.\n    if dir_path.path.startswith(\"studio://\"):\n        return dir_path\n\n    raise ValueError(f\"Invalid path format: {dir_path.path}\")\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n\n    if isinstance(dir_path, str):\n        dir_path = parse.urlsplit(dir_path)\n\n    if dir_path.scheme == \"s3\":\n        return Dir(url=parse.urlunsplit(dir_path))\n\n    if dir_path.scheme == \"\":\n        return Dir(path=os.path.abspath(dir_path.path))\n\n    return dir_path\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n\n    if isinstance(dir_path, str):\n        dir_path = parse.urlparse(dir_path)\n        if dir_path.scheme == \"s3\":\n            return Dir(url=dir_path)\n        else:\n            return Dir(path=dir_path)\n    elif isinstance(dir_path, Dir):\n        return dir_path\n    else:\n        raise TypeError(\"dir_path must be a string or Dir object.\")\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if not dir_path:\n        return Dir()\n\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n\n    return Dir(path=dir_path)\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n\n    if isinstance(dir_path, str):\n        if dir_path.startswith(\"s3://\"):\n            return Dir(url=dir_path)\n        else:\n            return Dir(path=dir_path)\n\n    elif isinstance(dir_path, Dir):\n        return dir_path\n\n    else:\n        raise ValueError(\n            \"The input dir_path must be a string or a Dir object. Instead, it is of type {}.\".format(\n                type(dir_path)\n            )\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if not dir_path:\n        return Dir()\n\n    if isinstance(dir_path, str):\n        if dir_path.startswith(\"s3://\"):\n            return Dir(url=dir_path)\n        else:\n            return Dir(path=dir_path)\n    else:\n        return dir_path\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n\n    if isinstance(dir_path, str):\n        if dir_path.startswith(\"s3://\"):\n            return Dir(url=dir_path)\n        else:\n            return Dir(path=dir_path)\n    else:\n        return dir_path\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"https://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"s3://\") or dir_path.startswith(\"https://\"):\n        return Dir(url=dir_path)\n\n    return Dir(path=dir_path)\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    # If the input directory path is already a Dir object, then return it.\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    # If the input directory path is None, then return an empty Dir object.\n    if dir_path is None:\n        return Dir()\n\n    # If the input directory path is a URL, then return a Dir object with the URL and no path.\n    if dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n\n    # If the input directory path is a local path, then return a Dir object with the path and no URL.\n    return Dir(path=dir_path)\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    # If the input directory path is a string, create a Dir object and set the path attribute.\n    if isinstance(dir_path, str):\n        dir_obj = Dir()\n        dir_obj.path = dir_path\n\n    # If the input directory path is a Dir object, set the path attribute.\n    elif isinstance(dir_path, Dir):\n        dir_obj = dir_path\n\n    # If the input directory path is None, set the path attribute to None.\n    else:\n        dir_obj = Dir()\n        dir_obj.path = None\n\n    # If the path attribute is not None, parse the path to determine the path's format.\n    if dir_obj.path is not None:\n\n        # If the path is an S3 URL, set the URL attribute.\n        if dir_obj.path.startswith(\"s3://\"):\n            dir_obj.url = dir_obj.path\n\n        # If the path is a local path, set the URL attribute.\n        elif os.path.isabs(dir_obj.path):\n            dir_obj.url = f\"s3://{_get_project_name()}/{dir_obj.path}\"\n\n        # If the path is a relative path, set the URL attribute.\n        else:\n            dir_obj.url = f\"s3://{_get_project_name()}/{os.getcwd()}/{dir_obj.path}\"\n\n    return dir_obj\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise TypeError(f\"The `output_dir` must be a `Dir` object, got: {type(output_dir)}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"The `output_dir` must be an S3 directory, got: {output_dir.url}\")\n\n    if not _is_empty_dir(output_dir):\n        raise ValueError(f\"The `output_dir` must be empty, got: {output_dir.url}\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"`output_dir` must be a `Dir` object, got: {output_dir}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"`output_dir` must be an S3 directory, got: {output_dir.url}\")\n\n    if not output_dir.path.endswith(\"/\"):\n        output_dir.path += \"/\"\n\n    s3 = boto3.resource(\"s3\")\n    bucket_name = output_dir.url.split(\"/\")[2]\n    prefix = \"/\".join(output_dir.url.split(\"/\")[3:])\n\n    if not prefix.endswith(\"/\"):\n        prefix += \"/\"\n\n    bucket = s3.Bucket(bucket_name)\n\n    for obj in bucket.objects.filter(Prefix=prefix):\n        if obj.key == prefix:\n            continue\n        raise ValueError(f\"The output directory is not empty. Please specify a different directory.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise TypeError(f\"The `output_dir` must be an instance of the `Dir` class, got {type(output_dir)}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"The `output_dir` must be an S3 bucket, got {output_dir.url}\")\n\n    if not _is_empty_dir(output_dir):\n        raise ValueError(f\"The `output_dir` must be empty, got {output_dir.url}\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"`output_dir` must be an instance of the `Dir` class, got: {output_dir}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"`output_dir` must be an S3 directory, got: {output_dir}\")\n\n    if not _is_s3_dir_empty(output_dir.url):\n        raise ValueError(f\"The directory {output_dir} is not empty. Please delete the data in the directory or use a different directory.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"The `output_dir` must be an instance of the `Dir` class, but got: {output_dir}.\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"The `output_dir` must start with `s3://`, but got: {output_dir.url}.\")\n\n    if not output_dir.path:\n        raise ValueError(f\"The `output_dir` must be a valid directory path, but got: {output_dir.path}.\")\n\n    s3_client = boto3.client(\"s3\")\n\n    try:\n        s3_client.head_object(Bucket=output_dir.url.split(\"/\")[2], Key=output_dir.url.split(\"/\")[3])\n        if not append:\n            raise ValueError(\n                f\"The `output_dir` already contains data, but appending is not allowed. Please set `append=True`.\"\n            )\n        if not overwrite:\n            raise ValueError(\n                f\"The `output_dir` already contains data, but overwriting is not allowed. Please set `overwrite=True`.\"\n            )\n    except botocore.exceptions.ClientError as e:\n        if e.response[\"Error\"][\"Code\"] == \"404\":\n            return\n        else:\n            raise e\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The `output_dir` must be a `Dir` object.\")\n\n    if output_dir.url is None:\n        raise ValueError(\"The `output_dir` must have an associated URL.\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(\"The `output_dir` must be an S3 directory.\")\n\n    s3_client = boto3.client(\"s3\")\n\n    try:\n        response = s3_client.list_objects_v2(Bucket=output_dir.url.split(\"/\")[2], Prefix=output_dir.url.split(\"/\")[3])\n    except botocore.exceptions.ClientError as e:\n        if e.response[\"Error\"][\"Code\"] == \"NoSuchBucket\":\n            raise ValueError(f\"The S3 bucket {output_dir.url.split('/')[2]} does not exist.\")\n        else:\n            raise e\n\n    if \"Contents\" in response.keys():\n        if not append:\n            raise ValueError(\"The `output_dir` is not empty. Please set `append` to `True` to allow appending data.\")\n        if not overwrite:\n            raise ValueError(\n                \"The `output_dir` is not empty. Please set `overwrite` to `True` to allow overwriting data.\"\n            )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"`output_dir` must be a `Dir` object, got: {output_dir}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"`output_dir` must be an S3 directory, got: {output_dir.url}\")\n\n    if not _empty_s3_directory(output_dir.url):\n        raise ValueError(f\"`output_dir` must be an empty directory, got: {output_dir.url}\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"`output_dir` must be an instance of the Dir class.\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(\"`output_dir` must be a remote directory.\")\n\n    if not output_dir.path:\n        raise ValueError(\"`output_dir` must be a remote directory.\")\n\n    if append or overwrite:\n        raise NotImplementedError(\"Appending and overwriting data is not implemented yet.\")\n\n    s3_client = boto3.client(\"s3\")\n\n    paginator = s3_client.get_paginator(\"list_objects_v2\")\n\n    try:\n        response = paginator.paginate(Bucket=output_dir.url.split(\"/\")[2], Prefix=output_dir.url.split(\"/\")[3])\n        for page in response:\n            if \"Contents\" in page:\n                if len(page[\"Contents\"]) > 0:\n                    raise ValueError(\"`output_dir` already contains data.\")\n    except botocore.exceptions.ClientError as error:\n        if error.response[\"Error\"][\"Code\"] == \"NoSuchBucket\":\n            raise ValueError(\"`output_dir` does not exist.\")\n        else:\n            raise error\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"`output_dir` must be a `Dir`, got: {output_dir}\")\n\n    if output_dir.url is None:\n        raise ValueError(f\"`output_dir` must contain a URL, got: {output_dir}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"`output_dir` must contain an S3 URL, got: {output_dir}\")\n\n    if not append and not overwrite:\n        # Check if the directory is empty\n        try:\n            s3 = boto3.resource(\"s3\")\n            s3.Object(output_dir.url.split(\"/\")[2], \"/\".join(output_dir.url.split(\"/\")[3:])).load()\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                # The object does not exist.\n                return\n            else:\n                raise e\n        else:\n            raise ValueError(f\"`output_dir` must be empty, got: {output_dir}\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"The provided directory is not a Dir object. Please use the `Dir` class to create a directory.\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"The provided directory is not in an S3 bucket. Please use a directory in an S3 bucket.\")\n\n    if not _is_empty_dir(output_dir.url):\n        raise ValueError(f\"The provided directory is not empty. Please use an empty directory.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise TypeError(\n            f\"`output_dir` must be a `Dir` object, got: {type(output_dir)}.\"\n        )\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"`output_dir` must be a `Dir` object with a valid S3 URL, got: {output_dir.url}.\"\n        )\n\n    if not output_dir.path is None:\n        if not os.path.isdir(output_dir.path):\n            raise ValueError(f\"`output_dir` must be a valid directory, got: {output_dir.path}.\"\n        )\n\n    if not output_dir.url is None:\n        if not _s3_bucket_is_empty(output_dir.url):\n            raise ValueError(f\"`output_dir` must be an empty directory, got: {output_dir.url}.\"\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"`output_dir` must be an instance of the Dir class, got: {output_dir}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"`output_dir` must be an S3 directory, got: {output_dir}\")\n\n    if _s3_dir_is_empty(output_dir.url):\n        return\n\n    if not append:\n        raise ValueError(f\"The directory {output_dir.url} is not empty. Specify `append=True` to allow appending.\")\n\n    if not overwrite:\n        raise ValueError(f\"The directory {output_dir.url} is not empty. Specify `overwrite=True` to allow overwriting.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"The `output_dir` must be a `Dir` object, got: {output_dir}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"The `output_dir` must be a `Dir` object with a url that starts with `s3://`, got: {output_dir}\")\n\n    if output_dir.path is None:\n        raise ValueError(f\"The `output_dir` must be a `Dir` object with a path, got: {output_dir}\")\n\n    if not os.path.exists(output_dir.path):\n        raise ValueError(f\"The `output_dir` path does not exist, got: {output_dir.path}\")\n\n    if not os.path.isdir(output_dir.path):\n        raise ValueError(f\"The `output_dir` path must be a directory, got: {output_dir.path}\")\n\n    if os.listdir(output_dir.path):\n        raise ValueError(f\"The `output_dir` path must be empty, got: {output_dir.path}\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"`output_dir` must be a `Dir` object, got: {output_dir}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"`output_dir` must be an S3 directory, got: {output_dir}\")\n\n    if not output_dir.path.endswith(\"/\"):\n        output_dir.path = output_dir.path + \"/\"\n\n    if not output_dir.url.endswith(\"/\"):\n        output_dir.url = output_dir.url + \"/\"\n\n    s3_client = boto3.client(\"s3\")\n\n    try:\n        response = s3_client.list_objects_v2(Bucket=output_dir.url.split(\"/\")[2], Prefix=output_dir.url.split(\"/\")[3])\n    except botocore.exceptions.ClientError as e:\n        if e.response[\"Error\"][\"Code\"] == \"NoSuchBucket\":\n            raise ValueError(f\"The bucket {output_dir.url.split('/')[2]} does not exist.\")\n        else:\n            raise e\n\n    if \"Contents\" in response:\n        raise ValueError(f\"The bucket {output_dir.url.split('/')[2]} is not empty.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise TypeError(\n            f\"The `output_dir` must be an instance of the Dir class, not {type(output_dir)}.\"\n        )\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"The `output_dir` must be an S3 directory, not {output_dir.url}.\")\n\n    if not _is_empty_s3_dir(output_dir.url):\n        raise ValueError(\n            f\"The `output_dir` must be empty, not {output_dir.url}.\"\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\n            f\"The provided `output_dir` is not a `Dir` object. Please provide a `Dir` object.\"\n        )\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(\n            f\"The provided `output_dir` does not start with `s3://`. Please provide a `Dir` object with a `url` starting with `s3://`.\"\n        )\n\n    if not append and not overwrite:\n        s3_client = boto3.client(\"s3\")\n        bucket_name = output_dir.url.split(\"/\")[2]\n        bucket_prefix = \"/\".join(output_dir.url.split(\"/\")[3:])\n\n        response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=bucket_prefix)\n\n        if \"Contents\" in response:\n            raise ValueError(\n                f\"The provided `output_dir` is not empty. Please provide an empty `output_dir`.\"\n            )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"`output_dir` must be a `Dir` object, got: {output_dir}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"`output_dir` must be a directory in an S3 bucket, got: {output_dir}\")\n\n    if not _is_empty(output_dir.url):\n        raise ValueError(f\"`output_dir` is not empty: {output_dir}\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"The `output_dir` must be a `Dir`, got: {output_dir}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"The `output_dir` must be in an S3 bucket, got: {output_dir}\")\n\n    if not output_dir.path:\n        raise ValueError(f\"The `output_dir` must be a local directory, got: {output_dir}\")\n\n    if not os.path.exists(output_dir.path):\n        raise ValueError(f\"The `output_dir` must exist, got: {output_dir}\")\n\n    if os.path.isfile(output_dir.path):\n        raise ValueError(f\"The `output_dir` must be a directory, got: {output_dir}\")\n\n    if os.listdir(output_dir.path):\n        raise ValueError(f\"The `output_dir` must be empty, got: {output_dir}\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"The provided output directory is not a Dir object. Please provide a Dir object.\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"The provided output directory is not in an S3 bucket. Please provide a Dir object in an S3 bucket.\")\n\n    if not output_dir.url.endswith(\"/\"):\n        raise ValueError(f\"The provided output directory does not end with a '/'. Please provide a Dir object with a trailing '/'.\")\n\n    if not output_dir.path is None:\n        if not os.path.exists(output_dir.path):\n            raise ValueError(f\"The provided output directory does not exist. Please provide a Dir object that exists.\")\n\n    if not output_dir.path is None:\n        if not os.path.isdir(output_dir.path):\n            raise ValueError(f\"The provided output directory is not a directory. Please provide a Dir object that is a directory.\")\n\n    if not output_dir.path is None:\n        if os.listdir(output_dir.path):\n            raise ValueError(f\"The provided output directory is not empty. Please provide an empty output directory.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"`output_dir` must be an instance of the Dir class, got: {output_dir}\")\n\n    if output_dir.url is None:\n        raise ValueError(f\"`output_dir` must have a url, got: {output_dir}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"`output_dir` must be in an S3 bucket, got: {output_dir}\")\n\n    if not append and not overwrite:\n        # Check if the directory is empty.\n        s3_client = boto3.client(\"s3\")\n        try:\n            s3_client.list_objects_v2(Bucket=output_dir.url.split(\"/\")[2], Prefix=output_dir.url.split(\"/\")[3])\n        except botocore.exceptions.ClientError as error:\n            if error.response[\"Error\"][\"Code\"] == \"NoSuchBucket\":\n                raise ValueError(f\"The bucket {output_dir.url.split('/')[2]} does not exist.\")\n            elif error.response[\"Error\"][\"Code\"] == \"NoSuchKey\":\n                # The directory is empty.\n                return\n            else:\n                raise error\n        else:\n            raise ValueError(\n                f\"The directory {output_dir.url} is not empty. Please set `append` or `overwrite` to `True`.\"\n            )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # If the directory does not contain an index file, delete all objects within the specified prefix in the bucket.\n    if objects[\"KeyCount\"] == 0:\n        s3.delete_objects(\n            Bucket=obj.netloc,\n            Delete={\n                \"Objects\": [{\"Key\": obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\" + obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\" + key} for key in [obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\" + obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\" + key for key in [obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\" + key for key in [obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\" + key for key in [obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\" + key for key in [obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\" + key for key in [obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\" + key for key in [obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\" + key for key in [obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\" + key for key in [obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\" + key for key in [obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\" +"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    # Check if the directory already contains an index file.\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # If the directory contains an index file, raise an error.\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains data and datasets are meant to be immutable.\"\n            \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n\n    # If the directory does not contain an index file, delete all objects within the specified prefix in the bucket.\n    else:\n        s3.delete_objects(\n            Bucket=obj.netloc,\n            Delete={\n                \"Objects\": [\n                    {\"Key\": obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\" + obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\"}\n                    for obj in s3.list_objects_v2(\n                        Bucket=obj.netloc,\n                        Delimiter=\"/\",\n                        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n                    )[\"Contents\"]\n                ]\n            },\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # If the index file is already present, we raise an error.\n    if objects[\"KeyCount\"] > 0:\n        for obj in objects[\"Contents\"]:\n            if obj[\"Key\"].endswith(\"index.json\"):\n                raise RuntimeError(\n                    f\"The provided output_dir `{output_dir.path}` already contains data and datasets are meant to be immutable.\"\n                    \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n                )\n\n    # If the index file is not present, we delete all objects within the specified prefix in the bucket.\n    else:\n        objects = s3.list_objects_v2(\n            Bucket=obj.netloc,\n            Delimiter=\"/\",\n            Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n        )\n        for obj in objects[\"Contents\"]:\n            s3.delete_object(Bucket=obj.netloc, Key=obj[\"Key\"])\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    # Check if the directory contains an index file named \"index.json\".\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if objects[\"KeyCount\"] > 0:\n        for obj in objects[\"Contents\"]:\n            if obj[\"Key\"].endswith(\"index.json\"):\n                raise RuntimeError(\n                    f\"The provided output_dir `{output_dir.path}` already contains an index file named `index.json`.\"\n                    \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n                )\n\n    # If the directory does not contain an index file, delete all objects within the specified prefix in the bucket.\n    if objects[\"KeyCount\"] == 0:\n        s3.delete_objects(\n            Bucket=obj.netloc,\n            Delete={\n                \"Objects\": [{\"Key\": obj[\"Key\"]} for obj in s3.list_objects_v2(Bucket=obj.netloc, Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\")[\"Contents\"]]\n            },\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # We are not allowing to add data to a non empty folder\n    if objects[\"KeyCount\"] > 0:\n        if \"index.json\" in objects[\"Contents\"][0][\"Key\"]:\n            raise RuntimeError(\n                f\"The provided output_dir `{output_dir.path}` already contains data and datasets are meant to be immutable.\"\n                \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n            )\n        else:\n            for item in objects[\"Contents\"]:\n                s3.delete_object(Bucket=obj.netloc, Key=item[\"Key\"])\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # If the directory already contains an index file, raise an error.\n    if objects[\"KeyCount\"] > 0:\n        for key in objects[\"Contents\"]:\n            key_name = key[\"Key\"]\n            if key_name.endswith(\"index.json\"):\n                raise RuntimeError(\n                    f\"The provided output_dir `{output_dir.path}` already contains an index file named `index.json`. \"\n                    \"This is not allowed. HINT: Did you already run this pipeline?\"\n                )\n\n    # If the directory does not contain an index file, delete all objects within the specified prefix in the bucket.\n    if objects[\"KeyCount\"] == 0:\n        s3.delete_objects(\n            Bucket=obj.netloc,\n            Delete={\n                \"Objects\": [{\"Key\": key[\"Key\"]} for key in objects[\"Contents\"]]\n            }\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # If the directory is empty, we can return.\n    if objects[\"KeyCount\"] == 0:\n        return\n\n    # If the directory is not empty, we need to check if an index file exists.\n    for obj in objects[\"Contents\"]:\n        if obj[\"Key\"] == obj.path.lstrip(\"/\").rstrip(\"/\") + \"/index.json\":\n            raise RuntimeError(\n                f\"The provided output_dir `{output_dir.path}` already contains data and datasets are meant to be immutable.\"\n                \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n            )\n\n    # If the directory is not empty, but does not contain an index file, we need to delete all objects within the specified prefix in the bucket.\n    for obj in objects[\"Contents\"]:\n        s3.delete_object(Bucket=obj.netloc, Key=obj[\"Key\"])\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # If the directory is empty, we don't need to do anything.\n    if objects[\"KeyCount\"] == 0:\n        return\n\n    # If the directory is not empty, we need to check if it contains an index file.\n    if \"index.json\" in objects[\"Contents\"][0][\"Key\"]:\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains an index file named `index.json`.\"\n            \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n\n    # If the directory is not empty and does not contain an index file, we need to delete all objects within the specified prefix in the bucket.\n    for object in objects[\"Contents\"]:\n        s3.delete_object(Bucket=obj.netloc, Key=object[\"Key\"])\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if \"Contents\" in objects:\n        for object in objects[\"Contents\"]:\n            if object[\"Key\"] == obj.path.lstrip(\"/\").rstrip(\"/\") + \"/index.json\":\n                raise RuntimeError(\n                    f\"The provided output_dir `{output_dir.path}` already contains an index file. Please choose a different output_dir.\"\n                )\n\n    s3.delete_objects(\n        Bucket=obj.netloc,\n        Delete={\n            \"Objects\": [{\"Key\": obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\" + object[\"Key\"]} for object in objects[\"Contents\"]]\n        },\n    )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # If there is no index file, we need to delete all the objects within the prefix\n    if objects[\"KeyCount\"] == 0:\n        s3.delete_objects(\n            Bucket=obj.netloc,\n            Delete={\"Objects\": [{\"Key\": obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\" + key} for key in objects[\"Contents\"]]},\n        )\n\n    else:\n        # If there is an index file, we need to check if it is empty\n        index_file_objects = s3.list_objects_v2(\n            Bucket=obj.netloc,\n            Delimiter=\"/\",\n            Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/index.json\",\n        )\n\n        if index_file_objects[\"KeyCount\"] > 0:\n            index_file_object = s3.get_object(\n                Bucket=obj.netloc,\n                Key=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/index.json\",\n            )\n\n            index_file_content = index_file_object[\"Body\"].read()\n\n            if index_file_content == b\"{}\":\n                s3.delete_objects(\n                    Bucket=obj.netloc,\n                    Delete={\n                        \"Objects\": [\n                            {\"Key\": obj.path.lstrip(\"/\").rstrip(\"/\") + \"/"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if \"Contents\" in objects:\n        for object in objects[\"Contents\"]:\n            if object[\"Key\"].endswith(\"index.json\"):\n                raise RuntimeError(\n                    f\"The provided output_dir `{output_dir.path}` already contains an index file. This is not allowed.\"\n                    \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n                )\n\n    # If no index file is found, delete all objects within the specified prefix in the bucket.\n    if \"Contents\" not in objects:\n        s3.delete_objects(\n            Bucket=obj.netloc,\n            Delete={\n                \"Objects\": [{\"Key\": obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\" + object[\"Key\"]} for object in objects[\"Contents\"]]\n            },\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    # If the index file is not present in the bucket, delete all objects in the prefix\n    # TODO: Add support for `append` and `overwrite`.\n    if not _dir_has_index_file(output_dir):\n        s3.delete_objects(\n            Bucket=obj.netloc,\n            Delete={\n                \"Objects\": [{\"Key\": obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\" + key} for key in s3.list_objects_v2(Bucket=obj.netloc, Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\")[\"Contents\"]]\n            },\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # If there is an index file, it means that the directory has been initialized and we should not overwrite it.\n    if objects[\"KeyCount\"] > 0 and \"index.json\" in objects[\"Contents\"][0][\"Key\"]:\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains an index file and datasets are meant to be immutable.\"\n            \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n\n    # If there is no index file, it means that the directory has not been initialized and we can delete all objects within the specified prefix in the bucket.\n    if objects[\"KeyCount\"] == 0:\n        s3.delete_objects(\n            Bucket=obj.netloc,\n            Delete={\n                \"Objects\": [{\"Key\": obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\" + obj[\"Key\"]} for obj in objects[\"Contents\"]]\n            },\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # If the directory is empty, we can return\n    if objects[\"KeyCount\"] == 0:\n        return\n\n    # If the directory is not empty, we check if it contains an index file\n    for obj in objects[\"Contents\"]:\n        if obj[\"Key\"].endswith(\"index.json\"):\n            raise RuntimeError(\n                f\"The provided output_dir `{output_dir.path}` already contains an index file. Please, change the `output_dir` with your own versioning as a suffix.\"\n            )\n\n    # If the directory does not contain an index file, we delete all objects within the specified prefix in the bucket\n    for obj in objects[\"Contents\"]:\n        s3.delete_object(Bucket=obj.netloc, Key=obj[\"Key\"])\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # If the directory already contains an index file, raise an error.\n    if \"Contents\" in objects:\n        for content in objects[\"Contents\"]:\n            if content[\"Key\"].endswith(\"index.json\"):\n                raise RuntimeError(\n                    f\"The provided output_dir `{output_dir.path}` already contains a dataset and datasets are meant to be immutable.\"\n                    \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n                )\n\n    # If the directory does not contain an index file, delete all objects within the specified prefix in the bucket.\n    if \"Contents\" not in objects:\n        s3.delete_objects(\n            Bucket=obj.netloc,\n            Delete={\n                \"Objects\": [\n                    {\"Key\": obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\" + obj[\"Key\"]}\n                    for obj in objects[\"Contents\"]\n                ]\n            },\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if objects[\"KeyCount\"] == 0:\n        return\n\n    if \"index.json\" in objects[\"Contents\"][0][\"Key\"]:\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains an index file named `index.json`. Please use a different output_dir.\"\n        )\n\n    for obj in objects[\"Contents\"]:\n        s3.delete_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\" + obj[\"Key\"])\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # If there is an index file, we don't want to delete any data.\n    if \"Contents\" in objects:\n        for obj in objects[\"Contents\"]:\n            if obj[\"Key\"] == obj.path.lstrip(\"/\").rstrip(\"/\") + \"/index.json\":\n                raise RuntimeError(\n                    f\"The provided output_dir `{output_dir.path}` already contains an index file named `index.json`. Datasets are meant to be immutable.\"\n                    \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n                )\n\n    # If there is no index file, we delete all objects within the specified prefix in the bucket.\n    else:\n        s3.delete_objects(\n            Bucket=obj.netloc,\n            Delete={\"Objects\": [{\"Key\": obj[\"Key\"]} for obj in objects[\"Contents\"]]},\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if objects[\"KeyCount\"] > 0:\n        if \"index.json\" in objects[\"Contents\"][0][\"Key\"]:\n            raise RuntimeError(\n                f\"The provided output_dir `{output_dir.path}` already contains an index file. Please choose a different folder.\"\n            )\n\n        else:\n            s3.delete_objects(\n                Bucket=obj.netloc,\n                Delete={\n                    \"Objects\": [{\"Key\": obj[\"Key\"]} for obj in objects[\"Contents\"]],\n                },\n            )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # If the directory is empty, we can exit\n    if objects[\"KeyCount\"] == 0:\n        return\n\n    # If the directory is not empty, we check for the presence of an index file\n    if \"index.json\" in objects[\"Contents\"][0][\"Key\"]:\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains data and datasets are meant to be immutable.\"\n            \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n\n    # If the directory is not empty and does not contain an index file, we delete all objects within the specified prefix in the bucket\n    for obj in objects[\"Contents\"]:\n        s3.delete_object(Bucket=obj.netloc, Key=obj[\"Key\"])\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # If there are no objects in the bucket, return.\n    if objects[\"KeyCount\"] == 0:\n        return\n\n    # If there are objects in the bucket, check if there is an index file.\n    # If there is an index file, raise an error.\n    # If there is not an index file, delete all objects in the bucket and return.\n    if \"Contents\" in objects:\n        for object in objects[\"Contents\"]:\n            if object[\"Key\"] == obj.path.lstrip(\"/\").rstrip(\"/\") + \"/index.json\":\n                raise RuntimeError(\n                    f\"The provided output_dir `{output_dir.path}` already contains a dataset. Datasets are meant to be immutable.\"\n                )\n        s3.delete_objects(\n            Bucket=obj.netloc,\n            Delete={\"Objects\": [{\"Key\": object[\"Key\"]} for object in objects[\"Contents\"]]},\n        )\n    return\n\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # Wait until all parts are available\n        while True:\n            files = os.listdir(self._cache_dir)\n            if len(files) == num_workers:\n                break\n            sleep(1)\n\n        # If the current node is not the master node, wait until the merged index file is available\n        if node_rank is not None and node_rank != 0:\n            while True:\n                files = os.listdir(self._cache_dir)\n                if len(files) == num_workers + 1:\n                    break\n                sleep(1)\n\n        # Merge the index files\n        index_files = [f for f in files if f.endswith(_INDEX_FILENAME)]\n        index_files.sort()\n        chunks_info = []\n        for index_file in index_files:\n            with open(os.path.join(self._cache_dir, index_file), \"r\") as f:\n                chunks_info.append(json.load(f)[\"chunks\"])\n        chunks_info = [item for sublist in chunks_info for item in sublist]\n        with open(os.path.join(self._cache_dir, f\"{self.rank}.{_INDEX_FILENAME}\"), \"w\") as out:\n            json.dump({\"chunks\": chunks_info, \"config\": self.get_config()}, out, sort_keys=True)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # Wait until all parts of the index are available\n        while len(os.listdir(self._cache_dir)) < num_workers:\n            sleep(0.1)\n\n        # Wait until the merged index is available\n        while not os.path.exists(os.path.join(self._cache_dir, f\"{node_rank}.{_INDEX_FILENAME}\")):\n            sleep(0.1)\n\n        # The master node performs the merge\n        if node_rank == 0:\n            # Read all index files\n            chunks_info = []\n            for i in range(num_workers):\n                with open(os.path.join(self._cache_dir, f\"{i}.{_INDEX_FILENAME}\"), \"r\") as f:\n                    chunks_info.extend(json.load(f)[\"chunks\"])\n\n            # Write the merged index\n            with open(os.path.join(self._cache_dir, _INDEX_FILENAME), \"w\") as f:\n                json.dump({\"chunks\": chunks_info}, f, sort_keys=True)\n\n            # Remove the individual index files\n            for i in range(num_workers):\n                os.remove(os.path.join(self._cache_dir, f\"{i}.{_INDEX_FILENAME}\"))\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # Check if the current node is the master node\n        if node_rank is None:\n            node_rank = 0\n        if self.rank != node_rank:\n            while not os.path.exists(self.write_chunks_index()):\n                sleep(1)\n            return\n\n        # Merge all index files\n        index_files = [f for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)]\n        if len(index_files) != num_workers:\n            warnings.warn(\n                f\"The number of index files ({len(index_files)}) doesn't match the number of workers ({num_workers}).\"\n                \" The index will be merged anyway.\",\n                UserWarning,\n            )\n        index_files.sort(key=lambda x: int(x.split(\".\")[0].split(\"-\")[-1]))\n\n        chunks_info = []\n        for index_file in index_files:\n            with open(os.path.join(self._cache_dir, index_file), \"r\") as f:\n                chunks_info.extend(json.load(f)[\"chunks\"])\n\n        # Write down the index file\n        config = self.get_config()\n        with open(os.path.join(self._cache_dir, f\"{self.rank}.{_INDEX_FILENAME}\"), \"w\") as out:\n            json.dump({\"chunks\": chunks_info, \"config\": config}, out, sort_keys=True)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # Check if the function is called in a distributed environment\n        if self._distributed_env.world_size > 1:\n            # Check if the node rank is provided\n            if node_rank is None:\n                # If the node rank is not provided, assume a non-distributed environment\n                node_rank = 0\n            # Check if the current node is the master node\n            if self.rank != node_rank:\n                # If the current node is not the master node, wait until the merged index file is available\n                while not os.path.exists(os.path.join(self._cache_dir, f\"{self.rank}.{_INDEX_FILENAME}\")):\n                    sleep(1)\n                # Exit the function\n                return\n\n        # Check if all parts of the index are available\n        while num_workers > 0:\n            # Check if the index part is available\n            if os.path.exists(os.path.join(self._cache_dir, f\"{num_workers - 1}.{_INDEX_FILENAME}\")):\n                # If the index part is available, decrease the number of expected parts\n                num_workers -= 1\n            else:\n                # If the index part is not available, wait for 1 second\n                sleep(1)\n\n        # Merge the index files\n        index_files = [f for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)]\n        index_files.sort()\n        index_files = [os.path.join(self._cache_dir, f) for f in index_files]\n\n        # Read the index files\n        indices = []\n        for index_file in index_files:\n            with open(index_file, \"r\") as in_f:\n                indices.append(json.load(in_f)[\"chunks\"])\n\n        # Merge the index files\n        merged_index = []\n        for index in indices:\n            merged_index.extend(index)\n\n        # Write the merged index file\n        with open(os.path.join(self._cache_dir, f\"{self.rank"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # If the current node is not the master node, wait until the merged index file is available\n        if node_rank is not None and node_rank != 0:\n            while not os.path.exists(os.path.join(self._cache_dir, f\"{self.rank}.{_INDEX_FILENAME}\")):\n                sleep(1)\n\n        # Wait until all index parts are available\n        while True:\n            if len(os.listdir(self._cache_dir)) == num_workers:\n                break\n            sleep(1)\n\n        # Merge all the index files\n        index_files = [os.path.join(self._cache_dir, f\"{self.rank}.{_INDEX_FILENAME}\") for self.rank in range(num_workers)]\n        chunks_info = []\n        for index_file in index_files:\n            with open(index_file, \"r\") as f:\n                chunks_info.append(json.load(f)[\"chunks\"])\n\n        # Write down the index file\n        with open(os.path.join(self._cache_dir, f\"{_INDEX_FILENAME}\"), \"w\") as out:\n            json.dump({\"chunks\": chunks_info, \"config\": self.get_config()}, out, sort_keys=True)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # If the user does not provide a node rank, assume a non-distributed environment\n        if node_rank is None:\n            node_rank = 0\n\n        # Wait until all parts of the index are available\n        while len(os.listdir(self._cache_dir)) < num_workers:\n            sleep(1)\n\n        # If the master node, perform the merge\n        if node_rank == 0:\n\n            # Collect the index files\n            index_files = [os.path.join(self._cache_dir, f) for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)]\n\n            # Combine the index files into a single JSON file\n            with open(os.path.join(self._cache_dir, f\"{self.rank}.{_INDEX_FILENAME}\"), \"w\") as out:\n                out.write(\"{\\\"chunks\\\": [\")\n                for f in index_files:\n                    with open(f) as in_f:\n                        out.write(in_f.read())\n                        out.write(\",\")\n                out.seek(out.tell() - 1, os.SEEK_SET)\n                out.write(\"]}\")\n\n            # Remove the index files\n            for f in index_files:\n                os.remove(f)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # If the environment is not distributed, assume the current node is the master node\n        if node_rank is None:\n            node_rank = 0\n\n        # Wait until all index parts are available\n        while not os.path.exists(os.path.join(self._cache_dir, f\"{node_rank}.{_INDEX_FILENAME}\")):\n            sleep(1)\n\n        # If the current node is not the master node, wait until the merged index file is available\n        if node_rank != 0:\n            while not os.path.exists(os.path.join(self._cache_dir, f\"{node_rank}.{_INDEX_FILENAME}\")):\n                sleep(1)\n            return\n\n        # Merge all index files into a single one\n        index_files = [f for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)]\n        index_files.sort()\n        index_files = [os.path.join(self._cache_dir, f) for f in index_files]\n        index_files = [f for f in index_files if os.path.exists(f)]\n\n        # Merge all index files into a single one\n        merged_index = {}\n        for index_file in index_files:\n            with open(index_file, \"r\") as in_file:\n                data = json.load(in_file)\n                merged_index.update(data[\"chunks\"])\n\n        # Write the merged index\n        with open(os.path.join(self._cache_dir, f\"{node_rank}.{_INDEX_FILENAME}\"), \"w\") as out:\n            json.dump({\"chunks\": list(merged_index.values()), \"config\": self.get_config()}, out, sort_keys=True)\n\n        # Delete all individual index files\n        for index_file in index_files:\n            os.remove(index_file)\n\n        # Delete all individual chunk files\n        for chunk_file in os.listdir(self._cache_dir):\n            if chunk_file.endswith(\".bin\"):"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # Wait until all parts of the index are ready\n        while True:\n            if node_rank is None:\n                # If the rank is None, assume a non-distributed environment\n                if len(os.listdir(self._cache_dir)) == num_workers:\n                    break\n            else:\n                # If the rank is not None, assume a distributed environment\n                if node_rank == 0:\n                    if len(os.listdir(self._cache_dir)) == num_workers:\n                        break\n                else:\n                    if len(os.listdir(self._cache_dir)) == num_workers + 1:\n                        break\n            sleep(1)\n\n        # If the current node is not the master node, wait until the merged index file is available\n        if node_rank is not None and node_rank != 0:\n            while True:\n                if len(os.listdir(self._cache_dir)) == 1:\n                    break\n                sleep(1)\n\n        # Merge the index files\n        if node_rank is None or node_rank == 0:\n            index_files = [f for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)]\n            chunks_info = {}\n            for file in index_files:\n                with open(os.path.join(self._cache_dir, file), \"r\") as in_file:\n                    chunks_info[file] = json.load(in_file)[\"chunks\"]\n            config = chunks_info[index_files[0]][\"config\"]\n            chunks = [chunks_info[file][\"chunks\"] for file in index_files]\n            chunks = [item for sublist in chunks for item in sublist]\n            chunks = sorted(chunks, key=lambda k: k[\"chunk_bytes\"])\n            with open(os.path.join(self._cache_dir, f\"{self.rank}.{_INDEX_FILENAME}\"), \"w\") as out:\n                json.dump({\"chunks\": chunks, \"config\": config"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            node_rank = 0\n\n        # Wait for all parts to be available\n        while len(os.listdir(self._cache_dir)) < num_workers:\n            sleep(0.1)\n\n        # Wait until the merged index is available\n        while not os.path.exists(os.path.join(self._cache_dir, f\"{node_rank}.{_INDEX_FILENAME}\")):\n            sleep(0.1)\n\n        # Perform the merge\n        if node_rank == 0:\n            self._merge_index_files(num_workers)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # If the user does not specify the node rank, assume a non-distributed environment\n        # and proceed with the merge\n        if node_rank is None:\n            self.merge(num_workers=num_workers, node_rank=0)\n            return\n\n        # If the node is not the master node, wait until the merged index file is available\n        if node_rank != 0:\n            while not os.path.exists(self.write_chunks_index()):\n                sleep(1)\n            return\n\n        # If the node is the master node, wait until all index parts are available\n        while len(os.listdir(self._cache_dir)) < num_workers:\n            sleep(1)\n\n        # If the node is the master node, merge the index files\n        chunks_info = []\n        for i in range(num_workers):\n            filepath = os.path.join(self._cache_dir, f\"{i}.{_INDEX_FILENAME}\")\n            with open(filepath, \"r\") as inp:\n                chunks_info.append(json.load(inp)[\"chunks\"])\n\n        # Merge the index files\n        self._chunks_info = [item for sublist in chunks_info for item in sublist]\n\n        # Write the merged index file\n        self.write_chunks_index()\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # If the number of workers is not specified, assume that the user is operating in a non-distributed environment\n        if num_workers == 1:\n            return\n\n        # If the node rank is not specified, assume that the user is operating in a non-distributed environment\n        if node_rank is None:\n            return\n\n        # If the master node (rank 0), perform the merge operation\n        if node_rank == 0:\n\n            # Wait until all index parts are available\n            while len(os.listdir(self._cache_dir)) < num_workers:\n                sleep(1)\n\n            # Merge all index parts\n            index_files = [os.path.join(self._cache_dir, file) for file in os.listdir(self._cache_dir)]\n            chunks_info = []\n            for file in index_files:\n                with open(file, \"r\") as in_file:\n                    chunks_info.append(json.load(in_file)[\"chunks\"])\n            chunks_info = [chunk for chunks in chunks_info for chunk in chunks]\n            with open(os.path.join(self._cache_dir, f\"{self.rank}.{_INDEX_FILENAME}\"), \"w\") as out_file:\n                json.dump({\"chunks\": chunks_info, \"config\": self.get_config()}, out_file, sort_keys=True)\n\n            # Wait until all index parts are available\n            while len(os.listdir(self._cache_dir)) > 1:\n                sleep(1)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # Wait for all parts of the index to be available\n        while not self.filled:\n            sleep(1)\n\n        # If the master node, perform the merge\n        if node_rank == 0 or node_rank is None:\n            # Merge the index files\n            filepaths = [os.path.join(self._cache_dir, f\"{i}.{_INDEX_FILENAME}\") for i in range(num_workers)]\n            index_files = [json.load(open(filepath)) for filepath in filepaths]\n            chunks = [index[\"chunks\"] for index in index_files]\n            config = index_files[0][\"config\"]\n\n            # Merge the chunks\n            chunks = [item for sublist in chunks for item in sublist]\n            chunks = sorted(chunks, key=lambda k: k[\"chunk_bytes\"], reverse=True)\n            self._chunks_info = chunks\n\n            # Write down the index file\n            self.write_chunks_index()\n\n            # Delete the individual index files\n            for filepath in filepaths:\n                os.remove(filepath)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # Determine the master node\n        if node_rank is None:\n            node_rank = 0\n\n        # Wait for all index parts to be available\n        while True:\n            files = os.listdir(self._cache_dir)\n            if len(files) == num_workers:\n                break\n            else:\n                sleep(1)\n\n        # Merge the index files\n        if node_rank == 0:\n            index_files = [f for f in files if f.endswith(_INDEX_FILENAME)]\n            index_files.sort()\n            index_files = [os.path.join(self._cache_dir, f) for f in index_files]\n\n            # Merge the index files\n            index_file_paths = []\n            for i in range(len(index_files)):\n                with open(index_files[i]) as f:\n                    index_file_paths.append(json.load(f))\n\n            chunks = []\n            for i in range(len(index_file_paths)):\n                chunks.extend(index_file_paths[i][\"chunks\"])\n\n            with open(os.path.join(self._cache_dir, f\"{self.rank}.{_INDEX_FILENAME}\"), \"w\") as out:\n                json.dump({\"chunks\": chunks, \"config\": self.get_config()}, out, sort_keys=True)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # Check if the writer is done\n        if self._is_done:\n            return\n\n        # Check if the node is the master node\n        if node_rank is None:\n            node_rank = self._distributed_env.global_rank\n        if node_rank != 0:\n            while not os.path.exists(os.path.join(self._cache_dir, f\"{self.rank}.{_INDEX_FILENAME}\")):\n                sleep(1)\n            return\n\n        # Check if all index parts are available\n        while len(os.listdir(self._cache_dir)) < num_workers + 1:\n            sleep(1)\n\n        # Merge the index files\n        index_files = [os.path.join(self._cache_dir, f\"{self.rank}.{_INDEX_FILENAME}\") for self.rank in range(num_workers)]\n        merged_index = {}\n        for index_file in index_files:\n            with open(index_file, \"r\") as in_file:\n                index = json.load(in_file)\n            merged_index.update(index[\"chunks\"])\n\n        # Write the merged index file\n        with open(os.path.join(self._cache_dir, f\"{self.rank}.{_INDEX_FILENAME}\"), \"w\") as out_file:\n            json.dump({\"chunks\": merged_index, \"config\": self.get_config()}, out_file, sort_keys=True)\n\n        # Wait for all workers to finish\n        while len(os.listdir(self._cache_dir)) > 1:\n            sleep(1)\n\n        # Mark the writer as done\n        self._is_done = True\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # If the writer is already done, there is nothing to do\n        if self.filled:\n            return\n\n        # If the master node is not specified, assume a non-distributed environment\n        if node_rank is None:\n            node_rank = 0\n\n        # If the current node is not the master node, wait until the merged index file is available\n        if node_rank != 0:\n            while not os.path.exists(os.path.join(self._cache_dir, f\"{node_rank}.{_INDEX_FILENAME}\")):\n                sleep(0.1)\n            return\n\n        # Wait until all index parts are available\n        while len(os.listdir(self._cache_dir)) < num_workers:\n            sleep(0.1)\n\n        # Merge the index files\n        index_files = [\n            os.path.join(self._cache_dir, f\"{i}.{_INDEX_FILENAME}\") for i in range(num_workers)\n        ]\n        index = {}\n        for file in index_files:\n            with open(file) as f:\n                index.update(json.load(f)[\"chunks\"])\n\n        # Write down the merged index file\n        with open(os.path.join(self._cache_dir, f\"{node_rank}.{_INDEX_FILENAME}\"), \"w\") as out:\n            json.dump({\"chunks\": list(index.values()), \"config\": self.get_config()}, out, sort_keys=True)\n\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # If the user specified a node rank, use it for the check\n        if node_rank is not None:\n            if node_rank != 0:\n                # Wait until the merged index file is available\n                while not os.path.exists(os.path.join(self._cache_dir, f\"{self.rank}.{_INDEX_FILENAME}\")):\n                    sleep(1)\n                return\n\n        # If the user did not specify a node rank, assume a non-distributed environment\n        # Wait until all parts of the index are available\n        while len(os.listdir(self._cache_dir)) < num_workers:\n            sleep(1)\n\n        # Merge the index files\n        index_files = [\n            os.path.join(self._cache_dir, f\"{rank}.{_INDEX_FILENAME}\") for rank in range(num_workers)\n        ]\n        index_files = [f for f in index_files if os.path.exists(f)]\n        chunks_info = {}\n        for index_file in index_files:\n            with open(index_file, \"r\") as f:\n                index_info = json.load(f)\n                chunks_info.update(index_info[\"chunks\"])\n\n        # Write down the index file\n        self._chunks_info = list(chunks_info.values())\n        self.write_chunks_index()\n\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # Check if the current node is the master node\n        if node_rank is None:\n            node_rank = 0\n\n        # Check if the current node is the master node\n        if node_rank != 0:\n            # Wait until the master node has created the merged index file\n            while not os.path.exists(os.path.join(self._cache_dir, f\"{node_rank}.{_INDEX_FILENAME}\")):\n                sleep(1)\n\n            return\n\n        # Wait until all index parts are available\n        while num_workers > 0:\n            if os.path.exists(os.path.join(self._cache_dir, f\"{num_workers - 1}.{_INDEX_FILENAME}\")):\n                num_workers -= 1\n            sleep(1)\n\n        # Merge the index files\n        filepaths = [os.path.join(self._cache_dir, f\"{i}.{_INDEX_FILENAME}\") for i in range(num_workers)]\n        chunks = []\n        configs = []\n        for filepath in filepaths:\n            with open(filepath, \"r\") as f:\n                data = json.load(f)\n                chunks.extend(data[\"chunks\"])\n                configs.append(data[\"config\"])\n\n        # Check if the chunks are consistent\n        assert len(chunks) > 0, \"No chunks were found.\"\n        assert all(\n            chunks[0][\"chunk_bytes\"] == chunk[\"chunk_bytes\"] for chunk in chunks\n        ), \"The chunks have different sizes.\"\n        assert all(\n            chunks[0][\"chunk_size\"] == chunk[\"chunk_size\"] for chunk in chunks\n        ), \"The chunks have different sizes.\"\n\n        # Merge the configs\n        config = {}\n        for key in configs[0]:\n            if key == \"config\":\n                continue\n            values = [configs[i][key] for i in range(len(configs))]\n            if isinstance(values[0], list):\n                values = [item for sublist in values for item"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # If the function is called from a non-distributed environment, assume the master node\n        if node_rank is None:\n            node_rank = 0\n\n        # Wait for all index parts to be available\n        while True:\n            if len(os.listdir(self._cache_dir)) == num_workers:\n                break\n            sleep(1)\n\n        # If the node is not the master node, wait until the merged index file is available\n        if node_rank != 0:\n            while not os.path.exists(self.write_chunks_index()):\n                sleep(1)\n\n        # Merge the index parts\n        if node_rank == 0:\n            # Get the list of all index files\n            index_files = [\n                os.path.join(self._cache_dir, f)\n                for f in os.listdir(self._cache_dir)\n                if f.endswith(_INDEX_FILENAME)\n            ]\n\n            # Read all index files and merge them into a single index\n            index = {}\n            for index_file in index_files:\n                with open(index_file, \"r\") as inp:\n                    index.update(json.load(inp)[\"chunks\"])\n\n            # Write the merged index file\n            with open(self.write_chunks_index(), \"w\") as out:\n                json.dump({\"chunks\": index, \"config\": self.get_config()}, out, sort_keys=True)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # The function assumes that the master node is rank 0 unless otherwise specified\n        if node_rank is None:\n            node_rank = 0\n\n        # The function waits for all index parts to be available\n        while len(os.listdir(self._cache_dir)) < num_workers:\n            sleep(1)\n\n        # The function merges the index parts only if the current node is the master node\n        if node_rank == 0:\n            filepaths = os.listdir(self._cache_dir)\n            filepaths.sort()\n            filepaths = [os.path.join(self._cache_dir, filepath) for filepath in filepaths]\n            filepaths = [filepath for filepath in filepaths if _INDEX_FILENAME in filepath]\n            with open(os.path.join(self._cache_dir, f\"merged-{_INDEX_FILENAME}\"), \"w\") as out:\n                for filepath in filepaths:\n                    with open(filepath, \"r\") as inp:\n                        json.dump(json.load(inp), out, sort_keys=True)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            node_rank = 0\n\n        if self._distributed_env.global_rank != node_rank:\n            # Wait until the merged index is available\n            while not os.path.exists(os.path.join(self._cache_dir, f\"{self._distributed_env.global_rank}.{_INDEX_FILENAME}\")):\n                sleep(0.1)\n            return\n\n        # Merge the index parts\n        index_files = [\n            os.path.join(self._cache_dir, f\"{rank}.{_INDEX_FILENAME}\")\n            for rank in range(num_workers)\n        ]\n        index_parts = [json.load(open(filepath, \"r\")) for filepath in index_files]\n        index_parts = sorted(index_parts, key=lambda x: x[\"config\"][\"chunk_size\"])\n        index = {\"chunks\": [], \"config\": index_parts[0][\"config\"]}\n        for part in index_parts:\n            index[\"chunks\"].extend(part[\"chunks\"])\n\n        with open(os.path.join(self._cache_dir, f\"{node_rank}.{_INDEX_FILENAME}\"), \"w\") as out:\n            json.dump(index, out)\n"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\n            \"The `lightning-sdk` is not available. Please install the SDK using `pip install lightning-sdk`.\"\n        )\n\n    if not machine:\n        machine = Machine()\n\n    if not command:\n        command = (\n            f\"cd {os.getcwd()} && \"\n            f\"export LIGHTNING_CLOUD_PROJECT_ID={os.getenv('LIGHTNING_CLOUD_PROJECT_ID')} && \"\n            f\"export LIGHTNING_CLOUD_SPACE_ID={os.getenv('LIGHTNING_CLOUD_SPACE_ID')} && \"\n            f\"export LIGHTNING_CLUSTER_ID={os.getenv('LIGHTNING_CLUSTER_ID')} && \"\n            f\"export LIGHTNING_CLOUD_PROJECT_ID={os.getenv('LIGHTNING_CLOUD_PROJECT_ID')} && \"\n            f\"export LIGHTNING_CLOUD_SPACE_ID={os.getenv('LIGHTNING_CLOUD_SPACE_ID')} && \"\n            f\"export LIGHTNING_CLUSTER_ID={os.getenv('LIGHTNING_CLUSTER_ID')} && \"\n            f\"export LIGHTNING_CLOUD_PROJECT_ID={os.getenv('LIGHTNING_CLOUD_PROJECT_ID')} && \"\n            f\"export LIGHTNING_CLOUD_SPACE_ID={os.getenv('LIGHTNING_CLOUD_SPACE_ID')} && \"\n            f\"export LIGHTNING_CLUSTER_ID={os.getenv('LIGHTNING_CLUSTER_ID')} && \"\n            f\"export LIGHTNING_CLOUD_PROJECT_ID={os.getenv('LIGHTNING_CLOUD_PROJECT_ID')} && \"\n            f\""}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\n            \"The `lightning-sdk` isn't available. Please install the `lightning-sdk` by running `pip install lightning-sdk`.\"\n        )\n\n    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\n            \"The `boto3` isn't available. Please install the `boto3` by running `pip install boto3`.\"\n        )\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && export LIGHTNING_CLOUD_PROJECT_ID={os.getenv('LIGHTNING_CLOUD_PROJECT_ID')} && export LIGHTNING_CLOUD_SPACE_ID={os.getenv('LIGHTNING_CLOUD_SPACE_ID')} && export LIGHTNING_CLOUD_DATASET_ID={os.getenv('LIGHTNING_CLOUD_DATASET_ID')} && export LIGHTNING_CLOUD_DATASET_VERSION={os.getenv('LIGHTNING_CLOUD_DATASET_VERSION')} && export LIGHTNING_CLOUD_DATASET_PATH={os.getenv('LIGHTNING_CLOUD_DATASET_PATH')} && export LIGHTNING_CLOUD_DATASET_URL={os.getenv('LIGHTNING_CLOUD_DATASET_URL')} && export LIGHTNING_CLOUD_DATASET_INDEX_PATH={os.getenv('LIGHTNING_CLOUD_DATASET_INDEX_PATH')} && export LIGHTNING_CLOUD_DATASET_INDEX_URL={os.getenv('LIGHTNING_CLOUD_DATASET_INDEX_URL')} && export LIGHTNING_CLOUD_DATASET_INDEX_VERSION={os.getenv('LIGHTNING_"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\n            \"The `lightning-sdk` package is required to use this function. Please install it and try again.\"\n        )\n\n    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\n            \"The `boto3` package is required to use this function. Please install it and try again.\"\n        )\n\n    if machine is None:\n        machine = Machine.get_default()\n\n    if command is None:\n        command = (\n            f\"cd {os.getcwd()} && \"\n            f\"export PYTHONPATH=$PYTHONPATH:{os.getcwd()} && \"\n            f\"export LIGHTNING_CLOUD_URL={_get_lightning_cloud_url()} && \"\n            f\"export LIGHTNING_CLOUD_PROJECT_ID={os.getenv('LIGHTNING_CLOUD_PROJECT_ID')} && \"\n            f\"export LIGHTNING_CLOUD_SPACE_ID={os.getenv('LIGHTNING_CLOUD_SPACE_ID')} && \"\n            f\"export LIGHTNING_CLUSTER_ID={os.getenv('LIGHTNING_CLUSTER_ID')} && \"\n            f\"export LIGHTNING_CLOUD_PROJECT_ID={os.getenv('LIGHTNING_CLOUD_PROJECT_ID')} && \"\n            f\"export LIGHTNING_CLOUD_SPACE_ID={os.getenv('LIGHTNING_CLOUD_SPACE_ID')} && \"\n            f\"export LIGHTNING_CLUSTER_ID={os.getenv('LIGHTNING_CLUSTER_ID')} && \"\n            f\"export LIGHTNING_CLOUD_PROJECT_ID={os.getenv('LIGHTNING_CLOUD_PROJECT_ID')} && \"\n            f\"export LIGHTNING_CLOUD_SPACE_ID={os."}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\n            \"The `lightning-sdk` is required to execute the operator remotely. Please install it with `pip install lightning-sdk`.\"\n        )\n\n    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\n            \"The `boto3` is required to execute the operator remotely. Please install it with `pip install boto3`.\"\n        )\n\n    if not machine:\n        machine = Machine()\n\n    if not command:\n        command = f\"cd {os.getcwd()} && export PYTHONPATH=$PYTHONPATH:. && python -m {name}\"\n\n    studio = Studio()\n\n    # Get the ids from env variables\n    cluster_id = os.getenv(\"LIGHTNING_CLUSTER_ID\", None)\n    project_id = os.getenv(\"LIGHTNING_CLOUD_PROJECT_ID\", None)\n    cloud_space_id = os.getenv(\"LIGHTNING_CLOUD_SPACE_ID\", None)\n\n    if cluster_id is None:\n        raise RuntimeError(\"The `cluster_id` couldn't be found from the environement variables.\")\n\n    if project_id is None:\n        raise RuntimeError(\"The `project_id` couldn't be found from the environement variables.\")\n\n    if cloud_space_id is None:\n        raise RuntimeError(\"The `cloud_space_id` couldn't be found from the environement variables.\")\n\n    # Get the cluster\n    clusters = studio.list_clusters(project_id=project_id)\n\n    cluster = [c for c in clusters if c.id == cluster_id]\n\n    if not cluster:\n        raise RuntimeError(f\"We didn't find any matching cluster associated with the id {cluster_id}.\")\n\n    # Get the cloudspace\n    cloudspaces = studio.list_cloud_spaces(project_id=project_id, cluster_id=cluster_id)\n\n    cloudspace = [cs for cs"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\n            \"The `lightning-sdk` package is not available. Please install it first with `pip install lightning-sdk`.\"\n        )\n\n    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\n            \"The `boto3` package is not available. Please install it first with `pip install boto3`.\"\n        )\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()}; export PYTHONPATH=$PYTHONPATH:{os.getcwd()}; python -u -m {sys.argv[0]}\"\n\n    client = LightningClient(max_tries=2)\n\n    # Get the ids from env variables\n    cluster_id = os.getenv(\"LIGHTNING_CLUSTER_ID\", None)\n    project_id = os.getenv(\"LIGHTNING_CLOUD_PROJECT_ID\", None)\n    cloud_space_id = os.getenv(\"LIGHTNING_CLOUD_SPACE_ID\", None)\n\n    if cluster_id is None:\n        raise RuntimeError(\"The `cluster_id` couldn't be found from the environement variables.\")\n\n    if project_id is None:\n        raise RuntimeError(\"The `project_id` couldn't be found from the environement variables.\")\n\n    if cloud_space_id is None:\n        raise RuntimeError(\"The `cloud_space_id` couldn't be found from the environement variables.\")\n\n    clusters = client.cluster_service_list_project_clusters(project_id).clusters\n\n    target_cluster = [cluster for cluster in clusters if cluster.id == cluster_id]\n\n    if not target_cluster:\n        raise ValueError(f\"We didn't find any matching cluster associated with the id {cluster_id}.\")\n\n    target_machine = machine.to_dict()\n\n    target_machine[\"cluster_id\"] = target_cluster["}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise ImportError(\n            \"The `lightning_sdk` is not available. Please install it using `pip install lightning-sdk`.\"\n        )\n\n    if not _BOTO3_AVAILABLE:\n        raise ImportError(\n            \"The `boto3` is not available. Please install it using `pip install boto3`.\"\n        )\n\n    if not isinstance(name, str):\n        raise ValueError(f\"The `name` must be a string, got: {name}\")\n\n    if not isinstance(num_nodes, int):\n        raise ValueError(f\"The `num_nodes` must be an integer, got: {num_nodes}\")\n\n    if num_nodes < 1:\n        raise ValueError(f\"The `num_nodes` must be greater than 0, got: {num_nodes}\")\n\n    if machine is not None and not isinstance(machine, Machine):\n        raise ValueError(f\"The `machine` must be a `Machine` object, got: {machine}\")\n\n    if command is not None and not isinstance(command, str):\n        raise ValueError(f\"The `command` must be a string, got: {command}\")\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && export PYTHONPATH=. && export PATH=$PATH:. && export LIGHTNING_CLOUD_URL={_get_lightning_cloud_url()} && export LIGHTNING_CLOUD_PROJECT_ID={os.getenv('LIGHTNING_CLOUD_PROJECT_ID')} && export LIGHTNING_CLOUD_SPACE_ID={os.getenv('LIGHTNING_CLOUD_SPACE_ID')} && export LIGHTNING_CLUSTER_ID={os.getenv('LIGHTNING_CLUSTER_ID')} && export LIGHTNING_CLOUD_DATASET_ID={os.getenv('LIGHTNING_CLOUD_DATASET_ID')"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\n            \"The Lightning SDK is not available. Please install the SDK by running `pip install lightning-sdk`.\"\n        )\n\n    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\n            \"The boto3 library is not available. Please install the library by running `pip install boto3`.\"\n        )\n\n    if machine is None:\n        machine = Machine.default()\n\n    if command is None:\n        command = f\"cd {os.getcwd()}; export PYTHONPATH=$(pwd); python -u {sys.argv[0]} {' '.join(sys.argv[1:])}\"\n\n    studio = Studio()\n    studio.create_job(name=name, machine=machine, num_nodes=num_nodes, command=command)\n\n    while True:\n        job = studio.get_job(name=name)\n        if job.status == \"running\":\n            print(f\"Job URL: {job.url}\")\n            break\n        sleep(10)"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\n            \"The `lightning-sdk` couldn't be imported. Please install the `lightning-sdk` from https://pypi.org/project/lightning-sdk/.\"\n        )\n\n    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\n            \"The `boto3` couldn't be imported. Please install the `boto3` from https://pypi.org/project/boto3/.\"\n        )\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()}; export LIGHTNING_CLOUD_URL={_get_lightning_cloud_url()}; export LIGHTNING_CLOUD_PROJECT_ID={os.getenv('LIGHTNING_CLOUD_PROJECT_ID')}; export LIGHTNING_CLOUD_SPACE_ID={os.getenv('LIGHTNING_CLOUD_SPACE_ID')}; export LIGHTNING_CLUSTER_ID={os.getenv('LIGHTNING_CLUSTER_ID')}; export LIGHTNING_CLOUD_DATASET_ID={os.getenv('LIGHTNING_CLOUD_DATASET_ID')}; export LIGHTNING_CLOUD_DATASET_VERSION={os.getenv('LIGHTNING_CLOUD_DATASET_VERSION')}; export LIGHTNING_CLOUD_DATASET_REVISION={os.getenv('LIGHTNING_CLOUD_DATASET_REVISION')}; {sys.executable} -m lightning_cloud.operator_executor\"\n\n    if os.getenv(\"LIGHTNING_CLOUD_PROJECT_ID\") is None:\n        raise RuntimeError(\"The `LIGHTNING_CLOUD_PROJECT_ID` couldn't be found from the environement variables.\")\n\n    if os.getenv(\""}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\n            \"The Lightning SDK is required to execute this operator. Please install the SDK by running `pip install lightning-sdk`.\"\n        )\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = (\n            \"cd ${{WORKING_DIR}} && \"\n            + \"export WORKING_DIR=${{WORKING_DIR}} && \"\n            + \"export LIGHTNING_CLOUD_PROJECT_ID=${{LIGHTNING_CLOUD_PROJECT_ID}} && \"\n            + \"export LIGHTNING_CLOUD_SPACE_ID=${{LIGHTNING_CLOUD_SPACE_ID}} && \"\n            + \"export LIGHTNING_CLOUD_SPACE_NAME=${{LIGHTNING_CLOUD_SPACE_NAME}} && \"\n            + \"export LIGHTNING_CLUSTER_ID=${{LIGHTNING_CLUSTER_ID}} && \"\n            + \"export LIGHTNING_CLUSTER_NAME=${{LIGHTNING_CLUSTER_NAME}} && \"\n            + \"export LIGHTNING_CLOUD_PROJECT_NAME=${{LIGHTNING_CLOUD_PROJECT_NAME}} && \"\n            + \"export LIGHTNING_CLOUD_SPACE_URL=${{LIGHTNING_CLOUD_SPACE_URL}} && \"\n            + \"export LIGHTNING_CLUSTER_URL=${{LIGHTNING_CLUSTER_URL}} && \"\n            + \"export LIGHTNING_CLOUD_SPACE_NAME=${{LIGHTNING_CLOUD_SPACE_NAME}} && \"\n            + \"export LIGHTNING_CLOUD_SPACE_URL=${{LIGHTNING_CLOUD_SPACE_URL}} && \"\n            + \"export LIGHTNING_CLOUD_SPACE_ID=${{LIGHTNING_CLOUD_"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\n            \"The `lightning-sdk` couldn't be imported. Please make sure that the `lightning-sdk` is installed and available in your current environment.\"\n        )\n\n    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\n            \"The `boto3` couldn't be imported. Please make sure that the `boto3` is installed and available in your current environment.\"\n        )\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()}; export PYTHONPATH={os.getcwd()}:$PYTHONPATH; {sys.executable} -m {name}\"\n\n    client = Studio()\n\n    client.create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command,\n    )\n\n    job_url = f\"{_get_lightning_cloud_url()}/studio/jobs/{client.job_id}\"\n\n    print(f\"Job URL: {job_url}\")\n\n    while True:\n        sleep(10)\n        job = client.get_job()\n        if job.status == \"running\":\n            break\n        if job.status == \"failed\":\n            raise RuntimeError(f\"The job failed with the following error: {job.error}\")\n\n    print(f\"Job URL: {job_url}\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\n            \"The `lightning-sdk` is not installed. Please install it with `pip install lightning-sdk`.\"\n        )\n\n    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\n            \"The `boto3` is not installed. Please install it with `pip install boto3`.\"\n        )\n\n    if not machine:\n        machine = Machine(\n            type=\"g4dn.xlarge\",\n            disk_size_gb=30,\n            min_vcpus=1,\n            max_vcpus=1,\n            min_gpus=0,\n            max_gpus=0,\n        )\n\n    if not command:\n        command = f\"cd {os.getcwd()}; export CUDA_VISIBLE_DEVICES=0; export LIGHTNING_CLOUD_URL={_get_lightning_cloud_url()}; export LIGHTNING_CLOUD_PROJECT_ID={os.getenv('LIGHTNING_CLOUD_PROJECT_ID', None)}; export LIGHTNING_CLUSTER_ID={os.getenv('LIGHTNING_CLUSTER_ID', None)}; export LIGHTNING_CLOUD_SPACE_ID={os.getenv('LIGHTNING_CLOUD_SPACE_ID', None)}; export LIGHTNING_CLOUD_SPACE_NAME={os.getenv('LIGHTNING_CLOUD_SPACE_NAME', None)}; export LIGHTNING_CLOUD_DATASET_ID={os.getenv('LIGHTNING_CLOUD_DATASET_ID', None)}; export LIGHTNING_CLOUD_DATASET_NAME={os.getenv('LIGHTNING_CLOUD_DATASET_NAME', None)}; python -m lightning_cloud.lightning_operator {sys.argv[0]} {' '.join(sys.argv[1:])}\"\n\n   "}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The `lightning-sdk` is not installed. Please install it with `pip install lightning-sdk`.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()}; \" + \" \".join(sys.argv)\n\n    # Create a new job\n    studio = Studio()\n    job = studio.create_job(name, num_nodes, machine, command)\n\n    # Wait for the job to start\n    while job.status == \"PENDING\":\n        sleep(1)\n        job = studio.get_job(job.id)\n\n    # Print the job URL\n    print(f\"Job started: {job.url}\")\n\n    # Wait for the job to finish\n    while job.status == \"RUNNING\":\n        sleep(1)\n        job = studio.get_job(job.id)\n\n    # Raise an exception if the job failed\n    if job.status == \"FAILED\":\n        raise RuntimeError(f\"Job failed: {job.url}\")\n\n"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\n            \"The `lightning-sdk` is not available. Please install it from PyPi (https://pypi.org/project/lightning-sdk/) or install the `lightning-sdk` from source.\"\n        )\n\n    if not machine:\n        machine = Machine()\n\n    if not command:\n        command = f\"cd {os.getcwd()}; export PYTHONPATH=$(pwd); python -m {name}\"\n\n    studio = Studio(url=_get_lightning_cloud_url())\n\n    # Get the ids from env variables\n    project_id = os.getenv(\"LIGHTNING_CLOUD_PROJECT_ID\", None)\n    cluster_id = os.getenv(\"LIGHTNING_CLUSTER_ID\", None)\n    cloudspace_id = os.getenv(\"LIGHTNING_CLOUD_SPACE_ID\", None)\n\n    if project_id is None:\n        raise RuntimeError(\"The `project_id` couldn't be found from the environement variables.\")\n\n    if cluster_id is None:\n        raise RuntimeError(\"The `cluster_id` couldn't be found from the environement variables.\")\n\n    if cloudspace_id is None:\n        raise RuntimeError(\"The `cloudspace_id` couldn't be found from the environement variables.\")\n\n    job = studio.jobs_create(\n        project_id=project_id,\n        cluster_id=cluster_id,\n        cloudspace_id=cloudspace_id,\n        name=name,\n        machine=machine,\n        command=command,\n        num_nodes=num_nodes,\n    )\n\n    print(f\"Job URL: {job.url}\")\n\n    while True:\n        job = studio.jobs_get(project_id=project_id, job_id=job.id)\n        if job.status in [\"failed\", \"success\"]:\n            break\n        sleep(10)\n\n    if job.status == \"failed\":\n        raise Runtime"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\n            \"The `lightning-sdk` is not available. Please install it with `pip install lightning-sdk`.\"\n        )\n\n    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\n            \"The `boto3` library is not available. Please install it with `pip install boto3`.\"\n        )\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()}; export LIGHTNING_CLOUD_URL={_get_lightning_cloud_url()}; export LIGHTNING_CLUSTER_ID={os.getenv('LIGHTNING_CLUSTER_ID', '')}; export LIGHTNING_CLOUD_PROJECT_ID={os.getenv('LIGHTNING_CLOUD_PROJECT_ID', '')}; export LIGHTNING_CLOUD_SPACE_ID={os.getenv('LIGHTNING_CLOUD_SPACE_ID', '')}; {sys.executable} -m lightning_cloud.lightning_operator {name}\"\n\n    studio = Studio()\n    studio.login()\n\n    job = studio.create_job(name, machine, num_nodes, command)\n\n    print(f\"Job URL: {job.url}\")\n\n    while job.status == \"pending\":\n        sleep(1)\n        job.refresh()\n\n    if job.status != \"success\":\n        raise RuntimeError(f\"Job failed with status: {job.status}.\")\n\n"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The `lightning-sdk` is not available. Please install it.\")\n\n    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\"The `boto3` library is not available. Please install it.\")\n\n    if machine is None:\n        machine = Machine.get_default()\n\n    if command is None:\n        command = \"cd {working_dir} && env > environment.txt && source activate {conda_env_name} && python -u {entrypoint}\"\n\n    # Get the ids from env variables\n    cluster_id = os.getenv(\"LIGHTNING_CLUSTER_ID\", None)\n    project_id = os.getenv(\"LIGHTNING_CLOUD_PROJECT_ID\", None)\n\n    if cluster_id is None:\n        raise RuntimeError(\"The `cluster_id` couldn't be found from the environement variables.\")\n\n    if project_id is None:\n        raise RuntimeError(\"The `project_id` couldn't be found from the environement variables.\")\n\n    # Get the client\n    client = LightningClient(max_tries=2)\n\n    # Get the cluster\n    clusters = client.cluster_service_list_project_clusters(project_id).clusters\n    target_cluster = [cluster for cluster in clusters if cluster.id == cluster_id]\n\n    if not target_cluster:\n        raise ValueError(f\"We didn't find a matching cluster associated with the id {cluster_id}.\" \" HINT: Did you create the cluster?\")\n\n    # Get the machine\n    machines = client.machine_service_list_project_machines(project_id, cluster_id).machines\n    target_machine = [machine for machine in machines if machine.name == machine.name]\n\n    if not target_machine:\n        raise ValueError(f\"We didn't find a matching machine associated with the name {machine.name}.\")\n\n    # Get the studio\n    studios = client.studio_service_list_project"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\n            \"The `lightning-sdk` package is required to execute this operator remotely. Please install it using `pip install lightning-sdk`.\"\n        )\n\n    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\n            \"The `boto3` package is required to execute this operator remotely. Please install it using `pip install boto3`.\"\n        )\n\n    if not machine:\n        machine = Machine()\n\n    if not command:\n        command = f\"cd {os.getcwd()};\"\n        for env_var in os.environ:\n            command += f\" export {env_var}={os.environ[env_var]};\"\n\n        command += f\" python {sys.argv[0]}\"\n\n    studio = Studio(\n        url=_get_lightning_cloud_url(),\n        token=os.getenv(\"LIGHTNING_CLOUD_TOKEN\"),\n    )\n\n    job = studio.create_job(\n        name=name,\n        machine=machine,\n        num_nodes=num_nodes,\n        command=command,\n    )\n\n    print(f\"Job URL: {job.url}\")\n\n    while job.status not in [\"done\", \"failed\"]:\n        job = studio.get_job(job.id)\n        sleep(5)\n\n    if job.status == \"failed\":\n        raise RuntimeError(f\"The job failed with the following error: {job.error}\")\n\n"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\n            \"The SDK is not available. Please make sure to install the SDK using the following command: `pip install lightning-sdk`.\"\n        )\n\n    if not machine:\n        machine = Machine()\n\n    if not command:\n        command = f\"cd {os.getcwd()} && env > environment.txt && source environment.txt && {sys.executable} -m lightning_cloud.operator {name} {num_nodes} {machine.name} {machine.gpu_type} {machine.gpu_count} {machine.cpu_count} {machine.memory_size} {machine.instance_type} {machine.volume_size} {machine.volume_type} {machine.volume_iops} {machine.volume_throughput} {machine.volume_count} {machine.volume_type_iops} {machine.volume_type_throughput} {machine.volume_type_size} {machine.volume_type_iops} {machine.volume_type_throughput} {machine.volume_type_size}\"\n\n    studio = Studio()\n    studio.login()\n\n    try:\n        job = studio.create_job(name, num_nodes, machine, command)\n    except Exception as e:\n        raise RuntimeError(f\"Failed to create job: {e}\")\n\n    if not job:\n        raise RuntimeError(\"Failed to create job.\")\n\n    print(f\"Job created: {job.url}\")\n\n    while job.status == \"pending\":\n        sleep(1)\n        job = studio.get_job(job.id)\n\n    if job.status == \"running\":\n        print(f\"Job started: {job.url}\")\n\n    while job.status == \"running\":\n        sleep(1)\n        job = studio.get_job(job.id)\n\n    if job.status == \"failed\":\n        raise RuntimeError(f\"Job failed: {job.url}\")\n\n    print(f\"Job finished: {job.url}\")\n\n"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\n            \"The `lightning-sdk` is required to execute the current operator. Please install the `lightning-sdk` or use the `local` execution mode.\"\n        )\n\n    if not machine:\n        machine = Machine()\n\n    if not command:\n        command = f\"cd {os.getcwd()}; {sys.executable} -m lightning_cloud.run_operator\"\n\n    studio = Studio()\n    studio.execute_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command,\n    )\n\n    job_url = studio.get_job_url()\n    print(f\"Job started: {job_url}\")\n    print(\"Waiting for job to complete...\")\n    while True:\n        job = studio.get_job()\n        if job.status in [\"failed\", \"completed\"]:\n            break\n        sleep(10)\n    if job.status == \"failed\":\n        raise RuntimeError(f\"The job failed: {job_url}\")\n    print(f\"Job completed: {job_url}\")\n\n"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install it with `pip install lightning-sdk`.\")\n\n    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\"The boto3 library is not available. Please install it with `pip install boto3`.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()}; export PYTHONPATH=$(pwd); python -m {name}\"\n\n    studio = Studio()\n    studio.connect(url=_get_lightning_cloud_url())\n\n    # Check if the current user has access to the studio\n    if not studio.is_connected():\n        raise RuntimeError(\"The current user is not connected to the studio. Please login with `studio.login()`.\")\n\n    # Check if the current user has access to the studio\n    if not studio.is_connected():\n        raise RuntimeError(\"The current user is not connected to the studio. Please login with `studio.login()`.\")\n\n    # Create a new job\n    job = studio.create_job(name=name, num_nodes=num_nodes, machine=machine, command=command)\n\n    # Wait until the job is running\n    while job.status == \"pending\":\n        sleep(1)\n        job.refresh()\n\n    if job.status == \"running\":\n        print(f\"Job {job.id} is running. You can follow the progress at {job.url}\")\n    elif job.status == \"error\":\n        raise RuntimeError(f\"Job {job.id} failed. Please check the logs at {job.url}\")\n    elif job.status == \"finished\":\n        print(f\"Job {job.id} finished successfully.\")\n    else:\n        raise RuntimeError(f\"Job {job.id} has an unknown status: {job.status}.\")\n\n"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\n            \"The `lightning-sdk` is not available. Please install the `lightning-sdk` by running `pip install lightning-sdk`.\"\n        )\n\n    if not machine:\n        machine = Machine()\n\n    if not command:\n        command = f\"cd {os.getcwd()}; export PYTHONPATH=$(pwd); {sys.executable} -m lightning_cloud.operator {name} --num-nodes {num_nodes} --machine {machine.name} --machine-type {machine.type}\"\n\n    studio = Studio()\n\n    job = studio.create_job(\n        name=name,\n        command=command,\n        num_nodes=num_nodes,\n        machine=machine,\n        wait_for_completion=False,\n    )\n\n    job_url = f\"{_get_lightning_cloud_url()}/studio/jobs/{job.id}\"\n\n    print(f\"Executing the operator `{name}` remotely on a machine with {num_nodes} nodes...\")\n    print(f\"Job URL: {job_url}\")\n\n    while True:\n        job = studio.get_job(job.id)\n        if job.status == \"running\":\n            break\n        if job.status == \"error\":\n            raise RuntimeError(f\"The job failed with the following error message: {job.error}\")\n        sleep(1)\n\n    print(f\"Job URL: {job_url}\")\n\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Load the config containing the index\n        try:\n            self._config = ChunksConfig(\n                cache_dir=self._cache_dir,\n                serializers=self._serializers,\n                remote_input_dir=self._remote_input_dir,\n                compression=self._compression,\n                item_loader=self._item_loader,\n            )\n        except FileNotFoundError:\n            return None\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Load the config\n        try:\n            self._config = ChunksConfig(\n                cache_dir=self._cache_dir,\n                serializers=self._serializers,\n                remote_input_dir=self._remote_input_dir,\n                compression=self._compression,\n                item_loader=self._item_loader,\n            )\n        except Exception as e:\n            logger.warning(f\"Couldn't load the config: {e}\")\n            return None\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        try:\n            self._config = ChunksConfig(\n                self._cache_dir,\n                self._serializers,\n                self._remote_input_dir,\n                self._compression,\n                self._item_loader,\n                self._max_cache_size,\n            )\n        except Exception:\n            return None\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        try:\n            self._config = ChunksConfig(\n                cache_dir=self._cache_dir,\n                remote_input_dir=self._remote_input_dir,\n                compression=self._compression,\n                serializers=self._serializers,\n                distributed_env=self._distributed_env,\n            )\n        except FileNotFoundError:\n            return None\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Load the config\n        try:\n            self._config = ChunksConfig(\n                cache_dir=self._cache_dir,\n                serializers=self._serializers,\n                remote_input_dir=self._remote_input_dir,\n                compression=self._compression,\n                item_loader=self._item_loader,\n            )\n        except Exception as e:\n            logger.error(f\"Error while loading the config: {e}\")\n            return None\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        try:\n            # Load the config\n            self._config = ChunksConfig(\n                self._cache_dir,\n                self._remote_input_dir,\n                self._serializers,\n                self._compression,\n                self._item_loader,\n            )\n        except Exception as e:\n            logger.warning(f\"Cannot load the configuration. {e}\")\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Check if the config file exists\n        config_filepath = os.path.join(self._cache_dir, \"config.json\")\n        if not os.path.exists(config_filepath):\n            return None\n\n        # Load the config file\n        self._config = ChunksConfig.load(config_filepath)\n\n        # Update the serializers\n        self._serializers.update(self._config.serializers)\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Load the config\n        config = ChunksConfig(\n            self._cache_dir,\n            self._remote_input_dir,\n            self._compression,\n            self._serializers,\n            self._item_loader,\n            self._rank,\n        )\n\n        if config.load():\n            self._config = config\n            return config\n\n        return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Create the chunks configuration\n        self._config = ChunksConfig(\n            cache_dir=self._cache_dir,\n            serializers=self._serializers,\n            remote_input_dir=self._remote_input_dir,\n            compression=self._compression,\n            item_loader=self._item_loader,\n        )\n\n        # Load the configuration\n        self._config.load_config()\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # If the config is already loaded, just return it\n        if self._config is not None:\n            return self._config\n\n        # Try to load the config\n        self._config = ChunksConfig(\n            self._cache_dir,\n            self._remote_input_dir,\n            self._serializers,\n            self._compression,\n            self._item_loader,\n            self._max_cache_size,\n        )\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Load the config\n        try:\n            self._config = ChunksConfig(\n                cache_dir=self._cache_dir,\n                serializers=self._serializers,\n                remote_input_dir=self._remote_input_dir,\n                compression=self._compression,\n                item_loader=self._item_loader,\n            )\n            return self._config\n        except Exception as e:\n            logger.warning(f\"Cannot load the configuration: {e}\")\n            return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Attempt to load the configuration\n        try:\n            # Load the configuration\n            self._config = ChunksConfig(\n                cache_dir=self._cache_dir,\n                serializers=self._serializers,\n                remote_input_dir=self._remote_input_dir,\n                compression=self._compression,\n                item_loader=self._item_loader,\n            )\n            return self._config\n        except Exception as e:\n            logger.info(f\"Failed to load the configuration: {e}\")\n            return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        if self._config is not None:\n            return self._config\n\n        # Check whether the index files are available\n        index_files = [os.path.join(self._cache_dir, f\"{self._rank}.{self._intervals[0]}.index\")]\n        if self._remote_input_dir:\n            index_files = [f\"{self._remote_input_dir}/{f}\" for f in index_files]\n\n        if not all(os.path.exists(f) for f in index_files):\n            return None\n\n        # Load the configuration\n        self._config = ChunksConfig(\n            cache_dir=self._cache_dir,\n            remote_input_dir=self._remote_input_dir,\n            serializers=self._serializers,\n            compression=self._compression,\n            intervals=self._intervals,\n            item_loader=self._item_loader,\n        )\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Try to load the config\n        self._config = ChunksConfig(\n            cache_dir=self._cache_dir,\n            serializers=self._serializers,\n            remote_input_dir=self._remote_input_dir,\n            compression=self._compression,\n            item_loader=self._item_loader,\n        )\n\n        # If the config is not loaded, then return None\n        if not self._config.is_loaded:\n            return None\n\n        # Otherwise, return the config\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Check if the config file exists\n        config_path = os.path.join(self._cache_dir, \"config.json\")\n        if not os.path.exists(config_path):\n            return None\n\n        # Load the config\n        self._config = ChunksConfig(config_path, self._serializers, self._remote_input_dir, self._compression)\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Try to load the config\n        config = ChunksConfig(\n            cache_dir=self._cache_dir,\n            remote_input_dir=self._remote_input_dir,\n            compression=self._compression,\n            serializers=self._serializers,\n            item_loader=self._item_loader,\n        )\n        if config.load():\n            self._config = config\n            return config\n\n        return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # If the config file is already loaded, return it\n        if self._config is not None:\n            return self._config\n\n        # Check if the config file is already cached\n        config_path = os.path.join(self._cache_dir, \"config.json\")\n        if os.path.exists(config_path):\n            self._config = ChunksConfig.from_json(config_path)\n            return self._config\n\n        # Otherwise, try to download it\n        if self._remote_input_dir is not None:\n            config_path = os.path.join(self._remote_input_dir, \"config.json\")\n            if os.path.exists(config_path):\n                self._config = ChunksConfig.from_json(config_path)\n                return self._config\n\n        return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # If the config is already loaded, then there's nothing to do.\n        if self._config is not None:\n            return self._config\n\n        # If the config is not loaded, then we need to try to load it.\n        try:\n            self._config = ChunksConfig(\n                self._cache_dir,\n                self._remote_input_dir,\n                self._serializers,\n                self._item_loader,\n                self._compression,\n            )\n            return self._config\n        except Exception as e:\n            logger.warning(f\"Could not load config: {e}\")\n            return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # If the config file doesn't exist, we don't have to do anything.\n        config_path = os.path.join(self._cache_dir, \"config.json\")\n        if not os.path.exists(config_path):\n            return None\n\n        # If the config file exists, we can load it.\n        config = ChunksConfig(\n            cache_dir=self._cache_dir,\n            serializers=self._serializers,\n            remote_input_dir=self._remote_input_dir,\n            compression=self._compression,\n        )\n        config.load(config_path)\n\n        # If the config is empty, we don't have to do anything.\n        if config.empty():\n            return None\n\n        # If the config is not empty, we can update the reader's attributes.\n        self._config = config\n        self._intervals = config.intervals\n\n        return config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Check whether the config file exists\n        config_filepath = os.path.join(self._cache_dir, \"config.json\")\n        if not os.path.exists(config_filepath):\n            return None\n\n        # Load the config file\n        self._config = ChunksConfig.from_file(config_filepath, self._serializers)\n        self._config.compression = self._compression\n        self._config.remote_input_dir = self._remote_input_dir\n        self._config.cache_dir = self._cache_dir\n\n        # Check whether the config is compatible with the current environment\n        if self._config.num_workers != self._distributed_env.num_workers:\n            raise ValueError(\n                f\"The number of workers in the config file ({self._config.num_workers}) doesn't match the current number of workers ({self._distributed_env.num_workers}).\"\n            )\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        self._to_download_queue.put(chunk_indexes)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        self._to_download_queue.put(chunk_indexes)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        # Enqueue the chunk indexes to be downloaded\n        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        self._to_download_queue.put(chunk_indexes)\n\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        self._to_download_queue.put(chunk_indexes)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        # Enqueue the chunk indexes to be downloaded\n        self._to_download_queue.put(chunk_indexes)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration should be defined before accessing it.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration is not set.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The reader config isn't defined.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration should be defined before accessing it.\")\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None and self._try_load_config() is None:\n            raise RuntimeError(\"The reader configuration isn't defined.\")\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The reader configuration isn't defined.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\n                \"The configuration of the BinaryReader instance is not set. Please set the configuration before using it.\"\n            )\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None and self._try_load_config() is None:\n            raise RuntimeError(\"The configuration of the reader is not set.\")\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None and self._try_load_config() is None:\n            raise RuntimeError(\"The reader config isn't defined.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration is not set.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None and self._try_load_config() is None:\n            raise RuntimeError(\"The reader configuration isn't defined.\")\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The reader config isn't defined.\")\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration is not set.\")\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None and self._try_load_config() is None:\n            raise RuntimeError(\"The reader configuration isn't defined.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration is not set.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration is not set.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration is not set.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration is not set.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None and self._try_load_config() is None:\n            raise RuntimeError(\"The reader config isn't defined.\")\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration is not set.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index is not an instance of ChunkedIndex.\")\n\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread is not defined.\")\n\n        if index.chunk_index != self._last_chunk_index:\n            self._last_chunk_index = index.chunk_index\n            self._prepare_thread.download([index.chunk_index])\n\n        return self._item_loader.read(index)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index is not an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Get the chunk index\n        chunk_index = self._get_chunk_index_from_index(index.index)\n\n        if chunk_index != self._last_chunk_index:\n            # Get the chunk filepath\n            chunk_filepath, _, _ = self._config[ChunkedIndex(index=-1, chunk_index=chunk_index)]\n\n            # Load the chunk\n            self._item_loader.load(chunk_index, chunk_filepath)\n            self._last_chunk_index = chunk_index\n\n        # Get the item\n        return self._item_loader.get_item(index)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index is not a ChunkedIndex.\")\n\n        # Load the config containing the index\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Get the chunk index\n        chunk_index = index.chunk_index\n\n        # Get the chunk filepath\n        chunk_filepath, _, _ = self.config[index]\n\n        # Check if the chunk is available locally\n        if not os.path.exists(chunk_filepath):\n            raise FileNotFoundError(f\"The chunk `{chunk_filepath}` doesn't exist.\")\n\n        # Get the chunk\n        chunk = self._item_loader.get_chunk(chunk_index, chunk_filepath)\n\n        # Get the item\n        item = self._item_loader.get_item(index, chunk)\n\n        return item\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The index {index} is not an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread isn't defined.\")\n\n        chunk_index = index.chunk_index\n        if chunk_index != self._last_chunk_index:\n            self._last_chunk_index = chunk_index\n            self._config.load_chunk_from_index(chunk_index)\n            self._prepare_thread.download([chunk_index])\n\n        chunk_filepath, _, _ = self._config[index]\n        return self._item_loader.read(chunk_index, chunk_filepath, index.index)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The index `{index}` should be a ChunkedIndex.\")\n\n        # Load the config containing the index\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Ensure that the chunk is available\n        self._config.ensure_chunk_available(index.chunk_index)\n\n        # Load the item from the chunk\n        chunk_filepath, _, _ = self._config[index]\n        return self._item_loader.load_item_from_chunk(index.chunk_index, chunk_filepath, index.index_in_chunk)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index must be an instance of ChunkedIndex.\")\n\n        if self._config is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread isn't defined.\")\n\n        chunk_index = index.chunk_index\n        if chunk_index != self._last_chunk_index:\n            self._last_chunk_index = chunk_index\n            self._prepare_thread.download([chunk_index])\n\n        chunk_filepath, _, _ = self._config[index]\n        return self._item_loader.load_item(chunk_filepath, index.index)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index is not a ChunkedIndex.\")\n\n        if self._config is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread is not defined.\")\n\n        # Check whether the chunk is already loaded\n        if self._config.is_chunk_loaded(index.chunk_index):\n            return self._config.get_item(index)\n\n        # If not, load the chunk\n        self._config.download_chunk_from_index(index)\n\n        # Wait until the chunk is loaded\n        while not self._config.is_chunk_loaded(index.chunk_index):\n            pass\n\n        # Return the item\n        return self._config.get_item(index)\n\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index is not an instance of ChunkedIndex.\")\n\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread is not defined.\")\n\n        if self._config is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        if index.chunk_index > self._last_chunk_index:\n            raise ValueError(f\"The provided index is out of range: {index.chunk_index} > {self._last_chunk_index}\")\n\n        # If the chunk is not available, we need to download it\n        if not self.config.is_chunk_available(index.chunk_index):\n            self._prepare_thread.download([index.chunk_index])\n\n        # Wait for the chunk to be downloaded\n        while not self.config.is_chunk_available(index.chunk_index):\n            pass\n\n        # Load the chunk\n        chunk_filepath, _, _ = self.config[index]\n        chunk = self._item_loader.load_chunk(index.chunk_index, chunk_filepath)\n\n        # Load the item from the chunk\n        item = chunk[index.index]\n\n        # Delete the chunk if it is fully consumed\n        if self._delete_chunks_when_processed:\n            self._prepare_thread.delete([index.chunk_index])\n\n        return item\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index is not a ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        if self._prepare_thread is None or not self._prepare_thread.is_alive():\n            raise Exception(\"The prepare thread isn't running.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        chunk_filepath, _, _ = self._config[index]\n\n        if chunk_index != self._last_chunk_index:\n            # Wait for the chunk to be loaded\n            self._prepare_thread.download([chunk_index])\n\n            # Wait for the chunk to be pre-loaded\n            self._prepare_thread.download([chunk_index])\n\n            # Wait for the chunk to be deleted\n            self._prepare_thread.delete([chunk_index])\n\n        # Load the item\n        item = self._item_loader.load(index, chunk_filepath)\n\n        # Update the last chunk index\n        self._last_chunk_index = chunk_index\n\n        return item\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The provided index `{index}` is not an instance of `ChunkedIndex`.\")\n\n        if self._config is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread isn't defined.\")\n\n        # Get the chunk index\n        chunk_index = self._get_chunk_index_from_index(index.index)\n\n        # Get the chunk filepath\n        chunk_filepath, _, _ = self._config[index]\n\n        # Download the chunk if necessary\n        if not os.path.exists(chunk_filepath):\n            self._prepare_thread.download([chunk_index])\n\n        # Wait for the chunk to be downloaded\n        while not os.path.exists(chunk_filepath):\n            pass\n\n        # Read the chunk\n        with open(chunk_filepath, \"rb\") as f:\n            if self._compression:\n                f = self._serializers[\"compression\"].open(f)\n            return self._item_loader.read(f, index.chunk_index)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index is not an instance of ChunkedIndex.\")\n\n        # Load the config containing the index\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread is not defined.\")\n\n        # Get the chunk index\n        chunk_index = self._get_chunk_index_from_index(index.index)\n\n        if chunk_index != self._last_chunk_index:\n            # Download the chunk if not available\n            if not self.config.is_chunk_available(chunk_index):\n                self.config.download_chunk_from_index(chunk_index)\n\n            # Preload item if possible to gain some time but only\n            # if this is one of the pre-downloaded chunk\n            if self._prepare_thread._pre_download_counter > 0:\n                self._prepare_thread._pre_load_chunk(chunk_index)\n\n            self._last_chunk_index = chunk_index\n\n        # Load the item from the chunk\n        return self._item_loader.load(chunk_index, index.index)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index is not an instance of ChunkedIndex.\")\n\n        if self._config is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread isn't defined.\")\n\n        # Make sure the chunk is available\n        self._config.download_chunk_from_index(index)\n\n        # Get the chunk filepath\n        chunk_filepath, _, _ = self._config[index]\n\n        # Load the chunk\n        chunk = self._item_loader.load(index, chunk_filepath)\n\n        # Get the item from the chunk\n        item = self._item_loader.get_item_from_chunk(index, chunk)\n\n        return item\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The provided index is not a ChunkedIndex: {index}\")\n\n        if self._config is None:\n            raise Exception(\"The config should be defined.\")\n\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread should be defined.\")\n\n        # Get the chunk index\n        chunk_index = self._get_chunk_index_from_index(index.index)\n\n        # Load the chunk if needed\n        if chunk_index != self._last_chunk_index:\n            self._prepare_thread.download([chunk_index])\n            self._last_chunk_index = chunk_index\n\n        # Get the item\n        item = self._item_loader.get_item(chunk_index, index.item_index)\n\n        return item\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index is not a ChunkedIndex.\")\n\n        if self._config is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread isn't defined.\")\n\n        # Check whether the chunk is already available\n        if self._config.is_chunk_available(index):\n            return self._config.read_item(index)\n\n        # Check whether the chunk is already being downloaded\n        if self._config.is_chunk_being_downloaded(index):\n            return self._config.read_item(index)\n\n        # Check whether the chunk is being preloaded\n        if self._config.is_chunk_being_preloaded(index):\n            return self._config.read_item(index)\n\n        # Check whether the chunk is being deleted\n        if self._config.is_chunk_being_deleted(index):\n            return self._config.read_item(index)\n\n        # Check whether the chunk is already deleted\n        if self._config.is_chunk_deleted(index):\n            return self._config.read_item(index)\n\n        # Download the chunk if possible\n        if self._config.is_chunk_available_to_download(index):\n            self._config.download_chunk_from_index(index)\n\n            # Preload item if possible to gain some time but only\n            # if this is one of the pre-downloaded chunk\n            if self._prepare_thread._pre_download_counter > 0:\n                self._prepare_thread._pre_load_chunk(index.chunk_index)\n\n            # Avoid downloading too many chunks in advance at the risk of over using the disk space\n            self._prepare_thread._pre_download_counter += 1\n\n            # Wait for the chunk to be available\n            return self.read(index)\n\n        # Raise an exception if the chunk is not available\n        raise Exception(f\"The chunk {index} is not available.\")\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\n                \"The provided index is not an instance of `litdata.streaming.index.ChunkedIndex`.\"\n            )\n\n        # Load the config containing the index\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Get the chunk index from the index\n        chunk_index = self._get_chunk_index_from_index(index.index)\n\n        # If the chunk is not already in memory, download it\n        if chunk_index not in self._item_loader.chunks:\n            self._download_chunk(chunk_index)\n\n        # Get the item from the chunk\n        item = self._item_loader.get_item(chunk_index, index.item_index)\n\n        return item\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The provided index `{index}` isn't an instance of `ChunkedIndex`.\")\n\n        if self._config is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread isn't defined.\")\n\n        # If the chunk is not already loaded, download it\n        chunk_index = self._get_chunk_index_from_index(index)\n        chunk_filepath = self._config.get_chunk_filepath(chunk_index)\n        if not self._config.is_chunk_loaded(chunk_index):\n            self._prepare_thread.download([chunk_index])\n\n        # Wait for the chunk to be fully loaded\n        while not self._config.is_chunk_loaded(chunk_index):\n            pass\n\n        # Read the item from the chunk\n        item = self._item_loader.read(chunk_index, chunk_filepath)\n\n        # Check if the chunk is fully consumed\n        if self._item_loader.is_chunk_consumed(chunk_index, chunk_filepath):\n            # Delete the chunk\n            self._prepare_thread.delete([chunk_index])\n\n        return item\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index is not an instance of ChunkedIndex.\")\n\n        # Load the config containing the index\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Make sure the chunk is available locally\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        if chunk_index != self._last_chunk_index:\n            self._last_chunk_index = chunk_index\n            self._prepare_thread.download([chunk_index])\n\n        # Load the item\n        chunk_filepath, _, _ = self.config[index]\n        item = self._item_loader.load_item(index, chunk_filepath)\n\n        return item\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The provided index `{index}` is not an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread is not running.\")\n\n        if index.chunk_index > self._last_chunk_index:\n            raise Exception(f\"The provided index `{index}` is not valid.\")\n\n        # Check if the chunk is already loaded\n        if not self._item_loader.is_chunk_loaded(index.chunk_index):\n            # Download the chunk\n            self._config.download_chunk_from_index(index.chunk_index)\n\n            # Wait until the chunk is downloaded\n            self._prepare_thread.download([index.chunk_index])\n\n            # Preload item if possible to gain some time but only\n            # if this is one of the pre-downloaded chunk\n            if self._prepare_thread.max_pre_download > 0:\n                self._prepare_thread._pre_load_chunk(index.chunk_index)\n\n        # Check if the chunk is already loaded\n        if not self._item_loader.is_chunk_loaded(index.chunk_index):\n            # Download the chunk\n            self._config.download_chunk_from_index(index.chunk_index)\n\n            # Wait until the chunk is downloaded\n            self._prepare_thread.download([index.chunk_index])\n\n            # Preload item if possible to gain some time but only\n            # if this is one of the pre-downloaded chunk\n            if self._prepare_thread.max_pre_download > 0:\n                self._prepare_thread._pre_load_chunk(index.chunk_index)\n\n        # Get the item from the chunk\n        return self._item_loader.get_item_from_index(index)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The index {index} should be an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread should be defined.\")\n\n        chunk_index = index.chunk_index\n\n        # Get the chunk filepath\n        chunk_filepath, _, _ = self._config[index]\n\n        # If the chunk is not in the cache, we need to download it\n        if not self._item_loader.is_in_cache(chunk_index, chunk_filepath):\n            # If the chunk is not in the cache, we need to download it\n            if not self._item_loader.is_in_cache(chunk_index, chunk_filepath):\n                self._prepare_thread.download([chunk_index])\n\n            # Wait until the chunk is in the cache\n            while not self._item_loader.is_in_cache(chunk_index, chunk_filepath):\n                # Check if the chunk is in the cache\n                if self._item_loader.is_in_cache(chunk_index, chunk_filepath):\n                    break\n\n                # Wait for the prepare thread to finish\n                self._prepare_thread.join(timeout=_DEFAULT_TIMEOUT)\n\n        # Get the item from the chunk\n        item = self._item_loader.get(chunk_index, chunk_filepath, index.index)\n\n        # If the chunk is fully consumed, we can delete it\n        if self._config.is_chunk_fully_consumed(chunk_index):\n            self._prepare_thread.delete([chunk_index])\n\n        return item\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index is not an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        if self._prepare_thread is None or not self._prepare_thread.is_alive():\n            raise Exception(\"The prepare thread isn't alive.\")\n\n        # The chunk index is the same as the index provided by the user.\n        chunk_index = index.chunk_index\n\n        # Check if the chunk is already in the cache\n        if chunk_index in self._item_loader.cache:\n            return self._item_loader.cache[chunk_index]\n\n        # Check if the chunk is already in the memory\n        if chunk_index in self._item_loader.memory:\n            return self._item_loader.memory[chunk_index]\n\n        # Check if the chunk is already in the disk\n        if self._config.is_chunk_in_disk(chunk_index):\n            return self._item_loader.load_chunk(chunk_index)\n\n        # If the chunk isn't in the cache, memory or disk, we need to download it.\n        self._prepare_thread.download([chunk_index])\n\n        # Wait for the chunk to be downloaded\n        while not self._config.is_chunk_in_disk(chunk_index):\n            continue\n\n        return self._item_loader.load_chunk(chunk_index)\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is not None:\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    else:\n        return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is not None:\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    else:\n        return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is not None:\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    else:\n        return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if _is_distributed_environment():\n        return _get_distributed_map().set_and_get(key, obj)\n    else:\n        return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is not None:\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    else:\n        return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is not None:\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    else:\n        return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is not None:\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    else:\n        return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    # Check if we are in a distributed environment\n    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is None:\n        return obj\n\n    # Create a distributed map\n    distributed_map = _ImmutableDistributedMap()\n\n    # Set the object\n    obj = distributed_map.set_and_get(key, obj)\n\n    return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if _is_distributed():\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    else:\n        return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is None:\n        return obj\n\n    return _ImmutableDistributedMap().set_and_get(key, obj)\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is not None:\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    else:\n        return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is not None:\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    else:\n        return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if _is_distributed():\n        return _get_distributed_map().set_and_get(key, obj)\n    return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is not None:\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    else:\n        return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if not os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\"):\n        return obj\n    else:\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is not None:\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    else:\n        return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is None:\n        return obj\n\n    return _ImmutableDistributedMap().set_and_get(key, obj)\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    # Check if we are running in a distributed environment\n    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is None:\n        return obj\n\n    # Get the distributed map\n    map = _ImmutableDistributedMap()\n\n    # Set and get the object\n    return map.set_and_get(key, obj)\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if _is_distributed_environment():\n        # The distributed environment has a distributed map\n        # We can use that to share the object across machines\n        return _get_distributed_map().set_and_get(key, obj)\n\n    # Not in a distributed environment, just return the object\n    return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if not os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") or not os.getenv(\"LIGHTNING_APP_STATE_URL\"):\n        return obj\n\n    # We are in a distributed environment\n    # Broadcast the object\n    return _ImmutableDistributedMap().set_and_get(key, obj)\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Create a list of shuffled chunk indexes\n    shuffled_chunks = []\n    for rank in range(distributed_env.world_size):\n        np.random.seed(seed + current_epoch + rank)\n        shuffled_chunks.extend(np.random.permutation(chunks_per_ranks[rank]).tolist())\n\n    return shuffled_chunks\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Create a list of the total number of chunks per node\n    chunks_per_node = [len(chunks) for chunks in chunks_per_ranks]\n\n    # Create a list of the total number of chunks per rank\n    chunks_per_rank = [sum(chunks) for chunks in chunks_per_ranks]\n\n    # Create a list of the total number of chunks per node\n    chunks_per_node = [len(chunks) for chunks in chunks_per_ranks]\n\n    # Create a list of the total number of chunks per rank\n    chunks_per_rank = [sum(chunks) for chunks in chunks_per_ranks]\n\n    # Create a list of the total number of chunks per node\n    chunks_per_node = [len(chunks) for chunks in chunks_per_ranks]\n\n    # Create a list of the total number of chunks per rank\n    chunks_per_rank = [sum(chunks) for chunks in chunks_per_ranks]\n\n    # Create a list of the total number of chunks per node\n    chunks_per_node = [len(chunks) for chunks in chunks_per_ranks]\n\n    # Create a list of the total number of chunks per rank\n    chunks_per_rank = [sum(chunks) for chunks in chunks_per_ranks]\n\n    # Create a list of the total number of chunks per node\n    chunks_per_node = [len(chunks) for chunks in chunks_per_ranks]\n\n    # Create a list of the total number of chunks per rank\n    chunks_per_rank = [sum(chunks) for chunks in chunks_per_ranks]\n\n    # Create a list of the total number of chunks per node\n    chunks_per_node = [len(chunks) for chunks in chunks_per_ranks]\n\n    # Create a list of the total number of chunks per rank\n    chunks_per_rank = [sum"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Shuffle the chunks for each node\n    np.random.seed(seed + current_epoch)\n    shuffled_chunks = np.random.permutation(chunks_per_ranks)\n\n    # Flatten the shuffled chunks\n    shuffled_chunks = [chunk for sublist in shuffled_chunks for chunk in sublist]\n\n    return shuffled_chunks\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Get the number of chunks per node.\n    chunks_per_node = sum(chunks_per_ranks[distributed_env.rank])\n\n    # Get the number of chunks per rank.\n    chunks_per_rank = [sum(chunks_per_ranks[i]) for i in range(distributed_env.world_size)]\n\n    # Get the number of chunks per node.\n    chunks_per_rank = [sum(chunks_per_ranks[i]) for i in range(distributed_env.world_size)]\n\n    # Get the number of chunks per node.\n    chunks_per_node = sum(chunks_per_ranks[distributed_env.rank])\n\n    # Get the number of chunks per node.\n    chunks_per_node = sum(chunks_per_ranks[distributed_env.rank])\n\n    # Get the number of chunks per node.\n    chunks_per_node = sum(chunks_per_ranks[distributed_env.rank])\n\n    # Get the number of chunks per node.\n    chunks_per_node = sum(chunks_per_ranks[distributed_env.rank])\n\n    # Get the number of chunks per node.\n    chunks_per_node = sum(chunks_per_ranks[distributed_env.rank])\n\n    # Get the number of chunks per node.\n    chunks_per_node = sum(chunks_per_ranks[distributed_env.rank])\n\n    # Get the number of chunks per node.\n    chunks_per_node = sum(chunks_per_ranks[distributed_env.rank])\n\n    # Get the number of chunks per node.\n    chunks_per_node = sum(chunks_per_ranks[distributed_env.rank])\n\n    # Get the number of chunks per node.\n    chunks_per_node = sum(chunks_per_ranks[distributed_env.rank])\n\n    # Get the number of chunks per node"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # create a list of lists of chunk indexes for each rank\n    rank_chunks = []\n    for rank_chunks_per_rank in chunks_per_ranks:\n        rank_chunks.append(rank_chunks_per_rank)\n\n    # create a list of lists of chunk indexes for each rank\n    rank_chunks = []\n    for rank_chunks_per_rank in chunks_per_ranks:\n        rank_chunks.append(rank_chunks_per_rank)\n\n    # create a list of lists of chunk indexes for each rank\n    rank_chunks = []\n    for rank_chunks_per_rank in chunks_per_ranks:\n        rank_chunks.append(rank_chunks_per_rank)\n\n    # create a list of lists of chunk indexes for each rank\n    rank_chunks = []\n    for rank_chunks_per_rank in chunks_per_ranks:\n        rank_chunks.append(rank_chunks_per_rank)\n\n    # create a list of lists of chunk indexes for each rank\n    rank_chunks = []\n    for rank_chunks_per_rank in chunks_per_ranks:\n        rank_chunks.append(rank_chunks_per_rank)\n\n    # create a list of lists of chunk indexes for each rank\n    rank_chunks = []\n    for rank_chunks_per_rank in chunks_per_ranks:\n        rank_chunks.append(rank_chunks_per_rank)\n\n    # create a list of lists of chunk indexes for each rank\n    rank_chunks = []\n    for rank_chunks_per_rank in chunks_per_ranks:\n        rank_chunks.append(rank_chunks_per_rank)\n\n    # create a list of lists of chunk indexes for each rank\n    rank_chunks = []\n    for rank_chunks_per_rank in chunks_per_ranks:\n        rank_chunks.append(rank_chunks_per_rank)\n\n    # create a list of lists of chunk indexes"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # create a list of chunk indexes for each node\n    chunk_indexes_per_node = [chunk_indexes for rank_chunks in chunks_per_ranks for chunk_indexes in rank_chunks]\n\n    # shuffle the chunk indexes for each node\n    np.random.seed(seed + current_epoch)\n    np.random.shuffle(chunk_indexes_per_node)\n\n    # flatten the chunk indexes across all nodes\n    chunk_indexes_across_nodes = [chunk_indexes for node_chunks in chunk_indexes_per_node for chunk_indexes in node_chunks]\n\n    return chunk_indexes_across_nodes\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Get the number of chunks per node\n    num_chunks_per_rank = np.array([len(chunks) for chunks in chunks_per_ranks])\n\n    # Get the number of chunks per node\n    num_nodes = distributed_env.world_size\n\n    # Get the number of chunks per node\n    num_chunks_per_node = num_chunks_per_rank.sum()\n\n    # Get the number of chunks per node\n    num_chunks_per_rank_per_node = num_chunks_per_rank / num_nodes\n\n    # Get the number of chunks per node\n    num_chunks_per_rank_per_node_int = num_chunks_per_rank_per_node.astype(int)\n\n    # Get the number of chunks per node\n    num_chunks_per_rank_remainder = num_chunks_per_rank - (num_chunks_per_rank_per_node_int * num_nodes)\n\n    # Get the number of chunks per node\n    num_chunks_per_rank_remainder_cumsum = np.cumsum(num_chunks_per_rank_remainder)\n\n    # Get the number of chunks per node\n    num_chunks_per_rank_remainder_cumsum_int = num_chunks_per_rank_remainder_cumsum.astype(int)\n\n    # Get the number of chunks per node\n    num_chunks_per_rank_remainder_cumsum_int_mod = num_chunks_per_rank_remainder_cumsum_int % num_nodes\n\n    # Get the number of chunks per node\n    num_chunks_per_rank_remainder_cumsum_int_mod_mask = num_chunks_per_rank_remainder_cumsum_int_mod == distributed_env.rank\n\n    # Get the number of chunks per node\n    num_chunks_per_rank_remainder_cumsum"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Initialize the random seed\n    np.random.seed(seed + current_epoch)\n\n    # Shuffle the chunks of data assigned to each node\n    shuffled_chunks_per_ranks = [np.random.permutation(chunks_per_ranks[rank]) for rank in range(distributed_env.world_size)]\n\n    # Flatten the list of shuffled chunks across all nodes\n    shuffled_chunks = [chunk for sublist in shuffled_chunks_per_ranks for chunk in sublist]\n\n    return shuffled_chunks\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # get the number of ranks and the current rank\n    num_ranks = distributed_env.world_size\n    current_rank = distributed_env.rank\n\n    # get the number of chunks assigned to the current rank\n    num_chunks_per_rank = len(chunks_per_ranks[current_rank])\n\n    # get the number of chunks assigned to each rank\n    num_chunks_per_rank = np.array([len(chunks_per_ranks[i]) for i in range(num_ranks)])\n\n    # get the number of chunks assigned to each node\n    num_chunks_per_node = num_chunks_per_rank[np.arange(num_ranks) % num_ranks == current_rank]\n\n    # get the number of chunks assigned to each node\n    num_chunks_per_node = np.array([len(chunks_per_ranks[i]) for i in range(num_ranks)])\n\n    # get the number of chunks assigned to each node\n    num_chunks_per_node = np.array([len(chunks_per_ranks[i]) for i in range(num_ranks)])\n\n    # get the number of chunks assigned to each node\n    num_chunks_per_node = np.array([len(chunks_per_ranks[i]) for i in range(num_ranks)])\n\n    # get the number of chunks assigned to each node\n    num_chunks_per_node = np.array([len(chunks_per_ranks[i]) for i in range(num_ranks)])\n\n    # get the number of chunks assigned to each node\n    num_chunks_per_node = np.array([len(chunks_per_ranks[i]) for i in range(num_ranks)])\n\n    # get the number of chunks assigned to each node\n    num_chunks_per_node = np.array([len(chunks_per_ranks[i]) for i in range(num_ranks)])\n\n    #"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Get the number of ranks\n    num_ranks = distributed_env.world_size\n\n    # Get the number of chunks per rank\n    num_chunks_per_rank = [len(chunks) for chunks in chunks_per_ranks]\n\n    # Get the total number of chunks\n    num_chunks = sum(num_chunks_per_rank)\n\n    # Create a list of chunk indexes\n    chunk_indexes = list(range(num_chunks))\n\n    # Create a list of random numbers\n    random_numbers = np.random.RandomState(seed + current_epoch).rand(num_chunks)\n\n    # Create a list of ranks\n    ranks = list(range(num_ranks))\n\n    # Create a list of chunk indexes per rank\n    chunk_indexes_per_rank = [[] for _ in range(num_ranks)]\n\n    # Create a list of chunk indexes per rank\n    chunk_indexes_per_rank_per_node = [[] for _ in range(num_ranks)]\n\n    # Create a list of chunk indexes per rank\n    chunk_indexes_per_rank_per_node_shuffled = [[] for _ in range(num_ranks)]\n\n    # Create a list of chunk indexes per rank\n    chunk_indexes_per_rank_shuffled = [[] for _ in range(num_ranks)]\n\n    # Create a list of chunk indexes per rank\n    chunk_indexes_per_rank_shuffled_flattened = []\n\n    # Create a list of chunk indexes per rank\n    chunk_indexes_per_rank_shuffled_flattened_per_node = []\n\n    # Create a list of chunk indexes per rank\n    chunk_indexes_per_rank_shuffled_flattened_per_node_shuffled = []\n\n    # Create a list of chunk indexes per rank\n    chunk_indexes_per_rank_shuffled_flattened_per_node_shuffled_shuffled = []\n\n    # Create a list of chunk indexes per rank\n   "}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # get the number of chunks per rank\n    chunks_per_rank = [len(chunks) for chunks in chunks_per_ranks]\n    # get the number of chunks per node\n    chunks_per_node = [sum(chunks_per_rank[rank:rank + distributed_env.world_size]) for rank in range(0, distributed_env.world_size, distributed_env.world_size)]\n    # get the number of chunks per node\n    chunks_per_node = chunks_per_node[:distributed_env.world_size]\n\n    # get the number of chunks per node\n    # chunks_per_node = [len(chunks) for chunks in chunks_per_ranks]\n    # get the number of chunks per node\n    # chunks_per_node = chunks_per_node[:distributed_env.world_size]\n\n    # get the number of chunks per node\n    # chunks_per_node = [len(chunks) for chunks in chunks_per_ranks]\n    # get the number of chunks per node\n    # chunks_per_node = chunks_per_node[:distributed_env.world_size]\n\n    # get the number of chunks per node\n    # chunks_per_node = [len(chunks) for chunks in chunks_per_ranks]\n    # get the number of chunks per node\n    # chunks_per_node = chunks_per_node[:distributed_env.world_size]\n\n    # get the number of chunks per node\n    # chunks_per_node = [len(chunks) for chunks in chunks_per_ranks]\n    # get the number of chunks per node\n    # chunks_per_node = chunks_per_node[:distributed_env.world_size]\n\n    # get the number of chunks per node\n    # chunks_per_node = [len(chunks) for chunks in chunks_per_ranks]\n    # get the number of chunks per node"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Create a list of all chunk indexes assigned to each node\n    all_chunks: List[List[int]] = [\n        [\n            chunk_index\n            for rank_chunks in chunks_per_ranks\n            for chunk_index in rank_chunks\n        ]\n    ]\n\n    # Shuffle the chunks for each node\n    np.random.seed(seed + current_epoch)\n    np.random.shuffle(all_chunks)\n\n    # Flatten the list of chunks\n    shuffled_chunks: List[int] = [\n        chunk_index for chunk_list in all_chunks for chunk_index in chunk_list\n    ]\n\n    return shuffled_chunks\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # get number of chunks per node\n    num_chunks_per_node = [len(chunk_list) for chunk_list in chunks_per_ranks]\n\n    # get number of chunks per rank\n    num_chunks_per_rank = [len(chunk_list) for chunk_list in chunks_per_ranks]\n\n    # get total number of chunks\n    num_chunks = sum(num_chunks_per_rank)\n\n    # get number of ranks\n    num_ranks = distributed_env.world_size\n\n    # get the rank of the current node\n    current_rank = distributed_env.rank\n\n    # get the local rank of the current node\n    local_rank = distributed_env.local_rank\n\n    # get the global rank of the current node\n    global_rank = distributed_env.global_rank\n\n    # get the number of nodes\n    num_nodes = distributed_env.num_nodes\n\n    # get the number of GPUs per node\n    num_gpus_per_node = distributed_env.num_gpus_per_node\n\n    # get the number of GPUs per rank\n    num_gpus_per_rank = distributed_env.num_gpus_per_rank\n\n    # get the number of GPUs per local rank\n    num_gpus_per_local_rank = distributed_env.num_gpus_per_local_rank\n\n    # get the number of GPUs per global rank\n    num_gpus_per_global_rank = distributed_env.num_gpus_per_global_rank\n\n    # get the number of GPUs per node\n    num_gpus_per_node = distributed_env.num_gpus_per_node\n\n    # get the number of GPUs per local rank\n    num_gpus_per_local_rank = distributed_env.num_gpus_per_local_rank\n\n    # get the number of GPUs per global rank\n    num_gpus_per_global_rank = distributed_env.num_gpus_per_global_rank\n\n    # get the number"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Get the number of chunks assigned to each rank\n    num_chunks_per_rank = [len(chunk_list) for chunk_list in chunks_per_ranks]\n\n    # Get the number of chunks assigned to each node\n    num_chunks_per_node = np.array(num_chunks_per_rank).reshape(distributed_env.world_size, -1).sum(axis=1)\n\n    # Get the number of chunks assigned to each node\n    num_chunks_per_node_cumsum = np.cumsum(num_chunks_per_node)\n\n    # Get the number of chunks assigned to each node\n    num_chunks_per_node_cumsum_prev = np.roll(num_chunks_per_node_cumsum, 1)\n    num_chunks_per_node_cumsum_prev[0] = 0\n\n    # Create a list of the chunk indexes for each node\n    chunk_indexes_per_node = [\n        list(range(num_chunks_per_node_cumsum_prev[node_idx], num_chunks_per_node_cumsum[node_idx]))\n        for node_idx in range(distributed_env.world_size)\n    ]\n\n    # Create a list of the chunk indexes for each rank\n    chunk_indexes_per_rank = [\n        list(range(num_chunks_per_rank[rank_idx])) for rank_idx in range(distributed_env.world_size)\n    ]\n\n    # Shuffle the chunk indexes for each node\n    for node_idx in range(distributed_env.world_size):\n        np.random.seed(seed + current_epoch + node_idx)\n        np.random.shuffle(chunk_indexes_per_node[node_idx])\n\n    # Create a list of the chunk indexes for each rank\n    chunk_indexes_per_rank = [\n        chunk_indexes_per_node[rank_idx][chunk_indexes_per_rank[rank_idx]]"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # get the number of chunks assigned to each rank\n    chunks_per_rank = np.array(chunks_per_ranks)\n    # get the number of chunks assigned to each node\n    chunks_per_node = chunks_per_rank.sum(axis=1)\n    # get the number of chunks assigned to each node\n    num_chunks = chunks_per_node.sum()\n    # get the number of ranks\n    num_ranks = chunks_per_rank.shape[0]\n    # get the number of nodes\n    num_nodes = distributed_env.world_size\n    # get the number of chunks per node\n    chunks_per_node = chunks_per_node.tolist()\n    # get the number of chunks per rank\n    chunks_per_rank = chunks_per_rank.tolist()\n\n    # shuffle the chunks\n    np.random.seed(seed + current_epoch)\n    np.random.shuffle(chunks_per_rank)\n\n    # get the number of chunks assigned to each rank\n    chunks_per_rank = np.array(chunks_per_rank)\n    # get the number of chunks assigned to each node\n    chunks_per_node = chunks_per_rank.sum(axis=1)\n    # get the number of chunks assigned to each node\n    num_chunks = chunks_per_node.sum()\n    # get the number of ranks\n    num_ranks = chunks_per_rank.shape[0]\n    # get the number of nodes\n    num_nodes = distributed_env.world_size\n    # get the number of chunks per node\n    chunks_per_node = chunks_per_node.tolist()\n    # get the number of chunks per rank\n    chunks_per_rank = chunks_per_rank.tolist()\n\n    # shuffle the chunks\n    np.random.seed(seed + current_epoch)\n    np.random.shuffle(chunks_per_node)\n\n    # get the number of ch"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Get the number of chunks assigned to each rank\n    num_chunks_per_rank = [len(chunks) for chunks in chunks_per_ranks]\n\n    # Create a list of the same length as the number of chunks assigned to each rank, where each element is the rank to which the corresponding chunk is assigned\n    ranks_per_chunks = [\n        [rank for rank in range(len(chunks_per_ranks))]\n        for chunks in chunks_per_ranks\n    ]\n\n    # Flatten the list of ranks per chunk\n    ranks_per_chunks = [rank for sublist in ranks_per_chunks for rank in sublist]\n\n    # Create a list of the same length as the number of chunks assigned to each rank, where each element is the chunk index\n    chunks_per_ranks = [chunk for sublist in chunks_per_ranks for chunk in sublist]\n\n    # Create a list of the same length as the number of chunks assigned to each rank, where each element is the epoch number\n    epochs_per_chunks = [current_epoch for sublist in chunks_per_ranks for chunk in sublist]\n\n    # Create a list of the same length as the number of chunks assigned to each rank, where each element is the node number\n    nodes_per_chunks = [\n        rank // distributed_env.world_size for rank in ranks_per_chunks\n    ]\n\n    # Create a list of the same length as the number of chunks assigned to each rank, where each element is the rank of the node to which the corresponding chunk is assigned\n    ranks_per_nodes = [\n        [\n            rank\n            for rank, node in enumerate(nodes_per_chunks)\n            if node == node_index\n        ]\n        for node_index in range(distributed_env.world_size)\n    ]\n\n    # Flatten the list of ranks per node\n    ranks_per_nodes = [rank for sublist in ranks_per_nodes for rank in sublist]\n\n    # Create a list of the same length as the number of chunks assigned"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Get the number of chunks assigned to each rank\n    num_chunks_per_rank = [len(chunks_per_rank) for chunks_per_rank in chunks_per_ranks]\n\n    # Get the number of chunks assigned to each node\n    num_chunks_per_node = num_chunks_per_rank[distributed_env.rank]\n\n    # Get the chunks assigned to the current node\n    chunks_per_node = chunks_per_ranks[distributed_env.rank]\n\n    # Create a list of the same size as the number of chunks assigned to the current node\n    shuffled_chunks_per_node = [None] * num_chunks_per_node\n\n    # Create a random seed based on the current epoch and the seed\n    random_seed = seed + current_epoch\n\n    # Create a random state for reproducibility\n    random_state = np.random.RandomState(random_seed)\n\n    # Shuffle the chunks assigned to the current node\n    random_state.shuffle(chunks_per_node)\n\n    # Add the shuffled chunks to the list of shuffled chunks for the current node\n    shuffled_chunks_per_node += chunks_per_node\n\n    # Create a list of the same size as the number of nodes\n    shuffled_chunks_per_rank = [None] * distributed_env.world_size\n\n    # Add the shuffled chunks for the current node to the list of shuffled chunks for all nodes\n    shuffled_chunks_per_rank[distributed_env.rank] = shuffled_chunks_per_node\n\n    # Synchronize the shuffled chunks across all nodes\n    distributed_env.all_gather_object(shuffled_chunks_per_rank)\n\n    # Flatten the list of shuffled chunks across all nodes\n    shuffled_chunks_across_all_nodes = [\n        shuffled_chunks_per_rank[i][j]\n        for"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Get the number of ranks in the distributed environment.\n    num_ranks = distributed_env.world_size\n\n    # Get the number of chunks assigned to each rank.\n    num_chunks_per_rank = [len(chunks) for chunks in chunks_per_ranks]\n\n    # Get the total number of chunks in the distributed environment.\n    num_chunks = sum(num_chunks_per_rank)\n\n    # Create a list of chunk indexes for each rank.\n    chunks_per_rank = [\n        np.array(chunks_per_ranks[rank_index])\n        for rank_index in range(num_ranks)\n    ]\n\n    # Create a list of chunk indexes for each node.\n    chunks_per_node = [\n        np.array([], dtype=int) for _ in range(distributed_env.num_nodes)\n    ]\n\n    # Assign each rank to a node.\n    ranks_per_node = [\n        np.array([], dtype=int) for _ in range(distributed_env.num_nodes)\n    ]\n\n    for rank_index in range(num_ranks):\n\n        # Get the node index for the current rank.\n        node_index = distributed_env.node_rank_map[rank_index]\n\n        # Add the rank to the list of ranks for the current node.\n        ranks_per_node[node_index] = np.append(\n            ranks_per_node[node_index], rank_index\n        )\n\n        # Add the chunks for the current rank to the list of chunks for the current node.\n        chunks_per_node[node_index] = np.append(\n            chunks_per_node[node_index], chunks_per_rank[rank_index]\n        )\n\n    # Create a list of shuffled chunks for each node.\n    shuffled_chunks_per_node = [\n        np.array([], dtype=int) for _ in range(distributed_env.num_nodes)\n    ]\n\n    # Create a list"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # get the number of nodes and the number of chunks assigned to each node\n    num_nodes = distributed_env.num_nodes\n    chunks_per_rank = chunks_per_ranks[distributed_env.rank]\n    num_chunks = len(chunks_per_rank)\n\n    # set the seed based on the current epoch and the seed\n    np.random.seed(seed + current_epoch)\n\n    # shuffle the chunk indexes\n    shuffled_chunks = np.random.permutation(chunks_per_rank)\n\n    # get the local chunk indexes\n    local_chunks = shuffled_chunks[:num_chunks // num_nodes]\n\n    return local_chunks.tolist()\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Get the number of chunks per node\n    num_chunks_per_rank = np.array(chunks_per_ranks).flatten()\n\n    # Generate a random number for each chunk and rank\n    random_nums = np.random.RandomState(seed=seed + current_epoch).rand(distributed_env.world_size, np.max(num_chunks_per_rank))\n\n    # Shuffle the random numbers\n    random_nums = np.array(random_nums.tolist())[distributed_env.rank]\n    np.random.shuffle(random_nums)\n\n    # Get the chunk indexes to be shuffled\n    chunk_indexes = np.array(np.where(np.array(chunks_per_ranks).flatten() != -1)).flatten()\n\n    # Get the number of chunks per rank\n    num_chunks_per_rank = np.array(chunks_per_ranks).flatten()\n\n    # Get the number of chunks to be shuffled\n    num_chunks_to_shuffle = np.sum(num_chunks_per_rank)\n\n    # Get the number of chunks to be shuffled per node\n    num_chunks_per_node = np.array(num_chunks_to_shuffle / distributed_env.world_size)\n\n    # Get the chunk indexes to be shuffled per node\n    chunk_indexes_per_node = np.array(np.where(np.array(chunks_per_ranks).flatten() != -1)).flatten()\n\n    # Get the chunk indexes to be shuffled per node\n    chunk_indexes_per_node = np.array(np.where(np.array(chunks_per_ranks).flatten() != -1)).flatten()\n\n    # Get the chunk indexes to be shuffled per node\n    chunk_indexes_per_node = np.array(np.where(np.array(chunks_per_ranks).flatten() != -1)).flatten()\n\n    # Get"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if len(indexed_paths) == 0:\n        return None\n\n    first_path = indexed_paths[0]\n    first_path_parts = Path(first_path).parts\n\n    for index in range(1, len(indexed_paths)):\n        second_path = indexed_paths[index]\n        second_path_parts = Path(second_path).parts\n\n        if first_path_parts != second_path_parts:\n            raise ValueError(\n                f\"Inconsistent file paths found: {first_path} and {second_path}.\"\n            )\n\n    if len(first_path_parts) == 1:\n        return Path.cwd()\n\n    return os.path.join(*first_path_parts[:-1])\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if len(indexed_paths) == 0:\n        return None\n\n    if len(indexed_paths) == 1:\n        return indexed_paths[0]\n\n    if len(indexed_paths) > 1:\n        input_dirs = set(indexed_paths.values())\n        if len(input_dirs) == 1:\n            return input_dirs.pop()\n        else:\n            raise ValueError(\n                f\"Found multiple input directories: {input_dirs}. Please specify a single directory.\"\n            )\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    if len(inputs) == 0:\n        return None\n\n    indexed_paths = _get_indexed_paths(inputs[0])\n\n    if len(indexed_paths) == 0:\n        return None\n\n    if len(inputs) == 1:\n        input_dir = indexed_paths[0]\n        return input_dir\n\n    indexed_paths_2 = _get_indexed_paths(inputs[1])\n\n    if len(indexed_paths_2) == 0:\n        return None\n\n    if len(indexed_paths) != len(indexed_paths_2):\n        raise ValueError(\"The number of input files is not consistent.\")\n\n    if indexed_paths != indexed_paths_2:\n        raise ValueError(\"The input files are not consistent.\")\n\n    input_dir = indexed_paths[0]\n    return input_dir\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    input_dirs = []\n\n    for input in inputs:\n\n        indexed_paths = _get_indexed_paths(input)\n\n        if indexed_paths:\n            input_dirs.append(os.path.dirname(next(iter(indexed_paths.values()))))\n\n    if input_dirs:\n\n        if len(set(input_dirs)) > 1:\n            raise ValueError(\n                \"Inconsistent input directories found: {}\".format(input_dirs)\n            )\n\n        input_dir = input_dirs[0]\n\n        if not os.path.isabs(input_dir):\n            input_dir = os.path.join(os.getcwd(), input_dir)\n\n        return input_dir\n\n    return None\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    # Get indexed paths\n    indexed_paths = _get_indexed_paths(inputs)\n\n    # Get input directory\n    if len(indexed_paths) == 0:\n        return None\n\n    # Get the first path\n    first_path = indexed_paths[0]\n\n    # Get the first path's parent directory\n    first_path_parent_dir = os.path.dirname(first_path)\n\n    # Get the first path's parent directory's parent directory\n    first_path_parent_dir_parent_dir = os.path.dirname(first_path_parent_dir)\n\n    # Get the first path's parent directory's parent directory's parent directory\n    first_path_parent_dir_parent_dir_parent_dir = os.path.dirname(first_path_parent_dir_parent_dir)\n\n    # Get the first path's parent directory's parent directory's parent directory's parent directory\n    first_path_parent_dir_parent_dir_parent_dir_parent_dir = os.path.dirname(first_path_parent_dir_parent_dir_parent_dir)\n\n    # Check if the first path's parent directory is the project root\n    if first_path_parent_dir == first_path_parent_dir_parent_dir_parent_dir_parent_dir:\n        return first_path_parent_dir\n\n    # Check if the first path's parent directory is the project root's parent directory\n    if first_path_parent_dir == first_path_parent_dir_parent_dir:\n        return first_path_parent_dir_parent_dir\n\n    # Check if the first path's parent directory is the project root's parent directory's parent directory\n    if first_path_parent_dir == first_path_parent_dir_parent_dir_parent_dir:\n        return first_path_parent_dir_parent_dir_parent_dir\n\n    # Check if the first path's parent directory is the project root's parent directory's parent directory's parent directory\n    if first_path_parent_dir == first_path_parent"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if len(indexed_paths) == 0:\n        return None\n\n    if len(indexed_paths) == 1:\n        input_dir = indexed_paths[0]\n    elif len(indexed_paths) == 2:\n        if indexed_paths[0] == indexed_paths[1]:\n            input_dir = indexed_paths[0]\n        else:\n            raise ValueError(\n                f\"Found inconsistent file paths: {indexed_paths[0]} and {indexed_paths[1]}\"\n            )\n    else:\n        raise ValueError(\n            f\"Found more than two file paths: {indexed_paths.values()}\"\n        )\n\n    input_dir = _resolve_dir(input_dir)\n\n    return input_dir\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if len(indexed_paths) == 0:\n        return None\n\n    input_dir = None\n    for path in indexed_paths.values():\n        if input_dir is None:\n            input_dir = path\n        elif input_dir != path:\n            raise ValueError(\n                f\"Found inconsistent file paths: {input_dir} and {path}. Please make sure that all inputs are located in the same directory.\"\n            )\n\n    input_dir = Path(input_dir).resolve()\n\n    return input_dir\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    # Get indexed paths from the inputs.\n    indexed_paths = _get_indexed_paths(inputs)\n\n    # Get the input directory from the indexed paths.\n    input_dir = _resolve_dir(list(indexed_paths.values()))\n\n    return input_dir\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if len(indexed_paths) == 0:\n        return None\n\n    if len(indexed_paths) == 1:\n        return indexed_paths[0]\n\n    first_path = indexed_paths[0]\n    second_path = indexed_paths[1]\n\n    if not os.path.isdir(first_path):\n        first_path = os.path.dirname(first_path)\n\n    if not os.path.isdir(second_path):\n        second_path = os.path.dirname(second_path)\n\n    if first_path != second_path:\n        raise ValueError(\n            f\"Inputs contain different paths: {first_path} and {second_path}\"\n        )\n\n    return first_path\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    # Extract indexed paths from the inputs\n    indexed_paths = _get_indexed_paths(inputs)\n\n    # If no indexed paths are found, return None\n    if not indexed_paths:\n        return None\n\n    # If multiple indexed paths are found, raise an error\n    if len(indexed_paths) > 1:\n        raise ValueError(\n            \"Multiple inputs were found with valid file paths. Please provide a single input with valid file paths.\"\n        )\n\n    # Get the first indexed path\n    input_path = next(iter(indexed_paths.values()))\n\n    # Resolve the input path\n    resolved_input_path = _resolve_dir(input_path)\n\n    # Return the input path\n    return resolved_input_path\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = {\n        index: element\n        for index, element in enumerate(inputs)\n        if isinstance(element, str) and os.path.exists(element)\n    }\n\n    if len(indexed_paths) == 0:\n        return None\n\n    if len(indexed_paths) > 2:\n        raise ValueError(\n            \"Found more than 2 valid file paths in the inputs, please specify the input directory.\"\n        )\n\n    input_paths = list(indexed_paths.values())\n    input_dir = None\n\n    if len(input_paths) == 1:\n        if os.path.isdir(input_paths[0]):\n            input_dir = input_paths[0]\n        else:\n            input_dir = os.path.dirname(input_paths[0])\n    else:\n        if os.path.dirname(input_paths[0]) == os.path.dirname(input_paths[1]):\n            input_dir = os.path.dirname(input_paths[0])\n        else:\n            raise ValueError(\n                \"Found inconsistent file paths in the inputs, please specify the input directory.\"\n            )\n\n    if _IS_IN_STUDIO:\n        input_dir = os.path.join(os.getcwd(), input_dir)\n\n    return input_dir\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    input_dirs = []\n    for input in inputs:\n        indexed_paths = _get_indexed_paths(input)\n        if indexed_paths:\n            input_dirs.append(next(iter(indexed_paths.values())))\n\n    if len(set(input_dirs)) > 1:\n        raise ValueError(\n            f\"Inconsistent file paths found in inputs: {input_dirs}. Please ensure that all inputs are located in the same directory.\"\n        )\n\n    input_dir = _resolve_dir(input_dirs[0]) if input_dirs else None\n\n    return input_dir\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if len(indexed_paths) == 0:\n        return None\n\n    if len(indexed_paths) > 2:\n        raise ValueError(\n            \"Found more than 2 valid file paths in the input sequence. Please specify the input directory or the input file paths directly.\"\n        )\n\n    if len(indexed_paths) == 1:\n        input_dir = indexed_paths[0]\n    else:\n        if indexed_paths[0] != indexed_paths[1]:\n            raise ValueError(\n                f\"Found inconsistent file paths in the input sequence: {indexed_paths[0]} and {indexed_paths[1]}.\"\n            )\n\n        input_dir = indexed_paths[0]\n\n    input_dir = _resolve_dir(input_dir)\n\n    return input_dir\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    # Extract indexed paths from inputs\n    indexed_paths = _get_indexed_paths(inputs)\n\n    # Determine the input directory\n    input_dirs = {\n        os.path.dirname(path)\n        for path in indexed_paths.values()\n        if os.path.dirname(path) != \"\"\n    }\n\n    if len(input_dirs) > 1:\n        raise ValueError(\n            \"Inconsistent file paths found in the inputs. Please specify a single directory.\"\n        )\n\n    input_dir = input_dirs.pop() if len(input_dirs) == 1 else None\n\n    return input_dir\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    input_dirs = []\n\n    for input in inputs:\n        if isinstance(input, str):\n            input_dir = _resolve_dir(input)\n            input_dirs.append(input_dir)\n\n    if len(input_dirs) == 0:\n        return None\n\n    input_dirs_set = set(input_dirs)\n    if len(input_dirs_set) > 1:\n        raise ValueError(\n            f\"Inconsistent input directories found: {input_dirs_set}. \"\n            f\"Please make sure that all inputs are located in the same directory.\"\n        )\n\n    input_dir = input_dirs.pop()\n    input_dir = os.path.abspath(input_dir)\n\n    return input_dir\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    # get indexed paths from inputs\n    indexed_paths = _get_indexed_paths(inputs)\n\n    # check if there are indexed paths\n    if indexed_paths:\n\n        # get first indexed path\n        first_indexed_path = indexed_paths[0]\n\n        # get first indexed path's path\n        first_indexed_path_path = Path(first_indexed_path)\n\n        # get first indexed path's path's parent\n        first_indexed_path_parent = first_indexed_path_path.parent\n\n        # check if first indexed path's parent is a directory\n        if first_indexed_path_parent.is_dir():\n\n            # get first indexed path's parent's absolute path\n            first_indexed_path_parent_absolute_path = first_indexed_path_parent.absolute()\n\n            # return first indexed path's parent's absolute path\n            return str(first_indexed_path_parent_absolute_path)\n\n        # check if first indexed path's parent is a file\n        elif first_indexed_path_parent.is_file():\n\n            # get first indexed path's parent's absolute path\n            first_indexed_path_parent_absolute_path = first_indexed_path_parent.parent.absolute()\n\n            # return first indexed path's parent's absolute path\n            return str(first_indexed_path_parent_absolute_path)\n\n        # raise error if first indexed path's parent is neither a directory nor a file\n        else:\n            raise ValueError(\n                f\"The first indexed path's parent is neither a directory nor a file. The first indexed path is {first_indexed_path}.\"\n            )\n\n    # return None if there are no indexed paths\n    return None\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if len(indexed_paths) == 0:\n        return None\n\n    # Get the first two paths\n    first_path = indexed_paths[0]\n    second_path = indexed_paths[1]\n\n    # Check if they are valid paths\n    if not os.path.isabs(first_path):\n        raise ValueError(f\"{first_path} is not a valid path.\")\n\n    if not os.path.isabs(second_path):\n        raise ValueError(f\"{second_path} is not a valid path.\")\n\n    # Check if they are in the same directory\n    if os.path.dirname(first_path) != os.path.dirname(second_path):\n        raise ValueError(\n            f\"{first_path} and {second_path} are not in the same directory.\"\n        )\n\n    # Get the common directory\n    input_dir = os.path.dirname(first_path)\n\n    # Check if the directory is empty\n    if not _assert_dir_is_empty(input_dir):\n        raise ValueError(f\"{input_dir} is not empty.\")\n\n    # Check if the directory contains an index file\n    if not _assert_dir_has_index_file(input_dir):\n        raise ValueError(f\"{input_dir} does not contain an index file.\")\n\n    # Return the absolute path to the directory\n    return input_dir\n\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if len(indexed_paths) == 0:\n        return None\n\n    if len(indexed_paths) == 1:\n        return indexed_paths[0]\n\n    if len(indexed_paths) > 1:\n        raise ValueError(\n            \"Found multiple valid file paths in the inputs. Please ensure that only one file path is provided.\"\n        )\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    # check for valid file paths\n    if len(inputs) > 2:\n        raise ValueError(\n            f\"Expected at most 2 inputs, but got {len(inputs)}. Please provide a valid input.\"\n        )\n    if len(inputs) < 2:\n        return None\n\n    # get indexed paths from inputs\n    indexed_paths_0 = _get_indexed_paths(inputs[0])\n    indexed_paths_1 = _get_indexed_paths(inputs[1])\n\n    # check for inconsistent file paths\n    if len(indexed_paths_0) != len(indexed_paths_1):\n        raise ValueError(\n            f\"Expected the same number of inputs, but got {len(indexed_paths_0)} and {len(indexed_paths_1)}.\"\n        )\n    if len(indexed_paths_0) == 0:\n        return None\n\n    # check for valid file paths\n    for indexed_path in indexed_paths_0.values():\n        if not os.path.isfile(indexed_path):\n            raise ValueError(f\"{indexed_path} is not a valid file path.\")\n\n    # get the input directory\n    input_dir = os.path.dirname(list(indexed_paths_0.values())[0])\n\n    # check if the input directory is empty\n    if _assert_dir_is_empty(input_dir):\n        return input_dir\n\n    # check if the input directory has an index file\n    if _assert_dir_has_index_file(input_dir):\n        return input_dir\n\n    # check if the input directory is a directory\n    if os.path.isdir(input_dir):\n        return input_dir\n\n    # check if the input directory is a valid path\n    if os.path.exists(input_dir):\n        raise ValueError(f\"{input_dir} is not a valid directory.\")\n\n    # check if the input directory is a relative path\n    if not os.path.isabs(input_dir):\n        return input_dir\n\n    #"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    if len(inputs) < 2:\n        raise ValueError(\n            \"At least two inputs must be provided to determine the input directory.\"\n        )\n\n    input_paths = [_get_indexed_paths(input) for input in inputs]\n\n    if not input_paths:\n        raise ValueError(\n            \"At least one input must contain a valid file path to determine the input directory.\"\n        )\n\n    # Check if all paths are the same\n    input_paths_set = set(input_paths)\n    if len(input_paths_set) > 1:\n        raise ValueError(\n            f\"Inputs must be the same, but got {input_paths_set}.\"\n        )\n\n    # Extract the first path\n    input_path = list(input_paths_set)[0]\n\n    # Check if all paths are files\n    if not all(os.path.isfile(path) for path in input_path.values()):\n        raise ValueError(\n            f\"Inputs must be files, but got {input_path}.\"\n        )\n\n    # Resolve the path to the project root or a specified depth in the file system\n    input_path = list(input_path.values())[0]\n    input_path = _resolve_dir(input_path)\n\n    return input_path\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if not enable:\n        yield\n        return\n\n    if not _IS_IN_STUDIO:\n        yield\n        return\n\n    try:\n        # Enable DNS optimization\n        proc = Popen([\"dns-optimization\", \"enable\"], stdout=DEVNULL, stderr=DEVNULL)\n        proc.wait()\n        yield\n    finally:\n        # Disable DNS optimization\n        proc = Popen([\"dns-optimization\", \"disable\"], stdout=DEVNULL, stderr=DEVNULL)\n        proc.wait()"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if _IS_IN_STUDIO:\n        if enable:\n            # Enable DNS optimization\n            proc = Popen(\n                [\"sudo\", \"sysctl\", \"-w\", \"net.ipv4.tcp_ecn=1\"],\n                stdout=DEVNULL,\n                stderr=DEVNULL,\n            )\n            proc.communicate()\n        else:\n            # Disable DNS optimization\n            proc = Popen(\n                [\"sudo\", \"sysctl\", \"-w\", \"net.ipv4.tcp_ecn=0\"],\n                stdout=DEVNULL,\n                stderr=DEVNULL,\n            )\n            proc.communicate()\n\n    try:\n        yield\n    finally:\n        if _IS_IN_STUDIO:\n            # Reset DNS optimization\n            proc = Popen(\n                [\"sudo\", \"sysctl\", \"-w\", \"net.ipv4.tcp_ecn=0\"],\n                stdout=DEVNULL,\n                stderr=DEVNULL,\n            )\n            proc.communicate()"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        # Enable DNS optimization\n        os.system(\"sudo sysctl -w net.ipv4.tcp_ecn=1\")\n        os.system(\"sudo sysctl -w net.ipv4.tcp_ecn_fallback=0\")\n\n    try:\n        yield\n    finally:\n        # Disable DNS optimization\n        os.system(\"sudo sysctl -w net.ipv4.tcp_ecn=0\")\n        os.system(\"sudo sysctl -w net.ipv4.tcp_ecn_fallback=1\")\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        # enable dns optimization\n        os.system(\"sudo sysctl -w net.ipv4.tcp_slow_start_after_idle=0\")\n        os.system(\"sudo sysctl -w net.ipv4.tcp_no_metrics_save=1\")\n        os.system(\"sudo sysctl -w net.ipv4.tcp_moderate_rcvbuf=1\")\n        os.system(\"sudo sysctl -w net.ipv4.tcp_moderate_sack=1\")\n        os.system(\"sudo sysctl -w net.ipv4.tcp_window_scaling=1\")\n        os.system(\"sudo sysctl -w net.ipv4.tcp_sack=1\")\n        os.system(\"sudo sysctl -w net.ipv4.tcp_timestamps=1\")\n        os.system(\"sudo sysctl -w net.ipv4.tcp_sack_global=1\")\n        os.system(\"sudo sysctl -w net.ipv4.tcp_dsack=1\")\n        os.system(\"sudo sysctl -w net.ipv4.tcp_fack=1\")\n        os.system(\"sudo sysctl -w net.ipv4.tcp_syn_retries=10\")\n        os.system(\"sudo sysctl -w net.ipv4.tcp_synack_retries=10\")\n        os.system(\"sudo sysctl -w net.ipv4.tcp_syn_cookies=1\")\n        os.system(\"sudo sysctl -w net.ipv4.tcp_rfc1337=1\")\n        os.system(\"sudo sysctl -w net.ipv4.tcp_max_syn_backlog=65535\")\n        os.system(\"sudo sysctl -w net.ipv4.tcp_tw_recycle=1\")\n        os.system(\"sudo sysctl -w net.ipv4.tcp_tw_reuse=1\")\n        os.system(\"sudo sysctl -w net.ipv4.tcp_keepalive_time=10\")\n       "}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        os.environ[\"LIGHTNING_CLOUD_DNS_ENABLE\"] = \"1\"\n    else:\n        os.environ[\"LIGHTNING_CLOUD_DNS_ENABLE\"] = \"0\"\n\n    try:\n        yield\n    finally:\n        os.environ[\"LIGHTNING_CLOUD_DNS_ENABLE\"] = \"0\"\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        # Enable DNS optimization\n        os.system(\"sudo sysctl -w net.ipv4.tcp_available_congestion_control=htcp\")\n        os.system(\"sudo sysctl -w net.ipv4.tcp_congestion_control=htcp\")\n        os.system(\"sudo sysctl -w net.ipv4.tcp_congestion_control=htcp\")\n        os.system(\"sudo sysctl -w net.ipv4.tcp_congestion_control=htcp\")\n        os.system(\"sudo sysctl -w net.ipv4.tcp_congestion_control=htcp\")\n\n    try:\n        # Yield execution to the caller\n        yield\n    finally:\n        # Disable DNS optimization\n        os.system(\"sudo sysctl -w net.ipv4.tcp_available_congestion_control=cubic\")\n        os.system(\"sudo sysctl -w net.ipv4.tcp_congestion_control=cubic\")\n        os.system(\"sudo sysctl -w net.ipv4.tcp_congestion_control=cubic\")\n        os.system(\"sudo sysctl -w net.ipv4.tcp_congestion_control=cubic\")\n        os.system(\"sudo sysctl -w net.ipv4.tcp_congestion_control=cubic\")\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        os.system(\"sudo dnscache -s 127.0.0.1 -m 100000000\")\n    yield\n    if enable:\n        os.system(\"sudo dnscache -d\")\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    try:\n        if enable:\n            os.environ[\"LIGHTNING_CLOUD_DNS_ENABLE\"] = \"1\"\n        yield\n    finally:\n        if \"LIGHTNING_CLOUD_DNS_ENABLE\" in os.environ:\n            del os.environ[\"LIGHTNING_CLOUD_DNS_ENABLE\"]\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        os.system(\"sudo dnscache -z\")\n        os.system(\"sudo dnscache -a\")\n    try:\n        yield\n    finally:\n        if enable:\n            os.system(\"sudo dnscache -k\")\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    try:\n        if enable:\n            os.environ[\"LIGHTNING_CLOUD_DNS_ENABLE\"] = \"1\"\n        yield\n    finally:\n        if \"LIGHTNING_CLOUD_DNS_ENABLE\" in os.environ:\n            del os.environ[\"LIGHTNING_CLOUD_DNS_ENABLE\"]\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    try:\n        if enable:\n            os.system(\"sudo dnsmasq -d\")\n        yield\n    finally:\n        if enable:\n            os.system(\"sudo killall dnsmasq\")\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if not _IS_IN_STUDIO:\n        return\n\n    if enable:\n        # Enable DNS optimization\n        with open(\"/proc/sys/net/ipv4/tcp_tw_reuse\", \"w\") as f:\n            f.write(\"1\\n\")\n        with open(\"/proc/sys/net/ipv4/tcp_keepalive_time\", \"w\") as f:\n            f.write(\"120\\n\")\n        with open(\"/proc/sys/net/ipv4/tcp_keepalive_probes\", \"w\") as f:\n            f.write(\"4\\n\")\n        with open(\"/proc/sys/net/ipv4/tcp_keepalive_intvl\", \"w\") as f:\n            f.write(\"15\\n\")\n\n    yield\n\n    if enable:\n        # Disable DNS optimization\n        with open(\"/proc/sys/net/ipv4/tcp_tw_reuse\", \"w\") as f:\n            f.write(\"0\\n\")\n        with open(\"/proc/sys/net/ipv4/tcp_keepalive_time\", \"w\") as f:\n            f.write(\"7200\\n\")\n        with open(\"/proc/sys/net/ipv4/tcp_keepalive_probes\", \"w\") as f:\n            f.write(\"9\\n\")\n        with open(\"/proc/sys/net/ipv4/tcp_keepalive_intvl\", \"w\") as f:\n            f.write(\"75\\n\")\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        os.environ[\"LIGHTNING_CLOUD_DNS_ENABLE\"] = \"1\"\n    try:\n        yield\n    finally:\n        if enable:\n            os.environ[\"LIGHTNING_CLOUD_DNS_ENABLE\"] = \"0\"\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    try:\n        if enable:\n            # Enable DNS optimization\n            os.system(\"sudo dnscache -f\")\n        else:\n            # Disable DNS optimization\n            os.system(\"sudo dnscache -d\")\n        yield\n    finally:\n        # Disable DNS optimization\n        os.system(\"sudo dnscache -d\")\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        proc = Popen([\"/usr/bin/sudo\", \"nscd\", \"-i\", \"hosts\", \"-g\", \"hosts\"], stdout=DEVNULL, stderr=DEVNULL)\n        proc.communicate()\n        yield\n        proc = Popen([\"/usr/bin/sudo\", \"nscd\", \"-c\"], stdout=DEVNULL, stderr=DEVNULL)\n        proc.communicate()\n    else:\n        proc = Popen([\"/usr/bin/sudo\", \"nscd\", \"-i\", \"hosts\", \"-g\", \"none\"], stdout=DEVNULL, stderr=DEVNULL)\n        proc.communicate()\n        yield\n        proc = Popen([\"/usr/bin/sudo\", \"nscd\", \"-i\", \"hosts\", \"-g\", \"hosts\"], stdout=DEVNULL, stderr=DEVNULL)\n        proc.communicate()\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        os.environ[\"LIGHTNING_CLOUD_DNS_OPTIMIZE\"] = \"1\"\n    try:\n        yield\n    finally:\n        if \"LIGHTNING_CLOUD_DNS_OPTIMIZE\" in os.environ:\n            del os.environ[\"LIGHTNING_CLOUD_DNS_OPTIMIZE\"]\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        os.environ[\"LIGHTNING_CLOUD_DNS_OPTIMIZE\"] = \"1\"\n    else:\n        os.environ[\"LIGHTNING_CLOUD_DNS_OPTIMIZE\"] = \"0\"\n\n    try:\n        yield\n    finally:\n        os.environ[\"LIGHTNING_CLOUD_DNS_OPTIMIZE\"] = \"0\"\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    # Enable DNS optimization\n    if enable:\n        if not _IS_IN_STUDIO:\n            # Optimize only if not in Studio\n            Popen([\"sudo\", \"systemd-resolve\", \"--flush-caches\"])\n            Popen([\"sudo\", \"systemd-resolve\", \"--flush-host-cache\"])\n            Popen([\"sudo\", \"systemd-resolve\", \"--flush-caches=single\"])\n            Popen([\"sudo\", \"systemd-resolve\", \"--flush-caches=all\"])\n        yield\n    else:\n        # Disable DNS optimization\n        if not _IS_IN_STUDIO:\n            # Optimize only if not in Studio\n            Popen([\"sudo\", \"systemd-resolve\", \"--flush-caches\"])\n            Popen([\"sudo\", \"systemd-resolve\", \"--flush-host-cache\"])\n            Popen([\"sudo\", \"systemd-resolve\", \"--flush-caches=single\"])\n            Popen([\"sudo\", \"systemd-resolve\", \"--flush-caches=all\"])\n        yield\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if _IS_IN_STUDIO:\n        # No optimization needed in studio\n        yield\n    else:\n        try:\n            # Optimization is only needed for non-studio environments\n            if enable:\n                # Enable optimization\n                Popen([\"sudo\", \"systemd-resolve\", \"--flush-caches\"])\n                Popen([\"sudo\", \"systemd-resolve\", \"--set-dns=192.168.0.1\"])\n            yield\n        finally:\n            # Reset DNS settings to default\n            Popen([\"sudo\", \"systemd-resolve\", \"--flush-caches\"])\n            Popen([\"sudo\", \"systemd-resolve\", \"--set-dns=8.8.8.8\"])\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    try:\n        if enable:\n            os.environ[\"LIGHTNING_CLOUD_DNS_ENABLE\"] = \"True\"\n        yield\n    finally:\n        os.environ[\"LIGHTNING_CLOUD_DNS_ENABLE\"] = \"False\"\n\n"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items per rank\n    num_items_per_rank = np.ceil(len(indexes) / distributed_env.world_size)\n    if drop_last:\n        num_items_per_rank = np.floor(len(indexes) / distributed_env.world_size)\n\n    # calculate the number of items per rank\n    num_items_per_rank = np.ceil(len(indexes) / distributed_env.world_size)\n    if drop_last:\n        num_items_per_rank = np.floor(len(indexes) / distributed_env.world_size)\n\n    # calculate the number of items per rank\n    num_items_per_rank = np.ceil(len(indexes) / distributed_env.world_size)\n    if drop_last:\n        num_items_per_rank = np.floor(len(indexes) / distributed_env.world_size)\n\n    # calculate the number of items per rank\n    num_items_per_rank = np.ceil(len(indexes) / distributed_env.world_size)\n    if drop_last:\n        num_items_per_rank = np.floor(len(indexes) / distributed_env.world_size)\n\n    # calculate the number of items per rank\n    num_items_per_rank = np.ceil(len(indexes) / distributed_env.world_size)\n    if drop_last:\n        num_items_per_rank = np.floor(len(indexes) / distributed_env.world_size)\n\n    # calculate the number of items per rank\n    num_items_per_rank = np.ceil(len(indexes) / distributed_env.world_size)\n    if drop_last:\n        num_items_per_rank = np.floor(len(indexes) / distributed_env.world_size)\n\n    # calculate the number of items per rank\n    num_items_per_rank = np.ceil(len(indexes) / distributed_env.world_size)\n    if drop_last:\n        num_items_per_rank ="}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items to be distributed among the ranks\n    num_items = len(indexes)\n    if drop_last:\n        num_items_per_rank = num_items // distributed_env.world_size\n    else:\n        num_items_per_rank = (num_items + distributed_env.world_size - 1) // distributed_env.world_size\n\n    # calculate the number of items to be distributed among the ranks\n    num_items_per_rank = num_items // distributed_env.world_size\n    if drop_last:\n        num_items_per_rank = num_items // distributed_env.world_size\n    else:\n        num_items_per_rank = (num_items + distributed_env.world_size - 1) // distributed_env.world_size\n\n    # calculate the number of items to be distributed among the ranks\n    num_items_per_rank = num_items // distributed_env.world_size\n    if drop_last:\n        num_items_per_rank = num_items // distributed_env.world_size\n    else:\n        num_items_per_rank = (num_items + distributed_env.world_size - 1) // distributed_env.world_size\n\n    # calculate the number of items to be distributed among the ranks\n    num_items_per_rank = num_items // distributed_env.world_size\n    if drop_last:\n        num_items_per_rank = num_items // distributed_env.world_size\n    else:\n        num_items_per_rank = (num_items + distributed_env.world_size - 1) // distributed_env.world_size\n\n    # calculate the number of items to be distributed among the ranks\n    num_items_per_rank = num_items // distributed_env.world_size\n    if drop_last:\n        num_items_per_rank = num_items // distributed_env.world_size\n    else:\n        num_items_per_rank = (num_items + distributed_env.world_size - 1) // distributed_env.world_size"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items to be distributed\n    num_items = len(indexes)\n    if drop_last:\n        num_items_per_rank = num_items // distributed_env.world_size\n    else:\n        num_items_per_rank = (num_items + distributed_env.world_size - 1) // distributed_env.world_size\n\n    # calculate the number of items to be distributed in the last rank\n    if drop_last:\n        num_items_in_last_rank = num_items_per_rank\n    else:\n        num_items_in_last_rank = num_items - (num_items_per_rank * (distributed_env.world_size - 1))\n\n    # calculate the number of items to be distributed in the other ranks\n    num_items_in_other_ranks = num_items_per_rank * (distributed_env.world_size - 1)\n\n    # calculate the number of chunks to be distributed\n    num_chunks = len(chunk_intervals)\n    if drop_last:\n        num_chunks_per_rank = num_chunks // distributed_env.world_size\n    else:\n        num_chunks_per_rank = (num_chunks + distributed_env.world_size - 1) // distributed_env.world_size\n\n    # calculate the number of chunks to be distributed in the last rank\n    if drop_last:\n        num_chunks_in_last_rank = num_chunks_per_rank\n    else:\n        num_chunks_in_last_rank = num_chunks - (num_chunks_per_rank * (distributed_env.world_size - 1))\n\n    # calculate the number of chunks to be distributed in the other ranks\n    num_chunks_in_other_ranks = num_chunks_per_rank * (distributed_env.world_size - 1)\n\n    # calculate the number of items per chunk\n    num_items_per_chunk = num_items / num_chunks\n\n    # calculate the number of"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items each rank should process\n    if drop_last:\n        num_items = len(indexes) // distributed_env.world_size\n    else:\n        num_items = (len(indexes) + distributed_env.world_size - 1) // distributed_env.world_size\n\n    # associate the chunks and intervals to each rank\n    chunk_indexes_per_ranks = [[] for _ in range(distributed_env.world_size)]\n    chunk_intervals_per_ranks = [[] for _ in range(distributed_env.world_size)]\n    for rank in range(distributed_env.world_size):\n        for i in range(num_items):\n            chunk_indexes_per_ranks[rank].append(indexes[i * distributed_env.world_size + rank])\n            chunk_intervals_per_ranks[rank].append(chunk_intervals[i * distributed_env.world_size + rank])\n\n    return chunk_indexes_per_ranks, chunk_intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items to be distributed per rank\n    num_items = len(indexes)\n    num_items_per_rank = num_items // distributed_env.world_size\n    if drop_last:\n        num_items_per_rank = num_items // distributed_env.world_size\n        num_items_per_rank = num_items_per_rank + 1 if num_items % distributed_env.world_size != 0 else num_items_per_rank\n    else:\n        num_items_per_rank = num_items // distributed_env.world_size\n        num_items_per_rank = num_items_per_rank + 2 if num_items % distributed_env.world_size != 0 else num_items_per_rank\n\n    # calculate the number of items to be distributed per rank\n    num_items_per_rank = num_items // distributed_env.world_size\n    if drop_last:\n        num_items_per_rank = num_items // distributed_env.world_size\n        num_items_per_rank = num_items_per_rank + 1 if num_items % distributed_env.world_size != 0 else num_items_per_rank\n    else:\n        num_items_per_rank = num_items // distributed_env.world_size\n        num_items_per_rank = num_items_per_rank + 2 if num_items % distributed_env.world_size != 0 else num_items_per_rank\n\n    # calculate the number of items to be distributed per rank\n    num_items_per_rank = num_items // distributed_env.world_size\n    if drop_last:\n        num_items_per_rank = num_items // distributed_env.world_size\n        num_items_per_rank = num_items_per_rank + 1 if num_items % distributed_env.world_size != 0 else num_items_per_rank\n    else:\n        num_items_per_rank = num_items // distributed_env.world_size\n        num_items_per_rank ="}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items per rank\n    num_items = len(indexes)\n    items_per_rank = [num_items // distributed_env.world_size] * distributed_env.world_size\n    if drop_last:\n        items_per_rank[-1] = num_items - sum(items_per_rank[:-1])\n    else:\n        items_per_rank[-1] += num_items - sum(items_per_rank)\n\n    # associate chunks and their intervals to ranks\n    chunks_per_ranks: List[List[int]] = [[] for _ in range(distributed_env.world_size)]\n    chunk_intervals_per_ranks: List[List[Any]] = [[] for _ in range(distributed_env.world_size)]\n    for rank in range(distributed_env.world_size):\n        for item_index in range(items_per_rank[rank]):\n            chunks_per_ranks[rank].append(indexes[item_index])\n            chunk_intervals_per_ranks[rank].append(chunk_intervals[item_index])\n\n    return chunks_per_ranks, chunk_intervals_per_ranks\n\n"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items to be distributed per rank\n    if drop_last:\n        num_items_per_rank = np.array_split(indexes, distributed_env.world_size)\n    else:\n        num_items_per_rank = np.array_split(indexes, distributed_env.world_size)\n\n    # associate the chunks and their intervals to the ranks\n    chunks_per_ranks = []\n    chunk_intervals_per_ranks = []\n    for rank in range(distributed_env.world_size):\n        if rank < len(num_items_per_rank):\n            chunks_per_ranks.append(num_items_per_rank[rank])\n            chunk_intervals_per_ranks.append(np.array_split(chunk_intervals, distributed_env.world_size)[rank])\n        else:\n            chunks_per_ranks.append([])\n            chunk_intervals_per_ranks.append([])\n\n    return chunks_per_ranks, chunk_intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # get the number of items to be distributed\n    num_items = len(indexes)\n\n    # calculate the number of items to be distributed per rank\n    num_items_per_rank = np.ceil(num_items / distributed_env.world_size)\n    if drop_last:\n        num_items_per_rank = np.floor(num_items / distributed_env.world_size)\n\n    # calculate the number of items to be distributed in the last rank\n    num_items_last_rank = num_items - (num_items_per_rank * (distributed_env.world_size - 1))\n\n    # calculate the number of items to be distributed in the other ranks\n    num_items_other_ranks = num_items - num_items_last_rank\n\n    # calculate the number of items to be distributed in each rank\n    num_items_per_rank = [num_items_per_rank] * (distributed_env.world_size - 1)\n    num_items_per_rank += [num_items_last_rank]\n\n    # calculate the number of items to be distributed in each rank\n    num_items_other_ranks = [num_items_other_ranks] * (distributed_env.world_size - 1)\n    num_items_other_ranks += [0]\n\n    # calculate the number of items to be distributed in each rank\n    num_items_per_rank = np.array(num_items_per_rank)\n    num_items_other_ranks = np.array(num_items_other_ranks)\n\n    # calculate the number of items to be distributed in each rank\n    num_items_per_rank = num_items_per_rank.astype(int)\n    num_items_other_ranks = num_items_other_ranks.astype(int)\n\n    # calculate the number of items to be distributed in each rank\n    num_items_per_rank = num_items_per_rank.tolist()\n    num_items_other_ranks = num_items_other_ranks.tolist()"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items per rank\n    if drop_last:\n        num_items_per_rank = [len(indexes) // distributed_env.world_size] * distributed_env.world_size\n    else:\n        num_items_per_rank = [\n            len(indexes) // distributed_env.world_size + 1 if i < len(indexes) % distributed_env.world_size else len(indexes) // distributed_env.world_size for i in range(distributed_env.world_size)\n        ]\n\n    # associate chunks and intervals to ranks\n    chunks_per_ranks = [[] for _ in range(distributed_env.world_size)]\n    intervals_per_ranks = [[] for _ in range(distributed_env.world_size)]\n    for rank, num_items_in_rank in enumerate(num_items_per_rank):\n        for i in range(num_items_in_rank):\n            chunks_per_ranks[rank].append(indexes[i])\n            intervals_per_ranks[rank].append(chunk_intervals[i])\n\n    return chunks_per_ranks, intervals_per_ranks\n\n"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # get the number of items to be distributed\n    num_items = len(indexes)\n    # calculate the number of items per rank\n    items_per_rank = [num_items // distributed_env.world_size] * distributed_env.world_size\n    # calculate the number of items to be dropped\n    items_to_drop = num_items % distributed_env.world_size\n    # drop the last items if necessary\n    if drop_last:\n        for i in range(items_to_drop):\n            items_per_rank[i] -= 1\n    else:\n        for i in range(items_to_drop):\n            items_per_rank[i] += 1\n\n    # calculate the number of items per rank\n    items_per_rank = [num_items // distributed_env.world_size] * distributed_env.world_size\n    # calculate the number of items to be dropped\n    items_to_drop = num_items % distributed_env.world_size\n    # drop the last items if necessary\n    if drop_last:\n        for i in range(items_to_drop):\n            items_per_rank[i] -= 1\n    else:\n        for i in range(items_to_drop):\n            items_per_rank[i] += 1\n\n    # calculate the number of items per rank\n    items_per_rank = [num_items // distributed_env.world_size] * distributed_env.world_size\n    # calculate the number of items to be dropped\n    items_to_drop = num_items % distributed_env.world_size\n    # drop the last items if necessary\n    if drop_last:\n        for i in range(items_to_drop):\n            items_per_rank[i] -= 1\n    else:\n        for i in range(items_to_drop):\n            items_per_rank[i] += 1\n\n    # calculate the number of items per rank\n    items_per_rank = [num_items // distributed_env.world_size] * distributed_env.world_size\n    # calculate the number of items to be dropped\n   "}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items each rank should process\n    if drop_last:\n        num_items_per_rank = [\n            len(indexes) // distributed_env.world_size\n            if rank < len(indexes) % distributed_env.world_size\n            else len(indexes) // distributed_env.world_size + 1\n            for rank in range(distributed_env.world_size)\n        ]\n    else:\n        num_items_per_rank = [\n            len(indexes) // distributed_env.world_size + 1\n            if len(indexes) % distributed_env.world_size != 0 and rank < len(indexes) % distributed_env.world_size\n            else len(indexes) // distributed_env.world_size\n            for rank in range(distributed_env.world_size)\n        ]\n\n    # associate chunks and their intervals to each rank\n    chunk_indexes_per_ranks = [[] for _ in range(distributed_env.world_size)]\n    chunk_intervals_per_ranks = [[] for _ in range(distributed_env.world_size)]\n    for rank, num_items in enumerate(num_items_per_rank):\n        for i in range(num_items):\n            chunk_indexes_per_ranks[rank].append(indexes[i])\n            chunk_intervals_per_ranks[rank].append(chunk_intervals[i])\n\n    return chunk_indexes_per_ranks, chunk_intervals_per_ranks\n\n"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items per rank\n    if drop_last:\n        num_items_per_rank = [\n            len(indexes) // distributed_env.world_size\n            for _ in range(distributed_env.world_size)\n        ]\n    else:\n        num_items_per_rank = [\n            (len(indexes) + distributed_env.world_size - 1) // distributed_env.world_size\n            for _ in range(distributed_env.world_size)\n        ]\n\n    # calculate the number of items to drop\n    num_items_to_drop = [\n        len(indexes) - num_items_per_rank[i]\n        for i in range(distributed_env.world_size)\n    ]\n\n    # calculate the number of items to add\n    num_items_to_add = [\n        num_items_to_drop[i] + num_items_per_rank[i] - len(indexes)\n        for i in range(distributed_env.world_size)\n    ]\n\n    # calculate the number of items to add to each rank\n    num_items_to_add_per_rank = [\n        num_items_to_add[i] // distributed_env.world_size\n        for i in range(distributed_env.world_size)\n    ]\n\n    # calculate the number of items to add to the last rank\n    num_items_to_add_last_rank = [\n        num_items_to_add[i] - (distributed_env.world_size - 1) * num_items_to_add_per_rank[i]\n        for i in range(distributed_env.world_size)\n    ]\n\n    # calculate the number of items to drop from the last rank\n    num_items_to_drop_last_rank = [\n        num_items_to_drop[i] - (distributed_env.world_size - 1) * num_items_to_add_per_rank[i]\n        for i in range(distributed_env.world_size)"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    num_items = len(indexes)\n    num_items_per_rank = num_items // distributed_env.world_size\n    num_items_last_rank = num_items % distributed_env.world_size\n    num_items_per_rank = (\n        num_items_per_rank + 1 if drop_last and distributed_env.rank < num_items_last_rank else num_items_per_rank\n    )\n\n    # calculate the start and end index of the chunk assigned to each rank\n    start_index = num_items_per_rank * distributed_env.rank\n    end_index = start_index + num_items_per_rank\n\n    # calculate the start and end index of the chunk interval assigned to each rank\n    start_interval = num_items_per_rank * (distributed_env.rank // distributed_env.world_size)\n    end_interval = start_interval + num_items_per_rank\n\n    # calculate the start and end index of the chunk interval assigned to each rank\n    chunks_per_rank = indexes[start_index:end_index]\n    chunk_intervals_per_rank = chunk_intervals[start_interval:end_interval]\n\n    return chunks_per_rank, chunk_intervals_per_rank"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # get the number of items per rank\n    if drop_last:\n        items_per_rank = [\n            len(indexes) // distributed_env.world_size\n            if i < len(indexes) % distributed_env.world_size\n            else len(indexes) // distributed_env.world_size + 1\n            for i in range(distributed_env.world_size)\n        ]\n    else:\n        items_per_rank = [\n            (len(indexes) + distributed_env.world_size - 1) // distributed_env.world_size\n            for _ in range(distributed_env.world_size)\n        ]\n\n    # get the number of chunks per rank\n    chunks_per_rank = [\n        len(indexes) // items_per_rank[i] if i < len(items_per_rank) else 0 for i in range(distributed_env.world_size)\n    ]\n\n    # get the number of items per rank\n    items_per_rank = [\n        items_per_rank[i] if i < len(items_per_rank) else 0 for i in range(distributed_env.world_size)\n    ]\n\n    # get the number of items per rank\n    chunks_per_rank = [\n        chunks_per_rank[i] if i < len(chunks_per_rank) else 0 for i in range(distributed_env.world_size)\n    ]\n\n    # get the indexes and intervals of chunks assigned to each rank\n    indexes_per_rank = [\n        indexes[items_per_rank[i] * chunks_per_rank[i] : items_per_rank[i] * (chunks_per_rank[i] + 1)]\n        if i < len(chunks_per_rank)\n        else []\n        for i in range(distributed_env.world_size)\n    ]\n\n    intervals_per_rank = [\n        [\n            chunk_intervals[indexes_per_rank[i][j]]\n            if i < len(indexes"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    if drop_last:\n        num_items_per_rank = [\n            int(np.ceil(len(indexes) * distributed_env.world_size / distributed_env.num_nodes))\n            for _ in range(distributed_env.num_nodes)\n        ]\n    else:\n        num_items_per_rank = [\n            int(np.ceil(len(indexes) * distributed_env.world_size / distributed_env.num_nodes)) + 1\n            for _ in range(distributed_env.num_nodes)\n        ]\n\n    chunks_per_ranks = []\n    chunk_intervals_per_ranks = []\n    for rank in range(distributed_env.world_size):\n        chunks_per_ranks.append(indexes[rank * num_items_per_rank[rank] : (rank + 1) * num_items_per_rank[rank]])\n        chunk_intervals_per_ranks.append(\n            chunk_intervals[rank * num_items_per_rank[rank] : (rank + 1) * num_items_per_rank[rank]]\n        )\n\n    return chunks_per_ranks, chunk_intervals_per_ranks\n\n"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items per rank\n    if drop_last:\n        items_per_rank = [\n            len(indexes) // distributed_env.world_size + (i < len(indexes) % distributed_env.world_size)\n            for i in range(distributed_env.world_size)\n        ]\n    else:\n        items_per_rank = [\n            (len(indexes) + distributed_env.world_size - 1) // distributed_env.world_size\n            for i in range(distributed_env.world_size)\n        ]\n\n    # calculate the number of items in each rank\n    items_per_rank = [\n        items_per_rank[i] if distributed_env.num_nodes == 1 else items_per_rank[i * distributed_env.num_nodes + distributed_env.rank]\n        for i in range(distributed_env.world_size)\n    ]\n\n    # calculate the number of chunks per rank\n    chunks_per_rank = [\n        len(indexes) // items_per_rank[i] + (len(indexes) % items_per_rank[i] > 0)\n        for i in range(distributed_env.world_size)\n    ]\n\n    # calculate the number of chunks per rank\n    chunks_per_rank = [\n        chunks_per_rank[i] if distributed_env.num_nodes == 1 else chunks_per_rank[i * distributed_env.num_nodes + distributed_env.rank]\n        for i in range(distributed_env.world_size)\n    ]\n\n    # calculate the number of items per rank\n    items_per_rank = [\n        items_per_rank[i] if distributed_env.num_nodes == 1 else items_per_rank[i * distributed_env.num_nodes + distributed_env.rank]\n        for i in range(distributed_env.world_size)\n    ]\n\n    # associate chunks and their intervals to each rank\n    chunks_per_ranks: List[List[int]] ="}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    if drop_last:\n        # the number of items each rank should process\n        num_items_per_rank = (len(indexes) // distributed_env.world_size) + 1\n    else:\n        # the number of items each rank should process\n        num_items_per_rank = (len(indexes) // distributed_env.world_size)\n\n    # the number of items each rank should process\n    num_chunks_per_rank = (len(chunk_intervals) // distributed_env.world_size) + 1\n\n    # the number of chunks per rank\n    chunks_per_ranks = [\n        indexes[i * num_items_per_rank : (i + 1) * num_items_per_rank]\n        for i in range(distributed_env.world_size)\n    ]\n\n    # the number of chunks per rank\n    chunk_intervals_per_ranks = [\n        chunk_intervals[i * num_chunks_per_rank : (i + 1) * num_chunks_per_rank]\n        for i in range(distributed_env.world_size)\n    ]\n\n    return chunks_per_ranks, chunk_intervals_per_ranks\n\n"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # determine the number of items to be distributed\n    num_items = len(indexes)\n\n    # determine the number of items to be distributed per rank\n    if drop_last:\n        num_items_per_rank = num_items // distributed_env.world_size\n    else:\n        num_items_per_rank = (num_items + distributed_env.world_size - 1) // distributed_env.world_size\n\n    # determine the number of items to be distributed in the last rank\n    num_items_in_last_rank = num_items % distributed_env.world_size\n\n    # determine the number of items to be distributed in the rest of the ranks\n    num_items_in_rest_of_ranks = num_items_per_rank\n\n    # determine the number of items to be distributed in each rank\n    num_items_per_rank_list = [num_items_in_rest_of_ranks] * (distributed_env.world_size - 1)\n    if distributed_env.num_nodes > 1:\n        num_items_per_rank_list = [num_items_in_rest_of_ranks] * (distributed_env.world_size - 1)\n        num_items_per_rank_list[-1] = num_items_in_last_rank\n    else:\n        num_items_per_rank_list[-1] = num_items_in_last_rank\n\n    # determine the number of chunks to be distributed per rank\n    num_chunks_per_rank = [len(chunk_intervals[i][0]) for i in range(distributed_env.world_size)]\n\n    # determine the number of chunks to be distributed in the last rank\n    num_chunks_in_last_rank = num_chunks_per_rank[-1]\n\n    # determine the number of chunks to be distributed in the rest of the ranks\n    num_chunks_in_rest_of_ranks = num_chunks_per_rank[:-1]\n    if distributed_env.num_nodes > 1:\n        num"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    num_items = len(indexes)\n    num_items_per_rank = num_items // distributed_env.world_size\n    if drop_last:\n        num_items_per_rank = num_items_per_rank + 1\n    num_items_per_rank_remainder = num_items % distributed_env.world_size\n    num_items_per_rank_remainder_per_node = num_items_per_rank_remainder // distributed_env.num_nodes\n\n    # calculate the number of items to process per rank\n    num_items_per_rank_per_node = num_items_per_rank + num_items_per_rank_remainder_per_node\n    if num_items_per_rank_per_node < num_items_per_rank:\n        num_items_per_rank_per_node = num_items_per_rank\n    if num_items_per_rank_per_node > num_items_per_rank + num_items_per_rank_remainder_per_node:\n        num_items_per_rank_per_node = num_items_per_rank + num_items_per_rank_remainder_per_node\n\n    # calculate the number of items to process per node\n    num_items_per_node = num_items_per_rank_per_node * distributed_env.world_size\n    if drop_last:\n        num_items_per_node = num_items_per_node - num_items_per_rank_remainder_per_node\n    num_items_per_node_remainder = num_items_per_node % distributed_env.num_nodes\n    num_items_per_node_remainder_per_rank = num_items_per_node_remainder // distributed_env.world_size\n\n    # calculate the number of items to process per node\n    num_items_per_node_per_rank = num_items_per_node + num_items_per_node_remainder_per_rank\n    if num_items_per_node"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    if not drop_last:\n        # if not dropping the last items, then we need to distribute the chunks equally among the ranks\n        # we calculate the number of items each rank should process\n        num_items = len(indexes)\n        num_items_per_rank = int(num_items / distributed_env.world_size)\n        # we distribute the chunks among the ranks\n        chunks_per_ranks = [\n            indexes[i * num_items_per_rank : (i + 1) * num_items_per_rank]\n            for i in range(distributed_env.world_size)\n        ]\n        # we associate the intervals of chunks to the ranks\n        chunks_intervals_per_ranks = [\n            chunk_intervals[i * num_items_per_rank : (i + 1) * num_items_per_rank]\n            for i in range(distributed_env.world_size)\n        ]\n\n    else:\n        # if dropping the last items, then we need to distribute the chunks equally among the ranks\n        # we calculate the number of items each rank should process\n        num_items = len(indexes)\n        num_items_per_rank = int(num_items / distributed_env.world_size)\n        # we distribute the chunks among the ranks\n        chunks_per_ranks = [\n            indexes[i * num_items_per_rank : (i + 1) * num_items_per_rank]\n            for i in range(distributed_env.world_size)\n        ]\n        # we associate the intervals of chunks to the ranks\n        chunks_intervals_per_ranks = [\n            chunk_intervals[i * num_items_per_rank : (i + 1) * num_items_per_rank]\n            for i in range(distributed_env.world_size)\n        ]\n\n    return chunks_per_ranks, chunks_intervals_per_ranks\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_is_last:\n            self._fn(item_metadata, output_dir, is_last=is_last)\n        else:\n            self._fn(item_metadata, output_dir)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_is_last:\n            self._fn(item_metadata, output_dir, is_last=is_last)\n        else:\n            self._fn(item_metadata, output_dir)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_is_last:\n            self._fn(item_metadata, output_dir, is_last=is_last)\n        else:\n            self._fn(item_metadata, output_dir)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_is_last:\n            self._fn(item_metadata, output_dir, is_last=is_last)\n        else:\n            self._fn(item_metadata, output_dir)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._device is None:\n            self._device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n        kwargs = {}\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_device:\n            if self._device is None:\n                self._device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n            kwargs = {\"device\": self._device}\n        else:\n            kwargs = {}\n\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._device is None:\n            self._device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n        if self._contains_is_last:\n            self._fn(item_metadata, output_dir, device=self._device, is_last=is_last)\n        else:\n            self._fn(item_metadata, output_dir, device=self._device)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._device is None:\n            self._device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n        kwargs = {}\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n\n        self._fn(item_metadata, output_dir, **kwargs)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        if self._contains_device:\n            if self._device is None:\n                self._device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n            kwargs[\"device\"] = self._device\n\n        self._fn(item_metadata, output_dir, **kwargs)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_is_last:\n            self._fn(item_metadata, output_dir, is_last=is_last)\n        else:\n            self._fn(item_metadata, output_dir)\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_is_last:\n            self._fn(item_metadata, output_dir, is_last=is_last)\n        else:\n            self._fn(item_metadata, output_dir)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        inputs = self._inputs\n        if self._contains_is_last:\n            inputs += (is_last,)\n\n        if self._device is None:\n            self._device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n        if self._contains_device:\n            inputs += (self._device,)\n\n        self._fn(item_metadata, output_dir, *inputs)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs: Dict[str, Any] = {}\n\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        if self._contains_device:\n            if self._device is None:\n                self._device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n            kwargs[\"device\"] = self._device\n\n        self._fn(item_metadata, output_dir, **kwargs)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if not _IS_IN_STUDIO:\n            optimize_dns_context()\n\n        if self._contains_is_last:\n            self._fn(item_metadata, output_dir, is_last=is_last)\n        else:\n            self._fn(item_metadata, output_dir)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        inputs = self._inputs if isinstance(self._inputs, Sequence) else [self._inputs]\n\n        if self._contains_device:\n            if self._device is None:\n                self._device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n            kwargs = {\"device\": self._device}\n        else:\n            kwargs = {}\n\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        # Set the device if not already set\n        if self._device is None:\n            self._device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n        # Set the keyword arguments to pass to the transformation function\n        kwargs = {}\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        # Call the transformation function\n        self._fn(item_metadata, output_dir, **kwargs)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        # If the transformation function contains a 'device' argument, then the device is set to the first available CUDA device.\n        if self._contains_device:\n            if self._device is None:\n                self._device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n        # If the transformation function contains an 'is_last' argument, then it is added to the keyword arguments passed to the transformation function.\n        kwargs = {}\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        # The transformation function is called with the provided arguments and keyword arguments.\n        self._fn(item_metadata, output_dir, **kwargs)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_is_last:\n            self._fn(item_metadata, output_dir, is_last=is_last)\n        else:\n            self._fn(item_metadata, output_dir)\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        # Get the device information if it is available in the signature of the transformation function.\n        if self._contains_device:\n            if self._device is None:\n                self._device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n            kwargs = {\"device\": self._device}\n        else:\n            kwargs = {}\n\n        # Add the 'is_last' argument if it is available in the signature of the transformation function.\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        # Call the transformation function with the item metadata and the output directory.\n        self._fn(item_metadata, output_dir, **kwargs)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        inputs = self._inputs\n\n        if self._contains_is_last:\n            kwargs = {\"is_last\": is_last}\n        else:\n            kwargs = {}\n\n        if self._contains_device:\n            if self._device is None:\n                self._device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n            kwargs[\"device\"] = self._device\n\n        self._fn(item_metadata, output_dir, **kwargs)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj.netloc, obj.path.lstrip(\"/\"))\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj.netloc, obj.path.lstrip(\"/\"))\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n                continue\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj.netloc, obj.path.lstrip(\"/\"))\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                logger.debug(f\"Object {obj.geturl()} does not exist. Sleeping for {sleep_time} seconds.\")\n                sleep(sleep_time)\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj.netloc, obj.path.lstrip(\"/\"))\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                logger.debug(f\"Object not found. Sleeping for {sleep_time} seconds.\")\n                sleep(sleep_time)\n            else:\n                raise\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj)\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n                continue\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj)\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n                continue\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj.netloc, obj.path.lstrip(\"/\"))\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj)\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj.netloc, obj.path.lstrip(\"/\"))\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj.netloc, obj.path.lstrip(\"/\"))\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                logger.info(f\"File {obj.geturl()} not found. Sleeping for {sleep_time} seconds.\")\n                sleep(sleep_time)\n            else:\n                raise\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj.netloc, obj.path.lstrip(\"/\"))\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj)\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                logger.debug(\"Object does not exist\")\n                sleep(sleep_time)\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj)\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj)\n        except s3.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n                continue\n            raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj)\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                logger.debug(f\"Object {obj} does not exist. Waiting {sleep_time} seconds before retrying.\")\n                sleep(sleep_time)\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj)\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n                continue\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj)\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n                continue\n            raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj.netloc, obj.path.lstrip(\"/\"))\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                logger.debug(\"File not found. Retrying in %s seconds...\", sleep_time)\n                sleep(sleep_time)\n            else:\n                raise\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.head_object(obj.netloc, obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n                continue\n            raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(obj)\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                logger.info(f\"File {obj.geturl()} does not exist. Waiting {sleep_time} seconds...\")\n                sleep(sleep_time)\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine. \"\n            \"Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if isinstance(batch_size, int) and batch_size > 1:\n            inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine. Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if isinstance(batch_size, int) and batch_size > 1:\n            inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n\n        data_"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine. Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if isinstance(batch_size, int) and batch_size > 1:\n            inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n\n        data_"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if isinstance(batch_size, int) and batch_size > 1:\n            inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if isinstance(batch_size, int) and batch_size > 1:\n            inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if isinstance(batch_size, int) and batch_size > 1:\n            inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine. Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if isinstance(batch_size, int) and batch_size > 1:\n            inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n\n        data_"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine. Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if isinstance(batch_size, int) and batch_size > 1:\n            inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n\n        data_"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine. \"\n            \"Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if isinstance(batch_size, int) and batch_size > 1:\n            inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine. Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine. Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine. Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine. Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if isinstance(batch_size, int) and batch_size > 1:\n            inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n\n        input_"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine. \"\n            \"Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size >"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if isinstance(batch_size, int) and batch_size > 1:\n            inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n\n       "}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > "}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine. Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if isinstance(batch_size, int) and batch_size > 1:\n            inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        input_dir"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine. Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if isinstance(batch_size, int) and batch_size > 1:\n            inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n\n        data_processor"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine. Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if isinstance(batch_size, int) and batch_size > 1:\n            inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n\n        input_dir"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if isinstance(batch_size, int) and batch_size > 1:\n            inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n       "}
{"namespace": "litdata.processing.functions.map", "completion": "    if not isinstance(fn, (FunctionType, partial)):\n        raise ValueError(f\"The provided {fn} isn't supported.\")\n\n    if not isinstance(inputs, Sequence):\n        raise ValueError(f\"The provided {inputs} isn't supported.\")\n\n    if not isinstance(output_dir, (str, Dir)):\n        raise ValueError(f\"The provided {output_dir} isn't supported.\")\n\n    if not isinstance(weights, (list, tuple, type(None))):\n        raise ValueError(f\"The provided {weights} isn't supported.\")\n\n    if not isinstance(num_workers, (int, type(None))):\n        raise ValueError(f\"The provided {num_workers} isn't supported.\")\n\n    if not isinstance(fast_dev_run, (bool, int)):\n        raise ValueError(f\"The provided {fast_dev_run} isn't supported.\")\n\n    if not isinstance(num_nodes, (int, type(None))):\n        raise ValueError(f\"The provided {num_nodes} isn't supported.\")\n\n    if not isinstance(machine, (str, type(None))):\n        raise ValueError(f\"The provided {machine} isn't supported.\")\n\n    if not isinstance(num_downloaders, (int, type(None))):\n        raise ValueError(f\"The provided {num_downloaders} isn't supported.\")\n\n    if not isinstance(num_uploaders, (int, type(None))):\n        raise ValueError(f\"The provided {num_uploaders} isn't supported.\")\n\n    if not isinstance(reorder_files, bool):\n        raise ValueError(f\"The provided {reorder_files} isn't supported.\")\n\n    if not isinstance(error_when_not_empty, bool):\n        raise ValueError(f\"The provided {error_when_not_empty} isn't supported.\")\n\n    if not isinstance(reader, (BaseReader, type(None))):\n        raise ValueError(f\"The provided {reader} isn't"}
{"namespace": "litdata.processing.functions.map", "completion": "    if not isinstance(fn, (FunctionType, partial)):\n        raise ValueError(f\"The provided {fn} isn't supported.\")\n\n    if not isinstance(inputs, Sequence):\n        raise ValueError(f\"The provided {inputs} isn't supported.\")\n\n    if not isinstance(output_dir, (str, Dir)):\n        raise ValueError(f\"The provided {output_dir} isn't supported.\")\n\n    if not isinstance(weights, (list, tuple, type(None))):\n        raise ValueError(f\"The provided {weights} isn't supported.\")\n\n    if not isinstance(num_workers, (int, type(None))):\n        raise ValueError(f\"The provided {num_workers} isn't supported.\")\n\n    if not isinstance(fast_dev_run, (bool, int)):\n        raise ValueError(f\"The provided {fast_dev_run} isn't supported.\")\n\n    if not isinstance(num_nodes, (int, type(None))):\n        raise ValueError(f\"The provided {num_nodes} isn't supported.\")\n\n    if not isinstance(machine, (str, type(None))):\n        raise ValueError(f\"The provided {machine} isn't supported.\")\n\n    if not isinstance(num_downloaders, (int, type(None))):\n        raise ValueError(f\"The provided {num_downloaders} isn't supported.\")\n\n    if not isinstance(num_uploaders, (int, type(None))):\n        raise ValueError(f\"The provided {num_uploaders} isn't supported.\")\n\n    if not isinstance(reorder_files, bool):\n        raise ValueError(f\"The provided {reorder_files} isn't supported.\")\n\n    if not isinstance(error_when_not_empty, bool):\n        raise ValueError(f\"The provided {error_when_not_empty} isn't supported.\")\n\n    if not isinstance(reader, (BaseReader, type(None))):\n        raise ValueError(f\"The provided {reader} isn't"}
{"namespace": "litdata.processing.functions.map", "completion": "    # Get the input directory\n    input_dir = _get_input_dir(inputs)\n\n    # Get the number of workers\n    num_workers = num_workers or _get_default_num_workers()\n\n    # Get the number of nodes\n    num_nodes = num_nodes or 1\n\n    # Get the number of downloaders\n    num_downloaders = num_downloaders or 1\n\n    # Get the number of uploaders\n    num_uploaders = num_uploaders or 1\n\n    # Get the number of workers\n    num_workers = num_workers or _get_default_num_workers()\n\n    # Get the number of downloaders\n    num_downloaders = num_downloaders or 1\n\n    # Get the number of uploaders\n    num_uploaders = num_uploaders or 1\n\n    # Get the number of workers\n    num_workers = num_workers or _get_default_num_workers()\n\n    # Get the number of downloaders\n    num_downloaders = num_downloaders or 1\n\n    # Get the number of uploaders\n    num_uploaders = num_uploaders or 1\n\n    # Get the number of workers\n    num_workers = num_workers or _get_default_num_workers()\n\n    # Get the number of downloaders\n    num_downloaders = num_downloaders or 1\n\n    # Get the number of uploaders\n    num_uploaders = num_uploaders or 1\n\n    # Get the number of workers\n    num_workers = num_workers or _get_default_num_workers()\n\n    # Get the number of downloaders\n    num_downloaders = num_downloaders or 1\n\n    # Get the number of uploaders\n    num_uploaders = num_uploaders or 1\n\n    # Get the number of workers\n    num_workers = num_workers or _get_default_num_workers()\n\n    # Get the number of downloaders\n    num_downloaders = num_downloaders or 1\n\n    # Get"}
{"namespace": "litdata.processing.functions.map", "completion": "    if not isinstance(fn, (FunctionType, partial)):\n        raise ValueError(f\"The provided {fn} isn't supported.\")\n\n    if not isinstance(inputs, (list, tuple)):\n        raise ValueError(f\"The provided {inputs} isn't supported.\")\n\n    if not isinstance(output_dir, (str, Dir)):\n        raise ValueError(f\"The provided {output_dir} isn't supported.\")\n\n    if not isinstance(weights, (list, tuple)) and weights is not None:\n        raise ValueError(f\"The provided {weights} isn't supported.\")\n\n    if not isinstance(num_workers, int) and num_workers is not None:\n        raise ValueError(f\"The provided {num_workers} isn't supported.\")\n\n    if not isinstance(fast_dev_run, (bool, int)) and fast_dev_run is not None:\n        raise ValueError(f\"The provided {fast_dev_run} isn't supported.\")\n\n    if not isinstance(num_nodes, int) and num_nodes is not None:\n        raise ValueError(f\"The provided {num_nodes} isn't supported.\")\n\n    if machine is not None and not isinstance(machine, str):\n        raise ValueError(f\"The provided {machine} isn't supported.\")\n\n    if not isinstance(num_downloaders, int) and num_downloaders is not None:\n        raise ValueError(f\"The provided {num_downloaders} isn't supported.\")\n\n    if not isinstance(num_uploaders, int) and num_uploaders is not None:\n        raise ValueError(f\"The provided {num_uploaders} isn't supported.\")\n\n    if not isinstance(reorder_files, bool):\n        raise ValueError(f\"The provided {reorder_files} isn't supported.\")\n\n    if not isinstance(error_when_not_empty, bool):\n        raise ValueError(f\"The provided {error_when_not_empty} isn't supported.\")\n\n    if not isinstance(reader, (Base"}
{"namespace": "litdata.processing.functions.map", "completion": "    if not isinstance(fn, (FunctionType, partial)):\n        raise ValueError(f\"The provided {fn} isn't supported.\")\n\n    if not isinstance(inputs, Sequence):\n        raise ValueError(f\"The provided {inputs} isn't a sequence.\")\n\n    if not isinstance(output_dir, (str, Dir)):\n        raise ValueError(f\"The provided {output_dir} isn't a valid directory.\")\n\n    if not isinstance(weights, (list, tuple, type(None))):\n        raise ValueError(f\"The provided {weights} isn't a list of weights.\")\n\n    if not isinstance(num_workers, (int, type(None))):\n        raise ValueError(f\"The provided {num_workers} isn't a valid number of workers.\")\n\n    if not isinstance(fast_dev_run, (bool, int)):\n        raise ValueError(f\"The provided {fast_dev_run} isn't a valid fast_dev_run parameter.\")\n\n    if not isinstance(num_nodes, (int, type(None))):\n        raise ValueError(f\"The provided {num_nodes} isn't a valid number of nodes.\")\n\n    if not isinstance(machine, (str, type(None))):\n        raise ValueError(f\"The provided {machine} isn't a valid machine.\")\n\n    if not isinstance(num_downloaders, (int, type(None))):\n        raise ValueError(f\"The provided {num_downloaders} isn't a valid number of downloaders.\")\n\n    if not isinstance(num_uploaders, (int, type(None))):\n        raise ValueError(f\"The provided {num_uploaders} isn't a valid number of uploaders.\")\n\n    if not isinstance(reorder_files, bool):\n        raise ValueError(f\"The provided {reorder_files} isn't a valid reorder_files parameter.\")\n\n    if not isinstance(error_when_not_empty, bool):\n        raise ValueError(f\"The provided {error_when_not_empty} isn"}
{"namespace": "litdata.processing.functions.map", "completion": "    if not isinstance(inputs, Sequence):\n        raise ValueError(f\"The provided inputs {inputs} isn't a sequence.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs {inputs} is empty.\")\n\n    if not isinstance(fn, (FunctionType, partial)):\n        raise ValueError(f\"The provided function {fn} isn't supported.\")\n\n    if isinstance(output_dir, Dir):\n        output_dir = output_dir.path\n\n    if not isinstance(output_dir, str):\n        raise ValueError(f\"The provided output_dir {output_dir} isn't a string.\")\n\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    if not os.path.isdir(output_dir):\n        raise ValueError(f\"The provided output_dir {output_dir} isn't a directory.\")\n\n    if fast_dev_run is True:\n        fast_dev_run = 1\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if num_workers <= 0:\n        raise ValueError(f\"The provided num_workers {num_workers} is invalid.\")\n\n    if weights is None:\n        weights = [1 for _ in range(len(inputs))]\n\n    if len(weights) != len(inputs):\n        raise ValueError(f\"The provided weights {weights} doesn't match the number of inputs {len(inputs)}.\")\n\n    if num_nodes is not None and num_nodes <= 0:\n        raise ValueError(f\"The provided num_nodes {num_nodes} is invalid.\")\n\n    if machine is not None and machine == \"\":\n        raise ValueError(f\"The provided machine {machine} is invalid.\")\n\n    if num_downloaders is not None and num_downloaders <= 0:\n        raise ValueError(f\"The provided num_downloaders {num_downloaders} is invalid.\")\n\n    if"}
{"namespace": "litdata.processing.functions.map", "completion": "    if isinstance(output_dir, str):\n        output_dir = Dir(output_dir)\n\n    if fast_dev_run:\n        if isinstance(fast_dev_run, bool):\n            fast_dev_run = 1\n\n        if fast_dev_run > len(inputs):\n            raise ValueError(\n                f\"fast_dev_run={fast_dev_run} is greater than the number of inputs={len(inputs)}.\"\n            )\n\n        inputs = inputs[:fast_dev_run]\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if num_nodes is None:\n        num_nodes = 1\n\n    if num_workers > num_nodes * _get_default_num_workers():\n        raise ValueError(\n            f\"num_workers={num_workers} is greater than the maximum number of workers={num_nodes * _get_default_num_workers()}.\"\n        )\n\n    if num_downloaders is None:\n        num_downloaders = num_workers\n\n    if num_uploaders is None:\n        num_uploaders = num_workers\n\n    if num_downloaders > num_workers:\n        raise ValueError(\n            f\"num_downloaders={num_downloaders} is greater than the number of workers={num_workers}.\"\n        )\n\n    if num_uploaders > num_workers:\n        raise ValueError(\n            f\"num_uploaders={num_uploaders} is greater than the number of workers={num_workers}.\"\n        )\n\n    if weights is None:\n        weights = [1] * len(inputs)\n\n    if len(weights) != len(inputs):\n        raise ValueError(\n            f\"The length of weights={len(weights)} doesn't match the length of inputs={len(inputs)}.\"\n        )\n\n    if len(weights) != len(set(weights)):\n        raise ValueError(f\"The weights={weights} contains duplicates.\")\n\n    if"}
{"namespace": "litdata.processing.functions.map", "completion": "    if _IS_IN_STUDIO:\n        raise ValueError(\n            \"map() is not supported in the Lightning AI studio. \"\n            \"Please use the map() function in the notebook interface.\"\n        )\n\n    if not isinstance(fn, Callable):\n        raise ValueError(f\"The provided {fn} isn't a callable.\")\n\n    if not isinstance(inputs, Sequence):\n        raise ValueError(f\"The provided {inputs} isn't a sequence.\")\n\n    if not isinstance(output_dir, (str, Dir)):\n        raise ValueError(f\"The provided {output_dir} isn't a string or a Dir object.\")\n\n    if weights is not None and not isinstance(weights, list):\n        raise ValueError(f\"The provided {weights} isn't a list.\")\n\n    if weights is not None and len(weights) != len(inputs):\n        raise ValueError(f\"The provided weights {weights} doesn't match the number of inputs {len(inputs)}.\")\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if num_workers < 0:\n        raise ValueError(f\"The provided num_workers {num_workers} is invalid.\")\n\n    if fast_dev_run is True:\n        num_workers = 1\n\n    if num_workers == 0:\n        raise ValueError(f\"The provided num_workers {num_workers} is invalid.\")\n\n    if num_nodes is not None and num_nodes < 0:\n        raise ValueError(f\"The provided num_nodes {num_nodes} is invalid.\")\n\n    if machine is not None and machine not in [\"gpu\", \"cpu\"]:\n        raise ValueError(f\"The provided machine {machine} is invalid.\")\n\n    if num_downloaders is not None and num_downloaders < 0:\n        raise ValueError(f\"The provided num_downloaders {num_downloaders} is invalid.\")\n\n    if num_uploaders is not"}
{"namespace": "litdata.processing.functions.map", "completion": "    # Check inputs\n    if not callable(fn):\n        raise ValueError(f\"The provided {fn} isn't a callable function.\")\n\n    if not isinstance(inputs, Sequence):\n        raise ValueError(f\"The provided {inputs} isn't a sequence of inputs.\")\n\n    if not isinstance(output_dir, (str, Dir)):\n        raise ValueError(f\"The provided {output_dir} isn't a valid output directory.\")\n\n    if weights is not None and len(weights) != len(inputs):\n        raise ValueError(f\"The provided weights {weights} should have the same length as the inputs {inputs}.\")\n\n    if num_workers is not None and num_workers <= 0:\n        raise ValueError(f\"The provided num_workers {num_workers} should be greater than 0.\")\n\n    if num_nodes is not None and num_nodes <= 0:\n        raise ValueError(f\"The provided num_nodes {num_nodes} should be greater than 0.\")\n\n    if machine is not None and machine not in (\"gpu\", \"cpu\"):\n        raise ValueError(f\"The provided machine {machine} should be either 'gpu' or 'cpu'.\")\n\n    if num_downloaders is not None and num_downloaders <= 0:\n        raise ValueError(f\"The provided num_downloaders {num_downloaders} should be greater than 0.\")\n\n    if num_uploaders is not None and num_uploaders <= 0:\n        raise ValueError(f\"The provided num_uploaders {num_uploaders} should be greater than 0.\")\n\n    if batch_size is not None and batch_size <= 0:\n        raise ValueError(f\"The provided batch_size {batch_size} should be greater than 0.\")\n\n    # Get the input directory\n    input_dir = _get_input_dir(inputs)\n\n    # Create the output directory\n    output_dir = Dir(output_dir)\n    if not output_dir.exists():\n        output_dir.mkdir()\n    elif error"}
{"namespace": "litdata.processing.functions.map", "completion": "    if not isinstance(fn, (FunctionType, partial)):\n        raise ValueError(f\"The provided {fn} isn't supported.\")\n\n    if not isinstance(inputs, Sequence):\n        raise ValueError(f\"The provided {inputs} isn't supported.\")\n\n    if not isinstance(output_dir, (str, Dir)):\n        raise ValueError(f\"The provided {output_dir} isn't supported.\")\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if num_nodes is None:\n        num_nodes = 1\n\n    if num_downloaders is None:\n        num_downloaders = num_workers\n\n    if num_uploaders is None:\n        num_uploaders = num_workers\n\n    if weights is None:\n        weights = [1] * len(inputs)\n\n    if not isinstance(weights, Sequence):\n        raise ValueError(f\"The provided {weights} isn't supported.\")\n\n    if len(weights) != len(inputs):\n        raise ValueError(f\"The provided {weights} isn't supported.\")\n\n    if isinstance(inputs[0], str):\n        input_dir = _get_input_dir(inputs)\n        if input_dir is None:\n            raise ValueError(f\"The provided {inputs} doesn't contain any filepaths.\")\n\n        input_dir = Dir(input_dir)\n\n    elif isinstance(inputs[0], Dir):\n        input_dir = inputs[0]\n\n    else:\n        raise ValueError(f\"The provided {inputs} isn't supported.\")\n\n    if isinstance(output_dir, str):\n        output_dir = Dir(output_dir)\n\n    if not output_dir.is_absolute():\n        output_dir = input_dir.join(output_dir)\n\n    if not output_dir.exists():\n        output_dir.mkdir(parents=True, exist_ok=True)\n\n    if not output_dir.is_"}
{"namespace": "litdata.processing.functions.map", "completion": "    if not isinstance(fn, (FunctionType, partial)):\n        raise ValueError(f\"The provided {fn} isn't a valid function.\")\n\n    if not isinstance(inputs, Sequence):\n        raise ValueError(f\"The provided {inputs} isn't a valid sequence.\")\n\n    if not isinstance(output_dir, (str, Dir)):\n        raise ValueError(f\"The provided {output_dir} isn't a valid directory.\")\n\n    if weights is not None and len(weights) != len(inputs):\n        raise ValueError(\n            f\"The provided weights {weights} should have the same length as the inputs {inputs}.\"\n        )\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if fast_dev_run is True:\n        num_workers = 1\n\n    if num_workers > len(inputs):\n        num_workers = len(inputs)\n\n    if num_workers > 1:\n        num_workers = num_workers - 1\n\n    if num_workers < 1:\n        num_workers = 1\n\n    if isinstance(fast_dev_run, int):\n        fast_dev_run = min(fast_dev_run, len(inputs))\n\n    if fast_dev_run is not False:\n        inputs = inputs[:fast_dev_run]\n\n    if isinstance(output_dir, str):\n        output_dir = Dir(output_dir)\n\n    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"The provided {output_dir} isn't a valid directory.\")\n\n    if output_dir.is_remote:\n        if num_nodes is None:\n            num_nodes = 1\n\n        if machine is None:\n            machine = \"local\"\n\n    if num_nodes is None:\n        num_nodes = 1\n\n    if machine is None:\n        machine = \"local\"\n\n    if num_downloaders is None:\n        num_download"}
{"namespace": "litdata.processing.functions.map", "completion": "    if _IS_IN_STUDIO:\n        raise ValueError(\n            \"map is not supported in the Lightning AI Cloud environment. \"\n            \"Please use the map function in the notebook instead.\"\n        )\n\n    if not isinstance(output_dir, Dir):\n        output_dir = Dir(output_dir)\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if fast_dev_run:\n        if isinstance(fast_dev_run, bool):\n            fast_dev_run = 1\n        num_workers = 1\n        fast_dev_run = min(fast_dev_run, len(inputs))\n        inputs = inputs[:fast_dev_run]\n\n    if num_workers > 1:\n        if num_downloaders is None:\n            num_downloaders = num_workers\n\n        if num_uploaders is None:\n            num_uploaders = num_workers\n\n    if weights is not None:\n        if len(weights) != len(inputs):\n            raise ValueError(\n                f\"The number of weights ({len(weights)}) doesn't match the number of inputs ({len(inputs)})\"\n            )\n\n    if reorder_files:\n        inputs = sorted(inputs, key=_get_input_dir)\n\n    if num_workers > 1:\n        _execute(\n            _map,\n            inputs,\n            output_dir,\n            fn,\n            weights=weights,\n            num_workers=num_workers,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            error_when_not_empty=error_when_not_empty,\n            reader=reader,\n            batch_size=batch_size,\n        )\n    else:\n        _map(\n            inputs,\n            output_dir,\n            fn,\n            weights=weights,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            error"}
{"namespace": "litdata.processing.functions.map", "completion": "    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if num_nodes is not None and machine is not None:\n        raise ValueError(\"Only one of `num_nodes` or `machine` can be specified.\")\n\n    if machine is not None and num_nodes is None:\n        raise ValueError(\"`num_nodes` must be specified when `machine` is specified.\")\n\n    if num_nodes is not None and num_nodes < 1:\n        raise ValueError(\"`num_nodes` must be a positive integer.\")\n\n    if machine is not None and machine not in [\"gpu\", \"tpu\"]:\n        raise ValueError(\"`machine` must be either `gpu` or `tpu`.\")\n\n    if num_workers < 1:\n        raise ValueError(\"`num_workers` must be a positive integer.\")\n\n    if fast_dev_run is True or (isinstance(fast_dev_run, int) and fast_dev_run > 1):\n        num_workers = 1\n\n    if batch_size is not None and batch_size < 1:\n        raise ValueError(\"`batch_size` must be a positive integer.\")\n\n    if num_downloaders is not None and num_downloaders < 1:\n        raise ValueError(\"`num_downloaders` must be a positive integer.\")\n\n    if num_uploaders is not None and num_uploaders < 1:\n        raise ValueError(\"`num_uploaders` must be a positive integer.\")\n\n    if isinstance(inputs, (tuple, list)):\n        inputs = list(inputs)\n    else:\n        inputs = [inputs]\n\n    if len(inputs) == 0:\n        raise ValueError(\"`inputs` must contain at least one input.\")\n\n    if len(inputs) > 1:\n        input_dir = _get_input_dir(inputs)\n    else:\n        input_dir = None\n\n    if output_dir is None:\n        raise ValueError(\"`output_dir` must be specified.\")\n\n    if is"}
{"namespace": "litdata.processing.functions.map", "completion": "    if not isinstance(fn, (FunctionType, partial)):\n        raise ValueError(f\"The provided {fn} isn't supported.\")\n\n    if not isinstance(inputs, Sequence):\n        raise ValueError(f\"The provided {inputs} isn't a sequence.\")\n\n    if not isinstance(output_dir, (str, Dir)):\n        raise ValueError(f\"The provided {output_dir} isn't a string or Dir object.\")\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if isinstance(output_dir, str):\n        output_dir = Dir(output_dir)\n\n    if output_dir.is_remote:\n        if num_nodes is None:\n            num_nodes = 1\n\n        if machine is None:\n            machine = \"gpu:1\"\n\n    if fast_dev_run is True:\n        num_workers = 1\n\n    if fast_dev_run is not False and not isinstance(fast_dev_run, int):\n        raise ValueError(f\"The provided {fast_dev_run} isn't a valid value.\")\n\n    if fast_dev_run is not False and fast_dev_run < 1:\n        raise ValueError(f\"The provided {fast_dev_run} isn't a valid value.\")\n\n    if fast_dev_run is not False:\n        inputs = inputs[:fast_dev_run]\n\n    if num_workers > len(inputs):\n        num_workers = len(inputs)\n\n    if num_workers > 1:\n        if weights is None:\n            weights = [1] * len(inputs)\n\n        if len(weights) != len(inputs):\n            raise ValueError(f\"The provided weights {weights} isn't a valid value.\")\n\n    if num_workers > 1:\n        if weights is not None:\n            weights = [int(weight) for weight in weights]\n\n    if num_workers > 1 and (num_downloaders is None or num"}
{"namespace": "litdata.processing.functions.map", "completion": "    if not isinstance(inputs, Sequence):\n        raise ValueError(\"Inputs must be a sequence.\")\n\n    if not isinstance(output_dir, (str, Dir)):\n        raise ValueError(\"Output directory must be a string path or a Dir object.\")\n\n    if len(inputs) == 0:\n        raise ValueError(\"Inputs must be a non-empty sequence.\")\n\n    if not isinstance(fn, (FunctionType, partial)):\n        raise ValueError(\"The provided fn is not a function.\")\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if num_nodes is None:\n        num_nodes = 1\n\n    if machine is None:\n        machine = \"gpu:v100-v100x1\"\n\n    if num_downloaders is None:\n        num_downloaders = 1\n\n    if num_uploaders is None:\n        num_uploaders = 1\n\n    if batch_size is None:\n        batch_size = 1\n\n    if weights is None:\n        weights = [1] * len(inputs)\n\n    if len(weights) != len(inputs):\n        raise ValueError(\"The length of weights must be equal to the length of inputs.\")\n\n    if not isinstance(fast_dev_run, bool) and not isinstance(fast_dev_run, int):\n        raise ValueError(\"Fast dev run must be a boolean or an integer.\")\n\n    if isinstance(fast_dev_run, int) and fast_dev_run < 0:\n        raise ValueError(\"Fast dev run must be a positive integer.\")\n\n    if not isinstance(reorder_files, bool):\n        raise ValueError(\"Reorder files must be a boolean.\")\n\n    if not isinstance(error_when_not_empty, bool):\n        raise ValueError(\"Error when not empty must be a boolean.\")\n\n    if not isinstance(reader, BaseReader) and reader is not None:\n        raise ValueError(\"The reader must be a BaseReader.\")\n\n    if isinstance(reader,"}
{"namespace": "litdata.processing.functions.map", "completion": "    if _IS_IN_STUDIO:\n        raise RuntimeError(\n            \"The map function is not supported in the Lightning AI Studio environment. Use the map_local function instead.\"\n        )\n\n    if not isinstance(inputs, Sequence):\n        raise ValueError(\n            f\"The provided inputs should be a sequence of elements, but got {type(inputs)}.\"\n        )\n\n    if not isinstance(fn, (FunctionType, partial)):\n        raise ValueError(f\"The provided fn should be a function, but got {type(fn)}.\")\n\n    if not isinstance(output_dir, (str, Dir)):\n        raise ValueError(\n            f\"The provided output_dir should be a string or a Dir object, but got {type(output_dir)}.\"\n        )\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if fast_dev_run is True:\n        num_workers = 1\n\n    if isinstance(fast_dev_run, int) and fast_dev_run > 1:\n        num_workers = 1\n\n    if isinstance(inputs, (list, tuple)):\n        inputs = list(inputs)\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should contain at least one element, but got {len(inputs)}.\")\n\n    if weights is not None and len(weights) != len(inputs):\n        raise ValueError(\n            f\"The weights should be a list of the same size as the inputs, but got {len(weights)} weights for {len(inputs)} inputs.\"\n        )\n\n    if not isinstance(num_workers, int) or num_workers <= 0:\n        raise ValueError(f\"The provided num_workers should be a positive integer, but got {num_workers}.\")\n\n    if not isinstance(reorder_files, bool):\n        raise ValueError(f\"The provided reorder_files should be a boolean, but got {type(reorder_files)}.\")"}
{"namespace": "litdata.processing.functions.map", "completion": "    if _IS_IN_STUDIO:\n        raise RuntimeError(\"map() is not supported in Lightning AI Cloud.\")\n\n    # Check for input type\n    if not isinstance(fn, (FunctionType, partial)):\n        raise ValueError(f\"The provided {fn} isn't supported. It should be a function.\")\n\n    # Check for output type\n    if not isinstance(output_dir, (str, Dir)):\n        raise ValueError(f\"The provided {output_dir} isn't supported. It should be a string or a Dir object.\")\n\n    if isinstance(output_dir, str):\n        output_dir = Dir(output_dir)\n\n    # Check for weights\n    if weights is not None and len(inputs) != len(weights):\n        raise ValueError(f\"The provided weights should be of the same length as the inputs.\")\n\n    # Check for fast_dev_run\n    if isinstance(fast_dev_run, bool):\n        if fast_dev_run:\n            fast_dev_run = len(inputs)\n        else:\n            fast_dev_run = 0\n    elif isinstance(fast_dev_run, int):\n        if fast_dev_run > len(inputs):\n            raise ValueError(f\"The provided fast_dev_run ({fast_dev_run}) should be less than the number of inputs ({len(inputs)}).\")\n    else:\n        raise ValueError(f\"The provided fast_dev_run ({fast_dev_run}) isn't supported. It should be a boolean or an integer.\")\n\n    # Check for num_workers\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    # Check for num_nodes\n    if num_nodes is not None and num_nodes <= 0:\n        raise ValueError(f\"The provided num_nodes ({num_nodes}) should be greater than 0.\")\n\n    # Check for machine\n    if machine is not None and machine not in [\"x1.16xlarge\", \"x1.32xlarge\"]:\n        raise"}
{"namespace": "litdata.processing.functions.map", "completion": "    if not isinstance(inputs, Sequence):\n        raise ValueError(f\"The provided inputs {inputs} should be a sequence of inputs.\")\n\n    if not isinstance(fn, (FunctionType, partial)):\n        raise ValueError(f\"The provided function {fn} should be a function.\")\n\n    if not isinstance(output_dir, (str, Dir)):\n        raise ValueError(f\"The provided output_dir {output_dir} should be a string or a Dir object.\")\n\n    if weights and len(weights) != len(inputs):\n        raise ValueError(f\"The provided weights {weights} should be the same length as the inputs {inputs}.\")\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if num_workers > len(inputs):\n        num_workers = len(inputs)\n\n    if fast_dev_run is True:\n        fast_dev_run = 1\n\n    if isinstance(fast_dev_run, int):\n        if fast_dev_run > len(inputs):\n            fast_dev_run = len(inputs)\n        inputs = inputs[:fast_dev_run]\n        weights = weights[:fast_dev_run] if weights else None\n\n    if num_workers > 1:\n        if not _IS_IN_STUDIO:\n            if num_nodes is None:\n                num_nodes = 1\n\n            if machine is None:\n                machine = \"gpu\"\n\n            if num_downloaders is None:\n                num_downloaders = 1\n\n            if num_uploaders is None:\n                num_uploaders = 1\n\n            if reader is None:\n                reader = BaseReader()\n\n        if _IS_IN_STUDIO:\n            # If running in the studio, we need to use a single worker\n            num_workers = 1\n\n        if num_nodes is None:\n            num_nodes = 1\n\n        if machine is None:\n            machine = \"gpu\"\n\n        if num_download"}
{"namespace": "litdata.processing.functions.map", "completion": "    if isinstance(inputs, (tuple, list)):\n        inputs = tuple(inputs)\n    else:\n        inputs = (inputs,)\n\n    if not isinstance(output_dir, Dir):\n        output_dir = Dir(output_dir)\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if num_workers > 1 and fast_dev_run:\n        num_workers = 1\n\n    if num_workers > 1 and _IS_IN_STUDIO:\n        num_workers = 1\n\n    if num_workers > 1 and torch.cuda.is_available():\n        num_workers = min(torch.cuda.device_count(), num_workers)\n\n    if weights is None:\n        weights = [1] * len(inputs)\n\n    if len(weights) != len(inputs):\n        raise ValueError(f\"The number of weights {len(weights)} should match the number of inputs {len(inputs)}.\")\n\n    if num_nodes is not None and machine is None:\n        raise ValueError(\"If num_nodes is specified, machine should also be specified.\")\n\n    if machine is not None and num_nodes is None:\n        raise ValueError(\"If machine is specified, num_nodes should also be specified.\")\n\n    if num_nodes is not None and num_nodes > 1 and machine is None:\n        raise ValueError(\"If num_nodes is greater than 1, machine should also be specified.\")\n\n    if machine is not None and num_nodes is None:\n        num_nodes = 1\n\n    if machine is not None and num_nodes is not None:\n        if num_nodes > 1 and machine not in [\"GPU\", \"TPU\"]:\n            raise ValueError(f\"{machine} is not a valid machine type for distributed execution.\")\n\n    if machine is not None and num_nodes is not None and num_workers > 1:\n        raise ValueError(\"Distributed execution is only supported with one worker per node.\")"}
{"namespace": "litdata.processing.functions.map", "completion": "    if not isinstance(inputs, (list, tuple)):\n        inputs = [inputs]\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if fast_dev_run is True:\n        num_workers = 0\n\n    if num_workers == 0:\n        num_workers = 1\n\n    if not isinstance(inputs[0], (list, tuple)):\n        inputs = [inputs]\n\n    if len(inputs) > 1:\n        input_dir = _get_input_dir(inputs)\n    else:\n        input_dir = None\n\n    if input_dir is None:\n        raise ValueError(f\"The provided inputs {inputs} didn't contain any filepaths.\")\n\n    if _IS_IN_STUDIO:\n        if machine is None:\n            raise ValueError(\"A machine must be specified when running in the studio.\")\n        if num_nodes is None:\n            num_nodes = 1\n\n    if machine is None:\n        machine = \"local\"\n\n    if num_nodes is None:\n        num_nodes = 1\n\n    if num_downloaders is None:\n        num_downloaders = num_workers\n\n    if num_uploaders is None:\n        num_uploaders = num_workers\n\n    if reorder_files:\n        _assert_dir_has_index_file(input_dir)\n\n    _assert_dir_is_empty(output_dir, error_when_not_empty)\n\n    if reader is None:\n        reader = BaseReader()\n\n    if batch_size is None:\n        batch_size = reader.batch_size\n\n    if batch_size is None:\n        batch_size = 1\n\n    if batch_size < 1:\n        raise ValueError(\"batch_size must be greater than 0.\")\n\n    if num_workers > 1:\n        if _IS_IN_STUDIO:\n            raise ValueError(\"num_workers must be 1 when running in the studio"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client()\n    while True:\n        try:\n            index, files = queue_in.get(timeout=1)\n        except Empty:\n            continue\n        for file in files:\n            obj = parse.urlparse(file)\n            if obj.scheme == \"s3\":\n                _wait_for_file_to_exist(s3, obj)\n                s3.download_file(obj.netloc, obj.path.lstrip(\"/\"), os.path.join(cache_dir, obj.path.lstrip(\"/\")))\n            else:\n                shutil.copyfile(file, os.path.join(cache_dir, obj.path.lstrip(\"/\")))\n        queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client(input_dir.url)\n\n    while True:\n        try:\n            task = queue_in.get(timeout=5)\n        except Empty:\n            continue\n\n        if task is None:\n            break\n\n        index, files = task\n        for file in files:\n            obj = parse.urlparse(file)\n            file_path = os.path.join(cache_dir, obj.path.lstrip(\"/\"))\n\n            if not os.path.exists(file_path):\n                _wait_for_disk_usage_higher_than_threshold(input_dir.path, sleep_time=2)\n                _wait_for_file_to_exist(s3, obj, sleep_time=2)\n                s3.download(file, file_path)\n\n        queue_out.put(index)\n\n    return\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    # Create a client for the source directory.\n    s3 = S3Client(input_dir)\n\n    # Create a local cache directory.\n    os.makedirs(cache_dir, exist_ok=True)\n\n    # Create a local cache directory for the data files.\n    os.makedirs(os.path.join(cache_dir, \"data\"), exist_ok=True)\n\n    # Create a local cache directory for the index file.\n    os.makedirs(os.path.join(cache_dir, \"index\"), exist_ok=True)\n\n    # Create a local cache directory for the index file.\n    os.makedirs(os.path.join(cache_dir, \"index\", \"tmp\"), exist_ok=True)\n\n    # Create a local cache directory for the index file.\n    os.makedirs(os.path.join(cache_dir, \"index\", \"tmp\", \"data\"), exist_ok=True)\n\n    # Create a local cache directory for the index file.\n    os.makedirs(os.path.join(cache_dir, \"index\", \"tmp\", \"index\"), exist_ok=True)\n\n    # Create a local cache directory for the index file.\n    os.makedirs(os.path.join(cache_dir, \"index\", \"tmp\", \"meta\"), exist_ok=True)\n\n    # Create a local cache directory for the index file.\n    os.makedirs(os.path.join(cache_dir, \"index\", \"tmp\", \"meta\", \"data\"), exist_ok=True)\n\n    # Create a local cache directory for the index file.\n    os.makedirs(os.path.join(cache_dir, \"index\", \"tmp\", \"meta\", \"index\"), exist_ok=True)\n\n    # Create a local cache directory for the index file.\n    os.makedirs(os.path.join(cache_dir, \"index\", \"tmp\", \"meta\", \"meta\"), exist_ok=True)\n\n    # Create a local cache directory for the index file.\n    os.makedirs(os.path.join(cache_"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    # Initialize the S3 client\n    s3 = S3Client()\n\n    # Initialize the cache\n    cache = Cache(cache_dir)\n\n    # Initialize a progress bar\n    pbar = _tqdm(total=0, position=0, desc=\"Download\", unit=\"files\")\n\n    # Initialize a counter for the total number of files that have been downloaded\n    total_downloaded = 0\n\n    # Initialize a counter for the total number of files that have been skipped\n    total_skipped = 0\n\n    # Initialize a counter for the total number of files that have been failed\n    total_failed = 0\n\n    # Initialize a counter for the total number of files that have been downloaded\n    total_downloaded = 0\n\n    # Initialize a counter for the total number of files that have been skipped\n    total_skipped = 0\n\n    # Initialize a counter for the total number of files that have been failed\n    total_failed = 0\n\n    # Initialize a counter for the total number of files that have been downloaded\n    total_downloaded = 0\n\n    # Initialize a counter for the total number of files that have been skipped\n    total_skipped = 0\n\n    # Initialize a counter for the total number of files that have been failed\n    total_failed = 0\n\n    # Initialize a counter for the total number of files that have been downloaded\n    total_downloaded = 0\n\n    # Initialize a counter for the total number of files that have been skipped\n    total_skipped = 0\n\n    # Initialize a counter for the total number of files that have been failed\n    total_failed = 0\n\n    # Initialize a counter for the total number of files that have been downloaded\n    total_downloaded = 0\n\n    # Initialize a counter for the total number of files that have been skipped\n    total_skipped = 0\n\n    # Initialize a counter for the total number of files that have been failed\n    total_failed = 0\n\n    # Initialize a counter for the total number of files that have been downloaded\n    total_downloaded = 0\n\n    # Initialize a counter for the total number of files that have been"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client(input_dir.netloc)\n    s3.client.download_file(input_dir.netloc, input_dir.path, cache_dir)\n\n    while True:\n        try:\n            index, file_paths = queue_in.get()\n        except Empty:\n            continue\n\n        for file_path in file_paths:\n            s3.client.download_file(input_dir.netloc, file_path, cache_dir)\n\n        queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client(input_dir.netloc)\n\n    while True:\n        try:\n            index, files = queue_in.get(block=False)\n            for file in files:\n                if not os.path.exists(os.path.join(cache_dir, file)):\n                    _wait_for_disk_usage_higher_than_threshold(cache_dir)\n                    obj = parse.urlparse(f\"{input_dir.scheme}://{input_dir.path.rstrip('/')}/{file}\")\n                    _wait_for_file_to_exist(s3, obj)\n                    s3.download(obj, os.path.join(cache_dir, file))\n            queue_out.put(index)\n        except Empty:\n            sleep(1)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client()\n\n    while True:\n        try:\n            task = queue_in.get(block=True, timeout=1)\n        except Empty:\n            continue\n\n        if task is None:\n            break\n\n        index, files = task\n        for file in files:\n            obj = parse.urlparse(file)\n            file_path = os.path.join(cache_dir, obj.path.lstrip(\"/\"))\n\n            if os.path.exists(file_path):\n                continue\n\n            os.makedirs(os.path.dirname(file_path), exist_ok=True)\n\n            _wait_for_file_to_exist(s3, obj)\n\n            s3.download_file(obj.netloc, obj.path.lstrip(\"/\"), file_path)\n\n        queue_out.put(index)\n\n    return\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client()\n    while True:\n        try:\n            # Get download task\n            task = queue_in.get(block=False)\n\n            # Download files\n            for obj in task[\"files\"]:\n                # Check if file already exists\n                if os.path.exists(os.path.join(cache_dir, obj.path.lstrip(\"/\"))):\n                    continue\n\n                # Wait for file to exist\n                _wait_for_file_to_exist(s3, obj)\n\n                # Download file\n                s3.download_file(\n                    bucket=obj.netloc,\n                    key=obj.path.lstrip(\"/\"),\n                    local_path=os.path.join(cache_dir, obj.path.lstrip(\"/\")),\n                )\n\n            # Signal completion\n            queue_out.put(task[\"index\"])\n        except Empty:\n            continue\n        except Exception as e:\n            traceback.print_exc()\n            raise e\n\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client(input_dir.url.netloc, input_dir.url.path.lstrip(\"/\"))\n\n    while True:\n        try:\n            index, obj_paths = queue_in.get(block=False)\n        except Empty:\n            break\n        else:\n            for obj_path in obj_paths:\n                obj = parse.urlparse(obj_path)\n                obj_path = os.path.join(cache_dir, obj.path.lstrip(\"/\"))\n                if not os.path.exists(obj_path):\n                    _wait_for_disk_usage_higher_than_threshold(cache_dir)\n                    s3.download_file(obj.path.lstrip(\"/\"), obj_path)\n                    _wait_for_file_to_exist(s3, obj)\n            queue_out.put(index)\n\n    return\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client(input_dir.netloc, input_dir.path)\n\n    while True:\n        task = queue_in.get()\n        if task is None:\n            break\n        task_index, task_files = task\n        logger.debug(f\"Downloading task {task_index} with {len(task_files)} files.\")\n        for file in task_files:\n            obj = parse.urlparse(file)\n            file_path = os.path.join(cache_dir, obj.path.lstrip(\"/\"))\n            if not os.path.exists(file_path):\n                _wait_for_file_to_exist(s3, obj)\n                s3.download_file(obj.path, file_path)\n                logger.debug(f\"Downloaded file {file} to {file_path}.\")\n            else:\n                logger.debug(f\"File {file} already exists in cache.\")\n        queue_out.put(task_index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client(input_dir.path)\n    for task in iter(queue_in.get, None):\n        index, files = task\n        for file in files:\n            obj = parse.urlparse(file)\n            if not os.path.exists(os.path.join(cache_dir, obj.path.lstrip(\"/\"))):\n                _wait_for_file_to_exist(s3, obj)\n                s3.download(file, os.path.join(cache_dir, obj.path.lstrip(\"/\")))\n        queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client(input_dir.path)\n    s3.download_dir(cache_dir)\n    while True:\n        try:\n            task = queue_in.get(block=True, timeout=1)\n        except Empty:\n            continue\n        if task is None:\n            break\n        index, paths = task\n        for path in paths:\n            obj = parse.urlparse(path)\n            if obj.scheme == \"s3\":\n                _wait_for_file_to_exist(s3, obj)\n                s3.download_file(os.path.join(cache_dir, obj.path.lstrip(\"/\")), obj.path)\n            else:\n                if not os.path.exists(os.path.join(cache_dir, obj.path.lstrip(\"/\"))):\n                    shutil.copy(path, os.path.join(cache_dir, obj.path.lstrip(\"/\")))\n        queue_out.put(index)\n    return\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client(input_dir.url.netloc)\n\n    while True:\n        try:\n            index, files = queue_in.get(block=True, timeout=1)\n        except Empty:\n            continue\n\n        for file in files:\n            obj = parse.urlparse(file)\n            obj = parse.ParseResult(\n                scheme=obj.scheme,\n                netloc=obj.netloc,\n                path=obj.path.lstrip(\"/\"),\n                params=obj.params,\n                query=obj.query,\n                fragment=obj.fragment,\n            )\n\n            file_path = os.path.join(cache_dir, obj.path)\n            os.makedirs(os.path.dirname(file_path), exist_ok=True)\n            if os.path.exists(file_path):\n                continue\n\n            _wait_for_file_to_exist(s3, obj)\n            s3.download_file(obj.netloc, obj.path.lstrip(\"/\"), file_path)\n\n        queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client(input_dir.netloc)\n\n    while True:\n        try:\n            index, paths = queue_in.get()\n        except Empty:\n            continue\n\n        if index is None:\n            break\n\n        for path in paths:\n            obj = parse.urlparse(path)\n            obj = parse.ParseResult(\n                scheme=obj.scheme,\n                netloc=obj.netloc,\n                path=obj.path.lstrip(\"/\"),\n                params=obj.params,\n                query=obj.query,\n                fragment=obj.fragment,\n            )\n\n            # check if file already exists\n            if os.path.exists(os.path.join(cache_dir, obj.path)):\n                continue\n\n            # wait for file to exist\n            _wait_for_file_to_exist(s3, obj)\n\n            # download file\n            s3.download_file(obj.netloc, obj.path, os.path.join(cache_dir, obj.path))\n\n        # signal completion\n        queue_out.put(index)\n\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client()\n    while True:\n        # get the next download task\n        try:\n            task = queue_in.get(block=True, timeout=1)\n        except Empty:\n            continue\n\n        # check if the files are already downloaded\n        for obj in task[\"files\"]:\n            if not s3.is_object_in_bucket(obj):\n                # download the files\n                obj_dir = os.path.join(cache_dir, obj.path.lstrip(\"/\"))\n                os.makedirs(obj_dir, exist_ok=True)\n                s3.download_file(obj, obj_dir)\n\n        # signal completion\n        queue_out.put(task[\"index\"])\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    # create a cache object\n    cache = Cache(cache_dir)\n\n    # wait for the input queue to be populated\n    while queue_in.empty():\n        sleep(0.1)\n\n    # loop until the input queue is empty\n    while not queue_in.empty():\n\n        # fetch a download task from the input queue\n        task = queue_in.get()\n\n        # check if the files are already downloaded\n        if cache.check_if_files_exist(task[\"files\"]):\n\n            # put the task index into the output queue to signal that the files are available\n            queue_out.put(task[\"index\"])\n\n            # continue to the next download task\n            continue\n\n        # download the files\n        cache.download_files(task[\"files\"])\n\n        # put the task index into the output queue to signal that the files are available\n        queue_out.put(task[\"index\"])\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client(input_dir.bucket, input_dir.key, input_dir.region)\n    cache = Cache(cache_dir)\n\n    while True:\n        try:\n            index, obj_list = queue_in.get()\n            logger.debug(f\"[{_get_node_rank()}] Downloading {len(obj_list)} files for index {index}...\")\n\n            for obj in obj_list:\n                obj = parse.urlparse(obj)\n                obj = input_dir.join(obj.path)\n                obj = obj.geturl()\n\n                if not cache.exists(obj):\n                    _wait_for_file_to_exist(s3, obj)\n                    cache.download(s3, obj)\n\n            logger.debug(f\"[{_get_node_rank()}] Finished downloading {len(obj_list)} files for index {index}.\")\n            queue_out.put(index)\n        except Exception as e:\n            logger.error(f\"[{_get_node_rank()}] Error in downloading data: {e}\")\n            queue_out.put(index)\n            traceback.print_exc()\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    # Setup S3 client\n    s3 = S3Client(input_dir.url.netloc, input_dir.url.path.lstrip(\"/\"))\n    s3.connect()\n\n    # Wait for the cache to have enough space\n    _wait_for_disk_usage_higher_than_threshold(cache_dir)\n\n    # Download files\n    while True:\n        try:\n            # Fetch download task\n            task = queue_in.get()\n\n            # Check if files exist\n            for obj in task[\"files\"]:\n                if not os.path.exists(os.path.join(cache_dir, obj.path)):\n                    # Download file\n                    _wait_for_file_to_exist(s3, obj)\n                    s3.client.download_file(\n                        obj.netloc,\n                        obj.path.lstrip(\"/\"),\n                        os.path.join(cache_dir, obj.path),\n                    )\n\n            # Signal completion\n            queue_out.put(task[\"index\"])\n\n        except Exception as e:\n            traceback.print_exc()\n            raise e\n\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    # Create the local cache directory if it doesn't exist.\n    os.makedirs(cache_dir, exist_ok=True)\n\n    # Get the local cache directory size.\n    cache_dir_size = shutil.disk_usage(cache_dir).free\n\n    # Create a S3 client.\n    s3 = S3Client()\n\n    # Fetch download tasks from the input queue.\n    while True:\n        # Fetch a download task from the input queue.\n        try:\n            task = queue_in.get(block=False)\n        except Empty:\n            continue\n\n        # Get the index and file paths.\n        index, files = task\n\n        # Check if the files are already downloaded.\n        if all(os.path.exists(os.path.join(cache_dir, f)) for f in files):\n            # Put the index into the output queue to signal completion.\n            queue_out.put(index)\n            continue\n\n        # Check if the cache directory is full.\n        if cache_dir_size < 1000000000:\n            # Wait until the cache directory is empty.\n            _wait_for_disk_usage_higher_than_threshold(cache_dir)\n\n            # Update the cache directory size.\n            cache_dir_size = shutil.disk_usage(cache_dir).free\n\n        # Download the files.\n        for f in files:\n            # Get the source path or URL for the file.\n            obj = _resolve_dir(input_dir, f)\n\n            # Wait until the file exists.\n            _wait_for_file_to_exist(s3, obj)\n\n            # Download the file.\n            s3.download_file(obj.netloc, obj.path.lstrip(\"/\"), os.path.join(cache_dir, f))\n\n        # Put the index into the output queue to signal completion.\n        queue_out.put(index)\n\n    return\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client()\n    # Create the cache directory if it doesn't exist.\n    os.makedirs(cache_dir, exist_ok=True)\n\n    # Download files until the input queue is empty.\n    while True:\n        # Get the next download task.\n        try:\n            task = queue_in.get(block=False)\n        except Empty:\n            break\n\n        # Get the index and file paths from the task.\n        index, files = task\n\n        # Download each file.\n        for file in files:\n            obj = parse.urlparse(file)\n            # Check if the file already exists.\n            if os.path.exists(os.path.join(cache_dir, obj.path.lstrip(\"/\"))):\n                continue\n\n            # Check if the file exists in the source directory.\n            if s3.exists(file):\n                # Wait until the file is available.\n                _wait_for_file_to_exist(s3, obj)\n\n                # Download the file.\n                s3.download(file, cache_dir)\n\n        # Signal that the files for the task are available.\n        queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            remove_queue.put(None)\n            return\n\n        # 3. Unpack\n        path = r\n\n        # 4. Check whether the file exists\n        if not os.path.exists(path):\n            continue\n\n        # 5. Check whether the file is already uploaded\n        if output_dir.path and os.path.exists(path.replace(cache_dir, output_dir.path)):\n            continue\n\n        # 6. Check whether the file is already uploaded\n        if output_dir.url and os.path.exists(path.replace(cache_dir, output_dir.url)):\n            continue\n\n        # 7. Upload the file\n        if output_dir.url:\n            obj = parse.urlparse(output_dir.url)\n\n            if obj.scheme == \"s3\":\n                s3.client.upload_file(path, obj.netloc, obj.path.lstrip(\"/\"))\n\n            elif obj.scheme == \"file\":\n                shutil.copyfile(path, path.replace(cache_dir, output_dir.path))\n\n            else:\n                raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n        # 8. Inform the worker the current files are available\n        remove_queue.put([path])\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    # 1. Create a client for the output directory\n    s3 = S3Client()\n\n    # 2. Iterate through the queue\n    while True:\n        # 2.1 Fetch an item from the queue\n        item = upload_queue.get()\n\n        # 2.2 Terminate the process if we received a termination signal\n        if item is None:\n            return\n\n        # 2.3 Unpack the item\n        if isinstance(item, tuple):\n            tmp_dir, path = item\n        else:\n            tmp_dir = None\n            path = item\n\n        # 2.4 Check whether the file already exists in the output directory\n        if output_dir.url is not None or output_dir.path is not None:\n            if output_dir.url:\n                # 2.5 Wait for the removers to catch up when we are uploading data.\n                _wait_for_disk_usage_higher_than_threshold(\"/\", 25)\n\n            # 2.6 Upload the file to the output directory\n            if output_dir.path:\n                local_path = path.replace(cache_dir, output_dir.path)\n\n            if output_dir.url and output_dir.path:\n                path = path.replace(cache_dir, output_dir.url)\n\n            obj = parse.urlparse(path)\n\n            if obj.scheme == \"s3\":\n                s3.client.upload_file(local_path, obj.netloc, obj.path.lstrip(\"/\"))\n\n            elif os.path.isfile(path):\n                if not path.startswith(\"/teamspace/studios/this_studio\"):\n                    os.makedirs(os.path.dirname(local_path), exist_ok=True)\n                    shutil.copyfile(path, local_path)\n            else:\n                raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n        # 2.7 Inform the worker that the current file is available for removal\n        if tmp_dir:\n            remove_queue.put(["}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            remove_queue.put(None)\n            return\n\n        # 3. Unpack\n        if isinstance(r, str):\n            path = r\n        else:\n            _, path = r\n\n        if output_dir.url is not None or output_dir.path is not None:\n            if output_dir.url:\n                # 4. Wait for the removers to catch up when we are uploading data.\n                _wait_for_disk_usage_higher_than_threshold(\"/\", 25)\n\n            # 5. Upload all the required paths to unblock the current index\n            obj = parse.urlparse(path)\n\n            if obj.scheme == \"s3\":\n                s3.client.upload_file(path, obj.netloc, obj.path.lstrip(\"/\"))\n            elif os.path.isfile(path):\n                if not path.startswith(\"/teamspace/studios/this_studio\"):\n                    os.makedirs(os.path.dirname(path.replace(cache_dir, output_dir.path)), exist_ok=True)\n                    shutil.copyfile(path, path.replace(cache_dir, output_dir.path))\n            else:\n                raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n        # 6. Inform the worker the current files are available\n        remove_queue.put([path])\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            remove_queue.put(None)\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            tmp_dir, path = r\n        else:\n            tmp_dir, path = None, r\n\n        # 4. Upload to the target directory\n        if output_dir.url is not None or output_dir.path is not None:\n            if output_dir.url:\n                # 5. Wait for the removers to catch up when we are uploading data.\n                _wait_for_disk_usage_higher_than_threshold(\"/\", 25)\n\n            if output_dir.path:\n                path = path.replace(cache_dir, output_dir.path)\n\n            if output_dir.url and output_dir.path:\n                path = path.replace(output_dir.path, output_dir.url)\n\n            obj = parse.urlparse(path)\n\n            if obj.scheme == \"s3\":\n                s3.client.upload_file(path, obj.netloc, obj.path.lstrip(\"/\"))\n\n            elif obj.scheme == \"file\":\n                if not path.startswith(\"/teamspace/studios/this_studio\"):\n                    s3.client.upload_file(path, obj.netloc, obj.path.lstrip(\"/\"))\n\n            else:\n                raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n        # 5. Inform the worker the current files are available\n        remove_queue.put([path])\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        item = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if item is None:\n            remove_queue.put(None)\n            return\n\n        # 3. Unpack\n        if isinstance(item, tuple):\n            tmp_dir, path = item\n        else:\n            path = item\n\n        # 4. Check whether the file is already uploaded\n        if output_dir.url is not None and output_dir.path is not None:\n            if output_dir.url:\n                # 5. Wait for the removers to catch up when we are uploading data.\n                _wait_for_disk_usage_higher_than_threshold(\"/\", 25)\n\n            # 6. Upload all the required paths to unblock the current index\n            obj = parse.urlparse(path)\n\n            if obj.scheme == \"s3\":\n                with open(path, \"rb\") as f:\n                    s3.client.upload_fileobj(f, obj.netloc, obj.path.lstrip(\"/\"))\n            elif os.path.isfile(path):\n                if not path.startswith(\"/teamspace/studios/this_studio\"):\n                    shutil.copyfile(path, path.replace(cache_dir, output_dir.path))\n            else:\n                raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n        # 7. Inform the worker the current files are available\n        remove_queue.put([path])\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Collect paths from the upload queue\n        paths = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if paths is None:\n            return\n\n        # 3. Iterate through the paths and upload them sequentially.\n        for path in paths:\n            if output_dir.url is not None or output_dir.path is not None:\n                if output_dir.url:\n                    # 4. Wait for the removers to catch up when we are uploading data.\n                    _wait_for_disk_usage_higher_than_threshold(\"/\", 25)\n\n                # 5. Upload all the required paths to unblock the current index\n                if output_dir.path:\n                    local_path = path.replace(cache_dir, output_dir.path)\n\n                if output_dir.url and output_dir.path:\n                    path = path.replace(cache_dir, output_dir.url)\n\n                obj = parse.urlparse(path)\n\n                if obj.scheme == \"s3\":\n                    with open(local_path, \"rb\") as f:\n                        s3.client.upload_fileobj(f, obj.netloc, obj.path.lstrip(\"/\"))\n\n                elif os.path.isfile(path):\n                    if not path.startswith(\"/teamspace/studios/this_studio\"):\n                        os.makedirs(os.path.dirname(local_path), exist_ok=True)\n                        shutil.copyfile(path, local_path)\n                else:\n                    raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n            # 6. Inform the worker the current files are available\n            remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        item = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if item is None:\n            return\n\n        # 3. Process the item\n        if isinstance(item, str):\n            if item.startswith(cache_dir):\n                path = item.replace(cache_dir, \"\")\n            else:\n                path = item\n\n            if output_dir.url:\n                if output_dir.url.startswith(\"s3://\"):\n                    obj = parse.urlparse(output_dir.url)\n                    s3.client.upload_file(item, obj.netloc, obj.path.lstrip(\"/\"))\n                    remove_queue.put(item)\n                else:\n                    shutil.move(item, os.path.join(output_dir.path, os.path.basename(item)))\n                    remove_queue.put(item)\n            else:\n                shutil.move(item, os.path.join(output_dir.path, os.path.basename(item)))\n                remove_queue.put(item)\n        elif isinstance(item, tuple):\n            path = os.path.join(item[0], os.path.basename(item[1]))\n            if output_dir.url:\n                if output_dir.url.startswith(\"s3://\"):\n                    obj = parse.urlparse(output_dir.url)\n                    s3.client.upload_file(item[1], obj.netloc, obj.path.lstrip(\"/\"))\n                    remove_queue.put(item[1])\n                else:\n                    shutil.move(item[1], os.path.join(output_dir.path, os.path.basename(item[1])))\n                    remove_queue.put(item[1])\n            else:\n                shutil.move(item[1], os.path.join(output_dir.path, os.path.basename(item[1]"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            remove_queue.put(None)\n            return\n\n        # 3. Unpack\n        if output_dir.url is not None:\n            if isinstance(r, tuple):\n                temp_dir, path = r\n                local_path = path.replace(temp_dir, cache_dir)\n            else:\n                local_path = r.replace(input_dir.path, cache_dir)\n\n            if output_dir.path:\n                remote_path = path.replace(output_dir.path, output_dir.url)\n\n        elif output_dir.path:\n            local_path = r.replace(input_dir.path, cache_dir)\n\n        # 4. Upload the file\n        if output_dir.url is not None or output_dir.path is not None:\n            if output_dir.url:\n                # 5. Wait for the removers to catch up when we are uploading data.\n                _wait_for_disk_usage_higher_than_threshold(\"/\", 25)\n\n            # 6. Upload all the required paths to unblock the current index\n            if output_dir.url:\n                obj = parse.urlparse(remote_path)\n\n                if obj.scheme == \"s3\":\n                    with open(local_path, \"rb\") as f:\n                        s3.client.upload_fileobj(f, obj.netloc, obj.path.lstrip(\"/\"))\n\n                elif os.path.isfile(path):\n                    if not path.startswith(\"/teamspace/studios/this_studio\"):\n                        os.makedirs(os.path.dirname(local_path), exist_ok=True)\n                        shutil.copyfile(path, local_path)\n                else:\n                    raise ValueError(f\"The provided {output_dir.url} isn"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Get the next item from the queue\n        item = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if item is None:\n            return\n\n        # 3. Upload the item to the output directory\n        if output_dir.url is not None and output_dir.path is not None:\n            # 3.1. Upload the item to the output directory\n            if isinstance(item, str):\n                path = item\n                if not path.startswith(output_dir.path):\n                    path = path.replace(cache_dir, output_dir.path)\n\n                if path.startswith(output_dir.url):\n                    path = path.replace(output_dir.url, output_dir.path)\n\n                obj = parse.urlparse(path)\n\n                if obj.scheme == \"s3\":\n                    with open(path, \"rb\") as f:\n                        s3.client.upload_fileobj(f, obj.netloc, obj.path.lstrip(\"/\"))\n\n                elif os.path.isfile(path):\n                    if not path.startswith(\"/teamspace/studios/this_studio\"):\n                        os.makedirs(os.path.dirname(path), exist_ok=True)\n                        shutil.copyfile(path, path.replace(cache_dir, output_dir.path))\n                else:\n                    raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n            elif isinstance(item, tuple):\n                tmp_dir, path = item\n\n                if not path.startswith(output_dir.path):\n                    path = path.replace(cache_dir, output_dir.path)\n\n                if path.startswith(output_dir.url):\n                    path = path.replace(output_dir.url, output_dir.path)\n\n                obj = parse.urlparse(path)\n\n                if obj.scheme == \"s3\":\n                    with"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Tuple[int, Union[str, Tuple[str, str]]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            remove_queue.put(None)\n            return\n\n        # 3. Unpack\n        index, path = r\n\n        # 4. Upload the file\n        if isinstance(path, tuple):\n            temp_dir, path = path\n\n            # 4.1. Upload the file\n            with open(path, \"rb\") as f:\n                s3.client.upload_fileobj(f, output_dir.netloc, os.path.join(output_dir.path, path.lstrip(\"/\")))\n\n            # 4.2. Remove the file\n            os.remove(path)\n\n        elif isinstance(path, str):\n            if output_dir.url:\n                # 4.1. Upload the file\n                with open(path, \"rb\") as f:\n                    s3.client.upload_fileobj(f, output_dir.netloc, os.path.join(output_dir.path, path.lstrip(\"/\")))\n\n                # 4.2. Remove the file\n                os.remove(path)\n\n            elif output_dir.path:\n                path = path.replace(cache_dir, output_dir.path)\n                os.makedirs(os.path.dirname(path), exist_ok=True)\n                shutil.copyfile(path, path)\n\n        # 5. Inform the worker the current files are available\n        remove_queue.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Tuple[int, List[str]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            remove_queue.put(None)\n            return\n\n        # 3. Unpack\n        index, paths = r\n\n        # 4. Check whether all the files are already uploaded\n        if all(\n            os.path.exists(p.replace(cache_dir, output_dir.path) if output_dir.path else p) for p in paths\n        ):\n            remove_queue.put(index)\n            continue\n\n        # 5. Upload all the required paths to unblock the current index\n        for path in paths:\n            if output_dir.path:\n                local_path = path.replace(cache_dir, output_dir.path)\n\n            if output_dir.url and output_dir.path:\n                path = path.replace(cache_dir, output_dir.url)\n\n            if os.path.isfile(path):\n                if not path.startswith(\"/teamspace/studios/this_studio\"):\n                    os.makedirs(os.path.dirname(local_path), exist_ok=True)\n                    shutil.copyfile(path, local_path)\n            else:\n                raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n        # 6. Inform the worker the current files are available\n        remove_queue.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            remove_queue.put(None)\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            tmp_dir, path = r\n        else:\n            tmp_dir = None\n            path = r\n\n        # 4. Check whether the file exists locally\n        if not os.path.exists(path):\n            continue\n\n        # 5. Check whether the file already exists remotely\n        if output_dir.url is not None or output_dir.path is not None:\n            if output_dir.url:\n                # 6. Wait for the removers to catch up when we are uploading data.\n                _wait_for_disk_usage_higher_than_threshold(\"/\", 25)\n\n            # 7. Upload the file\n            if output_dir.url:\n                obj = parse.urlparse(path)\n\n                if obj.scheme == \"s3\":\n                    s3.client.upload_file(path, obj.netloc, obj.path.lstrip(\"/\"))\n                elif os.path.isfile(path):\n                    if not path.startswith(\"/teamspace/studios/this_studio\"):\n                        s3.client.upload_file(path, output_dir.url, path.replace(cache_dir, \"\"))\n                else:\n                    raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n        # 8. Inform the worker the current files are available\n        remove_queue.put(path)\n\n        # 9. Remove the file if it is a temporary file\n        if tmp_dir:\n            os.remove(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        path = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if path is None:\n            remove_queue.put(None)\n            return\n\n        # 3. Upload the file to the output directory\n        if output_dir.url is not None and output_dir.path is not None:\n            # 3.1. Upload the file to the output directory\n            if path.startswith(cache_dir):\n                path = path.replace(cache_dir, output_dir.path)\n\n            if not path.startswith(output_dir.path):\n                path = os.path.join(output_dir.path, path.lstrip(\"/\"))\n\n            obj = parse.urlparse(path)\n\n            if obj.scheme == \"s3\":\n                s3.client.upload_file(obj.path, obj.netloc, obj.path.lstrip(\"/\"))\n            elif os.path.isfile(path):\n                os.makedirs(os.path.dirname(obj.path), exist_ok=True)\n                shutil.copyfile(path, obj.path)\n            else:\n                raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n        # 4. Inform the worker the current files are available\n        remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            tmp_dir, path = r\n        else:\n            tmp_dir, path = None, r\n\n        # 4. Check whether the file is already uploaded\n        if output_dir.url and output_dir.path and path.startswith(output_dir.path):\n            obj = parse.urlparse(path)\n            if s3.client.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\")):\n                continue\n\n        # 5. Upload the file\n        if output_dir.path:\n            if tmp_dir:\n                path = path.replace(tmp_dir, output_dir.path)\n            else:\n                path = path.replace(cache_dir, output_dir.path)\n\n        if output_dir.url and output_dir.path:\n            path = path.replace(output_dir.path, output_dir.url)\n\n        if output_dir.url and output_dir.path:\n            obj = parse.urlparse(path)\n\n            if obj.scheme == \"s3\":\n                s3.client.upload_file(path, obj.netloc, obj.path.lstrip(\"/\"))\n            else:\n                shutil.move(path, output_dir.path)\n\n        # 6. Inform the worker the current files are available\n        if output_dir.url and output_dir.path:\n            remove_queue.put([path])\n        else:\n            remove_queue.put([path])\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            remove_queue.put(None)\n            return\n\n        # 3. Unpack\n        if output_dir.url:\n            obj = parse.urlparse(output_dir.url)\n\n            if obj.scheme == \"s3\":\n                if isinstance(r, tuple):\n                    tmp_dir, path = r\n                    tmp_path = os.path.join(tmp_dir, path.replace(cache_dir, \"\"))\n                    s3.upload_file(tmp_path, obj.netloc, obj.path.lstrip(\"/\"))\n                else:\n                    s3.upload_file(r, obj.netloc, obj.path.lstrip(\"/\"))\n\n            elif os.path.isfile(r):\n                shutil.copyfile(r, r.replace(cache_dir, output_dir.path))\n\n        elif output_dir.path:\n            if isinstance(r, tuple):\n                tmp_dir, path = r\n                tmp_path = os.path.join(tmp_dir, path.replace(cache_dir, \"\"))\n                shutil.copyfile(tmp_path, os.path.join(output_dir.path, path.replace(cache_dir, \"\")))\n            else:\n                shutil.copyfile(r, r.replace(cache_dir, output_dir.path))\n\n        # 4. Inform the worker the current files are available\n        remove_queue.put(r)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            remove_queue.put(None)\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            tmp_dir, path = r\n        else:\n            path = r\n\n        # 4. Check whether the file exists\n        if not os.path.exists(path):\n            continue\n\n        # 5. Check whether the file is already uploaded\n        if output_dir.path and os.path.exists(path.replace(cache_dir, output_dir.path)):\n            continue\n\n        # 6. Upload the file to the target directory\n        if output_dir.url:\n            obj = parse.urlparse(path)\n\n            if obj.scheme == \"s3\":\n                s3.client.upload_file(path, obj.netloc, obj.path.lstrip(\"/\"))\n            else:\n                raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n        # 7. Inform the worker the current files are available\n        remove_queue.put([path])\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    # 1. Create a client for the output directory\n    s3 = S3Client(output_dir.url)\n\n    # 2. Iterate through the queue until a termination signal is received\n    while True:\n        # 2.1. Fetch from the queue\n        item = upload_queue.get()\n\n        # 2.2. Terminate the process if we received a termination signal\n        if item is None:\n            return\n\n        # 2.3. Upload the item\n        if isinstance(item, tuple):\n            # 2.3.1. If the item is a tuple, we assume it contains a temporary directory and a file path\n            with open(os.path.join(item[0], item[1].split(\"/\")[-1]), \"rb\") as f:\n                s3.client.upload_fileobj(f, item[1])\n\n        else:\n            # 2.3.2. If the item is a file path, we assume it's a file path to a cached chunk\n            if item.startswith(cache_dir):\n                item = item.replace(cache_dir, \"\")\n\n            if output_dir.url:\n                s3.client.upload_file(item, item)\n            else:\n                shutil.move(item, output_dir.path)\n\n        # 2.4. Inform the worker the current files are available\n        remove_queue.put(item)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        path = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if path is None:\n            remove_queue.put(None)\n            return\n\n        # 3. Upload the file to the target directory\n        if output_dir.url is not None:\n            obj = parse.urlparse(path)\n            if obj.scheme == \"s3\":\n                s3.client.upload_file(\n                    Bucket=obj.netloc,\n                    Key=obj.path.lstrip(\"/\"),\n                    Filename=path.replace(cache_dir, \"\"),\n                )\n            elif output_dir.path:\n                shutil.copyfile(path, path.replace(cache_dir, output_dir.path))\n            else:\n                raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n        # 4. Inform the worker the current files are available\n        remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Tuple[int, List[str]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        index, paths = r\n\n        # 4. Upload all the files to the output directory\n        for path in paths:\n            if not path.startswith(cache_dir) and output_dir.path is not None:\n                path = path.replace(cache_dir, output_dir.path)\n\n            if output_dir.url is not None and output_dir.path is not None:\n                if not path.startswith(output_dir.path):\n                    path = os.path.join(output_dir.path, path)\n\n                # 5. Upload the file to the remote directory\n                obj = parse.urlparse(path)\n                if obj.scheme == \"s3\":\n                    s3.client.upload_file(path, obj.netloc, obj.path.lstrip(\"/\"))\n                else:\n                    raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n        # 6. Inform the worker the current files are available\n        remove_queue.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            remove_queue.put(None)\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            tmp_dir, path = r\n        else:\n            path = r\n\n        # 4. Check whether the file is already uploaded\n        if output_dir.url and output_dir.path and os.path.exists(path.replace(cache_dir, output_dir.path)):\n            continue\n\n        # 5. Check whether the file is already uploaded\n        if output_dir.url is None and os.path.exists(path):\n            continue\n\n        # 6. Upload the file\n        if output_dir.url:\n            obj = parse.urlparse(path)\n            if obj.scheme == \"s3\":\n                s3.upload_file(path, obj.netloc, obj.path.lstrip(\"/\"))\n            else:\n                raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n        # 7. Inform the worker the current files are available\n        remove_queue.put([path])\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Associate the items to the workers based on number of nodes and node rank.\n    total_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n    total_workers = total_nodes * num_workers\n\n    items_per_worker = len(user_items) // total_workers\n    extra_items = len(user_items) % total_workers\n\n    start = 0\n    result = []\n    for i in range(total_workers):\n        worker_items = items_per_worker + 1 if i < extra_items else items_per_worker\n        end = start + worker_items\n        result.append(user_items[start:end])\n        start = end\n\n    if len(result) != num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    # Print distribution details for workers on the current node\n    print(f\"Distributing {len(user_items)} items among {total_workers} workers\")\n    if file_size:\n        print(\n            f\"Worker ID\\t\\tItems\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Associate the items to the workers based on number of nodes and node rank.\n    weights = [1] * len(user_items) if weights is None else weights\n\n    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n    world_size = num_nodes * num_workers\n\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    # Print the distribution details for workers on the current node.\n    print(f\"Node Rank: {node_rank} - {num_workers} workers\")\n    print(f\"Worker IDs: {worker_ids_this_node}\")\n    print(f\"Total Weight: {sum(worker_weights)}\")\n    if file_size:\n        print(f\"Total Size: {sum(worker_weights) / 1000 / 1000} MB\")\n    else:\n        print(f\"Total Size: {sum(worker_weights)}\")\n\n    # Shuffle the items for each worker.\n    for worker_id in worker_ids_this_node:\n        worker_items[worker_id] = np.random.permutation(worker_items[worker_id])\n\n    # Return the items for each worker.\n    return [worker_items[worker_id] for worker_id in worker_ids_this_node]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Associate the items to the workers based on number of nodes and node rank.\n    weights = [1] * len(user_items) if weights is None else weights\n\n    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n    world_size = num_nodes * num_workers\n\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    print(f\"Worker IDs on this node: {worker_ids_this_node}\")\n    print(f\"Total number of workers: {world_size}\")\n    print(f\"Total number of items: {len(user_items)}\")\n    print(f\"Total number of items assigned to this node: {len(worker_items[node_rank * num_workers: (node_rank + 1) * num_workers])}\")\n    print(f\"Total number of items assigned to other nodes: {len(user_items) - len(worker_items[node_rank * num_workers: (node_rank + 1) * num_workers])}\")\n\n    if file_size:\n        file_sizes = [os.path.getsize(item) for item in user_items]\n        total_size = sum(file_sizes)\n        print(f\"Total size of items on this node: {total_size / 1000000} MB\")\n        print(f\"Total size of items on other nodes: {(total_size - sum(worker_weights[node_rank * num_workers: (node_rank + 1) * num_workers])) / 1000000} MB\")\n\n        print(f\"Total size of items assigned to this node: {sum(file_sizes[node_rank * num_workers: (node_rank + 1) * num_workers]) / 1000"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Associate the items to the workers based on number of nodes and node rank.\n    weights = [1] * len(user_items) if weights is None else weights\n\n    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n    world_size = num_nodes * num_workers\n\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    # Print the distribution details for workers on the current node.\n    print(\n        f\"Distributing {len(user_items)} items to {world_size} workers, {num_workers} per node, \"\n        f\"with weights: {worker_weights}.\"\n    )\n\n    if file_size:\n        sizes = [os.path.getsize(item) for item in user_items]\n        sizes_this_node = [sizes[i] for i in range(len(user_items)) if i in worker_ids_this_node]\n        print(\n            f\"Total size of items assigned to this node: {sum(sizes_this_node) / 1024 / 1024} MB, \"\n            f\"average size: {sum(sizes_this_node) / len(sizes_this_node) / 1024 / 1024} MB.\"\n        )\n    else:\n        print(f\"Total weight of items assigned to this node: {sum(worker_weights)}\")\n\n    # Shuffle the items assigned to the current node.\n    worker_items_this_node = [worker_items[i] for i in worker_ids_this_node]\n    worker_weights_this_node = [worker_weights[i] for i in worker_ids_this_node]\n    random.shuffle(worker_items_this_node)\n\n    # Return the items assigned"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    from typing import List, Any\n    import os\n    total_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n    total_workers = total_nodes * num_workers\n\n    if len(user_items) != len(weights):\n        raise ValueError(\"The number of weights must match the number of items.\")\n\n    if not file_size:\n        worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=total_workers)\n        worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n        worker_items_this_node = [worker_items[i] for i in worker_ids_this_node]\n        worker_weights_this_node = [worker_weights[i] for i in worker_ids_this_node]\n\n        return worker_items_this_node\n\n    # Associate the items to the workers based on number of nodes and node rank.\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=total_workers)\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    # Print the distribution details for workers on the current node.\n    total_weight = sum(worker_weights)\n    worker_sizes = [os.path.getsize(item) for item in user_items]\n    worker_sizes_this_node = [worker_sizes[i] for i in worker_ids_this_node]\n    worker_size_sum_this_node = sum(worker_sizes_this_node)\n    worker_size_mean_this_node = worker_size_sum_this_node / len(worker_sizes_this_node)\n    worker_size_std_this_node = np.std(worker_sizes_this_node)\n\n   "}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Associate the items to the workers based on number of nodes and node rank.\n    weights = [1] * len(user_items) if weights is None else weights\n\n    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n    world_size = num_nodes * num_workers\n\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    # Print the distribution details for workers on the current node.\n    if file_size:\n        sizes = [os.path.getsize(item) for item in user_items]\n        total_size = sum(sizes)\n        sizes = [size / 1000000.0 for size in sizes]\n    else:\n        total_size = sum(weights)\n        sizes = None\n\n    print(\n        f\"Node {node_rank} has {len(worker_ids_this_node)} workers, with a total weight of {total_size}.\"\n    )\n    for worker_id in worker_ids_this_node:\n        print(\n            f\"Worker {worker_id} has {len(worker_items[worker_id])} items, with a total weight of {worker_weights[worker_id]}.\"\n        )\n        if sizes:\n            print(\n                f\"Worker {worker_id} has a total file size of {sum(sizes[i] for i in worker_items[worker_id])} MB.\"\n            )\n\n    return [worker_items[worker_id] for worker_id in worker_ids_this_node]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Associate the items to the workers based on number of nodes and node rank.\n    weights = [1] * len(user_items) if weights is None else weights\n\n    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n    world_size = num_nodes * num_workers\n\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    # Print the distribution details for workers on the current node.\n    total_weight = sum(worker_weights)\n    print(f\"Node {node_rank} has {len(worker_ids_this_node)} workers with a total weight of {total_weight}.\")\n\n    for worker_id in worker_ids_this_node:\n        print(\n            f\"Worker {worker_id} has {len(worker_items[worker_id])} items with a total weight of {worker_weights[worker_id]}.\"\n        )\n\n    if file_size:\n        sizes = [os.path.getsize(item) for item in user_items]\n        sizes = [size / (1024 * 1024) for size in sizes]\n        print(f\"The total file size of the items is {sum(sizes)} MB.\")\n    else:\n        print(f\"The total weight of the items is {total_weight}.\")\n\n    # Shuffle the items for each worker.\n    for worker_id in worker_ids_this_node:\n        random.shuffle(worker_items[worker_id])\n\n    # Return a list of items for each worker, with the items shuffled.\n    return [worker_items[worker_id] for worker_id in worker_ids_this_node]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    if weights is None:\n        weights = [1] * len(user_items)\n\n    if len(weights) != len(user_items):\n        raise ValueError(\"The weights and items must be of the same length.\")\n\n    if num_workers > len(user_items):\n        raise ValueError(\"The number of workers cannot be greater than the number of items.\")\n\n    if num_workers == 1:\n        return [user_items]\n\n    if num_workers > len(user_items):\n        raise ValueError(\"The number of workers cannot be greater than the number of items.\")\n\n    # Associate the items to the workers based on number of nodes and node rank.\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=num_workers)\n\n    # Print the distribution details for workers on the current node and return a list of items for each worker, with the items shuffled.\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n    worker_items_this_node = [worker_items[i] for i in worker_ids_this_node]\n    worker_weights_this_node = [worker_weights[i] for i in worker_ids_this_node]\n\n    if file_size:\n        total_weight_this_node = sum(worker_weights_this_node)\n        total_size_this_node = sum(\n            [os.path.getsize(item) for item in worker_items_this_node if os.path.exists(item)]\n        )\n        print(\n            f\"Node {node_rank} has {num_workers} workers with total weight {total_weight_this_node} and total size {total_size_this_node / 1024 / 1024:.2f} MB\"\n        )\n    else:\n        print(f\"Node {node_rank} has {num_workers} workers with total weight {sum(worker_we"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Associate the items to the workers based on number of nodes and node rank.\n    weights = [1] * len(user_items) if weights is None else weights\n\n    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n    world_size = num_nodes * num_workers\n\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    if file_size:\n        sizes = [os.path.getsize(item) for item in user_items]\n        total_size = sum(sizes)\n        sizes = [size / 1024 / 1024 for size in sizes]\n    else:\n        sizes = [1] * len(user_items)\n        total_size = sum(weights)\n\n    worker_sizes = [sum(sizes[i] for i in worker_items[worker_id]) for worker_id in range(world_size)]\n    worker_sizes_this_node = [worker_sizes[i] for i in worker_ids_this_node]\n\n    worker_weights = [sum(weights[i] for i in worker_items[worker_id]) for worker_id in range(world_size)]\n    worker_weights_this_node = [worker_weights[i] for i in worker_ids_this_node]\n\n    # Print the distribution details for workers on the current node.\n    logger.info(f\"Distribution details for workers on node {node_rank} of {num_nodes}:\")\n    logger.info(f\"Total number of workers: {world_size}\")\n    logger.info(f\"Worker IDs: {worker_ids_this_node}\")\n    logger.info(f\"Total size of items: {total_size} (MB)\")\n    logger.info(f\"Worker sizes (MB): {worker_s"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    from typing import List, Any\n    import os\n    total_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n    total_workers = total_nodes * num_workers\n\n    items_per_worker = len(user_items) // total_workers\n    extra_items = len(user_items) % total_workers\n\n    start = 0\n    result = []\n    for i in range(total_workers):\n        worker_items = items_per_worker + 1 if i < extra_items else items_per_worker\n        end = start + worker_items\n        result.append(user_items[start:end])\n        start = end\n\n    if len(result) != num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    worker_items = [result[i] for i in worker_ids_this_node]\n    worker_weights = [worker_weights[i] for i in worker_ids_this_node]\n\n    # Print the distribution details for workers on the current node\n    if node_rank == 0:\n        if file_size:\n            sizes = [os.path.getsize(item) for item in user_items]\n            total_size = sum(sizes)\n            sizes = [size / 1024 / 1024 for size in sizes]\n            total_size = total_size / 1024 / 1024\n        else:\n            sizes = weights\n            total_size = sum(sizes)\n        print(f\"{num_workers} workers with {num_nodes} nodes, {node_rank} node rank\")\n        print(f\"Total weight: {total_size:.2f}MB\")\n        for i, worker_id in enumerate(worker_ids_this_node):\n            print(f\"Worker {worker_id}: {len(worker_items[i]):6d} items, {sum(worker_weights[i]):.2f}MB\")\n\n    return worker_items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Associate the items to the workers based on number of nodes and node rank.\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    # Print the distribution details for workers on the current node.\n    total_weight = sum(worker_weights)\n    total_size = sum(os.path.getsize(f) for f in user_items) / 1000000.0 if file_size else total_weight\n    print(f\"Node {node_rank} has {num_workers} workers and {len(worker_items)} items.\")\n    print(f\"Total weight: {total_weight} ({total_size} MB) | Per worker: {total_weight / num_workers}\")\n\n    # Return a list of items for each worker, with the items shuffled.\n    return [random.sample(worker_items[i], len(worker_items[i])) for i in worker_ids_this_node]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Associate the items to the workers based on number of nodes and node rank.\n    weights = [1] * len(user_items) if weights is None else weights\n\n    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n    world_size = num_nodes * num_workers\n\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    print(\n        f\"Node {node_rank} has {len(worker_items[node_rank * num_workers:(node_rank + 1) * num_workers])} workers with a total of {sum(worker_weights[node_rank * num_workers:(node_rank + 1) * num_workers])} items\"\n    )\n\n    if file_size:\n        print(\n            \"Worker id | Worker items | Worker item sizes | Worker item sizes (MB) | Total item sizes | Total item sizes (MB)\"\n        )\n        for worker_id in worker_ids_this_node:\n            items = worker_items[worker_id]\n            sizes = [os.path.getsize(item) for item in items]\n            sizes_mb = [size / (1024 * 1024) for size in sizes]\n            print(\n                f\"{worker_id:<10} {len(items):<14} {sizes:<25} {sizes_mb:<25} {sum(sizes):<25} {sum(sizes_mb):<25}\"\n            )\n    else:\n        print(\n            \"Worker id | Worker items | Worker item sizes | Total item sizes\"\n        )\n        for worker_id in worker_ids_this_node:\n            items = worker_items[worker_id]\n            sizes = [os.path.getsize(item"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Associate the items to the workers based on number of nodes and node rank.\n    weights = [1] * len(user_items) if weights is None else weights\n\n    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n    world_size = num_nodes * num_workers\n\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    # Print the distribution details for workers on this node.\n    worker_items_this_node = [worker_items[i] for i in worker_ids_this_node]\n    worker_weights_this_node = [worker_weights[i] for i in worker_ids_this_node]\n    worker_sizes_this_node = [os.path.getsize(f) for f in worker_items_this_node]\n    total_size_this_node = sum(worker_sizes_this_node)\n    total_weight_this_node = sum(worker_weights_this_node)\n\n    if file_size:\n        print(\n            f\"Worker details for node {node_rank} (total nodes: {num_nodes}): \"\n            f\"{len(worker_items_this_node)} workers with a total of {total_size_this_node / 1e6:.2f} MB data.\"\n        )\n    else:\n        print(\n            f\"Worker details for node {node_rank} (total nodes: {num_nodes}): \"\n            f\"{len(worker_items_this_node)} workers with a total of {total_weight_this_node} data.\"\n        )\n\n    # Shuffle the items for each worker.\n    for i in range(len(worker_items_this_node)):\n        random.shuffle(worker_items_this_node[i])\n\n    # Return the items for"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Associate the items to the workers based on number of nodes and node rank.\n    weights = [1] * len(user_items) if weights is None else weights\n\n    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n    world_size = num_nodes * num_workers\n\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    # Calculate the total size of the dataset and the number of workers on this node\n    total_size = sum(weights)\n    num_workers_this_node = len(worker_ids_this_node)\n\n    # Print the distribution details\n    if file_size:\n        total_size_mb = total_size / 1024 / 1024\n        print(\n            f\"Node {node_rank} has {num_workers_this_node} workers. \"\n            f\"The total size of the dataset is {total_size_mb:.2f} MB. \"\n            f\"Each worker has {total_size_mb / num_workers_this_node:.2f} MB.\"\n        )\n    else:\n        print(\n            f\"Node {node_rank} has {num_workers_this_node} workers. \"\n            f\"The total weight of the dataset is {total_size:.2f}. \"\n            f\"Each worker has {total_size / num_workers_this_node:.2f}.\"\n        )\n\n    # Return the items assigned to the workers on this node\n    return [worker_items[i] for i in worker_ids_this_node]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    from typing import List, Any\n    import os\n    total_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n    total_workers = total_nodes * num_workers\n\n    worker_items_this_node, worker_weights_this_node = _pack_greedily(\n        items=user_items, weights=weights, num_bins=num_workers\n    )\n\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    if len(worker_items_this_node) != len(worker_weights_this_node):\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    if len(worker_items_this_node) != len(worker_ids_this_node):\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    if len(worker_items_this_node) != len(worker_weights_this_node):\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    if len(worker_items_this_node) != len(worker_ids_this_node):\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    # Print the distribution details for workers on this node\n    print(f\"Distributing {len(user_items)} items to {num_workers} workers on this node\")\n    print(f\"Workers on this node: {worker_ids_this_node}\")\n    print(f\"Total number of workers: {total_workers}\")\n    print(f\"Items per worker: {[len(x) for x in worker_items_this_node]}\")\n    print(f\"Weights per worker: {[sum(x) for x in worker_weights_this_node]}\")\n\n    if file_size:\n        file_sizes = [\n            sum(os.path.getsize(x) for x in worker_items_this_node[i]) / 1000000\n            for i in range("}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Associate the items to the workers based on number of nodes and node rank.\n    weights = [1] * len(user_items) if weights is None else weights\n\n    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n    world_size = num_nodes * num_workers\n\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    # Calculate the total size of the items\n    total_size = sum(worker_weights)\n    total_size_mb = round(total_size / 1024 / 1024, 2)\n\n    # Print the distribution details for workers on the current node\n    print(f\"Worker distribution on node {node_rank} (out of {num_nodes} nodes):\")\n    for i, worker_id in enumerate(worker_ids_this_node):\n        worker_size = worker_weights[i]\n        worker_size_mb = round(worker_size / 1024 / 1024, 2)\n        if file_size:\n            print(f\"\\tWorker {worker_id} has {len(worker_items[i])} files with total size of {worker_size_mb} MB.\")\n        else:\n            print(f\"\\tWorker {worker_id} has {len(worker_items[i])} items with total weight of {worker_size} units.\")\n\n    # Shuffle the items assigned to the workers\n    for worker_id in worker_ids_this_node:\n        random.shuffle(worker_items[worker_id])\n\n    # Return the items assigned to the workers\n    return worker_items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Associate the items to the workers based on number of nodes and node rank.\n    weights = [1] * len(user_items) if weights is None else weights\n\n    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n    world_size = num_nodes * num_workers\n\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    # Calculate the total number of items to be distributed\n    total_weight = sum(worker_weights)\n\n    # Calculate the total size of items to be distributed\n    total_size = sum(os.path.getsize(item) if isinstance(item, str) else 0 for item in user_items)\n\n    # Print the distribution details for workers on the current node\n    logger.info(\n        f\"Node {node_rank} has {num_workers} workers and will distribute {total_weight} items (total weight) or {total_size / (1024 * 1024)} MB (total size) among them.\"\n    )\n\n    # Shuffle the items for each worker\n    random.shuffle(worker_items)\n\n    # Return the items for each worker\n    return [worker_items[worker_ids_this_node[i]] for i in range(num_workers)]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    if len(user_items) != len(weights):\n        raise ValueError(\"The lengths of the user_items and weights must be equal.\")\n\n    if len(user_items) != len(set(user_items)):\n        raise ValueError(\"The user_items must be unique.\")\n\n    if len(user_items) != len(set(weights)):\n        raise ValueError(\"The weights must be unique.\")\n\n    if num_workers < 1:\n        raise ValueError(\"The number of workers must be greater than or equal to 1.\")\n\n    # Associate the items to the workers based on number of nodes and node rank.\n    weights = [1] * len(user_items) if weights is None else weights\n\n    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n    world_size = num_nodes * num_workers\n\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    # Calculate the total number of items and their total weight.\n    total_items = sum(worker_weights)\n    total_weight = sum(worker_weights)\n\n    # Calculate the total size of items and their total weight.\n    total_size = 0\n    if file_size:\n        for item in user_items:\n            if isinstance(item, Path):\n                total_size += item.stat().st_size\n            elif isinstance(item, str):\n                total_size += os.path.getsize(item)\n            else:\n                raise ValueError(\"The items must be Path or str objects.\")\n\n    # Print the distribution details for workers on the current node.\n    if file_size:\n        print(\n            f\"Node {node_rank + 1}/{num_nodes} has {len(worker_ids_this_node)} workers with a total of {total_weight}"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    if len(user_items) != len(weights):\n        raise ValueError(f\"The provided weights ({len(weights)}) do not match the number of items ({len(user_items)})\")\n\n    if num_workers == 1:\n        return [user_items]\n\n    # Associate the items to the workers based on number of nodes and node rank.\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=num_workers)\n\n    # Print distribution details for workers on the current node.\n    total_weight = sum(worker_weights)\n    total_size = sum([os.path.getsize(item) for item in user_items]) / 1000 / 1000\n\n    if file_size:\n        print(\n            f\"Node {node_rank} ({num_nodes} nodes): {len(worker_items)} workers with {total_weight} items ({total_size} MB) distributed as follows:\"\n        )\n    else:\n        print(\n            f\"Node {node_rank} ({num_nodes} nodes): {len(worker_items)} workers with {total_weight} items distributed as follows:\"\n        )\n\n    for i, items in enumerate(worker_items):\n        print(f\"Worker {i}: {len(items)} items ({sum(weights[j] for j in items)}/{total_weight})\")\n\n    # Return a list of lists, where each sublist contains the items assigned to a worker, shuffled.\n    worker_items = [random.sample(items, k=len(items)) for items in worker_items]\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    return [worker_items[i] for i in worker_ids_this_node]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Associate the items to the workers based on number of nodes and node rank.\n    total_workers = num_nodes * num_workers\n\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=total_workers)\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    # Print the distribution details for workers on the current node\n    print(f\"Distributing {len(user_items)} items across {total_workers} workers.\")\n    if file_size:\n        print(\n            f\"The distribution is weighted by file sizes. The total file size is {sum(weights) / 1000 / 1000} MB.\"\n        )\n    else:\n        print(f\"The distribution is weighted by item weights. The total weight is {sum(weights)}.\")\n    print(f\"The distribution is done by the following nodes:\")\n    for node_id in range(num_nodes):\n        print(\n            f\"Node {node_id} has {num_workers} workers with the following distribution of items:\"\n        )\n        for worker_id in range(num_workers):\n            worker_index = node_id * num_workers + worker_id\n            if worker_index in worker_ids_this_node:\n                print(\n                    f\"\\tWorker {worker_id} has {len(worker_items[worker_index])} items with a total weight of {worker_weights[worker_index]}\"\n                )\n\n    # Return the list of items for each worker, shuffled\n    return [random.sample(items, len(items)) for items in worker_items]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # 1. Calculate the total number of workers across all nodes\n    total_num_workers = _get_num_nodes() * num_workers\n\n    # 2. Calculate how many items each worker should process\n    items_per_worker = int(len(user_items) / total_num_workers)\n\n    # 3. Calculate the remainder\n    remainder = len(user_items) % total_num_workers\n\n    # 4. Calculate the cumulative sum\n    cumulative_sum = np.cumsum(np.array([items_per_worker] * total_num_workers + [items_per_worker + 1] * remainder))\n\n    # 5. Determine the start and end indices for each worker\n    start_idx = cumulative_sum[total_num_workers * _get_node_rank() : total_num_workers * (_get_node_rank() + 1)][0]\n    end_idx = cumulative_sum[total_num_workers * (_get_node_rank() + 1) : total_num_workers * (_get_node_rank() + 2)][0]\n\n    # 6. Return the items assigned to the current worker\n    return user_items[start_idx:end_idx]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # Calculate the total number of workers across all nodes\n    total_workers = _get_num_nodes() * num_workers\n\n    # Calculate the number of items each worker should process\n    items_per_worker = len(user_items) // total_workers\n\n    # Adjust for any remainder by adding extra items to the workers starting from the end of the list\n    remainder = len(user_items) % total_workers\n\n    if remainder > 0:\n        for i in range(remainder):\n            user_items[len(user_items) - i - 1] = [user_items[len(user_items) - i - 1]]\n\n    # Use cumulative sum to efficiently calculate the start and end indices for each worker's items\n    cumsum = np.cumsum([items_per_worker + 1 if i < remainder else items_per_worker for i in range(total_workers)])\n\n    # Ensure each worker knows which items they are responsible for processing\n    return [user_items[cumsum[i - 1] : cumsum[i]] for i in range(1, total_workers + 1)]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # 1. Get the number of nodes\n    num_nodes = _get_num_nodes()\n\n    # 2. Get the total number of workers across all nodes\n    num_workers_total = num_nodes * num_workers\n\n    # 3. Get the total number of items\n    num_items = len(user_items)\n\n    # 4. Calculate the number of items each worker should process\n    num_items_per_worker = int(num_items / num_workers_total)\n\n    # 5. Calculate the remainder\n    remainder = num_items % num_workers_total\n\n    # 6. Calculate the cumulative sum\n    cumulative_sum = np.cumsum(np.array([0] + [num_items_per_worker] * (num_workers_total - 1) + [num_items_per_worker + 1] * remainder))\n\n    # 7. Get the start and end indices for each worker\n    start_indices = cumulative_sum[num_workers_total * _get_node_rank() : num_workers_total * (_get_node_rank() + 1)]\n    end_indices = cumulative_sum[num_workers_total * (_get_node_rank() + 1) : num_workers_total * (_get_node_rank() + 2)]\n\n    # 8. Get the items assigned to the current worker\n    items = user_items[start_indices[_get_node_rank()] : end_indices[_get_node_rank()]]\n\n    # 9. Ensure the output list has the correct length\n    if len(items) != num_workers:\n        raise RuntimeError(\"The number of items assigned to the current worker is not equal to the number of workers.\")\n\n    return items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # 1. Get the total number of nodes and the current node's rank\n    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n\n    # 2. Calculate the number of items each worker should process\n    num_items_per_worker = len(user_items) // (num_nodes * num_workers)\n    num_items_per_worker_remainder = len(user_items) % (num_nodes * num_workers)\n\n    # 3. Calculate the number of items each worker should process in the current node\n    num_items_per_worker_node = num_items_per_worker + int(node_rank < num_items_per_worker_remainder)\n\n    # 4. Calculate the indices of the items assigned to the current node\n    start_index = node_rank * num_items_per_worker_node\n    end_index = start_index + num_items_per_worker_node\n\n    # 5. Get the items assigned to the current node\n    items = user_items[start_index:end_index]\n\n    # 6. Return the items assigned to the current node\n    return items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # Calculate the total number of workers across all nodes\n    num_workers_total = num_workers * _get_num_nodes()\n\n    # Calculate the number of items each worker should process\n    num_items_per_worker = len(user_items) // num_workers_total\n\n    # Calculate the number of items each worker should process\n    num_items_remainder = len(user_items) % num_workers_total\n\n    # Calculate the cumulative sum of the number of items each worker should process\n    items_cumsum = np.cumsum([num_items_per_worker] * num_workers_total)\n\n    # Calculate the start and end indices for each worker's items\n    items_start_indices = items_cumsum - num_items_per_worker\n    items_end_indices = items_cumsum\n\n    # Calculate the start and end indices for each worker's items\n    items_start_indices[num_workers_total - num_items_remainder :] += 1\n    items_end_indices[num_workers_total - num_items_remainder :] += 1\n\n    # Calculate the index of the current worker\n    worker_index = _get_node_rank() * num_workers + (num_workers - 1)\n\n    # Calculate the number of items assigned to the current worker\n    num_items_worker = items_end_indices[worker_index] - items_start_indices[worker_index]\n\n    # Calculate the start and end indices for the current worker's items\n    items_start_index = items_start_indices[worker_index]\n    items_end_index = items_end_indices[worker_index]\n\n    # Calculate the list of items assigned to the current worker\n    items = user_items[items_start_index:items_end_index]\n\n    # Ensure the output list has a length equal to the number of workers\n    if len(items) != num_workers:\n        raise RuntimeError(\n           "}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # Get the total number of workers across all nodes\n    total_workers = _get_num_nodes() * num_workers\n\n    # Get the total number of items\n    total_items = len(user_items)\n\n    # Calculate the number of items each worker should process\n    items_per_worker = int(total_items / total_workers)\n\n    # Adjust for any remainder\n    remainder = total_items - (items_per_worker * total_workers)\n\n    # Calculate the cumulative sum of the number of items\n    cumulative_sum = np.cumsum([items_per_worker + 1] * remainder + [items_per_worker] * (total_workers - remainder))\n\n    # Get the current node's rank\n    node_rank = _get_node_rank()\n\n    # Calculate the start and end indices for the current node's worker\n    start_index = cumulative_sum[node_rank - 1] if node_rank > 0 else 0\n    end_index = cumulative_sum[node_rank]\n\n    # Get the number of items assigned to the current node's worker\n    num_items = end_index - start_index\n\n    # Get the items assigned to the current node's worker\n    items = user_items[start_index:end_index]\n\n    # Ensure the number of items assigned to the current node's worker is equal to the number of workers\n    if len(items) != num_workers:\n        raise RuntimeError(\n            f\"The number of items assigned to the current node's worker ({len(items)}) is not equal to the number of workers ({num_workers}).\"\n        )\n\n    return items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # 1. Calculate the total number of workers across all nodes\n    total_num_workers = num_workers * _get_num_nodes()\n\n    # 2. Calculate how many items each worker should process\n    items_per_worker = len(user_items) // total_num_workers\n\n    # 3. Adjust for any remainder by adding extra items to the workers starting from the end of the list\n    remainder = len(user_items) % total_num_workers\n    if remainder > 0:\n        for i in range(remainder):\n            user_items[len(user_items) - i - 1] = [user_items[len(user_items) - i - 1]]\n\n    # 4. Use cumulative sum to efficiently calculate the start and end indices for each worker's items\n    items_per_worker_cumsum = np.cumsum(np.array([items_per_worker] * total_num_workers))\n\n    # 5. Ensure each worker knows which items they are responsible for processing\n    items_per_worker_cumsum[-1] = len(user_items)\n    items_per_worker_cumsum = items_per_worker_cumsum.tolist()\n\n    # 6. Ensure the output list has a length equal to the number of workers; otherwise, raise a RuntimeError\n    if len(items_per_worker_cumsum) != num_workers:\n        raise RuntimeError(\n            f\"The number of workers ({num_workers}) is greater than the number of items ({len(user_items)})\"\n        )\n\n    # 7. Return the list of lists containing the items assigned to each worker\n    return [user_items[items_per_worker_cumsum[i] - items_per_worker : items_per_worker_cumsum[i]] for i in range(num_workers)]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # 1. Calculate the total number of workers across all nodes\n    total_num_workers = _get_num_nodes() * num_workers\n\n    # 2. Calculate the number of items each worker should process\n    items_per_worker = int(np.ceil(len(user_items) / total_num_workers))\n\n    # 3. Calculate the cumulative sum of the items\n    items_cumsum = np.cumsum(np.array([0] + [items_per_worker] * (total_num_workers - 1)))\n\n    # 4. Calculate the start and end indices for each worker\n    start_idx = int(items_cumsum[total_num_workers - _get_node_rank() - 1])\n    end_idx = int(items_cumsum[total_num_workers - _get_node_rank()])\n\n    # 5. Check whether the number of items is equal to the total number of workers\n    if len(user_items) != total_num_workers:\n        raise RuntimeError(\n            f\"The number of items ({len(user_items)}) is not equal to the total number of workers ({total_num_workers}).\"\n        )\n\n    # 6. Return the items assigned to the worker\n    return user_items[start_idx:end_idx]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # 1. Calculate the total number of workers across all nodes.\n    num_workers_total = num_workers * _get_num_nodes()\n\n    # 2. Calculate the number of items each worker should process.\n    num_items_per_worker = len(user_items) // num_workers_total\n\n    # 3. Calculate the remainder of the division.\n    remainder = len(user_items) % num_workers_total\n\n    # 4. Calculate the cumulative sum of the number of items per worker.\n    cumsum = np.cumsum([num_items_per_worker] * num_workers_total)\n\n    # 5. Calculate the start and end indices for each worker.\n    start_indices = cumsum - num_items_per_worker\n    end_indices = cumsum\n\n    # 6. Adjust the remainder by adding extra items to the workers starting from the end of the list.\n    for i in range(remainder):\n        end_indices[-(i + 1)] += 1\n\n    # 7. Assign items to workers.\n    items_per_worker = [user_items[start_indices[i]:end_indices[i]] for i in range(num_workers_total)]\n\n    # 8. Ensure the output list has the correct length.\n    if len(items_per_worker) != num_workers:\n        raise RuntimeError(\"The number of workers assigned to each node is incorrect.\")\n\n    return items_per_worker\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # Calculate the number of workers across all nodes\n    num_workers_across_all_nodes = num_workers * _get_num_nodes()\n\n    # Calculate the number of items each worker should process\n    items_per_worker = len(user_items) // num_workers_across_all_nodes\n\n    # Adjust for any remainder by adding extra items to the workers starting from the end of the list\n    remainder = len(user_items) % num_workers_across_all_nodes\n\n    if remainder > 0:\n        for i in range(remainder):\n            user_items[num_workers_across_all_nodes * (num_workers - 1) + i] = [\n                user_items[num_workers_across_all_nodes * (num_workers - 1) + i],\n                user_items[num_workers_across_all_nodes * (num_workers - 1) + i],\n            ]\n\n    # Calculate the start and end indices for each worker's items\n    start_indices = [\n        items_per_worker * i + min(i, remainder) for i in range(num_workers_across_all_nodes)\n    ]\n    end_indices = [\n        items_per_worker * (i + 1) + min(i + 1, remainder) for i in range(num_workers_across_all_nodes)\n    ]\n\n    # Ensure the output list has a length equal to the number of workers; otherwise, raise a RuntimeError\n    if len(start_indices) != num_workers:\n        raise RuntimeError(\n            f\"The number of workers ({num_workers}) does not match the number of start indices ({len(start_indices)}).\"\n        )\n\n    # Return the items assigned to each worker\n    return [user_items[start_indices[i]:end_indices[i]] for i in range(num_workers)]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # 1. Calculate the number of workers across all nodes\n    num_workers_total = num_workers * _get_num_nodes()\n\n    # 2. Calculate the number of items each worker should process\n    items_per_worker = len(user_items) // num_workers_total\n\n    # 3. Adjust for any remainder by adding extra items to the workers starting from the end of the list, ensuring an even distribution as much as possible\n    remainder = len(user_items) % num_workers_total\n\n    # 4. Determine the start and end indices for each worker's items\n    start_idx = np.cumsum([items_per_worker] * num_workers_total)\n    end_idx = start_idx.copy()\n    end_idx[:-1] = start_idx[1:]\n    end_idx[-1] = len(user_items)\n\n    # 5. Create a list of lists, where each sublist contains the items assigned to a worker. This ensures each worker knows which items they are responsible for processing.\n    items_per_worker = [user_items[start_idx[i]:end_idx[i]] for i in range(num_workers)]\n\n    # 6. Ensure the output list has a length equal to the number of workers; otherwise, raise a RuntimeError indicating improper assignment\n    if len(items_per_worker) != num_workers:\n        raise RuntimeError(\n            f\"The number of workers ({len(items_per_worker)}) does not match the number of workers per node ({num_workers}).\"\n        )\n\n    return items_per_worker\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # 1. Get the number of nodes\n    num_nodes = _get_num_nodes()\n\n    # 2. Get the total number of workers\n    total_workers = num_nodes * num_workers\n\n    # 3. Get the current node's rank\n    node_rank = _get_node_rank()\n\n    # 4. Get the number of items\n    num_items = len(user_items)\n\n    # 5. Calculate the number of items each worker should process\n    items_per_worker = num_items // total_workers\n\n    # 6. Calculate the remainder\n    remainder = num_items % total_workers\n\n    # 7. Calculate the cumulative sum\n    cumulative_sum = np.cumsum(np.ones(total_workers, dtype=int) * items_per_worker)\n\n    # 8. Add the remainder to the last worker\n    cumulative_sum[-1] += remainder\n\n    # 9. Get the start and end indices for each worker\n    start_indices = cumulative_sum[:-1]\n    end_indices = cumulative_sum[1:]\n\n    # 10. Get the items assigned to the current worker\n    worker_items = user_items[start_indices[node_rank] : end_indices[node_rank]]\n\n    # 11. Ensure the number of items assigned to the current worker is equal to the number of workers\n    if len(worker_items) != num_workers:\n        raise RuntimeError(\n            f\"The number of items assigned to the current worker ({len(worker_items)}) is not equal to the number of workers ({num_workers}).\"\n        )\n\n    return worker_items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # Calculate the number of workers across all nodes\n    num_workers_across_all_nodes = _get_num_nodes() * num_workers\n\n    # Calculate the number of items each worker should process\n    num_items_per_worker = len(user_items) // num_workers_across_all_nodes\n\n    # Calculate the number of items each worker should process\n    num_items_remainder = len(user_items) % num_workers_across_all_nodes\n\n    # Calculate the start and end indices for each worker\n    start_indices = [\n        i * num_items_per_worker + min(i, num_items_remainder) for i in range(num_workers_across_all_nodes)\n    ]\n    end_indices = [\n        start_indices[i] + num_items_per_worker + (1 if i < num_items_remainder else 0)\n        for i in range(num_workers_across_all_nodes)\n    ]\n\n    # Determine the worker's start and end indices\n    start_index = start_indices[_get_node_rank()]\n    end_index = end_indices[_get_node_rank()]\n\n    # Assign the items to the worker\n    items = user_items[start_index:end_index]\n\n    # Raise an error if the number of workers does not match the number of items\n    if len(items) != num_workers:\n        raise RuntimeError(\n            f\"The number of workers ({num_workers}) does not match the number of items ({len(user_items)})!\"\n        )\n\n    # Return the items\n    return items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # Get the number of nodes\n    num_nodes = _get_num_nodes()\n\n    # Get the current node's rank\n    node_rank = _get_node_rank()\n\n    # Get the total number of workers across all nodes\n    total_workers = num_nodes * num_workers\n\n    # Get the number of items per worker\n    items_per_worker = len(user_items) // total_workers\n\n    # Calculate the remainder\n    remainder = len(user_items) % total_workers\n\n    # Get the cumulative sum\n    cumsum = np.cumsum(np.array([items_per_worker] * total_workers) + [remainder] * (total_workers - remainder))\n\n    # Calculate the start and end indices for each worker\n    start_index = cumsum[node_rank]\n    end_index = cumsum[node_rank + 1]\n\n    # Get the list of items assigned to the current worker\n    items = user_items[start_index:end_index]\n\n    # Raise an error if the number of items assigned to the worker is not equal to the number of workers\n    if len(items) != num_workers:\n        raise RuntimeError(\n            f\"The number of items assigned to the current worker ({len(items)}) is not equal to the number of workers ({num_workers}).\"\n        )\n\n    return items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    num_workers_per_node = num_workers\n    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n\n    num_workers_total = num_workers_per_node * num_nodes\n\n    if num_workers_total == 0:\n        raise RuntimeError(\"The number of workers must be greater than 0.\")\n\n    num_items = len(user_items)\n\n    if num_items == 0:\n        raise RuntimeError(\"The number of items must be greater than 0.\")\n\n    if num_items < num_workers_total:\n        raise RuntimeError(\"The number of items must be greater than the number of workers.\")\n\n    # Calculate the number of items each worker should process\n    items_per_worker = num_items // num_workers_total\n\n    # Calculate the number of items each worker will process on the current node\n    items_per_worker_node = items_per_worker // num_nodes\n\n    # Calculate the number of items each worker will process on the current node\n    items_per_worker_node_remainder = items_per_worker % num_nodes\n\n    # Calculate the number of items each worker will process on the current node\n    items_per_worker_total = items_per_worker_node + items_per_worker_node_remainder\n\n    # Calculate the start and end indices for each worker's items\n    start_index = node_rank * items_per_worker_total\n    end_index = start_index + items_per_worker_node\n\n    if node_rank == num_nodes - 1:\n        end_index += items_per_worker_node_remainder\n\n    # Distribute the items among the workers\n    items_per_worker_list = [items_per_worker_node] * (num_workers_per_node * num_nodes)\n\n    # Add the remainder to the last workers\n    for i in range(items_per_worker_node_remainder):\n        items_per_worker_list[-(i + 1"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    total_num_workers = num_workers * _get_num_nodes()\n    num_items = len(user_items)\n\n    if total_num_workers > num_items:\n        raise RuntimeError(\n            f\"The number of workers ({total_num_workers}) is greater than the number of items ({num_items}).\"\n        )\n\n    num_items_per_worker = num_items // total_num_workers\n    num_remainder = num_items % total_num_workers\n\n    # Calculate the number of items each worker should process\n    items_per_worker = [num_items_per_worker for _ in range(total_num_workers)]\n\n    # Distribute the remainder among the workers starting from the end of the list\n    for i in range(num_remainder):\n        items_per_worker[i + _get_node_rank() * num_workers] += 1\n\n    # Calculate the start and end indices for each worker\n    items_per_worker = np.cumsum(items_per_worker)\n    start_indices = list(items_per_worker[:-1])\n    end_indices = list(items_per_worker[1:])\n\n    # Ensure the output list has a length equal to the number of workers\n    if len(start_indices) != total_num_workers:\n        raise RuntimeError(\n            f\"The number of workers ({total_num_workers}) does not match the length of the start indices list ({len(start_indices)}).\"\n        )\n\n    # Create the output list\n    items_per_worker = [\n        user_items[start_indices[i]:end_indices[i]] for i in range(total_num_workers)\n    ]\n\n    return items_per_worker\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # 1. Calculate the total number of workers across all nodes\n    total_num_workers = _get_num_nodes() * num_workers\n\n    # 2. Calculate the number of items each worker should process\n    items_per_worker = int(np.ceil(len(user_items) / total_num_workers))\n\n    # 3. Calculate the cumulative sum of the items\n    cumulative_sum = np.cumsum(np.repeat(items_per_worker, total_num_workers))\n\n    # 4. Determine the start and end indices of each worker's items\n    start_idx = np.searchsorted(cumulative_sum, _get_node_rank() * items_per_worker)\n    end_idx = np.searchsorted(cumulative_sum, _get_node_rank() * items_per_worker + items_per_worker, side=\"right\")\n\n    # 5. Check if the number of workers matches the number of items\n    if len(user_items) < total_num_workers:\n        # 5.1. If there are more workers than items, we need to add extra items to the last workers\n        extra_items = user_items[-1:]\n        items_to_add = extra_items * (total_num_workers - len(user_items))\n\n        # 5.2. Add the extra items to the end indices\n        end_idx = np.concatenate([end_idx, end_idx[-1:] + len(items_to_add)])\n\n        # 5.3. Add the extra items to the user items\n        user_items = np.concatenate([user_items, items_to_add])\n\n    # 6. Ensure the number of workers matches the number of items\n    if len(user_items) != total_num_workers:\n        raise RuntimeError(\n            f\"The number of workers ({total_num_workers}) does not match the number of items ({len(user_items)}).\"\n        )\n\n    # 7. Return the items assigned to each"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    num_workers_per_node = num_workers\n    total_num_workers = num_workers_per_node * _get_num_nodes()\n\n    if total_num_workers == 0:\n        raise ValueError(\"The number of workers must be greater than 0.\")\n\n    if len(user_items) == 0:\n        raise ValueError(\"The number of items must be greater than 0.\")\n\n    if total_num_workers > len(user_items):\n        raise ValueError(\"The number of workers must be less than or equal to the number of items.\")\n\n    # Calculate the number of items each worker should process\n    items_per_worker = len(user_items) // total_num_workers\n\n    # Adjust for any remainder\n    items_per_worker += 1 if len(user_items) % total_num_workers > num_workers_per_node else 0\n\n    # Calculate the start and end indices for each worker\n    indices = np.arange(0, len(user_items), items_per_worker)\n\n    # Ensure the output list has the same number of workers\n    if len(indices) != total_num_workers:\n        raise RuntimeError(\"The number of workers is not equal to the number of workers.\")\n\n    # Calculate the cumulative sum\n    indices = np.cumsum(indices)\n\n    # Ensure the last index is the last item\n    indices[-1] = len(user_items)\n\n    # Get the items for each worker\n    items = [user_items[indices[i] : indices[i + 1]] for i in range(len(indices) - 1)]\n\n    # Add any remaining items to the last worker\n    items[-1].extend(user_items[indices[-1] :])\n\n    return items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # 1. Calculate the total number of workers across all nodes\n    num_workers_per_node = num_workers\n    num_workers_total = num_workers_per_node * _get_num_nodes()\n\n    # 2. Calculate the number of items each worker should process\n    num_items = len(user_items)\n    num_items_per_worker = int(num_items / num_workers_total)\n    num_items_remainder = num_items % num_workers_total\n\n    # 3. Calculate the cumulative sum\n    cumulative_sum = np.cumsum([0] + [num_items_per_worker] * (num_workers_total - 1) + [num_items_per_worker + 1])\n\n    # 4. Calculate the start and end indices for each worker\n    indices = [\n        (cumulative_sum[i], cumulative_sum[i + 1]) for i in range(num_workers_total)\n    ]\n\n    # 5. Calculate the number of items each worker should process\n    items_per_worker = [\n        user_items[indices[i][0] : indices[i][1]] for i in range(num_workers_total)\n    ]\n\n    # 6. Add extra items to the last workers in the list\n    for i in range(num_items_remainder):\n        items_per_worker[-1 * (i + 1)].append(user_items[indices[-1 * (i + 1)][0]])\n\n    # 7. Check the length of the output list\n    if len(items_per_worker) != num_workers_total:\n        raise RuntimeError(\n            \"The number of workers is not equal to the number of workers per node. This may be due to a bug or a change in the number of nodes.\"\n        )\n\n    # 8. Return the list of items assigned to each worker\n    return items_per_worker\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # 1. Calculate the total number of workers across all nodes.\n    num_nodes = _get_num_nodes()\n    num_workers_total = num_nodes * num_workers\n\n    # 2. Calculate how many items each worker should process.\n    num_items = len(user_items)\n    num_items_per_worker = int(num_items / num_workers_total)\n\n    # 3. Determine if there is a remainder.\n    remainder = num_items % num_workers_total\n\n    # 4. Calculate the cumulative sum of the number of items for each worker.\n    cumsum = np.cumsum(np.array([num_items_per_worker] * num_workers_total))\n\n    # 5. Determine the start and end indices for each worker.\n    start_indices = cumsum - num_items_per_worker\n    end_indices = cumsum\n\n    # 6. Determine if there is a remainder and add extra items to the last workers.\n    if remainder:\n        start_indices[-remainder:] = num_items - num_items_per_worker * remainder\n        end_indices[-remainder:] = num_items\n\n    # 7. Determine the start and end indices for the current node.\n    start_index = start_indices[_get_node_rank()]\n    end_index = end_indices[_get_node_rank()]\n\n    # 8. Determine the number of items assigned to the current node.\n    num_items_current_node = end_index - start_index\n\n    # 9. Ensure that the output list has the correct length.\n    if num_workers != num_items_current_node:\n        raise RuntimeError(\n            f\"The number of workers ({num_workers}) does not match the number of items assigned to the current node ({num_items_current_node}).\"\n        )\n\n    # 10. Assign the items to the workers.\n    items_per_worker = [user_items[start_index"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_dir = _get_cache_dir()\n\n        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_dir = _get_cache_dir()\n\n        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_dir = _get_cache_dir()\n\n        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_dir = _get_cache_dir()\n\n        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_dir = _get_cache_dir()\n\n        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_dir = _get_cache_dir()\n\n        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_dir = _get_cache_dir()\n\n        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_dir = _get_cache_dir()\n\n        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_dir = _get_cache_dir()\n\n        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)\n\n\n\n        \"\"\"\n        The function creates the cache directory to store the chunks.\n\n        Input-Output Arguments\n        :param self: DataProcessor. An instance of the DataProcessor class. It uses this instance to access the method.\n        :return: No return values. This method performs operations on the filesystem but does not return any value.\n        \"\"\"\n\n        cache_dir = _get_cache_dir()\n\n        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)\n"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)\n\n\n\n        \"\"\"\n        The function creates the cache directory to store the chunks.\n\n        Input-Output Arguments\n        :param self: DataProcessor. An instance of the DataProcessor class. It uses this instance to access the method.\n        :return: No return values. This method performs operations on the filesystem but does not return any value.\n        \"\"\"\n        cache_dir = _get_cache_dir()\n\n        os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_dir = _get_cache_dir()\n\n        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)\n\n\n\n        \"\"\"\n        The function creates cache directories by creating folders in the cache directory if they do not exist to ensure that they are available for use.\n\n        Input-Output Arguments\n        :param self: DataProcessor. An instance of the DataProcessor class. It uses this instance to access the method.\n        :return: No return values. This method performs operations on the filesystem but does not return any value.\n        \"\"\"\n        cache_dir = _get_cache_dir()\n\n        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)\n\n\n\n        \"\"\"\n        The function creates cache directories by creating folders in the cache directory if they do not exist to ensure that they are available for use.\n\n        Input-Output Arguments\n        :param self: DataProcessor. An instance of the DataProcessor class. It uses this instance to access the method.\n        :return: No return values. This method performs operations on the filesystem but does not return any value.\n        \"\"\"\n        cache_dir = _get_cache_dir()\n\n        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)\n\n\n\n        \"\"\"\n        The function creates cache directories by creating folders in the cache directory if they do not exist to ensure that they are available for use.\n\n        Input-Output Arguments\n        :param self: DataProcessor. An instance of"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        try:\n            item_sizes.append(future.result())\n        except Exception as exc:\n            print(f\"Exception: {exc}\")\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        try:\n            item_sizes.append(future.result())\n        except Exception as e:\n            print(e)\n            traceback.print_exc()\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        try:\n            item_sizes.append(future.result())\n        except Exception as e:\n            print(e)\n            item_sizes.append(0)\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        try:\n            item_sizes.append(future.result())\n        except Exception as e:\n            print(e)\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        try:\n            item_sizes.append(future.result())\n        except Exception as e:\n            print(e)\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        try:\n            item_sizes.append(future.result())\n        except Exception as exc:\n            print(exc)\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in futures:\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        try:\n            item_sizes.append(future.result())\n        except Exception as e:\n            print(e)\n            traceback.print_exc()\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        try:\n            item_sizes.append(future.result())\n        except Exception as e:\n            print(e)\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        try:\n            item_sizes.append(future.result())\n        except Exception as e:\n            print(e)\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        try:\n            item_sizes.append(future.result())\n        except Exception as e:\n            print(f\"Exception: {e}\")\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        try:\n            item_sizes.append(future.result())\n        except Exception as e:\n            print(e)\n            print(f\"Failed to compute file size for item: {future.result()}\")\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        try:\n            item_sizes.append(future.result())\n        except Exception as e:\n            print(e)\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        try:\n            item_sizes.append(future.result())\n        except Exception as exc:\n            print(exc)\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return _is_path(input_dir, element) or os.path.exists(_to_path(element))\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if not isinstance(element, str):\n        return False\n\n    if _IS_IN_STUDIO and input_dir is not None:\n        if element.startswith(input_dir):\n            return True\n\n        element = str(Path(element).absolute())\n\n    if os.path.exists(element) or os.path.exists(_to_path(element)):\n        return True\n\n    return False\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return _is_path(input_dir, element) or (Path(element).exists() if isinstance(element, str) else False)\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if not isinstance(element, str):\n        return False\n\n    if _IS_IN_STUDIO and input_dir is not None:\n        if element.startswith(input_dir):\n            return True\n\n        element = str(Path(element).absolute())\n\n    return Path(element).exists()\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if _IS_IN_STUDIO and input_dir is not None:\n        if element.startswith(input_dir):\n            return True\n\n        element = str(Path(element).absolute())\n\n    if isinstance(element, str) and (Path(element).exists() or Path(element).is_file()):\n        return True\n\n    return False\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if input_dir is not None and element.startswith(input_dir):\n        return True\n\n    if not isinstance(element, str):\n        return False\n\n    if _IS_IN_STUDIO and input_dir is not None:\n        if element.startswith(input_dir):\n            return True\n\n        element = str(Path(element).absolute())\n\n    return os.path.exists(element)\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if not isinstance(element, str):\n        return False\n\n    if _IS_IN_STUDIO and input_dir is not None:\n        if element.startswith(input_dir):\n            return True\n\n        element = str(Path(element).absolute())\n\n    return os.path.exists(element)\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return _is_path(input_dir, element) or os.path.exists(element)\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return _is_path(input_dir, element) or os.path.exists(_to_path(element))\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if not isinstance(element, str):\n        return False\n\n    if _IS_IN_STUDIO and input_dir is not None:\n        if element.startswith(input_dir):\n            return True\n\n        element = str(Path(element).absolute())\n\n    if os.path.exists(element):\n        return True\n\n    return False\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if not isinstance(element, str):\n        return False\n\n    if _IS_IN_STUDIO and input_dir is not None:\n        if element.startswith(input_dir):\n            return True\n\n        element = str(Path(element).absolute())\n\n    if element.startswith(\"/teamspace/studios/this_studio\"):\n        return True\n\n    if element.startswith(\"s3://\"):\n        return True\n\n    if os.path.exists(element):\n        return True\n\n    return False\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if input_dir is None:\n        return _is_path(input_dir, element)\n\n    if isinstance(element, str) and element.startswith(input_dir):\n        return True\n\n    return _is_path(input_dir, str(Path(element).absolute()))\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if not isinstance(element, str):\n        return False\n\n    if _IS_IN_STUDIO and input_dir is not None:\n        if element.startswith(input_dir):\n            return True\n\n        element = str(Path(element).absolute())\n\n    return os.path.exists(element)\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return (\n        isinstance(element, str) and\n        (\n            input_dir is not None and\n            (\n                element.startswith(input_dir) or\n                element.startswith(\"/teamspace/studios/this_studio\")\n            )\n        ) and\n        (\n            os.path.exists(element) or\n            os.path.exists(str(Path(element).absolute()))\n        )\n    )\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str) and os.path.exists(element):\n        return True\n\n    if input_dir is not None:\n        if element.startswith(input_dir):\n            return True\n\n        element = str(Path(element).absolute())\n\n    return os.path.exists(element)\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return (\n        (\n            input_dir is None\n            or (\n                (element.startswith(input_dir) if isinstance(element, str) else False)\n                and os.path.exists(element)\n            )\n        )\n        or os.path.exists(element)\n        or os.path.exists(_to_path(element))\n    )\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if not isinstance(element, str):\n        return False\n\n    if input_dir is not None:\n        if element.startswith(input_dir):\n            return True\n\n        element = str(Path(element).absolute())\n\n    if os.path.exists(element):\n        return True\n\n    return False\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if not isinstance(element, str):\n        return False\n\n    if _IS_IN_STUDIO and input_dir is not None:\n        if element.startswith(input_dir):\n            return True\n\n        element = str(Path(element).absolute())\n\n    return os.path.exists(element)\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        if input_dir is not None and element.startswith(input_dir):\n            return True\n\n        element = str(Path(element).absolute())\n\n        if os.path.exists(element):\n            return True\n\n    return False\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if _IS_IN_STUDIO and input_dir is not None:\n        if element.startswith(input_dir):\n            return True\n\n        element = str(Path(element).absolute())\n\n    if not isinstance(element, str):\n        return False\n\n    if os.path.exists(element):\n        return True\n\n    return False\n\n"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"Number of layers must be greater than 0.\"\n        assert n_neurons > 0, \"Number of neurons must be greater than 0.\"\n\n        if self.tcnn:\n            import tinycudann as tcnn\n\n            if n_layers == 1:\n                return tcnn.Network(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    n_neurons=n_neurons,\n                    activation=activation,\n                    output_activation=output_activation,\n                    internal_activation=activation,\n                )\n            else:\n                return tcnn.Network(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    n_neurons=n_neurons,\n                    n_hidden_layers=n_layers - 1,\n                    activation=activation,\n                    output_activation=output_activation,\n                    internal_activation=activation,\n                )\n\n        else:\n            layers = []\n            if n_layers == 1:\n                layers.append(nn.Linear(n_input_dims, n_output_dims))\n                if output_activation == \"ReLU\":\n                    layers.append(nn.ReLU())\n                elif output_activation == \"Sigmoid\":\n                    layers.append(nn.Sigmoid())\n                return nn.Sequential(*layers)\n            else:\n                layers.append(nn.Linear(n_input_dims, n_neurons))\n                if activation == \"ReLU\":\n                    layers.append(nn.ReLU())\n                elif activation == \"Sigmoid\":\n                    layers.append(nn.Sigmoid())\n                for i in range(n_layers - 2):\n                    layers.append(nn.Linear(n_neurons, n_neurons))\n                    if"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"Number of layers must be greater than zero.\"\n        assert n_neurons > 0, \"Number of neurons must be greater than zero.\"\n\n        if self.tcnn:\n            from tinycudann import Network\n\n            if n_layers == 1:\n                network = Network(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    n_neurons=n_neurons,\n                    activation=activation,\n                    output_activation=output_activation,\n                    net_seed=self._get_seed(),\n                )\n            else:\n                network = Network(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_neurons,\n                    n_neurons=n_neurons,\n                    activation=activation,\n                    output_activation=activation,\n                    net_seed=self._get_seed(),\n                )\n                for _ in range(n_layers - 2):\n                    network.add_layer(\n                        n_neurons=n_neurons,\n                        activation=activation,\n                        net_seed=self._get_seed(),\n                    )\n                network.add_layer(\n                    n_neurons=n_output_dims,\n                    activation=output_activation,\n                    net_seed=self._get_seed(),\n                )\n        else:\n            network = nn.Sequential()\n            network.add_module(\"input\", nn.Linear(n_input_dims, n_neurons))\n            network.add_module(\"input_activation\", self.get_activation(activation))\n            for _ in range(n_layers - 2):\n                network.add_module(\n                    f\"hidden_{len(network)}\", nn.Linear(n_neurons, n_neurons)\n                )\n                network.add_module(\n                    f\"hidden_activation_{len(network)}"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"The number of layers must be greater than 0.\"\n        assert n_neurons > 0, \"The number of neurons must be greater than 0.\"\n\n        if self.tcnn:\n            import tinycudann as tcnn\n\n            if n_layers == 1:\n                return tcnn.NetworkWithActivation(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    activation_type=activation,\n                    n_neurons=n_neurons,\n                    internal_activation_type=\"None\",\n                    use_bias=True,\n                    use_bn=False,\n                    use_ln=False,\n                    seed=self._get_seed(),\n                )\n            else:\n                layers = [\n                    tcnn.Layer_t(\n                        n_input_dims=n_input_dims,\n                        n_output_dims=n_neurons,\n                        activation_type=activation,\n                        n_neurons=n_neurons,\n                        internal_activation_type=\"None\",\n                        use_bias=True,\n                        use_bn=False,\n                        use_ln=False,\n                        seed=self._get_seed(),\n                    )\n                ]\n                for i in range(n_layers - 2):\n                    layers.append(\n                        tcnn.Layer_t(\n                            n_input_dims=n_neurons,\n                            n_output_dims=n_neurons,\n                            activation_type=activation,\n                            n_neurons=n_neurons,\n                            internal_activation_type=\"None\",\n                            use_bias=True,\n                            use_bn=False,\n                            use_ln=False,\n                            seed=self._get_seed(),\n                        )\n                    )\n                layers.append(\n                    tcnn.Layer_t(\n                        n_"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"Number of layers must be greater than zero.\"\n        assert n_neurons > 0, \"Number of neurons must be greater than zero.\"\n\n        if self.tcnn:\n            from tinycudann import Network\n\n            if n_layers == 1:\n                network = Network(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    n_neurons=n_neurons,\n                    activation=activation,\n                    output_activation=output_activation,\n                    n_hidden_layers=0,\n                )\n            else:\n                network = Network(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    n_neurons=n_neurons,\n                    activation=activation,\n                    output_activation=output_activation,\n                    n_hidden_layers=n_layers - 1,\n                )\n        else:\n            network = nn.Sequential()\n            for i in range(n_layers):\n                if i == 0:\n                    network.add_module(\n                        \"layer_0\",\n                        nn.Linear(\n                            in_features=n_input_dims,\n                            out_features=n_neurons,\n                            bias=True,\n                        ),\n                    )\n                elif i == n_layers - 1:\n                    network.add_module(\n                        f\"layer_{i}\",\n                        nn.Linear(\n                            in_features=n_neurons,\n                            out_features=n_output_dims,\n                            bias=True,\n                        ),\n                    )\n                else:\n                    network.add_module(\n                        f\"layer_{i}\",\n                        nn.Linear(\n                            in_features=n_neurons,\n                            out_features=n_neurons,\n                            bias=True,\n                        ),"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        # assert n_layers > 0, \"n_layers must be greater than 0\"\n        # assert n_neurons > 0, \"n_neurons must be greater than 0\"\n\n        if self.tcnn:\n            from tinycudann.networks import Network\n\n            if n_layers == 1:\n                return Network(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    n_neurons=n_neurons,\n                    activation=activation,\n                    output_activation=output_activation,\n                    use_bias=True,\n                )\n            else:\n                return Network(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    n_neurons=n_neurons,\n                    n_hidden_layers=n_layers - 1,\n                    activation=activation,\n                    output_activation=output_activation,\n                    use_bias=True,\n                )\n        else:\n            if n_layers == 1:\n                return nn.Sequential(\n                    nn.Linear(n_input_dims, n_output_dims, bias=True),\n                    getattr(nn, output_activation)(),\n                )\n            else:\n                return nn.Sequential(\n                    nn.Linear(n_input_dims, n_neurons, bias=True),\n                    getattr(nn, activation)(),\n                    *[\n                        nn.Sequential(\n                            nn.Linear(n_neurons, n_neurons, bias=True),\n                            getattr(nn, activation)(),\n                        )\n                        for _ in range(n_layers - 2)\n                    ],\n                    nn.Linear(n_neurons, n_output_dims, bias=True),\n                    getattr(nn, output_activation)(),\n                )"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"Number of layers must be greater than 0.\"\n        assert n_neurons > 0, \"Number of neurons must be greater than 0.\"\n\n        if self.tcnn:\n            import tinycudann as tcnn\n\n            if n_layers == 1:\n                # Create a single-layer network.\n                return tcnn.Network(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    n_neurons=n_neurons,\n                    activation_type=activation,\n                    output_activation_type=output_activation,\n                    use_bias=True,\n                    use_batch_norm=False,\n                    use_dropout=False,\n                    use_layernorm=False,\n                    seed=self._get_seed(),\n                )\n            else:\n                # Create a multi-layer network.\n                return tcnn.Network(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    n_neurons=n_neurons,\n                    n_hidden_layers=n_layers - 1,\n                    activation_type=activation,\n                    output_activation_type=output_activation,\n                    use_bias=True,\n                    use_batch_norm=False,\n                    use_dropout=False,\n                    use_layernorm=False,\n                    seed=self._get_seed(),\n                )\n        else:\n            # Create a multi-layer network.\n            layers = []\n            if n_layers == 1:\n                # Create a single-layer network.\n                layers.append(nn.Linear(n_input_dims, n_output_dims))\n            else:\n                # Create a multi-layer network.\n                layers.append(nn.Linear(n_input_dims, n_neurons))\n                for _ in range(n_layers -"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert (\n                n_layers > 0\n        ), \"Number of layers must be greater than 0.\"\n        assert (\n                n_neurons > 0\n        ), \"Number of neurons must be greater than 0.\"\n\n        if self.tcnn:\n            import tinycudann as tcnn\n\n            if n_neurons == 1:\n                return tcnn.Network(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    activation=activation,\n                    n_neurons=n_neurons,\n                    n_hidden_layers=n_layers - 1,\n                )\n            else:\n                return tcnn.Network(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    activation=activation,\n                    n_neurons=n_neurons,\n                    n_hidden_layers=n_layers - 1,\n                )\n        else:\n            layers = []\n            layers.append(nn.Linear(n_input_dims, n_neurons))\n            layers.append(getattr(nn, activation)())\n            for i in range(n_layers - 2):\n                layers.append(nn.Linear(n_neurons, n_neurons))\n                layers.append(getattr(nn, activation)())\n            layers.append(nn.Linear(n_neurons, n_output_dims))\n            layers.append(getattr(nn, output_activation)())\n            return nn.Sequential(*layers)\n"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert (\n            n_layers > 0 and n_neurons > 0\n        ), \"Invalid network configuration. Both n_layers and n_neurons must be greater than 0.\"\n\n        if self.tcnn:\n            from tinycudann import ReseededAdamOptimizer, Network\n\n            if n_layers == 1:\n                return Network(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    activation=activation,\n                    n_neurons=n_neurons,\n                    internal_activation=activation,\n                    use_bias=True,\n                    use_last_layer_bias=True,\n                    alpha=0.0,\n                    momentum=0.0,\n                    epsilon=1e-7,\n                    use_batch_norm=False,\n                    use_dropout=False,\n                    dropout_probability=0.0,\n                    use_layer_norm=False,\n                    use_xavier_init=True,\n                    use_adaptive_xavier_init=False,\n                    use_he_init=False,\n                    use_seeded_async_init=True,\n                    seed=self._get_seed(),\n                )\n            else:\n                return Network(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    activation=activation,\n                    n_neurons=n_neurons,\n                    n_hidden_layers=n_layers - 1,\n                    internal_activation=activation,\n                    use_bias=True,\n                    use_last_layer_bias=True,\n                    alpha=0.0,\n                    momentum=0.0,\n                    epsilon=1e-7,\n                    use_batch_norm=False,\n                    use_dropout=False,\n                    dropout_probability=0.0,\n                   "}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"Number of layers must be greater than 0.\"\n        assert n_neurons > 0, \"Number of neurons must be greater than 0.\"\n\n        if self.tcnn:\n            from tinycudann.models.networks import (\n                FCNN,\n                ConvolutionalNetwork2D,\n                ConvolutionalNetwork3D,\n            )\n\n            if n_layers == 1:\n                return FCNN(\n                    n_input_dims,\n                    n_output_dims,\n                    n_neurons,\n                    activation=activation,\n                    output_activation=output_activation,\n                    seed=self._get_seed(),\n                )\n            elif n_layers == 2:\n                return ConvolutionalNetwork2D(\n                    n_input_dims,\n                    n_output_dims,\n                    n_neurons,\n                    activation=activation,\n                    output_activation=output_activation,\n                    seed=self._get_seed(),\n                )\n            elif n_layers == 3:\n                return ConvolutionalNetwork3D(\n                    n_input_dims,\n                    n_output_dims,\n                    n_neurons,\n                    activation=activation,\n                    output_activation=output_activation,\n                    seed=self._get_seed(),\n                )\n            else:\n                raise NotImplementedError(\n                    \"The number of layers must be 1, 2, or 3 for the tinycudann implementation.\"\n                )\n        else:\n            if n_layers == 1:\n                return nn.Sequential(\n                    nn.Linear(n_input_dims, n_output_dims),\n                    getattr(nn, activation)(),\n                    getattr(nn, output_activation)(),\n                )\n            elif n_layers == 2:\n                return nn.Sequential(\n                    nn.Linear(n_input_dims, n_neurons),\n                    getattr"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        # Ensure valid network configuration\n        assert n_layers > 0, \"The number of layers must be greater than zero.\"\n        assert n_neurons > 0, \"The number of neurons must be greater than zero.\"\n\n        # Create the network\n        if self.tcnn:\n            import tinycudann as tcnn\n\n            # Select the network type based on the number of neurons\n            if n_neurons == 1:\n                network_type = \"RBFNode\"\n            elif n_neurons == 3:\n                network_type = \"RodriguesParamsNode\"\n            else:\n                network_type = \"FullyFusedMLP\"\n\n            # Create the network\n            return tcnn.Network(\n                {\n                    \"n_inputs\": n_input_dims,\n                    \"n_outputs\": n_output_dims,\n                    \"network_type\": network_type,\n                    \"activation\": activation,\n                    \"n_neurons\": n_neurons,\n                    \"n_hidden_layers\": n_layers - 1,\n                    \"output_activation\": output_activation,\n                }\n            )\n        else:\n            # Create the network\n            layers = []\n            for i in range(n_layers - 1):\n                layers.append(nn.Linear(n_input_dims, n_neurons))\n                layers.append(getattr(nn, activation)())\n                n_input_dims = n_neurons\n            layers.append(nn.Linear(n_input_dims, n_output_dims))\n            layers.append(getattr(nn, output_activation)())\n            return nn.Sequential(*layers)"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"The number of layers must be greater than 0.\"\n        assert n_neurons > 0, \"The number of neurons must be greater than 0.\"\n\n        if self.tcnn:\n            import tinycudann as tcnn\n\n            if n_neurons == 1:\n                network = tcnn.Network(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    activation=activation,\n                    n_neurons=n_neurons,\n                    n_hidden_layers=n_layers - 1,\n                )\n            else:\n                network = tcnn.Network(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    activation=activation,\n                    n_neurons=n_neurons,\n                    n_hidden_layers=n_layers - 1,\n                    tcnn_params={\"heuristic\": \"batch_norm\"},\n                )\n\n        else:\n            network = nn.Sequential()\n            network.add_module(\"input_layer\", nn.Linear(n_input_dims, n_neurons))\n            network.add_module(\"input_activation\", self.get_activation(activation))\n\n            for i in range(n_layers - 2):\n                network.add_module(\n                    f\"hidden_layer_{i}\", nn.Linear(n_neurons, n_neurons)\n                )\n                network.add_module(f\"hidden_activation_{i}\", self.get_activation(activation))\n\n            network.add_module(\n                f\"output_layer\", nn.Linear(n_neurons, n_output_dims)\n            )\n            network.add_module(f\"output_activation\", self.get_activation(output_activation))\n\n        return network\n"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"Number of layers must be greater than 0.\"\n        assert n_neurons > 0, \"Number of neurons must be greater than 0.\"\n\n        if self.tcnn:\n            import torch\n            import tinycudann as tcnn\n\n            if n_layers == 1:\n                network = tcnn.NetworkWithActivation(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    activation=activation,\n                    bias=True,\n                    internal_activation=\"None\",\n                    net_type=\"dense\",\n                    seed=self._get_seed(),\n                )\n            else:\n                network = tcnn.NetworkWithActivation(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_neurons,\n                    activation=activation,\n                    bias=True,\n                    internal_activation=\"None\",\n                    net_type=\"dense\",\n                    seed=self._get_seed(),\n                )\n                for _ in range(n_layers - 2):\n                    network = tcnn.NetworkWithActivation(\n                        n_input_dims=n_neurons,\n                        n_output_dims=n_neurons,\n                        activation=activation,\n                        bias=True,\n                        internal_activation=\"None\",\n                        net_type=\"dense\",\n                        seed=self._get_seed(),\n                    )\n                network = tcnn.NetworkWithActivation(\n                    n_input_dims=n_neurons,\n                    n_output_dims=n_output_dims,\n                    activation=output_activation,\n                    bias=True,\n                    internal_activation=\"None\",\n                    net_type=\"dense\",\n                    seed=self._get_seed(),\n                )\n\n        else:\n            network = nn.Sequential()\n            for i in range"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0 and n_neurons > 0, \"Invalid network configuration.\"\n\n        if self.tcnn:\n            import tinycudann as tcnn\n\n            if n_layers == 1:\n                return tcnn.Network(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    n_neurons=n_neurons,\n                    activation=activation,\n                    output_activation=output_activation,\n                    internal_activation=activation,\n                    use_bias=True,\n                    use_bn=False,\n                    architecture=\"FullyFusedMLP\",\n                    seed=self._get_seed(),\n                )\n\n            return tcnn.Network(\n                n_input_dims=n_input_dims,\n                n_output_dims=n_output_dims,\n                n_neurons=n_neurons,\n                n_hidden_layers=n_layers - 1,\n                activation=activation,\n                output_activation=output_activation,\n                internal_activation=activation,\n                use_bias=True,\n                use_bn=False,\n                architecture=\"FullyFusedMLP\",\n                seed=self._get_seed(),\n            )\n\n        else:\n            network = nn.Sequential()\n\n            for i in range(n_layers - 1):\n                network.add_module(\n                    f\"layer_{i}\",\n                    nn.Linear(\n                        in_features=n_input_dims if i == 0 else n_neurons,\n                        out_features=n_neurons,\n                        bias=True,\n                    ),\n                )\n                network.add_module(f\"activation_{i}\", getattr(nn, activation)())\n\n            network.add_module(\n                \"output_layer\",\n                nn.Linear(\n                    in_features=n_input_dims if n_layers == 1"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"n_layers must be greater than 0.\"\n        assert n_neurons > 0, \"n_neurons must be greater than 0.\"\n\n        if self.tcnn:\n            from tinycudann import ReseededAdamOptimizer, Network\n\n            if n_layers == 1:\n                # Linear network\n                return Network(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    activation=\"None\",\n                    n_neurons=n_neurons,\n                    internal_activation=\"None\",\n                    bias=True,\n                    bias_init=0,\n                    use_bn=False,\n                    use_bias=True,\n                    use_wa=False,\n                    lr=1e-3,\n                    seed=self._get_seed(),\n                )\n\n            else:\n                # Multi-layer network\n                return Network(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    activation=activation,\n                    n_neurons=n_neurons,\n                    internal_activation=activation,\n                    bias=True,\n                    bias_init=0,\n                    use_bn=False,\n                    use_bias=True,\n                    use_wa=False,\n                    lr=1e-3,\n                    seed=self._get_seed(),\n                )\n\n        else:\n            # Linear network\n            if n_layers == 1:\n                return nn.Linear(n_input_dims, n_output_dims)\n\n            # Multi-layer network\n            layers = []\n            for i in range(n_layers - 1):\n                layers.append(nn.Linear(n_neurons, n_neurons))\n                layers.append(getattr(nn, activation)())\n\n            layers.append(nn.Linear(n_neurons, n_output"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"Number of layers must be greater than 0.\"\n        assert n_neurons > 0, \"Number of neurons must be greater than 0.\"\n\n        if self.tcnn:\n            from tinycudann import Network\n\n            if n_layers == 1:\n                network = Network(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    n_neurons=n_neurons,\n                    activation_type=activation,\n                    output_activation_type=output_activation,\n                    use_bias=True,\n                    use_dropout=False,\n                    use_batch_norm=False,\n                    use_layer_norm=False,\n                    use_weight_norm=False,\n                    use_layernorm_before_pool=False,\n                    use_layernorm_after_pool=False,\n                    use_layernorm_after_fc=False,\n                    use_l2_norm_weights=False,\n                    use_l2_norm_weights_diff=False,\n                    use_l2_norm_weights_grad=False,\n                    use_l2_norm_weights_diff_grad=False,\n                    use_weight_pruning=False,\n                    use_weight_pruning_diff=False,\n                    use_weight_pruning_grad=False,\n                    use_weight_pruning_diff_grad=False,\n                    use_weight_pruning_magnitude=False,\n                    use_weight_pruning_magnitude_diff=False,\n                    use_weight_pruning_magnitude_grad=False,\n                    use_weight_pruning_magnitude_diff_grad=False,\n                    use_weight_pruning_magnitude_threshold=False,\n                    use_weight_pruning_magnitude_threshold_diff=False,\n                    use_weight_pruning_magnitude_"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"Number of layers must be greater than 0.\"\n        assert n_neurons > 0, \"Number of neurons must be greater than 0.\"\n\n        if self.tcnn:\n            import tinycudann as tcnn\n\n            # TODO: Add support for other activation functions\n            if activation == \"ReLU\":\n                activation = tcnn.ReLU()\n            elif activation == \"None\":\n                activation = tcnn.Identity()\n\n            # TODO: Add support for other activation functions\n            if output_activation == \"ReLU\":\n                output_activation = tcnn.ReLU()\n            elif output_activation == \"Sigmoid\":\n                output_activation = tcnn.Sigmoid()\n            elif output_activation == \"None\":\n                output_activation = tcnn.Identity()\n\n            if n_neurons < 1024:\n                net = tcnn.Network(\n                    n_input_dims, n_output_dims, n_neurons, activation, output_activation\n                )\n            else:\n                net = tcnn.Network(\n                    n_input_dims,\n                    n_output_dims,\n                    n_neurons,\n                    activation,\n                    output_activation,\n                    {\"n_hidden_layers\": n_layers - 2},\n                )\n\n        else:\n            net = nn.Sequential()\n            for i in range(n_layers):\n                net.add_module(\n                    \"linear\" + str(i),\n                    nn.Linear(\n                        n_input_dims if i == 0 else n_neurons,\n                        n_output_dims if i == n_layers - 1 else n_neurons,\n                    ),\n                )\n                if i < n_layers - 1:\n                    net.add_module(\"activation\" + str(i), nn.ReLU())\n\n        return net"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"Number of layers must be greater than 0.\"\n        assert n_neurons > 0, \"Number of neurons must be greater than 0.\"\n\n        if self.tcnn:\n            import tinycudann as tcnn\n\n            if n_layers == 1:\n                return tcnn.Network(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    activation=activation,\n                    n_neurons=n_neurons,\n                )\n            else:\n                return tcnn.Network(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    n_neurons=n_neurons,\n                    n_hidden_layers=n_layers - 1,\n                    activation=activation,\n                    output_activation=output_activation,\n                )\n        else:\n            layers = []\n            if n_layers == 1:\n                layers.append(nn.Linear(n_input_dims, n_output_dims))\n            else:\n                layers.append(nn.Linear(n_input_dims, n_neurons))\n                for i in range(n_layers - 2):\n                    layers.append(nn.ReLU())\n                    layers.append(nn.Linear(n_neurons, n_neurons))\n                layers.append(nn.ReLU())\n                layers.append(nn.Linear(n_neurons, n_output_dims))\n\n            if output_activation == \"Sigmoid\":\n                layers.append(nn.Sigmoid())\n            elif output_activation == \"None\":\n                pass\n            else:\n                raise ValueError(\n                    f\"{output_activation} is not a valid output activation function.\"\n                )\n\n            return nn.Sequential(*layers)\n\n"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"The number of layers must be greater than 0.\"\n        assert n_neurons > 0, \"The number of neurons must be greater than 0.\"\n\n        if self.tcnn:\n            from tinycudann import Network\n\n            if n_layers == 1:\n                network_type = \"fc\"\n            elif n_layers == 2:\n                network_type = \"fc2\"\n            elif n_layers == 3:\n                network_type = \"fc3\"\n            else:\n                raise NotImplementedError(\n                    \"tinycudann does not support networks with more than 3 hidden layers.\"\n                )\n\n            network = Network(\n                n_input_dims,\n                n_output_dims,\n                network_type,\n                n_neurons,\n                activation,\n                output_activation,\n            )\n        else:\n            layers = []\n            layers.append(nn.Linear(n_input_dims, n_neurons))\n            layers.append(getattr(nn, activation)())\n            for _ in range(n_layers - 2):\n                layers.append(nn.Linear(n_neurons, n_neurons))\n                layers.append(getattr(nn, activation)())\n            layers.append(nn.Linear(n_neurons, n_output_dims))\n            layers.append(getattr(nn, output_activation)())\n\n            network = nn.Sequential(*layers)\n\n        return network\n"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        # Ensure valid network configuration\n        assert n_layers > 0, \"n_layers must be greater than 0.\"\n        assert n_neurons > 0, \"n_neurons must be greater than 0.\"\n\n        # Generate a network using tinycudann\n        if self.tcnn:\n            if n_neurons == 1:\n                return nn.Sequential(\n                    tcnn.ReLU(n_input_dims, n_output_dims),\n                )\n            else:\n                return nn.Sequential(\n                    tcnn.ReLU(n_input_dims, n_neurons),\n                    *[\n                        tcnn.ReLU(n_neurons, n_neurons)\n                        for _ in range(n_layers - 2)\n                    ],\n                    tcnn.ReLU(n_neurons, n_output_dims),\n                )\n\n        # Generate a network using PyTorch\n        else:\n            # Define the network\n            net = nn.Sequential(\n                nn.Linear(n_input_dims, n_neurons),\n                nn.ReLU(),\n                *[\n                    nn.Sequential(\n                        nn.Linear(n_neurons, n_neurons),\n                        nn.ReLU(),\n                    )\n                    for _ in range(n_layers - 2)\n                ],\n                nn.Linear(n_neurons, n_output_dims),\n            )\n\n            if output_activation == \"Sigmoid\":\n                net.add_module(\"output_activation\", nn.Sigmoid())\n            elif output_activation == \"None\":\n                pass\n            else:\n                raise ValueError(\n                    f\"Output activation {output_activation} not supported.\"\n                )\n\n            return net\n\n"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        # Assert that the network parameters are valid.\n        assert n_layers > 0 and n_neurons > 0, \"Invalid network parameters.\"\n\n        # Use tinycudann if the tcnn flag is set to True.\n        if self.tcnn:\n            # Import the tinycudann package.\n            import tinycudann as tcnn\n\n            # Select the network type based on the number of neurons.\n            if n_neurons <= 1024:\n                network_type = \"fcnn\"\n            elif n_neurons <= 4096:\n                network_type = \"snn\"\n            else:\n                network_type = \"unet\"\n\n            # Return the network.\n            return tcnn.Network(\n                network_type=network_type,\n                n_inputs=n_input_dims,\n                n_outputs=n_output_dims,\n                n_neurons=n_neurons,\n                n_hidden_layers=n_layers - 1,\n                activation_type=activation,\n                output_activation_type=output_activation,\n                use_bias=True,\n                use_dropout=False,\n                use_batch_norm=False,\n                use_layer_norm=False,\n                use_xavier_init=True,\n                use_kaiming_init=False,\n                use_gain_init=True,\n                use_fan_in_init=False,\n                seed=self._get_seed(),\n            )\n\n        # Otherwise, construct the network sequentially, layer by layer.\n        else:\n            # Construct the network.\n            network = nn.Sequential()\n\n            # Add the input layer.\n            network.add_module(\n                name=\"input\",\n                module=nn.Linear(\n                    in_features=n_input_dims, out_features=n_neurons, bias=True\n                ),\n            )\n\n            # Add the hidden layers.\n            for i in range(n_layers - 2):\n                network.add_module(\n                   "}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Compute the rolling median by shifting the signal by a range defined by the kernel offset, computing the median of these shifted signals, and then trimming the resulting median array to account for edge effects introduced by the shifting process.\n        rolling_median = np.median(np.array([signal[i : len(signal) - (kernel_offset - i)] for i in range(kernel_offset)]), axis=0)\n        rolling_median = rolling_median[kernel_offset : len(rolling_median) - kernel_offset]\n\n        return rolling_median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Calculate the rolling median of the input signal\n        rolling_median = np.median(np.array([signal[i : i + 2 * kernel_offset + 1] for i in range(2 * kernel_offset)]), axis=0)\n\n        # Trim the rolling median array to remove edge effects\n        return rolling_median[kernel_offset : 2 * kernel_offset]"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Compute the rolling median by shifting the signal by a range defined by the kernel offset, computing the median of these shifted signals, and then trimmimg the resulting median array to account for edge effects introduced by the shifting process.\n        rolling_median = np.median(np.array([signal[i : len(signal) - kernel_offset + i] for i in range(kernel_offset)]), axis=0)\n\n        # Trim the rolling median array to account for edge effects introduced by the shifting process.\n        return rolling_median[kernel_offset : len(rolling_median) - kernel_offset]"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Pad the signal with 2 * kernel_offset elements on both sides\n        signal_padded = np.pad(signal, 2 * kernel_offset, 'edge')\n\n        # Generate shifted versions of the signal\n        signal_shifted = np.array([np.roll(signal_padded, -i) for i in range(2 * kernel_offset + 1)])\n\n        # Compute the median of the shifted signal\n        signal_median = np.median(signal_shifted, axis=0)\n\n        # Trim the signal to remove edge effects\n        signal_median = signal_median[kernel_offset:-kernel_offset]\n\n        return signal_median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Pad the signal with mirrored values at the beginning and end of the signal.\n        padded_signal = np.concatenate((signal[kernel_offset - 1 :: -1], signal, signal[-1 : -kernel_offset - 1 : -1]))\n\n        # Compute the median of the padded signal.\n        rolling_median = np.median(padded_signal.reshape(-1, 2 * kernel_offset + 1), axis=1)\n\n        # Trim the rolling median array to remove edge effects.\n        rolling_median = rolling_median[kernel_offset:-kernel_offset]\n\n        return rolling_median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Compute the rolling median by shifting the signal by a range of kernel_offset shifts in both directions.\n        # The shifted signals are then used to calculate the median.\n        shifted_signal = np.array([np.roll(signal, i) for i in range(-kernel_offset, kernel_offset + 1)])\n        rolling_median = np.median(shifted_signal, axis=0)\n\n        # Trim the rolling median array to remove edge effects.\n        trimmed_rolling_median = rolling_median[kernel_offset:-kernel_offset]\n\n        return trimmed_rolling_median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Generate the rolling median array by shifting the signal by the kernel offset, computing the median of the shifted signals, and then trimming the resulting array to remove edge effects.\n        rolling_median = np.median(\n            np.array(\n                [signal[i : len(signal) - (kernel_offset - i)] for i in range(0, kernel_offset + 1)]\n                + [signal[(kernel_offset - i) : i] for i in range(len(signal) - kernel_offset, len(signal))]\n            ),\n            axis=0,\n        )\n        return rolling_median[kernel_offset : len(rolling_median) - kernel_offset]"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Pad the signal array with 2 * kernel_offset elements on each side.\n        signal_padded = np.pad(signal, 2 * kernel_offset, mode=\"edge\")\n\n        # Create a kernel of size 2 * kernel_offset + 1.\n        kernel = np.ones(2 * kernel_offset + 1)\n\n        # Compute the median of the signal array using the kernel.\n        median = np.median(np.convolve(signal_padded, kernel, mode=\"same\"), axis=0)\n\n        # Trim the signal array to remove the edge effects introduced by the padding process.\n        median = median[kernel_offset:-kernel_offset]\n\n        return median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Pad the signal with 2 * kernel_offset elements on both sides.\n        signal_padded = np.pad(signal, 2 * kernel_offset, mode=\"edge\")\n\n        # Generate shifted versions of the signal.\n        signal_shifted = [np.roll(signal_padded, i) for i in range(-kernel_offset, kernel_offset + 1)]\n\n        # Compute the median of the shifted signal.\n        signal_median = np.median(signal_shifted, axis=0)\n\n        # Trim the signal to remove the edge effects introduced by the shifting process.\n        signal_median = signal_median[kernel_offset : -kernel_offset]\n\n        return signal_median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Pad the signal with the first and last elements to account for edge effects.\n        signal_padded = np.concatenate((signal[:kernel_offset], signal, signal[-kernel_offset:]))\n\n        # Shift the signal by a range of kernel_offset elements in both directions.\n        signal_shifted = np.array([signal_padded[i : i + len(signal)] for i in range(-kernel_offset, kernel_offset + 1)])\n\n        # Calculate the median of the shifted signal.\n        signal_median = np.median(signal_shifted, axis=0)\n\n        # Trim the signal median to account for edge effects.\n        signal_median = signal_median[kernel_offset:-kernel_offset]\n\n        return signal_median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Calculate the rolling median using the signal shifting process.\n        median = np.median(np.vstack([signal[kernel_offset:-kernel_offset], np.roll(signal, -kernel_offset)[kernel_offset:-kernel_offset], np.roll(signal, kernel_offset)[kernel_offset:-kernel_offset]]), axis=0)\n\n        # Trim the rolling median array to account for edge effects.\n        median = median[kernel_offset:-kernel_offset]\n\n        return median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Create a rolling window for the signal\n        window = np.arange(-kernel_offset, kernel_offset + 1)\n\n        # Shift the signal by the kernel offset\n        shifted_signal = np.roll(signal, kernel_offset)\n\n        # Calculate the median of the shifted signal\n        median_signal = np.median(np.roll(shifted_signal, window), axis=1)\n\n        # Trim the median signal to remove edge effects\n        median_signal = median_signal[kernel_offset:-kernel_offset]\n\n        return median_signal"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Pad the signal with 2 * kernel_offset elements at each end to account for edge effects\n        signal_padded = np.pad(signal, 2 * kernel_offset, \"edge\")\n        # Create a kernel of length 2 * kernel_offset + 1\n        kernel = np.ones(2 * kernel_offset + 1)\n        # Compute the median of the signal using the kernel\n        signal_median = np.convolve(signal_padded, kernel, mode=\"same\") / (2 * kernel_offset + 1)\n        # Trim the signal to remove the padding\n        signal_median_trimmed = signal_median[kernel_offset : 2 * kernel_offset + 1 + len(signal)]\n\n        return signal_median_trimmed"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Pad the signal with 2 * kernel_offset elements on each side to account for edge effects of the rolling median.\n        padded_signal = np.pad(signal, 2 * kernel_offset, mode=\"edge\")\n\n        # Create the kernel for the rolling median calculation.\n        kernel = np.ones(2 * kernel_offset + 1)\n\n        # Calculate the rolling median.\n        median_signal = np.convolve(padded_signal, kernel, mode=\"valid\")\n\n        # Trim the signal to remove the edge effects.\n        trimmed_signal = median_signal[kernel_offset:-kernel_offset]\n\n        return trimmed_signal"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Pad the signal array with its edge values to account for edge effects.\n        signal = np.pad(signal, (kernel_offset, kernel_offset), mode=\"edge\")\n\n        # Create an empty array to hold the rolling median.\n        rolling_median = np.zeros(len(signal) - 2 * kernel_offset)\n\n        # For each element in the rolling median array, compute the median of the shifted signal array.\n        for i in range(len(rolling_median)):\n            rolling_median[i] = np.median(signal[i : i + 2 * kernel_offset + 1])\n\n        # Return the rolling median array.\n        return rolling_median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Compute the rolling median by shifting the signal array by a range of values defined by the kernel offset, computing the median of these shifted signals, and then trimming the resulting median array to account for edge effects introduced by the shifting process.\n        # Note: the shifting process introduces edge effects. To account for these edge effects, the rolling median is trimmed by kernel_offset elements on each side.\n        rolling_median = np.zeros(len(signal) - 2 * kernel_offset)\n        for i in range(kernel_offset, len(signal) - kernel_offset):\n            rolling_median[i - kernel_offset] = np.median(signal[i - kernel_offset : i + kernel_offset + 1])\n\n        return rolling_median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Pad the signal array to account for edge effects of the rolling median.\n        padded_signal = np.pad(signal, 2 * kernel_offset, \"symmetric\")\n\n        # Generate shifted versions of the signal array.\n        shifted_signal = np.array(\n            [np.roll(padded_signal, -i) for i in range(-2 * kernel_offset, 2 * kernel_offset + 1)]\n        )\n\n        # Calculate the median of the shifted signal array.\n        median_signal = np.median(shifted_signal, axis=0)\n\n        # Trim the median signal to remove the edge effects introduced by the padding process.\n        median_signal = median_signal[kernel_offset : -kernel_offset]\n\n        return median_signal"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Pad the signal with 2 * kernel_offset elements to account for edge effects of the rolling median\n        signal_padded = np.concatenate((np.zeros(2 * kernel_offset), signal, np.zeros(2 * kernel_offset)))\n\n        # Shift the signal by a range of 2 * kernel_offset elements to generate shifted versions of itself\n        # for median calculation.\n        signal_shifted = np.roll(signal_padded, 2 * kernel_offset)\n\n        # Calculate the median of the shifted signal\n        median_signal = np.median(signal_shifted, axis=0)\n\n        # Trim the median signal to remove edge effects\n        median_signal = median_signal[kernel_offset:-kernel_offset]\n\n        return median_signal"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Check that kernel_offset is an integer\n        if not isinstance(kernel_offset, int):\n            raise ValueError(\"kernel_offset must be an integer!\")\n\n        # Check that kernel_offset is greater than 0\n        if kernel_offset <= 0:\n            raise ValueError(\"kernel_offset must be greater than 0!\")\n\n        # Check that kernel_offset is less than half of the signal length\n        if kernel_offset >= int(len(signal) / 2):\n            raise ValueError(\"kernel_offset must be less than half of the signal length!\")\n\n        # Check that kernel_offset is less than the signal length\n        if kernel_offset >= len(signal):\n            raise ValueError(\"kernel_offset must be less than the signal length!\")\n\n        # Check that the signal is a 1D array\n        if len(signal.shape) != 1:\n            raise ValueError(\"signal must be a 1D array!\")\n\n        # Initialize the rolling median array\n        rolling_median = np.zeros(len(signal) - 2 * kernel_offset)\n\n        # Loop through each element of the signal array and compute the median of the shifted signal\n        for i in range(kernel_offset, len(signal) - kernel_offset):\n            rolling_median[i - kernel_offset] = np.median(signal[i - kernel_offset : i + kernel_offset + 1])\n\n        return rolling_median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Pad the signal array with edge effects to account for shifts that go beyond the array bounds.\n        signal_padded = np.pad(signal, 2 * kernel_offset, mode=\"edge\")\n\n        # Create a kernel of length 2 * kernel_offset + 1, where the center element is 1, and the rest are 0.\n        kernel = np.zeros(2 * kernel_offset + 1)\n        kernel[kernel_offset] = 1\n\n        # Calculate the median of the shifted signal array using a convolution.\n        signal_median = np.convolve(signal_padded, kernel, mode=\"same\")\n\n        # Trim the signal median array to remove the edge effects introduced by the padding process.\n        signal_median = signal_median[kernel_offset : -kernel_offset]\n\n        return signal_median"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Calculate the size of the code\n    toal_codesize = template_probe.code.shape[0] * template_probe.code.shape[1]\n\n    # Calculate the half width\n    half_width = [int(np.ceil(toal_codesize / 2)) for _ in range(template_probe.code.shape[0])]\n\n    # Calculate the square root of the total number of bits\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        toal_codesize, half_width, weights\n    )\n\n    # Calculate the number of nonmatch bits\n    (\n        irisbitcount_top,\n        maskbitcount_top,\n        irisbitcount_bot,\n        maskbitcount_bot,\n    ) = count_nonmatchbits(template_probe.code, template_gallery.code, half_width, weights)\n\n    # Calculate the Hamming distance\n    if weights:\n        HD_top = np.sum(\n            [\n                np.sum(np.multiply(x[:, hw:, ...] & y[:, hw:, ...], z[:, hw:, ...]))\n                for x, y, hw, z in zip(template_probe.code, template_gallery.code, half_width, weights)\n            ]\n        )\n        HD_bot = np.sum(\n            [\n                np.sum(np.multiply(x[:, :hw, ...] & y[:, :hw, ...], z[:, :hw, ...]))\n                for x, y, hw, z in zip(template_probe.code, template_gallery.code, half_width, weights)\n            ]\n        )\n    else:\n        HD_top = np.sum(\n            [np.sum(x[:, hw:, ...] & y[:, hw:, ...]) for x, y, hw in zip(template_probe.code, template_gallery.code, half_width)]\n       "}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Get half widths\n    half_width = [int(np.floor(w / 2)) for w in template_probe.shape]\n\n    # Get total bit counts\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        template_probe.size, half_width, weights\n    )\n\n    # Get nonmatch bits\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        template_probe.iriscode,\n        template_probe.maskcode,\n        half_width,\n        weights,\n    )\n\n    # Calculate HD\n    if weights:\n        hd_top = np.sum(\n            [\n                np.sum(np.multiply(x[:, hw:, ...] & y[:, hw:, ...], z[:, hw:, ...]))\n                for x, y, hw, z in zip(template_probe.iriscode, template_gallery.iriscode, half_width, weights)\n            ]\n        )\n        hd_bot = np.sum(\n            [\n                np.sum(np.multiply(x[:, :hw, ...] & y[:, :hw, ...], z[:, :hw, ...]))\n                for x, y, hw, z in zip(template_probe.iriscode, template_gallery.iriscode, half_width, weights)\n            ]\n        )\n    else:\n        hd_top = np.sum(\n            [np.sum(x[:, hw:, ...] & y[:, hw:, ...]) for x, y, hw in zip(template_probe.iriscode, template_gallery.iriscode, half_width)]\n        )\n        hd_bot = np.sum(\n            [np.sum(x[:, :hw, ...] & y[:, :hw, ...]) for x, y, hw in zip(template_probe."}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Get the size of the iriscode\n    toal_codesize = template_probe.code_size\n\n    # Get the half width of the iriscode\n    half_width = [int(np.ceil(toal_codesize / 2)) for _ in range(template_probe.code_size)]\n\n    # Count total amount of sqrt bits\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        toal_codesize, half_width, weights\n    )\n\n    # Count nonmatch bits\n    (\n        irisbitcount_top,\n        maskbitcount_top,\n        irisbitcount_bot,\n        maskbitcount_bot,\n    ) = count_nonmatchbits(template_probe.iriscode, template_gallery.maskcode, half_width, weights)\n\n    # Calculate HD\n    HD_top = np.sum(\n        [\n            np.sum(np.multiply(x[:, hw:, ...] & y[:, hw:, ...], z[:, hw:, ...]))\n            for x, y, hw, z in zip(template_probe.iriscode, template_gallery.maskcode, half_width, weights)\n        ]\n    )\n    HD_bot = np.sum(\n        [\n            np.sum(np.multiply(x[:, :hw, ...] & y[:, :hw, ...], z[:, :hw, ...]))\n            for x, y, hw, z in zip(template_probe.iriscode, template_gallery.maskcode, half_width, weights)\n        ]\n    )\n\n    # Calculate normalized HD\n    if nm_dist:\n        norm_HD_top = normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist)\n        norm_HD_bot = normalized_HD(irisbitcount_bot, maskbitcount_bot, sqrt_totalbitcount_"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Get the half width of the code\n    half_width = [int(np.ceil(template_probe.code.shape[1] / 2)), int(np.ceil(template_gallery.code.shape[1] / 2))]\n\n    # Get the total size of the code\n    toal_codesize = template_probe.code.shape[1]\n\n    # Get the number of bits in the code\n    code_bit_count = template_probe.code.shape[0] * template_probe.code.shape[1]\n\n    # Get the number of bits in the mask\n    mask_bit_count = template_probe.mask.shape[0] * template_probe.mask.shape[1]\n\n    # Get the number of bits in the code\n    code_bit_count = template_probe.code.shape[0] * template_probe.code.shape[1]\n\n    # Get the number of bits in the mask\n    mask_bit_count = template_probe.mask.shape[0] * template_probe.mask.shape[1]\n\n    # Get the number of bits in the mask\n    mask_bit_count = template_probe.mask.shape[0] * template_probe.mask.shape[1]\n\n    # Get the number of bits in the mask\n    mask_bit_count = template_probe.mask.shape[0] * template_probe.mask.shape[1]\n\n    # Get the number of bits in the mask\n    mask_bit_count = template_probe.mask.shape[0] * template_probe.mask.shape[1]\n\n    # Get the number of bits in the mask\n    mask_bit_count = template_probe.mask.shape[0] * template_probe.mask.shape[1]\n\n    # Get the number of bits in the mask\n    mask_bit_count = template_probe.mask.shape[0] * template_probe.mask.shape[1]\n\n    # Get the number of bits in the mask\n    mask_bit_count = template_pro"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Check if the probe and gallery iris templates are the same size.\n    if template_probe.code_size != template_gallery.code_size:\n        raise MatcherError(\n            f\"The probe and gallery iris templates are not the same size: {template_probe.code_size} != {template_gallery.code_size}\"\n        )\n\n    # Check if the probe and gallery iris templates are the same size.\n    if template_probe.code_size != template_gallery.code_size:\n        raise MatcherError(\n            f\"The probe and gallery iris templates are not the same size: {template_probe.code_size} != {template_gallery.code_size}\"\n        )\n\n    # Check if the probe and gallery iris templates are the same size.\n    if template_probe.code_size != template_gallery.code_size:\n        raise MatcherError(\n            f\"The probe and gallery iris templates are not the same size: {template_probe.code_size} != {template_gallery.code_size}\"\n        )\n\n    # Check if the probe and gallery iris templates are the same size.\n    if template_probe.code_size != template_gallery.code_size:\n        raise MatcherError(\n            f\"The probe and gallery iris templates are not the same size: {template_probe.code_size} != {template_gallery.code_size}\"\n        )\n\n    # Check if the rotation shift is within the allowed range.\n    if not (0 <= rotation_shift <= template_probe.code_size // 2):\n        raise MatcherError(\n            f\"The rotation shift must be between 0 and {template_probe.code_size // 2}: {rotation_shift} != {template_probe.code_size // 2}\"\n        )\n\n    # Check if the rotation shift is within the allowed range.\n    if not (0 <= rotation_shift <= template_gallery.code_size // 2):\n        raise MatcherError(\n            f\"The"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Check if probe and gallery template are of the same size.\n    if template_probe.template.shape != template_gallery.template.shape:\n        raise MatcherError(\"Probe and gallery template must be of the same size.\")\n\n    # Check if probe and gallery template are of the same size.\n    if template_probe.mask.shape != template_gallery.mask.shape:\n        raise MatcherError(\"Probe and gallery mask must be of the same size.\")\n\n    # Check if probe and gallery template are of the same size.\n    if template_probe.weights is not None and template_gallery.weights is not None:\n        if template_probe.weights.shape != template_gallery.weights.shape:\n            raise MatcherError(\"Probe and gallery weights must be of the same size.\")\n\n    # Check if rotation shift is a positive integer.\n    if not isinstance(rotation_shift, int) or rotation_shift < 0:\n        raise MatcherError(\"Rotation shift must be a positive integer.\")\n\n    # Calculate the half width of the template.\n    half_width = [int(np.floor(template_probe.template.shape[0] / 2)) + 1, int(np.floor(template_probe.template.shape[1] / 2)) + 1]\n\n    # Calculate the total amount of bits in the template.\n    toal_codesize = np.sum(template_probe.mask)\n\n    # Calculate the square root of the total amount of bits in the template.\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        toal_codesize, half_width, weights\n    )\n\n    # Calculate the nonmatch bits for the top and bottom halves of the template.\n    (\n        irisbitcount_top,\n        maskbitcount_top,\n        irisbitcount_bot,\n        maskbitcount_bot,\n    ) = count_nonmatchbits(template_probe.template, template_g"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Calculate the Hamming distance between the probe and gallery iris templates\n    hd = np.sum(np.abs(template_probe.iris_code - template_gallery.iris_code))\n\n    # Calculate the Hamming distance between the probe and gallery mask templates\n    mask_hd = np.sum(np.abs(template_probe.mask_code - template_gallery.mask_code))\n\n    # Calculate the amount of half width\n    half_width = [int(np.ceil(x / 2)) for x in template_probe.code_size]\n\n    # Calculate the square root of total bit counts\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        sum(template_probe.code_size), half_width, weights\n    )\n\n    # Calculate the nonmatch bits\n    (\n        irisbitcount_top,\n        maskbitcount_top,\n        irisbitcount_bot,\n        maskbitcount_bot,\n    ) = count_nonmatchbits(template_probe.iris_code, template_probe.mask_code, half_width, weights)\n\n    # Calculate the Hamming distance between the probe and gallery iris templates, considering an allowed rotation shift\n    hd_rot = np.zeros(rotation_shift)\n    for i in range(rotation_shift):\n        hd_rot[i] = np.sum(\n            np.abs(\n                np.roll(template_probe.iris_code, i, axis=1)[:, :, :] - np.roll(template_gallery.iris_code, i, axis=1)[:, :, :]\n            )\n        )\n\n    # Calculate the Hamming distance between the probe and gallery mask templates, considering an allowed rotation shift\n    mask_hd_rot = np.zeros(rotation_shift)\n    for i in range(rotation_shift):\n        mask_hd_rot[i] = np.sum(\n            np"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    if template_probe.iriscode.shape != template_gallery.iriscode.shape:\n        raise MatcherError(\"Probe and gallery iriscode shapes are not equal.\")\n\n    if template_probe.maskcode.shape != template_gallery.maskcode.shape:\n        raise MatcherError(\"Probe and gallery maskcode shapes are not equal.\")\n\n    if template_probe.maskcode.shape != template_gallery.maskcode.shape:\n        raise MatcherError(\"Probe and gallery maskcode shapes are not equal.\")\n\n    if template_probe.iriscode.ndim != 3:\n        raise MatcherError(\"Iriscode must be a 3D numpy array.\")\n\n    if template_probe.maskcode.ndim != 3:\n        raise MatcherError(\"Maskcode must be a 3D numpy array.\")\n\n    if template_probe.maskcode.ndim != 3:\n        raise MatcherError(\"Maskcode must be a 3D numpy array.\")\n\n    if rotation_shift > 180:\n        raise MatcherError(\"Rotation shift must be less than 180.\")\n\n    if rotation_shift < 0:\n        raise MatcherError(\"Rotation shift must be greater than 0.\")\n\n    if nm_dist and nm_dist < 0:\n        raise MatcherError(\"Nonmatch distance must be greater than 0.\")\n\n    if weights and len(weights) != 3:\n        raise MatcherError(\"Weights must be a list of three numpy arrays.\")\n\n    if weights and any(w.ndim != 3 for w in weights):\n        raise MatcherError(\"Weights must be a list of three numpy arrays.\")\n\n    if weights and any(w.shape != template_probe.iriscode.shape for w in weights):\n        raise MatcherError(\"Weights must be a list of three numpy arrays with the same shape as the iriscode.\")\n\n    if weights and any(w.shape != template_probe.maskcode.shape for w in weights):\n        raise MatcherError(\"Weights must be a list of three numpy"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Check if the rotation_shift is valid\n    if rotation_shift > template_probe.code_size or rotation_shift > template_gallery.code_size:\n        raise MatcherError(\n            \"The rotation shift is too large for the current iris template size. Please choose a smaller rotation shift.\"\n        )\n\n    # Check if the template sizes are equal\n    if template_probe.code_size != template_gallery.code_size:\n        raise MatcherError(\"The two iris templates must have the same size.\")\n\n    # Calculate the half width of the code\n    half_width = [int(np.ceil(template_probe.code_size / 2)) for _ in range(template_probe.code_size)]\n\n    # Calculate the square root of the total bit count\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        template_probe.code_size, half_width, weights\n    )\n\n    # Calculate the nonmatch bit count\n    (\n        irisbitcount_top,\n        maskbitcount_top,\n        irisbitcount_bot,\n        maskbitcount_bot,\n    ) = count_nonmatchbits(template_probe.irisbits, template_gallery.maskbits, half_width, weights)\n\n    # Calculate the Hamming distance\n    if weights:\n        HD_top = np.sum(\n            [\n                np.sum(np.multiply(x[:, hw:, ...] & y[:, hw:, ...], z[:, hw:, ...]))\n                for x, y, hw, z in zip(template_probe.irisbits, template_gallery.maskbits, half_width, weights)\n            ]\n        )\n        HD_bot = np.sum(\n            [\n                np.sum(np.multiply(x[:, :hw, ...] & y[:, :hw, ...], z[:, :hw, ...]))\n                for x, y, hw, z in zip(template_pro"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Check if the probe and gallery templates are valid\n    if not template_probe.is_valid():\n        raise MatcherError(\"The probe template is not valid.\")\n\n    if not template_gallery.is_valid():\n        raise MatcherError(\"The gallery template is not valid.\")\n\n    # Check if the rotation shift is valid\n    if rotation_shift < 0:\n        raise MatcherError(\"The rotation shift must be a positive integer.\")\n\n    # Check if the number of weights is equal to the number of iris codes\n    if weights and len(weights) != len(template_probe.iris_codes):\n        raise MatcherError(\n            f\"The number of weights must be equal to the number of iris codes. Probe has {len(template_probe.iris_codes)} iris codes, but {len(weights)} weights were given.\"\n        )\n\n    # Check if the number of weights is equal to the number of iris codes\n    if weights and len(weights) != len(template_gallery.iris_codes):\n        raise MatcherError(\n            f\"The number of weights must be equal to the number of iris codes. Gallery has {len(template_gallery.iris_codes)} iris codes, but {len(weights)} weights were given.\"\n        )\n\n    # Calculate the half width of the iris codes\n    half_width = [int(np.floor(w / 2)) for w in template_probe.iris_codes[0].shape]\n\n    # Calculate the total number of bits in the iris codes\n    toal_codesize = np.sum(\n        [np.sum(np.multiply(x, y)) for x, y in zip(template_probe.iris_codes, template_gallery.iris_codes)]\n    )\n\n    # Calculate the square root of the total number of bits\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        toal_codesize, half_width, weights\n    )"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    if template_probe.iriscode.shape != template_gallery.iriscode.shape:\n        raise MatcherError(\n            f\"Iriscode shape of probe and gallery do not match: {template_probe.iriscode.shape} != {template_gallery.iriscode.shape}\"\n        )\n\n    if weights:\n        if len(weights) != len(template_probe.iriscode):\n            raise MatcherError(\n                f\"Number of weights tables does not match number of iriscode layers: {len(weights)} != {len(template_probe.iriscode)}\"\n            )\n        for w in weights:\n            if w.shape != template_probe.iriscode.shape[1:]:\n                raise MatcherError(\n                    f\"Shape of weights table does not match shape of iriscode layers: {w.shape} != {template_probe.iriscode.shape[1:]}\"\n                )\n\n    half_width = [int(np.floor(w / 2)) for w in template_probe.iriscode.shape[1:]]\n\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        toal_codesize=template_probe.iriscode.shape[0],\n        half_width=half_width,\n        weights=weights,\n    )\n\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        irisbits=template_probe.iriscode,\n        maskbits=template_gallery.maskcode,\n        half_width=half_width,\n        weights=weights,\n    )\n\n    # calculate HD for top and bottom iris\n    hd_top = max(\n        [\n            normalized_HD(\n                irisbitcount=irisbitcount_top,\n                maskbitcount=maskbitcount_top,\n                sqrt_totalbitcount=sqrt_totalbitcount_top,"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Get iris sizes\n    iris_width = template_probe.iris_width\n    iris_height = template_probe.iris_height\n\n    # Get code sizes\n    code_width = template_probe.code_width\n    code_height = template_probe.code_height\n\n    # Get half width\n    half_width = [int(code_width / 2), int(code_height / 2)]\n\n    # Get total codesize\n    toal_codesize = code_width * code_height\n\n    # Get rotation shift in columns\n    rotation_shift_col = rotation_shift * code_width\n\n    # Get masks\n    mask_top = template_probe.mask_top\n    mask_bot = template_probe.mask_bot\n\n    # Get weights\n    if weights:\n        weights_top = weights[0]\n        weights_bot = weights[1]\n\n    # Get probe irisbits and maskbits\n    probe_irisbits = template_probe.irisbits\n    probe_maskbits = template_probe.maskbits\n\n    # Get gallery irisbits and maskbits\n    gallery_irisbits = template_gallery.irisbits\n    gallery_maskbits = template_gallery.maskbits\n\n    # Get rotation shifted probe irisbits and maskbits\n    probe_irisbits_rot = np.roll(probe_irisbits, rotation_shift_col, axis=1)\n    probe_maskbits_rot = np.roll(probe_maskbits, rotation_shift_col, axis=1)\n\n    # Get rotation shifted gallery irisbits and maskbits\n    gallery_irisbits_rot = np.roll(gallery_irisbits, rotation_shift_col, axis=1)\n    gallery_maskbits_rot = np.roll(gallery_maskbits, rotation_shift_col, axis=1)\n\n    # Get probe iriscode\n    probe_iriscode = np.bitwise_and(probe_irisbits_rot, probe_maskbits"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Get the half width of the iris code\n    half_width = [int(x / 2) for x in template_probe.code_size]\n\n    # Get the number of bits in the iris code\n    toal_codesize = np.prod(template_probe.code_size)\n\n    # Get the number of bits in the mask code\n    maskbits = np.sum(template_probe.mask)\n\n    # Get the number of bits in the nonmatched iris code\n    irisbits = np.sum(template_probe.code & ~template_probe.mask)\n\n    # Count the square root of total bits\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        toal_codesize, half_width, weights\n    )\n\n    # Count nonmatch bits\n    (\n        irisbitcount_top,\n        maskbitcount_top,\n        irisbitcount_bot,\n        maskbitcount_bot,\n    ) = count_nonmatchbits(irisbits, maskbits, half_width, weights)\n\n    # Calculate the Hamming distance\n    HD = max(\n        0,\n        toal_codesize\n        - min(\n            [\n                np.sum(np.abs(x[:, hw:, ...] - y[:, hw:, ...]))\n                for x, y, hw in zip(template_probe.code, template_gallery.code, half_width)\n            ]\n        ),\n    )\n\n    # Calculate the normalized Hamming distance\n    if nm_dist:\n        norm_HD = normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist)\n\n    # Calculate the weighted Hamming distance\n    if weights:\n        weighted_HD = np.sum(\n            [\n                np.sum(np.abs(x[:, hw:, ...] - y[:, hw:, ...]))\n                for x,"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # check if rotation_shift is a positive integer\n    if not isinstance(rotation_shift, int) or rotation_shift < 0:\n        raise MatcherError(\"Rotation shift must be a positive integer\")\n\n    # check if nm_dist is a positive float\n    if nm_dist is not None and (not isinstance(nm_dist, float) or nm_dist < 0):\n        raise MatcherError(\"Nonmatch distance must be a positive float\")\n\n    # check if weights are a list of ndarrays\n    if weights is not None and not isinstance(weights, list):\n        raise MatcherError(\"Weights must be a list of ndarrays\")\n\n    # check if weights are a list of ndarrays\n    if weights is not None and not all(isinstance(w, np.ndarray) for w in weights):\n        raise MatcherError(\"Weights must be a list of ndarrays\")\n\n    # check if weights are a list of ndarrays\n    if weights is not None and not all(w.shape == template_gallery.shape for w in weights):\n        raise MatcherError(\"Weights must be a list of ndarrays with the same shape as the gallery iris template\")\n\n    # check if weights are a list of ndarrays\n    if weights is not None and not all(w.shape == template_probe.shape for w in weights):\n        raise MatcherError(\"Weights must be a list of ndarrays with the same shape as the probe iris template\")\n\n    # calculate the half widths\n    half_width = [int(np.ceil(template_gallery.shape[1] / 2)) for _ in range(template_gallery.shape[0])]\n\n    # calculate the total number of bits in the code\n    toal_codesize = np.sum(template_gallery.shape)\n\n    # calculate the number of bits in the code for the top and bottom half\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n       "}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    if weights:\n        if not len(weights) == len(template_probe.iris_code):\n            raise MatcherError(\n                \"Number of weights table must be equal to number of iriscode.\"\n            )\n\n    if nm_dist:\n        if not 0 <= nm_dist <= 1:\n            raise MatcherError(\n                \"Nonmatch distance must be between 0 and 1.\"\n            )\n\n    if not 0 <= rotation_shift <= 90:\n        raise MatcherError(\n            \"Rotation shift must be between 0 and 90.\"\n        )\n\n    half_width = [int(np.ceil(template_probe.iris_code[i].shape[1] / 2)) for i in range(len(template_probe.iris_code))]\n\n    # Calculate the Hamming distance\n    min_HD = np.inf\n    min_rotation_shift = 0\n    for rotation_shift_try in range(rotation_shift + 1):\n        # Rotate the probe template\n        template_probe_rotated = template_probe.rotate_template(rotation_shift_try)\n\n        # Calculate the bit count\n        irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n            template_probe_rotated.iris_code,\n            template_gallery.mask_code,\n            half_width,\n            weights,\n        )\n\n        # Calculate the square root bit count\n        sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n            template_probe_rotated.iris_code.shape[1],\n            half_width,\n            weights,\n        )\n\n        # Calculate the Hamming distance\n        HD = max(\n            irisbitcount_top / maskbitcount_top,\n            irisbitcount_bot / maskbitcount_bot,\n        )\n\n        # Calculate the normalized Hamming distance"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Check if rotation_shift is valid\n    if rotation_shift % 2 != 0 or rotation_shift < 0:\n        raise MatcherError(\"Invalid rotation_shift value. Please enter a valid rotation_shift.\")\n\n    # Get half width of the template\n    half_width = [int(template_probe.shape[i] / 2) for i in range(len(template_probe.shape))]\n\n    # Get total amount of bits\n    toal_codesize = np.sum(template_probe.mask)\n\n    # Get square root of total amount of bits\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        toal_codesize, half_width, weights\n    )\n\n    # Get nonmatch bits\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        template_probe.iris_bits, template_gallery.mask, half_width, weights\n    )\n\n    # Calculate Hamming distance\n    hd_top = np.sum(\n        [\n            np.sum(np.multiply(x[:, hw:, ...] & y[:, hw:, ...], z[:, hw:, ...]))\n            for x, y, hw, z in zip(template_probe.iris_bits, template_gallery.mask, half_width, weights)\n        ]\n    )\n\n    hd_bot = np.sum(\n        [\n            np.sum(np.multiply(x[:, :hw, ...] & y[:, :hw, ...], z[:, :hw, ...]))\n            for x, y, hw, z in zip(template_probe.iris_bits, template_gallery.mask, half_width, weights)\n        ]\n    )\n\n    hd_top = hd_top / sqrt_totalbitcount_top\n    hd_bot = hd_bot / sqrt_totalbitcount_bot\n\n   "}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    if template_probe.shape != template_gallery.shape:\n        raise MatcherError(\"Probe and gallery shapes do not match\")\n\n    if nm_dist and nm_dist < 0:\n        raise MatcherError(\"Non-match distance must be positive\")\n\n    if weights and len(weights) != 3:\n        raise MatcherError(\"Weights must be a list of three ndarrays\")\n\n    if weights and not all(w.shape == template_probe.shape for w in weights):\n        raise MatcherError(\"Weights must be ndarrays with the same shape as the probe and gallery\")\n\n    if weights and not all(np.all(w == weights[0]) for w in weights[1:]):\n        raise MatcherError(\"Weights must all be the same\")\n\n    if rotation_shift < 0:\n        raise MatcherError(\"Rotation shift must be positive\")\n\n    if rotation_shift > template_probe.shape[1]:\n        raise MatcherError(\"Rotation shift must be less than the number of columns in the probe\")\n\n    half_width = [int(np.ceil(template_probe.shape[1] / 2)), int(np.ceil(template_gallery.shape[1] / 2))]\n\n    # Calculate the total amount of sqrt bits in the iris code\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        template_probe.shape[1], half_width, weights\n    )\n\n    # Calculate the nonmatch bits for the Hamming distance calculation\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        template_probe.iris_code, template_gallery.mask_code, half_width, weights\n    )\n\n    # Calculate the Hamming distance\n    if weights:\n        hd_top = np.sum(\n            [\n                np.sum(np.multiply(x[:, hw:"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Check if rotation_shift is valid\n    if rotation_shift < 0:\n        raise MatcherError(\"Rotation shift must be a non-negative integer.\")\n\n    # Check if weights is valid\n    if weights is not None:\n        if not isinstance(weights, list):\n            raise MatcherError(\"Parameter 'weights' must be a list.\")\n        for weight in weights:\n            if not isinstance(weight, np.ndarray):\n                raise MatcherError(\"Parameter 'weights' must be a list of numpy arrays.\")\n\n    # Check if probe and gallery iris templates have the same size\n    if template_probe.code_size != template_gallery.code_size:\n        raise MatcherError(\"The probe and gallery iris templates must have the same size.\")\n\n    # Get half width\n    half_width = [int(template_probe.code_size / 2) for _ in range(template_probe.code_size)]\n\n    # Get number of bits in probe and gallery iris codes\n    probe_code_size = template_probe.code_size\n    gallery_code_size = template_gallery.code_size\n\n    # Get number of bits in probe and gallery mask codes\n    probe_mask_size = template_probe.mask_size\n    gallery_mask_size = template_gallery.mask_size\n\n    # Get probe and gallery iris codes\n    probe_iriscode = template_probe.iriscode\n    gallery_iriscode = template_gallery.iriscode\n\n    # Get probe and gallery mask codes\n    probe_maskcode = template_probe.maskcode\n    gallery_maskcode = template_gallery.maskcode\n\n    # Get probe and gallery weights\n    probe_weights = weights[0] if weights else None\n    gallery_weights = weights[1] if weights else None\n\n    # Get probe and gallery code sizes\n    probe_code_size = template_probe.code_size\n    gallery_code_size = template_gallery.code_size\n\n    # Get pro"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    if nm_dist is None and weights is None:\n        raise MatcherError(\"No normalized Hamming distance or weights specified\")\n\n    if weights is not None:\n        if len(weights) != 3:\n            raise MatcherError(\"Weights list must contain three elements\")\n\n        if weights[0].shape != weights[1].shape or weights[0].shape != weights[2].shape:\n            raise MatcherError(\"Weights list must contain three elements of equal size\")\n\n        if weights[0].shape != template_probe.code.shape or weights[1].shape != template_gallery.code.shape:\n            raise MatcherError(\"Weights list must contain three elements of equal size\")\n\n    half_width = [int(np.floor(template_probe.code.shape[1] / 2)), int(np.floor(template_gallery.code.shape[1] / 2))]\n\n    # Calculate the Hamming distance for each possible rotation shift\n    hd_list = []\n    for i in range(-rotation_shift, rotation_shift + 1):\n        # Rotate the probe template\n        template_probe_rot = np.rot90(template_probe.code, i, (1, 2))\n\n        # Calculate the Hamming distance for each possible rotation shift\n        hd = np.sum(template_probe_rot & template_gallery.code)\n        hd_list.append(hd)\n\n    # Find the minimum Hamming distance\n    min_hd = np.min(hd_list)\n\n    # Find the corresponding rotation shift\n    min_hd_idx = np.argmin(hd_list)\n    min_rotation_shift = -rotation_shift + min_hd_idx\n\n    # Calculate the square root of the total amount of bits\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        template_probe.code.size, half_width, weights\n    )\n\n    # Calculate the nonmatch bits\n    (\n        ir"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    if template_probe.code.shape != template_gallery.code.shape:\n        raise MatcherError(\"Template codes are not of the same shape.\")\n\n    if not np.all(template_probe.code.shape == template_gallery.code.shape):\n        raise MatcherError(\"Template codes are not of the same shape.\")\n\n    if not np.all(template_probe.mask.shape == template_gallery.mask.shape):\n        raise MatcherError(\"Template masks are not of the same shape.\")\n\n    if template_probe.code.shape[1] % 2 == 0:\n        raise MatcherError(\"Template codes are not of odd width.\")\n\n    if template_probe.mask.shape[1] % 2 == 0:\n        raise MatcherError(\"Template masks are not of odd width.\")\n\n    if template_probe.code.shape[2] != template_gallery.code.shape[2]:\n        raise MatcherError(\"Template codes are not of the same height.\")\n\n    if template_probe.mask.shape[2] != template_gallery.mask.shape[2]:\n        raise MatcherError(\"Template masks are not of the same height.\")\n\n    if not np.all(template_probe.mask == template_gallery.mask):\n        raise MatcherError(\"Template masks are not the same.\")\n\n    if not np.all(template_probe.mask_type == template_gallery.mask_type):\n        raise MatcherError(\"Template masks are not the same.\")\n\n    if weights:\n        if len(weights) != len(template_probe.code.shape):\n            raise MatcherError(\"Number of weights tables does not match the number of template code layers.\")\n\n        for w, w_shape in zip(weights, template_probe.code.shape):\n            if w.shape != w_shape:\n                raise MatcherError(\"Weights table shapes do not match the shape of the template codes.\")\n\n    # Calculate the half-width of the template codes.\n    half_width = [int(np.ceil(w /"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Initialize the arrays that will be returned\n        first_bisectors_point = np.zeros(2)\n        second_bisectors_point = np.zeros(2)\n\n        # Initialize the number of iterations\n        num_iterations = 0\n\n        # Initialize the number of successful iterations\n        num_successful_iterations = 0\n\n        # Initialize the number of pairs of points that meet the distance criterion\n        num_pairs_of_points_that_meet_distance_criterion = 0\n\n        # Initialize the number of pairs of points that meet the distance criterion\n        num_pairs_of_points_that_meet_distance_criterion = 0\n\n        # Initialize the number of pairs of points that meet the distance criterion\n        num_pairs_of_points_that_meet_distance_criterion = 0\n\n        # Initialize the number of pairs of points that meet the distance criterion\n        num_pairs_of_points_that_meet_distance_criterion = 0\n\n        # Initialize the number of pairs of points that meet the distance criterion\n        num_pairs_of_points_that_meet_distance_criterion = 0\n\n        # Initialize the number of pairs of points that meet the distance criterion\n        num_pairs_of_points_that_meet_distance_criterion = 0\n\n        # Initialize the number of pairs of points that meet the distance criterion\n        num_pairs_of_points_that_meet_distance_criterion = 0\n\n        # Initialize the number of pairs of points that meet the distance criterion\n        num_pairs_of_points_that_meet_distance_criterion = 0\n\n        # Initialize the number of pairs of points that meet the distance criterion\n        num_pairs_of_points_that_meet_distance_criterion = 0\n\n        # Initialize the number of pairs of points that meet the distance criterion\n        num_pairs_of_points_that_meet_distance_criterion = 0\n\n        # Initialize the number"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Number of iterations to try to find a sufficient number of points that are sufficiently far away from each other.\n        max_iterations = self.params.max_iterations\n\n        # Number of points to choose from the polygon to calculate perpendicular bisectors.\n        num_bisectors = self.params.num_bisectors\n\n        # Number of points to choose from the polygon to calculate perpendicular bisectors.\n        num_bisectors = self.params.num_bisectors\n\n        # Number of points to choose from the polygon to calculate perpendicular bisectors.\n        num_bisectors = self.params.num_bisectors\n\n        # Number of points to choose from the polygon to calculate perpendicular bisectors.\n        num_bisectors = self.params.num_bisectors\n\n        # Number of points to choose from the polygon to calculate perpendicular bisectors.\n        num_bisectors = self.params.num_bisectors\n\n        # Number of points to choose from the polygon to calculate perpendicular bisectors.\n        num_bisectors = self.params.num_bisectors\n\n        # Number of points to choose from the polygon to calculate perpendicular bisectors.\n        num_bisectors = self.params.num_bisectors\n\n        # Number of points to choose from the polygon to calculate perpendicular bisectors.\n        num_bisectors = self.params.num_bisectors\n\n        # Number of points to choose from the polygon to calculate perpendicular bisectors.\n        num_bisectors = self.params.num_bisectors\n\n        # Number of points to choose from the polygon to calculate perpendicular bisectors.\n        num_bisectors = self.params.num_bisectors\n\n        # Number of points to choose from the polygon to calculate perpendicular bisectors.\n        num_bisectors = self.params.num_bisectors\n\n        # Number of points to choose from the polygon to calculate perpendicular bisectors.\n        num_bisectors = self.params.num_bisectors\n\n        # Number of points to choose from the polygon to calculate perpendicular bisectors.\n        num_bisectors = self.params.num_bisectors\n\n        # Number"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Initialize the array that will hold the coordinates of the starting points of the bisectors.\n        first_bisectors_point = np.zeros((self.params.num_bisectors, 2), dtype=np.float64)\n\n        # Initialize the array that will hold the coordinates of the ending points of the bisectors.\n        second_bisectors_point = np.zeros((self.params.num_bisectors, 2), dtype=np.float64)\n\n        # Initialize the array that will hold the coordinates of the center of the circle.\n        center = np.zeros((2,), dtype=np.float64)\n\n        # Initialize the array that will hold the number of iterations.\n        iterations = 0\n\n        # Initialize the array that will hold the distance between the starting points of the bisectors.\n        distances = np.zeros((self.params.num_bisectors,), dtype=np.float64)\n\n        # Initialize the array that will hold the angle between the bisectors.\n        angles = np.zeros((self.params.num_bisectors,), dtype=np.float64)\n\n        # Initialize the array that will hold the angles of the bisectors.\n        bisector_angles = np.zeros((self.params.num_bisectors,), dtype=np.float64)\n\n        # Initialize the array that will hold the coordinates of the center of the circle.\n        center = np.zeros((2,), dtype=np.float64)\n\n        # Initialize the array that will hold the number of iterations.\n        iterations = 0\n\n        # Initialize the array that will hold the distance between the starting points of the bisectors.\n        distances = np.zeros((self.params.num_bisectors,), dtype=np.float64)\n\n        # Initialize the array that will hold the angle between the bisectors.\n        angles = np.zeros((self.params.num_bisectors,), dtype=np.float64)\n\n        # Initialize the array that will hold the angles of the bisectors.\n        bisector_angles = np.zeros((self.params.num_bisectors,), dtype"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Initialize the arrays that will store the points of the perpendicular bisectors.\n        first_bisectors_point = np.zeros(2)\n        second_bisectors_point = np.zeros(2)\n\n        # Initialize the number of iterations to zero.\n        iterations = 0\n\n        # Initialize the number of valid pairs to zero.\n        num_valid_pairs = 0\n\n        # Initialize the number of invalid pairs to zero.\n        num_invalid_pairs = 0\n\n        # Initialize the number of pairs that have been discarded because they are too close to each other to the minimum distance between pairs.\n        num_discarded_pairs = 0\n\n        # Initialize the number of pairs that have been discarded because they are too close to the edge of the polygon.\n        num_discarded_pairs_too_close_to_edge = 0\n\n        # Initialize the number of pairs that have been discarded because they are too close to the center of the polygon.\n        num_discarded_pairs_too_close_to_center = 0\n\n        # Initialize the number of pairs that have been discarded because they are not valid.\n        num_discarded_pairs_not_valid = 0\n\n        # Initialize the number of pairs that have been discarded because they are not valid.\n        num_discarded_pairs_not_valid = 0\n\n        # Initialize the number of pairs that have been discarded because they are not valid.\n        num_discarded_pairs_not_valid = 0\n\n        # Initialize the number of pairs that have been discarded because they are not valid.\n        num_discarded_pairs_not_valid = 0\n\n        # Initialize the number of pairs that have been discarded because they are not valid.\n        num_discarded_pairs_not_valid = 0\n\n        # Initialize the number of pairs that have been discarded because they are not valid.\n        num_discarded_pairs_not_valid = 0\n\n        # Initialize the number of pairs that have been discarded because they are not valid.\n        num"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Generate a list of random points from the polygon.\n        points = np.random.choice(polygon, size=(self.params.num_bisectors, 2), replace=False)\n\n        # Calculate the perpendicular bisectors for the randomly chosen pairs of points.\n        first_bisectors_point = np.array([])\n        second_bisectors_point = np.array([])\n        for i in range(self.params.num_bisectors):\n            first_bisectors_point = np.append(first_bisectors_point, points[i])\n            second_bisectors_point = np.append(second_bisectors_point, self._calculate_perpendicular_bisector(points[i]))\n\n        # Ensure that the points are not too close together.\n        first_bisectors_point = self._remove_close_points(\n            first_bisectors_point, second_bisectors_point, min_distance_between_sector_points_in_px\n        )\n        second_bisectors_point = self._remove_close_points(\n            second_bisectors_point, first_bisectors_point, min_distance_between_sector_points_in_px\n        )\n\n        return first_bisectors_point, second_bisectors_point\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Initialize the arrays that will store the starting and ending points of the perpendicular bisectors.\n        first_bisectors_point = np.empty((0, 2))\n        second_bisectors_point = np.empty((0, 2))\n\n        # Initialize a counter for the number of iterations.\n        num_iterations = 0\n\n        # Loop until the number of iterations is equal to the maximum number of iterations allowed.\n        while num_iterations < self.params.max_iterations:\n            # Increment the number of iterations.\n            num_iterations += 1\n\n            # Generate a random index.\n            random_index = np.random.randint(0, polygon.shape[0])\n\n            # Generate a second random index.\n            random_index_2 = np.random.randint(0, polygon.shape[0])\n\n            # Ensure that the random index is not equal to the random index 2.\n            while random_index == random_index_2:\n                random_index_2 = np.random.randint(0, polygon.shape[0])\n\n            # Calculate the distance between the two points.\n            distance_between_points = np.linalg.norm(polygon[random_index] - polygon[random_index_2])\n\n            # Ensure that the distance between the two points is greater than the minimum distance between sector points.\n            if distance_between_points > min_distance_between_sector_points_in_px:\n                # Calculate the perpendicular bisector of the two points.\n                perpendicular_bisector = self._calculate_perpendicular_bisector(\n                    polygon[random_index], polygon[random_index_2]\n                )\n\n                # Append the starting and ending points of the bisector to the corresponding arrays.\n                first_bisectors_point = np.append(first_bisectors_point, [polygon[random_index]], axis=0)\n                second_bisectors_point = np.append(second_bisectors_point, [perpendicular_bisector], axis=0)\n\n        # If the number of iterations is"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Initialize the number of iterations to zero\n        num_iterations = 0\n\n        # Initialize the arrays that will hold the starting and ending points of the calculated perpendicular bisectors\n        first_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n        second_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n\n        # Initialize the array that will hold the points that were selected as the starting points for the bisectors\n        selected_points = np.zeros((self.params.num_bisectors, 2))\n\n        # Initialize the array that will hold the points that were selected as the ending points for the bisectors\n        selected_end_points = np.zeros((self.params.num_bisectors, 2))\n\n        # Initialize the array that will hold the angles between the calculated perpendicular bisectors\n        bisectors_angles = np.zeros(self.params.num_bisectors)\n\n        # Initialize the array that will hold the angles between the calculated perpendicular bisectors\n        bisectors_angles_diff = np.zeros(self.params.num_bisectors)\n\n        # Initialize the array that will hold the angles between the calculated perpendicular bisectors\n        bisectors_angles_diff_abs = np.zeros(self.params.num_bisectors)\n\n        # Initialize the array that will hold the angles between the calculated perpendicular bisectors\n        bisectors_angles_diff_abs_mean = 0.0\n\n        # Initialize the array that will hold the angles between the calculated perpendicular bisectors\n        bisectors_angles_diff_abs_std = 0.0\n\n        # Initialize the array that will hold the angles between the calculated perpendicular bisectors\n        bisectors_angles_diff_abs_min = 0.0\n\n        # Initialize the array that will hold the angles between the calculated perpendicular bisectors\n        bisectors_angles_diff_abs_max = 0.0\n\n        # Initialize the array that will hold the angles between the calculated perpendicular bisectors\n        bisectors_angles_diff_abs_sum = "}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Initialize variables\n        first_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n        second_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n\n        # Initialize iteration counter\n        iteration = 0\n\n        while iteration < self.params.max_iterations:\n\n            # Choose a random pair of points from the polygon\n            first_bisectors_point[iteration, :], second_bisectors_point[iteration, :] = self._random_point_pair(\n                polygon, min_distance_between_sector_points_in_px\n            )\n\n            # Calculate the perpendicular bisector of the chosen pair of points\n            bisector = self._calculate_perpendicular_bisector(\n                first_bisectors_point[iteration, :], second_bisectors_point[iteration, :]\n            )\n\n            # Check if the bisector is valid\n            if self._is_valid_bisector(bisector, polygon):\n\n                # Increment the iteration counter\n                iteration += 1\n\n                # Break out of the loop if the iteration counter has reached the maximum number of iterations\n                if iteration == self.params.max_iterations:\n                    break\n\n        # Raise an exception if the iteration counter has reached the maximum number of iterations\n        if iteration == self.params.max_iterations:\n            raise EyeCentersEstimationError(\n                \"Failed to find a sufficient number of point pairs that meet the distance criterion within the maximum number of iterations allowed.\"\n            )\n\n        return first_bisectors_point, second_bisectors_point\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Initialize variables\n        first_bisectors_point = np.empty(2)\n        second_bisectors_point = np.empty(2)\n        num_iterations = 0\n\n        # Loop until a sufficient number of points are found\n        while (\n            np.linalg.norm(first_bisectors_point - second_bisectors_point) > min_distance_between_sector_points_in_px\n            and num_iterations < self.params.max_iterations\n        ):\n\n            # Select two random points from the polygon\n            first_point = self._select_random_point(polygon)\n            second_point = self._select_random_point(polygon)\n\n            # Calculate the perpendicular bisector of the line segment between the two points\n            first_bisectors_point, second_bisectors_point = self._calculate_perpendicular_bisector(first_point, second_point)\n\n            # Increment the number of iterations\n            num_iterations += 1\n\n        # Check if the number of iterations exceeded the maximum number of iterations allowed\n        if num_iterations >= self.params.max_iterations:\n            raise EyeCentersEstimationError(\n                f\"Failed to find a sufficient number of point pairs that meet the distance criterion within the maximum number of iterations allowed ({self.params.max_iterations}).\"\n            )\n\n        return first_bisectors_point, second_bisectors_point\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Initialize the arrays that will hold the starting and ending points of the calculated bisectors.\n        first_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n        second_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n\n        # Initialize the array that will hold the center points of the circular shape.\n        center_points = np.zeros((self.params.num_bisectors, 2))\n\n        # Initialize the array that will hold the distance between each pair of points.\n        distances = np.zeros(self.params.num_bisectors)\n\n        # Initialize a counter that will keep track of the number of iterations.\n        iteration = 0\n\n        # Initialize a counter that will keep track of the number of pairs of points that meet the distance criterion.\n        num_valid_pairs = 0\n\n        # Initialize a counter that will keep track of the number of pairs of points that do not meet the distance criterion.\n        num_invalid_pairs = 0\n\n        # Initialize a counter that will keep track of the number of pairs of points that meet the distance criterion but do not pass the sanity check.\n        num_invalid_pairs_after_sanity_check = 0\n\n        # Initialize a counter that will keep track of the number of pairs of points that meet the distance criterion and pass the sanity check.\n        num_valid_pairs_after_sanity_check = 0\n\n        # Initialize a counter that will keep track of the number of pairs of points that meet the distance criterion and pass the sanity check, but do not pass the center point sanity check.\n        num_invalid_center_points = 0\n\n        # Initialize a counter that will keep track of the number of pairs of points that meet the distance criterion, pass the sanity check, and pass the center point sanity check.\n        num_valid_center_points = 0\n\n        # Initialize a counter that will keep track of the number of pairs of points that meet the distance criterion, pass the sanity check, and pass the center point sanity check, but do not pass the center point san"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Initialize the arrays that will hold the starting and ending points of the perpendicular bisectors.\n        first_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n        second_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n\n        # Initialize the array that will hold the distances between pairs of points.\n        distance_between_points = np.zeros(self.params.num_bisectors)\n\n        # Initialize the counter that will keep track of the number of iterations.\n        iteration_counter = 0\n\n        # Calculate the distance between each pair of points.\n        while (\n            np.any(distance_between_points < min_distance_between_sector_points_in_px)\n            and iteration_counter < self.params.max_iterations\n        ):\n            # Choose a random pair of points from the polygon.\n            random_pair_of_points = np.random.randint(0, len(polygon), size=(2,))\n\n            # Calculate the distance between the two points.\n            distance_between_points[iteration_counter] = np.linalg.norm(\n                polygon[random_pair_of_points[0]] - polygon[random_pair_of_points[1]]\n            )\n\n            # Calculate the perpendicular bisector of the two points.\n            perpendicular_bisector = self._calculate_perpendicular_bisector(\n                polygon[random_pair_of_points[0]], polygon[random_pair_of_points[1]]\n            )\n\n            # Assign the starting and ending points of the perpendicular bisector to the appropriate arrays.\n            first_bisectors_point[iteration_counter] = polygon[random_pair_of_points[0]]\n            second_bisectors_point[iteration_counter] = perpendicular_bisector\n\n            # Increment the iteration counter.\n            iteration_counter += 1\n\n        # Raise an exception if the maximum number of iterations is reached without finding a sufficient number of points that meet the distance criterion.\n        if iteration_"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Initialize variables.\n        first_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n        second_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n\n        # Initialize variables to track the number of iterations.\n        num_iterations = 0\n\n        # Initialize a variable to track whether the minimum distance criterion has been met.\n        min_distance_criterion_met = False\n\n        # Iterate until the minimum distance criterion has been met or the maximum number of iterations has been exceeded.\n        while not min_distance_criterion_met and num_iterations < self.params.max_iterations:\n\n            # Increment the number of iterations.\n            num_iterations += 1\n\n            # Generate a random pair of points from the polygon's vertices.\n            random_pair_of_points = self._generate_random_pair_of_points(polygon)\n\n            # Calculate the perpendicular bisector of the two points.\n            perpendicular_bisector = self._calculate_perpendicular_bisector(random_pair_of_points)\n\n            # Calculate the intersection of the perpendicular bisector with the polygon.\n            intersection_point = self._calculate_intersection_with_polygon(perpendicular_bisector, polygon)\n\n            # If the distance between the two points in the perpendicular bisector is greater than the minimum distance criterion, then set the flag to true.\n            if np.linalg.norm(intersection_point - random_pair_of_points[0]) > min_distance_between_sector_points_in_px:\n                min_distance_criterion_met = True\n\n            # If the minimum distance criterion has not been met, then update the arrays with the perpendicular bisector and intersection point.\n            if not min_distance_criterion_met:\n                first_bisectors_point[num_iterations - 1] = random_pair_of_points[0]\n                second_bisectors_point[num_iterations - 1"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Initialize the array that will contain the starting points of the perpendicular bisectors.\n        first_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n\n        # Initialize the array that will contain the ending points of the perpendicular bisectors.\n        second_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n\n        # Initialize the counter that will keep track of the number of iterations.\n        iteration_counter = 0\n\n        # Initialize the counter that will keep track of the number of pairs of points that meet the distance criterion.\n        point_pairs_counter = 0\n\n        # Loop through the number of iterations.\n        while iteration_counter < self.params.max_iterations:\n\n            # Increment the iteration counter.\n            iteration_counter += 1\n\n            # Choose a random pair of points from the polygon.\n            point_pair = np.random.choice(polygon, size=2, replace=False)\n\n            # Calculate the perpendicular bisector of the chosen pair of points.\n            perpendicular_bisector = self._calculate_perpendicular_bisector(point_pair)\n\n            # Calculate the intersection of the perpendicular bisector with the polygon.\n            intersection = self._calculate_intersection(polygon, perpendicular_bisector)\n\n            # Check if the intersection point is valid.\n            if self._is_valid_intersection(intersection):\n\n                # Check if the distance between the two points is greater than the specified minimum.\n                if self._is_distance_greater_than_minimum(point_pair, intersection, min_distance_between_sector_points_in_px):\n\n                    # Increment the counter of valid pairs of points.\n                    point_pairs_counter += 1\n\n                    # Assign the starting point of the perpendicular bisector to the first bisectors point array.\n                    first_bisectors_point[point_pairs_counter - 1] = point_pair[0]\n\n                    # Assign the ending point of the perpend"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Initialize variables.\n        first_bisectors_point = np.array([])\n        second_bisectors_point = np.array([])\n        first_bisectors_point_list = []\n        second_bisectors_point_list = []\n\n        # Initialize variables for tracking the progress of the function.\n        num_iterations = 0\n        num_valid_pairs = 0\n\n        # Iterate until the maximum number of iterations is reached or until a sufficient number of valid point pairs are found.\n        while num_iterations < self.params.max_iterations and num_valid_pairs < self.params.num_bisectors:\n\n            # Choose two random points from the polygon's vertices.\n            random_points = np.random.randint(0, len(polygon), size=2)\n            first_bisectors_point = polygon[random_points[0]]\n            second_bisectors_point = polygon[random_points[1]]\n\n            # Ensure that the distance between the two points is greater than the specified minimum.\n            if np.linalg.norm(first_bisectors_point - second_bisectors_point) > min_distance_between_sector_points_in_px:\n\n                # Add the points to the list of valid points.\n                first_bisectors_point_list.append(first_bisectors_point)\n                second_bisectors_point_list.append(second_bisectors_point)\n\n                # Increment the number of valid pairs.\n                num_valid_pairs += 1\n\n            # Increment the number of iterations.\n            num_iterations += 1\n\n        # If the function failed to find a sufficient number of valid point pairs, raise an exception.\n        if num_valid_pairs < self.params.num_bisectors:\n            raise EyeCentersEstimationError(\n                f\"Failed to find a sufficient number of valid point pairs (num_valid_pairs = {num_valid_pairs}) within the maximum number of iterations (max_iterations = {self.params.max_iterations})\"\n            )\n\n        # Convert the lists of"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Initialize variables\n        num_bisectors = self.params.num_bisectors\n        max_iterations = self.params.max_iterations\n\n        # Initialize arrays to store points\n        first_bisectors_point = np.zeros(shape=(num_bisectors, 2))\n        second_bisectors_point = np.zeros(shape=(num_bisectors, 2))\n\n        # Initialize variables to keep track of the number of iterations\n        num_iterations = 0\n\n        # Iterate until the maximum number of iterations is reached\n        while num_iterations < max_iterations:\n\n            # Choose a random pair of points\n            random_index_1 = np.random.randint(0, polygon.shape[0])\n            random_index_2 = np.random.randint(0, polygon.shape[0])\n\n            # Ensure that the two points are not too close to each other\n            if np.linalg.norm(polygon[random_index_1] - polygon[random_index_2]) > min_distance_between_sector_points_in_px:\n\n                # Calculate the perpendicular bisector of the two points\n                bisector = self._calculate_perpendicular_bisector(polygon[random_index_1], polygon[random_index_2])\n\n                # Store the two points of the bisector in the arrays\n                first_bisectors_point[num_iterations] = polygon[random_index_1]\n                second_bisectors_point[num_iterations] = bisector[1]\n\n                # Increment the number of iterations\n                num_iterations += 1\n\n        # If the number of iterations is not equal to the number of bisectors, raise an exception\n        if num_iterations != num_bisectors:\n            raise EyeCentersEstimationError(\n                f\"Failed to find {num_bisectors} bisectors within {max_iterations} iterations. The number of iterations was {num_iterations}.\"\n            )\n\n        # Return the arrays containing the starting and ending points of the bisectors\n        return first_bisectors_point"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Generate a list of random pairs of points from the polygon's vertices\n        # The number of pairs of points is equal to the number of bisectors to be calculated\n        points_list = self._generate_random_point_pairs(polygon, self.params.num_bisectors)\n\n        # Initialize a list to store the calculated perpendicular bisectors\n        bisectors_list = []\n\n        # Initialize a counter to keep track of the number of iterations\n        iteration_counter = 0\n\n        # Initialize a list to store the points that are too close to each other\n        # These points will be discarded from the calculation\n        discard_list = []\n\n        # Iterate until the number of iterations is equal to the maximum number of iterations\n        while iteration_counter < self.params.max_iterations:\n\n            # Iterate over the list of points\n            for point_pair in points_list:\n\n                # Calculate the perpendicular bisector of the current pair of points\n                bisector = self._calculate_perpendicular_bisector(point_pair)\n\n                # Check if the distance between the start and end points of the bisector is greater than the minimum distance between sector points\n                if self._distance_between_points(bisector[0], bisector[1]) > min_distance_between_sector_points_in_px:\n\n                    # If the distance between the start and end points of the bisector is greater than the minimum distance between sector points, add the bisector to the list of bisectors\n                    bisectors_list.append(bisector)\n\n                # If the distance between the start and end points of the bisector is less than the minimum distance between sector points, add the pair of points to the discard list\n                else:\n                    discard_list.append(point_pair)\n\n            # Check if the number of bisectors in the list is greater than or equal to the number of bisectors to be calculated\n            if len(bisectors_list) >= self.params.num_bisectors:\n\n                # If the number of bisectors in the list is greater than or equal to the number of bisectors to be calculated, break out of the loop"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Initialize a list to store the coordinates of the points\n        points = []\n\n        # Initialize a list to store the coordinates of the bisectors\n        bisectors = []\n\n        # Initialize a counter to keep track of the number of iterations\n        iterations = 0\n\n        # Initialize a counter to keep track of the number of valid point pairs\n        valid_point_pairs = 0\n\n        # Loop until we have a sufficient number of valid point pairs\n        while valid_point_pairs < self.params.num_bisectors and iterations < self.params.max_iterations:\n\n            # Increment the number of iterations\n            iterations += 1\n\n            # Generate a random index for the polygon array\n            index = np.random.randint(len(polygon))\n\n            # If the index is not the last index, then we can calculate the bisector\n            # of the next point in the polygon array\n            if index != len(polygon) - 1:\n\n                # Calculate the bisector of the next point in the polygon array\n                bisector = self._calculate_bisector(polygon[index], polygon[index + 1])\n\n                # Append the bisector to the list of bisectors\n                bisectors.append(bisector)\n\n                # Increment the number of valid point pairs\n                valid_point_pairs += 1\n\n            # If the index is not the first index, then we can calculate the bisector\n            # of the previous point in the polygon array\n            if index != 0:\n\n                # Calculate the bisector of the previous point in the polygon array\n                bisector = self._calculate_bisector(polygon[index], polygon[index - 1])\n\n                # Append the bisector to the list of bisectors\n                bisectors.append(bisector)\n\n                # Increment the number of valid point pairs\n                valid_point_pairs += 1\n\n            # If the index is not the first or last index, then we can calculate the bisector\n            # of the previous point in the polygon array\n            if index != 0 and index != len(polygon) - 1:\n\n                # Calculate the bis"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Calculate the number of bisectors to calculate.\n        num_bisectors = self.params.num_bisectors\n\n        # Calculate the number of iterations.\n        max_iterations = self.params.max_iterations\n\n        # Initialize the arrays that will hold the starting and ending points of the calculated bisectors.\n        first_bisectors_point = np.zeros((num_bisectors, 2))\n        second_bisectors_point = np.zeros((num_bisectors, 2))\n\n        # Initialize the counter that will keep track of how many bisectors have been calculated.\n        num_bisectors_calculated = 0\n\n        # Initialize the counter that will keep track of how many iterations have been performed.\n        num_iterations = 0\n\n        # Initialize a variable that will keep track of whether the minimum number of bisectors have been calculated.\n        min_bisectors_calculated = False\n\n        # Initialize a variable that will keep track of whether the maximum number of iterations have been performed.\n        max_iterations_reached = False\n\n        # Initialize a variable that will keep track of whether the minimum distance between the points of the bisectors has been met.\n        min_distance_between_points_met = False\n\n        # Iterate until either the minimum number of bisectors have been calculated, or the maximum number of iterations have been performed.\n        while not (min_bisectors_calculated or max_iterations_reached):\n\n            # Increment the counter for the number of iterations.\n            num_iterations += 1\n\n            # Initialize a variable that will keep track of whether the minimum distance between the points of the bisectors has been met.\n            min_distance_between_points_met = False\n\n            # Initialize a variable that will keep track of whether the minimum number of bisectors have been calculated.\n            min_bisectors_calculated = False\n\n            # Initialize a counter that will keep track of how many bisectors have been calculated.\n            num_bisectors_calculated = 0\n\n            # Choose a random starting point from the polygon.\n            starting_point_index = np.random.randint(0, len(polygon"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Initialize a list to store the perpendicular bisectors\n        perpendicular_bisectors = []\n\n        # Initialize a list to store the points from which the bisectors are calculated\n        sector_points = []\n\n        # Initialize a counter to keep track of the number of iterations\n        iteration_counter = 0\n\n        # Initialize a flag to keep track of whether the number of iterations has reached the maximum allowed\n        reached_max_iterations = False\n\n        # Initialize a flag to keep track of whether the number of points has reached the minimum required\n        reached_min_points = False\n\n        # Iterate until the number of iterations has reached the maximum allowed or the number of points has reached the minimum required\n        while not reached_max_iterations and not reached_min_points:\n\n            # Increment the number of iterations\n            iteration_counter += 1\n\n            # If the number of iterations has reached the maximum allowed, set the flag to True\n            if iteration_counter >= self.params.max_iterations:\n                reached_max_iterations = True\n\n            # Choose two random points from the polygon\n            random_point_1, random_point_2 = self._choose_two_random_points(polygon)\n\n            # Calculate the perpendicular bisector of the two points\n            perpendicular_bisector = self._calculate_perpendicular_bisector(random_point_1, random_point_2)\n\n            # If the perpendicular bisector is not a line, then it is invalid and should be ignored\n            if len(perpendicular_bisector) != 2:\n                continue\n\n            # If the distance between the two points is less than the minimum distance, then the bisector is invalid and should be ignored\n            if self._distance_between_points(random_point_1, random_point_2) < min_distance_between_sector_points_in_px:\n                continue\n\n            # If the perpendicular bisector is valid, then add it to the list of perpendicular bisectors\n            perpendicular_bisectors.append(perpendicular_bisector)\n\n            # If the number of perpendicular bisectors"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Initialize variables\n        num_points = polygon.shape[0]\n        first_bisectors_points = np.zeros((self.params.num_bisectors, 2))\n        second_bisectors_points = np.zeros((self.params.num_bisectors, 2))\n\n        # Loop through the maximum number of iterations\n        for i in range(self.params.max_iterations):\n\n            # Randomly choose two points\n            point_1_idx = np.random.randint(0, num_points)\n            point_2_idx = np.random.randint(0, num_points)\n\n            # If the two points are the same, skip them\n            if point_1_idx == point_2_idx:\n                continue\n\n            # Calculate the perpendicular bisector of the two points\n            first_bisector_point, second_bisector_point = self._calculate_perpendicular_bisector(\n                polygon[point_1_idx], polygon[point_2_idx]\n            )\n\n            # Calculate the distance between the two points\n            distance = np.linalg.norm(polygon[point_1_idx] - polygon[point_2_idx])\n\n            # If the distance between the two points is less than the minimum distance, skip them\n            if distance < min_distance_between_sector_points_in_px:\n                continue\n\n            # If the distance between the two points is greater than the minimum distance, store the bisectors\n            first_bisectors_points[i] = first_bisector_point\n            second_bisectors_points[i] = second_bisector_point\n\n        # If the number of bisectors found is less than the number of bisectors specified, raise an error\n        if np.sum(first_bisectors_points) == 0 or np.sum(second_bisectors_points) == 0:\n            raise EyeCentersEstimationError(\n                \"Could not find sufficient number of bisectors that meet the distance criterion. \"\n                \"This may be due to a poorly formed polygon or the specified minimum distance between points being too small.\"\n           "}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.on_before_execute(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.on_after_execute(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.on_before_execution(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.on_after_execution(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.on_before_execute(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.on_after_execute(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.on_before_execution(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.on_after_execution(self, result, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.on_before_execute(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.on_after_execute(self, result, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.on_before_execute(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.on_after_execute(self, result, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.on_before_execute(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.on_after_execute(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.on_before_execute(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.on_after_execute(self, result, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.on_before_execution(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.on_after_execution(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.on_before_execution(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.on_after_execution(self, result, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.on_before_execution(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.on_after_execution(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.on_before_execution(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.on_after_execution(self, result, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.on_before_execution(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.on_after_execution(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        # Pre-execution hooks\n        for callback in self._callbacks:\n            callback.on_before_execution(self, *args, **kwargs)\n\n        # Run method\n        result = self.run(*args, **kwargs)\n\n        # Post-execution hooks\n        for callback in self._callbacks:\n            callback.on_after_execution(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.on_before_execute(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.on_after_execute(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.on_before_execution(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.on_after_execution(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.on_before_run(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.on_after_run(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.on_before_execute(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.on_after_execute(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        # Call pre-execution callbacks\n        for callback in self._callbacks:\n            callback.on_execution_begin(self)\n\n        # Run algorithm\n        result = self.run(*args, **kwargs)\n\n        # Call post-execution callbacks\n        for callback in self._callbacks:\n            callback.on_execution_end(self)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.on_before_execute(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.on_after_execute(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            value = json.loads(output)\n            return self.check_type(value, type_definition)\n        except Exception as e:\n            return False\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            output_obj = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n        return self.check_type(output_obj, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        # check if the output is a valid JSON\n        try:\n            output = json.loads(output)\n        except json.decoder.JSONDecodeError:\n            return False\n\n        # check if the output matches the type definition\n        return self.check_type(output, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            output = json.loads(output)\n        except json.decoder.JSONDecodeError:\n            return False\n\n        return self.check_type(output, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            output_dict = json.loads(output)\n        except Exception as e:\n            return False\n\n        if self.check_type(output_dict, type_definition):\n            return True\n        else:\n            return False\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            output = json.loads(output)\n        except Exception:\n            return False\n        return self.check_type(output, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        # If the output is None, return True\n        if output is None:\n            return True\n\n        # Deserialize the output from JSON format\n        try:\n            output = json.loads(output)\n        except json.decoder.JSONDecodeError:\n            return False\n\n        # If the type definition is a base type, return True if the output matches the type definition\n        if self.is_base_type(type_definition):\n            return self.validate_base_type(output, type_definition)\n\n        # If the type definition is a dataclass, return True if the output matches the type definition\n        if is_dataclass(type_definition):\n            return self.validate_dataclass(output, type_definition)\n\n        # If the type definition is a pydantic model, return True if the output matches the type definition\n        if isinstance(type_definition, BaseModel):\n            return self.validate_pydantic_model(output, type_definition)\n\n        # If the type definition is a dict, return True if the output matches the type definition\n        if type_definition is dict:\n            return self.validate_dict(output, type_definition)\n\n        # If the type definition is a list, return True if the output matches the type definition\n        if type_definition is list:\n            return self.validate_list(output, type_definition)\n\n        # If the type definition is a set, return True if the output matches the type definition\n        if type_definition is set:\n            return self.validate_set(output, type_definition)\n\n        # If the type definition is a tuple, return True if the output matches the type definition\n        if type_definition is tuple:\n            return self.validate_tuple(output, type_definition)\n\n        # If the type definition is a Union, return True if the output matches the type definition\n        if get_origin(type_definition) is Union:\n            return self.validate_union(output, type_definition)\n\n        # If the type definition is a Literal, return True if the output matches the type definition\n        if get_origin(type_definition) is Literal:\n            return self.validate_"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        if not isinstance(output, str):\n            return False\n\n        try:\n            output_value = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.validate_type(output_value, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            output_object = json.loads(output)\n            return self.check_type(output_object, type_definition)\n        except Exception:\n            return False\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            output = json.loads(output)\n            return self.check_type(output, type_definition)\n        except Exception as e:\n            return False\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            output_deserialized = json.loads(output)\n            return self.check_type(output_deserialized, type_definition)\n        except json.JSONDecodeError:\n            return False\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        if not isinstance(output, str):\n            return False\n\n        try:\n            output_obj = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(output_obj, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            output_value = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n        return self.check_type(output_value, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            # Deserialize the output from JSON format\n            output_dict = json.loads(output)\n            # Check if the output matches the type definition\n            return self.check_type(output_dict, type_definition)\n        except:\n            # If the output cannot be deserialized, return False\n            return False\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            # Deserialize the output string\n            output = json.loads(output)\n\n            # Check if the deserialized output matches the type definition\n            return self.check_type(output, type_definition)\n        except:\n            # If the output cannot be deserialized or does not match the type definition, return False\n            return False\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            # Deserialize the output string from JSON\n            output_object = json.loads(output)\n\n            # Check if the deserialized output matches the type definition\n            return self.check_type(output_object, type_definition)\n        except:\n            # If the output cannot be deserialized or does not match the type definition, return False\n            return False\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            # Deserialize the output from JSON\n            output = json.loads(output)\n            # Check if the output matches the type definition\n            return self.check_type(output, type_definition)\n        except:\n            # If there is any error during deserialization or type checking, return False\n            return False\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            output_dict = json.loads(output)\n            if not self.check_type(output_dict, type_definition):\n                return False\n        except Exception as e:\n            return False\n        return True\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            output = json.loads(output)\n        except:\n            return False\n\n        if self.check_type(output, type_definition):\n            return True\n        else:\n            return False\n\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        if output is None:\n            return True\n\n        try:\n            # Deserialize the output string\n            output_obj = json.loads(output)\n\n            # Check if the output object matches the type definition\n            return self.check_type(output_obj, type_definition)\n\n        except Exception as e:\n            print(f'Error deserializing output: {e}')\n            return False\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        def get_class_definition(type_hint):\n            \"\"\"\n            This function fetches a class definition for a given type hint, handling generic types and ensuring that class definitions are fetched for non-built-in types.\n            :param type_hint: The type hint to fetch the class definition for.\n            :return: The class definition of the type hint.\n            \"\"\"\n            if get_origin(type_hint) is not None:\n                return get_origin(type_hint)\n            else:\n                return type_hint\n\n        def is_embedding_type(type_hint):\n            \"\"\"\n            This function determines whether a type hint is a subclass of an Embedding class.\n            :param type_hint: The type hint to check.\n            :return: True if the type hint is a subclass of an Embedding class, False otherwise.\n            \"\"\"\n            if get_origin(type_hint) is not None:\n                return issubclass(get_origin(type_hint), Embedding)\n            else:\n                return issubclass(type_hint, Embedding)\n\n        def is_union_type(type_hint):\n            \"\"\"\n            This function determines whether a type hint is part of a Union type.\n            :param type_hint: The type hint to check.\n            :return: True if the type hint is part of a Union type, False otherwise.\n            \"\"\"\n            if get_origin(type_hint) is not None:\n                return get_origin(type_hint) is Union\n            else:\n                return type_hint is Union\n\n        def is_literal_type(type_hint):\n            \"\"\"\n            This function determines whether a type hint is part of a Literal type.\n            :param type_hint: The type hint to check.\n            :return: True if the type hint is part of a Literal type, False otherwise.\n            \"\"\"\n            if get_origin(type_hint) is not None:\n                return get_origin(type_hint) is Literal\n            else:\n                return type_hint is Literal"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Get function name\n        func_name = func_object.__name__\n\n        # Get function signature\n        signature = inspect.signature(func_object)\n\n        # Get function docstring\n        docstring = inspect.getdoc(func_object)\n\n        # Get function type\n        output_type_hint = get_type_hints(func_object).get(\"return\")\n        if output_type_hint is None:\n            raise ValueError(f\"Function {func_name} does not have an output type hint\")\n        else:\n            if get_origin(output_type_hint) is Union:\n                output_type_hint = get_args(output_type_hint)[0]\n            if issubclass(output_type_hint, Embedding):\n                function_type = FunctionType.EMBEDDABLE\n            else:\n                function_type = FunctionType.SYMBOLIC\n\n        # Get input and output type hints\n        input_type_hints = get_type_hints(func_object)\n        input_type_hints.pop(\"return\")\n        output_class_definition = get_class_definition(output_type_hint)\n\n        return FunctionDescription(\n            func_name,\n            signature,\n            input_type_hints,\n            output_type_hint,\n            output_class_definition,\n            docstring,\n            function_type\n        )\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Get function name\n        func_name = func_object.__name__\n\n        # Get function signature\n        func_signature = inspect.signature(func_object)\n\n        # Get function docstring\n        func_docstring = inspect.getdoc(func_object)\n\n        # Get function type hints\n        func_type_hints = get_type_hints(func_object)\n\n        # Get input type hints\n        input_type_hints = {}\n        for name, type_hint in func_type_hints.items():\n            if name != \"return\":\n                input_type_hints[name] = type_hint\n\n        # Get output type hint\n        output_type_hint = func_type_hints[\"return\"]\n\n        # Get class definitions for input type hints\n        input_class_hints = {}\n        for name, type_hint in input_type_hints.items():\n            input_class_hints[name] = Register.get_class_definition(type_hint)\n\n        # Get class definition for output type hint\n        output_class_hint = Register.get_class_definition(output_type_hint)\n\n        # Determine function type\n        if output_class_hint is None:\n            function_type = FunctionType.SYMBOLIC\n        elif issubclass(output_class_hint, Embedding):\n            function_type = FunctionType.EMBEDDABLE\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        # Create function description\n        function_description = FunctionDescription(\n            func_name,\n            func_signature,\n            input_type_hints,\n            input_class_hints,\n            output_type_hint,\n            output_class_hint,\n            func_docstring,\n            function_type\n        )\n\n        return function_description\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Get function name\n        func_name = func_object.__name__\n\n        # Get function signature\n        func_signature = inspect.signature(func_object)\n\n        # Get function type hints\n        func_type_hints = get_type_hints(func_object)\n\n        # Get function docstring\n        func_docstring = inspect.getdoc(func_object)\n\n        # Get function input and output types\n        func_input_types = []\n        func_output_type = None\n        for arg_name, arg_type in func_type_hints.items():\n            if arg_name == \"return\":\n                func_output_type = arg_type\n            else:\n                func_input_types.append(arg_type)\n\n        # Get function input and output class definitions\n        func_input_class_defs = [get_class_definition(arg_type) for arg_type in func_input_types]\n        func_output_class_def = get_class_definition(func_output_type)\n\n        # Determine function type\n        if issubclass(func_output_class_def, Embedding):\n            func_type = FunctionType.EMBEDDABLE\n        else:\n            func_type = FunctionType.SYMBOLIC\n\n        # Create function description\n        func_description = FunctionDescription(\n            func_name,\n            func_signature,\n            func_input_types,\n            func_output_type,\n            func_input_class_defs,\n            func_output_class_def,\n            func_type,\n            func_docstring,\n        )\n\n        return func_description\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Get function name\n        func_name = func_object.__name__\n\n        # Get function signature\n        func_signature = inspect.signature(func_object)\n\n        # Get function docstring\n        func_docstring = inspect.getdoc(func_object)\n\n        # Get function type\n        func_type = None\n\n        # Get function input and output type hints\n        func_input_type_hints = get_type_hints(func_object)\n        func_output_type_hints = get_type_hints(func_object)\n\n        # Get function input and output class definitions\n        func_input_class_definitions = {}\n        for input_name, input_type_hint in func_input_type_hints.items():\n            func_input_class_definitions[input_name] = Register.get_class_definition(input_type_hint)\n\n        func_output_class_definition = Register.get_class_definition(func_output_type_hints['return'])\n\n        # Determine function type\n        if issubclass(func_output_class_definition, Embedding):\n            func_type = FunctionType.EMBEDDABLE\n        else:\n            func_type = FunctionType.SYMBOLIC\n\n        # Create function description\n        func_description = FunctionDescription(\n            func_name,\n            func_signature,\n            func_docstring,\n            func_input_type_hints,\n            func_input_class_definitions,\n            func_output_type_hints,\n            func_output_class_definition,\n            func_type\n        )\n\n        return func_description\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        docstring = inspect.getdoc(func_object)\n        func_name = func_object.__name__\n\n        if \"return\" in type_hints:\n            return_type = type_hints[\"return\"]\n        else:\n            return_type = None\n\n        input_types = []\n        for param_name in signature.parameters.keys():\n            if param_name not in [\"self\", \"cls\"]:\n                input_types.append(type_hints[param_name])\n\n        if return_type is None:\n            return_type = type(None)\n\n        return_type_class = get_class_definition(return_type)\n        input_type_classes = [get_class_definition(input_type) for input_type in input_types]\n\n        if issubclass(return_type, Embedding):\n            function_type = FunctionType.EMBEDDABLE\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        return FunctionDescription(func_name, input_types, return_type, input_type_classes, return_type_class, docstring, function_type)\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Get the function's signature and type hints\n        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n\n        # Get the function's name and docstring\n        func_name = func_object.__name__\n        func_docstring = inspect.getdoc(func_object)\n\n        # Get the function's input and output type hints\n        input_type_hints = {\n            key: value for key, value in type_hints.items() if key != \"return\"\n        }\n        output_type_hint = type_hints.get(\"return\", None)\n\n        # Get the function's input and output classes\n        input_classes = {\n            key: get_class_definition(value) for key, value in input_type_hints.items()\n        }\n        output_class = get_class_definition(output_type_hint)\n\n        # Determine the function type\n        if output_type_hint is None:\n            function_type = FunctionType.SYMBOLIC\n        elif issubclass(output_class, Embedding):\n            function_type = FunctionType.EMBEDDABLE\n        elif get_origin(output_type_hint) is Union:\n            function_type = FunctionType.EMBEDDABLE\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        # Create the function description\n        function_description = FunctionDescription(\n            func_name,\n            func_docstring,\n            input_type_hints,\n            output_type_hint,\n            input_classes,\n            output_class,\n            function_type,\n        )\n\n        return function_description\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        if not callable(func_object):\n            raise ValueError(f\"{func_object} is not callable\")\n\n        # Get function signature\n        signature = inspect.signature(func_object)\n\n        # Get function name\n        func_name = func_object.__name__\n\n        # Get function docstring\n        docstring = inspect.getdoc(func_object)\n\n        # Get type hints\n        type_hints = get_type_hints(func_object)\n\n        # Get input and output type hints\n        input_type_hints = {\n            name: type_hints[name]\n            for name in signature.parameters.keys()\n            if name in type_hints\n        }\n        output_type_hints = {\n            name: type_hints[name]\n            for name in type_hints.keys()\n            if name not in signature.parameters.keys()\n        }\n\n        # Get input and output class definitions\n        input_class_definitions = {\n            name: get_class_definition(type_hint)\n            for name, type_hint in input_type_hints.items()\n        }\n        output_class_definitions = {\n            name: get_class_definition(type_hint)\n            for name, type_hint in output_type_hints.items()\n        }\n\n        # Determine function type\n        function_type = FunctionType.EMBEDDABLE\n        if len(output_type_hints) == 0:\n            function_type = FunctionType.SYMBOLIC\n        elif len(output_type_hints) == 1:\n            output_type_hint = list(output_type_hints.values())[0]\n            if get_origin(output_type_hint) == Union:\n                function_type = FunctionType.SYMBOLIC\n\n        # Create function description\n        function_description = FunctionDescription(\n            func_name,\n            docstring,\n            input_type_hints,\n            output_type_hints,\n            input_class_definitions,\n            output"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        func_name = func_object.__name__\n        func_signature = inspect.signature(func_object)\n        func_docstring = inspect.getdoc(func_object)\n        func_type_hints = get_type_hints(func_object)\n        func_input_types = {}\n        func_output_type = None\n        func_output_class_definition = None\n        func_type = None\n\n        for param_name, param in func_signature.parameters.items():\n            if param.annotation != inspect._empty:\n                func_input_types[param_name] = get_class_definition(param.annotation)\n            else:\n                func_input_types[param_name] = None\n\n        if \"return\" in func_type_hints:\n            func_output_type = func_type_hints[\"return\"]\n            func_output_class_definition = get_class_definition(func_output_type)\n\n            if inspect.isclass(func_output_type) and issubclass(func_output_type, Embedding):\n                func_type = FunctionType.EMBEDDABLE\n            elif get_origin(func_output_type) == Union:\n                for output_type in func_output_type.__args__:\n                    if inspect.isclass(output_type) and issubclass(output_type, Embedding):\n                        func_type = FunctionType.EMBEDDABLE\n                        break\n\n        if not func_type:\n            func_type = FunctionType.SYMBOLIC\n\n        return FunctionDescription(\n            func_name,\n            func_docstring,\n            func_input_types,\n            func_output_type,\n            func_output_class_definition,\n            func_type\n        )\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        func_name = func_object.__name__\n        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        docstring = inspect.getdoc(func_object)\n        output_type = type_hints[\"return\"]\n        output_class = get_class_definition(output_type)\n        output_type_hint = get_type_hint(output_type)\n        input_types = []\n        input_classes = []\n        input_type_hints = []\n        for arg in signature.parameters.values():\n            input_types.append(arg.annotation)\n            input_class = get_class_definition(arg.annotation)\n            input_classes.append(input_class)\n            input_type_hint = get_type_hint(arg.annotation)\n            input_type_hints.append(input_type_hint)\n\n        if issubclass(output_class, Embedding):\n            function_type = FunctionType.EMBEDDABLE\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        return FunctionDescription(\n            func_name,\n            docstring,\n            input_types,\n            input_classes,\n            input_type_hints,\n            output_type,\n            output_class,\n            output_type_hint,\n            function_type,\n        )\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        def get_class_definition(type_hint):\n            if get_origin(type_hint) is not None:\n                if get_origin(type_hint) is Union:\n                    for arg in type_hint.__args__:\n                        if inspect.isclass(arg):\n                            if issubclass(arg, Embedding):\n                                return arg\n                else:\n                    return type_hint.__origin__\n            else:\n                return type_hint\n\n        def get_type_hint_class(type_hint):\n            if get_origin(type_hint) is not None:\n                if get_origin(type_hint) is Union:\n                    for arg in type_hint.__args__:\n                        if inspect.isclass(arg):\n                            return arg\n                else:\n                    return type_hint.__origin__\n            else:\n                return type_hint\n\n        def get_type_hint_classes(type_hints):\n            return {key: get_type_hint_class(type_hints[key]) for key in type_hints}\n\n        def get_type_hint_classes_from_signature(signature):\n            return get_type_hint_classes(signature.parameters)\n\n        def get_type_hint_classes_from_type_hints(type_hints):\n            return get_type_hint_classes(type_hints)\n\n        def get_type_hint_classes_from_func_object(func_object):\n            return get_type_hint_classes_from_type_hints(get_type_hints(func_object))\n\n        def get_output_type_hint_class(type_hints):\n            if get_origin(type_hints[\"return\"]) is not None:\n                if get_origin(type_hints[\"return\"]) is Union:\n                    for arg in type_hints[\"return\"].__args__:\n                        if inspect.isclass(arg):\n                            return arg\n                else:\n                    return type_"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        func_signature = inspect.signature(func_object)\n        func_type_hints = get_type_hints(func_object)\n        func_name = func_object.__name__\n        func_docstring = func_object.__doc__\n        func_input_type_hints = {}\n        func_output_type_hints = {}\n        func_input_classes = {}\n        func_output_classes = {}\n        func_type = None\n        func_output_class_definition = None\n\n        # Get type hints\n        for arg_name, arg_type in func_type_hints.items():\n            if arg_name == \"return\":\n                func_output_type_hints = arg_type\n            else:\n                func_input_type_hints[arg_name] = arg_type\n\n        # Get class definitions\n        for arg_name, arg_type in func_input_type_hints.items():\n            func_input_classes[arg_name] = get_class_definition(arg_type)\n\n        # Get output class definition\n        func_output_class_definition = get_class_definition(func_output_type_hints)\n\n        # Determine function type\n        if isinstance(func_output_class_definition, Embedding):\n            func_type = FunctionType.EMBEDDABLE\n        else:\n            func_type = FunctionType.SYMBOLIC\n\n        # Create function description\n        func_description = FunctionDescription(func_name, func_type, func_input_type_hints, func_output_type_hints,\n                                              func_input_classes, func_output_class_definition, func_docstring)\n\n        return func_description\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Get function name\n        func_name = func_object.__name__\n\n        # Get function signature\n        signature = inspect.signature(func_object)\n\n        # Get function docstring\n        docstring = inspect.getdoc(func_object)\n\n        # Get function type hints\n        type_hints = get_type_hints(func_object)\n\n        # Get function input and output type hints\n        input_type_hints = {\n            name: type_hint\n            for name, type_hint in type_hints.items()\n            if name != \"return\"\n        }\n        output_type_hint = type_hints[\"return\"]\n\n        # Get input and output class definitions\n        input_class_definitions = {\n            name: get_class_definition(type_hint)\n            for name, type_hint in input_type_hints.items()\n        }\n        output_class_definition = get_class_definition(output_type_hint)\n\n        # Get function type\n        if issubclass(output_class_definition, Embedding):\n            function_type = FunctionType.EMBEDDABLE\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        # Create function description\n        function_description = FunctionDescription(\n            func_name,\n            signature,\n            docstring,\n            input_class_definitions,\n            output_class_definition,\n            function_type\n        )\n\n        return function_description\n\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Get the function's name\n        func_name = func_object.__name__\n\n        # Get the function's signature\n        signature = inspect.signature(func_object)\n\n        # Get the function's type hints\n        type_hints = get_type_hints(func_object)\n\n        # Get the function's docstring\n        docstring = inspect.getdoc(func_object)\n\n        # Get the function's input and output type hints\n        input_type_hints = {\n            key: type_hints[key] for key in signature.parameters.keys()\n        }\n        output_type_hint = type_hints[signature.return_annotation]\n\n        # Get the function's input and output class definitions\n        input_class_definitions = {\n            key: Register.get_class_definition(value)\n            for key, value in input_type_hints.items()\n        }\n        output_class_definition = Register.get_class_definition(output_type_hint)\n\n        # Determine the function type\n        if issubclass(output_class_definition, Embedding):\n            function_type = FunctionType.EMBEDDABLE\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        # Create a FunctionDescription\n        function_description = FunctionDescription(\n            func_name,\n            input_class_definitions,\n            output_class_definition,\n            function_type,\n            docstring,\n        )\n\n        return function_description\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Get function name\n        func_name = func_object.__name__\n\n        # Get function signature\n        signature = inspect.signature(func_object)\n\n        # Get function docstring\n        docstring = func_object.__doc__\n\n        # Get type hints\n        type_hints = get_type_hints(func_object)\n\n        # Get input and output types\n        input_type_hint = type_hints[\"input\"]\n        output_type_hint = type_hints[\"output\"]\n\n        # Get class definitions for input and output types\n        input_class_definition = get_class_definition(input_type_hint)\n        output_class_definition = get_class_definition(output_type_hint)\n\n        # Check if output type hint is a subclass of an Embedding class\n        if issubclass(output_class_definition, Embedding):\n            function_type = FunctionType.EMBEDDABLE\n        # Check if output type hint is part of a Union\n        elif get_origin(output_type_hint) == Union:\n            # Check if any of the Union types are subclasses of an Embedding class\n            for type_hint in output_type_hint.__args__:\n                if issubclass(get_class_definition(type_hint), Embedding):\n                    function_type = FunctionType.EMBEDDABLE\n                    break\n            # Check if any of the Union types are subclasses of a Literal\n            for type_hint in output_type_hint.__args__:\n                if get_origin(type_hint) == Literal:\n                    function_type = FunctionType.SYMBOLIC\n                    break\n            else:\n                function_type = FunctionType.SYMBOLIC\n        # Otherwise, function is symbolic\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        # Create function description\n        return FunctionDescription(\n            func_name,\n            signature,\n            input_type_hint,\n            output_type_hint,\n            input_class_definition,\n            output_"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        if not callable(func_object):\n            raise TypeError(\"Function must be callable\")\n\n        func_name = func_object.__name__\n        func_docstring = func_object.__doc__\n        func_signature = inspect.signature(func_object)\n        func_type_hints = get_type_hints(func_object)\n\n        input_type_hints = {}\n        for input_name, input_type_hint in func_type_hints.items():\n            input_type_hints[input_name] = get_class_definition(input_type_hint)\n\n        output_type_hint = func_type_hints.get(\"return\", None)\n        output_type_hint_class_definition = get_class_definition(output_type_hint)\n\n        if issubclass(output_type_hint_class_definition, Embedding):\n            function_type = FunctionType.EMBEDDABLE\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        return FunctionDescription(\n            func_name,\n            func_docstring,\n            input_type_hints,\n            output_type_hint,\n            output_type_hint_class_definition,\n            function_type\n        )\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Get the function name\n        func_name = func_object.__name__\n\n        # Get the function signature\n        signature = inspect.signature(func_object)\n\n        # Get the function docstring\n        docstring = inspect.getdoc(func_object)\n\n        # Get the function type hints\n        type_hints = get_type_hints(func_object)\n\n        # Get the function class definitions\n        input_class_definitions = {}\n        output_class_definition = None\n        for key in type_hints.keys():\n            input_class_definitions[key] = get_class_definition(type_hints[key])\n        if \"return\" in type_hints.keys():\n            output_class_definition = get_class_definition(type_hints[\"return\"])\n\n        # Determine the function type\n        if issubclass(output_class_definition, Embedding):\n            function_type = FunctionType.EMBEDDABLE\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        # Create the function description\n        function_description = FunctionDescription(\n            func_name,\n            signature,\n            docstring,\n            input_class_definitions,\n            output_class_definition,\n            function_type\n        )\n\n        return function_description\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Get function name\n        func_name = func_object.__name__\n\n        # Get function signature\n        signature = inspect.signature(func_object)\n\n        # Get function docstring\n        docstring = inspect.getdoc(func_object)\n\n        # Get type hints\n        type_hints = get_type_hints(func_object)\n\n        # Get class definitions for type hints\n        input_class_definitions = {key: Register.get_class_definition(value) for key, value in type_hints.items()}\n        output_class_definition = Register.get_class_definition(type_hints[\"return\"])\n\n        # Determine function type\n        if issubclass(type_hints[\"return\"], Embedding):\n            function_type = FunctionType.EMBEDDABLE\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        # Create function description\n        function_description = FunctionDescription(\n            func_name,\n            docstring,\n            signature,\n            input_class_definitions,\n            output_class_definition,\n            function_type\n        )\n\n        return function_description\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Get the function's signature\n        signature = inspect.signature(func_object)\n\n        # Get the function's type hints\n        type_hints = get_type_hints(func_object)\n\n        # Get the function's docstring\n        docstring = func_object.__doc__\n\n        # Get the function's name\n        func_name = func_object.__name__\n\n        # Get the function's class definitions\n        input_class_definitions = [get_class_definition(type_hints[arg]) for arg in signature.parameters]\n        output_class_definition = get_class_definition(type_hints['return'])\n\n        # Determine the function type based on the output type hint\n        if issubclass(type_hints['return'], Embedding):\n            function_type = FunctionType.EMBEDDABLE\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        # Create the function description\n        return FunctionDescription(func_name, docstring, signature, type_hints, input_class_definitions, output_class_definition, function_type)\n\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        docstring = inspect.getdoc(func_object)\n        name = func_object.__name__\n\n        if len(signature.parameters) == 0:\n            raise ValueError(\n                \"Functions with no input arguments are not supported\")\n\n        if \"return\" not in type_hints:\n            raise ValueError(\n                \"Functions without a return type hint are not supported\")\n\n        if issubclass(type_hints[\"return\"], Embedding):\n            function_type = FunctionType.EMBEDDABLE\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        input_types = []\n        input_class_definitions = []\n        for key in signature.parameters:\n            if key == \"self\":\n                continue\n            input_types.append(type_hints[key])\n            input_class_definitions.append(get_class_definition(type_hints[key]))\n\n        return_class_definition = get_class_definition(type_hints[\"return\"])\n\n        return FunctionDescription(name, docstring, input_types,\n                                   input_class_definitions, return_class_definition, function_type)\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] = seed\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] = seed\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] = seed\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] = hash1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] = seed\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            #print(f\"Add: Seed={seed}, Digest={index}, BitValue={self.bit_array[index]}\")\n            self.bit_array[index] = 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] = seed\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        self.bit_array = self.persistence.load()\n        if len(self.bit_array) != self.size:\n            logging.warning(f\"Loaded bit array length ({len(self.bit_array)}) does not match expected length ({self.size}). Reinitializing.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        bit_array = self.persistence.load()\n        if len(bit_array) != self.size:\n            logging.warning(f\"Loaded bit array length ({len(bit_array)}) does not match expected length ({self.size})\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        self.bit_array = self.persistence.load()\n        if len(self.bit_array) != self.size:\n            logging.warning(f\"Loaded bit array length ({len(self.bit_array)}) does not match expected length ({self.size}). Reinitializing bit array.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        self.bit_array = self.persistence.load()\n        if len(self.bit_array) != self.size:\n            logging.warning(\"Loaded bit array length does not match expected length. Reinitializing bit array.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(f\"Loaded bit array length ({len(loaded_bit_array)}) does not match expected length ({self.size}). Reinitializing.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        self.bit_array = self.persistence.load()\n        if len(self.bit_array) != self.size:\n            logging.warning(\"Loaded bit array length does not match expected length. Reinitializing bit array.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        bit_array = self.persistence.load()\n        if len(bit_array) != self.size:\n            logging.warning(\"Loaded bit array length does not match expected length. Reinitializing and saving.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        self.bit_array = self.persistence.load()\n        if len(self.bit_array) != self.size:\n            logging.warning(f\"Loaded bit array length does not match expected length. Reinitializing bit array and indices.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        self.bit_array = self.persistence.load()\n        if self.bit_array.length() != self.size:\n            logging.warning(\"Bit array length mismatch. Reinitializing bit array\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        self.bit_array = self.persistence.load()\n        if len(self.bit_array) != self.size:\n            logging.warning(\"Loaded bit array length does not match expected length. BloomFilter will be reinitialized.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if loaded_bit_array.length() != self.size:\n            logging.warning(f\"Loaded bit array length ({loaded_bit_array.length()}) does not match expected length ({self.size}). Reinitializing bit array.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Loaded bit array length does not match expected length. BloomFilter reinitialized.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(f\"Loaded BloomFilter has length {len(loaded_bit_array)} which does not match expected length {self.size}. Reinitializing BloomFilter.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        bit_array = self.persistence.load()\n        if len(bit_array) == self.size:\n            self.bit_array = bit_array\n            self.indices = np.zeros(self.size, dtype=np.int32)\n        else:\n            logging.warning(\"BloomFilter bit array length mismatch. Reinitializing BloomFilter.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if loaded_bit_array.length() != self.size:\n            logging.warning(\"Loaded bit array length does not match expected length. Reinitializing bit array.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array\n\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        self.bit_array = self.persistence.load()\n        if len(self.bit_array) != self.size:\n            logging.warning(f\"Loaded BloomFilter has length {len(self.bit_array)} but expected length is {self.size}. Reinitializing and saving.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        try:\n            loaded_bit_array = self.persistence.load()\n            if len(loaded_bit_array) != self.size:\n                logging.warning(\"Loaded bit array length does not match expected length. Reinitializing bit array and indices.\")\n                self.bit_array, self.indices = self.init_bit_array(self.size)\n                self.save()\n            else:\n                self.bit_array = loaded_bit_array\n        except Exception as e:\n            logging.warning(f\"Failed to load bit array: {e}\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(f\"Loaded BloomFilter bit array length does not match expected length based on size. \"\n                            f\"Loaded length: {len(loaded_bit_array)}, Expected length: {self.size}. \"\n                            f\"Reinitializing BloomFilter.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        _bit_array = self.persistence.load()\n        if len(_bit_array) != self.size:\n            logging.warning(f\"Bit array length mismatch: {len(_bit_array)} != {self.size}. Reinitializing bit array.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = _bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        self.bit_array = self.persistence.load()\n        if self.bit_array.length() != self.size:\n            logging.warning(f\"Loaded bit array length does not match expected length based on size. Expected: {self.size}, Loaded: {self.bit_array.length()}. Reinitializing bit array.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        indices = self.indices\n        indices[0] = hash1 % self.size\n        indices[1] = hash2 % self.size\n        indices[2] = (hash1 + hash2) % self.size\n        indices[3] = (hash1 + hash2 * 2) % self.size\n        indices[4] = (hash1 * 2 + hash2) % self.size\n        indices[5] = (hash1 * 3 + hash2) % self.size\n        indices[6] = (hash1 * 4 + hash2) % self.size\n        indices[7] = (hash1 * 5 + hash2) % self.size\n        indices[8] = (hash1 * 6 + hash2) % self.size\n        indices[9] = (hash1 * 7 + hash2) % self.size\n        indices[10] = (hash1 * 8 + hash2) % self.size\n        indices[11] = (hash1 * 9 + hash2) % self.size\n        indices[12] = (hash1 * 10 + hash2) % self.size\n        indices[13] = (hash1 * 11 + hash2) % self.size\n        indices[14] = (hash1 * 12 + hash2) % self.size\n        indices[15] = (hash1 * 13 + hash2) % self.size\n        indices[16] = (hash1 * 14 + hash2) % self.size\n        indices[17] = (hash1 * 15 + hash2) % self.size\n        indices[18] = (hash1 * 16 + hash2) % self.size\n        indices[19] = (hash1 * 17 + hash2) % self.size\n        indices[20] = (hash1 * 18 + hash2) % self.size\n        indices[21] = (hash1 * 19 + hash2) % self.size\n        indices[22] = (hash"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        indices = self.indices\n        indices[0] = (hash1 % self.size)\n        indices[1] = (hash2 % self.size)\n        indices[2] = ((hash1 + hash2) % self.size)\n        indices[3] = ((hash1 + hash2 + 1) % self.size)\n        indices[4] = ((hash1 + hash2 + 2) % self.size)\n        indices[5] = ((hash1 + hash2 + 3) % self.size)\n        indices[6] = ((hash1 + hash2 + 4) % self.size)\n        indices[7] = ((hash1 + hash2 + 5) % self.size)\n        indices[8] = ((hash1 + hash2 + 6) % self.size)\n        indices[9] = ((hash1 + hash2 + 7) % self.size)\n        indices[10] = ((hash1 + hash2 + 8) % self.size)\n        indices[11] = ((hash1 + hash2 + 9) % self.size)\n        indices[12] = ((hash1 + hash2 + 10) % self.size)\n        indices[13] = ((hash1 + hash2 + 11) % self.size)\n        indices[14] = ((hash1 + hash2 + 12) % self.size)\n        indices[15] = ((hash1 + hash2 + 13) % self.size)\n        indices[16] = ((hash1 + hash2 + 14) % self.size)\n        indices[17] = ((hash1 + hash2 + 15) % self.size)\n        indices[18] = ((hash1 + hash2 + 16) % self.size)\n        indices[19] = ((hash1 + hash2 + 17) % self.size)\n        indices[20] = ((hash1 + hash2 + 18) % self.size)\n        indices[21] = ((hash1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n\n        for i in range(self.hash_count):\n            index1 = hash1 % self.size\n            index2 = hash2 % self.size\n            if not self.bit_array[index1] or not self.bit_array[index2]:\n                return False\n            hash1 = (hash1 * 1664525 + 1013904223) % 2**32\n            hash2 = (hash2 * 1664525 + 1013904223) % 2**32\n\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for i in range(self.hash_count):\n            index1 = hash1 % self.size\n            index2 = hash2 % self.size\n            if not self.bit_array[index1] or not self.bit_array[index2]:\n                return False\n            hash1 += self.indices[index1]\n            hash2 += self.indices[index2]\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        indices = self.indices\n        indices[0:self.hash_count] = (hash1 % self.size), (hash2 % self.size)\n        return self.bit_array[indices].all()\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        indices = self.indices\n        bit_array = self.bit_array\n        for i in range(self.hash_count):\n            index1 = (hash1 + i * hash2) % self.size\n            index2 = (hash2 + i * hash1) % self.size\n            indices[i] = index1\n            if not bit_array[index1]:\n                return False\n            if not bit_array[index2]:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        # Generate hash indices\n        hash1, hash2 = self.hash_functions(string)\n        indices = self.indices\n        indices[0:self.hash_count] = [hash1 % self.size, hash2 % self.size]\n        indices[self.hash_count:2*self.hash_count] = [hash1 % self.size, hash2 % self.size]\n\n        # Check if all indices are set in the bit array\n        return np.all(self.bit_array[indices])\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for i in range(self.hash_count):\n            index = (hash1 + i * hash2) % self.size\n            if not self.bit_array[index]:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        indices = self.indices\n        indices[0:self.hash_count] = self.hash_count * [hash1]\n        indices[self.hash_count:2*self.hash_count] = self.hash_count * [hash2]\n        return all(self.bit_array[indices])\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        indices = self.indices[hash1 % self.size]\n        indices2 = self.indices[hash2 % self.size]\n        if indices == 0 and indices2 == 0:\n            return False\n        return self.bit_array[indices] and self.bit_array[indices2]\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        # Get the two hash values\n        hash1, hash2 = self.hash_functions(string)\n\n        # Get the indices from the hash values\n        indices = self.indices[hash1 % self.size]\n        indices = np.append(indices, self.indices[hash2 % self.size])\n\n        # Check if all the indices are set in the bit array\n        return np.all(self.bit_array[indices])\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        indices = self.indices\n        bit_array = self.bit_array\n        for i in range(self.hash_count):\n            # h1(x) mod size\n            index1 = hash1 % self.size\n            # h2(x) mod size\n            index2 = hash2 % self.size\n            # Set indices to indices of hash functions\n            indices[i] = index1\n            indices[i+self.hash_count] = index2\n            # Check if bit is set at index\n            if not bit_array[index1] or not bit_array[index2]:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        indices = self.indices[hash1 % self.size:hash2 % self.size]\n        return np.all(self.bit_array[indices])\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        indices = self.indices[hash1 % self.size:hash2 % self.size]\n        return all(self.bit_array[indices])\n\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        indices = self.indices[hash1 % self.size]\n        indices2 = self.indices[hash2 % self.size]\n\n        if indices == 0:\n            return False\n\n        if indices2 == 0:\n            return False\n\n        return self.bit_array[indices - 1] and self.bit_array[indices2 - 1]\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        indices = self.indices[hash1 % self.size]\n        indices = np.append(indices, self.indices[hash2 % self.size])\n        return np.all(self.bit_array[indices])\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        # Hash the string to generate hash1 and hash2\n        hash1, hash2 = self.hash_functions(string)\n\n        # Generate the indices\n        indices = self.indices[hash1 % self.size] + hash2 % self.size\n\n        # Check if all bits are set at the indices\n        return np.all(self.bit_array[indices])\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        indices = self.indices\n        indices[0] = hash1 % self.size\n        indices[1] = hash2 % self.size\n        return all(self.bit_array[indices[0:self.hash_count]])\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        # Hash the input string\n        hash1, hash2 = self.hash_functions(string)\n\n        # Get the indices\n        indices = self.indices[hash1 % self.size]\n\n        # Check if any bit is not set\n        return np.all(self.bit_array[indices])\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        indices = self.indices[hash1 % self.size:hash2 % self.size]\n        return np.all(self.bit_array[indices])\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        if \"distilled_model\" in json_dict:\n            self.distilled_model = config_factory.create(json_dict[\"distilled_model\"])\n        if \"current_model_stats\" in json_dict:\n            self.current_model_stats = json_dict[\"current_model_stats\"]\n        if \"last_training_run\" in json_dict:\n            self.last_training_run = json_dict[\"last_training_run\"]\n        if \"current_training_run\" in json_dict:\n            self.current_training_run = json_dict[\"current_training_run\"]\n        if \"nr_of_training_runs\" in json_dict:\n            self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = [config_factory.create(json_dict[\"teacher_models\"][i]) for i in range(len(json_dict[\"teacher_models\"]))]\n\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        if \"distilled_model\" in json_dict:\n            self.distilled_model = config_factory.create(json_dict[\"distilled_model\"])\n        if \"current_model_stats\" in json_dict:\n            self.current_model_stats = json_dict[\"current_model_stats\"]\n        if \"last_training_run\" in json_dict:\n            self.last_training_run = json_dict[\"last_training_run\"]\n        if \"current_training_run\" in json_dict:\n            self.current_training_run = json_dict[\"current_training_run\"]\n        if \"nr_of_training_runs\" in json_dict:\n            self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = []\n            for teacher_model in json_dict[\"teacher_models\"]:\n                self.teacher_models.append(config_factory.create(teacher_model))\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        if \"distilled_model\" in json_dict:\n            self.distilled_model = config_factory.get_model_config(json_dict[\"distilled_model\"])\n        if \"current_model_stats\" in json_dict:\n            self.current_model_stats = json_dict[\"current_model_stats\"]\n        if \"last_training_run\" in json_dict:\n            self.last_training_run = json_dict[\"last_training_run\"]\n        if \"current_training_run\" in json_dict:\n            self.current_training_run = json_dict[\"current_training_run\"]\n        if \"nr_of_training_runs\" in json_dict:\n            self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = [config_factory.get_model_config(teacher_model) for teacher_model in json_dict[\"teacher_models\"]]\n\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        if \"distilled_model\" in json_dict:\n            self.distilled_model = config_factory.create(json_dict[\"distilled_model\"])\n        if \"current_model_stats\" in json_dict:\n            self.current_model_stats = json_dict[\"current_model_stats\"]\n        if \"last_training_run\" in json_dict:\n            self.last_training_run = json_dict[\"last_training_run\"]\n        if \"current_training_run\" in json_dict:\n            self.current_training_run = json_dict[\"current_training_run\"]\n        if \"nr_of_training_runs\" in json_dict:\n            self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = [config_factory.create(json_dict[\"teacher_models\"][i]) for i in range(len(json_dict[\"teacher_models\"]))]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        if \"distilled_model\" in json_dict:\n            self.distilled_model = config_factory.create(json_dict[\"distilled_model\"])\n\n        if \"current_model_stats\" in json_dict:\n            self.current_model_stats = json_dict[\"current_model_stats\"]\n\n        if \"last_training_run\" in json_dict:\n            self.last_training_run = json_dict[\"last_training_run\"]\n\n        if \"current_training_run\" in json_dict:\n            self.current_training_run = json_dict[\"current_training_run\"]\n\n        if \"nr_of_training_runs\" in json_dict:\n            self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = []\n            for teacher_model in json_dict[\"teacher_models\"]:\n                self.teacher_models.append(config_factory.create(teacher_model))\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        if \"distilled_model\" in json_dict:\n            self.distilled_model = config_factory.create_model_config(json_dict[\"distilled_model\"])\n        if \"current_model_stats\" in json_dict:\n            self.current_model_stats = json_dict[\"current_model_stats\"]\n        if \"last_training_run\" in json_dict:\n            self.last_training_run = json_dict[\"last_training_run\"]\n        if \"current_training_run\" in json_dict:\n            self.current_training_run = json_dict[\"current_training_run\"]\n        if \"nr_of_training_runs\" in json_dict:\n            self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = []\n            for teacher_model in json_dict[\"teacher_models\"]:\n                self.teacher_models.append(config_factory.create_model_config(teacher_model))\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        # Load distilled model\n        if \"distilled_model\" in json_dict:\n            self.distilled_model = config_factory.create(json_dict[\"distilled_model\"])\n\n        # Load current model stats\n        if \"current_model_stats\" in json_dict:\n            self.current_model_stats = json_dict[\"current_model_stats\"]\n\n        # Load last training run\n        if \"last_training_run\" in json_dict:\n            self.last_training_run = json_dict[\"last_training_run\"]\n\n        # Load current training run\n        if \"current_training_run\" in json_dict:\n            self.current_training_run = json_dict[\"current_training_run\"]\n\n        # Load teacher models\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = [config_factory.create(json_dict[\"teacher_models\"])]\n\n        # Load number of training runs\n        if \"nr_of_training_runs\" in json_dict:\n            self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n\n        return self\n\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        # Load distilled model\n        if \"distilled_model\" in json_dict:\n            self.distilled_model = config_factory.create_model_config(json_dict[\"distilled_model\"])\n\n        # Load current model stats\n        if \"current_model_stats\" in json_dict:\n            self.current_model_stats = json_dict[\"current_model_stats\"]\n\n        # Load last training run\n        if \"last_training_run\" in json_dict:\n            self.last_training_run = json_dict[\"last_training_run\"]\n\n        # Load current training run\n        if \"current_training_run\" in json_dict:\n            self.current_training_run = json_dict[\"current_training_run\"]\n\n        # Load number of training runs\n        if \"nr_of_training_runs\" in json_dict:\n            self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n\n        # Load teacher models\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = []\n            for teacher_model in json_dict[\"teacher_models\"]:\n                self.teacher_models.append(config_factory.create_model_config(teacher_model))\n\n        return self\n\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        if \"distilled_model\" in json_dict:\n            self.distilled_model = config_factory.load_model(json_dict[\"distilled_model\"])\n        if \"current_model_stats\" in json_dict:\n            self.current_model_stats = json_dict[\"current_model_stats\"]\n        if \"last_training_run\" in json_dict:\n            self.last_training_run = json_dict[\"last_training_run\"]\n        if \"current_training_run\" in json_dict:\n            self.current_training_run = json_dict[\"current_training_run\"]\n        if \"nr_of_training_runs\" in json_dict:\n            self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = [config_factory.load_model(teacher_model) for teacher_model in json_dict[\"teacher_models\"]]\n\n        return self\n\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        if \"distilled_model\" in json_dict:\n            self.distilled_model = config_factory.create(json_dict[\"distilled_model\"])\n        if \"current_model_stats\" in json_dict:\n            self.current_model_stats = json_dict[\"current_model_stats\"]\n        if \"last_training_run\" in json_dict:\n            self.last_training_run = json_dict[\"last_training_run\"]\n        if \"current_training_run\" in json_dict:\n            self.current_training_run = json_dict[\"current_training_run\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = [config_factory.create(teacher_model) for teacher_model in json_dict[\"teacher_models\"]]\n        if \"nr_of_training_runs\" in json_dict:\n            self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.create(json_dict[\"distilled_model\"])\n        self.current_model_stats = json_dict[\"current_model_stats\"]\n        self.last_training_run = json_dict[\"last_training_run\"]\n        self.current_training_run = json_dict[\"current_training_run\"]\n        self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        self.teacher_models = [config_factory.create(teacher_model) for teacher_model in json_dict[\"teacher_models\"]]\n        return self\n\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        if \"distilled_model\" in json_dict:\n            self.distilled_model = config_factory.create(json_dict[\"distilled_model\"])\n        if \"current_model_stats\" in json_dict:\n            self.current_model_stats = json_dict[\"current_model_stats\"]\n        if \"last_training_run\" in json_dict:\n            self.last_training_run = json_dict[\"last_training_run\"]\n        if \"current_training_run\" in json_dict:\n            self.current_training_run = json_dict[\"current_training_run\"]\n        if \"nr_of_training_runs\" in json_dict:\n            self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = [config_factory.create(json_dict[\"teacher_models\"][i]) for i in range(len(json_dict[\"teacher_models\"]))]\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        if \"distilled_model\" in json_dict:\n            self.distilled_model = config_factory.get_model_config(json_dict[\"distilled_model\"])\n        if \"current_model_stats\" in json_dict:\n            self.current_model_stats = json_dict[\"current_model_stats\"]\n        if \"last_training_run\" in json_dict:\n            self.last_training_run = json_dict[\"last_training_run\"]\n        if \"current_training_run\" in json_dict:\n            self.current_training_run = json_dict[\"current_training_run\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = [config_factory.get_model_config(model) for model in json_dict[\"teacher_models\"]]\n        if \"nr_of_training_runs\" in json_dict:\n            self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.create_config(json_dict[\"distilled_model\"])\n        self.current_model_stats = json_dict[\"current_model_stats\"]\n        self.last_training_run = json_dict[\"last_training_run\"]\n        self.current_training_run = json_dict[\"current_training_run\"]\n        self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        self.teacher_models = [config_factory.create_config(json_dict[\"teacher_models\"][i]) for i in range(len(json_dict[\"teacher_models\"]))]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.create_model_config(json_dict[\"distilled_model\"])\n        self.current_model_stats = json_dict[\"current_model_stats\"]\n        self.last_training_run = json_dict[\"last_training_run\"]\n        self.current_training_run = json_dict[\"current_training_run\"]\n        self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = [config_factory.create_model_config(json_dict[\"teacher_models\"])]\n        else:\n            self.teacher_models = [DEFAULT_TEACHER_MODELS[teacher_model_name] for teacher_model_name in DEFAULT_TEACHER_MODEL_NAMES]\n\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        # Load distilled model\n        if DISTILLED_MODEL in json_dict:\n            self.distilled_model = config_factory.create_config(json_dict[DISTILLED_MODEL])\n\n        # Load current model stats\n        if \"current_model_stats\" in json_dict:\n            self.current_model_stats = json_dict[\"current_model_stats\"]\n\n        # Load last training run\n        if \"last_training_run\" in json_dict:\n            self.last_training_run = json_dict[\"last_training_run\"]\n\n        # Load current training run\n        if \"current_training_run\" in json_dict:\n            self.current_training_run = json_dict[\"current_training_run\"]\n\n        # Load number of training runs\n        if \"nr_of_training_runs\" in json_dict:\n            self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n\n        # Load teacher models\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = []\n            for teacher_model in json_dict[\"teacher_models\"]:\n                self.teacher_models.append(config_factory.create_config(teacher_model))\n\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        if \"distilled_model\" in json_dict:\n            self.distilled_model = config_factory.create(json_dict[\"distilled_model\"])\n        if \"current_model_stats\" in json_dict:\n            self.current_model_stats = json_dict[\"current_model_stats\"]\n        if \"last_training_run\" in json_dict:\n            self.last_training_run = json_dict[\"last_training_run\"]\n        if \"current_training_run\" in json_dict:\n            self.current_training_run = json_dict[\"current_training_run\"]\n        if \"nr_of_training_runs\" in json_dict:\n            self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = [config_factory.create(json_dict[\"teacher_models\"])]\n        return self\n\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.create(json_dict['distilled_model'])\n        self.current_model_stats = json_dict['current_model_stats']\n        self.last_training_run = json_dict['last_training_run']\n        self.current_training_run = json_dict['current_training_run']\n        self.teacher_models = [config_factory.create(teacher_model) for teacher_model in json_dict['teacher_models']]\n        self.nr_of_training_runs = json_dict['nr_of_training_runs']\n\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        for key in json_dict:\n            if key == \"distilled_model\":\n                self.distilled_model = config_factory.create(json_dict[key])\n            elif key == \"teacher_models\":\n                self.teacher_models = [config_factory.create(teacher_model_dict) for teacher_model_dict in json_dict[key]]\n            else:\n                setattr(self, key, json_dict[key])\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        for key, value in json_dict.items():\n            if key == \"distilled_model\":\n                self.distilled_model = config_factory.get_model_config(value)\n            elif key == \"teacher_models\":\n                self.teacher_models = [config_factory.get_model_config(teacher_model) for teacher_model in value]\n            else:\n                setattr(self, key, value)\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # Handle optional parameters\n        if not \"max_tokens\" in kwargs:\n            kwargs[\"max_tokens\"] = model.max_tokens\n        if not \"stop\" in kwargs:\n            kwargs[\"stop\"] = model.stop\n        if not \"frequency_penalty\" in kwargs:\n            kwargs[\"frequency_penalty\"] = model.frequency_penalty\n        if not \"presence_penalty\" in kwargs:\n            kwargs[\"presence_penalty\"] = model.presence_penalty\n        if not \"temperature\" in kwargs:\n            kwargs[\"temperature\"] = model.temperature\n        if not \"top_p\" in kwargs:\n            kwargs[\"top_p\"] = model.top_p\n        if not \"max_new_tokens\" in kwargs:\n            kwargs[\"max_new_tokens\"] = model.max_new_tokens\n\n        # Handle optional parameters\n        if not \"max_tokens\" in kwargs:\n            kwargs[\"max_tokens\"] = model.max_tokens\n        if not \"stop\" in kwargs:\n            kwargs[\"stop\"] = model.stop\n        if not \"frequency_penalty\" in kwargs:\n            kwargs[\"frequency_penalty\"] = model.frequency_penalty\n        if not \"presence_penalty\" in kwargs:\n            kwargs[\"presence_penalty\"] = model.presence_penalty\n        if not \"temperature\" in kwargs:\n            kwargs[\"temperature\"] = model.temperature\n        if not \"top_p\" in kwargs:\n            kwargs[\"top_p\"] = model.top_p\n        if not \"max_new_tokens\" in kwargs:\n            kwargs[\"max_new_tokens\"] = model.max_new_tokens\n\n        # Handle optional parameters\n        if not \"max_tokens\" in kwargs:\n            kwargs[\"max_tokens\"] = model.max_tokens\n        if not \"stop\" in kwargs:\n            kwargs[\""}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        # Verify the API key is set\n        self.check_api_key()\n\n        # Verify the model is valid\n        self.check_model(model)\n\n        # Verify the system message is valid\n        self.check_system_message(system_message)\n\n        # Verify the prompt is valid\n        self.check_prompt(prompt)\n\n        # Verify the generation parameters are valid\n        self.check_generation_parameters(**kwargs)\n\n        # Make the request\n        response = self.make_request(model, system_message, prompt, **kwargs)\n\n        # Process the response\n        response = self.process_response(response)\n\n        return response\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # Check if any generation parameters are passed in. If not, set them to the default values.\n        for param in LLM_GENERATION_PARAMETERS:\n            if param not in kwargs:\n                kwargs[param] = model.default_parameters[param]\n\n        # Set the model name to the name of the model if it isn't already set.\n        if \"model\" not in kwargs:\n            kwargs[\"model\"] = model.model_name\n\n        # Set the prompt to the system message and user prompt if it isn't already set.\n        if \"prompt\" not in kwargs:\n            kwargs[\"prompt\"] = system_message + \"\\n\" + prompt\n\n        # Set the temperature to the default temperature if it isn't already set.\n        if \"temperature\" not in kwargs:\n            kwargs[\"temperature\"] = model.default_parameters[\"temperature\"]\n\n        # Set the max_tokens to the default max_tokens if it isn't already set.\n        if \"max_tokens\" not in kwargs:\n            kwargs[\"max_tokens\"] = model.default_parameters[\"max_tokens\"]\n\n        # Set the top_p to the default top_p if it isn't already set.\n        if \"top_p\" not in kwargs:\n            kwargs[\"top_p\"] = model.default_parameters[\"top_p\"]\n\n        # Set the frequency_penalty to the default frequency_penalty if it isn't already set.\n        if \"frequency_penalty\" not in kwargs:\n            kwargs[\"frequency_penalty\"] = model.default_parameters[\"frequency_penalty\"]\n\n        # Set the presence_penalty to the default presence_penalty if it isn't already set.\n        if \"presence_penalty\" not in kwargs:\n            kwargs[\"presence_penalty\"] = model.default_parameters[\"presence_penalty\"]\n\n        # Set the max_new_tokens to the default max_new_tokens if it isn't already set.\n        if"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        # Check that the API key is valid\n        self.check_api_key()\n\n        # Validate the parameters\n        self.validate_parameters(model, system_message, prompt, **kwargs)\n\n        # Make the request\n        response = self.generate_with_retries(model, system_message, prompt, **kwargs)\n\n        # Parse the response\n        text = self.parse_response(response)\n\n        return text\n\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        # Check API key\n        self.check_api_key()\n\n        # Check parameters\n        self.check_parameters(model, system_message, prompt, **kwargs)\n\n        # Create generation parameters\n        generation_parameters = copy.deepcopy(kwargs)\n        generation_parameters[\"model\"] = model.model_name\n        generation_parameters[\"prompt\"] = f\"{system_message} {prompt}\"\n        generation_parameters[\"echo\"] = True\n\n        # Make generation request\n        response = self.make_generation_request(generation_parameters)\n\n        # Process response\n        response_text = self.process_generation_response(response)\n\n        return response_text\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        # Validate the input parameters\n        if not isinstance(model, OpenAIConfig):\n            raise TypeError(\"The model parameter must be an instance of the OpenAIConfig class.\")\n        if not isinstance(system_message, str):\n            raise TypeError(\"The system_message parameter must be a string.\")\n        if not isinstance(prompt, str):\n            raise TypeError(\"The prompt parameter must be a string.\")\n        for key, value in kwargs.items():\n            if key not in LLM_GENERATION_PARAMETERS:\n                raise ValueError(f\"The {key} parameter is not a valid generation parameter.\")\n\n        # Verify the API key\n        self.check_api_key()\n\n        # Create the generation parameters\n        generation_params = copy.deepcopy(kwargs)\n        generation_params[\"model\"] = model.model_name\n        generation_params[\"temperature\"] = 0.0 if \"temperature\" not in generation_params else generation_params[\"temperature\"]\n        generation_params[\"top_p\"] = 1.0 if \"top_p\" not in generation_params else generation_params[\"top_p\"]\n        generation_params[\"frequency_penalty\"] = 0.0 if \"frequency_penalty\" not in generation_params else generation_params[\"frequency_penalty\"]\n        generation_params[\"presence_penalty\"] = 0.0 if \"presence_penalty\" not in generation_params else generation_params[\"presence_penalty\"]\n        generation_params[\"max_new_tokens\"] = 100 if \"max_new_tokens\" not in generation_params else generation_params[\"max_new_tokens\"]\n\n        # Create the prompt\n        prompt = f\"{system_message}\\n{prompt}\"\n\n        # Create the text to remove\n        remove_text = \"\".join([f\"{token} \" for token in model.parsing_helper_tokens])\n\n        # Retry generation on failure\n        for i in range(5):\n            try:\n                response = self.client.completions.create(\n                    prompt=prompt,\n                    **"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # Validate the parameters\n        self.validate_parameters(model, system_message, prompt, **kwargs)\n\n        # Retry generation up to 5 times with exponential backoff\n        for retry in range(5):\n            try:\n                # Generate the response\n                response = self.client.engines.generate_text(\n                    model.model_name,\n                    prompt=system_message + \"\\n\" + prompt,\n                    **kwargs\n                )\n                # Remove any parsing helper tokens from the response\n                response = self.remove_helper_tokens(response, model.parsing_tokens)\n                return response\n            except Exception as e:\n                print(f\"An error occurred: {e}\")\n                if retry == 4:\n                    return None\n                else:\n                    time.sleep(2 ** retry)\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        # Verify that the API key is set\n        self.check_api_key()\n\n        # Validate the model\n        self.validate_model(model)\n\n        # Validate the system message\n        self.validate_system_message(system_message)\n\n        # Validate the prompt\n        self.validate_prompt(prompt)\n\n        # Validate the parameters\n        self.validate_parameters(kwargs)\n\n        # Retry generation up to 5 times with exponential backoff\n        for i in range(5):\n            try:\n                # Generate the response from the OpenAI API\n                response = self.client.engines.generate_text(\n                    engine=model.model_name,\n                    prompt=system_message + prompt,\n                    **kwargs\n                )\n\n                # Process the response to remove any parsing helper tokens\n                response = self.process_response(response, model)\n\n                # Return the response\n                return response\n\n            except Exception as e:\n                # Raise the exception if this is the last attempt\n                if i == 4:\n                    raise e\n\n                # Wait 2^i seconds before retrying\n                time.sleep(2**i)\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # Validate the parameters\n        self.validate_params(model, system_message, prompt, **kwargs)\n\n        # Set up the request\n        request_parameters = copy.deepcopy(kwargs)\n        request_parameters[\"model\"] = model.model_name\n        request_parameters[\"prompt\"] = system_message + \"\\n\" + prompt\n        request_parameters[\"max_tokens\"] = model.max_tokens\n        request_parameters[\"temperature\"] = model.temperature\n        request_parameters[\"top_p\"] = model.top_p\n        request_parameters[\"frequency_penalty\"] = model.frequency_penalty\n        request_parameters[\"presence_penalty\"] = model.presence_penalty\n\n        # Retry generation with exponential backoff\n        for i in range(5):\n            try:\n                response = requests.post(OPENAI_URL, json=request_parameters, headers={\"Authorization\": f\"Bearer {self.api_key}\"}).json()\n                response_text = response[\"choices\"][0][\"text\"]\n                response_text = response_text.replace(model.start_token, \"\")\n                response_text = response_text.replace(model.end_token, \"\")\n                return response_text\n            except Exception as e:\n                print(f\"An error occurred: {e}\")\n                print(f\"Retrying in {2 ** i} seconds\")\n                time.sleep(2 ** i)\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        # Validate the input parameters\n        self.check_api_key()\n        self.check_model(model)\n        self.check_system_message(system_message)\n        self.check_prompt(prompt)\n        self.check_generation_parameters(**kwargs)\n\n        # Retry generation on failure up to 5 times with exponential backoff\n        for attempt in range(5):\n            try:\n                # Generate the response from the OpenAI API\n                response = self.client.completions.create(\n                    engine=model.model_name,\n                    prompt=system_message + prompt,\n                    **kwargs\n                )\n                assert response.object == \"list\"\n                assert len(response.data) == 1\n                assert response.data[0].object == \"completion\"\n\n                # Remove any parsing helper tokens from the response and return\n                response_text = response.data[0].text.replace(model.start_token, \"\").replace(model.end_token, \"\")\n                return response_text\n            except Exception as e:\n                if attempt == 4:\n                    print(f\"An error occurred: {e}\")\n                    return None\n                else:\n                    sleep_time = 2 ** attempt\n                    print(f\"An error occurred: {e}. Retrying in {sleep_time} seconds.\")\n                    time.sleep(sleep_time)\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        # Verify that the OpenAI API key has been set.\n        self.check_api_key()\n\n        # Validate the parameters.\n        self.validate_parameters(model, system_message, prompt, **kwargs)\n\n        # Retry generation on failure.\n        for attempt in range(5):\n            try:\n                # Send the generation request.\n                response = self.client.completions.create(\n                    engine=model.model_name,\n                    prompt=system_message + prompt,\n                    **kwargs\n                )\n\n                # Return the response text after removing any parsing helper tokens.\n                return response.choices[0].text.replace(model.parse_helper_token, \"\")\n\n            # Handle rate limiting errors.\n            except requests.exceptions.HTTPError as e:\n                if e.response.status_code == 429:\n                    print(f\"Rate limited. Retrying in {2 ** attempt} seconds.\")\n                    time.sleep(2 ** attempt)\n                    continue\n                else:\n                    raise e\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        # Validate the model configuration\n        self.check_model(model)\n\n        # Validate the parameters\n        self.check_parameters(**kwargs)\n\n        # Validate the system message\n        self.check_system_message(system_message)\n\n        # Validate the prompt\n        self.check_prompt(prompt)\n\n        # Handle API key verification\n        self.check_api_key()\n\n        # Handle retries on failure\n        for i in range(5):\n            try:\n                # Send the request to the OpenAI API\n                response = self.client.engines.generate_text(\n                    engine=model.model_name,\n                    prompt=system_message + prompt,\n                    **kwargs\n                )\n\n                # Process the response\n                response_text = self.process_response(response, model)\n\n                # Return the response text\n                return response_text\n\n            except Exception as e:\n                logging.error(f\"An error occurred: {e}\")\n                logging.error(f\"Retrying in {2**i} seconds...\")\n                time.sleep(2**i)\n\n        # If the request fails after 5 retries, return None\n        return None\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # Make sure the model is valid\n        if not isinstance(model, OpenAIConfig):\n            raise TypeError(\"model must be a valid OpenAIConfig object\")\n\n        # Set the default temperature\n        if \"temperature\" not in kwargs:\n            kwargs[\"temperature\"] = 0.9\n\n        # Set the default top_p\n        if \"top_p\" not in kwargs:\n            kwargs[\"top_p\"] = 1.0\n\n        # Set the default max_new_tokens\n        if \"max_new_tokens\" not in kwargs:\n            kwargs[\"max_new_tokens\"] = 100\n\n        # Set the default frequency_penalty\n        if \"frequency_penalty\" not in kwargs:\n            kwargs[\"frequency_penalty\"] = 0.0\n\n        # Set the default presence_penalty\n        if \"presence_penalty\" not in kwargs:\n            kwargs[\"presence_penalty\"] = 0.0\n\n        # Set the default max_tries\n        max_tries = 5\n\n        # Set the default sleep time between retries\n        sleep_time = 1\n\n        # Set the default exponential backoff factor\n        exponential_backoff = 1.5\n\n        # Set the default maximum sleep time\n        max_sleep = 16\n\n        # Set the default number of retries\n        retries = 0\n\n        # Make sure the system message is valid\n        if not isinstance(system_message, str):\n            raise TypeError(\"system_message must be a string\")\n\n        # Make sure the prompt is valid\n        if not isinstance(prompt, str):\n            raise TypeError(\"prompt must be a string\")\n\n        # Make sure the additional parameters are valid\n        for key in kwargs:\n            if key not in LLM_GENERATION_PARAMETERS:\n                raise TypeError(f\"{key} is not a valid generation parameter\")\n\n        # Make sure the additional parameters are valid\n        for key in kwargs:\n            if key not in LLM_"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        # Check the API key\n        self.check_api_key()\n\n        # Check the parameters\n        self.check_params(model, system_message, prompt, **kwargs)\n\n        # Set the parameters\n        params = self.set_params(model, system_message, prompt, **kwargs)\n\n        # Set the headers\n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\",\n        }\n\n        # Set the data\n        data = {\n            \"prompt\": params[\"prompt\"],\n            \"echo\": params[\"echo\"],\n            \"frequency_penalty\": params[\"frequency_penalty\"],\n            \"presence_penalty\": params[\"presence_penalty\"],\n            \"top_p\": params[\"top_p\"],\n            \"max_new_tokens\": params[\"max_new_tokens\"],\n            \"temperature\": params[\"temperature\"],\n        }\n\n        # Set the URL\n        url = OPENAI_URL\n\n        # Try the request\n        for i in range(5):\n            try:\n                response = requests.post(url, headers=headers, json=data)\n                response.raise_for_status()\n                break\n            except Exception as e:\n                if i == 4:\n                    print(f\"An error occurred: {e}\")\n                    return None\n                time.sleep(2 ** i)\n        else:\n            return None\n\n        # Process the response\n        response_json = response.json()\n        response_text = response_json[\"choices\"][0][\"text\"]\n\n        # Remove the parsing helper tokens\n        response_text = self.remove_helper_tokens(response_text, model.parse_helper_token)\n\n        return response_text\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        # Validate the parameters\n        self.check_api_key()\n        self.validate_parameters(kwargs, LLM_GENERATION_PARAMETERS)\n\n        # Make the request\n        response = None\n        for retry in range(5):\n            try:\n                response = self.client.engines.generate(\n                    engine=model.model_name,\n                    prompt=system_message + \"\\n\" + prompt,\n                    **kwargs\n                )\n                break\n            except Exception as e:\n                logging.warning(f\"An error occurred: {e}\")\n                logging.warning(f\"Retrying in {2 ** retry} seconds...\")\n                time.sleep(2 ** retry)\n\n        # Process the response\n        if response is not None:\n            return response.choices[0].text.replace(model.start_token, \"\").replace(model.end_token, \"\")\n        else:\n            return None\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        # Check API key\n        self.check_api_key()\n\n        # Validate parameters\n        self.validate_parameters(**kwargs)\n\n        # Retry generation up to 5 times with exponential backoff\n        for i in range(5):\n            try:\n                # Make generation request\n                response = self.client.engines.generate(\n                    engine=model.model_name,\n                    prompt=system_message + \"\\n\" + prompt,\n                    **kwargs\n                )\n                assert response.object == \"list\"\n                assert len(response.data) == 1\n                assert response.data[0].object == \"generate_response\"\n                assert len(response.data[0].choices) == 1\n                assert response.data[0].choices[0].object == \"choice\"\n                assert response.data[0].choices[0].text is not None\n\n                # Remove any parsing helper tokens\n                text = response.data[0].choices[0].text\n                text = text.replace(model.parse_helper_token, \"\")\n\n                # Return text\n                return text\n\n            except Exception as e:\n                print(f\"An error occurred: {e}\")\n                time.sleep(2 ** i)\n\n        return None\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        # Verify that the API key is set\n        self.check_api_key()\n\n        # Verify that the model is configured correctly\n        self.check_model(model)\n\n        # Validate the additional parameters\n        self.check_parameters(**kwargs)\n\n        # Retry generation on failure\n        for i in range(5):\n            try:\n                response = self.client.engines.generate(\n                    engine=model.model_name,\n                    prompt=system_message + \"\\n\" + prompt,\n                    **kwargs\n                )\n                assert response.object == \"list\"\n                assert len(response.data) == 1\n                assert response.data[0].object == \"generate_response\"\n                assert response.data[0].choices[0].object == \"completion\"\n                response_text = response.data[0].choices[0].text\n                # Remove any parsing helper tokens\n                response_text = self.remove_helper_tokens(response_text, model)\n                return response_text\n            except Exception as e:\n                print(f\"An error occurred: {e}\")\n                print(f\"Retrying in {2**i} seconds...\")\n                time.sleep(2**i)\n        return None\n\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # Set the default parameters\n        params = {\n            \"temperature\": 0.7,\n            \"top_p\": 1.0,\n            \"frequency_penalty\": 0.6,\n            \"presence_penalty\": 0.0,\n            \"max_new_tokens\": 100\n        }\n\n        # Add the parameters to the dictionary\n        for param in LLM_GENERATION_PARAMETERS:\n            if param in kwargs:\n                params[param] = kwargs[param]\n\n        # Create the payload for the request\n        payload = {\n            \"prompt\": system_message + \"\\n\" + prompt,\n            \"echo\": \"true\",\n            \"frequency_penalty\": params[\"frequency_penalty\"],\n            \"presence_penalty\": params[\"presence_penalty\"],\n            \"max_new_tokens\": params[\"max_new_tokens\"],\n            \"temperature\": params[\"temperature\"],\n            \"top_p\": params[\"top_p\"],\n            \"stop\": model.stop_token\n        }\n\n        # Create the headers for the request\n        headers = {\n            \"Authorization\": \"Bearer \" + self.api_key,\n            \"Content-Type\": \"application/json\"\n        }\n\n        # Create the request\n        r = requests.post(OPENAI_URL, json=payload, headers=headers)\n\n        # If the request was successful, return the response\n        if r.status_code == 200:\n            return r.json()[\"choices\"][0][\"text\"].replace(model.stop_token, \"\")\n        else:\n            # If the request was not successful, log the error code and message\n            logging.error(f\"Error {r.status_code}: {r.json()['error']}\")\n\n            # If the error code was 429, sleep for the specified time and try again\n            if r.status_code == 429:\n                time.sleep(2 ** (kwargs[\"retries\"] + 1))\n                return self"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        # Verify that the API key is set\n        self.check_api_key()\n\n        # Verify that the model is set\n        if model is None:\n            raise ValueError(\"Model not set\")\n\n        # Verify that the system message is set\n        if system_message is None:\n            raise ValueError(\"System message not set\")\n\n        # Verify that the prompt is set\n        if prompt is None:\n            raise ValueError(\"Prompt not set\")\n\n        # Verify that the parameters are valid\n        self.validate_parameters(model, system_message, prompt, **kwargs)\n\n        # Create the request parameters\n        request_parameters = self.create_request_parameters(model, system_message, prompt, **kwargs)\n\n        # Create the backoff parameters\n        backoff_parameters = self.create_backoff_parameters(model)\n\n        # Retry generation on failure up to 5 times with exponential backoff\n        for retry_number in range(0, 5):\n            try:\n                # Make the request\n                response = self.client.completions.create(**request_parameters)\n                assert response.object == \"list\"\n                assert len(response.data) == 1\n                assert response.data[0].object == \"completion\"\n\n                # Process the response\n                text = response.data[0].completion\n                text = self.process_response(text, model)\n\n                return text\n\n            except Exception as e:\n                logging.error(e)\n\n                # Increase the backoff delay\n                backoff_parameters[\"backoff_delay\"] = backoff_parameters[\"backoff_delay\"] * 2\n\n                # Raise an exception if the backoff delay exceeds 16 seconds\n                if backoff_parameters[\"backoff_delay\"] > 16:\n                    raise Exception(f\"Maximum backoff attempts exceeded: {backoff_parameters['backoff_delay']} seconds\")\n\n                # Sleep the thread for the backoff delay\n                time.sleep(backoff_parameters[\"backoff_delay\"])\n\n        # If the request fails after 5 attempts,"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n        # validate parameters\n        for param in LLM_GENERATION_PARAMETERS:\n            if param in kwargs:\n                if kwargs[param] < 0:\n                    raise ValueError(f\"{param} must be greater than 0\")\n\n        # set up retry count and exponential backoff\n        retry_count = 0\n        max_retries = 5\n        retry_delay = 1\n\n        # get the generation parameters from the model\n        generation_parameters = copy.deepcopy(model.generation_parameters)\n        generation_parameters.update(kwargs)\n\n        # generate text\n        while retry_count < max_retries:\n            try:\n                response = self.client.engines.generate_text(\n                    engine=model.model_name,\n                    prompt=system_message + \"\\n\" + prompt,\n                    **generation_parameters\n                )\n                assert response.object == \"list\"\n                assert len(response.data) == 1\n                assert response.data[0].object == \"text\"\n                text = response.data[0].text\n                return self.remove_parsing_tokens(text)\n            except Exception as e:\n                print(f\"An error occurred: {e}\")\n                retry_count += 1\n                time.sleep(retry_delay)\n                retry_delay *= 2\n        return None\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if np.any(x != x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    if x.ndim != 2:\n        raise ValueError(\"The matrix must be 2-dimensional\")\n    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    # Check if the matrix is square\n    assert_is_square(x)\n    # Check if the matrix is symmetric\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")\n    if np.allclose(x, x.T) == False:\n        raise ValueError(\"The matrix is not symmetric\")\n\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    if not x.ndim == 2:\n        raise ValueError(\"The matrix must be 2-dimensional\")\n\n    if not x.shape[0] == x.shape[1]:\n        raise ValueError(\"The matrix must be square\")\n\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    # Check if the matrix is square\n    assert_is_square(x)\n\n    # Check if the matrix is symmetric\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    # Check if the matrix is square\n    assert_is_square(x)\n\n    # Check if the matrix is symmetric\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if np.array_equal(x, x.T) == False:\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")\n\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    # Verify if the matrix is square.\n    assert_is_square(x)\n\n    # Check if the matrix is symmetric.\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), np.zeros(x.shape[0])):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), np.zeros(x.shape[0])):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The diagonal elements must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    if not isinstance(x, np.ndarray):\n        raise ValueError(\"The given matrix is not a numpy ndarray\")\n\n    if x.ndim != 2:\n        raise ValueError(\"The given matrix is not a 2-dimensional matrix\")\n\n    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The given matrix is not a square matrix\")\n\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The given matrix is not symmetric\")\n\n    if not np.allclose(np.diag(x), 0.0):\n        raise ValueError(\"The given matrix is not a distance matrix\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), np.zeros(x.shape[0])):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The matrix must have zero elements along the diagonal\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The matrix diagonal elements must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The matrix diagonal must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n    if not np.allclose(np.diag(x), np.zeros(x.shape[0]), rtol=1e-5, atol=1e-8):\n        raise ValueError(\"The diagonal elements must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n\n    # Check if the matrix is symmetric\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n    # Check if the diagonal elements are close to zero\n    if not np.allclose(np.diag(x), np.zeros(x.shape[0])):\n        raise ValueError(\"The diagonal elements must be close to zero\")\n\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # get the current function setup\n        current_function_setup = self.initialized_functions.get(func_hash, None)\n\n        # initialize the function if not already done\n        if not current_function_setup:\n            self.initialized_functions[func_hash] = {}\n            self.initialized_functions[func_hash][\"model\"] = \"\"\n            self.initialized_functions[func_hash][\"examples\"] = []\n            self.initialized_functions[func_hash][\"is_distilled_model\"] = False\n\n        # get the current function setup\n        current_function_setup = self.initialized_functions.get(func_hash, None)\n\n        # get the current function setup\n        current_function_setup = self.initialized_functions.get(func_hash, None)\n\n        # initialize the function if not already done\n        if not current_function_setup:\n            self.initialized_functions[func_hash] = {}\n            self.initialized_functions[func_hash][\"model\"] = \"\"\n            self.initialized_functions[func_hash][\"examples\"] = []\n            self.initialized_functions[func_hash][\"is_distilled_model\"] = False\n\n        # get the current function setup\n        current_function_setup = self.initialized_functions.get(func_hash, None)\n\n        # initialize the function if not already done\n        if not current_function_setup:\n            self.initialized_functions[func_hash] = {}\n            self.initialized_functions[func_hash][\"model\"] = \"\"\n            self.initialized_functions[func_hash][\"examples\"] = []\n            self.initialized_functions[func_hash][\"is_distilled_model\"] = False\n\n        # get the current function setup\n        current_function_setup = self.initialized_functions.get(func_hash, None)\n\n        # initialize the function if not already done\n        if not current_function_setup:\n            self.initialized_functions[func_hash] = {}\n            self.initialized_functions[func_hash][\"model\"] = \"\""}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # get the model and prompt\n        prompt, model, save_to_finetune, is_distilled_model = self._get_generation_case(args, kwargs, function_description, llm_parameters)\n\n        # initialize the function if necessary\n        if func_hash not in self.initialized_functions:\n            self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": []}\n\n        # if the model is not a distilled model, save the generated examples for fine-tuning\n        if not is_distilled_model:\n            self.initialized_functions[func_hash][\"examples\"].append(prompt)\n\n        return prompt, model, save_to_finetune, is_distilled_model\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # get the model and prompt\n        if func_hash not in self.initialized_functions:\n            # initialize the function\n            self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": []}\n            self.token_counts[func_hash] = 0\n\n        # get the model\n        model = self.get_model(function_description)\n\n        # get the prompt\n        prompt = self.get_prompt(args, kwargs, function_description)\n\n        # check if the model is distilled\n        is_distilled_model = model.distilled\n\n        # check if the model is suitable for distillation\n        suitable_for_distillation = model.suitable_for_distillation\n\n        # check if the model is suitable for fine-tuning\n        suitable_for_finetuning = model.suitable_for_finetuning\n\n        # check if the model is suitable for fine-tuning\n        suitable_for_finetuning = model.suitable_for_finetuning\n\n        # check if the model is suitable for fine-tuning\n        suitable_for_finetuning = model.suitable_for_finetuning\n\n        # check if the model is suitable for fine-tuning\n        suitable_for_finetuning = model.suitable_for_finetuning\n\n        # check if the model is suitable for fine-tuning\n        suitable_for_finetuning = model.suitable_for_finetuning\n\n        # check if the model is suitable for fine-tuning\n        suitable_for_finetuning = model.suitable_for_finetuning\n\n        # check if the model is suitable for fine-tuning\n        suitable_for_finetuning = model.suitable_for_finetuning\n\n        # check if the model is suitable for fine-tuning\n        suitable_for_finetuning = model.suitable_for_finetuning\n\n        # check if the model is suitable for fine-tuning\n        suitable_for_finetuning = model.suitable_for_finetuning\n\n        # check if the model is suitable for"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # get the model type\n        model_type = self.function_modeler.get_model_type(function_description)\n\n        # get the model\n        model = self.function_modeler.get_model(model_type)\n\n        # get the prompt\n        prompt = self.function_modeler.get_prompt(args, kwargs, function_description, model_type)\n\n        # get the examples\n        examples = self.function_modeler.get_examples(args, kwargs, function_description)\n\n        # check if the model is suitable for distillation\n        is_distilled_model = self.function_modeler.is_distilled_model(model_type)\n\n        # check if the model is suitable for fine-tuning\n        is_suitable_for_finetuning = self.function_modeler.is_suitable_for_finetuning(model_type)\n\n        # check if the model is suitable for distillation\n        is_suitable_for_distillation = self.function_modeler.is_suitable_for_distillation(model_type)\n\n        # check if the model is a distilled model\n        is_distilled_model = self.function_modeler.is_distilled_model(model_type)\n\n        # check if the model is a teacher model\n        is_teacher_model = self.function_modeler.is_teacher_model(model_type)\n\n        # check if the model is a teacher model\n        is_distilled_model = self.function_modeler.is_distilled_model(model_type)\n\n        # check if the model is a teacher model\n        is_teacher_model = self.function_modeler.is_teacher_model(model_type)\n\n        # check if the model is a teacher model\n        is_teacher_model = self.function_modeler.is_teacher_model(model_type)\n\n        # check if the model is a teacher model\n        is_teacher_model = self.function_modeler.is_teacher_model(model_type)"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # check if the function is already initialized\n        if func_hash not in self.initialized_functions:\n            # if not, initialize it\n            self.initialized_functions[func_hash] = {}\n            self.initialized_functions[func_hash][\"examples\"] = []\n            self.initialized_functions[func_hash][\"model\"] = \"\"\n        # check if the model is already selected\n        if \"model\" not in self.initialized_functions[func_hash]:\n            # if not, select the model\n            model = self.select_model(args, kwargs, function_description, llm_parameters)\n            self.initialized_functions[func_hash][\"model\"] = model.model_name\n        else:\n            # if it is, get the model\n            model = self.api_provider[self.initialized_functions[func_hash][\"model\"]]\n        # get the prompt\n        prompt = self.construct_prompt(args, kwargs, function_description)\n        # check if the model is suitable for distillation\n        is_distilled_model = model.is_distilled_model\n        # check if the model is suitable for fine-tuning\n        is_suitable_for_finetuning = model.is_suitable_for_finetuning\n        # check if the model is suitable for fine-tuning\n        is_suitable_for_finetuning = model.is_suitable_for_finetuning\n        # check if the model is suitable for fine-tuning\n        is_suitable_for_finetuning = model.is_suitable_for_finetuning\n        # check if the model is suitable for fine-tuning\n        is_suitable_for_finetuning = model.is_suitable_for_finetuning\n        # check if the model is suitable for fine-tuning\n        is_suitable_for_finetuning = model.is_suitable_for_finetuning\n        # check if the model is suitable for fine-tuning\n        is_suitable_for_finetuning = model.is_suitable_for_finetuning\n        #"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # get the function setup\n        function_setup = self.initialized_functions.get(func_hash, None)\n        # if the function is not initialized, initialize it\n        if not function_setup:\n            function_setup = {\"model\": \"\", \"examples\": []}\n            self.initialized_functions[func_hash] = function_setup\n        # get the model\n        model = self.get_model(function_description, function_setup, llm_parameters)\n        # get the prompt\n        prompt = self.construct_prompt(args, kwargs, function_description)\n        # check if the model is suitable for distillation\n        is_distilled_model = model.is_distilled_model\n        # check if the model is suitable for fine-tuning\n        save_to_finetune = model.is_suitable_for_finetuning\n        # check if the model is suitable for distillation\n        is_distilled_model = model.is_distilled_model\n        # check if the model is suitable for fine-tuning\n        save_to_finetune = model.is_suitable_for_finetuning\n        return prompt, model, save_to_finetune, is_distilled_model\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # check if the function is already initialized\n        initialized_function = self.initialized_functions.get(func_hash, None)\n        # if it is, check if the model is the same\n        if initialized_function:\n            if initialized_function[\"model\"] == function_description.model_type:\n                # if the model is the same, check if the token count is the same\n                if self.token_counts[func_hash] == self.get_token_count(args, kwargs, function_description):\n                    # if the token count is the same, generate the prompt\n                    prompt = self.construct_prompt(args, kwargs, function_description)\n                    return prompt, initialized_function[\"model\"], initialized_function[\"save_to_finetune\"], initialized_function[\"distilled_model\"]\n                else:\n                    # if the token count is not the same, update the examples and generate the prompt\n                    self.update_examples(args, kwargs, function_description, func_hash)\n                    prompt = self.construct_prompt(args, kwargs, function_description)\n                    return prompt, initialized_function[\"model\"], initialized_function[\"save_to_finetune\"], initialized_function[\"distilled_model\"]\n            else:\n                # if the model is not the same, update the examples and generate the prompt\n                self.update_examples(args, kwargs, function_description, func_hash)\n                prompt = self.construct_prompt(args, kwargs, function_description)\n                return prompt, function_description.model_type, False, False\n        else:\n            # if it is not, initialize the function\n            self.initialized_functions[func_hash] = {}\n            self.initialized_functions[func_hash][\"model\"] = function_description.model_type\n            self.initialized_functions[func_hash][\"save_to_finetune\"] = True\n            self.initialized_functions[func_hash][\"distilled_model\"] = False\n            self.initialized_functions[func_hash][\"examples\"] = []\n            self.token_counts[func_hash] = self"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # get the function setup\n        current_function_setup = self.initialized_functions.get(func_hash, None) # getting the current function setup - model and align statements\n        if current_function_setup:\n            model = current_function_setup[\"model\"]\n            examples = current_function_setup[\"examples\"]\n        else:\n            model = \"\"\n            examples = []\n            self.initialized_functions[func_hash] = {\"model\": model, \"examples\": examples}\n\n        # get the prompt\n        prompt = self._construct_prompt(args, kwargs, function_description)\n\n        # get the model\n        model_type = llm_parameters.get(\"model_type\", \"teacher\")\n        if model_type == \"teacher\":\n            model, save_to_finetune, is_distilled_model = self.get_teacher_model(function_description, model)\n        elif model_type == \"distilled\":\n            model, save_to_finetune, is_distilled_model = self.get_distilled_model(function_description, model)\n        else:\n            raise ValueError(f\"model_type must be 'teacher' or 'distilled', not {model_type}\")\n\n        # update examples if necessary\n        if save_to_finetune:\n            examples.append(prompt)\n\n        return prompt, model, save_to_finetune, is_distilled_model\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # get the model\n        model = self._get_model(function_description)\n\n        # get the prompt\n        prompt = self._get_prompt(args, kwargs, function_description)\n\n        # check if the model is suitable for distillation\n        is_distilled_model = model.is_distilled_model\n\n        # check if the model is suitable for fine-tuning\n        is_suitable_for_finetuning = model.is_suitable_for_finetuning\n\n        # get the examples for fine-tuning\n        examples = self._get_examples(args, kwargs, function_description, func_hash)\n\n        # check if the model is suitable for fine-tuning\n        if is_suitable_for_finetuning:\n            # get the examples for fine-tuning\n            examples = self._get_examples(args, kwargs, function_description, func_hash)\n\n            # check if the model is suitable for distillation\n            if is_distilled_model:\n                # if the model is suitable for distillation, check if the model has been initialized\n                if func_hash not in self.initialized_functions:\n                    # if the model has not been initialized, initialize it\n                    self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": examples}\n                else:\n                    # if the model has been initialized, check if the model has changed\n                    if self.initialized_functions[func_hash][\"model\"] != model.model_name:\n                        # if the model has changed, update the examples\n                        self.initialized_functions[func_hash] = {\"model\": model.model_name, \"examples\": examples}\n                    else:\n                        # if the model has not changed, update the examples\n                        self.initialized_functions[func_hash][\"examples\"] = examples\n            else:\n                # if the model is not suitable for distillation, update the examples\n                self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": examples}\n\n        # check if the model is suitable for distillation\n        if"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # check if the function is already initialized\n        if func_hash not in self.initialized_functions:\n            # if not, initialize the function\n            self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": []}\n\n        # get the examples for the function\n        examples = self.initialized_functions[func_hash][\"examples\"]\n        # get the model for the function\n        model = self.initialized_functions[func_hash][\"model\"]\n\n        # get the prompt for the function\n        prompt = self.construct_prompt(args, kwargs, function_description)\n\n        # get the token count for the function\n        token_count = self.get_token_count(args, kwargs, function_description)\n\n        # check if the model is already selected\n        if model == \"\":\n            # if not, select the model\n            model = self.select_model(token_count, examples, function_description)\n\n        # check if the model is suitable for distillation\n        is_distilled_model = self.is_distilled_model(model)\n\n        # check if the model is suitable for fine-tuning\n        suitable_for_finetuning = self.is_suitable_for_finetuning(model, token_count, examples)\n\n        # check if the model is suitable for distillation\n        # if not, select the model\n        # if not, select the model\n        # check if the model is suitable for distillation\n        # if not, select the model\n        # check if the model is suitable for distillation\n        # if not, select the model\n        # check if the model is suitable for distillation\n        # if not, select the model\n        # check if the model is suitable for distillation\n        # if not, select the model\n        # check if the model is suitable for distillation\n        # if not, select the model\n        # check if the model is suitable for distillation\n        # if not, select the model\n        # check if the model is suitable for distillation\n        # if not, select the model\n        # check if the model is suitable for"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # check if the function is already initialized\n        initialized_functions = self.initialized_functions.get(func_hash, None)\n        if initialized_functions:\n            # check if the function is already initialized with the same model\n            if initialized_functions[\"model\"] == llm_parameters[\"model\"]:\n                # if so, use the model and prompt\n                model = llm_parameters[\"model\"]\n                prompt = self.construct_prompt(args, kwargs, function_description, llm_parameters)\n                # check if the model is distilled\n                is_distilled_model = initialized_functions[\"is_distilled_model\"]\n                # check if the model is suitable for distillation\n                suitable_for_distillation = self.is_suitable_for_distillation(args, kwargs, function_description, llm_parameters)\n                # check if the model is suitable for finetuning\n                suitable_for_finetuning = self.is_suitable_for_finetuning(args, kwargs, function_description, llm_parameters)\n                # check if the model is suitable for finetuning\n                save_to_finetune = suitable_for_finetuning and not suitable_for_distillation\n                return prompt, model, save_to_finetune, is_distilled_model\n            else:\n                # if not, generate a new model and prompt\n                model = llm_parameters[\"model\"]\n                prompt = self.construct_prompt(args, kwargs, function_description, llm_parameters)\n                is_distilled_model = False\n                save_to_finetune = self.is_suitable_for_finetuning(args, kwargs, function_description, llm_parameters)\n                return prompt, model, save_to_finetune, is_distilled_model\n        else:\n            # if not, initialize the function and generate a model and prompt\n            model = llm_parameters[\"model\"]\n            prompt = self.construct_prompt(args, kwargs, function_description, llm_parameters)\n            is_distilled_model = False\n            save_to_fin"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Get the model\n        model = self.get_model(function_description, llm_parameters)\n\n        # Get the prompt\n        prompt = self.get_prompt(args, kwargs, function_description)\n\n        # Get the examples\n        examples = self.get_examples(function_description, func_hash)\n\n        # Get the examples\n        examples = self.get_examples(function_description, func_hash)\n\n        # Check if the model is suitable for distillation\n        distillation_model = model.distillation_model\n\n        # Check if the model is suitable for finetuning\n        save_to_finetune = model.save_to_finetune\n\n        # Check if the function is already initialized\n        initialized = func_hash in self.initialized_functions\n\n        return prompt, model, save_to_finetune, initialized\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Get the model and prompt\n        model = self._get_model(function_description, llm_parameters)\n        prompt = self._construct_prompt(args, kwargs, function_description)\n\n        # Get the generation case\n        save_to_finetune, is_distilled_model = self._get_generation_case_params(function_description, model, llm_parameters)\n\n        # Initialize the function if necessary\n        self._initialize_function(args, kwargs, function_description, model, save_to_finetune, is_distilled_model, llm_parameters, func_hash)\n\n        return prompt, model, save_to_finetune, is_distilled_model\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # get the model\n        model_name = function_description.model_name\n        if model_name not in self.api_provider:\n            model_name = \"gpt2\"\n\n        # get the model type\n        model_type = self.api_provider[model_name].model_type\n\n        # get the model\n        model = self.api_provider[model_name].get_model(model_type, llm_parameters)\n\n        # get the prompt\n        prompt = self.api_provider[model_name].construct_prompt(args, kwargs, function_description)\n\n        # get the examples\n        examples = self.api_provider[model_name].get_examples(args, kwargs, function_description)\n\n        # get the examples for fine-tuning\n        examples_for_finetune = self.api_provider[model_name].get_examples_for_finetuning(args, kwargs, function_description)\n\n        # get the examples for distillation\n        examples_for_distillation = self.api_provider[model_name].get_examples_for_distillation(args, kwargs, function_description)\n\n        # check if we need to save examples for fine-tuning\n        save_to_finetune = False\n        if len(examples_for_finetune) > 0:\n            save_to_finetune = True\n\n        # check if we need to save examples for distillation\n        distill_model = False\n        if len(examples_for_distillation) > 0:\n            distill_model = True\n\n        # check if we need to initialize the function\n        initialize_function = False\n        if func_hash not in self.initialized_functions:\n            initialize_function = True\n\n        # check if we need to update the examples for fine-tuning\n        update_examples = False\n        if initialize_function:\n            update_examples = True\n        elif func_hash in self.initialized_functions:\n            if len(examples) > len(self.initialized_functions[func_hash][\"examples\"]):\n                update_"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # check if the function is already initialized\n        if func_hash not in self.initialized_functions:\n            # if not, initialize the function\n            self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": []}\n\n        # get the number of tokens in the prompt\n        prompt_token_count = approximate_token_count(function_description.name, args, kwargs)\n\n        # check if the prompt is already in the examples\n        prompt_already_in_examples = False\n        for example in self.initialized_functions[func_hash][\"examples\"]:\n            if example.args == args and example.kwargs == kwargs:\n                prompt_already_in_examples = True\n                break\n\n        # if the prompt is already in the examples, use the model for fine-tuning\n        if prompt_already_in_examples:\n            model = self.api_provider[\"finetune\"].model_type\n            save_to_finetune = True\n            is_distilled_model = False\n            prompt = self._construct_prompt(function_description.name, args, kwargs)\n            return prompt, model, save_to_finetune, is_distilled_model\n\n        # otherwise, check if the prompt is suitable for distillation\n        prompt_suitable_for_distillation = False\n        if prompt_token_count <= self.api_provider[\"distill\"].token_limit:\n            prompt_suitable_for_distillation = True\n\n        # if the prompt is suitable for distillation, use the distill model for generation\n        if prompt_suitable_for_distillation:\n            model = self.api_provider[\"distill\"].model_type\n            save_to_finetune = False\n            is_distilled_model = True\n            prompt = self._construct_prompt(function_description.name, args, kwargs)\n            return prompt, model, save_to_finetune, is_distilled_model\n\n        # otherwise, use the teacher model for generation\n        model = self.api_provider[\"finetune\"].model_type\n        save_to"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # get the model and the prompt\n        prompt = self.construct_prompt(args, kwargs, function_description)\n        model = self.get_model(function_description)\n        save_to_finetune = True\n        is_distilled_model = False\n        # check if the function is already initialized\n        initialized_function = self.initialized_functions.get(func_hash, None)\n        if initialized_function:\n            # if it is, check if we need to update the examples\n            if initialized_function[\"model\"] == model.model_name:\n                if initialized_function[\"examples\"]:\n                    if initialized_function[\"examples\"][-1].generated_response == prompt:\n                        save_to_finetune = False\n                        is_distilled_model = True\n                else:\n                    save_to_finetune = False\n                    is_distilled_model = True\n            else:\n                self.initialized_functions[func_hash] = {\"model\": model.model_name, \"examples\": []}\n        else:\n            # if it is not, initialize it\n            self.initialized_functions[func_hash] = {\"model\": model.model_name, \"examples\": []}\n\n        return prompt, model, save_to_finetune, is_distilled_model\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # check if the function is already initialized\n        if func_hash not in self.initialized_functions:\n            # initialize the function\n            self.initialized_functions[func_hash] = {\n                \"model\": \"\",\n                \"examples\": []\n            }\n            self.token_counts[func_hash] = 0\n\n        # get the model to use\n        model = self.get_model_to_use(function_description, llm_parameters)\n\n        # get the prompt to use\n        prompt = self.get_prompt_to_use(args, kwargs, function_description, model)\n\n        # check if the model is suitable for distillation\n        is_distilled_model = model.model_name in [\"distilgpt2\", \"distilbart\"]\n\n        # check if the model is suitable for fine-tuning\n        save_to_finetune = self.check_model_suitability(model, self.token_counts[func_hash])\n\n        return prompt, model, save_to_finetune, is_distilled_model\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Get the model and prompt\n        model = self.get_model(function_description, llm_parameters)\n        prompt = self.get_prompt(args, kwargs, function_description)\n        # Get the distillation and fine-tuning cases\n        is_distilled_model = model.is_distilled_model\n        save_to_finetune = False\n        if not self.initialized_functions.get(func_hash, None):\n            # If the function is not initialized, initialize it and save the examples\n            self.initialized_functions[func_hash] = {\n                \"model\": \"\",\n                \"examples\": []\n            }\n            save_to_finetune = True\n        elif self.initialized_functions[func_hash][\"model\"] == \"\":\n            # If the function is initialized but no model is selected, select a model and save the examples\n            self.initialized_functions[func_hash][\"model\"] = model.model_name\n            save_to_finetune = True\n        elif self.initialized_functions[func_hash][\"model\"] != model.model_name:\n            # If the function is initialized but a different model is selected, select a model and save the examples\n            self.initialized_functions[func_hash][\"model\"] = model.model_name\n            save_to_finetune = True\n        return prompt, model, save_to_finetune, is_distilled_model\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # check if the function is already initialized\n        if func_hash not in self.initialized_functions:\n            # if not, initialize the function\n            self.initialized_functions[func_hash] = {\n                \"model\": \"\",\n                \"examples\": []\n            }\n\n        # get the model type for the function\n        model_type = self.function_modeler.get_model_type(function_description)\n        # get the model for the function\n        model = self.function_modeler.get_model(model_type)\n        # get the prompt for the function\n        prompt = self.function_modeler.get_prompt(function_description, args, kwargs)\n        # get the token count for the function\n        token_count = self.function_modeler.get_token_count(function_description, args, kwargs)\n        # get the examples for the function\n        examples = self.function_modeler.get_examples(function_description, args, kwargs)\n        # check if the function is suitable for distillation\n        distilled_model = self.function_modeler.is_distilled_model(model_type)\n        # check if the function is suitable for fine-tuning\n        suitable_for_finetuning = self.function_modeler.is_suitable_for_finetuning(function_description,\n                                                                                   model_type)\n        # check if the function is already initialized\n        if func_hash not in self.initialized_functions:\n            # if not, initialize the function\n            self.initialized_functions[func_hash] = {\n                \"model\": \"\",\n                \"examples\": []\n            }\n        # if the function is already initialized, check if the model is the same\n        elif self.initialized_functions[func_hash][\"model\"] != model.model_name:\n            # if not, update the examples\n            self.initialized_functions[func_hash][\"model\"] = model.model_name\n            self.initialized_functions[func_hash][\"examples\"] = examples\n\n        # check if the token count is too high\n        if token_count >"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # if the function is already initialized, use the model from the initialized function\n        if func_hash in self.initialized_functions:\n            current_function_setup = self.initialized_functions[func_hash]\n            # if the model is a distilled model, use that\n            if current_function_setup[\"model\"] == \"\":\n                model = current_function_setup[\"distilled_model\"]\n                is_distilled_model = True\n            else:\n                model = current_function_setup[\"model\"]\n                is_distilled_model = False\n            # if the model is not a distilled model, use the model from the initialized function\n            return self.construct_prompt(args, kwargs, function_description, model, llm_parameters), model, False, is_distilled_model\n\n        # otherwise, get the model and prompt\n        else:\n            model, is_distilled_model = self.get_model(function_description, llm_parameters)\n            prompt = self.construct_prompt(args, kwargs, function_description, model, llm_parameters)\n            # if the model is a distilled model, use that\n            if is_distilled_model:\n                self.initialized_functions[func_hash] = {\"model\": \"\", \"distilled_model\": model}\n            # if the model is not a distilled model, use the model from the initialized function\n            else:\n                self.initialized_functions[func_hash] = {\"model\": model, \"distilled_model\": \"\"}\n            return prompt, model, True, is_distilled_model\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        return _cov_nearest_higham(cov, higham_max_iteration)\n    else:\n        return _cov_nearest_clip(cov)\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        return _cov_nearest_higham(cov, higham_max_iteration)\n    else:\n        return _cov_nearest_clip(cov)\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if cov.ndim != 2:\n        raise ValueError(f\"`cov` must be a 2D array, got a {cov.ndim}D array\")\n    if higham:\n        return _higham_cov_nearest(cov, max_iteration=higham_max_iteration)\n    else:\n        return _clip_cov_nearest(cov)\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        return _cov_nearest_higham(cov, higham_max_iteration)\n    else:\n        return _cov_nearest_clip(cov)\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        return _cov_nearest_higham(cov, higham_max_iteration)\n    else:\n        return _cov_nearest_clip(cov)\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        return _cov_nearest_higham(cov, higham_max_iteration)\n    else:\n        return _cov_nearest_clip(cov)\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    assert_is_symmetric(cov)\n\n    if higham:\n        return _higham_cov(cov, higham_max_iteration)\n    else:\n        return _clip_cov(cov)\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        return _higham(cov, higham_max_iteration)\n    else:\n        return _clip(cov)\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    assert_is_square(cov)\n    assert_is_symmetric(cov)\n    assert_is_distance(cov)\n    if higham:\n        cov_pd = _cov_nearest_higham(cov, max_iteration=higham_max_iteration)\n    else:\n        cov_pd = _cov_nearest_clip(cov)\n    return cov_pd\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        return _cov_nearest_higham(cov, higham_max_iteration)\n    else:\n        return _cov_nearest_clip(cov)\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        return _cov_nearest_higham(cov, higham_max_iteration)\n    else:\n        return _cov_nearest_clip(cov)\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        return _cov_nearest_higham(cov, higham_max_iteration)\n    else:\n        return _cov_nearest_clip(cov)\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    # Check if the input matrix is positive definite\n    if not is_positive_definite(cov):\n        # If not, raise an error\n        raise ValueError(\"The input matrix is not positive definite.\")\n\n    # Check if the input matrix is symmetric\n    if not is_symmetric(cov):\n        # If not, raise an error\n        raise ValueError(\"The input matrix is not symmetric.\")\n\n    # Check if the input matrix is a covariance matrix\n    if not is_covariance(cov):\n        # If not, raise an error\n        raise ValueError(\"The input matrix is not a covariance matrix.\")\n\n    # Check if the input matrix is a correlation matrix\n    if is_correlation(cov):\n        # If it is, return it\n        return cov\n\n    # If the Higham & Nick (2002) algorithm is used, set the variable to True\n    if higham:\n        # Set the maximum number of iterations\n        max_iteration = higham_max_iteration\n\n    # Get the eigenvalues and eigenvectors of the input matrix\n    eig_vals, eig_vecs = np.linalg.eigh(cov)\n\n    # If the Higham & Nick (2002) algorithm is used, set the variable to True\n    if higham:\n        # Set the variable to False\n        iteration = False\n\n    # For each eigenvalue\n    for i in range(len(eig_vals)):\n        # If the Higham & Nick (2002) algorithm is used\n        if higham:\n            # If the variable is True\n            if iteration:\n                # If the current eigenvalue is less than the clipping value\n                if eig_vals[i] < _CLIPPING_VALUE:\n                    # Set the current eigenvalue to the clipping value\n                    eig_vals[i] = _CLIPPING_VALUE\n\n            # If the current eigenvalue is greater than the clipping value\n            if eig_vals[i] > _CLIPPING_VALUE:\n                # Set the variable to True\n                iteration = True\n\n        # If the Higham & Nick ("}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    # Check if the input covariance matrix is positive definite.\n    if not is_positive_definite(cov):\n        # If it is not, raise an error.\n        raise ValueError(\"The input covariance matrix is not positive definite.\")\n\n    # If the Higham & Nick (2002) algorithm is not used, clip the eigenvalues.\n    if not higham:\n        # Compute the eigendecomposition of the covariance matrix.\n        eig_decomp = np.linalg.eigh(cov)\n        # Clip the eigenvalues.\n        eig_decomp[0] = np.clip(eig_decomp[0], _CLIPPING_VALUE, None)\n        # Return the covariance matrix.\n        return eig_decomp[1] @ np.diag(eig_decomp[0] ** 0.5) @ eig_decomp[1].T\n\n    # If the Higham & Nick (2002) algorithm is used, compute the eigendecomposition of the covariance matrix.\n    eig_decomp = np.linalg.eigh(cov)\n    # Initialize the number of iterations.\n    iteration = 0\n    # Initialize the change in the covariance matrix.\n    delta_cov = np.inf\n    # Initialize the covariance matrix.\n    cov_new = cov\n    # Initialize the maximum number of iterations.\n    max_iteration = higham_max_iteration\n    # While the maximum number of iterations has not been reached and the change in the covariance matrix is larger than the specified tolerance, repeat the following steps:\n    while iteration < max_iteration and delta_cov > _CLIPPING_VALUE:\n        # Compute the eigendecomposition of the covariance matrix.\n        eig_decomp = np.linalg.eigh(cov_new)\n        # Clip the eigenvalues.\n        eig_decomp[0] = np.clip(eig_decomp[0], _CLIPPING_VALUE, None)\n        # Compute the covariance matrix.\n        cov_new = eig_decomp[1] @"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    # Check the input\n    assert_is_symmetric(cov)\n    assert cov.shape[0] == cov.shape[1]\n\n    # Compute the eigenvalue decomposition of the covariance matrix\n    e_vals, e_vecs = np.linalg.eigh(cov)\n\n    # Compute the nearest covariance matrix that is positive definite and allows for a Cholesky decomposition\n    if higham:\n        # Use the Higham & Nick (2002) algorithm\n        e_vals = np.maximum(e_vals, _CLIPPING_VALUE)\n        e_vals = np.minimum(e_vals, 1 - _CLIPPING_VALUE)\n        cov = np.dot(e_vecs, np.dot(np.diag(e_vals), e_vecs.T))\n        for i in range(higham_max_iteration):\n            try:\n                np.linalg.cholesky(cov)\n                break\n            except np.linalg.LinAlgError:\n                e_vals = np.maximum(e_vals, _CLIPPING_VALUE)\n                e_vals = np.minimum(e_vals, 1 - _CLIPPING_VALUE)\n                cov = np.dot(e_vecs, np.dot(np.diag(e_vals), e_vecs.T))\n    else:\n        # Clip the eigenvalues\n        e_vals = np.maximum(e_vals, _CLIPPING_VALUE)\n        e_vals = np.minimum(e_vals, 1 - _CLIPPING_VALUE)\n        cov = np.dot(e_vecs, np.dot(np.diag(e_vals), e_vecs.T))\n\n    return cov\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    # Make sure the input is a square matrix\n    if cov.ndim != 2 or cov.shape[0] != cov.shape[1]:\n        raise ValueError(f\"`cov` must be a square matrix, got a {cov.shape} matrix\")\n\n    # Make sure the input matrix is symmetric\n    if not np.allclose(cov, cov.T):\n        raise ValueError(f\"`cov` must be symmetric, got a {cov} matrix\")\n\n    # Make sure the input matrix is not singular\n    if np.linalg.matrix_rank(cov) != cov.shape[0]:\n        raise ValueError(f\"`cov` must be full rank, got a {cov} matrix\")\n\n    # Make sure the input matrix is positive semidefinite\n    if not np.all(np.linalg.eigvals(cov) >= 0):\n        raise ValueError(f\"`cov` must be positive semidefinite, got a {cov} matrix\")\n\n    # Make sure the input matrix is not already positive definite\n    if is_positive_definite(cov):\n        return cov\n\n    # Compute the eigendecomposition of the input matrix\n    eigvals, eigvecs = np.linalg.eigh(cov)\n\n    # Compute the square root of the input matrix\n    sqrt_cov = eigvecs @ np.diag(np.sqrt(eigvals)) @ eigvecs.T\n\n    # Compute the nearest positive definite matrix\n    if higham:\n        sqrt_cov = _higham_nearest_positive_definite(sqrt_cov, higham_max_iteration)\n    else:\n        sqrt_cov = _clip_eigenvalues(sqrt_cov)\n\n    # Compute the nearest covariance matrix\n    nearest_cov = sqrt_cov @ sqrt_cov.T\n\n    return nearest_cov\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    # Check input arguments\n    if higham:\n        if higham_max_iteration <= 0:\n            raise ValueError(\"`higham_max_iteration` must be a positive integer.\")\n        if cov.ndim != 2:\n            raise ValueError(\"`cov` must be a 2D array.\")\n        if cov.shape[0] != cov.shape[1]:\n            raise ValueError(\"`cov` must be a square matrix.\")\n\n    # Compute the eigenvalues and eigenvectors of the input covariance matrix\n    w, v = np.linalg.eigh(cov)\n\n    # Compute the diagonal matrix of the eigenvalues\n    w_diag = np.diag(w)\n\n    # If the Higham & Nick (2002) algorithm is used, repeat until convergence\n    if higham:\n\n        # Initialize the iteration counter\n        iteration = 0\n\n        # Initialize the difference between the previous and current covariance matrices\n        diff = np.inf\n\n        # Initialize the previous covariance matrix\n        prev_cov = cov\n\n        # Repeat until convergence\n        while iteration < higham_max_iteration and diff > _CLIPPING_VALUE:\n\n            # Compute the next covariance matrix\n            next_cov = v @ np.diag(np.clip(w, _CLIPPING_VALUE, np.inf)) @ v.T\n\n            # Compute the difference between the previous and current covariance matrices\n            diff = np.linalg.norm(next_cov - prev_cov)\n\n            # Update the previous covariance matrix\n            prev_cov = next_cov\n\n            # Update the iteration counter\n            iteration += 1\n\n        # Return the nearest positive definite covariance matrix\n        return next_cov\n\n    # Otherwise, clip the eigenvalues\n    else:\n\n        # Clip the eigenvalues\n        w = np.clip(w, _CLIPPING_VALUE, np.inf)\n\n        # Return the nearest positive definite covariance matrix\n        return v @ w_diag @ v.T\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    # Compute the eigendecomposition of the covariance matrix.\n    eig_vals, eig_vecs = np.linalg.eigh(cov)\n\n    # If the Higham & Nick (2002) algorithm is used, compute the number of iterations.\n    if higham:\n        iteration = higham_max_iteration\n    else:\n        iteration = 1\n\n    # For each iteration, adjust the eigenvalues and recompute the covariance matrix.\n    for i in range(iteration):\n        # If the Higham & Nick (2002) algorithm is used, adjust the eigenvalues.\n        if higham:\n            # Compute the eigenvalues of the covariance matrix.\n            eig_vals_cov = np.diag(cov)\n            # Compute the eigenvalues of the correlation matrix.\n            eig_vals_corr = np.diag(np.corrcoef(np.ones((cov.shape[0], 1))))\n            # Compute the eigenvalues of the adjusted covariance matrix.\n            eig_vals_adj = (eig_vals_cov - eig_vals_corr) / 2\n            # Compute the adjusted eigenvalues.\n            eig_vals = eig_vals_adj\n        # Clip the eigenvalues.\n        else:\n            # Compute the eigenvalues of the adjusted covariance matrix.\n            eig_vals_adj = np.clip(eig_vals, _CLIPPING_VALUE, np.inf)\n            # Compute the adjusted eigenvalues.\n            eig_vals = eig_vals_adj\n        # Recompute the covariance matrix.\n        cov = eig_vecs @ np.diag(eig_vals) @ eig_vecs.T\n\n    return cov\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    # Ensure the input matrix is square\n    if cov.ndim != 2 or cov.shape[0] != cov.shape[1]:\n        raise ValueError(f\"`cov` must be a 2D square matrix, got a {cov.shape} matrix\")\n    # Ensure the input matrix is symmetric\n    if not np.allclose(cov, cov.T):\n        raise ValueError(f\"`cov` must be symmetric, got a non-symmetric matrix\")\n    # Ensure the input matrix is not singular\n    if np.linalg.matrix_rank(cov) != cov.shape[0]:\n        raise ValueError(f\"`cov` must not be singular, got a singular matrix\")\n\n    # Compute the eigendecomposition of the input matrix\n    eigvals, eigvecs = np.linalg.eigh(cov)\n\n    # If the Higham & Nick (2002) algorithm is used\n    if higham:\n        # Compute the eigendecomposition of the input matrix\n        eigvals, eigvecs = np.linalg.eigh(cov)\n        # Sort the eigenvalues in ascending order\n        eigvals_sorted = np.sort(eigvals)\n        # Reverse the sorted eigenvalues\n        eigvals_sorted = eigvals_sorted[::-1]\n        # Reverse the sorted eigenvectors\n        eigvecs_sorted = eigvecs[:, ::-1]\n        # Compute the number of eigenvalues to clip\n        num_eigvals_to_clip = np.count_nonzero(eigvals_sorted < _CLIPPING_VALUE)\n        # Compute the number of iterations\n        num_iterations = higham_max_iteration\n        # Initialize the clipped covariance matrix\n        cov_clipped = np.zeros_like(cov)\n        # Initialize the clipped eigenvalues\n        eigvals_clipped = np.zeros_like(eigvals)\n        # Initialize the clipped eigenvectors\n        eigvecs_clipped = np.zeros_like(eigvecs)\n\n        # Iterate over"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    # If the covariance matrix is already positive definite, return it.\n    if is_positive_definite(cov):\n        return cov\n\n    # Compute the eigenvalues and eigenvectors of the covariance matrix.\n    eig_vals, eig_vecs = np.linalg.eigh(cov)\n\n    # If the Higham & Nick (2002) algorithm is not used, clip the eigenvalues.\n    if not higham:\n        # Clip the negative eigenvalues.\n        eig_vals = np.clip(eig_vals, a_min=_CLIPPING_VALUE, a_max=None)\n        # Clip the negative eigenvalues in the subspace spanned by the eigenvectors with negative eigenvalues.\n        eig_vecs = np.clip(eig_vecs, a_min=0, a_max=None)\n\n    # If the Higham & Nick (2002) algorithm is used, compute the matrix that is positive definite and allows for a Cholesky decomposition.\n    if higham:\n        # Compute the inverse of the covariance matrix.\n        inv_cov = np.linalg.inv(cov)\n        # Compute the matrix that is positive definite and allows for a Cholesky decomposition.\n        mat_higham = np.matmul(np.matmul(eig_vecs, inv_cov), eig_vecs.T)\n        # Compute the nearest positive definite matrix.\n        nearest_cov = np.matmul(np.matmul(eig_vecs, mat_higham), eig_vecs.T)\n        # Compute the number of iterations used to compute the nearest positive definite matrix.\n        num_iterations = 0\n        # Compute the difference between the covariance matrix and the nearest positive definite matrix.\n        diff = cov - nearest_cov\n        # Compute the norm of the difference between the covariance matrix and the nearest positive definite matrix.\n        norm = np.linalg.norm(diff)\n        # While the norm is greater than the specified tolerance, compute the nearest positive definite matrix.\n        while norm > _CLIPPING_VALUE"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, torch.Tensor):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, collections.abc.Mapping):\n        return DictSchema.flatten(obj)\n    if isinstance(obj, collections.abc.Sequence):\n        return ListSchema.flatten(obj)\n    if isinstance(obj, (Boxes, RotatedBoxes, BitMasks)):\n        return TensorWrapSchema.flatten(obj)\n    if isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    if isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    raise ValueError(\"Unsupported type {}\".format(type(obj)))\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, torch.Tensor):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, collections.abc.Mapping):\n        return DictSchema.flatten(obj)\n    if isinstance(obj, collections.abc.Sequence):\n        return ListSchema.flatten(obj)\n    if isinstance(obj, tuple):\n        return TupleSchema.flatten(obj)\n    if isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    if isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    if isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    raise ValueError(f\"Unsupported type for autograd: {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, torch.Tensor):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, collections.abc.Mapping):\n        obj = dict(obj)\n        keys = sorted(obj.keys())\n        values = [obj[k] for k in keys]\n        return flatten_to_tuple(values)\n    if isinstance(obj, collections.abc.Sequence):\n        if isinstance(obj, (list, tuple)):\n            values = obj\n        else:\n            # treat other sequences (e.g. iterators) as lists\n            values = list(obj)\n        return ListSchema.flatten(values)\n    if isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    if isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    if isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    raise ValueError(f\"Unsupported type for autograd: {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    # TODO: add support for more types, e.g. masks\n    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, list):\n        values, schema = ListSchema.flatten(obj)\n        return values, ListSchema(schema.schemas, schema.sizes)\n    if isinstance(obj, tuple):\n        values, schema = TupleSchema.flatten(obj)\n        return values, TupleSchema(schema.schemas, schema.sizes)\n    if isinstance(obj, dict):\n        values, schema = DictSchema.flatten(obj)\n        return values, schema\n    if isinstance(obj, Instances):\n        values, schema = InstancesSchema.flatten(obj)\n        return values, schema\n    if isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    if isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    raise ValueError(f\"Do not know how to flatten type {type(obj)}!\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    # TODO: make this a registry\n    if isinstance(obj, torch.Tensor):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, collections.abc.Mapping):\n        return DictSchema.flatten(obj)\n    if isinstance(obj, collections.abc.Sequence):\n        return ListSchema.flatten(obj)\n    if isinstance(obj, (Boxes, RotatedBoxes, BitMasks)):\n        return TensorWrapSchema.flatten(obj)\n    if isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    if isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    raise ValueError(f\"Don't know how to flatten {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    # TODO: add support for more types\n    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, collections.abc.Mapping):\n        # TODO: can add support for other mappings\n        if isinstance(obj, dict):\n            return DictSchema.flatten(obj)\n        else:\n            raise NotImplementedError\n    elif isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    elif isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    elif isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    elif isinstance(obj, tuple):\n        schema_list = [flatten_to_tuple(v)[1] for v in obj]\n        values, schema = ListSchema.flatten([v[0] for v in obj])\n        return values + schema_list, TupleSchema(schema, schema_list)\n    elif isinstance(obj, list):\n        schema_list = [flatten_to_tuple(v)[1] for v in obj]\n        values, schema = ListSchema.flatten(obj)\n        return values + schema_list, ListSchema(schema, schema_list)\n    else:\n        return TensorWrapSchema.flatten(obj)\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    # TODO: add support for nested containers\n    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, collections.abc.Mapping):\n        if isinstance(obj, dict):\n            return DictSchema.flatten(obj)\n        else:\n            raise NotImplementedError(f\"Mapping type {type(obj)} is not supported yet.\")\n    if isinstance(obj, collections.abc.Sequence):\n        if isinstance(obj, list):\n            return ListSchema.flatten(obj)\n        elif isinstance(obj, tuple):\n            return TupleSchema.flatten(obj)\n        else:\n            raise NotImplementedError(f\"Sequence type {type(obj)} is not supported yet.\")\n    if isinstance(obj, torch.Tensor):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    if isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    if isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    raise NotImplementedError(f\"{type(obj)} is not supported yet.\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    # TODO: add support for nested containers\n    if isinstance(obj, torch.Tensor):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, collections.abc.Mapping):\n        obj = dict(obj)\n        res, schema = DictSchema.flatten(obj)\n        return res, schema\n    elif isinstance(obj, collections.abc.Sequence):\n        obj = list(obj)\n        res, schema = ListSchema.flatten(obj)\n        return res, schema\n    elif isinstance(obj, (Boxes, RotatedBoxes, BitMasks)):\n        res, schema = TensorWrapSchema.flatten(obj)\n        return res, schema\n    elif isinstance(obj, Instances):\n        res, schema = InstancesSchema.flatten(obj)\n        return res, schema\n    elif isinstance(obj, ROIMasks):\n        res, schema = TensorWrapSchema.flatten(obj)\n        return res, schema\n    else:\n        raise ValueError(\"Unsupported type : {}\".format(type(obj)))\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, torch.Tensor):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, collections.abc.Mapping):\n        return DictSchema.flatten(obj)\n    if isinstance(obj, collections.abc.Sequence):\n        return ListSchema.flatten(obj)\n    if isinstance(obj, tuple):\n        return TupleSchema.flatten(obj)\n    if isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    if isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    if isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n\n    raise ValueError(f\"Unsupported type: {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    # TODO: add support for nested container\n    if isinstance(obj, torch.Tensor):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, collections.abc.Mapping):\n        return DictSchema.flatten(obj)\n    if isinstance(obj, collections.abc.Sequence):\n        if isinstance(obj, (list, tuple)):\n            return ListSchema.flatten(obj)\n    if isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    if isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    if isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    raise ValueError(f\"Unsupported type for flatten_to_tuple: {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes)):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, collections.abc.Mapping):\n        # sort it so that we get deterministic results\n        # and also go through flatten_to_tuple to handle\n        # sub-objects\n        items = sorted(obj.items())\n        flat_keys, flat_vals = zip(*[flatten_to_tuple(k) + flatten_to_tuple(v) for k, v in items])\n        flat_vals, schema_vals = ListSchema.flatten(flat_vals)\n        flat_keys, schema_keys = ListSchema.flatten(flat_keys)\n        return flat_vals, DictSchema(schema_vals, schema_keys)\n    if isinstance(obj, collections.abc.Sequence):\n        # sort it so that we get deterministic results\n        # and also go through flatten_to_tuple to handle\n        # sub-objects\n        items = sorted(obj)\n        flat_items, schema_items = ListSchema.flatten(items)\n        return flat_items, ListSchema(schema_items, [len(obj)])\n    if isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    if isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    if isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    if isinstance(obj, torch.Tensor):\n        return (obj,), IdentitySchema()\n    raise ValueError(\"Unsupported type {}\".format(type(obj)))\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, torch.Tensor):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, collections.abc.Mapping):\n        if isinstance(obj, dict):\n            return DictSchema.flatten(obj)\n        else:\n            # other mapping views, e.g. KeysView\n            # use list schedule\n            return ListSchema.flatten([obj])\n    if isinstance(obj, collections.abc.Sequence):\n        if isinstance(obj, list):\n            return ListSchema.flatten(obj)\n        elif isinstance(obj, tuple):\n            return TupleSchema.flatten(obj)\n        else:\n            # other sequence views, e.g. ValuesView\n            # use list schedule\n            return ListSchema.flatten([obj])\n    if isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    if isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    if isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n\n    raise ValueError(\"Unsupported type : {}\".format(type(obj)))\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, collections.abc.Mapping):\n        # recursively flattening the values\n        values, schemas = zip(*[flatten_to_tuple(v) for v in obj.values()])\n        return (\n            *torch._C.flatten_dict(obj, \"_\", 1),\n            *values,\n        ), DictSchema(schemas, list(obj.keys()))\n    if isinstance(obj, collections.abc.Sequence):\n        # recursively flattening the elements\n        values, schemas = zip(*[flatten_to_tuple(v) for v in obj])\n        return (\n            *torch._C.flatten_sequence(obj, 1),\n            *values,\n        ), ListSchema(schemas, [len(obj)])\n    if isinstance(obj, Boxes):\n        return obj.tensor, TensorWrapSchema(_convert_target_to_string(type(obj)))\n    if isinstance(obj, ROIMasks):\n        return obj.tensor, TensorWrapSchema(_convert_target_to_string(type(obj)))\n    if isinstance(obj, Instances):\n        return flatten_instances(obj)\n    raise ValueError(f\"Unsupported type: {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes)):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, collections.abc.Mapping):\n        # recursively flatten each value in the dict\n        values, schemas = zip(*[flatten_to_tuple(v) for v in obj.values()])\n        return ListSchema.flatten((values, schemas))\n    elif isinstance(obj, collections.abc.Sequence) and not isinstance(obj, (str, bytes)):\n        # recursively flatten each value in the list\n        values, schemas = zip(*[flatten_to_tuple(v) for v in obj])\n        return ListSchema.flatten((values, schemas))\n    elif isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    elif isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    elif isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    elif isinstance(obj, torch.Tensor):\n        return (obj,), IdentitySchema()\n    else:\n        raise ValueError(\"Unsupported type {} for flatten_to_tuple\".format(type(obj)))\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes)):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, collections.abc.Mapping):\n        schema_list = [\n            flatten_to_tuple(v)\n            for v in obj.values()\n            if v is not None\n        ]\n        values, schemas = zip(*schema_list) if len(schema_list) else ((), ())\n        return TupleSchema.flatten(values) + (DictSchema(schemas, []),)\n    elif isinstance(obj, collections.abc.Sequence):\n        schema_list = [\n            flatten_to_tuple(v)\n            for v in obj\n            if v is not None\n        ]\n        values, schemas = zip(*schema_list) if len(schema_list) else ((), ())\n        return TupleSchema.flatten(values) + (ListSchema(schemas, []),)\n    elif isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    elif isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    elif isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    else:\n        raise ValueError(f\"Unable to flatten object of type {type(obj)}!\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, TensorWrapSchema):\n        return TensorWrapSchema.flatten(obj)\n    elif isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    elif isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    elif isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    elif isinstance(obj, str):\n        return IdentitySchema.flatten(obj)\n    elif isinstance(obj, bytes):\n        return IdentitySchema.flatten(obj)\n    elif isinstance(obj, collections.abc.Mapping):\n        return DictSchema.flatten(obj)\n    elif isinstance(obj, tuple) and hasattr(obj, \"_fields\"):  # namedtuple\n        return TupleSchema.flatten(obj)\n    elif isinstance(obj, list):\n        return ListSchema.flatten(obj)\n    elif torch.is_tensor(obj):\n        return (obj,), IdentitySchema()\n    else:\n        raise ValueError(f\"Unable to flatten object of type {type(obj)}!\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, torch.Tensor):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (str, bytes)):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, collections.abc.Mapping):\n        obj_items = obj.items()\n        keys = [k for k, v in obj_items]\n        values = [v for k, v in obj_items]\n        return DictSchema.flatten(values) + (tuple(keys),)\n    elif isinstance(obj, collections.abc.Sequence):\n        return ListSchema.flatten(obj)\n    elif isinstance(obj, collections.abc.Set):\n        obj_list = list(obj)\n        return ListSchema.flatten(obj_list)\n    elif isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    elif isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    elif isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    else:\n        raise ValueError(\"Unsupported type : {}\".format(type(obj)))\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, torch.Tensor):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, collections.abc.Mapping):\n        schema = DictSchema\n    elif isinstance(obj, Instances):\n        schema = InstancesSchema\n    elif isinstance(obj, Boxes):\n        schema = TensorWrapSchema\n    elif isinstance(obj, ROIMasks):\n        schema = TensorWrapSchema\n    elif isinstance(obj, tuple):\n        schema = TupleSchema\n    elif isinstance(obj, list):\n        schema = ListSchema\n    else:\n        raise ValueError(f\"Unsupported type for autograd: {type(obj)}\")\n    return schema.flatten(obj)\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    # TODO: add support for nested containers\n    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, list):\n        values, schema = ListSchema.flatten(obj)\n        return values, ListSchema(schema.schemas, schema.sizes)\n    if isinstance(obj, tuple):\n        values, schema = TupleSchema.flatten(obj)\n        return values, TupleSchema(schema.schemas, schema.sizes)\n    if isinstance(obj, dict):\n        values, schema = DictSchema.flatten(obj)\n        return values, schema\n    if isinstance(obj, Instances):\n        values, schema = InstancesSchema.flatten(obj)\n        return values, schema\n    if isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    if isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n\n    raise ValueError(f\"Do not know how to flatten type {type(obj)}!\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, collections.abc.Mapping):\n        if isinstance(obj, dict):\n            obj = obj.copy()\n        else:\n            # namedtuple\n            obj = obj._asdict()\n        schema = DictSchema.flatten(obj)\n        return schema\n    if isinstance(obj, collections.abc.Sequence):\n        if isinstance(obj, (list, tuple)):\n            obj = list(obj)\n        elif isinstance(obj, collections.abc.KeysView):\n            obj = list(obj)\n        elif isinstance(obj, Instances):\n            obj = obj.get_fields()\n        else:\n            # typically this is a list of Boxes or RotatedBoxes\n            obj = list(obj)\n        schema = ListSchema.flatten(obj)\n        return schema\n    if isinstance(obj, (Boxes, ROIMasks)):\n        return TensorWrapSchema.flatten(obj)\n    if isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    raise ValueError(\"Do not know how to flatten type {}!\".format(type(obj)))\n\n"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    if not isinstance(groups, np.ndarray):\n        groups = np.array(groups)\n    if not isinstance(equations, np.ndarray):\n        equations = np.array(equations)\n\n    # Raise error if groups is not a 2D array\n    if groups.ndim != 2:\n        raise EquationToMatrixError(\n            f\"{names[0]} must be a 2D array of shape (n_groups, n_assets).\"\n        )\n\n    # Raise error if equations is not a 1D array\n    if equations.ndim != 1:\n        raise EquationToMatrixError(\n            f\"{names[1]} must be a 1D array of shape (n_equations,).\"\n        )\n\n    # Raise error if equations contains non-string elements\n    if not np.issubdtype(equations.dtype, np.str_):\n        raise EquationToMatrixError(\n            f\"{names[1]} must be a 1D array of string representations of linear equations.\"\n        )\n\n    # Raise error if groups contains non-string elements\n    if not np.issubdtype(groups.dtype, np.str_):\n        raise EquationToMatrixError(\n            f\"{names[0]} must be a 2D array of string representations of linear equations.\"\n        )\n\n    # Raise error if groups is not a 2D array\n    if groups.ndim != 2:\n        raise EquationToMatrixError(\n            f\"{names[0]} must be a 2D array of shape (n_groups, n_assets).\"\n        )\n\n    # Raise error if equations is not a 1D array\n    if equations.ndim != 1:\n        raise EquationToMatrixError(\n            f\"{names[1]} must be a 1D array of shape (n_equations,).\"\n        )\n\n    # Raise error if equations contains non-string elements\n    if not np.issubdtype(equations.dtype, np.str_):\n        raise EquationToMatrixError"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    groups = np.asarray(groups)\n    equations = np.asarray(equations)\n\n    if groups.ndim != 2:\n        raise ValueError(\n            f\"{names[0]} must be a 2D array of shape (n_groups, n_assets).\"\n        )\n\n    if equations.ndim != 1:\n        raise ValueError(\n            f\"{names[1]} must be a 1D array of shape (n_equations,).\"\n        )\n\n    n_groups, n_assets = groups.shape\n    n_equations = equations.size\n\n    left = np.zeros((n_equations, n_assets), dtype=bool)\n    right = np.zeros(n_equations, dtype=bool)\n\n    for i, equation in enumerate(equations):\n        left[i], right[i] = _parse_equation(\n            equation, groups, n_groups, n_assets, sum_to_one, raise_if_group_missing, names\n        )\n\n    return left, right\n\n"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # check input\n    if not isinstance(groups, np.ndarray):\n        groups = np.asarray(groups)\n    if not isinstance(equations, np.ndarray):\n        equations = np.asarray(equations)\n    if groups.ndim != 2:\n        raise ValueError(\n            f\"{names[0]} must be a 2D array of shape (n_groups, n_assets).\"\n        )\n    if equations.ndim != 1:\n        raise ValueError(\n            f\"{names[1]} must be a 1D array of shape (n_equations,).\"\n        )\n    if not isinstance(sum_to_one, bool):\n        raise TypeError(\n            f\"sum_to_one must be a bool, got {type(sum_to_one)}\"\n        )\n    if not isinstance(raise_if_group_missing, bool):\n        raise TypeError(\n            f\"raise_if_group_missing must be a bool, got {type(raise_if_group_missing)}\"\n        )\n    if not isinstance(names, tuple):\n        raise TypeError(\n            f\"names must be a tuple, got {type(names)}\"\n        )\n    if len(names) != 2:\n        raise ValueError(\n            f\"names must be a tuple of length 2, got {len(names)}\"\n        )\n    if not isinstance(names[0], str):\n        raise TypeError(\n            f\"names[0] must be a str, got {type(names[0])}\"\n        )\n    if not isinstance(names[1], str):\n        raise TypeError(\n            f\"names[1] must be a str, got {type(names[1])}\"\n        )\n\n    # check if all groups are present in equations\n    if not np.all([group in equations for group in groups]):\n        if raise_if_group_missing:\n            raise GroupNotFoundError(\n                \"Not all groups are present in the equations.\"\n            )\n        else:\n            warnings.warn(\n                \"Not all groups are present in the equations"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    if isinstance(groups, list):\n        groups = np.array(groups)\n    if isinstance(equations, list):\n        equations = np.array(equations)\n\n    if not isinstance(groups, np.ndarray):\n        raise TypeError(\n            f\"{names[0]} must be an array-like object, not {type(groups)}\"\n        )\n    if not isinstance(equations, np.ndarray):\n        raise TypeError(\n            f\"{names[1]} must be an array-like object, not {type(equations)}\"\n        )\n    if not isinstance(sum_to_one, bool):\n        raise TypeError(\n            f\"sum_to_one must be a boolean, not {type(sum_to_one)}\"\n        )\n    if not isinstance(raise_if_group_missing, bool):\n        raise TypeError(\n            f\"raise_if_group_missing must be a boolean, not {type(raise_if_group_missing)}\"\n        )\n    if not isinstance(names, tuple):\n        raise TypeError(\n            f\"names must be a tuple, not {type(names)}\"\n        )\n\n    if len(names) != 2:\n        raise ValueError(\n            f\"names must have exactly two elements, not {len(names)}\"\n        )\n    if not isinstance(names[0], str):\n        raise TypeError(\n            f\"names[0] must be a string, not {type(names[0])}\"\n        )\n    if not isinstance(names[1], str):\n        raise TypeError(\n            f\"names[1] must be a string, not {type(names[1])}\"\n        )\n\n    if len(groups) == 0:\n        raise ValueError(\n            f\"{names[0]} must have at least one element\"\n        )\n    if len(equations) == 0:\n        raise ValueError(\n            f\"{names[1]} must have at least one element\"\n        )\n\n    if not isinstance(groups[0], np.ndarray):\n        raise TypeError(\n            f"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # check inputs\n    groups = np.asarray(groups)\n    equations = np.asarray(equations)\n    if groups.ndim != 2:\n        raise ValueError(\n            f\"{names[0]} must be a 2D array of shape (n_groups, n_assets).\"\n        )\n    if equations.ndim != 1:\n        raise ValueError(\n            f\"{names[1]} must be a 1D array of shape (n_equations,).\"\n        )\n\n    # check if all groups are in the equations\n    if not np.all([group in equations for group in groups]):\n        if raise_if_group_missing:\n            raise GroupNotFoundError(\n                f\"Some groups in {names[0]} are not found in {names[1]}.\"\n            )\n        else:\n            warnings.warn(\n                f\"Some groups in {names[0]} are not found in {names[1]}.\"\n            )\n\n    # check if all groups are in the equations\n    if not np.all([group in equations for group in groups]):\n        if raise_if_group_missing:\n            raise GroupNotFoundError(\n                f\"Some groups in {names[0]} are not found in {names[1]}.\"\n            )\n        else:\n            warnings.warn(\n                f\"Some groups in {names[0]} are not found in {names[1]}.\"\n            )\n\n    # check if all equations are in the groups\n    if not np.all([eq in groups for eq in equations]):\n        if raise_if_group_missing:\n            raise GroupNotFoundError(\n                f\"Some groups in {names[1]} are not found in {names[0]}.\"\n            )\n        else:\n            warnings.warn(\n                f\"Some groups in {names[1]} are not found in {names[0]}.\"\n            )\n\n    # check if equations are valid\n    for eq in equations:\n        if not re.match(r\"^[a-zA-Z0-9_]+$\", eq):\n            raise EquationToMatrixError(\n                f\"Equ"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Checking arguments\n    if not isinstance(groups, np.ndarray):\n        groups = np.array(groups)\n    if not isinstance(equations, np.ndarray):\n        equations = np.array(equations)\n    if not isinstance(sum_to_one, bool):\n        raise TypeError(f\"sum_to_one must be a bool, got {type(sum_to_one)}\")\n    if not isinstance(raise_if_group_missing, bool):\n        raise TypeError(\n            f\"raise_if_group_missing must be a bool, got {type(raise_if_group_missing)}\"\n        )\n    if not isinstance(names, tuple):\n        raise TypeError(f\"names must be a tuple, got {type(names)}\")\n    if len(names) != 2:\n        raise ValueError(\n            f\"names must have exactly two elements, got {len(names)}\"\n        )\n    if not isinstance(names[0], str):\n        raise TypeError(f\"names[0] must be a string, got {type(names[0])}\")\n    if not isinstance(names[1], str):\n        raise TypeError(f\"names[1] must be a string, got {type(names[1])}\")\n\n    # Checking groups and equations\n    if groups.ndim != 2:\n        raise ValueError(\n            f\"{names[0]} must be a 2D array, got {groups.ndim}D array\"\n        )\n    if equations.ndim != 1:\n        raise ValueError(\n            f\"{names[1]} must be a 1D array, got {equations.ndim}D array\"\n        )\n    if groups.shape[0] != equations.shape[0]:\n        raise ValueError(\n            f\"{names[0]} and {names[1]} must have the same number of rows\"\n        )\n    if not np.issubdtype(groups.dtype, np.integer):\n        raise TypeError(f\"{names[0]} must be an integer array\")\n    if not np.issubdtype("}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    groups = np.asarray(groups)\n    equations = np.asarray(equations)\n\n    if not isinstance(groups, np.ndarray):\n        raise TypeError(f\"{names[0]} must be a numpy array\")\n    if not isinstance(equations, np.ndarray):\n        raise TypeError(f\"{names[1]} must be a numpy array\")\n\n    if groups.ndim != 2:\n        raise ValueError(f\"{names[0]} must be a 2D array\")\n    if equations.ndim != 1:\n        raise ValueError(f\"{names[1]} must be a 1D array\")\n\n    if groups.shape[0] == 0:\n        raise ValueError(f\"{names[0]} must have at least one group\")\n    if groups.shape[1] == 0:\n        raise ValueError(f\"{names[0]} must have at least one asset\")\n    if equations.shape[0] == 0:\n        raise ValueError(f\"{names[1]} must have at least one equation\")\n\n    if np.any(groups.sum(axis=1) == 0):\n        raise ValueError(f\"{names[0]} must have at least one asset per group\")\n\n    if np.any(groups.sum(axis=1) > 1):\n        warnings.warn(\n            f\"{names[0]} contains groups with more than one asset per group. \"\n            \"This is not supported by this function. \"\n            \"The groups will be reduced to one asset per group.\"\n        )\n        groups = groups[groups.sum(axis=1) == 1]\n\n    if np.any(groups.sum(axis=1) < 1):\n        warnings.warn(\n            f\"{names[0]} contains groups with no asset per group. \"\n            \"This is not supported by this function. \"\n            \"The groups will be removed from the output.\"\n        )\n        groups = groups[groups.sum(axis=1) > 0]\n\n    if np.any(groups.sum(axis=1) > 1):"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    if not isinstance(groups, np.ndarray):\n        groups = np.array(groups)\n    if not isinstance(equations, np.ndarray):\n        equations = np.array(equations)\n    if not isinstance(sum_to_one, bool):\n        raise TypeError(\"sum_to_one must be a boolean.\")\n    if not isinstance(raise_if_group_missing, bool):\n        raise TypeError(\"raise_if_group_missing must be a boolean.\")\n    if not isinstance(names, tuple):\n        raise TypeError(\"names must be a tuple.\")\n    if len(names) != 2:\n        raise ValueError(\"names must contain exactly two elements.\")\n    if not isinstance(names[0], str):\n        raise TypeError(\"names[0] must be a string.\")\n    if not isinstance(names[1], str):\n        raise TypeError(\"names[1] must be a string.\")\n\n    if groups.ndim != 2:\n        raise ValueError(\n            f\"groups must be a 2D array. Received groups with {groups.ndim} dimensions.\"\n        )\n    if equations.ndim != 1:\n        raise ValueError(\n            f\"equations must be a 1D array. Received equations with {equations.ndim} dimensions.\"\n        )\n\n    if np.isnan(groups).any():\n        raise ValueError(\n            f\"{names[0]} must not contain NaN values.\"\n        )\n    if np.isnan(equations).any():\n        raise ValueError(\n            f\"{names[1]} must not contain NaN values.\"\n        )\n\n    if (groups.dtype != np.float64) and (groups.dtype != np.int64):\n        raise TypeError(\n            f\"{names[0]} must be of type np.float64 or np.int64.\"\n        )\n    if (equations.dtype != np.float64) and (equations.dtype != np.int64):\n        raise TypeError(\n            f\"{names[1]} must be of type np.float64 or np."}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    groups = np.array(groups)\n    equations = np.array(equations)\n\n    if groups.ndim != 2:\n        raise ValueError(f\"{names[0]} must be 2D\")\n\n    if equations.ndim != 1:\n        raise ValueError(f\"{names[1]} must be 1D\")\n\n    if groups.shape[1] != len(equations):\n        raise ValueError(\n            f\"{names[0]} and {names[1]} must have the same number of columns\"\n        )\n\n    if sum_to_one:\n        if not np.all(groups.sum(axis=1) == 1):\n            raise ValueError(\"All elements in a group must sum to one\")\n\n    left = np.zeros((len(equations), groups.shape[1]))\n    right = np.zeros(len(equations))\n\n    for i, equation in enumerate(equations):\n        left[i] = _parse_equation(equation, groups, raise_if_group_missing)\n        right[i] = _parse_right_side(equation)\n\n    return left, right\n\n"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    groups = np.asarray(groups)\n    equations = np.asarray(equations)\n\n    if len(groups) == 0:\n        raise GroupNotFoundError(\n            f\"No group was found in {names[0]}.\"\n        )\n\n    if len(equations) == 0:\n        raise EquationToMatrixError(\n            f\"No equation was found in {names[1]}.\"\n        )\n\n    if groups.ndim != 2:\n        raise GroupNotFoundError(\n            f\"{names[0]} must be a 2D array.\"\n        )\n\n    if equations.ndim != 1:\n        raise EquationToMatrixError(\n            f\"{names[1]} must be a 1D array.\"\n        )\n\n    n_groups, n_assets = groups.shape\n\n    if n_groups == 0:\n        raise GroupNotFoundError(\n            f\"No group was found in {names[0]}.\"\n        )\n\n    if n_assets == 0:\n        raise GroupNotFoundError(\n            f\"No asset was found in {names[0]}.\"\n        )\n\n    n_equations = equations.size\n\n    if n_equations == 0:\n        raise EquationToMatrixError(\n            f\"No equation was found in {names[1]}.\"\n        )\n\n    # Convert equations to matrix\n    eq_matrix = np.zeros((n_equations, n_assets))\n    eq_vector = np.zeros(n_equations)\n\n    for i, eq in enumerate(equations):\n        eq_matrix[i, :], eq_vector[i] = _equation_to_matrix(\n            eq, groups, sum_to_one, raise_if_group_missing, names\n        )\n\n    return eq_matrix, eq_vector\n\n"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    groups = np.array(groups)\n    equations = np.array(equations)\n\n    if groups.ndim != 2:\n        raise ValueError(\n            f\"The {names[0]} parameter must be a 2D array of shape (n_groups, n_assets).\"\n        )\n\n    if equations.ndim != 1:\n        raise ValueError(\n            f\"The {names[1]} parameter must be a 1D array of shape (n_equations,).\"\n        )\n\n    if np.any(groups < 0):\n        raise ValueError(\n            f\"The {names[0]} parameter must be a non-negative 2D array.\"\n        )\n\n    if np.any(equations < 0):\n        raise ValueError(\n            f\"The {names[1]} parameter must be a non-negative 1D array.\"\n        )\n\n    if np.any(groups.sum(axis=1) == 0):\n        raise ValueError(\n            f\"The {names[0]} parameter must have at least one asset in each group.\"\n        )\n\n    if np.any(equations == 0):\n        raise ValueError(\n            f\"The {names[1]} parameter must contain at least one non-zero element.\"\n        )\n\n    if sum_to_one:\n        if np.any(groups.sum(axis=1) != 1):\n            raise ValueError(\n                f\"The {names[0]} parameter must have exactly one asset in each group when sum_to_one is True.\"\n            )\n\n    if raise_if_group_missing:\n        group_names = np.unique(groups)\n        equation_names = np.unique(equations)\n\n        if len(np.intersect1d(group_names, equation_names)) != len(equation_names):\n            raise GroupNotFoundError(\n                f\"The {names[1]} parameter contains groups that are not part of the {names[0]} parameter.\"\n            )\n\n    # Split equations into left and right matrices\n    left_matrices = []\n    right_matrices = []"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Check input\n    groups = np.asarray(groups)\n    equations = np.asarray(equations)\n\n    if len(groups.shape) != 2:\n        raise ValueError(\n            f\"The shape of the {names[0]} argument must be (n_groups, n_assets), but got {groups.shape}.\"\n        )\n    if len(equations.shape) != 1:\n        raise ValueError(\n            f\"The shape of the {names[1]} argument must be (n_equations,), but got {equations.shape}.\"\n        )\n\n    # Check if all groups are present in the equations\n    if raise_if_group_missing:\n        missing_groups = [\n            group\n            for group in np.unique(groups)\n            if group not in np.unique(equations)\n        ]\n        if len(missing_groups) > 0:\n            raise GroupNotFoundError(\n                f\"The following groups are missing in the {names[1]} argument: {missing_groups}\"\n            )\n\n    # Check if all groups are present in the equations\n    if not raise_if_group_missing:\n        missing_groups = [\n            group\n            for group in np.unique(groups)\n            if group not in np.unique(equations)\n        ]\n        if len(missing_groups) > 0:\n            warnings.warn(\n                f\"The following groups are missing in the {names[1]} argument: {missing_groups}\"\n            )\n\n    # Check if all equations are present in the groups\n    missing_equations = [\n        equation\n        for equation in np.unique(equations)\n        if equation not in np.unique(groups)\n    ]\n    if len(missing_equations) > 0:\n        raise GroupNotFoundError(\n            f\"The following equations are missing in the {names[0]} argument: {missing_equations}\"\n        )\n\n    # Check if all groups are present in the equations\n    if not raise_if_group_missing:\n        missing_equations = [\n            equation\n            for equation in np.unique(equations"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    if not isinstance(groups, np.ndarray):\n        groups = np.array(groups)\n    if not isinstance(equations, np.ndarray):\n        equations = np.array(equations)\n\n    if groups.ndim != 2:\n        raise ValueError(\n            f\"The parameter {names[0]} must be a 2D array.\"\n            f\"Got {groups.ndim} dimension(s).\"\n        )\n    if equations.ndim != 1:\n        raise ValueError(\n            f\"The parameter {names[1]} must be a 1D array.\"\n            f\"Got {equations.ndim} dimension(s).\"\n        )\n\n    n_groups, n_assets = groups.shape\n    n_equations = equations.shape[0]\n\n    if n_groups == 0:\n        raise ValueError(\n            f\"The parameter {names[0]} must contain at least one group.\"\n        )\n    if n_equations == 0:\n        raise ValueError(\n            f\"The parameter {names[1]} must contain at least one equation.\"\n        )\n\n    if n_equations > n_groups:\n        raise ValueError(\n            f\"The parameter {names[1]} must contain at most as many equations as groups.\"\n            f\"Got {n_equations} equations and {n_groups} groups.\"\n        )\n\n    if n_assets == 0:\n        raise ValueError(\n            f\"The parameter {names[0]} must contain at least one asset.\"\n        )\n\n    # Extract the group names from the equations\n    group_names = []\n    for equation in equations:\n        matches = re.findall(r\"[A-Za-z]+\", equation)\n        if len(matches) == 0:\n            raise ValueError(\n                f\"The parameter {names[1]} must contain at least one group name.\"\n            )\n        for match in matches:\n            if match not in group_names:\n                group_names.append(match)\n\n    # Check if all group names are present in the input groups"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # check input arguments\n    groups = np.asarray(groups)\n    equations = np.asarray(equations)\n\n    if groups.ndim != 2:\n        raise ValueError(\n            f\"Expected {names[0]} to have 2 dimensions, got {groups.ndim}.\"\n        )\n    if equations.ndim != 1:\n        raise ValueError(\n            f\"Expected {names[1]} to have 1 dimension, got {equations.ndim}.\"\n        )\n    if len(groups) == 0:\n        raise ValueError(f\"Expected {names[0]} to have at least one group.\")\n    if len(equations) == 0:\n        raise ValueError(f\"Expected {names[1]} to have at least one equation.\")\n\n    # check if groups are present in equations\n    group_names = np.unique(groups)\n    group_names_in_equations = np.unique(np.concatenate(equations))\n    if not np.isin(group_names_in_equations, group_names).all():\n        if raise_if_group_missing:\n            raise GroupNotFoundError(\n                f\"Some groups in {names[1]} are not found in {names[0]}.\"\n            )\n        else:\n            warnings.warn(\n                f\"Some groups in {names[1]} are not found in {names[0]}.\",\n                UserWarning,\n            )\n\n    # create the left matrix\n    left = np.zeros((len(equations), len(group_names)))\n    for i, eq in enumerate(equations):\n        for g in eq:\n            left[i, np.where(group_names == g)[0]] = 1\n\n    # check if all groups sum to one\n    if sum_to_one:\n        if not np.allclose(left.sum(axis=1), 1):\n            raise EquationToMatrixError(\n                \"All groups in equations must sum to one.\"\n            )\n\n    # create the right matrix\n    right = np.zeros(len(equations))"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    groups = np.asarray(groups)\n    equations = np.asarray(equations)\n\n    if groups.ndim != 2:\n        raise ValueError(\n            f\"Expected {names[0]} to be a 2D array, but got {groups.ndim} dimensions\"\n        )\n\n    if equations.ndim != 1:\n        raise ValueError(\n            f\"Expected {names[1]} to be a 1D array, but got {equations.ndim} dimensions\"\n        )\n\n    if not np.issubdtype(groups.dtype, np.number):\n        raise ValueError(\n            f\"Expected {names[0]} to be of a numeric type, but got {groups.dtype}\"\n        )\n\n    if not np.issubdtype(equations.dtype, np.str_):\n        raise ValueError(\n            f\"Expected {names[1]} to be of a string type, but got {equations.dtype}\"\n        )\n\n    n_groups, n_assets = groups.shape\n    n_equations = len(equations)\n\n    if n_equations == 0:\n        raise ValueError(f\"Expected {names[1]} to be non-empty\")\n\n    if n_assets == 0:\n        raise ValueError(f\"Expected {names[0]} to be non-empty\")\n\n    if n_equations > n_assets:\n        warnings.warn(\n            f\"{names[1]} has {n_equations} equations, but only {n_assets} assets in {names[0]}\",\n            EquationToMatrixError,\n        )\n\n    groups_names = np.array(\n        [f\"group_{i}\" for i in range(n_groups)]\n    )  # for error messages\n\n    equations_names = np.array(\n        [f\"equation_{i}\" for i in range(n_equations)]\n    )  # for error messages\n\n    left = np.zeros((n_equations, n_assets), dtype=np.float64)\n    right ="}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Checking input parameters\n    if not isinstance(groups, np.ndarray):\n        groups = np.array(groups)\n\n    if not isinstance(equations, np.ndarray):\n        equations = np.array(equations)\n\n    if groups.ndim != 2:\n        raise ValueError(f\"{names[0]} must be 2D array\")\n\n    if equations.ndim != 1:\n        raise ValueError(f\"{names[1]} must be 1D array\")\n\n    if sum_to_one:\n        if np.any(np.sum(groups, axis=1) != 1):\n            raise ValueError(\"groups must sum to one\")\n\n    if np.any(groups < 0):\n        raise ValueError(\"groups must be non-negative\")\n\n    if np.any(equations < 0):\n        raise ValueError(\"equations must be non-negative\")\n\n    # Checking if there are any groups in the equations that are not in the groups array\n    groups_in_equations = set(\n        [\n            group\n            for equation in equations\n            for group in re.findall(r\"[A-Z]\", equation)\n        ]\n    )\n\n    if not groups_in_equations.issubset(set(groups)):\n        if raise_if_group_missing:\n            raise GroupNotFoundError(\n                \"Some groups in the equations are not found in the groups array\"\n            )\n        else:\n            warnings.warn(\n                \"Some groups in the equations are not found in the groups array\",\n                stacklevel=2,\n            )\n\n    # Converting equations to matrix\n    try:\n        left_matrix = np.zeros((len(equations), groups.shape[1]))\n        right_matrix = np.zeros((len(equations),))\n\n        for i, equation in enumerate(equations):\n            left_matrix[i, :] = _parse_equation(\n                equation, groups, sum_to_one, names\n            )\n            right_matrix[i] = _parse_equation(\n                equation, groups"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    groups = np.array(groups, dtype=object)\n    equations = np.array(equations, dtype=object)\n    n_groups = groups.shape[0]\n    n_equations = equations.shape[0]\n    n_assets = groups.shape[1]\n\n    # check for validity of input\n    if n_groups == 0:\n        raise ValueError(\n            f\"{names[0]} must be a non-empty array of shape (n_groups, n_assets)\"\n        )\n    if n_equations == 0:\n        raise ValueError(\n            f\"{names[1]} must be a non-empty array of shape (n_equations,)\"\n        )\n    if n_assets == 0:\n        raise ValueError(\n            f\"{names[0]} must be a non-empty array of shape (n_groups, n_assets)\"\n        )\n    if n_groups < n_equations:\n        raise ValueError(\n            f\"{names[0]} must have at least as many rows as {names[1]}\"\n        )\n\n    # check if groups are part of the equations\n    if not np.any(np.isin(groups, equations)):\n        warnings.warn(\n            f\"None of the {names[0]} are part of {names[1]}. Returning `None`.\"\n        )\n        return None, None\n\n    # check if groups are part of the equations\n    if not np.any(np.isin(equations, groups)):\n        warnings.warn(\n            f\"None of the {names[1]} are part of {names[0]}. Returning `None`.\"\n        )\n        return None, None\n\n    # convert equations to matrix\n    left_matrix = np.zeros((n_equations, n_assets))\n    right_vector = np.zeros(n_equations)\n    for i, equation in enumerate(equations):\n        try:\n            left_matrix[i, :], right_vector[i] = _equation_to_matrix(\n                equation, groups, sum_to_one, names\n           "}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    groups = np.asarray(groups)\n    equations = np.asarray(equations)\n\n    if groups.ndim != 2:\n        raise ValueError(f\"{names[0]} must be a 2D array\")\n\n    if equations.ndim != 1:\n        raise ValueError(f\"{names[1]} must be a 1D array\")\n\n    if sum_to_one:\n        if np.any(np.sum(groups, axis=1) != 1):\n            raise ValueError(\n                f\"All elements in {names[0]} must sum to one, i.e. each row must sum to one.\"\n            )\n\n    if np.any(groups < 0):\n        raise ValueError(\n            f\"All elements in {names[0]} must be greater than or equal to zero.\"\n        )\n\n    if np.any(groups > 1):\n        raise ValueError(f\"All elements in {names[0]} must be less than or equal to one.\")\n\n    if np.any(equations < 0):\n        raise ValueError(f\"All elements in {names[1]} must be greater than or equal to zero.\")\n\n    if np.any(equations > 1):\n        raise ValueError(f\"All elements in {names[1]} must be less than or equal to one.\")\n\n    if np.any(equations > 1):\n        raise ValueError(f\"All elements in {names[1]} must be less than or equal to one.\")\n\n    if len(groups) < 2:\n        raise ValueError(\n            f\"{names[0]} must contain at least two groups of assets.\"\n        )\n\n    if len(equations) < 1:\n        raise ValueError(\n            f\"{names[1]} must contain at least one equation.\"\n        )\n\n    if len(groups) > 100:\n        warnings.warn(\n            f\"{names[0]} contains {len(groups)} groups, which is a large number of groups. This can lead to a large number of equations and may slow down the function.\"\n        )\n\n   "}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    groups = np.asarray(groups)\n    equations = np.asarray(equations)\n\n    if groups.ndim != 2:\n        raise ValueError(f\"{names[0]} must be a 2D array\")\n\n    if equations.ndim != 1:\n        raise ValueError(f\"{names[1]} must be a 1D array\")\n\n    n_groups, n_assets = groups.shape\n    n_equations = equations.shape[0]\n\n    if n_equations == 0:\n        return None, None\n\n    left = np.zeros((n_equations, n_assets), dtype=bool)\n    right = np.zeros((n_equations,), dtype=bool)\n\n    for i, equation in enumerate(equations):\n\n        if equation == \"\":\n            continue\n\n        equation = equation.replace(\" \", \"\")\n        equation = equation.replace(\"=\", \"==\")\n\n        # Check if equation is a valid string\n        if not re.match(r\"^[a-zA-Z0-9==_-]+$\", equation):\n            raise ValueError(f\"{names[1]} contains invalid characters\")\n\n        # Check if equation is a valid equation\n        if \"==\" not in equation:\n            raise ValueError(f\"{names[1]} must be a valid equation\")\n\n        # Check if equation contains groups that are not in groups\n        for group in equation.split(\"==\"):\n            if group not in groups:\n                if raise_if_group_missing:\n                    raise GroupNotFoundError(group)\n                else:\n                    warnings.warn(f\"{names[1]} contains a group not found in {names[0]}\")\n                    return None, None\n\n        # Convert equation to left and right matrix\n        equation = equation.replace(\"+\", \" + \")\n        equation = equation.replace(\"-\", \" - \")\n        equation = equation.replace(\"_\", \" - \")\n\n        for group in equation.split(\"==\"):\n\n            if group == \"\":\n                continue\n\n            for asset in group.split(\"+\"):\n                if asset"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    if not isinstance(groups, np.ndarray):\n        groups = np.array(groups)\n    if not isinstance(equations, np.ndarray):\n        equations = np.array(equations)\n\n    if groups.ndim != 2:\n        raise ValueError(\n            f\"{names[0]} must be a 2D array of shape (n_groups, n_assets).\"\n        )\n    if equations.ndim != 1:\n        raise ValueError(\n            f\"{names[1]} must be a 1D array of shape (n_equations,).\"\n        )\n\n    if equations.size == 0:\n        warnings.warn(\n            \"No equations were provided. Returning None.\", UserWarning\n        )\n        return None\n\n    if groups.size == 0:\n        warnings.warn(\n            \"No groups were provided. Returning None.\", UserWarning\n        )\n        return None\n\n    if sum_to_one:\n        if np.any(np.sum(groups, axis=1) != 1):\n            raise ValueError(\n                f\"{names[0]} must have all elements summing to one.\"\n            )\n\n    # We use a regex to parse the equations\n    # The regex is split into 4 groups:\n    # 1. The group name\n    # 2. The group coefficients\n    # 3. The operator (e.g., '+', '-', '=')\n    # 4. The right side of the equation\n    regex = r\"([\\w\\d]+)\\s*([\\+-]?\\d*\\.?\\d*)\\s*([\\+-]?=)\\s*([\\+-]?\\d*\\.?\\d*)\"\n    regex_obj = re.compile(regex)\n\n    # We first extract the groups and coefficients from the equations\n    groups_eq = []\n    coefficients = []\n    for equation in equations:\n        match = regex_obj.match(equation)\n        if match:\n            groups_eq.append(match.group(1))\n            coefficients.append(float(match.group("}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n\n    # Create new class definition\n    class_name = \"InstancesScriptable\"\n    lines = [\"import torch\"]\n    for i, (name, value) in enumerate(fields):\n        lines.append(f\"class {name}(torch.Tensor):\")\n        lines.append(f\"    __torch_script_class__ = 'InstancesScriptable'\")\n        lines.append(f\"    __annotations__ = {{'{name}': {value}}}\")\n        lines.append(f\"    def __init__(self, x):\")\n        lines.append(f\"        pass\")\n    lines.append(f\"class {class_name}:\")\n    lines.append(f\"    def __init__(self, image_size: torch.Tensor, pred_boxes: torch.Tensor,\")\n    lines.append(f\"                 pred_classes: torch.Tensor, scores: torch.Tensor,\")\n    lines.append(f\"                 pred_masks: torch.Tensor,\")\n    lines.append(f\"                 pred_keypoints: torch.Tensor):\")\n    lines.append(f\"        pass\")\n    for name, _ in fields:\n        lines.append(f\"    def get_{name}(self):\")\n        lines.append(f\"        return self.{name}\")\n    lines.append(f\"    def has_{name}(self):\")\n    lines.append(f\"        return hasattr(self, '{name}')\")\n    lines.append(f\"    def set_{name}(self, {name}):\")\n    lines.append(f\"        self.{name} = {name}\")\n    lines.append(f\"    def remove_{name}(self):\")\n    lines.append(f\"        if hasattr(self, '{name}'):\")\n    lines.append(f\"            delattr(self, '{name}')\")\n    lines.append(f\"    def to(self, device: str):\")\n    lines.append(f\"        return self\")\n    lines.append(f\"   "}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n    # generate a new class\n    cls_name = \"InstancesScriptable\"\n    lines = []\n    lines.append(f\"import torch\")\n    lines.append(f\"from detectron2.structures import Instances\")\n    lines.append(f\"class {cls_name}:\")\n    for name, value in fields:\n        if isinstance(value, bool):\n            value = str(value).lower()\n        lines.append(f\"  _{name} = {value}\")\n    lines.append(f\"  def __init__(self, image_size: torch.Tensor, {cls_name}.from_instances = Instances.from_instances):\")\n    lines.append(f\"    self.image_size = image_size\")\n    lines.append(f\"    self.fields = {cls_name}._fields\")\n    for name in fields:\n        lines.append(f\"    self._{name} = None\")\n    lines.append(f\"  def get_{cls_name}_fields(self):\")\n    lines.append(f\"    return {cls_name}._fields\")\n    for name, _ in fields:\n        lines.append(f\"  @property\")\n        lines.append(f\"  def {name}(self):\")\n        lines.append(f\"    return self._{name}\")\n    lines.append(f\"  def has_{cls_name}_field(self, field):\")\n    lines.append(f\"    return field in {cls_name}._fields\")\n    lines.append(f\"  def set_{cls_name}_field(self, name, value):\")\n    lines.append(f\"    self._{name} = value\")\n    lines.append(f\"  def remove_{cls_name}_field(self, name):\")\n    lines.append(f\"    self._{name} = None\")\n    lines.append(f\"  def get_{cls_name}_field(self, name):\")\n    lines.append(f\"    return self._{name}\")\n    lines.append(f\"  def"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    # Generate a unique name for the class\n    cls_name = \"Instances_patched_{}\".format(_counter)\n    _counter += 1\n\n    # Generate the class source code\n    cls_def = [\n        f\"class {cls_name}(\" + \"Instances):\",\n        \"    def __init__(self, image_size: Tuple[int, int]):\",\n        \"        super().__init__(image_size)\",\n    ]\n    for name, value in fields:\n        cls_def.append(f\"        self._{name} = torch.jit.annotate(Optional[torch.Tensor], None)\")\n        cls_def.append(f\"        self._{name}_fields: List[str] = []\")\n    cls_def.append(f\"\")\n    cls_def.append(f\"    @property\")\n    cls_def.append(f\"    def has_pred_boxes(self) -> bool:\")\n    cls_def.append(f\"        return False\")\n    cls_def.append(f\"\")\n    for name, _ in fields:\n        cls_def.append(f\"    @property\")\n        cls_def.append(f\"    def {name}(self) -> torch.Tensor:\")\n        cls_def.append(f'        \"\"\"')\n        cls_def.append(f\"        Warning: this is only an approximation of the original method.\")\n        cls_def.append(f'        \"\"\"')\n        cls_def.append(f\"        if self._{name} is None:\")\n        cls_def.append(f\"            raise Exception()\")\n        cls_def.append(f\"        return self._{name}\")\n        cls_def.append(f\"\")\n        cls_def.append(f\"    @{name}.setter\")\n        cls_def.append(f\"    def {name}(self, value: torch.Tensor):\")\n        cls_def.append(f\"        self."}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n\n    # Generate new class\n    cls_name = \"TracedInstances\"\n    lines = [\n        \"import torch\",\n        \"from torch import Tensor\",\n        f\"class {cls_name}:\",\n    ]\n    for name, value in fields:\n        if isinstance(value, list):\n            value = \"[\" + \", \".join([f\"{v}\" for v in value]) + \"]\"\n        elif isinstance(value, str):\n            value = f'\"{value}\"'\n        elif isinstance(value, int):\n            value = f\"{value}\"\n        elif isinstance(value, float):\n            value = f\"{value}\"\n        elif isinstance(value, bool):\n            value = f\"{value}\"\n        elif isinstance(value, dict):\n            value = \"{\" + \", \".join([f\"{k}: {v}\" for k, v in value.items()]) + \"}\"\n        elif isinstance(value, type):\n            value = f\"{value.__name__}\"\n        elif isinstance(value, torch.dtype):\n            value = f\"torch.{value.name}\"\n        elif isinstance(value, torch.device):\n            value = f\"torch.device('{value}')\"\n        elif callable(value):\n            value = f\"{value.__name__}\"\n        else:\n            raise ValueError(f\"Unknown field type: {type(value)}\")\n        lines.append(f\"    {name}: {value} = {value}\")\n    lines.extend(\n        [\n            \"\",\n            \"    def __init__(self, image_size: Tuple[int, int]):\",\n            \"        self.image_size = image_size\",\n            \"        self.fields: Dict[str, Union[Tensor, List[Tensor]]] = {}\",\n            \"\",\n            \"        for name, value in self.__annotations__.items():\",\n            \"            if name == 'image_size':\",\n            \"                continue\",\n            \"            if isinstance(value, List):"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n\n    # generate a new class that has the same name as the original 'Instances' class\n    cls_name = \"Instances\"\n    cls_fields = fields\n    Instances = _import_file(\n        \"detectron2.structures.instances\", \"Instances\", \"Instances\"\n    )\n    cls_dict = {\"__annotations__\": {}, \"__module__\": Instances.__module__}\n    for name, ty in cls_fields:\n        cls_dict[\"__annotations__\"][name] = ty\n\n    # generate a new module, write the new class to it, and import it\n    import_line = \"from torch import Tensor\"\n    cls_txt = (\n        f\"class {cls_name}(Instances):\\n\"\n        + \"    def __init__(self, image_size: Tuple[int, int]):\\n\"\n        + \"        super().__init__()\\n\"\n        + \"        self.image_size = image_size\\n\"\n        + \"    \"\n        + \"\\n    \".join(\n            [\n                f\"    {name}: {ty.__name__}\"\n                for name, ty in cls_fields\n                if ty != Instances\n            ]\n        )\n        + \"\\n\"\n        + \"\\n\".join([f\"    @property\\n    def {name}(self) -> {ty.__name__}:\", f\"        return self.get('{name}')\"])\n        + \"\\n\"\n        + \"\\n\".join(\n            [\n                f\"    @{name}.setter\\n    def {name}(self, {name}):\",\n                f\"        self.set('{name}', {name})\",\n            ]\n        )\n        + \"\\n\"\n        + \"\\n\".join(\n            [\n                f\"    def get_{name}(self) -> {ty.__name__}:\",\n                f\"        return self.get('{name}')\",\n            ]\n        )\n        + \"\\n\"\n        + \"\\n\".join(\n           "}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n\n    # Generate new class\n    cls_name = f\"Instances_{_counter}\"\n    _counter += 1\n    cls_def = (\n        f\"class {cls_name}(\"\n        + \", \".join(f\"{fname}: {ftype.__name__}\" for fname, ftype in fields)\n        + \"):\\n\"\n    )\n    methods = [\n        \"def __init__(self, image_size: List[int]):\\n\"\n        + \"\\n\".join(\n            f\"    self._{fname} = torch.jit.annotate(Optional[Tensor], None)\"\n            for fname, _ in fields\n        )\n        + \"\\n    self.image_size = image_size\\n\",\n        \"def to(self, device: str):\\n\"\n        + \"\\n\".join(\n            f\"    if self._{fname} is not None: self._{fname} = self._{fname}.to(device)\"\n            for fname, _ in fields\n        )\n        + \"\\n    return self\",\n        \"def __len__(self) -> int:\\n\" + \"    return 0\",\n        \"def get_fields(self) -> Dict[str, Tensor]:\\n\"\n        + \"    r = {}\\n\"\n        + \"\\n\".join(\n            f\"    if self._{fname} is not None: r['{fname}'] = self._{fname}\"\n            for fname, _ in fields\n        )\n        + \"\\n    return r\",\n    ]\n    script = cls_def + \"\\n\".join(methods)\n    fd, fname = tempfile.mkstemp(suffix=\".py\", text=True)\n    with os.fdopen(fd, \"w\") as fp:\n        fp.write(script)\n\n    # Import the new class\n    new_module = _import_file(fname, verbose=False)\n    newInstances = getattr(new_module, cls_name)\n    _add_instances_conversion"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n\n    # Create new class\n    cls_name = \"InstancesScriptable\"\n    lines = [\n        \"import torch\",\n        \"from torch import Tensor\",\n        \"import detectron2\",\n        \"from detectron2.structures import Boxes\",\n        \"from detectron2.structures import Instances\",\n        \"\",\n        f\"class {cls_name}:\",\n    ]\n    for name, type_ in fields:\n        lines.append(f\"    _{name}: {type_}\")\n\n    for name in (\"_fields\", \"__len__\"):\n        lines.append(f\"    def {name}(self) -> tuple[str]:\")\n        lines.append(f\"        return ({', '.join(f'self._{name}' for name in self._fields)},)\")\n\n    for name in (\"_has\", \"has\"):\n        lines.append(f\"    def {name}(self, name: str) -> bool:\")\n        lines.append(f\"        return name in self._fields\")\n\n    for name, type_ in fields:\n        lines.append(f\"    @property\")\n        lines.append(f\"    def {name}(self) -> {type_}:\")\n        lines.append(f\"        return self._{name}\")\n\n    for name in (\"set\", \"to\", \"remove\"):\n        lines.append(f\"    def {name}(self, name: str, value):\")\n        lines.append(f\"        self._{name}(name, value)\")\n\n    lines.append(f\"    def to(self, device: torch.device):\")\n    lines.append(\n        f\"        ret = {cls_name}(self.image_size, tuple(f.to(device) for f in self._fields))\")\n    lines.append(f\"        return ret\")\n\n    lines.append(f\"    def __len__(self) -> int:\")\n    lines.append(f\"        return len(self._fields)\")\n\n    lines.append(f\"    def __repr__(self):\")\n    lines.append(f\"       "}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n\n    # generate the new class\n    cls_name = \"InstancesScriptable\"\n    lines = [\n        \"import torch\",\n        \"from torch import Tensor\",\n        \"from detectron2.structures import Instances\",\n        \"class \" + cls_name + \"(Instances):\",\n    ]\n    for name, value in fields:\n        if isinstance(value, list):\n            lines.append(f\"    _{name}: List[{value[0].__name__ if isinstance(value[0], type) else value[0]}] = []\")\n        elif isinstance(value, str):\n            lines.append(f\"    _{name}: {value} = ''\")\n        elif isinstance(value, type):\n            lines.append(f\"    _{name}: {value.__name__} = 0\")\n        else:\n            lines.append(f\"    _{name}: {value.__class__.__name__} = 0\")\n    lines.append(\"\")\n    lines.append(\n        \"    def __init__(self, image_size: Tuple[int, int]):\")\n    lines.append(\"        super().__init__()\")\n    for name, _ in fields:\n        lines.append(f\"        self._{name} = []\")\n    lines.append(\"        self.image_size = image_size\")\n    lines.append(\"\")\n    lines.append(\"    @classmethod\")\n    lines.append(\"    def from_instances(cls, instances: Instances):\")\n    lines.append(\"        ret = cls(instances.image_size)\")\n    for name, _ in fields:\n        lines.append(f\"        ret._{name} = list(instances._{name})\")\n    lines.append(\"        return ret\")\n    lines.append(\"\")\n    lines.append(\"    def to(self, device: str):\")\n    lines.append(\"        ret = super().to(device)\")\n    lines.append(\"        for n in self.fields():\")\n    lines.append(\"            val = self.__getattr__(n)\")"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n\n    # Create a new class that inherits from the original 'Instances' class\n    cls_name = \"InstancesScriptable\"\n    cls_definition = [\n        f\"class {cls_name}(detectron2.structures.Instances):\",\n        \"    def __init__(self, image_size: Tuple[int, int]):\",\n        \"        super().__init__(image_size)\",\n    ]\n    for name, value in fields:\n        cls_definition.append(f\"        self._{name} = torch.jit.Attribute([], {value})\")\n\n    # Write the new class definition to a temporary file\n    with tempfile.TemporaryDirectory() as dir, tempfile.NamedTemporaryFile(\n        mode=\"w\", dir=dir, suffix=\".py\", delete=False\n    ) as f:\n        module_name = os.path.basename(f.name[: -len(\".py\")])\n        f.write(\"\\n\".join(cls_definition))\n\n    # Import the temporary module\n    sys.path.insert(0, dir)\n    module = _import_file(f.name, module_name)\n\n    # Register the new class\n    newInstances = getattr(module, cls_name)\n    _add_instances_conversion_methods(newInstances)\n\n    # Yield the new class\n    yield newInstances\n\n    # Cleanup\n    sys.path.remove(dir)\n    del sys.modules[module_name]\n    os.remove(f.name)\n    _counter -= 1\n    if _counter == 0:\n        _clear_jit_cache()\n\n"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n\n    # create new class\n    cls_name = f\"Instances_{_counter}\"\n    _counter += 1\n    newInstances = type(cls_name, (Instances,), fields)\n\n    # add conversion methods\n    _add_instances_conversion_methods(newInstances)\n\n    # create temporary file to store new class\n    with tempfile.TemporaryDirectory() as dir, ExitStack() as stack:\n        # create temporary file\n        fd, f_name = tempfile.mkstemp(dir=dir)\n        os.close(fd)\n        f_name += \".py\"\n\n        # write new class to file\n        with open(f_name, \"w\") as f:\n            f.write(f\"class {cls_name}(\")\n            f.write(\", \".join([cls.__name__ for cls in newInstances.mro()]))\n            f.write(\"):\\n\")\n            for name, val in fields.items():\n                if isinstance(val, property):\n                    f.write(f\"    @property\\n\")\n                    f.write(f\"    def {name}(self) -> {val.annotation}:\\n\")\n                    f.write(f\"        return self._{name}\\n\")\n                else:\n                    f.write(f\"    {name}: {val.__class__.__name__}\\n\")\n                f.write(\"\\n\")\n\n        # import class from file\n        module = _import_file(f_name, verbose=False)\n        newInstances = getattr(module, cls_name)\n\n        # add new class to detectron2's globals\n        stack.enter_context(mock.patch.object(detectron2.structures, \"Instances\", newInstances))\n        stack.enter_context(\n            mock.patch.dict(sys.modules, {\"detectron2.structures\": detectron2.structures})\n        )\n\n        yield newInstances"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n\n    # Create new class\n    cls_name = \"TracedInstances\"\n    d = {\"__annotations__\": {}, \"__slots__\": [\"_image_size\"] + fields}\n    d[\"__annotations__\"][\"_image_size\"] = torch.Size\n    for name, typ in fields:\n        d[\"__annotations__\"][name] = typ\n        d[\"__slots__\"].append(name)\n    newInstances = type(cls_name, (Instances,), d)\n    _add_instances_conversion_methods(newInstances)\n\n    # Write new class to file\n    tmp_dir = tempfile.gettempdir()  # TODO: provide option to set directory\n    tmp_file_name = \"instances_cls\" + str(_counter) + \".py\"\n    tmp_file_path = os.path.join(tmp_dir, tmp_file_name)\n    with open(tmp_file_path, \"w\") as f:\n        f.write(f\"import torch\\nclass {cls_name}(Instances):\\n\")\n        for name, typ in fields:\n            f.write(f\"    {name}: {typ} = None\\n\")\n        f.write(f\"{cls_name}.script_name = {repr(tmp_file_name)}\\n\")\n\n    # Import class from file\n    module = _import_file(tmp_file_path, verbose=False)\n    newInstances = getattr(module, cls_name)\n\n    # Patch 'Instances'\n    oldInstances = Instances\n    sys.modules[\"detectron2.structures.instances\"] = mock.Mock()\n    sys.modules[\"detectron2.structures.instances\"].Instances = newInstances\n    sys.modules[\"detectron2.structures.instances\"]._cache_Instances = lambda: newInstances\n    sys.modules[\"detectron2.structures.instances\"]._jit_override = True\n\n    # Run context\n    try:\n       "}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n\n    # get the original 'Instances' class\n    oldInstances = _import_file(\"detectron2.structures.instances\").Instances\n\n    # make a new class that inherits from the original 'Instances' class\n    newInstances = type(f\"Instances{_counter}\", (oldInstances,), {})\n\n    # add the fields to the new class\n    for field in fields:\n        assert isinstance(\n            field, tuple\n        ), \"Each field must be a tuple of the form (name, type, default_value)\"\n        assert len(field) == 3, \"Each field must be a tuple of length 3\"\n        name, type_, default = field\n        setattr(newInstances, name, type_)\n        setattr(newInstances, f\"_{name}\", default)\n\n    # add from_instances conversion methods\n    _add_instances_conversion_methods(newInstances)\n\n    # make the new class scriptable\n    torch.jit.script(newInstances)\n\n    # write the new class to a temporary file\n    fd, fname = tempfile.mkstemp(\n        suffix=\".py\", prefix=f\"detectron2_scriptable_instances_{_counter}\", text=True\n    )\n    with open(fname, \"w\") as f:\n        f.write(newInstances.__source__)\n\n    # increment the counter so that the next call to this function will use a different file name\n    _counter += 1\n\n    # import the new class from the temporary file\n    sys.path.insert(0, os.path.dirname(fname))\n    newInstances = _import_file(fname).Instances\n\n    # clean up the temporary file\n    os.close(fd)\n    os.remove(fname)\n\n    # monkey-patch the 'Instances' class to be the new class\n    old_modules = {}\n    for module in detectron2.structures.__all__:\n        m = _import_file(f\"detectron2.structures.{module}\")\n        old"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n    # Define a new class that inherits from 'Instances'\n    newInstances = type(f\"Instances_{_counter}\", (Instances,), fields)\n    _add_instances_conversion_methods(newInstances)\n    # Write the class to a file\n    fd, fname = tempfile.mkstemp(suffix=\".py\", prefix=f\"detectron2_instances_{_counter}\")\n    try:\n        with os.fdopen(fd, \"w\") as f:\n            f.write(f\"class {newInstances.__name__}(Instances):\\n\")\n            for name, val in fields.items():\n                if name.startswith(\"_\"):\n                    continue\n                f.write(f\"    {name}: {val.__class__.__name__}\\n\")\n        # Import the class from the file\n        module = _import_file(fname, verbose=False)\n        newInstances = getattr(module, newInstances.__name__)\n        # Patch the class into detectron2\n        with ExitStack() as stack:\n            # Disable the caching layer to avoid potential side effects\n            stack.enter_context(_patch_module(detectron2, \"jit_caching_layer\", lambda x: x))\n            # Replace the class\n            stack.enter_context(_patch_module(detectron2.structures, \"Instances\", newInstances))\n            # Replace the class in torchvision\n            if \"torchvision\" in sys.modules:\n                stack.enter_context(_patch_module(sys.modules[\"torchvision\"].ops.boxes, \"Instances\", newInstances))\n            yield newInstances\n    finally:\n        os.remove(fname)\n\n"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n    if _counter > 1:\n        return Instances\n\n    with tempfile.TemporaryDirectory(prefix=\"detectron2\") as dir, ExitStack() as stack:\n        # Write the Instances class to a file\n        module_name = \"instances\"\n        code = \"\"\""}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    import detectron2\n\n    # get path to Instances class\n    instances_path = str(inspect.getfile(detectron2.structures.instances.Instances))\n\n    # define the new Instances class\n    lines = [\n        \"from detectron2.structures import Boxes\",\n        \"import torch\",\n        \"\",\n        \"class Instances:\",\n    ]\n    for name, type_ in fields:\n        lines.append(f\"    {name}: {type_}\")\n\n    # add the from_instances method\n    lines.append(\n        \"\"\"    @torch.jit.unused\n    @staticmethod\n    def from_instances(instances: Instances):\n        fields = instances.get_fields()\n        image_size = instances.image_size\n        ret = Instances(image_size)\n        for name, val in fields.items():\n            assert hasattr(ret, f'_{name}'), f'No attribute named {name} in Instances'\n            setattr(ret, name, deepcopy(val))\n        return ret\"\"\"\n    )\n\n    # write the new class to a file\n    tmp_dir = tempfile.gettempdir()\n    name = \"instances\" + str(_counter)\n    _counter += 1\n    path = os.path.join(tmp_dir, name + \".py\")\n    with open(path, \"w\") as f:\n        f.write(\"\\n\".join(lines))\n\n    # add the path to sys.path\n    sys.path.append(tmp_dir)\n    with ExitStack() as stack:\n        # import the module\n        new_module = _import_file(name, tmp_dir)\n        # register the Instances class\n        stack.enter_context(mock.patch.object(detectron2.structures.instances, \"Instances\", new_module.Instances))\n        # add the from_instances method\n        _add_instances_conversion_methods(new_module.Instances)\n        # run the context\n        yield\n\n    # clean up\n   "}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    # import here to avoid depending on torchvision in main module\n    import torchvision\n\n    # Create the new class\n    cls_name = \"NewInstances\"\n    NewInstances = type(\n        cls_name,\n        (torchvision.ops.Instances,),\n        {\n            name: torch.jit.annotate(ty, None)\n            for name, ty in fields\n            if name not in (\"image_size\", \"proposal_boxes\")\n        },\n    )\n    NewInstances.__module__ = \"detectron2.structures\"\n    NewInstances.__qualname__ = \"Instances\"\n    _add_instances_conversion_methods(NewInstances)\n\n    # Write the new class to a file\n    with tempfile.TemporaryDirectory() as dir, ExitStack() as stack:\n        path = os.path.join(dir, f\"tmp_mod_{_counter}.py\")\n        _counter += 1\n        with open(path, \"w\") as f:\n            # The class must be in a module to be scripted\n            f.write(f\"class {cls_name}:\\n\")\n            for name, ty in fields:\n                f.write(f\"    {name}: {ty} = ...\\n\")\n\n            f.write(f\"    image_size: {torch.jit.Future[torch.Size]}\")\n            f.write(\n                f\"    proposal_boxes: {torch.jit.Future[Boxes]}\"\n            )  # Boxes is not scriptable\n            f.write(\"\\n\")\n            f.write(f\"    def __init__(self, image_size: torch.Size): ...\\n\")\n            f.write(f\"    def to(self, *args, **kwargs) -> {cls_name}: ...\\n\")\n            f.write(f\"    def __getitem__(self, i: int) -> {cls_name}: ...\\n\")\n            f.write(f\"    def __len__(self) -> int: ...\\n\")\n           "}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n\n    # Create new Instances class\n    cls_name = \"InstancesScriptable\"\n    fields = deepcopy(fields)\n    for i, (name, type_) in enumerate(fields):\n        if type_ not in [torch.Tensor, BoxMode, Boxes]:\n            raise ValueError(f\"Unsupported field type {type_}\")\n        if type_ is torch.Tensor:\n            fields[i] = (name, torch.Tensor)\n    InstancesScriptable = Instances.create_class_with_fields(fields, cls_name)\n    InstancesScriptable.__name__ = cls_name\n\n    # Add from_instances method\n    _add_instances_conversion_methods(InstancesScriptable)\n\n    # Write class to file\n    fd, path = tempfile.mkstemp(suffix=\".py\", prefix=f\"instances_patch_{_counter}\")\n    with ExitStack() as stack:\n        stack.enter_context(open(fd, \"w\", encoding=\"utf-8\"))\n        stack.enter_context(mock.patch(\"detectron2.structures.instances.Instances\", InstancesScriptable))\n        stack.enter_context(mock.patch(\"detectron2.structures.boxes.Boxes\", Boxes))\n        stack.enter_context(mock.patch(\"detectron2.structures.boxes.BoxMode\", BoxMode))\n        stack.enter_context(_patch_instances_fields())\n        stack.enter_context(_patch_instances_boxes())\n        stack.enter_context(_patch_instances_boxes_compat())\n        stack.enter_context(_patch_instances_boxes_py2())\n        stack.enter_context(_patch_instances_boxes_py3())\n        stack.enter_context(_patch_instances_boxes_py3_compat())\n        stack.enter_context(_patch_instances_boxes_py3_compat2())\n        stack.enter_context(_patch_instances_boxes_py3_compat"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n\n    # generate a temporary file to write the new module to\n    with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as f:\n        # generate the module code\n        module_code = f\"\"\""}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n\n    # generate the new class\n    cls_name = \"InstancesScriptable\"\n    lines = [\"import torch\"]\n    for name, value in fields:\n        lines.append(f\"class {name}:\")\n        if isinstance(value, list):\n            lines.append(f\"    value: {value.__class__.__name__} = {value}\")\n        elif isinstance(value, (int, float, bool, str)):\n            lines.append(f\"    value: {value.__class__.__name__} = {value}\")\n        else:\n            lines.append(f\"    value: {value.__name__} = {value.__name__}\")\n    source = \"\\n\".join(lines)\n\n    # write the source code to a file\n    with tempfile.TemporaryDirectory() as dir_name:\n        file_path = os.path.join(dir_name, f\"{cls_name}.py\")\n        with open(file_path, \"w\") as f:\n            f.write(source)\n\n        # import the file as a new module\n        module = _import_file(file_path, report_package=cls_name)\n\n        # get the generated class\n        newInstances = getattr(module, cls_name)\n\n        # add from_instances method\n        _add_instances_conversion_methods(newInstances)\n\n        # register the new class as a sub-class of Instances\n        Instances.__bases__ = (newInstances,)\n\n        # set up environment to use the new class\n        old_imports = sys.modules.copy()\n        old_path = sys.path.copy()\n        sys.modules.pop(module.__name__, None)  # remove the old module\n        sys.path.remove(dir_name)  # remove the directory from the pythonpath\n\n        yield newInstances\n\n        # cleanup environment\n        sys.modules.pop(module.__name__, None)  # remove the old module\n        sys.path = old_path  # restore the pythonpath\n        sys.modules.update(old_"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n    if _counter > 1:\n        return Instances\n\n    fields = deepcopy(fields)\n    for field in fields:\n        assert isinstance(field, tuple) and len(field) == 2, field\n\n    # Create a new class\n    cls_name = \"Instances_script\"\n    lines = [\"class Instances_script(Instances):\"]\n    for name, type_ in fields:\n        lines.append(f\"    {name}: {type_}\")\n\n    body = \"\\n\".join(lines)\n    # print(body)\n    # print(Instances.__module__)\n    with tempfile.NamedTemporaryFile(\n        \"w\", suffix=\".py\", delete=False, prefix=cls_name\n    ) as f:\n        f.write(body)\n        f.flush()\n        f.close()\n        tgt_mod = f\"{cls_name}.py\"\n        tgt_cls = cls_name\n        module = _import_file(f.name, verbose=False)\n\n    # Replace the class in the 'detectron2.structures' module\n    m_name = \"detectron2.structures\"\n    tgt_full_cls = m_name + \".\" + tgt_cls\n    src_cls = m_name + \".Instances\"\n    sys.modules[m_name] = _patch_module(module, tgt_full_cls, src_cls)\n    _clear_jit_cache()\n\n    # Now that the class is properly defined in the module, we can import it\n    newInstances = _import_file(f.name, verbose=False).Instances_script\n    _add_instances_conversion_methods(newInstances)\n\n    # Remove temporary file\n    os.remove(f.name)\n\n    # Patch other modules that use Instances\n    for m in (\"detectron2.modeling.roi_heads.mask_head\",):\n        _patch_module(\n            sys.modules[m], tgt_full_cls, src_cls"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        # work around this bug: https://github.com/python-pillow/Pillow/issues/3973\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n\n        # work around this bug: https://github.com/python-pillow/Pillow/issues/3973\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n\n        # work around this bug: https://github.com/python-pillow/Pillow/issues/3973\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n\n        # work around this bug: https://github.com/python-pillow/Pillow/issues/3973\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        # work around this bug: https://github.com/python-pillow/Pillow/issues/3973\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        # work around this bug: https://github.com/python-pillow/Pillow/issues/3973\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        # work around this bug: https://github.com/python-pillow/Pillow/issues/3973\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        # work around this bug: https://github.com/python-pillow/Pillow/issues/3973\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n\n        # work around this bug: https://github.com/python-pillow/Pillow/issues/3973\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n\n        # work around this bug: https://github.com/python-pillow/Pillow/issues/3973\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        # work-around for this bug: https://github.com/python-pillow/Pillow/issues/3973\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        # work around this bug: https://github.com/python-pillow/Pillow/issues/3973\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        if format is not None:\n            image = _apply_exif_orientation(image)\n            image = convert_PIL_to_numpy(image, format)\n        else:\n            image = np.array(image)\n\n    return image\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        # work around this bug: https://github.com/python-pillow/Pillow/issues/3973\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n\n        # work around this bug: https://github.com/python-pillow/Pillow/issues/3973\n        image = _apply_exif_orientation(image)\n\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        if format is not None:\n            image = image.convert(format)\n        # work around this bug: https://github.com/python-pillow/Pillow/issues/3973\n        image = _apply_exif_orientation(image)\n        image = np.asarray(image)\n    return image\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        # work around this bug: https://github.com/python-pillow/Pillow/issues/3973\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        format = format or image.format\n\n        if format == \"JPEG\" or format == \"PNG\" or format == \"TIFF\":\n            # handle rotations\n            image = _apply_exif_orientation(image)\n\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n\n        # work around this bug: https://github.com/python-pillow/Pillow/issues/3973\n        image = _apply_exif_orientation(image)\n\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if isinstance(transforms, (tuple, list)):\n        transforms = T.TransformList(transforms)\n    # bbox is 1d (per-instance bounding box)\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # clip transformed bbox to image size\n    bbox = transforms.apply_box([bbox])[0].clip(min=0)\n    annotation[\"bbox\"] = np.minimum(bbox, list(image_size + image_size)[::-1])\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    if \"segmentation\" in annotation:\n        # each instance contains 1 or more polygons\n        segm = annotation[\"segmentation\"]\n        if isinstance(segm, list):\n            # polygons\n            polygons = [np.asarray(p).reshape(-1, 2) for p in segm]\n            annotation[\"segmentation\"] = [\n                p.reshape(-1) for p in transforms.apply_polygons(polygons)\n            ]\n        elif isinstance(segm, dict):\n            # RLE\n            mask = mask_util.decode(segm)\n            mask = transforms.apply_segmentation(mask)\n            assert tuple(mask.shape[:2]) == image_size\n            annotation[\"segmentation\"] = mask\n        else:\n            raise ValueError(\n                \"Cannot transform segmentation of type '{}'!\"\n                \"Supported types are: polygons as list[list[float] or ndarray],\"\n                \" COCO-style RLE as a dict.\".format(type(segm))\n            )\n\n    if \"keypoints\" in annotation:\n        keypoints = transform_keypoint_annotations(\n            annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # Note that bbox is 1d (per-instance bounding box)\n    annotation[\"bbox\"] = transforms.apply_box([bbox])[0]\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    if \"segmentation\" in annotation:\n        # each instance contains 1 or more polygons\n        segm = annotation[\"segmentation\"]\n        if isinstance(segm, list):\n            # polygons\n            polygons = [np.asarray(p).reshape(-1, 2) for p in segm]\n            annotation[\"segmentation\"] = [\n                p.reshape(-1) for p in transforms.apply_polygons(polygons)\n            ]\n        elif isinstance(segm, dict):\n            # RLE\n            mask = mask_util.decode(segm)\n            mask = transforms.apply_segmentation(mask)\n            assert tuple(mask.shape[:2]) == image_size\n            annotation[\"segmentation\"] = mask\n        else:\n            raise ValueError(\n                \"Cannot transform segmentation of type '{}'!\"\n                \"Supported types are: polygons as list[list[float] or ndarray],\"\n                \" COCO-style RLE as a dict.\".format(type(segm))\n            )\n\n    if \"keypoints\" in annotation:\n        keypoints = transform_keypoint_annotations(\n            annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # Note that bbox is 1d (per-instance bounding box)\n    annotation[\"bbox\"] = transforms.apply_box([bbox])[0]\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # use_instance_mask = \"segmentation\" in annotation\n    # if use_instance_mask:\n    #     # each instance contains 1 or more polygons\n    #     segm = annotation[\"segmentation\"]\n    #     if isinstance(segm, list):\n    #         # polygons\n    #         polygons = [np.asarray(p).reshape(-1, 2) for p in segm]\n    #         annotation[\"segmentation\"] = [\n    #             p.reshape(-1) for p in transforms.apply_polygons(polygons)\n    #         ]\n    #     elif isinstance(segm, dict):\n    #         # RLE\n    #         mask = mask_util.decode(segm)\n    #         mask = transforms.apply_segmentation(mask)\n    #         assert tuple(mask.shape[:2]) == image_size\n    #         annotation[\"segmentation\"] = mask\n    #     else:\n    #         raise ValueError(\n    #             \"Cannot transform segmentation of type '{}'!\"\n    #             \"Supported types are: polygons as list[list[float] or ndarray],\"\n    #             \" COCO-style RLE as a dict.\".format(type(segm))\n    #         )\n\n    # use_keypoint = \"keypoints\" in annotation\n    # if use_keypoint:\n    #     keypoints = transform_keypoint_annotations(\n    #         annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n    #     )\n    #     annotation[\"keypoints\"] = keypoints\n\n    # if \"beziers\" in annotation:\n    #     beziers ="}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # Note that bbox is 1d (per-instance bounding box)\n    annotation[\"bbox\"] = transforms.apply_box([bbox])[0]\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    if \"segmentation\" in annotation:\n        # each instance contains 1 or more polygons\n        segm = annotation[\"segmentation\"]\n        if isinstance(segm, list):\n            # polygons\n            polygons = [np.asarray(p).reshape(-1, 2) for p in segm]\n            annotation[\"segmentation\"] = [\n                p.reshape(-1) for p in transforms.apply_polygons(polygons)\n            ]\n        elif isinstance(segm, dict):\n            # RLE\n            mask = mask_util.decode(segm)\n            mask = transforms.apply_segmentation(mask)\n            assert tuple(mask.shape[:2]) == image_size\n            annotation[\"segmentation\"] = mask\n        else:\n            raise ValueError(\n                \"Cannot transform segmentation of type '{}'!\"\n                \"Supported types are: polygons as list[list[float] or ndarray],\"\n                \" COCO-style RLE as a dict.\".format(type(segm))\n            )\n\n    if \"keypoints\" in annotation:\n        keypoints = transform_keypoint_annotations(\n            annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    bbox = BoxMode.convert(\n        annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # Note that bbox is 1d (per-instance bounding box)\n    annotation[\"bbox\"] = transforms.apply_box([bbox])[0]\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    if \"segmentation\" in annotation:\n        # each instance contains 1 or more polygons\n        segm = annotation[\"segmentation\"]\n        if isinstance(segm, list):\n            # polygons\n            polygons = [np.asarray(p).reshape(-1, 2) for p in segm]\n            annotation[\"segmentation\"] = [\n                p.reshape(-1) for p in transforms.apply_polygons(polygons)\n            ]\n        elif isinstance(segm, dict):\n            # RLE\n            mask = mask_util.decode(segm)\n            mask = transforms.apply_segmentation(mask)\n            assert tuple(mask.shape[:2]) == image_size\n            annotation[\"segmentation\"] = mask\n        else:\n            raise ValueError(\n                \"Cannot transform segmentation of type '{}'!\"\n                \"Supported types are: polygons as list[list[float] or ndarray],\"\n                \" COCO-style RLE as a dict.\".format(type(segm))\n            )\n\n    if \"keypoints\" in annotation:\n        keypoints = transform_keypoint_annotations(\n            annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Convert bounding boxes to XYXY_ABS\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # Note that bbox is 1d (per-instance bounding box)\n    annotation[\"bbox\"] = transforms.apply_box([bbox])[0]\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Continue transformation on segmentation polygons\n    polygons = [np.asarray(p).reshape(-1, 2) for p in annotation[\"segmentation\"]]\n    annotation[\"segmentation\"] = [p.reshape(-1) for p in transforms.apply_polygons(polygons)]\n\n    # Continue transformation on keypoints\n    keypoints = transform_keypoint_annotations(\n        annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n    )\n    annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Subtract 1 because RLE starts from 1 (not 0), but the \"boxes\" in the json starts from 0.\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # clip transformed bbox to image size\n    bbox = transforms.apply_box([bbox])[0].clip(min=0)\n    annotation[\"bbox\"] = np.minimum(bbox, list(image_size + image_size)[::-1])\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    if \"segmentation\" in annotation:\n        # each instance contains 1 or more polygons\n        segm = annotation[\"segmentation\"]\n        if isinstance(segm, list):\n            # polygons\n            polygons = [np.asarray(p).reshape(-1, 2) for p in segm]\n            annotation[\"segmentation\"] = [\n                p.reshape(-1) for p in transforms.apply_polygons(polygons)\n            ]\n        elif isinstance(segm, dict):\n            # RLE\n            mask = mask_util.decode(segm)\n            mask = transforms.apply_segmentation(mask)\n            assert tuple(mask.shape[:2]) == image_size\n            annotation[\"segmentation\"] = mask\n        else:\n            raise ValueError(\n                \"Cannot transform segmentation of type '{}'!\"\n                \"Supported types are: polygons as list[list[float] or ndarray],\"\n                \" COCO-style RLE as a dict.\".format(type(segm))\n            )\n\n    if \"keypoints\" in annotation:\n        keypoints = transform_keypoint_annotations(\n            annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # Note that bbox is 1d (per-instance bounding box)\n    annotation[\"bbox\"] = transforms.apply_box([bbox])[0]\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # use_instance_mask is deprecated.\n    if annotation.get(\"segmentation\", None):\n        # TODO: really need to make transformation deterministic\n        if isinstance(annotation[\"segmentation\"], list):\n            # polygon\n            for polygons in annotation[\"segmentation\"]:\n                polygons = [transforms.apply_coords(polygon) for polygon in polygons]\n            annotation[\"segmentation\"] = [\n                torch.tensor(polygons, dtype=torch.float32) for polygons in annotation[\"segmentation\"]\n            ]\n        elif isinstance(annotation[\"segmentation\"], dict):\n            # RLE\n            mask = mask_util.decode(annotation[\"segmentation\"])\n            mask = transforms.apply_segmentation(mask)\n            assert tuple(mask.shape[:2]) == image_size\n            annotation[\"segmentation\"] = mask\n        else:\n            raise ValueError(\n                \"Cannot transform segmentation of type '{}'!\"\n                \"Supported types are: polygons as list[list[float] or ndarray],\"\n                \" COCO-style RLE as a dict.\".format(type(annotation[\"segmentation\"]))\n            )\n\n    if annotation.get(\"keypoints\", None):\n        keypoints = transform_keypoint_annotations(\n            annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    bbox = BoxMode.convert(\n        annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS\n    )\n    # Note that bbox is 1d (per-instance bounding box)\n    annotation[\"bbox\"] = transforms.apply_box([bbox])[0]\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # use_instance_mask is deprecated\n    # assert \"segmentation\" in annotation\n    # if \"segmentation\" in annotation:\n    #     # each instance contains 1 or more polygons\n    #     if isinstance(annotation[\"segmentation\"], list):\n    #         polygons = [np.asarray(p).reshape(-1, 2) for p in annotation[\"segmentation\"]]\n    #         annotation[\"segmentation\"] = [\n    #             p.reshape(-1) for p in transforms.apply_polygons(polygons)\n    #         ]\n    #     # else:\n    #     #     raise NotImplementedError\n\n    # if \"keypoints\" in annotation:\n    #     keypoints = transform_keypoint_annotations(\n    #         annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n    #     )\n    #     annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # Note that bbox is 1d (per-instance bounding box)\n    annotation[\"bbox\"] = transforms.apply_box([bbox])[0]\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # each instance contains 1 or more polygons\n    if \"segmentation\" in annotation:\n        # polygons = [\n        #     torch.tensor(p, dtype=torch.float32)\n        #     for p in annotation[\"segmentation\"]\n        # ]\n        polygons = [\n            torch.as_tensor(p, dtype=torch.float32)\n            for p in annotation[\"segmentation\"]\n        ]\n        annotation[\"segmentation\"] = [\n            p.clip_to_image(remove_empty=True) for p in polygons\n        ]\n        # transform_polygons_to_rects(polygons, transforms, image_size)\n\n    if \"keypoints\" in annotation:\n        keypoints = transform_keypoint_annotations(\n            annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # Note that bbox is 1d (per-instance bounding box)\n    annotation[\"bbox\"] = transforms.apply_box([bbox])[0]\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # use_instance_mask is for Zhu's code\n    if annotation.get(\"segmentation\", None):\n        # TODO: make this more general\n        if isinstance(annotation[\"segmentation\"], list):\n            # polygons\n            polygons = [np.asarray(p).reshape(-1, 2) for p in annotation[\"segmentation\"]]\n            annotation[\"segmentation\"] = [\n                p.reshape(-1) for p in transforms.apply_polygons(polygons)\n            ]\n        elif isinstance(annotation[\"segmentation\"], dict):\n            # RLE\n            mask = mask_util.decode(annotation[\"segmentation\"])\n            mask = transforms.apply_segmentation(mask)\n            assert tuple(mask.shape[:2]) == image_size\n            annotation[\"segmentation\"] = mask\n        else:\n            raise ValueError(\n                \"Cannot transform segmentation of type '{}'!\"\n                \"Supported types are: polygons as list[list[float] or ndarray],\"\n                \" COCO-style RLE as a dict.\".format(type(annotation[\"segmentation\"]))\n            )\n\n    if annotation.get(\"keypoints\", None):\n        keypoints = np.array(annotation[\"keypoints\"]).reshape(-1, 3)\n        keypoints[:, :2] = transforms.apply_coords(keypoints[:, :2])\n        # TODO: keypoint transforms\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Convert bounding boxes to XYXY_ABS format\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # Note that bbox is 1d (per-instance bounding box)\n    annotation[\"bbox\"] = transforms.apply_box([bbox])[0]\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Continue transformation of bounding box, segmentation, and keypoints\n    # Apply transformations to segmentation polygons\n    if \"segmentation\" in annotation:\n        # Transform polygon segmentation to binary mask\n        if isinstance(annotation[\"segmentation\"], list):\n            # polygons\n            polygons = [np.asarray(p).reshape(-1, 2) for p in annotation[\"segmentation\"]]\n            annotation[\"segmentation\"] = [\n                p.reshape(-1) for p in transforms.apply_polygons(polygons)\n            ]\n        elif isinstance(annotation[\"segmentation\"], dict):\n            # RLE\n            mask = mask_util.decode(annotation[\"segmentation\"])\n            mask = transforms.apply_segmentation(mask)\n            assert tuple(mask.shape[:2]) == image_size\n            annotation[\"segmentation\"] = mask\n        else:\n            raise ValueError(\n                \"Cannot transform segmentation of type '{}'!\"\n                \"Supported types are: polygons as list[list[float] or ndarray],\"\n                \" COCO-style RLE as a dict.\".format(type(annotation[\"segmentation\"]))\n            )\n\n    # Apply transformations to keypoints\n    if \"keypoints\" in annotation:\n        keypoints = transform_keypoints(\n            annotation[\"keypoints\"],\n            transforms,\n            image_size,\n            keypoint_hflip_indices,\n        )\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Convert bounding boxes to XYXY_ABS format\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # Note that bbox is a single list of [x0, y0, x1, y1]\n    # and will be converted to an ndarray of float32.\n    annotation[\"bbox\"] = transforms.apply_box([bbox])[0].clip(min=0)\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Apply transformations to segmentation polygons\n    if \"segmentation\" in annotation:\n        # either polygons or RLE format\n        polygons = annotation[\"segmentation\"]\n        annotation[\"segmentation\"] = transforms.apply_polygons(polygons)\n\n    # Apply transformations to keypoints\n    if \"keypoints\" in annotation:\n        keypoints = transforms.apply_coords(annotation[\"keypoints\"])\n        annotation[\"keypoints\"] = keypoints\n\n    # Apply transformations to keypoints\n    if \"keypoints_3d\" in annotation:\n        keypoints_3d = transforms.apply_coords(annotation[\"keypoints_3d\"])\n        annotation[\"keypoints_3d\"] = keypoints_3d\n\n    # Apply transformations to camera\n    if \"camera\" in annotation:\n        camera = transforms.apply_coords(annotation[\"camera\"])\n        annotation[\"camera\"] = camera\n\n    # Apply transformations to intrinsics\n    if \"intrinsics\" in annotation:\n        intrinsics = transforms.apply_coords(annotation[\"intrinsics\"])\n        annotation[\"intrinsics\"] = intrinsics\n\n    # Apply transformations to extrinsics\n    if \"extrinsics\" in annotation:\n        extrinsics = transforms.apply_coords(annotation[\"extrinsics\"])\n        annotation[\"extrinsics\"] = extrinsics\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Convert bounding boxes to XYXY_ABS format\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # Note that bbox is a list of float which contains the bounding box coordinates\n    annotation[\"bbox\"] = transforms.apply_box([bbox])[0]\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Apply transformations to segmentation polygons\n    if \"segmentation\" in annotation:\n        # Transform polygon segmentation to binary mask\n        if isinstance(annotation[\"segmentation\"], list):\n            # polygon\n            masks = PolygonMasks([annotation[\"segmentation\"]])\n        else:\n            # COCO RLE\n            masks = mask_util.decode(annotation[\"segmentation\"])\n        # apply transforms on masks\n        masks = torch.from_numpy(masks.to_tensor().numpy())\n        masks = transforms.apply_segmentation(masks.to(dtype=torch.float32))\n        # convert binary masks to polygons\n        polygons = masks_to_polygons(masks)\n        annotation[\"segmentation\"] = [p for p in polygons if p.shape[0] >= 6]\n\n    # Apply transformations to keypoints\n    if \"keypoints\" in annotation:\n        keypoints = transform_keypoint_annotations(\n            annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Convert bounding boxes to XYXY_ABS format\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # Note that bbox is a normalized coordinate format in [0, 1]\n    annotation[\"bbox\"] = transforms.apply_box([bbox])[0]\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Apply transformations to segmentation polygons\n    for object_id in range(len(annotation[\"segmentation\"])):\n        # Load segmentation polygons\n        polygons = [np.array(p, dtype=np.float64) for p in annotation[\"segmentation\"][object_id]]\n        # Clip polygons to image bbox\n        clip_box = transforms.apply_box([np.array(image_size)])[0].flatten()\n        polygons = clip_boxes([polygons], clip_box).tolist()\n        # Apply transformations to polygons\n        polygons = [p.reshape(-1, 2) for p in transforms.apply_coords(polygons)]\n        annotation[\"segmentation\"][object_id] = [p.flatten().tolist() for p in polygons]\n\n    # Apply transformations to keypoints\n    if \"keypoints\" in annotation:\n        keypoints = transform_keypoint_annotations(\n            annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Ensure bounding box is valid, and transform otherwise\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    if transforms.box_in_clip_area(bbox, image_size):\n        annotation[\"bbox\"] = transforms.apply_box([bbox])[0].clip(min=0)\n        annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n    else:\n        annotation.pop(\"bbox\", None)\n        annotation.pop(\"bbox_mode\", None)\n\n    # Ensure segmentation polygons are valid, and transform otherwise\n    if \"segmentation\" in annotation:\n        # Transform polygon annotations of this instance to the target format (from dict to list of list of float)\n        polygons = [np.asarray(p).flatten().tolist() for p in annotation[\"segmentation\"]]\n        annotation[\"segmentation\"] = [\n            transforms.apply_polygons(p) for p in polygons\n        ]\n\n        # Remove invalid polygons (< 3 points)\n        annotation[\"segmentation\"] = [\n            p for p in annotation[\"segmentation\"] if len(p) >= 6\n        ]\n\n    # Ensure keypoints are valid, and transform otherwise\n    if \"keypoints\" in annotation:\n        keypoints = transform_keypoint_annotations(\n            annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Convert bounding boxes to XYXY_ABS format\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # Note that bbox is a single list of [x0, y0, x1, y1]\n    # and not a list of list as it is in the instance annotations.\n    annotation[\"bbox\"] = transforms.apply_box([bbox])[0]\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Apply transformations to segmentation polygons\n    if \"segmentation\" in annotation:\n        # currently only supports the segmentation polygons encoded as polygons\n        polygons = [np.asarray(p).reshape(-1, 2) for p in annotation[\"segmentation\"]]\n        annotation[\"segmentation\"] = [p.reshape(-1) for p in transforms.apply_polygons(polygons)]\n\n    # Apply transformations to keypoints\n    if \"keypoints\" in annotation:\n        keypoints = transform_keypoint_annotations(\n            annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n        )\n        annotation[\"keypoints\"] = keypoints\n\n    # Apply transformations to instance masks\n    if \"masks\" in annotation:\n        # Masks are already converted to bitmasks\n        masks = annotation[\"masks\"]\n        masks = torch.from_numpy(masks)\n        # TODO: make this more general\n        if transforms.transforms:\n            if \"RandomRotation\" in transforms.transforms[0].__class__.__name__:\n                masks = torch.from_numpy(polygons_to_bitmask(masks.numpy(), *image_size))\n        masks = torch.stack([transforms.apply_image(mask) for mask in masks])\n        annotation[\"masks\"] = masks.numpy()\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Convert bounding boxes to XYXY_ABS format\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # Note that bbox is a list of box corners, not the box centers\n    annotation[\"bbox\"] = transforms.apply_box([bbox])[0]\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Apply transformations to segmentation polygons\n    if \"segmentation\" in annotation:\n        # Load polygons/masks and apply transformations\n        polygons = PolygonInstance.polygons_to_bitmask(\n            annotation[\"segmentation\"], *image_size\n        )\n        polygons = transforms.apply_polygons(polygons)\n        # Split the transformed polygons to the new \"segmentation\" field\n        annotation[\"segmentation\"] = PolygonInstance.bitmasks_to_polygons(\n            polygons, *image_size\n        )\n\n    # Apply transformations to keypoints\n    if \"keypoints\" in annotation:\n        keypoints = transforms.apply_coords(annotation[\"keypoints\"])\n        annotation[\"keypoints\"] = keypoints\n\n        # Set the keypoint hflip indices\n        if keypoint_hflip_indices is not None and len(keypoints) > 0:\n            keypoints = keypoints.reshape((len(keypoints), -1, 3))\n            keypoints[:, :, 0] *= -1\n            keypoints[:, :, 0] += image_size[0]\n            keypoints = keypoints.reshape(len(keypoints), -1)\n            annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Subtract 1 because RLE starts from 1 (not 0), 1234 = [1 2 3 4]\n    RLE_MAX_LENGTH = 1234\n    # Coordinates for polygons may be represented in the dictionary as either lists or arrays.\n    # In the case of lists, all coordinates are relative to the upper-left corner of the image.\n    # In the case of arrays, coordinates are absolute. TransformList expects arrays in the later case.\n    # We convert to absolute coordinates for transfoms but convert back to relative coordinates after.\n    # If the annotation provided by the dataset is already in absolute coordinates, set this to False.\n    absolute_coords = True\n\n    if \"bbox\" in annotation:\n        assert \"bbox_mode\" in annotation\n        bbox = BoxMode.convert(\n            annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS\n        )\n\n        # Note that bbox is 1d (per-instance bounding box)\n        annotation[\"bbox\"] = transforms.apply_box([bbox])[0]\n        annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    if \"segmentation\" in annotation:\n        # each instance contains 1 or more polygons\n        segm = annotation[\"segmentation\"]\n        if isinstance(segm, list):\n            # polygons\n            polygons = [np.asarray(p).reshape(-1, 2) for p in segm]\n            annotation[\"segmentation\"] = [\n                p.reshape(-1) for p in transforms.apply_polygons(polygons)\n            ]\n        elif isinstance(segm, dict):\n            # RLE\n            mask = mask_util.decode(segm)\n            mask = transforms.apply_segmentation(mask)\n            assert tuple(mask.shape[:2]) == image_size\n            annotation[\"segmentation\"] = mask\n        else:\n            raise ValueError(\n                \"Cannot transform segmentation of type '{}'!\"\n                \"Supported types are: polygons as list"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Convert bounding boxes to XYXY_ABS\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n\n    # Note that the bbox transformation is always applied directly, and never to the segmentation or keypoints.\n    # This is because segmentation and keypoints are not in image coordinates but in the coordinates of the original image.\n    annotation[\"bbox\"] = transforms.apply_box([bbox])[0]\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # The original annotation dict has \"segmentation\" and \"keypoints\" fields.\n    # We remove those before applying transformations, and add them back in after the transformations are applied.\n    # This way, the transformation doesn't have to conditionally operate on whether these fields are present.\n    annotation.pop(\"segmentation\", None)\n    annotation.pop(\"keypoints\", None)\n\n    # Apply transformations to image and its corresponding annotations\n    annotation = transforms.apply_to_dict(annotation)\n\n    # Make sure the bounding box is within the image.\n    # The `transform.apply_box` already ensures the box is within the image but ignores the (0.5, 0.5) centerness of the box.\n    # This bug is due to the fact that the centerness is rounded to integer and the box is transformed to the integer pixel coordinates.\n    annotation[\"bbox\"] = np.maximum(np.minimum(annotation[\"bbox\"], list(image_size)), [0, 0, 0, 0])\n\n    # Apply transformations to segmentation polygons\n    segmentation = annotation.get(\"segmentation\")\n    if segmentation is None:\n        return annotation\n\n    # Transform polygon annotations to binary masks\n    polygons = [np.asarray(p).reshape(-1, 2) for p in segmentation]\n    polygons_in_image = [\n        p for p in polygons if p.shape[0] >= 6\n    ]  # Valid polygons have at least 3 points (6"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        return cv2.transform(coords[:, np.newaxis, :], self.rm_coords)[:, 0, :]\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        coords = np.asarray(coords, dtype=np.float32)\n        # Rotate.\n        coords = cv2.transform(coords[:, np.newaxis, :], self.rm_coords)[:, 0, :]\n        return coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        return cv2.transform(coords[:, np.newaxis, :], self.rm_coords)[:, 0, :]\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        coords = np.asarray(coords, dtype=np.float32)\n        # Change the coordinates to center on zero for rotation.\n        coords = coords - self.center\n        # Rotate the coordinates based on the instance's rotation matrix.\n        coords = np.dot(coords, self.rm_coords.T)\n        # Change the coordinates back to normal.\n        coords = coords + self.center\n        return coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        return cv2.transform(coords[:, np.newaxis, :], self.rm_coords)[:, 0, :]\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        coords = np.asarray(coords, dtype=np.float32)\n        if coords.shape[1] != 2:\n            raise ValueError(\n                f\"coords input should be an array of shape (N,2), but got {coords.shape}\"\n            )\n        return cv2.transform(coords[:, np.newaxis, :], self.rm_coords)[:, 0, :]\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        coords = np.asarray(coords, dtype=np.float32)\n        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        return cv2.transform(coords[:, np.newaxis, :], self.rm_coords)[:, 0, :]\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        coords = np.asarray(coords, dtype=np.float32)\n        # Transform image center from source coordinates into output coordinates\n        # and then map the new origin to the corner of the output image.\n        h, w = self.h, self.w\n        center = np.array((w / 2, h / 2))\n        coords = coords - center\n        coords = np.dot(coords, self.rm_coords.T)\n        coords = coords + center\n        return coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        coords = np.asarray(coords, dtype=np.float32)\n        # This assumes that the image is a grayscale image\n        if len(coords.shape) == 3:\n            coords = coords.squeeze(-1)\n        assert coords.shape[1] == 2\n        if coords.shape[0] == 0:\n            return coords\n        # Rows are x, Columns are y\n        coords = np.concatenate(\n            [coords[:, 0:1], self.h - coords[:, 1:2]], axis=1\n        )  # N * 2 (x, y)\n        coords = np.matmul(coords, self.rm_coords.T)  # N * 2 (x, y)\n        coords = np.concatenate(\n            [coords[:, 0:1], self.w - coords[:, 1:2]], axis=1\n        )  # N * 2 (x, y)\n        return coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        coords = np.asarray(coords, dtype=np.float32)\n        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n\n        # Transform the coordinates to the image center.\n        coords = coords - self.center\n\n        # Rotate the coordinates.\n        coords = np.dot(coords, self.rm_coords)\n\n        # Transform the coordinates back to the original image.\n        coords = coords + self.center\n\n        return coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        coords = np.asarray(coords, dtype=np.float32)\n        # Change the coordinates to center on zero for rotation\n        coords = coords - self.center\n        # Rotate the coordinates according to the instance's rotation matrix\n        coords = np.dot(coords, self.rm_coords.T)\n        # Change the coordinates back to their original position\n        coords = coords + self.center\n        return coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        coords = np.asarray(coords, dtype=np.float32)\n        # prevent negative 0\n        coords += 0\n\n        # Transform the coordinates\n        coords = cv2.transform(coords[:, np.newaxis, :], self.rm_coords)[:, 0, :]\n        return coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        coords = np.asarray(coords, dtype=np.float32)\n        if len(coords.shape) == 2 and coords.shape[1] == 2:\n            coords = coords @ self.rm_coords\n        return coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        coords = coords.astype(np.float32)\n        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        return cv2.transform(coords[:, np.newaxis, :], self.rm_coords)[:, 0, :]\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        return cv2.transform(coords[:, np.newaxis, :], self.rm_coords)[:, 0, :]\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        coords = np.asarray(coords, dtype=np.float32)\n        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n\n        # Transform the coordinates to the space of the image.\n        coords = np.concatenate([coords, np.ones((coords.shape[0], 1))], axis=1)\n        assert coords.shape[1] == 3\n\n        # Apply the rotation transformation to the coordinates.\n        coords = np.dot(coords, self.rm_coords.T)\n        return coords[:, :2]\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        coords = np.asarray(coords, dtype=np.float32)\n        # Change (x, y) order to (y, x)\n        coords = coords[:, [1, 0]]\n        # Rotate coordinates\n        coords = cv2.transform(coords, self.rm_coords)\n        # Change (y, x) order to (x, y)\n        coords = coords[:, [1, 0]]\n        return coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        coords = np.asarray(coords, dtype=np.float32)\n        # Change the coordinates to center on zero for rotation\n        coords = coords - self.center\n        # Rotate coordinates\n        coords = np.dot(coords, self.rm_coords.T)\n        # Change the coordinates back\n        coords = coords + self.center\n        return coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        coords = np.asarray(coords, dtype=np.float32)\n        # This assumes that the image is a square with side length equal to the largest side length\n        # TODO: This should be fixed to be more general\n        # TODO: This should be fixed to be more general\n        # TODO: This should be fixed to be more general\n        coords[:, 0] -= self.center[0]\n        coords[:, 1] -= self.center[1]\n        coords = cv2.transform(coords[:, np.newaxis, :], self.rm_coords)[:, 0, :]\n        coords[:, 0] += self.center[0]\n        coords[:, 1] += self.center[1]\n        return coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n\n        coords = np.asarray(coords, dtype=np.float64)\n\n        # Convert coordinates from the original frame of reference to the frame of reference defined by the rotation matrix.\n        coords = np.atleast_2d(coords)\n        coords = np.hstack((coords, np.ones((coords.shape[0], 1), dtype=np.float64)))\n        coords = np.dot(coords, self.rm_coords.T)\n        return coords\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # Run the model once to get the number of flops\n    flops_count = FlopCountAnalysis(model, inputs)\n    flops_count.tracer.save_to_tensorboard()\n    return flops_count.total()\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    assert isinstance(inputs, list), \"Inputs should be a list of dictionaries.\"\n    assert isinstance(inputs[0], dict), \"Inputs should be a list of dictionaries.\"\n    assert \"image\" in inputs[0], \"Inputs should be a list of dictionaries with an 'image' key.\"\n\n    flops_count = FlopCountAnalysis(model, inputs)\n    flops_count.tracer.save_to_file(\"flops_count.txt\")\n    return flops_count.by_operator()\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # Wrap the model and inputs to prepare for tracing\n    analysis = FlopCountAnalysis(model, inputs)\n    analysis.tracer.set_op_handle(**{k: None for k in _IGNORED_OPS})\n\n    # Trace the model and get the flops\n    analysis.unsupported_ops_warnings(False).uncalled_modules_warnings(False)\n    analysis.tracer.trace(analysis.root)\n    return analysis.by_operator()\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # Count flops using FlopCountAnalysis\n    flops_analyzer = FlopCountAnalysis(model, inputs)\n    flops_analyzer.unsupported_ops_warnings(False).uncalled_modules_warnings(False)\n    flops_analyzer.tracer_warnings(\"none\")\n    flops_analyzer.start()\n    flops_analyzer.stop()\n    flops = flops_analyzer.by_operator()\n\n    return flops\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    inputs = _convert_tensor_to_device(inputs, model)\n    flops_analyzer = FlopCountAnalysis(model, inputs)\n    flops_analyzer.unsupported_ops_warnings(False)\n    flops_analyzer.uncalled_modules_warnings(False)\n    flops_analyzer.tracer_warnings(\"none\")\n    flops_analyzer.analyze(\n        verbose=False,\n        enable_log=False,\n        ignore_flops_layers=None,\n        custom_ops=None,\n        output=None,\n    )\n    return flops_analyzer.by_operator()\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    if not isinstance(inputs, list):\n        inputs = [inputs]\n\n    # Run the model to prepare the trace\n    with torch.no_grad():\n        model(inputs)\n\n    # Run the flop count\n    flops = FlopCountAnalysis(model, inputs)\n    flops.tracer.clear_cache()\n\n    return flops.total()\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # Set the model to eval mode\n    model.eval()\n\n    # Wrap the model in a tracing module\n    tracing_model = TracingAdapter(model, inputs)\n\n    # Count the number of flops\n    flops_count = flop_count(tracing_model, inputs)\n\n    # Convert the results to a dictionary\n    flops_dict = flop_count_analysis_to_dict(flops_count)\n\n    return flops_dict\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # run the model to get the trace\n    trace = FlopCountAnalysis(model, inputs)\n\n    # extract the flop counts\n    flop_dict = trace.by_operator()\n\n    # return the flop count\n    return flop_dict\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # This function is adapted from the one in fvcore.nn.\n    # https://github.com/facebookresearch/fvcore/blob/master/fvcore/nn/flop_count.py\n    # Copyright (c) Facebook, Inc. and its affiliates.\n    #\n    # This source code is licensed under the MIT license found in the\n    # LICENSE file in the root directory of this source tree.\n\n    # ignore some ops\n    supported_ops = {\n        \"aten::_convolution\",\n        \"aten::addmm\",\n        \"aten::addmv\",\n        \"aten::bmm\",\n        \"aten::einsum\",\n        \"aten::matmul\",\n        \"aten::mm\",\n        \"aten::mv\",\n        \"aten::mul\",\n        \"aten::mul_\",\n        \"aten::nonzero_numpy\",\n        \"aten::rsub\",\n        \"aten::rsub_\",\n        \"aten::softmax\",\n        \"aten::sort\",\n        \"aten::t\",\n        \"aten::to\",\n        \"aten::transpose\",\n        \"aten::unsqueeze\",\n        \"aten::view\",\n        \"aten::zeros\",\n        \"aten::zeros_like\",\n    }\n    supported_ops.update(_IGNORED_OPS)\n\n    def flop_count_func(\n        inputs: typing.List[object], outputs: typing.List[object]\n    ) -> typing.Counter[str]:\n        \"\"\"\n        Given a float function, count the Gflops.\n        Args:\n            inputs (list(object)): inputs to the function\n            outputs (list(object)): outputs to the function\n        Returns:\n            Counter: a Counter dictionary that counts the number of\n                floating point operations in this operator.\n        \"\"\"\n        assert len(outputs) == 1\n        outputs_ = outputs[0]\n        # we only count float operations\n        if outputs_.dtype not in [torch.float, torch.float16, torch.float64]:\n            return Counter()\n\n        flops ="}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    if isinstance(inputs, (list, tuple)) and isinstance(inputs[0], (list, tuple)):\n        assert (\n            len(inputs[0]) == 1\n        ), \"Please provide only a single input example for each model\"\n\n    # Run the model once to get the number of flops.\n    flops = FlopCountAnalysis(model, inputs)\n    flops.tracer.run()\n\n    return flops.total()\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    if not isinstance(inputs, list):\n        inputs = [inputs]\n\n    # Run the model once to get the trace\n    trace = FlopCountAnalysis(model, inputs)\n\n    # Extract the Gflops from the trace\n    flops = trace.total()\n\n    return flops\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # Set the model to eval mode\n    model.eval()\n\n    # Run the model with the provided inputs\n    outputs = model(inputs)\n\n    # Initialize the flop count analysis\n    flop_counter = FlopCountAnalysis(model, inputs)\n\n    # Execute the flop count analysis\n    flop_counter.unsupported_ops_warnings(False).uncalled_modules_warnings(False).warn_CPU_FLOPS(False).warn_selective_batch_norm_ops(False)\n    flop_counter.analyze(\n        tracer_kwargs={\"collect_args\": True, \"collect_return\": True}\n    )\n\n    # Return the flop counts\n    return flop_counter.by_operator()\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    assert isinstance(inputs, list), \"Inputs should be a list\"\n    assert isinstance(inputs[0], dict), \"Inputs should be a list of dictionaries\"\n\n    # Run the model to trace the operators\n    flops = FlopCountAnalysis(model, inputs)\n    flops.tracer.format_stack_trace = True\n    flops.unsupported_ops_warnings(False)\n    flops.uncalled_modules_warnings(False)\n    flops.tracer.total_exec_ops = 0\n    flops.tracer.total_exec_all_ops = 0\n\n    # Count the flops\n    flops.unsupported_ops_warnings(False)\n    flops.uncalled_modules_warnings(False)\n    flops.tracer.total_exec_ops = 0\n    flops.tracer.total_exec_all_ops = 0\n    flops.total()\n\n    # Convert the results to a dictionary\n    ret = flops.by_operator()\n    return ret\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    assert isinstance(inputs, list), \"Inputs must be a list\"\n\n    flops_count = FlopCountAnalysis(model, inputs)\n    flops_count.tracer.save_to_file(\"flops.txt\")\n\n    return flops_count.by_operator()\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # Run the model to get the outputs.\n    outputs = model(inputs)\n\n    # Wrap the model to get the Gflops.\n    analysis = FlopCountAnalysis(model, inputs)\n\n    # Get the Gflops.\n    gflops = analysis.total()\n\n    return gflops\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    if isinstance(inputs, tuple):\n        inputs = list(inputs)\n\n    # We need to wrap the model in our TracingAdapter\n    analysis = FlopCountAnalysis(model, inputs)\n    giga_flops = analysis.total() / 1e9\n\n    return giga_flops\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # 1. Run the model once to get the trace\n    trace = FlopCountAnalysis(model, inputs).traced_model\n\n    # 2. Extract the nodes from the trace\n    graph = trace.graph\n    nodes = list(graph.nodes)\n\n    # 3. Create a dictionary to store the node names and their corresponding flop counts\n    flops_dict = {}\n\n    # 4. Iterate through the nodes and compute the flops\n    for node in nodes:\n\n        # Extract the node name\n        node_name = node.name()\n\n        # Extract the node's flop count\n        node_flops = flop_count(graph, node)\n\n        # Add the node name and flops count to the dictionary\n        flops_dict[node_name] = node_flops\n\n    return flops_dict\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # The following code is adapted from detectron2\n    # https://github.com/facebookresearch/detectron2/blob/main/detectron2/utils/flops_counter.py\n\n    # Make dict out of list of dicts\n    inputs = inputs[0]\n    inputs = {k: v for d in inputs for k, v in d.items()}\n\n    # Convert to tuple of tensors\n    inputs = tuple(inputs[k] for k in model.input_names)\n\n    # Count flops\n    flops = FlopCountAnalysis(model, inputs)\n    flops.tracer.save_traced_model(path=\"flops_model.pt\")\n    flops.tracer.export_chrome_trace(\"flops_trace.json\")\n\n    # Return results\n    return flops.total()\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # TODO: Check if this is still necessary\n    if isinstance(inputs, dict):\n        inputs = [inputs]\n\n    # TODO: Check if this is still necessary\n    if isinstance(inputs, list):\n        if isinstance(inputs[0], dict):\n            if \"image\" in inputs[0]:\n                inputs = [{\"image\": x[\"image\"]} for x in inputs]\n            else:\n                raise ValueError(\n                    \"inputs is a list of dictionaries but do not contain the 'image' key.\"\n                )\n        elif isinstance(inputs[0], (list, tuple)):\n            if isinstance(inputs[0][0], dict):\n                if \"image\" in inputs[0][0]:\n                    inputs = [[x[\"image\"] for x in y] for y in inputs]\n                else:\n                    raise ValueError(\n                        \"inputs is a list of lists/tuples of dictionaries but do not contain the 'image' key.\"\n                    )\n            else:\n                raise ValueError(\n                    \"inputs is a list of lists/tuples of dictionaries but do not contain the 'image' key.\"\n                )\n        else:\n            raise ValueError(\n                \"inputs should be a list of dictionaries or a list of lists/tuples of dictionaries.\"\n            )\n\n    analysis = FlopCountAnalysis(model, inputs)\n    return analysis.by_operator()\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # The following code is mostly copied from fvcore.nn.FlopCountAnalysis.\n    # It is copied to avoid introducing fvcore as a detectron2 dependency.\n    assert isinstance(model, nn.Module), f\"{type(model)} is not a valid type for model\"\n    assert isinstance(inputs, list), f\"{type(inputs)} is not a valid type for inputs\"\n\n    if isinstance(inputs, tuple):\n        inputs = list(inputs)\n\n    with torch.no_grad():\n        try:\n            analysis = FlopCountAnalysis(model, inputs)\n            analysis.tracing_op_conversion(\n                customized_ops={\n                    TracingAdapter: fvcore.nn.flop_count_hooks.tracing_adapter_ops,\n                    TracingAdapter.flattened_inputs: fvcore.nn.flop_count_hooks.tracing_adapter_ops,\n                }\n            )\n            analysis.eval_self()\n        except Exception as e:\n            raise ValueError(\n                \"Failed to run FlopCountAnalysis. This is likely due to the model not \"\n                \"running smoothly. Please inspect the model and make sure it runs \"\n                \"smoothly with `model(inputs)`.\"\n            )\n\n    flops = analysis.by_operator(flops=True)\n\n    return flops\n\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if interp is None:\n            interp = self.interp\n        if not self.angle % 360:\n            return img\n        h, w = img.shape[:2]\n        center = (w / 2, h / 2)\n        if len(img.shape) > 2 and img.shape[2] == 1:\n            img = img[:, :, 0]\n        img = cv2.warpAffine(img, self.rm_image, (bound_w, bound_h), flags=interp)\n        if len(img.shape) < 2:\n            img = np.expand_dims(img, -1)\n        return img\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        # If the image is empty or the angle results in no change, return the original image.\n        if img.size == 0 or 360.0 % self.angle == 0:\n            return img\n\n        # If the interpolation method is not provided, use the instance's default interpolation method.\n        if interp is None:\n            interp = self.interp\n\n        # Rotate the image using OpenCV's warpAffine function.\n        rotated_img = cv2.warpAffine(img, self.rm_image, (self.bound_w, self.bound_h), flags=interp)\n\n        return rotated_img\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if not interp:\n            interp = self.interp\n        if not np.any(img):\n            return img\n        h, w = img.shape[:2]\n        if h == self.bound_h and w == self.bound_w:\n            return img\n        rotated = cv2.warpAffine(img, self.rm_image, (self.bound_w, self.bound_h), flags=interp)\n        return rotated\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        interp = interp if interp is not None else self.interp\n        if len(img.shape) > 2 and img.shape[2] == 1:\n            pil_image = Image.fromarray(img[:, :, 0], mode=\"L\")\n        else:\n            pil_image = Image.fromarray(img)\n        rotated_image = pil_image.transform((self.bound_w, self.bound_h), Image.AFFINE, self.rm_image, interp)\n        ret = np.asarray(rotated_image)\n        if len(img.shape) > 2 and img.shape[2] == 1:\n            ret = np.expand_dims(ret, -1)\n        return ret\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        # If the image is empty or the angle results in no change, return the original image\n        if img.size == 0 or 360.0 % self.angle == 0:\n            return img\n\n        # If no interpolation method is provided, use the default interpolation method\n        interp = self.interp if interp is None else interp\n\n        # Rotate the image\n        rotated_image = cv2.warpAffine(img, self.rm_image, (self.bound_w, self.bound_h), flags=interp)\n\n        return rotated_image\n\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if interp is None:\n            interp = self.interp\n\n        if self.angle % 360 == 0 or self.angle % 360 == 180:\n            return img\n\n        if len(img.shape) > 2 and img.shape[2] == 1:\n            pil_image = Image.fromarray(img[:, :, 0], mode=\"L\")\n        else:\n            pil_image = Image.fromarray(img)\n        rotated_image = pil_image.transform(\n            size=(self.bound_h, self.bound_w),\n            method=Image.AFFINE,\n            data=self.rm_image,\n            resample=interp,\n        )\n        ret = np.asarray(rotated_image)\n        if len(img.shape) > 2 and img.shape[2] == 1:\n            ret = np.expand_dims(ret, -1)\n        return ret\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        # If the image is empty or the angle results in no change, return the original image\n        if img.size == 0 or 360.0 % self.angle == 0:\n            return img\n\n        # Otherwise, rotate the image using the stored rotation matrix\n        else:\n            # If the interpolation method is not provided, use the instance's default\n            if interp is None:\n                interp = self.interp\n\n            # Rotate the image\n            return cv2.warpAffine(img, self.rm_image, (self.bound_w, self.bound_h), flags=interp)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if img.size == 0:\n            return img\n\n        h, w = img.shape[:2]\n        interp = interp if interp is not None else self.interp\n        rot_mat = self.rm_image\n\n        img = cv2.warpAffine(img, rot_mat, (bound_w, bound_h), flags=interp)\n\n        return img\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if len(img.shape) > 2 and img.shape[2] == 1:\n            pil_image = Image.fromarray(img[:, :, 0], mode=\"L\")\n        else:\n            pil_image = Image.fromarray(img)\n        pil_image = pil_image.transform((self.bound_w, self.bound_h), Image.AFFINE, self.rm_image, interp if interp else self.interp)\n        ret = np.asarray(pil_image)\n        if len(img.shape) > 2 and img.shape[2] == 1:\n            ret = np.expand_dims(ret, -1)\n        return ret\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if interp is None:\n            interp = self.interp\n        if not interp in [cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_LANCZOS4]:\n            raise ValueError(\"The specified interpolation method is not supported. Use one of the following: cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_LANCZOS4\")\n\n        if img.size == 0:\n            return img\n\n        if self.angle % 360 == 0:\n            return img\n\n        img = cv2.warpAffine(img, self.rm_image, (self.bound_w, self.bound_h), flags=interp)\n        return img\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if len(img.shape) > 2 and img.shape[2] == 1:\n            pil_image = Image.fromarray(img[:, :, 0], mode=\"L\")\n        else:\n            pil_image = Image.fromarray(img)\n        pil_image = pil_image.transform(\n            size=(self.bound_w, self.bound_h),\n            method=Image.AFFINE,\n            data=self.rm_image,\n            interpolation=interp if interp is not None else self.interp,\n        )\n        ret = np.asarray(pil_image)\n        if len(img.shape) > 2 and img.shape[2] == 1:\n            ret = np.expand_dims(ret, -1)\n        return ret\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if interp is None:\n            interp = self.interp\n        if not img.size or self.angle % 360 == 0:\n            return img\n\n        # grab the rotation matrix to use\n        rm = self.rm_image if self.expand else self.rm_coords\n\n        # Apply the rotation\n        img = cv2.warpAffine(img, rm, (self.bound_w, self.bound_h), flags=interp)\n\n        # Return the rotated image\n        return img\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if interp is None:\n            interp = self.interp\n        if not len(img):\n            return img\n        h, w = img.shape[:2]\n        rot_mat = self.rm_image\n        if not np.any(rot_mat):\n            return img\n        img = cv2.warpAffine(\n            img,\n            rot_mat,\n            (bound_w, bound_h),\n            flags=interp,\n            borderMode=cv2.BORDER_CONSTANT,\n        )\n        if img.ndim < 3:\n            img = np.expand_dims(img, axis=-1)\n        return img\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if not interp:\n            interp = self.interp\n        if not img.size or self.angle % 360 == 0:\n            return img\n\n        h, w = img.shape[:2]\n        center = (w / 2, h / 2)\n        rot_mat = self.rm_image\n        ret = cv2.warpAffine(img, rot_mat, (bound_w, bound_h), flags=interp)\n        return ret\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.angle % 360 == 0 or img.size < 1:\n            return img\n\n        interp = interp if interp is not None else self.interp\n        img = Image.fromarray(img)\n        rotated_img = img.transform((self.bound_w, self.bound_h), Image.AFFINE, self.rm_image, interp)\n        return np.asarray(rotated_img)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.angle % 360 == 0 or not np.count_nonzero(img):\n            return img\n        interp = interp if interp is not None else self.interp\n        img = Image.fromarray(img)\n        return np.asarray(img.rotate(self.angle, resample=interp, expand=self.expand))\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.angle == 0:\n            return img\n        if interp is None:\n            interp = self.interp\n        h, w = img.shape[:2]\n        center = (w / 2, h / 2)\n        # 1. construct rotation matrix\n        rm = cv2.getRotationMatrix2D(center, self.angle, 1.0)\n        # 2. calculate new image center\n        new_center = rm.dot(np.array([center[0], center[1], 1]))\n        # 3. handle case where angle is multiple of 360 degrees\n        if new_center[0].is_integer() and new_center[1].is_integer():\n            new_center = (int(new_center[0]), int(new_center[1]))\n            rm = rm - np.round(new_center) + center\n        # 4. rotate image\n        img = cv2.warpAffine(img, rm, (bound_w, bound_h), flags=interp)\n        return img\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if img.size == 0:\n            return img\n        h, w = img.shape[:2]\n        interpolation = interp if interp is not None else self.interp\n        rm_image = self.rm_image\n        # The translation matrix for the rotation about the center of the image\n        # The translation is to bring the center of the image to the origin\n        # It is then rotated around the origin and then shifted back\n        # If there is no translation (center = image center), the rotation\n        # is about the origin, which is what we want\n        translation = np.eye(3)\n        translation[0, 2] = -w / 2  # x translation (pixels)\n        translation[1, 2] = -h / 2  # y translation (pixels)\n        # The rotation matrix for the rotation about the center of the image\n        rm_rotation = self.rm_coords\n        # The translation matrix for the shift back to the original image location\n        translation_back = np.eye(3)\n        translation_back[0, 2] = w / 2  # x translation (pixels)\n        translation_back[1, 2] = h / 2  # y translation (pixels)\n        # Combine all the transforms together\n        affine_matrix = translation @ rm_rotation @ translation_back\n        # Apply the transforms to the image\n        img = cv2.warpAffine(\n            img, affine_matrix[:2], (self.bound_w, self.bound_h), flags=interpolation\n        )\n        return img\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if not interp:\n            interp = self.interp\n        if not interp in (cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_LANCZOS4):\n            raise NotImplementedError\n        if self.angle % 360 == 0:\n            return img\n        h, w = img.shape[:2]\n        center = (w / 2, h / 2)\n        # The rotation matrix is a 2x3 matrix which contains the coefficients a, b, and c of the equation:\n        # x_new = a * x + b * y + c\n        # y_new = d * x + e * y + f\n        # where x and y are the original image coordinates, and x_new and y_new are the coordinates of the transformed image.\n        # The rotation matrix is used to transform each pixel coordinate in the original image to its corresponding pixel coordinate in the transformed image.\n        # The center of the rotation is the center of the image.\n        # The angle of rotation is stored in the instance.\n        # The bounding dimensions of the transformed image are stored in the instance.\n        # The rotation matrix is created using the function create_rotation_matrix.\n        # The rotation is performed using OpenCV's warpAffine function.\n        matrix = self.rm_image\n        img = cv2.warpAffine(img, matrix, (bound_w, bound_h), flags=interp)\n        return img\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if not interp:\n            interp = self.interp\n        if self.angle % 360 == 0 or img.size < 1:\n            return img\n\n        # grab the rotation matrix to use\n        rm = self.rm_image if self.expand else self.rm_coords\n\n        # if we are expanding the image, then the rotation operation is complex\n        # and involves four steps:\n        # 1. draw a rectangle that is the same size as the original, but\n        # *flipped* (since counter-clockwise rotation is defined to be\n        # rotation in a direct geometric sense)\n        # 2. perform an affine rotation on the rectangle\n        # 3. translate the rotated rectangle to the center of the image\n        # 4. resize the rotated rectangle to be the size of the original\n        # otherwise, the rotation operation is very simple\n\n        if self.expand:\n            # calculate the size of the un-rotated image\n            (a, b, c, d) = rm.flatten()\n            M = np.array([[a, b, c], [d, e, f], [0, 0, 1]])\n            # note that the size of the target rectangle is the same as\n            # the un-rotated rectangle but with a *flipped* axis\n            # this means instead of a CW rotation, we perform an CCW rotation\n            # by using -angle\n            (unrotated_h, unrotated_w) = self.get_output_shape(\n                M, (self.h, self.w)\n            )\n            # step 1: draw the un-rotated rectangle in the un-rotated image\n            rotated = cv2.warpAffine(\n                img,\n                M,\n                (unrotated_w, unrotated_h),\n                flags=cv2.INTER_LINEAR | cv2.WARP_INVERSE_MAP,\n            )\n            # step 2: rotate this un-rotated rectangle by angle\n            rotated = cv2.warpAffine(\n                rotated,\n                rm,\n                (self.bound"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n                if predictions.has(\"pred_masks\")\n                else None\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            boxes=boxes,\n            labels=labels,\n            masks=predictions.pred_masks if predictions.has(\"pred_masks\") else None,\n            keypoints=predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            boxes=boxes,\n            masks=predictions.pred_masks if predictions.has(\"pred_masks\") else None,\n            keypoints=keypoints,\n            labels=labels,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            boxes=boxes,\n            labels=labels,\n            masks=predictions.pred_masks if predictions.has(\"pred_masks\") else None,\n            keypoints=predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n                if predictions.has(\"pred_masks\")\n                else None\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n                if predictions.has(\"pred_masks\")\n                else None\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            boxes=boxes,\n            masks=predictions.pred_masks if predictions.has(\"pred_masks\") else None,\n            labels=labels,\n            keypoints=predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            boxes=boxes,\n            masks=predictions.pred_masks if predictions.has(\"pred_masks\") else None,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            boxes=boxes,\n            masks=predictions.pred_masks if predictions.has(\"pred_masks\") else None,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            boxes=boxes,\n            masks=predictions.pred_masks if predictions.has(\"pred_masks\") else None,\n            keypoints=keypoints,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n\n        if self._instance_mode == ColorMode.SEGMENTATION:\n            self.overlay_class_names(predictions.pred_classes, predictions.pred_scores, labels)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            boxes=boxes,\n            masks=predictions.pred_masks if predictions.has(\"pred_masks\") else None,\n            labels=labels,\n            keypoints=predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.img = self._create_grayscale_image(\n                (predictions.pred_masks.any(dim=0) > 0).numpy()\n            )\n            alpha = 0.3\n\n        self.overlay_instances(\n            boxes=boxes,\n            masks=predictions.pred_masks if predictions.has(\"pred_masks\") else None,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n        # buf = io.BytesIO()  # works for cairo backend\n        # canvas.print_rgba(buf)\n        # width, height = self.width, self.height\n        # s = buf.getvalue()\n\n        buffer = np.frombuffer(s, dtype=\"uint8\")\n\n        img_rgba = buffer.reshape(height, width, 4)\n        rgb, alpha = np.split(img_rgba, [3], axis=2)\n        return rgb.astype(\"uint8\")\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n        # buf = io.BytesIO()  # works for cairo backend\n        # canvas.print_rgba(buf)\n        # width, height = self.width, self.height\n        # s = buf.getvalue()\n\n        buffer = np.frombuffer(s, dtype=\"uint8\")\n\n        img_rgba = buffer.reshape(height, width, 4)\n        rgb, alpha = np.split(img_rgba, [3], axis=2)\n        return rgb.astype(\"uint8\")\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # draw the canvas to get RGBA image array\n        self.canvas.draw()\n        # get the RGBA numpy data array\n        img_arr = np.array(self.canvas.renderer._renderer)\n        # convert RGBA to RGB\n        img_arr = img_arr[:, :, :3]\n        # convert to np.uint8\n        img_arr = img_arr.astype(np.uint8)\n        return img_arr\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # Get the image as a numpy ndarray of uint8 type.\n        canvas_img = self.canvas.get_renderer().tostring_rgb()\n        canvas_img = np.fromstring(canvas_img, dtype=\"uint8\").reshape(\n            self.height, self.width, 3\n        )\n        return canvas_img\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas_img = self.canvas.tostring_rgb()\n        canvas_img = np.fromstring(canvas_img, dtype=\"uint8\").reshape(\n            self.height, self.width, 3\n        )\n        return canvas_img\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # draw the canvas to get the image\n        self.canvas.draw()\n        # Get the RGBA buffer from the figure\n        w, h = self.canvas.get_width_height()\n        buf = np.frombuffer(self.canvas.tostring_argb(), dtype=np.uint8)\n        buf.shape = (h, w, 4)\n\n        # canvas.tostring_argb give pixmap in ARGB mode. Roll the ALPHA channel to have it in RGBA mode\n        buf = np.roll(buf, 3, axis=2)\n        w, h, d = buf.shape\n        return buf.reshape(h, w, d // 4)\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n        # buf = io.BytesIO()  # works for cairo backend\n        # canvas.print_rgba(buf)\n        # width, height = self.width, self.height\n        # s = buf.getvalue()\n\n        buffer = np.frombuffer(s, dtype=\"uint8\")\n\n        img_rgba = buffer.reshape(height, width, 4)\n        rgb, alpha = np.split(img_rgba, [3], axis=2)\n        return rgb.astype(\"uint8\")\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # Get the image as a numpy ndarray of uint8 type.\n        canvas_buffer = self.canvas.buffer_rgba()\n        canvas_image = np.asarray(canvas_buffer)\n\n        # Convert the image from RGBA to RGB format.\n        visualized_image = cv2.cvtColor(canvas_image, cv2.COLOR_RGBA2RGB)\n\n        return visualized_image\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # Get the canvas's renderer and grab the pixel buffer\n        renderer = self.canvas.get_renderer()\n        buffer = np.array(renderer.buffer_rgba())\n\n        # Image is in RGBA format; convert to RBG\n        buffer = buffer[:, :, :3]\n\n        return buffer\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # self.fig.canvas.draw()\n        # w, h = self.fig.canvas.get_width_height()\n        # buf = np.fromstring(self.fig.canvas.tostring_rgb(), dtype=np.uint8)\n        # buf.shape = (h, w, 3)\n        # return buf\n\n        self.fig.canvas.draw()\n        canvas_img = np.frombuffer(self.fig.canvas.tostring_rgb(), dtype=np.uint8)\n        canvas_img = canvas_img.reshape(self.fig.canvas.get_width_height()[::-1] + (3,))\n        canvas_img = cv2.cvtColor(canvas_img, cv2.COLOR_BGR2RGB)\n        return canvas_img\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n        # buf = io.BytesIO()  # works for cairo backend\n        # canvas.print_rgba(buf)\n        # width, height = self.width, self.height\n        # s = buf.getvalue()\n\n        buffer = np.frombuffer(s, dtype=\"uint8\")\n\n        img_rgba = buffer.reshape(height, width, 4)\n        rgb, alpha = np.split(img_rgba, [3], axis=2)\n        return rgb.astype(\"uint8\")\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n        # buf = io.BytesIO()  # works for cairo backend\n        # canvas.print_rgba(buf)\n        # width, height = self.width, self.height\n        # s = buf.getvalue()\n\n        buffer = np.frombuffer(s, dtype=\"uint8\")\n\n        img_rgba = buffer.reshape(height, width, 4)\n        rgb, alpha = np.split(img_rgba, [3], axis=2)\n        return rgb.astype(\"uint8\")\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # draw the plot on the canvas\n        self.canvas.draw()\n\n        # convert canvas to image\n        img = np.fromstring(self.canvas.tostring_rgb(), dtype=\"uint8\")\n        img = img.reshape(self.height, self.width, 3)\n\n        return img\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # draw the canvas to get draw object\n        self.canvas.draw()\n        # get the RGBA buffer from the draw object\n        w, h = self.get_width_height()\n        buf = self.canvas.buffer_rgba()\n        # The np.frombuffer method converts the RGBA buffer to a numpy ndarray\n        # of uint8 type. The shape of the array is (H, W, 4), where H and W are\n        # the height and width of the image, respectively.\n        # The reshape method reshapes the array to (H, W, 3), which is the\n        # shape of the visualized image required by the PIL package.\n        image = np.frombuffer(buf, dtype=np.uint8)\n        image = image.reshape(w, h, 4)\n        image = image[..., :3]\n        return image\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # canvas_img = self.canvas.get_renderer().tostring_rgb()\n        # canvas_img = np.fromstring(canvas_img, dtype=\"uint8\").reshape(self.height, self.width, 3)\n        # canvas_img = cv2.cvtColor(canvas_img, cv2.COLOR_RGB2BGR)\n        # canvas_img = cv2.resize(canvas_img, (self.width, self.height))\n        # canvas_img = cv2.cvtColor(canvas_img, cv2.COLOR_BGR2RGB)\n        # return canvas_img\n\n        canvas_img = self.canvas.get_renderer().tostring_rgb()\n        canvas_img = np.fromstring(canvas_img, dtype=\"uint8\").reshape(self.height, self.width, 3)\n        canvas_img = cv2.cvtColor(canvas_img, cv2.COLOR_RGB2BGR)\n        canvas_img = cv2.resize(canvas_img, (self.width, self.height))\n        canvas_img = cv2.cvtColor(canvas_img, cv2.COLOR_BGR2RGB)\n        return canvas_img\n\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # canvas_img = self.canvas.renderer.buffer_rgba()\n        # canvas_img = np.asarray(canvas_img)\n        # canvas_img = cv2.cvtColor(canvas_img, cv2.COLOR_RGBA2RGB)\n        # canvas_img = canvas_img[:, :, ::-1].copy()\n        # return canvas_img\n        self.canvas.draw()\n        canvas_img = np.asarray(self.canvas.get_renderer()._renderer)\n        return canvas_img\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n        # buf = io.BytesIO()  # works for cairo backend\n        # canvas.print_rgba(buf)\n        # width, height = self.width, self.height\n        # s = buf.getvalue()\n\n        buffer = np.frombuffer(s, dtype=\"uint8\")\n\n        img_rgba = buffer.reshape(height, width, 4)\n        rgb, alpha = np.split(img_rgba, [3], axis=2)\n        return rgb.astype(\"uint8\")\n\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # self.ax.imshow(self.img, extent=(0, self.width, self.height, 0), interpolation='nearest')\n        # self.fig.canvas.draw()\n        # W, H = self.get_size_inches() * self.dpi\n        # buf = np.fromstring(self.canvas.tostring_rgb(), dtype='uint8')\n        # buf.shape = (H, W, 3)\n        # return buf\n\n        # self.fig.canvas.draw()\n        # W, H = self.get_size_inches() * self.dpi\n        # # canvas.tostring_argb give pixmap in ARGB mode. Roll the ALPHA channel to have RGBA.\n        # buf = np.fromstring(self.canvas.tostring_argb(), dtype=np.uint8)\n        # buf.shape = (H, W, 4)\n        # # Can be following way also:\n        # # import matplotlib.pyplot as plt\n        # # buf = (plt.imread(self.fig.canvas.buffer_rgba()) * 255).astype(np.uint8)\n        # # But it requires matplotlib>=3.3.0\n        # buf = np.roll(buf, 3, axis=2)\n        # w, h, d = buf.shape\n        # return buf.reshape((w, h, 3))\n\n        # self.fig.canvas.draw()\n        # w, h = self.get_size_inches() * self.dpi\n        # buf = np.fromstring(self.canvas.tostring_argb(), dtype=np.uint8)\n        # buf.shape = (w, h, 4)\n        # # canvas.tostring_argb give pixmap in ARGB mode. Roll the ALPHA channel to have RGBA.\n        # buf = np.roll(buf, 3, axis=2)\n        # w, h, d = buf.shape\n        # return buf.reshape((w, h, 4))\n\n        self.fig.canvas.draw()"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # Draw the canvas to get RGBA pixels.\n        self.canvas.draw()\n\n        # Convert the RGBA numpy ndarray to RGB.\n        # This is used to convert the numpy ndarray to a python Image object.\n        # See: https://stackoverflow.com/questions/3498c123/save-matplotlib-file-to-image-array-without-saving-to-file\n        w, h = self.get_width_height()\n        buf = np.frombuffer(self.canvas.tostring_rgb(), dtype=\"uint8\")\n        buf = buf.reshape(h, w, 3)\n\n        return buf\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # canvas.tostring_rgb() returns the raw bytes in rgb format\n        # the array needs to be reshaped from (H, W, 3) to (H, W, 3).\n        # the array is also flipped, because the canvas.tostring_rgb() function\n        # returns the array in (H, W, 3) format, where H is the height and W is the width\n        # of the image, while the image is stored in RGB format, so the channels are in\n        # the order (H, W, 3).\n        # canvas.to_string_rgb() returns the raw bytes in rgb format, while the\n        # tobytes_rgb() function returns the raw bytes in bgr format.\n        data = self.canvas.tobytes_rgb()\n        # reshape the data into an image of size (H, W, 3)\n        size = self.width, self.height\n        image = np.frombuffer(data, dtype=np.uint8)\n        image = image.reshape(size[1], size[0], 3)\n        # flip the image\n        image = np.flipud(image)\n        return image\n\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic[\"annotations\"]\n        # for anno in annos:\n        #     if anno[\"category_id\"] == 1:\n        #         print(anno)\n        #         print(dic[\"file_name\"])\n        #         print(dic[\"image_id\"])\n        #         print(dic[\"height\"])\n        #         print(dic[\"width\"])\n        #     if anno[\"category_id\"] == 2:\n        #         print(anno)\n        #         print(dic[\"file_name\"])\n        #         print(dic[\"image_id\"])\n        #         print(dic[\"height\"])\n        #         print(dic[\"width\"])\n        #     if anno[\"category_id\"] == 3:\n        #         print(anno)\n        #         print(dic[\"file_name\"])\n        #         print(dic[\"image_id\"])\n        #         print(dic[\"height\"])\n        #         print(dic[\"width\"])\n        #     if anno[\"category_id\"] == 4:\n        #         print(anno)\n        #         print(dic[\"file_name\"])\n        #         print(dic[\"image_id\"])\n        #         print(dic[\"height\"])\n        #         print(dic[\"width\"])\n        #     if anno[\"category_id\"] == 5:\n        #         print(anno)\n        #         print(dic[\"file_name\"])\n        #         print(dic[\"image_id\"])\n        #         print(dic[\"height\"])\n        #         print(dic[\"width\"])\n        #     if anno[\"category_id\"] == 6:\n        #         print(anno)\n        #         print(dic[\"file_name\"])\n        #         print(dic[\"image_id\"])\n        #         print(dic[\"height\"])\n        #         print(dic[\"width\"])\n        #     if anno[\"category_id\"] == 7:\n        #         print(anno)\n        #         print(dic[\"file_name\"])\n        #         print(dic[\"image_id\"])\n        #         print(dic[\"height\"])\n        #         print(dic[\"width\"])\n        #     if anno[\"category_id\"]"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic.get(\"annotations\", [])\n\n        # Draw segmentation masks for all object instances\n        masks = [x[\"segmentation\"] for x in annos if x[\"category_id\"] != 0]\n        if masks:\n            masks = SegmentationMask(masks, *dic[\"image\"].shape[:2])\n            self.overlay_masks(masks, alpha=0.5)\n\n        # Draw semantic segmentation masks for all semantic segments\n        sem_seg = dic.get(\"sem_seg\")\n        if sem_seg is None and \"sem_seg_file_name\" in dic:\n            with PathManager.open(dic[\"sem_seg_file_name\"], \"rb\") as f:\n                sem_seg = Image.open(f)\n                sem_seg = np.asarray(sem_seg, dtype=\"uint8\")\n        if sem_seg is not None:\n            self.draw_sem_seg(sem_seg, area_threshold=0)\n\n        # Draw panoptic segmentation masks for all panoptic segments\n        panoptic_seg = dic.get(\"panoptic_seg\")\n        if panoptic_seg is None and \"panoptic_seg_file_name\" in dic:\n            with PathManager.open(dic[\"panoptic_seg_file_name\"], \"rb\") as f:\n                panoptic_seg = Image.open(f)\n                panoptic_seg = np.asarray(panoptic_seg)\n\n        if panoptic_seg is not None:\n            segments_info = dic[\"segments_info\"]\n            pan_seg = PanopticSegmentation(panoptic_seg, segments_info, self.metadata)\n            self.draw_panoptic_seg(pan_seg, segments_info, area_threshold=0)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic.get(\"annotations\", [])\n\n        # Draw segmentation masks for all objects\n        if \"segmentation\" in annos[0]:\n            masks = [x[\"segmentation\"] for x in annos]\n            # MaskUtils.polygons_to_mask(masks, self.output.height, self.output.width)\n            class_ids = [x[\"category_id\"] for x in annos]\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in class_ids\n            ]\n            self.overlay_instances(masks=masks, assigned_colors=colors, alpha=0.4)\n\n        # Draw keypoints for all objects\n        if \"keypoints\" in annos[0]:\n            keypts = [x[\"keypoints\"] for x in annos]\n            self.overlay_keypoints(keypts=keypts)\n\n        # Draw bounding boxes for all objects\n        if \"bbox\" in annos[0]:\n            bbox_lens = [len(x[\"bbox\"]) for x in annos]\n            assert all(\n                bbox_lens == [4] * len(bbox_lens)\n            ), \"Only bboxes of length 4 (xywh) are supported.\"\n            bboxes = [x[\"bbox\"] for x in annos]\n            class_ids = [x[\"category_id\"] for x in annos]\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in class_ids\n            ]\n            self.overlay_boxes(bboxes=bboxes, assigned_colors=colors)\n\n        # Draw semantic segmentation masks for all objects\n        if \"sem_seg\" in dic:\n            self.draw_sem_seg(dic[\"sem_seg\"])\n\n        # Draw panoptic segmentation masks for all objects\n        if \"panoptic_seg\" in dic:\n            self.draw_panoptic_seg"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic.get(\"annotations\", [])\n        if \"sem_seg\" in dic:\n            self.draw_sem_seg(dic[\"sem_seg\"])\n        # Some datasets provide bbox and mask annotations together\n        # if it is the case, we draw the masks first because they may be occluded by the bboxes\n        if \"segments_info\" in annos[0]:\n            masks = [x[\"segmentation\"] for x in annos]\n            # TODO: really need to draw them in the order given by segments_info?\n            self.overlay_instances(masks=masks, boxes=[x[\"bbox\"] for x in annos], labels=[x[\"category_id\"] for x in annos])\n\n        if \"keypoints\" in annos[0]:\n            keypts = [x[\"keypoints\"] for x in annos]\n            visibilities = [x[\"keypoint_visibility\"] for x in annos]\n            self.overlay_keypoints(keypts, visibilities)\n\n        if \"panoptic_seg\" in dic:\n            panoptic_seg, segments_info = dic[\"panoptic_seg\"]\n            self.draw_panoptic_seg(panoptic_seg, segments_info)\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic.get(\"annotations\", [])\n\n        # Draw segmentation masks for all objects\n        masks = [x[\"segmentation\"] for x in annos if \"segmentation\" in x]\n        if masks:\n            self.overlay_masks(masks, alpha=0.5)\n\n        # Draw keypoints for all objects\n        keypts = [x[\"keypoints\"] for x in annos if \"keypoints\" in x]\n        if keypts:\n            self.overlay_keypoints(keypts)\n\n        # Draw bounding boxes for all objects\n        bboxes = [x[\"bbox\"] for x in annos if \"bbox\" in x]\n        if bboxes:\n            self.overlay_bboxes(bboxes)\n\n        # Draw semantic segmentation masks for all objects\n        sem_segs = [x[\"sem_seg\"] for x in annos if \"sem_seg\" in x]\n        if sem_segs:\n            self.draw_sem_seg(sem_segs[0], area_threshold=0)\n\n        # Draw panoptic segmentation masks for all objects\n        pan_segs = [x[\"pan_seg\"] for x in annos if \"pan_seg\" in x]\n        if pan_segs:\n            pan_seg = pan_segs[0]\n            segments_info = annos[0][\"pan_seg_id_to_segments\"]\n            self.draw_panoptic_seg(pan_seg, segments_info, area_threshold=0)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic.get(\"annotations\", [])\n\n        if \"sem_seg\" in dic:\n            sem_seg = dic[\"sem_seg\"]\n            if isinstance(sem_seg, str):\n                sem_seg = np.asarray(Image.open(sem_seg), dtype=\"uint8\")\n            self.draw_sem_seg(sem_seg, alpha=0.5)\n\n        if \"panoptic_seg\" in dic:\n            panoptic_seg, segments_info = dic[\"panoptic_seg\"]\n            if isinstance(panoptic_seg, str):\n                panoptic_seg = np.asarray(Image.open(panoptic_seg), dtype=\"uint8\")\n            self.draw_panoptic_seg(panoptic_seg, segments_info, alpha=0.5)\n\n        # draw bounding boxes\n        if \"bbox\" in annos[0]:\n            for anno in annos:\n                self.draw_bbox(anno[\"bbox\"], anno[\"category_id\"])\n        # draw segmentation masks\n        if \"segmentation\" in annos[0]:\n            for anno in annos:\n                mask = anno[\"segmentation\"]\n                if isinstance(mask, list):\n                    mask = mask[0]\n                self.draw_binary_mask(mask, category_id=anno[\"category_id\"])\n        # draw keypoints\n        if \"keypoints\" in annos[0]:\n            for anno in annos:\n                self.draw_keypoints(anno[\"keypoints\"], category_id=anno[\"category_id\"])\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic.get(\"annotations\", [])\n\n        # draw segmentation masks if in the dict\n        if \"sem_seg\" in dic:\n            sem_seg = dic[\"sem_seg\"]\n            self.draw_sem_seg(sem_seg, area_threshold=0)\n\n        # draw panoptic segmentation masks if in the dict\n        if \"panoptic_seg\" in dic:\n            panoptic_seg, segments_info = dic[\"panoptic_seg\"]\n            self.draw_panoptic_seg(panoptic_seg, segments_info, area_threshold=0)\n\n        # draw keypoints if in the dict\n        if \"keypoints\" in dic:\n            keypts = dic[\"keypoints\"][0]\n            keyp_tags = dic[\"keypoints\"][1]\n            self.draw_and_connect_keypoints(keypts, keyp_tags)\n\n        # draw bounding boxes if in the dict\n        if \"bbox\" in dic:\n            bboxes = dic[\"bbox\"][0]\n            bbox_tags = dic[\"bbox\"][1]\n            self.draw_bboxes(bboxes, bbox_tags)\n\n        # draw masks if in the dict\n        if \"mask\" in dic:\n            masks = dic[\"mask\"][0]\n            mask_tags = dic[\"mask\"][1]\n            self.draw_masks(masks, mask_tags)\n\n        # draw captions if in the dict\n        if \"caption\" in dic:\n            caption = dic[\"caption\"]\n            self.draw_caption(caption)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic.get(\"annotations\", [])\n\n        # draw segmentation masks\n        if \"segmentation\" in annos[0]:\n            masks = [x[\"segmentation\"] for x in annos]\n            # TODO: currently this only supports the RLE format,\n            # which is not compatible with bitmasks.\n            # in the future we will accept bitmasks as a second\n            # option here.\n            self.overlay_masks(masks, alpha=0.5)\n\n        # draw keypoints\n        if \"keypoints\" in annos[0]:\n            keypts = [x[\"keypoints\"] for x in annos]\n            self.overlay_keypoints(keypts)\n\n        # draw bounding boxes\n        if \"bbox\" in annos[0]:\n            boxes = [BoxMode.convert(x[\"bbox\"], x[\"bbox_mode\"], BoxMode.XYXY_ABS) for x in annos]\n            labels = [x[\"category_id\"] for x in annos]\n            self.overlay_boxes(boxes, labels)\n\n        # draw semantic segmentation masks\n        if \"sem_seg\" in dic:\n            sem_seg = dic[\"sem_seg\"]\n            self.draw_sem_seg(sem_seg, area_threshold=0)\n\n        # draw panoptic segmentation masks\n        if \"panoptic_seg\" in dic:\n            panoptic_seg = dic[\"panoptic_seg\"]\n            segments_info = dic[\"segments_info\"]\n            self.draw_panoptic_seg(panoptic_seg, segments_info, area_threshold=0)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic.get(\"annotations\", [])\n\n        if \"sem_seg\" in dic:\n            sem_seg = dic[\"sem_seg\"]\n            if isinstance(sem_seg, str):\n                sem_seg = PathManager.get_local_path(sem_seg)\n            self.draw_sem_seg(sem_seg, area_threshold=0)\n\n        # draw masks\n        mask_array = [x[\"segmentation\"] for x in annos if \"segmentation\" in x]\n        if mask_array:\n            self.overlay_masks(mask_array)\n\n        # draw keypoints\n        keypoint_array = [x[\"keypoints\"] for x in annos if \"keypoints\" in x]\n        if keypoint_array:\n            self.overlay_keypoints(keypoint_array)\n\n        # draw bounding boxes\n        bbox_array = [x[\"bbox\"] for x in annos if \"bbox\" in x]\n        if bbox_array:\n            self.overlay_boxes(bbox_array)\n\n        # draw panoptic segmentation that are labeled\n        if \"panoptic_seg\" in dic:\n            panoptic_seg, segments_info = dic[\"panoptic_seg\"]\n            if isinstance(panoptic_seg, str):\n                panoptic_seg = PathManager.get_local_path(panoptic_seg)\n            self.draw_panoptic_seg(panoptic_seg, segments_info, area_threshold=0)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic[\"annotations\"]\n        if \"sem_seg\" in dic:\n            sem_seg = dic[\"sem_seg\"]\n        else:\n            sem_seg = None\n\n        if \"pan_seg\" in dic:\n            pan_seg = dic[\"pan_seg\"]\n            segments_info = dic[\"segments_info\"]\n        else:\n            pan_seg = None\n            segments_info = None\n\n        if \"keypoints\" in annos[0]:\n            keypts = [x[\"keypoints\"] if \"keypoints\" in x else [] for x in annos]\n        else:\n            keypts = None\n\n        boxes = [x[\"bbox\"] if \"bbox\" in x else [] for x in annos]\n        classes = [x[\"category_id\"] if \"category_id\" in x else [] for x in annos]\n        try:\n            classes = [self.metadata.thing_classes[x] for x in classes]\n        except (AttributeError, KeyError):\n            pass\n        masks = [x[\"segmentation\"] if \"segmentation\" in x else [] for x in annos]\n\n        if sem_seg is not None and len(sem_seg.size) == 2:\n            sem_seg = sem_seg.unsqueeze(0)\n\n        # draw segmentation masks if provided\n        if sem_seg is not None:\n            self.draw_sem_seg(sem_seg.to(\"cpu\"), area_threshold=0)\n        if pan_seg is not None:\n            self.draw_panoptic_seg(pan_seg.to(\"cpu\"), segments_info, area_threshold=0)\n\n        # draw keypoints if provided\n        if keypts is not None:\n            for keypts_per_instance in keypts:\n                self.draw_and_connect_keypoints(keypts_per_instance)\n\n        # draw bounding boxes\n        for box, cls in zip(boxes, classes):\n            self.draw_box(box, edge_color=_OFF_WHITE, label=cls)\n\n        # draw masks if provided"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic.get(\"annotations\", [])\n\n        # draw segmentation masks if in the dict\n        if \"segmentation\" in annos[0]:\n            masks = [x[\"segmentation\"] for x in annos]\n            #print(masks)\n            #print(type(masks))\n            #print(len(masks))\n            #print(masks[0])\n            #print(type(masks[0]))\n            #print(masks[0].shape)\n            #print(masks[0][0])\n            #print(len(masks[0]))\n            #print(masks[0][0].shape)\n            #print(type(masks[0][0]))\n            #print(masks[0][0][0])\n            #print(masks[0][0][0].shape)\n            #print(type(masks[0][0][0]))\n            #print(masks[0][0][0][0])\n            #print(type(masks[0][0][0][0]))\n            #print(masks[0][0][0][0].shape)\n            #print(masks[0][0][0][0][0])\n            #print(masks[0][0][0][0][0].shape)\n            #print(masks[0][0][0][0][0][0])\n            #print(type(masks[0][0][0][0][0][0]))\n            #print(masks[0][0][0][0][0][0].shape)\n            #print(masks[0][0][0][0][0][0][0])\n            #print(type(masks[0][0][0][0][0][0][0]))\n            #print(masks[0][0][0][0][0][0][0][0])\n            #print(type(masks[0][0][0][0][0][0][0][0]))\n            #print(masks[0][0][0][0][0][0][0][0][0])\n            #print(type"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic[\"annotations\"]\n\n        # Draw segmentation masks for all objects\n        if \"segmentation\" in annos[0]:\n            masks = [x[\"segmentation\"] for x in annos]\n            classes = [x[\"category_id\"] for x in annos]\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n            ]\n            self.overlay_instances(\n                labels=classes, masks=masks, assigned_colors=colors, alpha=0.3\n            )\n\n        # Draw keypoints for all objects\n        if \"keypoints\" in annos[0]:\n            keypoints = [x[\"keypoints\"] for x in annos]\n            classes = [x[\"category_id\"] for x in annos]\n            self.overlay_keypoints(classes, keypoints)\n\n        # Draw panoptic segmentation\n        if \"panoptic_seg\" in dic:\n            panoptic_seg = dic[\"panoptic_seg\"][0]\n            segments_info = dic[\"panoptic_seg\"][1]\n            self.draw_panoptic_seg(panoptic_seg, segments_info, area_threshold=0)\n\n        # Draw semantic segmentation\n        if \"sem_seg\" in dic:\n            self.draw_sem_seg(dic[\"sem_seg\"][0], area_threshold=0)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic[\"annotations\"]\n        if \"sem_seg\" in dic:\n            sem_seg = dic[\"sem_seg\"]\n        else:\n            sem_seg = None\n        if \"pan_seg\" in dic:\n            pan_seg = dic[\"pan_seg\"]\n        else:\n            pan_seg = None\n        if \"panoptic_seg\" in dic:\n            panoptic_seg = dic[\"panoptic_seg\"]\n        else:\n            panoptic_seg = None\n        if \"bbox\" in annos:\n            bbox = annos[\"bbox\"]\n        else:\n            bbox = None\n        if \"bbox_mode\" in annos:\n            bbox_mode = annos[\"bbox_mode\"]\n        else:\n            bbox_mode = None\n        if \"keypoints\" in annos:\n            keypoints = annos[\"keypoints\"]\n        else:\n            keypoints = None\n        if \"category_id\" in annos:\n            category_id = annos[\"category_id\"]\n        else:\n            category_id = None\n        if \"segmentation\" in annos:\n            segmentation = annos[\"segmentation\"]\n        else:\n            segmentation = None\n\n        if bbox is not None:\n            self.overlay_bbox(bbox, edge_color=_RED)\n        if bbox_mode == BoxMode.XYXY_ABS:\n            self.draw_text(f\"Objects: {len(bbox)}\", (5, 5), color=_RED)\n        if keypoints is not None:\n            self.overlay_keypoints(keypoints)\n        if segmentation is not None:\n            self.draw_binary_mask(segmentation, color=_GREEN, alpha=0.5)\n        if category_id is not None:\n            self.draw_text(f\"Category: {category_id}\", (5, 30), color=_RED)\n        if sem_seg is not None:\n            self.draw_sem_seg(sem_seg, area_threshold=0, alpha=0."}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic.get(\"annotations\", [])\n\n        # draw segmentation masks if in dictionary\n        if \"segmentation\" in annos[0]:\n            masks = [x[\"segmentation\"] for x in annos]\n            # print(\"masks: \", masks)\n            # print(\"type(masks): \", type(masks))\n            if any(len(x) > 1 for x in masks):\n                masks = masks\n            else:\n                masks = masks\n            class_ids = [x[\"category_id\"] for x in annos]\n            # print(\"class_ids: \", class_ids)\n            # print(\"type(class_ids): \", type(class_ids))\n            # print(\"type(masks[0]): \", type(masks[0]))\n            # print(\"type(masks[1]): \", type(masks[1]))\n            # print(\"type(masks[2]): \", type(masks[2]))\n            # print(\"type(masks[3]): \", type(masks[3]))\n            # print(\"type(masks[4]): \", type(masks[4]))\n            # print(\"type(masks[5]): \", type(masks[5]))\n            # print(\"type(masks[6]): \", type(masks[6]))\n            # print(\"type(masks[7]): \", type(masks[7]))\n            # print(\"type(masks[8]): \", type(masks[8]))\n            # print(\"type(masks[9]): \", type(masks[9]))\n            # print(\"type(masks[10]): \", type(masks[10]))\n            # print(\"type(masks[11]): \", type(masks[11]))\n            # print(\"type(masks[12]): \", type(masks[12]))\n            # print(\"type(masks[13]): \", type(masks[13]))\n            # print(\"type(masks[14]): \", type(masks[14]))\n            #"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic.get(\"annotations\", [])\n\n        if \"sem_seg\" in dic:\n            sem_seg = dic[\"sem_seg\"]\n            if isinstance(sem_seg, tuple):\n                # convert to label map if the format is tuple\n                sem_seg = self._convert_to_label_map(sem_seg)\n            self.draw_sem_seg(sem_seg, alpha=0.5)\n\n        # draw segmentation masks for all objects\n        if \"segments_info\" in annos[0]:\n            # draw panoptic stuff\n            self.draw_panoptic_seg(\n                panoptic_seg=dic[\"panoptic_seg\"], segments_info=annos[0][\"segments_info\"]\n            )\n        else:\n            # draw regular instance masks\n            masks = [x[\"segmentation\"] for x in annos if x[\"category_id\"] != 0]\n            if masks:\n                # draw masks for all objects\n                self.overlay_instances(masks=masks, alpha=0.5)\n\n            # draw keypoints\n            keypoints = [x[\"keypoints\"] for x in annos if \"keypoints\" in x]\n            if keypoints:\n                self.draw_and_connect_keypoints(keypoints=keypoints)\n\n            # draw bounding boxes\n            if \"bbox\" in annos[0]:\n                # handle bboxes\n                self.overlay_boxes(bboxes=[x[\"bbox\"] for x in annos])\n\n        # draw keypoints\n        keypoints = [x[\"keypoints\"] for x in annos if \"keypoints\" in x]\n        if keypoints:\n            self.draw_and_connect_keypoints(keypoints=keypoints)\n\n        # draw bounding boxes\n        if \"bbox\" in annos[0]:\n            # handle bboxes\n            self.overlay_boxes(bboxes=[x[\"bbox\"] for x in annos])\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic[\"annotations\"]\n        if \"sem_seg\" in dic:\n            self.draw_sem_seg(dic[\"sem_seg\"])\n\n        if \"pan_seg\" in dic:\n            self.draw_panoptic_seg(dic[\"pan_seg\"].to(self.cpu_device), dic[\"pan_seg_metadata\"])\n\n        # draw bounding boxes\n        if \"bbox\" in annos[0]:\n            for anno in annos:\n                self.draw_bbox(anno[\"bbox\"], anno[\"category_id\"])\n        # draw keypoints\n        if \"keypoints\" in annos[0]:\n            for anno in annos:\n                self.draw_keypoints(anno[\"keypoints\"], anno[\"category_id\"])\n        # draw masks\n        if \"segmentation\" in annos[0]:\n            for anno in annos:\n                self.draw_binary_mask(\n                    anno[\"segmentation\"],\n                    anno[\"category_id\"],\n                    edge_color=_OFF_WHITE,\n                    text=self.metadata.get_thing_name(anno[\"category_id\"]),\n                )\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic.get(\"annotations\", [])\n\n        # if 'sem_seg' in dic:\n        #     self.draw_sem_seg(dic['sem_seg'])\n        # if 'panoptic_seg' in dic:\n        #     self.draw_panoptic_seg(\n        #         dic['panoptic_seg'], metadata=dic['panoptic_seg_metadata'], alpha=0.5\n        #     )\n\n        # if 'sem_seg_file_name' in dic:\n        #     self.draw_sem_seg(\n        #         cv2.imread(dic['sem_seg_file_name'], -1),\n        #         area_threshold=0,\n        #         alpha=0.5,\n        #     )\n\n        # if 'panoptic_seg_file_name' in dic:\n        #     pan_seg = cv2.imread(dic['panoptic_seg_file_name'], -1)\n        #     pan_seg = torch.tensor(pan_seg.swapaxes(1, 2))\n        #     self.draw_panoptic_seg(\n        #         pan_seg, metadata=dic['panoptic_seg_metadata'], alpha=0.5\n        #     )\n\n        for anno in annos:\n            # self.draw_annotation(anno)\n            if isinstance(anno, list):\n                self.draw_annotation(anno[0])\n            else:\n                self.draw_annotation(anno)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic.get(\"annotations\", [])\n\n        # if 'sem_seg' in dic:\n        #     sem_seg = dic['sem_seg']\n        #     self.draw_sem_seg(sem_seg, area_threshold=0)\n\n        for anno in annos:\n            # print(anno)\n            # print(anno['category_id'])\n            # print(self.metadata.thing_classes[anno['category_id']])\n            # print(self.metadata.stuff_classes[anno['category_id']])\n            # print(self.metadata.label_divisor)\n            # print(anno['category_id'] % self.metadata.label_divisor)\n\n            if anno[\"iscrowd\"]:\n                # print(anno)\n                # print(self.metadata.thing_classes[anno['category_id']])\n                self.draw_binary_mask(\n                    mask=anno[\"segmentation\"],\n                    color=self._jitter([x / 255 for x in self.metadata.thing_colors[anno['category_id']]]),\n                    text=self.metadata.thing_classes[anno['category_id']],\n                    alpha=0.8,\n                )\n            else:\n                self.draw_binary_mask(\n                    mask=anno[\"segmentation\"],\n                    color=self._jitter([x / 255 for x in self.metadata.stuff_colors[anno['category_id']]]),\n                    text=self.metadata.stuff_classes[anno['category_id']],\n                    alpha=0.8,\n                )\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic.get(\"annotations\", [])\n\n        # if 'sem_seg' in dic:\n        #     mask_format = \"bitmask\" if isinstance(dic['sem_seg'], np.ndarray) else \"rle\"\n        #     self.draw_sem_seg(dic['sem_seg'], mask_format, alpha=0.5)\n\n        # if \"pan_seg\" in dic:\n        #     self.draw_panoptic_seg(dic[\"pan_seg\"][\"seg\"], dic[\"pan_seg\"][\"seg_info\"])\n\n        for anno in annos:\n            # SEMANTIC SEGMENTATION\n            if \"segmentation\" in anno:\n                if isinstance(anno[\"segmentation\"], list):\n                    # polygon\n                    for segm in anno[\"segmentation\"]:\n                        self.draw_polygon(segm, anno[\"category_id\"])\n                elif isinstance(anno[\"segmentation\"], dict):\n                    # RLE\n                    self.draw_mask(anno[\"segmentation\"], anno[\"category_id\"])\n                else:\n                    raise NotImplementedError(\n                        \"Add support for new segmentation format\"\n                    )\n\n            # BOUNDING BOXES\n            if \"bbox\" in anno:\n                self.draw_box(anno[\"bbox\"], anno[\"category_id\"])\n\n            # CATEGORIES\n            if \"category_id\" in anno:\n                # use category metadaata (e.g. color) from dataset label info\n                if \"meta\" in anno and \"category_id\" in anno[\"meta\"]:\n                    assert anno[\"meta\"][\"category_id\"] == anno[\"category_id\"]\n                    category_id = anno[\"meta\"][\"category_id\"]\n                else:\n                    category_id = anno[\"category_id\"]\n\n                if \"keypoints\" in anno:\n                    self.draw_keypoints(\n                        anno[\"keypoints\"], category_id, keypoint_threshold=self.keypoint_threshold\n                    )\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic.get(\"annotations\", [])\n\n        # if \"sem_seg\" in dic:\n        #     sem_seg = dic[\"sem_seg\"]\n        #     self.draw_sem_seg(sem_seg, alpha=0.5)\n\n        # if \"panoptic_seg\" in dic:\n        #     panoptic_seg, segments_info = dic[\"panoptic_seg\"]\n        #     self.draw_panoptic_seg(panoptic_seg, segments_info, area_threshold=0)\n\n        # if \"instances\" in dic:\n        #     instances = dic[\"instances\"]\n        #     if not self.metadata or not self.metadata.has_thing_class:\n        #         thing_colors = colormap(\n        #             np.arange(len(instances) + 1) % len(colormap), alpha=1\n        #         ).tolist()\n        #         self.metadata = MetadataCatalog.get(\"thing_predictions\")\n        #         self.metadata.thing_colors = thing_colors\n\n        #     self.overlay_instances(instances=instances)\n\n        # draw keypoints\n        # if \"keypoints\" in dic:\n        #     keypoints = dic[\"keypoints\"][\"keypoints\"]\n        #     num_instances, _ = keypoints.shape\n        #     for kp in keypoints:\n        #         self.draw_and_connect_keypoints(kp[:, :2])\n\n        # draw bounding boxes or masks\n        if \"bboxes\" in dic:\n            boxes = dic[\"bboxes\"][\"boxes\"]\n            num_instances = len(boxes)\n            if \"bbox_mode\" in dic[\"bboxes\"]:\n                assert dic[\"bboxes\"][\"bbox_mode\"] == BoxMode.XYXY_ABS\n                if num_instances:\n                    for k in range(num_instances):\n                        bbox = BoxMode.convert(boxes[k], BoxMode.XYXY_ABS, BoxMode.XYWH"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        \"\"\"\n        Input-Output Arguments\n        :param self: Visualizer. An instance of the Visualizer class.\n        :param binary_mask: ndarray. A numpy array of shape (H, W) representing the binary mask, where H is the image height and W is the image width. Each value in the array is either 0 or 1 of uint8 type.\n        :param color: Optional. The color of the mask. If None, a random color is chosen. Accepts formats listed in `matplotlib.colors`.\n        :param edge_color: Optional. The color of the polygon edges. Accepts formats listed in `matplotlib.colors`.\n        :param text: str, Optional. The text to be drawn on the mask. If None, no text is drawn.\n        :param alpha: float, Optional. The blending efficiency for the mask, with smaller values leading to more transparent masks. Defaults to 0.5.\n        :param area_threshold: float, Optional. The minimum area of connected components to be shown. Defaults to 10.\n        :return: VisImage. The image object with the mask drawn on it.\n        \"\"\"\n\n        \"\"\"\n        Input-Output Arguments\n        :param self: Visualizer. An instance of the Visualizer class.\n        :param binary_mask: ndarray. A numpy array of shape (H, W) representing the binary mask, where H is the image height and W is the image width. Each value in the array is either 0 or 1 of uint8 type.\n        :param color: Optional. The color of the mask. If None, a random color is chosen. Accepts formats listed in `matplotlib.colors`.\n        :param edge_color: Optional. The color of the polygon edges. Accepts formats listed in `matplotlib.colors`.\n        :param text: str, Optional. The text to be drawn on the mask. If None, no text is drawn.\n        :param alpha: float, Optional. The blending efficiency for the mask, with smaller values leading to more transparent masks. Defaults to 0.5.\n        :param area_threshold: float, Optional. The minimum area of connected components to be shown. Defaults to 10"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        \"\"\"\n        This function draws a binary mask on an image. It supports drawing regular masks as polygons and masks with holes using a different approach. It can also draw text on the mask if specified. The function allows for customization of the mask's color, edge color, transparency, and the minimum area of components to be drawn.\n\n        Input-Output Arguments\n        :param self: Visualizer. An instance of the Visualizer class.\n        :param binary_mask: ndarray. A numpy array of shape (H, W) representing the binary mask, where H is the image height and W is the image width. Each value in the array is either 0 or 1 of uint8 type.\n        :param color: Optional. The color of the mask. If None, a random color is chosen. Accepts formats listed in `matplotlib.colors`.\n        :param edge_color: Optional. The color of the polygon edges. Accepts formats listed in `matplotlib.colors`.\n        :param text: str, Optional. The text to be drawn on the mask. If None, no text is drawn.\n        :param alpha: float, Optional. The blending efficiency for the mask, with smaller values leading to more transparent masks. Defaults to 0.5.\n        :param area_threshold: float, Optional. The minimum area of connected components to be shown. Defaults to 10.\n        :return: VisImage. The image object with the mask drawn on it.\n        \"\"\"\n        # If mask is not a numpy array, make it one.\n        if isinstance(binary_mask, list):\n            binary_mask = np.array(binary_mask)\n        # If mask is not binary, make it binary.\n        if binary_mask.max() != 1:\n            binary_mask = np.uint8(binary_mask > 0.5)\n        # If mask is not a numpy array, make it one.\n        if isinstance(binary_mask, list):\n            binary_mask = np.array(binary_mask)\n        # If mask is not binary, make it binary.\n        if binary_mask.max() != 1:\n            binary_mask = np.uint8("}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        # Draw the mask as a polygon\n        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        edge_color = edge_color or color\n        polygon = _binary_mask_to_polygon(binary_mask, area_threshold)\n        polygon = [polygon] if polygon else None\n        self.draw_polygon(polygon, color=color, edge_color=edge_color, alpha=alpha)\n\n        # Draw text on the mask\n        if text:\n            text_pos = (0, 0)\n            horiz_align = \"center\"\n            font_size = self._default_font_size\n            self.draw_text(\n                text, text_pos, color=color, horizontal_alignment=horiz_align, font_size=font_size\n            )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        # If the mask is in RLE format, convert it to a regular binary mask.\n        if isinstance(binary_mask, dict) and \"counts\" in binary_mask:\n            binary_mask = binary_mask[\"counts\"]\n            binary_mask = self._decode_binary_mask(binary_mask)\n\n        # If the mask is a regular binary mask, convert it to a polygon.\n        if isinstance(binary_mask, np.ndarray):\n            binary_mask = self._binary_mask_to_polygon(binary_mask)\n\n        # If the mask is a polygon, convert it to a polygon list.\n        if isinstance(binary_mask, list):\n            binary_mask = [self._convert_polygon_to_polygon_list(polygon) for polygon in binary_mask]\n\n        # If the mask is a polygon list, convert it to a polygon list.\n        if isinstance(binary_mask, list):\n            binary_mask = [self._convert_polygon_to_polygon_list(polygon) for polygon in binary_mask]\n\n        # If the mask is a polygon list, convert it to a polygon list.\n        if isinstance(binary_mask, list):\n            binary_mask = [self._convert_polygon_to_polygon_list(polygon) for polygon in binary_mask]\n\n        # If the mask is a polygon list, convert it to a polygon list.\n        if isinstance(binary_mask, list):\n            binary_mask = [self._convert_polygon_to_polygon_list(polygon) for polygon in binary_mask]\n\n        # If the mask is a polygon list, convert it to a polygon list.\n        if isinstance(binary_mask, list):\n            binary_mask = [self._convert_polygon_to_polygon_list(polygon) for polygon in binary_mask]\n\n        # If the mask is a polygon list, convert it to a polygon list.\n        if isinstance(binary_mask, list):\n            binary_mask = [self._convert_polygon_to_polygon_list(polygon) for polygon in binary_mask]"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        \"\"\"\n        Args:\n            binary_mask (ndarray): numpy array of shape (H, W), binary mask to draw\n            color: color of the mask\n            edge_color: color of the polygon edges. If None, color is used.\n            text: text to draw\n            alpha: alpha of the mask\n            area_threshold: minimal area of mask to draw\n\n        Returns:\n            output (VisImage): image object with mask drawn.\n        \"\"\"\n        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        if edge_color is None:\n            # make edge color darker than the background\n            edge_color = self._change_color_brightness(color, brightness_factor=-0.7)\n        edge_color = mplc.to_rgb(edge_color) + (1,)\n\n        has_valid_segment = False\n        binary_mask = binary_mask.astype(\"uint8\")  # opencv needs uint8\n        mask = GenericMask(binary_mask, self.output.height, self.output.width)\n        shape2d = (binary_mask.shape[0], binary_mask.shape[1])\n\n        if mask.has_holes:\n            hole_masks = mask.polygons()\n            hole_color = self._change_color_brightness(color, brightness_factor=-0.7)\n            for hole_mask in hole_masks:\n                hole_color = random_color(rgb=True, maximum=1)\n                hole_mask = np.asarray(hole_mask.exterior.coords).clip(0, shape2d[1]).astype(np.int32)\n                cv2.fillPoly(\n                    img=binary_mask,\n                    pts=[hole_mask],\n                    color=(1 if binary_mask.ndim > 2 else 255),\n                )\n                self.draw_polygon(\n                    hole_mask,\n                    color=hole_color,\n                    edge_color=edge_color,\n                    alpha=alpha,\n                )"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        # Draw the mask on the image.\n        self.draw_polygon(binary_mask, color, edge_color=edge_color, alpha=alpha, area_threshold=area_threshold)\n\n        # Draw the text on the image.\n        if text is not None:\n            self.draw_text(text, (0, 0), color=color)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        # Draw the mask on the image.\n        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        if edge_color is None:\n            edge_color = random_color(rgb=True, maximum=1)\n\n        binary_mask = np.asarray(binary_mask).astype(np.uint8)\n        contours, hierarchy = cv2.findContours(binary_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n        for contour in contours:\n            self.draw_polygon(contour, color=color, edge_color=edge_color, alpha=alpha, text=text,\n                              edge_width=1, area_threshold=area_threshold)\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        \"\"\"\n        Args:\n            binary_mask (ndarray): numpy array of shape (H, W), binary mask to be drawn.\n            color: color of the mask. If None, it will be randomly sampled from\n                self._mask_colors.\n            edge_color: color of the polygon edges. If None, it will be set to color.\n            text: text to be displayed along with the mask.\n            alpha: blending efficient. Smaller values lead to more transparent masks.\n            area_threshold: minimal area of a component in # of pixels to be shown.\n\n        Returns:\n            output (VisImage): image object with mask drawn.\n        \"\"\"\n        # if color is None:\n        #     color = random.choice(self._mask_colors)\n        # color = mplc.to_rgb(color)\n        # if edge_color is None:\n        #     edge_color = color\n        # edge_color = mplc.to_rgb(edge_color)\n\n        # Use `putpixel` instead of `draw_polygon` here, because `draw_polygon`\n        # will cause trouble for panoptic segmentation.\n        # for x in range(binary_mask.shape[1]):\n        #     for y in range(binary_mask.shape[0]):\n        #         if binary_mask[y, x] > 0:\n        #             self.output.img[y, x] = color\n        #             self.output.img[max(0, y - 1), x] = color\n        #             self.output.img[y, max(0, x - 1)] = color\n        #             self.output.img[min(y + 1, binary_mask.shape[0] - 1), x] = color\n        #             self.output.img[y, min(x + 1, binary_mask.shape[1] - 1)] = color\n        #             if not (0 <= y - 1 < binary_mask.shape[0] and 0 <= x - 1 < binary_mask.shape[1]):\n        #                 continue\n        #            "}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        # Draw the mask\n        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        color = mplc.to_rgb(color)\n        edge_color = mplc.to_rgb(edge_color) if edge_color is not None else edge_color\n        edge_color = (1.0, 1.0, 1.0) if edge_color is None else edge_color\n        edge_color = np.array(edge_color)\n        edge_color = edge_color * np.ones((binary_mask.shape[0], binary_mask.shape[1], -1), dtype=np.uint8)\n\n        binary_mask = binary_mask.astype(np.uint8)\n        mask_image = np.zeros(binary_mask.shape[:2] + (3,), dtype=np.uint8)\n        mask_image[:, :, :] = color\n        mask_image = np.where(binary_mask == 1, mask_image, edge_color)\n        mask_image = cv2.cvtColor(mask_image, cv2.COLOR_RGB2BGR)\n        self.output.ax.imshow(mask_image, extent=(0, self.output.width, self.output.height, 0))\n\n        # Draw the text\n        if text is not None:\n            text_pos = (mask_image.shape[1] * 0.1, mask_image.shape[0] * 0.1)  # (x, y)\n            self.draw_text(text, text_pos, color=color, horizontal_alignment=\"left\")\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        # If the mask is not binary, convert it to a binary mask.\n        binary_mask[binary_mask != 0] = 1\n\n        # If a color is not provided, choose a random color.\n        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        # If an edge color is not provided, choose a color with a low saturation.\n        if edge_color is None:\n            edge_color = random_color(rgb=True, maximum=1, minimum=0.3)\n\n        # If a text is provided, draw it.\n        if text is not None:\n            self.draw_text(text, (0, 0), color=color)\n\n        # If the mask is a polygon mask, draw it as a polygon.\n        if isinstance(binary_mask, GenericMask):\n            self.draw_polygon(binary_mask.polygons, color=color, edge_color=edge_color, alpha=alpha)\n\n        # If the mask is a binary mask, draw it as a connected component.\n        else:\n            # Find the connected components in the mask.\n            cnts = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n            cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n\n            # Draw only the connected components that are large enough.\n            for c in cnts:\n                if cv2.contourArea(c) >= area_threshold:\n                    self.draw_polygon(c, color=color, edge_color=edge_color, alpha=alpha)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        \"\"\"\n        Draw a binary mask on an image.\n\n        Args:\n            binary_mask (ndarray): The prediction result is the binary mask. The shape is (H, W)\n            color (RGB format color, tuple of 3 numbers): The color to draw the mask. If None, random color is used.\n            edge_color (RGB format color, tuple of 3 numbers): The color to draw the edge of the mask. If None, it is same with `color`.\n            text (str): If provided, mask will be drawn with this text.\n            alpha (float): blending efficient. Smaller values lead to more transparent masks.\n        \"\"\"\n        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        if edge_color is None:\n            # make edge color darker than the background for better visibility\n            edge_color = self._change_color_brightness(color, brightness_factor=-0.7)\n        edge_color = mplc.to_rgb(edge_color) + (1,)\n\n        binary_mask = binary_mask.astype(\"uint8\")\n        mask = GenericMask(binary_mask, self.output.height, self.output.width)\n        shape2d = (binary_mask.shape[0], binary_mask.shape[1])\n\n        fg_mask = mask.get_mask_instance_with_hole(shape2d)\n        if fg_mask is None:\n            fg_mask = mask.get_mask()\n        contours = cv2.findContours(\n            fg_mask.astype(\"uint8\"), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE\n        )\n        # Using hierarchy might be useful if we want to draw contour for instance\n        # levels.\n        # hierarchy = contours[1]\n        contours = contours[0]\n\n        for contour in contours:\n            contour = contour.astype(\"int32\")\n            self.draw_polygon(contour, color=color, edge_color=edge_color"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        if edge_color is None:\n            # make edge color darker than the mask color\n            if all(0.2 <= x <= 0.5 for x in to_rgb(color)):\n                edge_color = [\n                    x / 1.5 if x <= 0.5 else x / 0.8 for x in to_rgb(color)\n                ]\n            else:\n                edge_color = [min(x * 0.8, 1.0) for x in to_rgb(color)]\n\n        edge_color = mplc.to_rgb(edge_color) + (1,)\n        area_threshold = area_threshold if area_threshold else 10\n\n        # pad mask to ensure proper polygons for masks that touch image edges.\n        padded_binary_mask = np.zeros(\n            (binary_mask.shape[0] + 2, binary_mask.shape[1] + 2), dtype=np.uint8\n        )\n        padded_binary_mask[1:-1, 1:-1] = binary_mask\n        contours = find_contours(padded_binary_mask, 0.5)\n        contours = np.subtract(contours, 1)\n\n        for contour in contours:\n            contour = np.fliplr(contour)\n            if contour.shape[0] == 0:\n                continue\n            area = cv2.contourArea(contour)\n            if area < area_threshold:\n                continue\n            # TODO: remove this recast to np.int32 once the issue\n            # in the below line is resolved.\n            contour = contour.astype(np.int32)\n            self.draw_polygon(contour, color=color, edge_color=edge_color, alpha=alpha)\n\n            if text:\n                x, y = contour[0][0]\n                self.draw_text(text, (x, y), color=color, area"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        \"\"\"\n        Args:\n            binary_mask: numpy array of shape (H, W), where H is the image height and\n                W is the image width. Each value in the array is either a 0 or 1,\n                and 0 represents the background, 1 represents the object.\n            color: color of the mask. Refer to `matplotlib.colors` for a full list of\n                formats that are accepted.\n            edge_color: color of the polygon edges. Refer to `matplotlib.colors` for a\n                full list of formats that are accepted.\n            text: str. The text to be displayed with the mask.\n            alpha: float. Blending efficient. Smaller values lead to more transparent masks.\n            area_threshold: float. If `area_threshold` > 0,\n                will not render a polygon with an area smaller than it.\n\n        Returns:\n            output (VisImage): image object with mask drawn.\n        \"\"\"\n        if area_threshold > 0:\n            # too small masks will be ignored\n            if binary_mask.sum() <= area_threshold:\n                return self.output\n\n        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        h, w = binary_mask.shape\n        binary_mask = binary_mask.reshape(h, w, 1)\n        binary_mask = np.asarray(binary_mask, dtype=np.uint8)\n\n        contours, hierarchy = cv2.findContours(binary_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n        if not contours:\n            return self.output\n        # This is the single-contour version.\n        # contour = max(contours, key=lambda x: cv2.contourArea(x))\n        # This is the multi-contour version.\n        # contours = sorted(contours, key=lambda x: cv2.contourArea(x), reverse=True)\n        # contour = contours[0]\n        for contour in contours:\n            contour = contour"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        \"\"\"\n        Args:\n            binary_mask (ndarray): numpy array of shape (H, W), binary mask to be visualized.\n            color: color of the mask. If None, it will be randomly sampled from\n                self._instance_mode_color_map.\n            edge_color: color of the polygon edges. If None, it will be set to color.\n            text: str. The text to be displayed with the mask.\n            alpha: float. blending efficiency of the mask.\n            area_threshold: float. If `mask` is a polygon, all its areas below this\n                threshold will not be drawn.\n\n        Returns:\n            output (VisImage): image object with mask drawn.\n        \"\"\"\n        if color is None:\n            # randomly select mask color\n            color = random_color(rgb=True, maximum=1)\n        color = mplc.to_rgb(color)\n        color = np.array(color) * 255\n\n        edge_color = self._change_color_brightness(color, brightness_factor=0.7)\n        edge_color = mplc.to_rgb(edge_color)\n        edge_color = np.array(edge_color) * 255\n\n        if binary_mask.ndim != 2:\n            raise ValueError(\"binary_mask should be a single channel array\")\n\n        binary_mask = binary_mask.astype(\"uint8\")\n        binary_mask = np.asarray(binary_mask, order=\"F\")\n\n        contours, hierarchy = cv2.findContours(\n            binary_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE\n        )\n        if not contours:\n            return self.output\n\n        # Mask is split into two contours (outer and inner)\n        # If mask has more than 2 contours, only the first two will be considered\n        contour_num = min(2, len(contours))\n\n        # Create polygons for mask\n        for i in range(contour_num):\n            contour = contours[i"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        # If no color is provided, choose a random color\n        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        # If no edge color is provided, choose a color with a low saturation\n        if edge_color is None:\n            edge_color = random_color(rgb=True, maximum=1, minimum=0.8)\n\n        # Convert the mask to a polygon\n        contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n        polygons = []\n        for contour in contours:\n            contour = contour.flatten().tolist()\n            if len(contour) > 4:\n                polygon = Polygon(contour, color=color)\n                polygons.append(polygon)\n\n        # Draw the contours on the image\n        for polygon in polygons:\n            self.draw_polygon(polygon, edge_color=edge_color, alpha=alpha)\n\n        # Draw the text on the image\n        if text is not None:\n            text_positions = []\n            for polygon in polygons:\n                text_positions.append(polygon.label_positions[0])\n            self.draw_multiple_text(\n                text, text_positions, color=edge_color, font_size=self._default_font_size\n            )\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        # If the mask is in uint8 format, convert it to bool\n        if binary_mask.dtype == np.uint8:\n            binary_mask = binary_mask > 0\n\n        # If a color is not specified, choose a random color\n        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        # If a edge color is not specified, choose a random color\n        if edge_color is None:\n            edge_color = random_color(rgb=True, maximum=1)\n\n        # Copy binary mask array into a color mask array\n        color_mask = np.zeros((binary_mask.shape[0], binary_mask.shape[1], 3))\n        color_mask[binary_mask] = color\n\n        # Find the contours of each individual mask\n        contours = find_contours(binary_mask, 0.5)\n\n        # Draw the contours on the color mask\n        for contour in contours:\n            contour = np.flip(contour, axis=1)\n            self.draw_polygon(contour, color=edge_color, alpha=alpha)\n\n        # Remove the masks with small areas\n        color_mask = remove_small_objects(color_mask, area_threshold)\n\n        # Draw the masks on the image\n        self.draw_polygon(color_mask, color=color, alpha=alpha)\n\n        # Draw the text on the mask\n        if text is not None:\n            self.draw_text(text, [0, 0], color=color)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        \"\"\"\n        Draw a binary mask on an image.\n\n        Args:\n            binary_mask (ndarray): The prediction result is the binary mask.\n            color: The color to draw the mask with. If None is given, random color will be used.\n            edge_color: The color to draw the mask edge with. If None is given, random color will be used.\n            text: The text to draw with the mask.\n            alpha: The transparency of the mask.\n            area_threshold: The minimal area of the mask to be drawn.\n\n        Returns:\n            output (VisImage): image object with mask drawn.\n        \"\"\"\n        if len(binary_mask.shape) == 3:\n            binary_mask = np.amax(binary_mask, axis=0)\n        if binary_mask.ndim != 2:\n            raise ValueError(\"binary_mask should be 2 dimensional. Got {} dimensions.\".format(binary_mask.ndim))\n        if binary_mask.shape[0] != self.output.height or binary_mask.shape[1] != self.output.width:\n            binary_mask = cv2.resize(binary_mask, self.output.size, interpolation=cv2.INTER_NEAREST)\n\n        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        if not np.finfo(np.float32).eps < color[0] < 1.0 - np.finfo(np.float32).eps:\n            color = mplc.to_rgb(color)\n            color = np.array(color[0] * 255, color[1] * 255, color[2] * 255, keepdims=True).astype(np.uint8)\n        # binary_mask = binary_mask.astype(np.uint8)\n        contours, hierarchy = cv2.findContours((binary_mask * 255).astype(np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n        # print(cont"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        # If the mask is not binary, convert it to a binary mask.\n        binary_mask = np.array(binary_mask, dtype=np.uint8)\n        binary_mask[binary_mask > 0] = 1\n\n        # If a color is not specified, choose a random color.\n        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        # If the edge color is not specified, choose a color that is contrasted\n        # against the main color.\n        if edge_color is None:\n            edge_color = self._change_color_brightness(color, brightness_factor=-0.7)\n\n        # If the text is not specified, create an empty string.\n        if text is None:\n            text = \"\"\n\n        # Create a mask image that is a single channel.\n        mask_image = np.zeros(shape=binary_mask.shape + (3,), dtype=np.uint8)\n\n        # Draw the binary mask on the image.\n        mask_image[:, :, :] = color\n        mask_image[binary_mask == 1] = 0\n\n        # Draw the contour of the mask on the image.\n        contours, hierarchy = cv2.findContours(binary_mask.astype(np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n\n        # If the contours are not empty, draw them on the image.\n        if contours:\n            cv2.drawContours(mask_image, contours, -1, edge_color, 1)\n\n        # Draw the text on the image.\n        text_image = np.zeros(shape=mask_image.shape, dtype=np.uint8)\n        text_image[:, :, :] = color\n        text_image = putText(text_image, text, org=(0, 15), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.5, color=(0, 0, 0), thickness=1)"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        binary_mask = np.asarray(binary_mask).astype(np.bool)\n        contours, hierarchy = cv2.findContours(binary_mask.astype(np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n\n        if not contours:\n            return self.output\n\n        # If not empty, find the contour with the largest area.\n        contour = max(contours, key=cv2.contourArea)\n        if cv2.contourArea(contour) < area_threshold:\n            return self.output\n\n        if edge_color is None:\n            edge_color = color\n\n        # Generate random color if None is provided.\n        edge_color = mplc.to_rgb(edge_color) + (1,)\n        color = mplc.to_rgb(color) + (1,)\n\n        # Draw contour using cv2 directly.\n        self.draw_contour(contour, edge_color=edge_color, linewidth=max(1, int(self._default_font_size / 4)))\n\n        # Draw mask using cv2 directly.\n        mask_image = np.ones(binary_mask.shape)\n        mask_image = cv2.drawContours(mask_image, [contour], -1, color=1, thickness=-1)\n        self.draw_mask(mask_image, color=color, alpha=alpha)\n\n        if text:\n            self.draw_text(text, contour[0][0][0], color=edge_color)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        # Draw binary mask\n        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        color = mplc.to_rgb(color)\n        edge_color = mplc.to_rgb(edge_color) if edge_color is not None else color\n\n        # Convert the mask to polygons\n        mask = np.array(binary_mask, dtype=np.uint8)\n        contours, hierarchy = cv2.findContours(\n            mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE\n        )\n        polygons = [c.reshape(-1, 2) for c in contours]\n        # If there is no polygon, just draw the mask\n        if len(polygons) == 0:\n            mask = np.ma.masked_not_equal(mask, 0)\n            mask = mask.astype(np.uint8)\n            mask_color = np.array(color) * 255\n            mask_color = np.expand_dims(mask_color, axis=2)\n            mask_color = np.repeat(mask_color, mask.shape[2], axis=2)\n            self.output.ax.imshow(mask, cmap=\"gray\", interpolation=\"none\", alpha=alpha)\n            return self.output\n\n        # If there is a polygon, draw the mask with the polygon\n        # Otherwise, draw the mask with the mask\n        for polygon in polygons:\n            # If the polygon is too small, do not draw it\n            if cv2.contourArea(polygon) < area_threshold:\n                continue\n            # If the polygon is a hole, draw the polygon with its edge\n            if hierarchy[0, 0, 3] == polygon_i:\n                edge_color = self._change_color_brightness(edge_color, brightness_factor=-0.7)\n            # Otherwise, draw the polygon with its color\n            self.draw_polygon(polygon, color=color, edge_color=edge_color, alpha=alpha)\n        return self"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert input.image_size == other.image_size, f\"{msg} Image sizes do not match! \"\n    if size_as_tensor:\n        assert torch.equal(input.image_size, other.image_size), f\"{msg} Image sizes do not match! \"\n    assert input.proposal_boxes == other.proposal_boxes, f\"{msg} proposal_boxes do not match! \"\n    assert input.objectness_logits == other.objectness_logits, f\"{msg} objectness_logits do not match! \"\n    assert input.pred_boxes == other.pred_boxes, f\"{msg} pred_boxes do not match! \"\n    assert input.scores == other.scores, f\"{msg} scores do not match! \"\n    assert input.pred_classes == other.pred_classes, f\"{msg} pred_classes do not match! \"\n    assert input.pred_masks == other.pred_masks, f\"{msg} pred_masks do not match! \"\n    assert input.pred_keypoints == other.pred_keypoints, f\"{msg} pred_keypoints do not match! \"\n    assert input.pred_keypoint_heatmaps == other.pred_keypoint_heatmaps, f\"{msg} pred_keypoint_heatmaps do not match! \"\n\n"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if not isinstance(input, Instances):\n        raise ValueError(\"Input is not an Instances object.\")\n    if not isinstance(other, Instances):\n        raise ValueError(\"Other is not an Instances object.\")\n\n    if size_as_tensor:\n        if not torch.is_tensor(input.image_size) and not isinstance(input.image_size, tuple):\n            raise ValueError(\"Input image_size is not a tensor or tuple.\")\n        if not torch.is_tensor(other.image_size) and not isinstance(other.image_size, tuple):\n            raise ValueError(\"Other image_size is not a tensor or tuple.\")\n        if torch.is_tensor(input.image_size) and torch.is_tensor(other.image_size):\n            assert torch.allclose(input.image_size, other.image_size), msg\n        elif isinstance(input.image_size, tuple) and isinstance(other.image_size, tuple):\n            assert input.image_size == other.image_size, msg\n    else:\n        assert input.image_size == other.image_size, msg\n\n    for input_field, other_field in zip(input._fields, other._fields):\n        assert input_field == other_field, msg\n        if input_field == \"pred_boxes\":\n            assert torch.allclose(input.pred_boxes, other.pred_boxes, rtol=rtol), msg\n        elif input_field == \"pred_masks\":\n            assert torch.allclose(input.pred_masks, other.pred_masks), msg\n        elif input_field == \"pred_keypoints\":\n            assert torch.allclose(input.pred_keypoints, other.pred_keypoints, rtol=rtol), msg\n        elif input_field == \"pred_classes\":\n            assert torch.allclose(input.pred_classes, other.pred_classes), msg\n        elif input_field == \"scores\":\n            assert torch.allclose(input.scores, other.scores, rtol=rtol), msg"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert isinstance(input, Instances), f\"Input must be an Instances object, but got {type(input)}\"\n    assert isinstance(other, Instances), f\"Other must be an Instances object, but got {type(other)}\"\n\n    if size_as_tensor:\n        assert torch.is_tensor(input.image_size), f\"Input image_size must be a tensor, but got {type(input.image_size)}\"\n        assert torch.is_tensor(other.image_size), f\"Other image_size must be a tensor, but got {type(other.image_size)}\"\n        assert torch.allclose(input.image_size, other.image_size), f\"Image sizes don't match. Input: {input.image_size}, Other: {other.image_size}\"\n    else:\n        assert isinstance(input.image_size, tuple), f\"Input image_size must be a tuple, but got {type(input.image_size)}\"\n        assert isinstance(other.image_size, tuple), f\"Other image_size must be a tuple, but got {type(other.image_size)}\"\n        assert input.image_size == other.image_size, f\"Image sizes don't match. Input: {input.image_size}, Other: {other.image_size}\"\n\n    for input_field, other_field in zip(input._fields, other._fields):\n        assert input_field == other_field, f\"Field names don't match. Input: {input_field}, Other: {other_field}\"\n\n    for input_field, other_field in zip(input._fields, other._fields):\n        assert input_field == other_field, f\"Field names don't match. Input: {input_field}, Other: {other_field}\"\n\n        input_value = getattr(input, input_field)\n        other_value = getattr(other, other_field)\n\n        if isinstance(input_value, Boxes):\n            assert torch.allclose(input_value.tensor, other_value.tensor, rtol=rtol, at"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if input.image_size != other.image_size:\n        if size_as_tensor:\n            if input.image_size[0].shape != other.image_size[0].shape:\n                raise ValueError(\"Mismatch in image size shape: {} vs {}\".format(input.image_size[0].shape, other.image_size[0].shape))\n            sz0 = input.image_size[0].item() == other.image_size[0].item()\n            sz1 = input.image_size[1].item() == other.image_size[1].item()\n        else:\n            sz0 = input.image_size[0] == other.image_size[0]\n            sz1 = input.image_size[1] == other.image_size[1]\n        assert sz0 and sz1, \"{}Mismatch in image size: {} vs {}\".format(msg, input.image_size, other.image_size)\n\n    for name in sorted(input.get_fields().keys()):\n        if isinstance(input.get(name), Boxes):\n            assert torch.allclose(input.get(name).tensor, other.get(name).tensor, rtol=rtol, atol=0.0), \"{}Mismatch in {} of type Boxes: {} vs {}\".format(msg, name, input.get(name), other.get(name))\n        elif isinstance(input.get(name), ROIMasks):\n            assert torch.allclose(input.get(name).tensor, other.get(name).tensor, rtol=rtol, atol=0.0), \"{}Mismatch in {} of type ROIMasks: {} vs {}\".format(msg, name, input.get(name), other.get(name))\n        elif isinstance(input.get(name), torch.Tensor):\n            assert torch.allclose(input.get(name), other.get(name), rtol=rtol, atol=0.0), \"{}Mismatch in {} of type torch.Tensor: {} vs {}\".format(msg, name, input."}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert input.image_size == other.image_size, f\"{msg} Image sizes do not match! {input.image_size} != {other.image_size}\"\n    if size_as_tensor:\n        assert torch.all(torch.eq(input.image_size, other.image_size)), f\"{msg} Image sizes do not match!\"\n\n    for name in input._field_names:\n        input_val = getattr(input, name, None)\n        other_val = getattr(other, name, None)\n        if input_val is None or other_val is None:\n            assert input_val is None and other_val is None, f\"{msg} One of the instances does not contain a value for field '{name}'\"\n            continue\n        if isinstance(input_val, Boxes):\n            assert torch.allclose(input_val.tensor, other_val.tensor, rtol=rtol), f\"{msg} Boxes are different for field '{name}'\"\n        elif isinstance(input_val, ROIMasks):\n            assert torch.allclose(input_val.tensor, other_val.tensor, rtol=rtol), f\"{msg} ROIMasks are different for field '{name}'\"\n        elif isinstance(input_val, torch.Tensor):\n            assert torch.allclose(input_val, other_val, rtol=rtol), f\"{msg} Tensors are different for field '{name}'\"\n        elif isinstance(input_val, list):\n            assert len(input_val) == len(other_val), f\"{msg} Lists have different lengths for field '{name}'\"\n            for i, input_val_elem in enumerate(input_val):\n                other_val_elem = other_val[i]\n                assert torch.allclose(input_val_elem, other_val_elem, rtol=rtol), f\"{msg} Tensors are different for field '{name}'\"\n        else:\n            raise ValueError(f\"Don't know how to compare type {type(input_val)}\")"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if not isinstance(input, Instances):\n        raise ValueError(\"Input is not an Instances object\")\n    if not isinstance(other, Instances):\n        raise ValueError(\"Other is not an Instances object\")\n\n    if size_as_tensor:\n        if not (isinstance(input.image_size, torch.Tensor) and isinstance(other.image_size, torch.Tensor)):\n            raise ValueError(\"Input and other image_size are not both torch.Tensor objects\")\n        assert torch.allclose(input.image_size, other.image_size), f\"{msg} Image sizes are not equal\"\n    else:\n        if not (isinstance(input.image_size, tuple) and isinstance(other.image_size, tuple)):\n            raise ValueError(\"Input and other image_size are not both tuples\")\n        assert input.image_size == other.image_size, f\"{msg} Image sizes are not equal\"\n\n    for input_field, other_field in zip(input.get_fields(), other.get_fields()):\n        if input_field not in other.get_fields():\n            raise AssertionError(f\"{msg} Field {input_field} is not in other\")\n        if other_field not in input.get_fields():\n            raise AssertionError(f\"{msg} Field {other_field} is not in input\")\n\n        input_value = getattr(input, input_field)\n        other_value = getattr(other, other_field)\n\n        if isinstance(input_value, Boxes) and isinstance(other_value, Boxes):\n            continue\n        if isinstance(input_value, ROIMasks) and isinstance(other_value, ROIMasks):\n            continue\n        if isinstance(input_value, torch.Tensor) and isinstance(other_value, torch.Tensor):\n            assert torch.allclose(input_value, other_value, rtol=rtol), f\"{msg} Tensor field {input_field} is not close\"\n            continue\n        if isinstance(input"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert isinstance(input, Instances), f\"Input must be an Instances object, got {type(input)}\"\n    assert isinstance(other, Instances), f\"Other must be an Instances object, got {type(other)}\"\n\n    if size_as_tensor:\n        assert torch.is_tensor(input.image_size), f\"Input image_size must be a tensor, got {type(input.image_size)}\"\n        assert torch.is_tensor(other.image_size), f\"Other image_size must be a tensor, got {type(other.image_size)}\"\n        assert (\n            input.image_size.shape == other.image_size.shape\n        ), f\"Image sizes must have the same shape, but got {input.image_size.shape} and {other.image_size.shape}\"\n        assert torch.allclose(\n            input.image_size, other.image_size\n        ), f\"Image sizes must be equal, but got {input.image_size} and {other.image_size}\"\n    else:\n        assert isinstance(input.image_size, tuple), f\"Input image_size must be a tuple, got {type(input.image_size)}\"\n        assert isinstance(other.image_size, tuple), f\"Other image_size must be a tuple, got {type(other.image_size)}\"\n        assert len(input.image_size) == len(other.image_size), f\"Image sizes must have the same number of elements, but got {len(input.image_size)} and {len(other.image_size)}\"\n        assert all(\n            s1 == s2 for s1, s2 in zip(input.image_size, other.image_size)\n        ), f\"Image sizes must be equal, but got {input.image_size} and {other.image_size}\"\n\n    for input_field, other_field in zip(input._fields, other._fields):\n        assert input_field == other_field, f\"Input and other must have the same fields, but got {input_field} and {other_field}\"\n\n    for field"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if not isinstance(input, Instances):\n        raise ValueError(\"Input must be an Instances object\")\n    if not isinstance(other, Instances):\n        raise ValueError(\"Other must be an Instances object\")\n\n    if size_as_tensor:\n        if not isinstance(input.image_size, torch.Tensor):\n            raise ValueError(\"Input image_size is not a tensor\")\n        if not isinstance(other.image_size, torch.Tensor):\n            raise ValueError(\"Other image_size is not a tensor\")\n        assert torch.allclose(input.image_size, other.image_size), f\"{msg} Image sizes are not equal\"\n    else:\n        assert input.image_size == other.image_size, f\"{msg} Image sizes are not equal\"\n\n    for input_field, other_field in zip(input._fields, other._fields):\n        assert input_field == other_field, f\"{msg} Different fields in the two instances: {input_field} vs. {other_field}\"\n        input_value = getattr(input, input_field)\n        other_value = getattr(other, other_field)\n        if isinstance(input_value, Boxes):\n            assert torch.allclose(input_value.tensor, other_value.tensor), f\"{msg} Boxes are not equal for field {input_field}\"\n        elif isinstance(input_value, ROIMasks):\n            assert torch.allclose(input_value.tensor, other_value.tensor), f\"{msg} ROIMasks are not equal for field {input_field}\"\n        elif isinstance(input_value, torch.Tensor):\n            assert torch.allclose(input_value, other_value, rtol=rtol), f\"{msg} Tensors are not close enough for field {input_field}\"\n        else:\n            raise ValueError(f\"Unknown field type {type(input_value)} in Instances object\")\n\n"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if not isinstance(input, Instances):\n        raise ValueError(\"Input object is not of type Instances!\")\n    if not isinstance(other, Instances):\n        raise ValueError(\"Other object is not of type Instances!\")\n\n    if size_as_tensor:\n        if not torch.is_tensor(input.image_size) and not isinstance(input.image_size, tuple):\n            raise ValueError(\"Input image_size is not a tensor!\")\n        if not torch.is_tensor(other.image_size) and not isinstance(other.image_size, tuple):\n            raise ValueError(\"Other image_size is not a tensor!\")\n        if torch.is_tensor(input.image_size) and torch.is_tensor(other.image_size):\n            assert torch.allclose(input.image_size, other.image_size), msg\n        elif isinstance(input.image_size, tuple) and isinstance(other.image_size, tuple):\n            assert input.image_size == other.image_size, msg\n    else:\n        if not isinstance(input.image_size, tuple) or not isinstance(other.image_size, tuple):\n            raise ValueError(\"Input or other image_size is not a tuple!\")\n        assert input.image_size == other.image_size, msg\n\n    for input_field, other_field in zip(input.get_fields(), other.get_fields()):\n        assert input_field == other_field, f\"{msg}Field names {input_field} and {other_field} don't match!\"\n        input_value = getattr(input, input_field)\n        other_value = getattr(other, other_field)\n        if isinstance(input_value, Boxes):\n            assert torch.allclose(input_value.tensor, other_value.tensor, rtol=rtol), msg\n        elif isinstance(input_value, ROIMasks):\n            assert torch.allclose(input_value.tensor, other_value.tensor, rtol=rtol), msg\n        elif isinstance("}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if not isinstance(other, Instances):\n        raise ValueError(f\"Expected an Instances object as the second argument, but got {type(other)}\")\n\n    if size_as_tensor:\n        if not isinstance(input.image_size, torch.Tensor):\n            raise ValueError(f\"Expected input.image_size to be a torch.Tensor, but got {type(input.image_size)}\")\n        if not isinstance(other.image_size, torch.Tensor):\n            raise ValueError(f\"Expected other.image_size to be a torch.Tensor, but got {type(other.image_size)}\")\n        assert torch.allclose(input.image_size, other.image_size), f\"{msg}The image sizes do not match. \"\n    else:\n        assert input.image_size == other.image_size, f\"{msg}The image sizes do not match. \"\n\n    for name in input.get_fields():\n        if name == \"proposal_boxes\" and isinstance(input.proposal_boxes, Boxes):\n            assert isinstance(other.proposal_boxes, Boxes), f\"{msg}proposal_boxes field is a Boxes object, but other does not have a Boxes object.\"\n            assert torch.allclose(input.proposal_boxes.tensor, other.proposal_boxes.tensor), f\"{msg}proposal_boxes.tensor is not close.\"\n        elif name == \"pred_boxes\" and isinstance(input.pred_boxes, Boxes):\n            assert isinstance(other.pred_boxes, Boxes), f\"{msg}pred_boxes field is a Boxes object, but other does not have a Boxes object.\"\n            assert torch.allclose(input.pred_boxes.tensor, other.pred_boxes.tensor), f\"{msg}pred_boxes.tensor is not close.\"\n        elif name == \"pred_masks\" and isinstance(input.pred_masks, ROIMasks):\n            assert"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if input.image_size != other.image_size:\n        if size_as_tensor:\n            if input.image_size != tuple(other.image_size):\n                raise AssertionError(\n                    f\"{msg} Image sizes differ: {input.image_size} != {other.image_size}\"\n                )\n        else:\n            if tuple(input.image_size) != other.image_size:\n                raise AssertionError(\n                    f\"{msg} Image sizes differ: {input.image_size} != {other.image_size}\"\n                )\n\n    for name in input._field_names:\n        input_val = getattr(input, name, None)\n        other_val = getattr(other, name, None)\n        if input_val is None or other_val is None:\n            if input_val is not other_val:\n                raise AssertionError(\n                    f\"{msg} Instances do not have the same values for field '{name}'.\"\n                )\n            continue\n\n        if isinstance(input_val, Boxes) and isinstance(other_val, Boxes):\n            assert torch.allclose(input_val.tensor, other_val.tensor, rtol=rtol), (\n                f\"{msg} Instances do not have the same values for field '{name}'.\"\n                f\"Boxes: input = {input_val}, other = {other_val}\"\n            )\n            continue\n\n        if isinstance(input_val, ROIMasks) and isinstance(other_val, ROIMasks):\n            assert torch.allclose(input_val.tensor, other_val.tensor, rtol=rtol), (\n                f\"{msg} Instances do not have the same values for field '{name}'.\"\n                f\"ROIMasks: input = {input_val}, other = {other_val}\"\n            )\n            continue\n\n        if isinstance(input_val, torch.Tensor) and isinstance(other_val, torch.Tensor):\n            assert torch.allclose(input_val, other_val, rtol"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert isinstance(input, Instances)\n    assert isinstance(other, Instances)\n\n    if size_as_tensor:\n        assert torch.is_tensor(input.image_size) and torch.is_tensor(other.image_size)\n    else:\n        assert isinstance(input.image_size, tuple) and isinstance(other.image_size, tuple)\n\n    if not input.image_size == other.image_size:\n        default_msg = f\"Mismatch in image size: {input.image_size} != {other.image_size}\"\n        raise AssertionError(msg + default_msg)\n\n    if not input.fields == other.fields:\n        default_msg = f\"Mismatch in fields: {input.fields} != {other.fields}\"\n        raise AssertionError(msg + default_msg)\n\n    for f in input.fields:\n        msg = f\"Mismatch in field '{f}'\"\n        if f == \"pred_boxes\":\n            assert_array_equal(input.get(f), other.get(f), 1e-4, msg=msg)\n        elif f == \"pred_masks\":\n            assert_array_equal(input.get(f), other.get(f), 1e-4, msg=msg)\n        elif f == \"pred_keypoints\":\n            assert_array_equal(input.get(f), other.get(f), 1e-4, msg=msg)\n        elif isinstance(input.get(f), Boxes):\n            assert_array_equal(input.get(f).tensor, other.get(f).tensor, 1e-4, msg=msg)\n        elif isinstance(input.get(f), ROIMasks):\n            assert_array_equal(input.get(f).tensor, other.get(f).tensor, 1e-4, msg=msg)\n        elif isinstance(input.get(f), torch.Tensor):\n            assert_array_equal(input.get(f), other.get(f), rtol, msg=msg)\n        else"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert isinstance(input, Instances)\n    assert isinstance(other, Instances)\n\n    if size_as_tensor:\n        assert torch.is_tensor(input.image_size) and torch.is_tensor(other.image_size)\n        assert torch.all(input.image_size == other.image_size), f\"{msg} Image sizes do not match! {input.image_size} != {other.image_size}\"\n    else:\n        assert input.image_size == other.image_size, f\"{msg} Image sizes do not match! {input.image_size} != {other.image_size}\"\n\n    for input_field, other_field in zip(input._fields, other._fields):\n        assert input_field == other_field, f\"{msg} Different fields: {input_field} vs. {other_field}\"\n        input_value = getattr(input, input_field)\n        other_value = getattr(other, other_field)\n        assert input_value is not None and other_value is not None, f\"{msg} One of the instances does not have field '{input_field}'\"\n        if isinstance(input_value, Boxes):\n            assert torch.allclose(input_value.tensor, other_value.tensor, rtol=rtol), f\"{msg} Boxes are different! {input_value} != {other_value}\"\n        elif isinstance(input_value, ROIMasks):\n            assert torch.all(input_value.tensor == other_value.tensor), f\"{msg} ROIMasks are different! {input_value} != {other_value}\"\n        elif isinstance(input_value, torch.Tensor):\n            assert torch.allclose(input_value, other_value, rtol=rtol), f\"{msg} Tensors are different! {input_value} != {other_value}\"\n        elif isinstance(input_value, np.ndarray):\n            assert np.allclose(input_value, other_value), f\"{msg} Numpy arrays are different! {input_value"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert isinstance(input, Instances)\n    assert isinstance(other, Instances)\n    assert len(input) == len(other), f\"{len(input)} != {len(other)}\"\n    assert input.image_size == other.image_size, f\"{input.image_size} != {other.image_size}\"\n    if size_as_tensor:\n        if not (isinstance(input.image_size, torch.Tensor) and isinstance(other.image_size, torch.Tensor)):\n            raise ValueError(f\"Image size inconsistent: input.image_size is {type(input.image_size)}, other.image_size is {type(other.image_size)}\")\n    else:\n        if not (isinstance(input.image_size, tuple) and isinstance(other.image_size, tuple)):\n            raise ValueError(f\"Image size inconsistent: input.image_size is {type(input.image_size)}, other.image_size is {type(other.image_size)}\")\n\n    for k, v in input.get_fields().items():\n        other_v = other[k]\n        if type(v) == Boxes:\n            assert torch.allclose(v.tensor, other_v.tensor, rtol=rtol), f\"{k} values differ: {v} != {other_v}\"\n        elif type(v) == ROIMasks:\n            assert torch.allclose(v.tensor, other_v.tensor, rtol=rtol), f\"{k} values differ: {v} != {other_v}\"\n        elif type(v) == torch.Tensor:\n            assert torch.allclose(v, other_v, rtol=rtol), f\"{k} values differ: {v} != {other_v}\"\n        elif type(v) == np.ndarray:\n            assert np.allclose(v, other_v, rtol=rtol), f\"{k} values differ: {v} != {other_v}\"\n        elif type(v) == int:\n            assert v == other_v"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if not isinstance(other, Instances):\n        raise ValueError(f\"Input 'other' must be an Instances object, but got {type(other)}\")\n\n    if size_as_tensor:\n        if not isinstance(input.image_size, torch.Tensor):\n            raise ValueError(\n                f\"Input 'input.image_size' must be a torch.Tensor, but got {type(input.image_size)}\"\n            )\n        if not isinstance(other.image_size, torch.Tensor):\n            raise ValueError(\n                f\"Input 'other.image_size' must be a torch.Tensor, but got {type(other.image_size)}\"\n            )\n        assert torch.allclose(input.image_size, other.image_size), f\"{msg} Image sizes are different! \"\n    else:\n        assert input.image_size == other.image_size, f\"{msg} Image sizes are different! \"\n\n    for k in input:\n        if k == \"mask\":\n            assert (input.get(k) == other.get(k)).all(), f\"{msg} Masks are different! \"\n        elif k == \"boxes\":\n            assert torch.allclose(input.get(k), other.get(k), rtol=rtol), f\"{msg} Boxes are different! \"\n        elif k == \"proposal_boxes\":\n            assert torch.allclose(input.get(k), other.get(k), rtol=rtol), f\"{msg} Proposal Boxes are different! \"\n        elif k == \"pred_boxes\":\n            assert torch.allclose(input.get(k), other.get(k), rtol=rtol), f\"{msg} Predicted Boxes are different! \"\n        elif k == \"gt_boxes\":\n            assert torch.allclose(input.get(k), other.get(k), rtol=rtol), f\"{msg} Ground Truth Boxes are different! \"\n        elif k == \"gt_classes\":\n            assert tor"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if not isinstance(other, Instances):\n        raise ValueError(\"Expected an Instances object as the second argument.\")\n\n    if size_as_tensor:\n        if not isinstance(input.image_size, torch.Tensor):\n            raise ValueError(\"Expected input.image_size to be a torch.Tensor.\")\n        if not isinstance(other.image_size, torch.Tensor):\n            raise ValueError(\"Expected other.image_size to be a torch.Tensor.\")\n        assert torch.allclose(\n            input.image_size, other.image_size\n        ), f\"{msg} The image sizes do not match. The input.image_size is {input.image_size} and the other.image_size is {other.image_size}.\"\n    else:\n        assert input.image_size == other.image_size, f\"{msg} The image sizes do not match. The input.image_size is {input.image_size} and the other.image_size is {other.image_size}.\"\n\n    for name in input._field_names:\n        input_val = getattr(input, name, None)\n        other_val = getattr(other, name, None)\n        if input_val is None or other_val is None:\n            # field might not exist in both; ignore if not found in one\n            continue\n\n        if isinstance(input_val, Boxes):\n            assert torch.allclose(\n                input_val.tensor, other_val.tensor, rtol=rtol\n            ), f\"{msg} The Boxes field '{name}' is not close.\"\n        elif isinstance(input_val, ROIMasks):\n            assert torch.allclose(\n                input_val.tensor, other_val.tensor, rtol=rtol\n            ), f\"{msg} The ROIMasks field '{name}' is not close.\"\n        elif isinstance(input_val, torch.Tensor):\n            assert torch.allclose(input_val, other_val, rtol=rtol), f\"{msg} The tensor field '{name"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert isinstance(input, Instances)\n    assert isinstance(other, Instances)\n\n    if size_as_tensor:\n        assert torch.is_tensor(input.image_size) and torch.is_tensor(other.image_size)\n    else:\n        assert isinstance(input.image_size, tuple) and isinstance(other.image_size, tuple)\n\n    if not input.image_size == other.image_size:\n        default_msg = f\"image_size do not match: {input.image_size} != {other.image_size}\"\n        msg = default_msg if len(msg) == 0 else default_msg + \", \" + msg\n\n    for input_field, other_field in zip(input.get_fields(), other.get_fields()):\n        assert input_field == other_field, f\"{input_field} != {other_field}\"\n        assert input_field in other._field_names, f\"{input_field} is not in {other._field_names}\"\n\n        in_val = getattr(input, input_field)\n        if isinstance(in_val, Boxes):\n            # boxes in tensor mode are not comparable because of the different internal representation\n            if torch.is_tensor(in_val.tensor):\n                default_msg = f\"cannot compare {input_field} because it is a tensor of Boxes\"\n                msg = default_msg if len(msg) == 0 else default_msg + \", \" + msg\n            else:\n                assert torch.allclose(\n                    in_val.tensor, getattr(other, other_field).tensor, rtol=rtol\n                ), f\"{input_field} and {other_field} differ\"\n        elif isinstance(in_val, ROIMasks):\n            # ROIMasks in tensor mode are not comparable because of the different internal representation\n            if torch.is_tensor(in_val._tensor):\n                default_msg = f\"cannot compare {input_field} because it is a tensor of ROIMasks\"\n                msg = default_msg if len("}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert isinstance(input, Instances) and isinstance(\n        other, Instances\n    ), f\"Input and other must be instances of Instances. Got: {type(input)} and {type(other)}.\"\n\n    if size_as_tensor:\n        assert torch.all(\n            torch.eq(input.image_size, other.image_size)\n        ), f\"Image sizes do not match: {input.image_size} != {other.image_size}\"\n    else:\n        assert input.image_size == other.image_size, f\"Image sizes do not match: {input.image_size} != {other.image_size}\"\n\n    for k in input.get_fields().keys():\n        assert k in other.get_fields(), f\"Field {k} is missing from other instances.\"\n        if isinstance(input.get(k), Boxes):\n            assert torch.all(\n                torch.eq(input.get(k), other.get(k))\n            ), f\"Field {k} is not equal: \\n{input.get(k)}\\n{other.get(k)}\"\n        elif isinstance(input.get(k), ROIMasks):\n            assert torch.all(\n                torch.eq(input.get(k).tensor, other.get(k).tensor)\n            ), f\"Field {k} is not equal: \\n{input.get(k)}\\n{other.get(k)}\"\n        elif isinstance(input.get(k), torch.Tensor):\n            assert torch.allclose(\n                input.get(k), other.get(k), rtol=rtol\n            ), f\"Field {k} is not close with rtol={rtol}: \\n{input.get(k)}\\n{other.get(k)}\"\n        elif isinstance(input.get(k), np.ndarray):\n            assert np.allclose(\n                input.get(k), other.get(k), rtol=rtol, atol=1e-5\n            ), f\"Field {k} is not close with rtol={rtol}: \\"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert isinstance(input, Instances), f\"input must be Instances object, got {type(input)}\"\n    assert isinstance(other, Instances), f\"input must be Instances object, got {type(other)}\"\n\n    assert (\n        input.image_size == other.image_size\n    ), f\"image_size do not match: {input.image_size} != {other.image_size}\"\n\n    if size_as_tensor:\n        assert (\n            input.image_size[0].is_contiguous()\n            and input.image_size[1].is_contiguous()\n            and other.image_size[0].is_contiguous()\n            and other.image_size[1].is_contiguous()\n        ), f\"image_size must be tensors with contiguous memory; got {input.image_size} and {other.image_size}\"\n\n    for k in input.get_fields().keys():\n        assert k in other.get_fields(), f\"{k} missing from other\"\n\n    for k in other.get_fields().keys():\n        assert k in input.get_fields(), f\"{k} missing from input\"\n\n    for k in input.get_fields().keys():\n        assert k in other.get_fields(), f\"{k} missing from other\"\n\n        if isinstance(input.get(k), Boxes):\n            assert torch.all(\n                input.get(k).tensor == other.get(k).tensor\n            ), f\"{k} not equal: \\ninput = {input.get(k)}\\nother = {other.get(k)}\"\n        elif isinstance(input.get(k), ROIMasks):\n            assert torch.all(\n                input.get(k).tensor == other.get(k).tensor\n            ), f\"{k} not equal: \\ninput = {input.get(k)}\\nother = {other.get(k)}\"\n        elif isinstance(input.get(k), torch.Tensor):\n            assert torch.allclose(\n                input.get(k"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert input.image_size == other.image_size, f\"{msg} Image sizes do not match! \"\n    if size_as_tensor:\n        assert (\n            torch.all(torch.eq(input.image_size, other.image_size))\n        ), f\"{msg} Image sizes do not match!\"\n\n    assert input.get(\"detection_masks\") == other.get(\n        \"detection_masks\"\n    ), f\"{msg} detection_masks differ!\"\n\n    for name in input._field_names:\n        input_val = getattr(input, name, None)\n        other_val = getattr(other, name, None)\n        if input_val is None or other_val is None:\n            # None values in the Instances will be ignored in the conversion to dicts\n            continue\n\n        if isinstance(input_val, Boxes):\n            assert torch.all(input_val.tensor == other_val.tensor), f\"{msg} Boxes in {name} do not match!\"\n        elif isinstance(input_val, ROIMasks):\n            assert torch.all(input_val.tensor == other_val.tensor), f\"{msg} ROIMasks in {name} do not match!\"\n        elif isinstance(input_val, torch.Tensor):\n            assert torch.allclose(input_val, other_val, rtol=rtol), f\"{msg} Tensor fields in {name} do not match!\"\n        else:\n            raise ValueError(f\"Don't know how to compare type {type(input_val)} in {name}!\")"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        box_areas = self.tensor[:, 2] * self.tensor[:, 3]\n        return box_areas\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        area = self.tensor[:, 2] * self.tensor[:, 3]\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        box_areas = self.tensor[:, 2] * self.tensor[:, 3]\n        return box_areas\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        area = self.tensor[:, 2] * self.tensor[:, 3]\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        box_areas = self.tensor[:, 2] * self.tensor[:, 3]\n        return box_areas\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        box_areas = self.tensor[:, 2] * self.tensor[:, 3]\n        return box_areas\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        box_areas = self.tensor[:, 2] * self.tensor[:, 3]\n        return box_areas\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        area = self.tensor[:, 2] * self.tensor[:, 3]\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        box_areas = self.tensor[:, 2] * self.tensor[:, 3]\n        return box_areas\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        box_areas = self.tensor[:, 2] * self.tensor[:, 3]\n        return box_areas\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        area = self.tensor[:, 2] * self.tensor[:, 3]\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        area = self.tensor[:, 2] * self.tensor[:, 3]\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        # TODO: check for device mismatch\n        # TODO: check for shape mismatch\n        # TODO: check for type mismatch\n        # TODO: check for zero area boxes\n        # TODO: check for inf boxes\n        # TODO: check for nan boxes\n        # TODO: check for boxes that are too small\n        # TODO: check for boxes that are too large\n        # TODO: check for boxes that are not rotated\n        # TODO: check for boxes that are rotated by too much\n        # TODO: check for boxes that are rotated by pi/2\n        # TODO: check for boxes that are rotated by pi\n        # TODO: check for boxes that are rotated by -pi/2\n        # TODO: check for boxes that are rotated by 3pi/2\n        # TODO: check for boxes that are rotated by -3pi/2\n        # TODO: check for boxes that are rotated by 5pi/2\n        # TODO: check for boxes that are rotated by -5pi/2\n        # TODO: check for boxes that are rotated by 7pi/2\n        # TODO: check for boxes that are rotated by -7pi/2\n        # TODO: check for boxes that are rotated by 9pi/2\n        # TODO: check for boxes that are rotated by -9pi/2\n        # TODO: check for boxes that are rotated by 11pi/2\n        # TODO: check for boxes that are rotated by -11pi/2\n        # TODO: check for boxes that are rotated by 13pi/2\n        # TODO: check for boxes that are rotated by -13pi/2\n        # TODO: check for boxes that are rotated by 15pi/2\n        # TODO: check for boxes that are rotated by -15pi/2\n        # TODO: check for boxes that are rotated by 17pi/2\n        # TODO: check for boxes that are rotated by -17pi/2\n        # TODO: check for boxes that are rotated by 19pi/2\n        # TODO: check for boxes that are rotated by -19pi/2\n        # TODO: check for boxes that are rotated"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        area = self.tensor[:, 2] * self.tensor[:, 3]\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        box_areas = self.tensor[:, 2] * self.tensor[:, 3]\n        return box_areas\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        # TODO: need to verify this implementation.\n        area = self.tensor[:, 2] * self.tensor[:, 3]\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        area = self.tensor[:, 2] * self.tensor[:, 3]\n\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        # TODO: add check for valid rotated boxes\n        # TODO: add gradient support\n        #\n        # https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocotools/coco.py#L347\n        # https://github.com/tensorflow/models/blob/master/object_detection/core/post_processing.py#L854\n        # https://github.com/pytorch/pytorch/issues/16459\n        # https://github.com/scikit-image/scikit-image/blob/master/skimage/measure/measures.py#L262\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #\n        #"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        area = self.tensor[:, 2] * self.tensor[:, 3]\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        # TODO: 1. check if the output is correct\n        # 2. check if the gradient flows correctly in the backward pass\n        # 3. add explanation in the docstring\n        # 4. add a test for this function\n\n        area = torch.zeros(self.tensor.shape[0], device=self.tensor.device, dtype=torch.float32)\n        area = area.to(self.tensor.dtype)\n        area = area.to(self.tensor.device)\n\n        # TODO: this is very inefficient, replace it with a batched version\n        # of computing areas of rectangles\n        for i in range(self.tensor.shape[0]):\n            area[i] = (self.tensor[i, 3] * self.tensor[i, 4])\n\n        return area\n"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    proposal_generator_name = cfg.PROPOSAL_GENERATOR.NAME\n    if proposal_generator_name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(proposal_generator_name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    proposal_gen_name = cfg.PROPOSAL_GENERATOR.NAME\n    if proposal_gen_name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(proposal_gen_name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    proposal_generator_name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if proposal_generator_name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(proposal_generator_name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)\n\n"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)\n\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        return FastRCNNOutputs(\n            self.box2box_transform,\n            scores,\n            proposal_deltas,\n            proposals,\n            self.smooth_l1_beta,\n            self.box_reg_loss_type,\n            self.loss_weight,\n        ).losses()\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        return FastRCNNOutputs(\n            self.box2box_transform,\n            scores,\n            proposal_deltas,\n            proposals,\n            self.smooth_l1_beta,\n            self.box_reg_loss_type,\n            self.loss_weight,\n        ).losses()\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        # Extract the scores and proposal deltas from the predictions.\n        scores, proposal_deltas = predictions\n\n        # Extract the ground truth boxes from the proposals.\n        gt_boxes = [proposal.gt_boxes for proposal in proposals]\n\n        # Extract the ground truth classes from the proposals.\n        gt_classes = [proposal.gt_classes for proposal in proposals]\n\n        # Extract the ground truth boxes from the proposals.\n        gt_boxes = [proposal.gt_boxes for proposal in proposals]\n\n        # Extract the ground truth classes from the proposals.\n        gt_classes = [proposal.gt_classes for proposal in proposals]\n\n        # Extract the ground truth boxes from the proposals.\n        gt_boxes = [proposal.gt_boxes for proposal in proposals]\n\n        # Extract the ground truth classes from the proposals.\n        gt_classes = [proposal.gt_classes for proposal in proposals]\n\n        # Extract the ground truth boxes from the proposals.\n        gt_boxes = [proposal.gt_boxes for proposal in proposals]\n\n        # Extract the ground truth classes from the proposals.\n        gt_classes = [proposal.gt_classes for proposal in proposals]\n\n        # Extract the ground truth boxes from the proposals.\n        gt_boxes = [proposal.gt_boxes for proposal in proposals]\n\n        # Extract the ground truth classes from the proposals.\n        gt_classes = [proposal.gt_classes for proposal in proposals]\n\n        # Extract the ground truth boxes from the proposals.\n        gt_boxes = [proposal.gt_boxes for proposal in proposals]\n\n        # Extract the ground truth classes from the proposals.\n        gt_classes = [proposal.gt_classes for proposal in proposals]\n\n        # Extract the ground truth boxes from the proposals.\n        gt_boxes = [proposal."}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        return FastRCNNOutputs(\n            self.box2box_transform,\n            scores,\n            proposal_deltas,\n            proposals,\n            self.smooth_l1_beta,\n            self.box_reg_loss_type,\n            self.loss_weight,\n        ).losses()\n\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        # Extract the scores and proposal deltas from the predictions\n        scores, proposal_deltas = predictions\n\n        # Extract the ground truth bounding boxes from the proposals\n        gt_boxes = [proposal.gt_boxes for proposal in proposals]\n\n        # Extract the ground truth classes from the proposals\n        gt_classes = [proposal.gt_classes for proposal in proposals]\n\n        # Extract the bounding boxes from the proposals\n        boxes = [proposal.proposal_boxes for proposal in proposals]\n\n        # Extract the bounding boxes from the proposals\n        # boxes = [proposal.proposal_boxes for proposal in proposals]\n\n        # Extract the bounding boxes from the proposals\n        # boxes = [proposal.proposal_boxes for proposal in proposals]\n\n        # Extract the bounding boxes from the proposals\n        # boxes = [proposal.proposal_boxes for proposal in proposals]\n\n        # Extract the bounding boxes from the proposals\n        # boxes = [proposal.proposal_boxes for proposal in proposals]\n\n        # Extract the bounding boxes from the proposals\n        # boxes = [proposal.proposal_boxes for proposal in proposals]\n\n        # Extract the bounding boxes from the proposals\n        # boxes = [proposal.proposal_boxes for proposal in proposals]\n\n        # Extract the bounding boxes from the proposals\n        # boxes = [proposal.proposal_boxes for proposal in proposals]\n\n        # Extract the bounding boxes from the proposals\n        # boxes = [proposal.proposal_boxes for proposal in proposals]\n\n        # Extract the bounding boxes from the proposals\n        # boxes = [proposal.proposal_boxes for proposal in proposals]\n\n        # Extract the bounding boxes from the proposals\n        # boxes = [proposal.proposal_boxes for proposal in proposals]\n\n        #"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        return_dict = {}\n        return_dict[\"loss_cls\"] = cross_entropy(scores, proposals, self.loss_weight)\n        return_dict[\"loss_box_reg\"] = _dense_box_regression_loss(\n            proposal_deltas,\n            proposals,\n            self.box2box_transform,\n            self.smooth_l1_beta,\n            self.box_reg_loss_type,\n            self.loss_weight,\n        )\n        return return_dict\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        return_dict = {}\n        return_dict[\"loss_cls\"] = cross_entropy(scores, proposals, self.loss_weight)\n        return_dict[\"loss_box_reg\"] = _dense_box_regression_loss(\n            proposal_deltas, proposals, self.box2box_transform, self.box_reg_loss_type, self.loss_weight\n        )\n        return return_dict\n\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        # Extract scores and proposal deltas from predictions\n        scores, proposal_deltas = predictions\n        # Unpack ground truth values from the list of Instances objects\n        gt_boxes = [p.gt_boxes for p in proposals]\n        gt_classes = [p.gt_classes for p in proposals]\n\n        # Calculate classification and box regression losses\n        loss_cls, loss_box_reg = fast_rcnn_losses(\n            gt_classes, gt_boxes, scores, proposal_deltas, self.box2box_transform, self.smooth_l1_beta\n        )\n\n        # Scale losses by loss weights\n        loss_cls = loss_cls * self.loss_weight.get(\"loss_cls\", 1.0)\n        loss_box_reg = loss_box_reg * self.loss_weight.get(\"loss_box_reg\", 1.0)\n\n        losses = {\n            \"loss_cls\": loss_cls,\n            \"loss_box_reg\": loss_box_reg,\n        }\n\n        return losses\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        gt_classes = cat([p.gt_classes for p in proposals], dim=0)\n        loss_cls = cross_entropy(scores, gt_classes, reduction=\"mean\")\n\n        num_classes = scores.shape[1]\n        boxes = self.box2box_transform.apply_deltas(\n            proposal_deltas,\n            proposals[-1].proposal_boxes.tensor.unsqueeze(1).expand(\n                proposal_deltas.shape[0], num_classes, 4\n            ),\n        )\n\n        # Same performance as in FastRCNNOutputs, but simpler code\n        with torch.no_grad():\n            gt_proposal_deltas = self.box2box_transform.get_deltas(\n                proposals[-1].gt_boxes.tensor, boxes\n            )\n\n        box_dim = gt_proposal_deltas.size(1)  # 4 or 5\n        loss_box_reg = _dense_box_regression_loss(\n            proposal_deltas,\n            gt_proposal_deltas,\n            box_dim,\n            self.box_reg_loss_type,\n            loss_weight=self.loss_weight[\"loss_box_reg\"],\n        )\n\n        return {\"loss_cls\": loss_cls * self.loss_weight[\"loss_cls\"], \"loss_box_reg\": loss_box_reg * self.loss_weight[\"loss_box_reg\"]}\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        # Extract the scores and proposal deltas from the predictions tuple.\n        scores, proposal_deltas = predictions\n\n        # Extract the ground-truth boxes, classes, and corresponding class labels from the ground truth instances.\n        gt_boxes = [proposal.gt_boxes for proposal in proposals]\n        gt_classes = [proposal.gt_classes for proposal in proposals]\n        gt_classes_img_oh = [proposal.gt_classes_img_oh for proposal in proposals]\n\n        # Extract the bounding boxes from the ground truth instances.\n        # These boxes are used to compute the bounding box regression loss.\n        gt_boxes = torch.cat(gt_boxes, dim=0)\n\n        # Extract the class labels from the ground truth instances.\n        # These labels are used to compute the classification loss.\n        gt_classes = torch.cat(gt_classes, dim=0)\n        gt_classes_img_oh = torch.cat(gt_classes_img_oh, dim=0)\n\n        # Extract the bounding box deltas and convert them to the original bounding box coordinates.\n        # These deltas are used to compute the bounding box regression loss.\n        boxes_per_image = [len(boxes) for boxes in gt_boxes]\n        proposal_deltas = proposal_deltas.split(boxes_per_image, dim=0)\n        box_reg_losses = [\n            self.box_reg_loss(\n                proposal_deltas_per_image,\n                gt_boxes,\n                gt_classes,\n                img_oh=gt_classes_img_oh,\n            )\n            for proposal_deltas_per_image, gt_boxes, gt_classes, gt_classes_img_oh in zip(\n                proposal_deltas, gt_boxes, gt_classes, gt_classes_img_oh\n            )\n        ]\n        box_reg_loss = torch.cat(box_reg_losses"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        # scores is (N, num_classes), proposal_deltas is (N, K * BUCKETS, 4)\n\n        return_dict = {}\n        losses = FastRCNNOutputs(\n            self.box2box_transform,\n            scores,\n            proposal_deltas,\n            proposals,\n            self.smooth_l1_beta,\n            self.box_reg_loss_type,\n        ).losses()\n\n        # Add weight decay regularization on all parameters except the prediction head layers.\n        weight_dict = {\"loss_box_reg\": loss_box_reg, \"loss_cls\": loss_cls}\n        for name, loss in weight_dict.items():\n            loss = loss * self.loss_weight.get(name, 1.0)\n            return_dict[name] = loss\n\n        return return_dict\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        # print(scores.shape)\n        # print(proposal_deltas.shape)\n        # print(proposals[0].proposal_boxes)\n        # print(proposals[0].gt_boxes)\n        # print(proposals[0].gt_classes)\n        # print(len(proposals))\n        # print(scores.device)\n        # print(proposal_deltas.device)\n        # print(proposals[0].proposal_boxes.device)\n        # print(proposals[0].gt_boxes.device)\n        # print(proposals[0].gt_classes.device)\n\n        return {\n            \"loss_cls\": fast_rcnn_losses(\n                scores, proposals, self.box2box_transform, self.num_classes\n            ),\n            \"loss_box_reg\": box_reg_loss(\n                proposal_deltas,\n                proposals,\n                self.box2box_transform,\n                self.smooth_l1_beta,\n                self.box_reg_loss_type,\n            ),\n        }\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        gt_classes = (\n            cat([p.gt_classes for p in proposals], dim=0) if len(proposals) else torch.empty(0)\n        )\n        gt_classes = gt_classes.to(dtype=torch.int64)\n\n        # The score_threshold for calculating loss is lower than the score_threshold for inference.\n        loss_cls_weights, loss_box_reg_weights, indices = self._get_ground_truth(\n            gt_classes, self.loss_weight\n        )\n\n        gt_classes_targets = gt_classes[indices]\n        scores = scores[indices]\n        proposal_deltas = proposal_deltas[indices]\n\n        labels = gt_classes_targets\n        # BBox regression loss is only computed for positive boxes.\n        # Note that target for all regression targets are 0. This is not\n        # ideal, but works for training the backbone (without the head)\n        box_regression_targets = torch.zeros_like(proposal_deltas)\n\n        classification_loss = F.cross_entropy(scores, labels, reduction=\"none\")\n        if self.box_reg_loss_type == \"smooth_l1\":\n            box_loss = smooth_l1_loss(\n                proposal_deltas,\n                box_regression_targets,\n                beta=self.smooth_l1_beta,\n                reduction=\"none\",\n            )\n        elif self.box_reg_loss_type == \"giou\":\n            box_loss = giou_loss(\n                proposal_deltas,\n                box_regression_targets,\n                reduction=\"none\",\n            )\n        elif self.box_reg_loss_type == \"diou\":\n            box_loss = diou_loss(\n                proposal_deltas,\n                box_regression_targets,\n                reduction=\"none\",\n            )\n        elif self.box_reg_loss_type == \"ci"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        gt_classes = (\n            cat([p.gt_classes for p in proposals], dim=0) if len(proposals) else torch.empty(0)\n        )\n        # GT boxes and classes\n        if len(proposals):\n            gt_boxes = cat([p.gt_boxes.tensor for p in proposals], dim=0)\n        else:\n            gt_boxes = torch.empty(0, 4, dtype=torch.float32, device=proposal_deltas.device)\n\n        # num_classes x num_boxes\n        labels = match_gts(\n            self.num_classes, gt_classes, gt_boxes, proposal_deltas\n        )\n\n        # Box regression loss\n        box_dim = proposal_deltas.size(1) // 4\n        box_reg_loss = smooth_l1_loss(\n            proposal_deltas,\n            labels[:, :box_dim],\n            beta=self.smooth_l1_beta,\n            reduction=\"sum\",\n        )\n        box_reg_loss = box_reg_loss / (max(1, labels.numel() * box_dim))\n\n        # Classification loss\n        fg_labels = nonzero_tuple(labels[:, box_dim:])[0]\n        cls_loss = F.cross_entropy(\n            scores, labels, reduction=\"sum\", ignore_index=self.num_classes\n        )\n        # The above operation computes softmax internally.\n        cls_loss = cls_loss / (max(1, labels.numel()))\n\n        # Normalization\n        box_reg_loss = box_reg_loss * self.loss_weight.get(\"loss_box_reg\", 1.0)\n        cls_loss = cls_loss * self.loss_weight.get(\"loss_cls\", 1.0)\n\n        losses = {\"loss_cls\": cls_loss, \"loss_box_reg\": box_reg_loss}"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        # Extract the scores and proposal deltas from the predictions\n        scores, proposal_deltas = predictions\n        # Extract the ground-truth classes and bounding boxes from the proposals\n        gt_classes = (\n            cat([p.gt_classes for p in proposals], dim=0) if len(proposals) else torch.empty(0)\n        )\n        gt_boxes = (\n            cat([p.gt_boxes for p in proposals], dim=0) if len(proposals) else torch.empty(0)\n        )\n        # Extract the ground-truth boxes from the proposals\n        # gt_boxes = [p.gt_boxes for p in proposals]\n\n        # Sample the boxes to train on\n        # proposals, _ = self.box_selector_train(proposals, gt_boxes)\n        # Extract the ground-truth classes and bounding boxes from the proposals\n        # gt_classes = cat([p.gt_classes for p in proposals], dim=0)\n        # gt_boxes = cat([p.gt_boxes for p in proposals], dim=0)\n\n        # Extract the predicted boxes from the proposals\n        # pred_boxes = [p.pred_boxes for p in proposals]\n\n        # Extract the predicted boxes from the proposals\n        pred_boxes = proposals\n\n        # Extract the predicted scores from the proposals\n        pred_scores = [p.scores for p in proposals]\n\n        # Calculate the classification loss\n        loss_cls = cross_entropy(scores, gt_classes, reduction=\"mean\")\n\n        # Calculate the bounding box regression loss\n        # loss_box_reg = smooth_l1_loss(\n        #     proposal_deltas,\n        #     self.box2box_transform.get_deltas(gt_boxes, pred_boxes),\n        #     self.smooth_l1_beta,\n        #     reduction=\"mean\",\n        # )\n        loss_box_reg ="}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        # Extract the scores and proposal deltas from the predictions\n        scores, proposal_deltas = predictions\n\n        # Extract the ground-truth classes, bounding boxes, and corresponding masks from the ground-truth proposals\n        gt_classes = [proposal.gt_classes for proposal in proposals]\n        gt_boxes = [proposal.gt_boxes for proposal in proposals]\n\n        # Extract the bounding boxes from the proposals\n        proposal_boxes = [proposal.proposal_boxes for proposal in proposals]\n\n        # Extract the bounding boxes from the proposals\n        proposal_boxes = [proposal.proposal_boxes for proposal in proposals]\n\n        # Extract the masks from the ground-truth proposals\n        gt_masks = [proposal.gt_masks for proposal in proposals]\n\n        # Calculate the classification loss\n        loss_cls = cross_entropy(scores, torch.cat(gt_classes))\n\n        # Calculate the box regression loss\n        # Transform the predicted bounding boxes into proposals\n        boxes = self.box2box_transform.apply_deltas(proposal_deltas, proposal_boxes)\n\n        # Calculate the mask loss\n        loss_mask = mask_rcnn_loss(boxes, gt_masks)\n\n        # Calculate the smooth L1 loss for bounding box regression\n        loss_box_reg = _smooth_l1_loss(\n            boxes, gt_boxes, self.smooth_l1_beta, reduction=\"sum\"\n        )\n\n        # Scale the losses by the specified weights\n        loss_cls = loss_cls * self.loss_weight.get(\"loss_cls\", 1.0)\n        loss_box_reg = loss_box_reg * self.loss_weight.get(\"loss_box_reg\", 1.0)\n        loss_mask = loss_mask * self.loss_weight.get(\"loss_mask\", 1.0)\n\n        # Return the losses in"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        # Extract the scores and proposal deltas from the predictions\n        scores, proposal_deltas = predictions\n\n        # Extract the ground-truth classes and bounding boxes from the proposals\n        gt_classes = cat([p.gt_classes for p in proposals], dim=0)\n        gt_boxes = cat([p.gt_boxes for p in proposals], dim=0)\n\n        # Extract the ground-truth boxes for each class from the ground-truth boxes\n        gt_classes_list = []\n        gt_boxes_list = []\n        for cls_idx in range(1, self.num_classes):\n            cls_mask = gt_classes == cls_idx\n            gt_classes_list.append(gt_classes[cls_mask])\n            gt_boxes_list.append(gt_boxes[cls_mask])\n\n        # Compute the classification loss\n        loss_cls = cross_entropy(scores, gt_classes, reduction=\"mean\")\n\n        # Compute the box regression loss\n        loss_box_reg = _box_reg_loss(\n            proposal_deltas,\n            gt_boxes,\n            gt_classes,\n            self.box2box_transform,\n            self.smooth_l1_beta,\n            self.box_reg_loss_type,\n        )\n\n        # Scale the losses by the specified weights\n        loss_cls = loss_cls * self.loss_weight.get(\"loss_cls\", 1.0)\n        loss_box_reg = loss_box_reg * self.loss_weight.get(\"loss_box_reg\", 1.0)\n\n        # Return a dict containing the losses\n        losses = {\n            \"loss_cls\": loss_cls,\n            \"loss_box_reg\": loss_box_reg,\n        }\n        return losses\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        # print(\"scores\", scores.shape)\n        # print(\"proposal_deltas\", proposal_deltas.shape)\n        return {\n            \"loss_cls\": self.loss_cls(scores, proposals, self.num_classes),\n            \"loss_box_reg\": self.loss_box_reg(proposal_deltas, proposals),\n        }\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        # Extract the scores and proposal deltas from the predictions\n        scores, proposal_deltas = predictions\n        # Extract the ground-truth classes, bounding boxes, and corresponding weights from the ground-truth proposals\n        gt_classes = (\n            cat([p.gt_classes for p in proposals], dim=0) if len(proposals) else torch.empty(0)\n        )\n        gt_boxes = (\n            cat([p.gt_boxes for p in proposals], dim=0) if len(proposals) else torch.empty(0)\n        )\n        gt_weights = (\n            cat([p.gt_weights for p in proposals], dim=0) if len(proposals) else torch.empty(0)\n        )\n        # Extract the indices of the ground-truth proposals\n        keep_idx = gt_weights > 0\n        gt_classes = gt_classes[keep_idx]\n        gt_weights = gt_weights[keep_idx]\n        gt_boxes = gt_boxes[keep_idx]\n\n        # Calculate the classification loss\n        loss_cls = F.binary_cross_entropy_with_logits(scores, gt_classes.float()) * gt_weights\n\n        # Calculate the box regression loss\n        box_dim = getattr(self.box2box_transform, \"output_size\", 4)\n        gt_boxes_per_image = [len(p) for p in proposals]\n        num_boxes = sum(gt_boxes_per_image)\n        proposal_weights = cat([p.gt_weights for p in proposals], dim=0)\n        proposal_weights = proposal_weights.to(torch.float32)\n        proposal_weights[proposal_weights < 1] = 0\n        num_fg = proposal_weights.sum()\n        proposal_weights = proposal_weights.view(-1, 1)\n        assert proposal_weights"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        # print(\"scores\", scores.shape)\n        # print(\"proposal_deltas\", proposal_deltas.shape)\n\n        # 1. proposal_boxes: the proposal_boxes are the boxes that are fed to the model, and they are the boxes that are predicted by the model.\n        # 2. gt_boxes: the gt_boxes are the ground truth boxes for the proposals.\n        # 3. gt_classes: the gt_classes are the ground truth classes for the proposals.\n\n        # The following code is based on the detectron2 code.\n        # The detectron2 code is based on the Caffe2 code.\n        # The Caffe2 code is based on the MXNet code.\n        # The MXNet code is based on the GluonCV code.\n\n        # The following code is based on the detectron2 code.\n        # The detectron2 code is based on the Caffe2 code.\n        # The Caffe2 code is based on the MXNet code.\n        # The MXNet code is based on the GluonCV code.\n\n        # The following code is based on the detectron2 code.\n        # The detectron2 code is based on the Caffe2 code.\n        # The Caffe2 code is based on the MXNet code.\n        # The MXNet code is based on the GluonCV code.\n\n        # The following code is based on the detectron2 code.\n        # The detectron2 code is based on the Caffe2 code.\n        # The Caffe2 code is based on the MXNet code.\n        # The MXNet code is based on the GluonCV code.\n\n        # The following code is based on the detectron2 code.\n        # The detectron2 code is based on the Caffe2 code.\n        # The Caffe2 code is based on the MXNet code.\n        # The MXNet code is based on the GluonCV code.\n\n        # The following code is based on the detectron"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.TRACKER_NAME\n    tracker = TRACKER_HEADS_REGISTRY.get(tracker_name)\n    return tracker.from_config(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.TRACKER_NAME\n    tracker = TRACKER_HEADS_REGISTRY.get(tracker_name)\n    return tracker.from_config(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.TRACKER_HEAD.NAME\n    return TRACKER_HEADS_REGISTRY.get(name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.TRACKER_NAME\n    tracker = TRACKER_HEADS_REGISTRY.get(tracker_name)\n\n    return tracker.from_config(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.TRACKER_NAME\n    tracker = TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)\n    return tracker"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.TRACKER_NAME\n    tracker_class = TRACKER_HEADS_REGISTRY.get(tracker_name)\n    return tracker_class.from_config(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    # Retrieve the tracker name from the configuration\n    name = cfg.TRACKER_NAME\n\n    # Build the tracker object\n    tracker = TRACKER_HEADS_REGISTRY.get(name)(cfg)\n\n    return tracker"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    # Retrieve the tracker name from the configuration\n    name = cfg.TRACKER_NAME\n\n    # Build the tracker\n    tracker = TRACKER_HEADS_REGISTRY.get(name)(cfg)\n\n    return tracker"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.TRACKER_NAME\n    return TRACKER_HEADS_REGISTRY.get(name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.TRACKER_HEAD.NAME\n    name = name.replace(\"_\", \"-\")\n    return TRACKER_HEADS_REGISTRY.get(name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.TRACKER_NAME\n    tracker = TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)\n    assert isinstance(tracker, BaseTracker), \"Tracker must be an instance of BaseTracker\"\n    return tracker"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    # Retrieve the tracker name from the configuration\n    name = cfg.TRACKER_HEAD.NAME\n    # Retrieve the tracker class from the registry\n    tracker_class = TRACKER_HEADS_REGISTRY.get(name)\n    # Instantiate the tracker class with the configuration\n    return tracker_class.from_config(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    # Retrieve the tracker name\n    name = cfg.TRACKER_NAME\n\n    # Build the tracker head\n    tracker_head = TRACKER_HEADS_REGISTRY.get(name)(cfg)\n\n    return tracker_head"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    # Retrieve the tracker name from the configuration\n    tracker_name = cfg.TRACKER_HEAD.NAME\n\n    # Build the tracker object\n    tracker = TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)\n\n    return tracker"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    # Retrieve the name of the tracker to be built from the configuration.\n    name = cfg.TRACKER_HEAD.NAME\n\n    # Build the tracker object from the tracker class.\n    tracker = TRACKER_HEADS_REGISTRY.get(name)(cfg)\n\n    return tracker"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.TRACKER_HEAD.NAME\n    assert name in TRACKER_HEADS_REGISTRY, f\"Tracker {name} is not registered in registry\"\n    return TRACKER_HEADS_REGISTRY.get(name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.TRACKER_NAME\n    tracker = TRACKER_HEADS_REGISTRY.get(tracker_name)\n    tracker = tracker(cfg)\n    return tracker"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    # Retrieve tracker name\n    name = cfg.TRACKER_HEADS.NAME\n\n    # Build tracker\n    tracker = TRACKER_HEADS_REGISTRY.get(name)(cfg)\n\n    # Return tracker\n    return tracker"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    # Build the tracker\n    name = cfg.TRACKER_NAME\n    tracker = TRACKER_HEADS_REGISTRY.get(name)(cfg)\n    assert isinstance(tracker, BaseTracker)\n\n    return tracker"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.TRACKER_NAME\n    tracker = TRACKER_HEADS_REGISTRY.get(tracker_name)\n    tracker = tracker(cfg)\n    return tracker\n\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h  # y1\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w  # x2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h  # y2\n\n        return pred_boxes\n\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h  # y1\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w  # x2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h  # y2\n\n        return pred_boxes\n\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h  # y1\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w  # x2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h  # y2\n\n        return pred_boxes\n\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h  # y1\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w  # x2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h  # y2\n        return pred_boxes\n\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h  # y1\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w  # x2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h  # y2\n        return pred_boxes\n\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h  # y1\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w  # x2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h  # y2\n\n        return pred_boxes\n\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        # boxes = Boxes(boxes)\n        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h  # y1\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w  # x2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h  # y2\n\n        return pred_boxes\n\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h  # y1\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w  # x2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h  # y2\n        return pred_boxes\n\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        #dw = torch.clamp(dw, max=self.scale_clamp)\n        #dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h  # y1\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w  # x2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h  # y2\n\n        return pred_boxes\n\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        #dw = torch.clamp(dw, max=self.scale_clamp)\n        #dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h  # y1\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w  # x2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h  # y2\n\n        return pred_boxes\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        # boxes = Boxes(boxes)\n        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        # dw = torch.clamp(dw, max=self.scale_clamp)\n        # dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h  # y1\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w  # x2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h  # y2\n        return pred_boxes\n\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        # import pdb; pdb.set_trace()\n        # boxes = boxes.to(deltas.dtype)\n\n        # boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        # dw = torch.clamp(dw, max=self.scale_clamp)\n        # dh = torch.clamp(dh, max=self.scale_clamp)\n\n        # dw = torch.clamp(dw, max=self.scale_clamp)\n        # dh = torch.clamp(dh, max=self.scale_clamp)\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        # import pdb\n        # pdb.set_trace()\n\n        # boxes: 1, 4\n        # deltas: N, k*4\n        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        # TODO is this really a bright idea?\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h  # y1\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w  # x2\n        pred_boxes[:, "}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        # import pdb; pdb.set_trace()\n        # boxes = Boxes(boxes)\n        # boxes = boxes.tensor\n        # import pdb; pdb.set_trace()\n        # import pdb; pdb.set_trace()\n        # import pdb; pdb.set_trace()\n        # boxes = boxes.tensor\n        # import pdb; pdb.set_trace()\n        # import pdb; pdb.set_trace()\n        # boxes = boxes.tensor\n        # import pdb; pdb.set_trace()\n        # import pdb; pdb.set_trace()\n        # boxes = boxes.tensor\n        # import pdb; pdb.set_trace()\n        # import pdb; pdb.set_trace()\n        # boxes = boxes.tensor\n        # import pdb; pdb.set_trace()\n        # import pdb; pdb.set_trace()\n        # boxes = boxes.tensor\n        # import pdb; pdb.set_trace()\n        # import pdb; pdb.set_trace()\n        # boxes = boxes.tensor\n        # import pdb; pdb.set_trace()\n        # import pdb; pdb.set_trace()\n        # boxes = boxes.tensor\n        # import pdb; pdb.set_trace()\n        # import pdb; pdb.set_trace()\n        # boxes = boxes.tensor\n        # import pdb; pdb.set_trace()\n        # import pdb; pdb.set_trace()\n        # boxes = boxes.tensor\n        # import pdb; pdb.set_trace()\n        # import pdb; pdb.set_trace()\n        # boxes = boxes.tensor\n        # import pdb; pdb.set_trace()\n        # import pdb; pdb.set_trace()\n        # boxes = boxes.tensor\n        # import pdb; pdb.set_trace()\n        # import pdb; pdb.set_trace()\n        # boxes = boxes.tensor\n        # import pdb; pdb.set_trace()\n        # import pdb"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        # import pdb; pdb.set_trace()\n        # boxes: 1, 4\n        # deltas: N, k*4\n        # we only use deltas[i, :] to transform boxes[i, :]\n        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h  # y1\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w  # x2"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        # type(deltas)\n        # Tensor\n        # deltas.size()\n        # torch.Size([1000, 4])\n        # type(boxes)\n        # Tensor\n        # boxes.size()\n        # torch.Size([1000, 4])\n\n        # deltas.dtype\n        # torch.float32\n        # boxes.dtype\n        # torch.float32\n\n        # deltas.shape\n        # torch.Size([1000, 4])\n        # boxes.shape\n        # torch.Size([1000, 4])\n\n        # deltas.ndimension()\n        # 2\n        # boxes.ndimension()\n        # 2\n\n        # deltas.device\n        # device(type='cuda', index=0)\n        # boxes.device\n        # device(type='cuda', index=0)\n\n        # deltas.is_cuda\n        # True\n        # boxes.is_cuda\n        # True\n\n        # deltas.requires_grad\n        # False\n        # boxes.requires_grad\n        # False\n\n        # deltas.numel()\n        # 4000\n        # boxes.numel()\n        # 4000\n\n        # deltas.element_size()\n        # 4\n        # boxes.element_size()\n        # 4\n\n        # deltas.nelement()\n        # 4000\n        # boxes.nelement()\n        # 4000\n\n        # deltas.shape[0]\n        # 1000\n        # boxes.shape[0]\n        # 1000\n\n        # deltas.shape[1]\n        # 4\n        # boxes.shape[1]\n        # 4\n\n        # deltas.ndim\n        # 2\n        # boxes.ndim\n        # 2\n\n        # deltas.device\n        #"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        # dw/dh can be < 0, which leads to np.exp(<small negative value>)=0\n        # which is OK, but we don't want the dw/dh values to be exactly 0.\n        # Avoid this by clipping dw/dh to a small positive value.\n        # This comes at the cost of possibly evaluating np.exp(-x) for small x > 0,\n        # but this should be a rare event.\n        # dw/dh is at most 1 - which leads to a very small value for np.exp(-x) > 0\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        # dw/dh can be < -1, which causes NaN\n        # TODO: remove the clamp once we have a proper activation function\n        # clamp = self.scale_clamp\n        # dw = torch.clamp(dw, max=clamp)\n        # dh = torch.clamp(dh, max=clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h  # y1\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w  # x2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0."}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        # boxes: 1D: N, 2D: [x1, y1, x2, y2]\n        # deltas: 1D: k*4, 2D: [dx, dy, dw, dh]\n        # pred_boxes: 1D: N, 2D: [x1, y1, x2, y2]\n\n        # Convert to y, x, h, w\n        # boxes = box_utils.xcycwh_to_xyxy(boxes)\n        # pred_boxes = box_utils.xcycwh_to_xyxy(boxes + deltas)\n\n        boxes = boxes.to(deltas.dtype)\n\n        ctr_x = 0.5 * (boxes[:, 0] + boxes[:, 2])\n        ctr_y = 0.5 * (boxes[:, 1] + boxes[:, 3])\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        #dw = torch.clamp(dw, max=self.scale_clamp)\n        #dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch."}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        # import pdb; pdb.set_trace()\n        # boxes = Boxes(boxes)\n        # boxes = boxes.tensor\n        # import pdb; pdb.set_trace()\n        # print(boxes.shape)\n        # print(deltas.shape)\n        # print(boxes)\n        # print(deltas)\n        # print(self.weights)\n        # print(self.scale_clamp)\n        # print(self.apply_deltas(deltas, boxes))\n        # import pdb; pdb.set_trace()\n        # boxes = torch.tensor([[0, 0, 10, 10], [0, 0, 5, 5]], dtype=torch.float32)\n        # deltas = torch.tensor([[0.25, 0.125, 0.5, 0.25], [0.1, 0.2, 0.75, 0.75]], dtype=torch.float32)\n        # weights = (10.0, 10.0, 5.0, 5.0)\n        # scale_clamp = 3.0\n        # print(self.apply_deltas(deltas, boxes))\n        # import pdb; pdb.set_trace()\n        # print(self.apply_deltas(deltas, boxes))\n        # print(self.apply_deltas(deltas, boxes))\n        # print(self.apply_deltas(deltas, boxes))\n        # print(self.apply_deltas(deltas, boxes))\n        # print(self.apply_deltas(deltas, boxes))\n        # print(self.apply_deltas(deltas, boxes))\n        # print(self.apply_deltas(deltas, boxes))\n        # print(self.apply_deltas(deltas, boxes))\n        # print(self.apply_deltas(deltas, boxes))\n        # print"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if isinstance(image, str):\n            image = cv2.imread(image)\n        elif isinstance(image, np.ndarray):\n            pass\n        else:\n            raise Exception(f'Error image: {image}')\n\n        if anno_type is None:\n            return self.general_ins(image)\n        else:\n            output = self.general_ins(image)\n            if isinstance(anno_type, str):\n                return output[anno_type]\n            elif isinstance(anno_type, (list, tuple)):\n                return {key: output[key] for key in anno_type if key in output}\n            else:\n                raise Exception(f'Error anno_type: {anno_type}')"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is not None:\n            if isinstance(anno_type, str):\n                anno_type = [anno_type]\n            elif isinstance(anno_type, (list, tuple)):\n                assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n            else:\n                raise Exception(f'Error anno_type: {anno_type}')\n\n        output = self.general_ins(image)\n        if anno_type is None:\n            return output\n        else:\n            for tp in anno_type:\n                assert tp in output.keys(), f'{tp} not found in output'\n            if len(anno_type) == 1:\n                return output[anno_type[0]]\n            else:\n                return {tp: output[tp] for tp in anno_type}"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if isinstance(anno_type, str):\n            anno_type = [anno_type]\n        elif anno_type is None:\n            anno_type = list(self.anno_type_map.keys())\n\n        output = self.general_ins(image)\n        output_keys = list(output.keys())\n        anno_dict = {}\n        for tp in anno_type:\n            if tp in output_keys:\n                anno_dict[tp] = output[tp]\n        if len(anno_dict) == 1:\n            return list(anno_dict.values())[0]\n        elif len(anno_dict) > 1:\n            return anno_dict\n        else:\n            return output"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if isinstance(image, str):\n            image = cv2.imread(image)\n        if image is None:\n            raise Exception('Error image: None')\n        if isinstance(anno_type, str):\n            anno_type = [anno_type]\n        elif anno_type is None:\n            anno_type = self.anno_type_map.keys()\n\n        output = self.general_ins(image)\n        if anno_type is not None:\n            output = {k: v for k, v in output.items() if k in anno_type}\n        return output"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        assert isinstance(image, np.ndarray)\n        assert image.ndim == 3\n        assert image.shape[2] == 3\n\n        if anno_type is not None:\n            if isinstance(anno_type, str):\n                anno_type = [anno_type]\n            elif isinstance(anno_type, (list, tuple)):\n                assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n            else:\n                raise Exception(f'Error anno_type: {anno_type}')\n\n        output = self.general_ins(image)\n        if anno_type is not None:\n            assert all(tp in output.keys() for tp in anno_type)\n            if len(anno_type) == 1:\n                return output[anno_type[0]]\n            else:\n                return {tp: output[tp] for tp in anno_type}\n        else:\n            return output"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            anno_type = self.anno_type_map.keys()\n        elif isinstance(anno_type, str):\n            assert anno_type in self.anno_type_map.keys()\n            anno_type = [anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')\n\n        output = self.general_ins(image)\n\n        if len(anno_type) == 1:\n            return output[anno_type[0]]\n        else:\n            return {tp: output[tp] for tp in anno_type}\n\n"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            return self.general_ins(image)\n        else:\n            out = self.general_ins(image)\n            if isinstance(anno_type, str):\n                if anno_type in out.keys():\n                    return out[anno_type]\n                else:\n                    raise Exception(f'{anno_type} is not found in output')\n            elif isinstance(anno_type, (list, tuple)):\n                return {\n                    tp: out[tp]\n                    for tp in anno_type if tp in out.keys()\n                }\n            else:\n                raise Exception(f'Error anno_type: {anno_type}')"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if isinstance(image, str):\n            image = cv2.imread(image)\n        if isinstance(image, np.ndarray):\n            image = image.astype(np.float32)\n            image = np.transpose(image, (2, 0, 1))\n            image = np.expand_dims(image, 0)\n            image = image.astype(np.float32)\n        else:\n            raise Exception(f'Error image: {image}')\n\n        output = self.general_ins(image)\n        if anno_type is None:\n            return output\n        else:\n            if isinstance(anno_type, str):\n                anno_type = [anno_type]\n            else:\n                assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n            output_dict = {}\n            for tp in anno_type:\n                if tp in output.keys():\n                    output_dict[tp] = output[tp]\n            if len(output_dict) == 0:\n                return None\n            elif len(output_dict) == 1:\n                return list(output_dict.values())[0]\n            else:\n                return output_dict\n\n"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            anno_type = self.anno_type_map.keys()\n        elif isinstance(anno_type, str):\n            assert anno_type in self.anno_type_map.keys()\n            anno_type = [anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')\n\n        output = self.general_ins(image)\n        if len(anno_type) == 1:\n            return output[anno_type[0]]\n        else:\n            return {k: output[k] for k in anno_type}\n\n"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        assert isinstance(image, np.ndarray)\n        assert image.ndim == 3\n        assert image.shape[2] == 3\n        assert anno_type is None or isinstance(anno_type, (str, list, tuple))\n\n        if isinstance(anno_type, str):\n            anno_type = [anno_type]\n        elif anno_type is None:\n            anno_type = list(self.anno_type_map.keys())\n\n        output = self.general_ins(image)\n        output = {key: output[key] for key in output if key in anno_type}\n        return output\n\n"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if isinstance(image, str):\n            image = cv2.imread(image)\n        if image.ndim == 2:\n            image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n        if image.ndim == 4:\n            image = image.squeeze()\n        if image.ndim != 3:\n            raise Exception(f'Error image.ndim: {image.ndim}')\n\n        if anno_type is None:\n            return self.general_ins(image)\n        elif isinstance(anno_type, str):\n            return self.general_ins(image)[anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            return {\n                tp: self.general_ins(image)[tp]\n                for tp in anno_type if tp in self.general_ins(image)\n            }\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')\n\n"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if isinstance(image, str):\n            image = cv2.imread(image)\n        if len(image.shape) == 2:\n            image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n        if len(image.shape) != 3:\n            raise Exception(f'Error image shape: {image.shape}')\n        if image.shape[2] != 3:\n            raise Exception(f'Error image shape: {image.shape}')\n\n        if anno_type is None:\n            return self.general_ins(image)\n        elif isinstance(anno_type, str):\n            return self.general_ins(image)[anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            return {tp: self.general_ins(image)[tp] for tp in anno_type}\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')\n\n"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if isinstance(image, str):\n            image = cv2.imread(image)\n        elif not isinstance(image, np.ndarray):\n            raise Exception(f'Error image: {image}')\n\n        if image.ndim == 2:\n            image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n        elif image.ndim == 3:\n            if image.shape[-1] == 3:\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n            elif image.shape[-1] == 1:\n                image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n        else:\n            raise Exception(f'Error image: {image}')\n\n        resized_img, k = resize_image(image, 512)\n        resized_img = np.ascontiguousarray(resized_img)\n\n        output = self.general_ins(resized_img)\n        output['img'] = resized_img\n        output['k'] = k\n\n        if anno_type is None:\n            return output\n        elif isinstance(anno_type, str):\n            assert anno_type in self.anno_type_map.keys()\n            if anno_type in output.keys():\n                return output[anno_type]\n            else:\n                return None\n        elif isinstance(anno_type, (list, tuple)):\n            assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n            out_dict = {}\n            for tp in anno_type:\n                if tp in output.keys():\n                    out_dict[tp] = output[tp]\n            return out_dict\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')\n\n"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        assert anno_type is None or isinstance(anno_type, (str, list, tuple))\n        if isinstance(anno_type, str):\n            anno_type = [anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n        else:\n            anno_type = None\n\n        output = self.general_ins(image)\n        if anno_type is not None:\n            output = {\n                k: v\n                for k, v in output.items() if k in anno_type\n            }\n\n        return output\n\n"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is not None:\n            if isinstance(anno_type, str):\n                anno_type = [anno_type]\n            elif isinstance(anno_type, (list, tuple)):\n                assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n            else:\n                raise Exception(f'Error anno_type: {anno_type}')\n\n        out = self.general_ins(image)\n\n        if anno_type is not None:\n            if len(anno_type) == 1:\n                if anno_type[0] in out.keys():\n                    return out[anno_type[0]]\n                else:\n                    raise Exception(f'Error anno_type: {anno_type}')\n            else:\n                out_dict = {}\n                for tp in anno_type:\n                    if tp in out.keys():\n                        out_dict[tp] = out[tp]\n                return out_dict\n        else:\n            return out\n\n"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if isinstance(anno_type, str):\n            anno_type = [anno_type]\n        elif anno_type is None:\n            anno_type = self.anno_type_map.keys()\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')\n\n        output = self.general_ins(image)\n        if anno_type is None:\n            return output\n        else:\n            anno_dict = {}\n            for tp in anno_type:\n                if tp in output.keys():\n                    anno_dict[tp] = output[tp]\n            if len(anno_dict) == 1:\n                return next(iter(anno_dict.values()))\n            else:\n                return anno_dict\n\n"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        assert isinstance(image, np.ndarray)\n        assert image.ndim == 3\n        assert image.shape[2] == 3\n\n        if anno_type is not None:\n            if isinstance(anno_type, str):\n                anno_type = [anno_type]\n            elif isinstance(anno_type, (list, tuple)):\n                assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n            else:\n                raise Exception(f'Error anno_type: {anno_type}')\n\n        image = np.transpose(image, (2, 0, 1))\n        image = np.expand_dims(image, 0)\n        image = np.ascontiguousarray(image, dtype=np.float32)\n        image = image.astype(np.float32) / 255.0\n\n        output = self.general_ins(image)\n\n        if anno_type is not None:\n            output = {\n                k: v\n                for k, v in output.items()\n                if k in anno_type or k in self.anno_type_map.keys()\n            }\n\n        return output\n\n"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            return self.general_ins(image)\n        elif isinstance(anno_type, str):\n            output = self.general_ins(image)\n            if anno_type in output.keys():\n                return output[anno_type]\n            else:\n                return output\n        elif isinstance(anno_type, (list, tuple)):\n            output = self.general_ins(image)\n            return {\n                tp: output[tp]\n                for tp in anno_type if tp in output.keys()\n            }\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')\n\n"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        assert anno_type is None or isinstance(anno_type,\n                                               (str, list, tuple))\n        if anno_type is None:\n            return self.general_ins(image)\n        else:\n            out = self.general_ins(image)\n            if isinstance(anno_type, str):\n                if anno_type in out.keys():\n                    return out[anno_type]\n                else:\n                    return None\n            else:\n                out_dict = {}\n                for tp in anno_type:\n                    if tp in out.keys():\n                        out_dict[tp] = out[tp]\n                return out_dict\n\n"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if isinstance(anno_type, str):\n            anno_type = [anno_type]\n        elif anno_type is None:\n            anno_type = []\n        else:\n            assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n\n        output = self.general_ins(image)\n        if anno_type:\n            output = {\n                tp: output[tp]\n                for tp in anno_type if tp in output.keys()\n            }\n\n        return output\n\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n        scores = defaultdict(float)\n        for kw in keywords:\n            scores = update_url_scores(scores, self.bm25(kw))\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        scores = {}\n        for kw in keywords:\n            scores = update_url_scores(scores, self.bm25(kw))\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split(\" \")\n        scores = {}\n        for kw in keywords:\n            scores = update_url_scores(scores, self.bm25(kw))\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        query_terms = query.split()\n        scores = {}\n        for term in query_terms:\n            scores = update_url_scores(scores, self.bm25(term))\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        query_keywords = query.split()\n        scores = defaultdict(float)\n        for kw in query_keywords:\n            scores = update_url_scores(scores, self.bm25(kw))\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        query_terms = query.split()\n        scores = defaultdict(float)\n        for term in query_terms:\n            scores = update_url_scores(scores, self.bm25(term))\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        query_keywords = normalized_query.split()\n        scores = {}\n        for kw in query_keywords:\n            scores = update_url_scores(scores, self.bm25(kw))\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        scores = defaultdict(float)\n        for kw in keywords:\n            scores = update_url_scores(scores, self.bm25(kw))\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n        scores = defaultdict(float)\n        for kw in keywords:\n            scores = update_url_scores(scores, self.bm25(kw))\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query_normalized = normalize_string(query)\n        query_keywords = query_normalized.split()\n        query_scores = {}\n        for kw in query_keywords:\n            query_scores = update_url_scores(query_scores, self.bm25(kw))\n        return query_scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        # normalize the query string\n        normalized_query = normalize_string(query)\n\n        # split the query string into keywords\n        keywords = normalized_query.split(\" \")\n\n        # initialize an empty dictionary to store the BM25 scores for each keyword\n        url_scores = {}\n\n        # for each keyword, calculate the BM25 score for each URL\n        for kw in keywords:\n            # get the BM25 scores for the current keyword\n            kw_scores = self.bm25(kw)\n            # update the dictionary of URL scores with the current keyword's scores\n            url_scores = update_url_scores(url_scores, kw_scores)\n\n        return url_scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        query_keywords = normalized_query.split()\n        url_scores = defaultdict(float)\n        for kw in query_keywords:\n            url_scores = update_url_scores(url_scores, self.bm25(kw))\n        return url_scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split(\" \")\n        scores = defaultdict(float)\n        for kw in keywords:\n            scores = update_url_scores(scores, self.bm25(kw))\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n        url_scores = {}\n        for kw in keywords:\n            url_scores = update_url_scores(url_scores, self.bm25(kw))\n        return url_scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n        scores = {}\n        for kw in keywords:\n            scores = update_url_scores(scores, self.bm25(kw))\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        # normalize the query\n        normalized_query = normalize_string(query)\n        # split the query into keywords\n        keywords = normalized_query.split()\n        # create a dictionary to store the scores for each keyword\n        scores = defaultdict(float)\n        # for each keyword in the query\n        for kw in keywords:\n            # calculate the BM25 score for the keyword across all URLs\n            url_scores = self.bm25(kw)\n            # update the scores for each keyword\n            update_url_scores(scores, url_scores)\n        # return the scores as a dictionary\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        # normalize query string and split into keywords\n        query_string = normalize_string(query)\n        query_keywords = query_string.split(\" \")\n\n        # calculate the BM25 score for each keyword across URLs\n        scores = defaultdict(float)\n        for kw in query_keywords:\n            scores = update_url_scores(scores, self.bm25(kw))\n\n        # aggregate the scores across keywords\n        for url, score in scores.items():\n            scores[url] = sum(scores[url] for kw in query_keywords)\n\n        # return the scores as a dictionary\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        query_keywords = normalized_query.split()\n        scores = defaultdict(float)\n        for kw in query_keywords:\n            scores = update_url_scores(scores, self.bm25(kw))\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        # normalize the query string\n        query_string = normalize_string(query)\n\n        # split the query string into keywords\n        query_keywords = query_string.split()\n\n        # initialize the dictionary to hold the aggregated BM25 scores\n        scores = defaultdict(float)\n\n        # loop through each keyword and calculate the BM25 score\n        for kw in query_keywords:\n            # get the BM25 scores for the keyword\n            kw_scores = self.bm25(kw)\n\n            # update the scores dictionary\n            update_url_scores(scores, kw_scores)\n\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        # TODO: Your code here\n        normalized_query = normalize_string(query)\n        query_keywords = normalized_query.split()\n        url_scores = defaultdict(float)\n        for kw in query_keywords:\n            url_scores = update_url_scores(url_scores, self.bm25(kw))\n        return url_scores\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        angles = self.tensor[:, 4]\n        angle_threshold = clip_angle_threshold * math.pi / 180.0\n        nearly_horizontal_mask = torch.abs(angles) < angle_threshold\n        if nearly_horizontal_mask.sum() > 0:\n            boxes = self.tensor[nearly_horizontal_mask, :]\n            boxes = boxes[:, :4].contiguous()\n            boxes = Boxes(boxes)\n            boxes.clip(box_size)\n            self.tensor[nearly_horizontal_mask, :4] = boxes.tensor\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        clip_angle_threshold = float(clip_angle_threshold)\n        assert clip_angle_threshold >= 0.0 and clip_angle_threshold <= 180.0\n\n        # Identify nearly horizontal boxes\n        horizontal_indices = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n\n        # Convert to (x1, y1, x2, y2) format\n        x1 = self.tensor[:, 0] - self.tensor[:, 2] / 2.0\n        y1 = self.tensor[:, 1] - self.tensor[:, 3] / 2.0\n        x2 = self.tensor[:, 0] + self.tensor[:, 2] / 2.0\n        y2 = self.tensor[:, 1] + self.tensor[:, 3] / 2.0\n\n        # Clip the boxes\n        x1 = torch.clamp(x1, min=0, max=box_size[1])\n        y1 = torch.clamp(y1, min=0, max=box_size[0])\n        x2 = torch.clamp(x2, min=0, max=box_size[1])\n        y2 = torch.clamp(y2, min=0, max=box_size[0])\n\n        # Convert back to (cx, cy, w, h, angle) format\n        w = x2 - x1\n        h = y2 - y1\n        cx = x1 + w / 2.0\n        cy = y1 + h / 2.0\n        angle = self.tensor[:, 4]\n\n        # Update boxes\n        self.tensor[horizontal_indices, :] = torch.stack([cx[horizontal_indices], cy[horizontal_indices], w[horizontal_indices], h[horizontal_indices], angle[horizontal_indices]], dim=1)\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        box = self.tensor\n        angle = box[:, 4]\n        angle_threshold = clip_angle_threshold * math.pi / 180\n        horizontal_mask = torch.abs(angle) < angle_threshold\n        x_center = box[:, 0]\n        y_center = box[:, 1]\n        width = box[:, 2]\n        height = box[:, 3]\n        x1 = x_center - width / 2\n        x2 = x_center + width / 2\n        y1 = y_center - height / 2\n        y2 = y_center + height / 2\n        clipped_width = torch.clamp(torch.abs(torch.sin(angle[horizontal_mask]) * height[horizontal_mask]) + torch.abs(torch.cos(angle[horizontal_mask]) * width[horizontal_mask]), max=box_size[1] - 1)\n        clipped_height = torch.clamp(torch.abs(torch.sin(angle[horizontal_mask]) * width[horizontal_mask]) + torch.abs(torch.cos(angle[horizontal_mask]) * height[horizontal_mask]), max=box_size[0] - 1)\n        x1[horizontal_mask] = x_center[horizontal_mask] - clipped_width / 2\n        x2[horizontal_mask] = x_center[horizontal_mask] + clipped_width / 2\n        y1[horizontal_mask] = y_center[horizontal_mask] - clipped_height / 2\n        y2[horizontal_mask] = y_center[horizontal_mask] + clipped_height / 2\n        assert (x2 >= x1).all()\n        assert (y2 >= y1).all()\n        self.tensor[:, 0] = x1\n        self.tensor[:, 1] = y1\n        self.tensor[:, 2] = x2 - x1\n        self.tensor[:, 3] = y2 - y1\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        # Compute the areas of all boxes before clipping\n        areas_before_clipping = self.area()\n\n        # Identify the indices of boxes that are nearly horizontal\n        abs_angle_threshold = abs(math.radians(clip_angle_threshold))\n        nearly_horizontal_indices = torch.logical_and(abs_angle_threshold >= abs(self.tensor[:, 4]),\n                                                      self.tensor[:, 4] >= 0)\n\n        # Convert the boxes to their (x1, y1, x2, y2) representation\n        x1 = self.tensor[:, 0] - self.tensor[:, 2] / 2\n        y1 = self.tensor[:, 1] - self.tensor[:, 3] / 2\n        x2 = self.tensor[:, 0] + self.tensor[:, 2] / 2\n        y2 = self.tensor[:, 1] + self.tensor[:, 3] / 2\n        boxes_to_clip = torch.stack((x1, y1, x2, y2), dim=1)\n\n        # Clip the boxes\n        boxes_to_clip[nearly_horizontal_indices, :] = boxes_to_clip[nearly_horizontal_indices, :].clamp(min=0,\n                                                                                                         max=torch.tensor(\n                                                                                                             box_size,\n                                                                                                             device=boxes_to_clip.device))\n\n        # Convert the boxes back to their (center x, center y, width, height, angle) representation\n        self.tensor[:, 0] = (boxes_to_clip[:, 0] + boxes_to_clip[:, 2]) / 2\n        self.tensor[:, 1] = (boxes_to_clip[:, 1] + boxes_to_clip[:, 3]) / 2\n        self.tensor[:, 2] = boxes_to_clip[:, 2] - boxes_to_clip[:, "}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        indices = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n        self.tensor[indices, :4] = RotatedBoxes.clip_boxes(self.tensor[indices, :4], box_size)\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        self.tensor[:, 2:4] = torch.abs(self.tensor[:, 2:4])\n        angle_threshold = torch.tensor(clip_angle_threshold * math.pi / 180.0).to(self.tensor.device)\n        is_horizontal = torch.abs(self.tensor[:, 4]) <= angle_threshold\n        self.tensor[~is_horizontal, :4] = self.tensor[~is_horizontal, :4].clamp(min=0.0, max=float(box_size[1]))\n        self.tensor[~is_horizontal, 2:4] = self.tensor[~is_horizontal, 2:4].clamp(min=0.0, max=float(box_size[0]))\n        self.tensor[is_horizontal, 2] = torch.min(self.tensor[is_horizontal, 2], float(box_size[1]))\n        self.tensor[is_horizontal, 3] = torch.min(self.tensor[is_horizontal, 3], float(box_size[0]))\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        clip_angle_threshold = float(clip_angle_threshold)\n        assert clip_angle_threshold > 0, \"clip_angle_threshold must be positive\"\n        assert len(box_size) == 2, \"box_size must be a sequence of length 2\"\n        assert box_size[0] > 0 and box_size[1] > 0, \"box_size values must be positive\"\n\n        boxes = self.tensor\n        width, height = box_size\n\n        # Get the indices of boxes whose angle is almost horizontal\n        horizontal_indices = torch.abs(boxes[:, 4]) < clip_angle_threshold\n\n        # Convert the boxes to (x1, y1, x2, y2) format\n        x1 = boxes[:, 0] - boxes[:, 2] / 2\n        y1 = boxes[:, 1] - boxes[:, 3] / 2\n        x2 = boxes[:, 0] + boxes[:, 2] / 2\n        y2 = boxes[:, 1] + boxes[:, 3] / 2\n\n        # Clamp the x and y coordinates to the box_size limits\n        x1.clamp_(min=0, max=width)\n        y1.clamp_(min=0, max=height)\n        x2.clamp_(min=0, max=width)\n        y2.clamp_(min=0, max=height)\n\n        # Convert the boxes back to (center x, center y, width, height, angle) format\n        boxes[:, 0] = (x1 + x2) / 2\n        boxes[:, 1] = (y1 + y2) / 2\n        boxes[:, 2] = x2 - x1\n        boxes[:, 3] = y2 - y1\n\n        # Ensure that the converted boxes do not increase in size\n        assert torch.allclose(boxes[horizontal_indices, 2], (x2 - x1)[horizontal_indices], atol=1e-07), \"Con"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        clip_angle_threshold = float(clip_angle_threshold)\n        assert clip_angle_threshold > 0.0\n        assert len(box_size) == 2, box_size\n        assert box_size[0] > 0 and box_size[1] > 0, box_size\n        boxes_widths = self.tensor[:, 2]\n        boxes_heights = self.tensor[:, 3]\n        boxes_angles = self.tensor[:, 4]\n        boxes_xcenters = self.tensor[:, 0]\n        boxes_ycenters = self.tensor[:, 1]\n        boxes_clip_indices = torch.abs(boxes_angles) <= clip_angle_threshold\n        boxes_x1 = boxes_xcenters - boxes_widths / 2.0\n        boxes_y1 = boxes_ycenters - boxes_heights / 2.0\n        boxes_x2 = boxes_xcenters + boxes_widths / 2.0\n        boxes_y2 = boxes_ycenters + boxes_heights / 2.0\n        boxes_x1[~boxes_clip_indices] = torch.clamp(boxes_x1[~boxes_clip_indices], min=0, max=float(box_size[1]))\n        boxes_y1[~boxes_clip_indices] = torch.clamp(boxes_y1[~boxes_clip_indices], min=0, max=float(box_size[0]))\n        boxes_x2[~boxes_clip_indices] = torch.clamp(boxes_x2[~boxes_clip_indices], min=0, max=float(box_size[1]))\n        boxes_y2[~boxes_clip_indices] = torch.clamp(boxes_y2[~boxes_clip_indices], min=0, max=float(box_size[0]))\n        boxes_widths = boxes_x2 - boxes_x1\n       "}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n\n        # Compute the angle threshold in radians\n        angle_threshold = clip_angle_threshold * math.pi / 180\n\n        # Get the indices of the boxes that are nearly horizontal\n        horizontal_indices = torch.where(torch.abs(self.tensor[:, 4]) < angle_threshold)[0]\n\n        # Convert the nearly horizontal boxes to their corner representation\n        corners = self._convert_to_corners(horizontal_indices)\n\n        # Clamp the x and y coordinates to fit within the box_size\n        corners[:, 0::2].clamp_(min=0, max=box_size[1])\n        corners[:, 1::2].clamp_(min=0, max=box_size[0])\n\n        # Convert the nearly horizontal boxes back to their original representation\n        self._convert_from_corners(corners, horizontal_indices)\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        angle_threshold_radians = clip_angle_threshold * math.pi / 180.0\n        box_tensor = self.tensor\n        # Compute the (x1, y1, x2, y2) format for the current boxes\n        widths = box_tensor[:, 2]\n        heights = box_tensor[:, 3]\n        x1 = box_tensor[:, 0] - widths / 2.0\n        x2 = box_tensor[:, 0] + widths / 2.0\n        y1 = box_tensor[:, 1] - heights / 2.0\n        y2 = box_tensor[:, 1] + heights / 2.0\n        # Identify nearly horizontal boxes\n        angle_cond = torch.abs(box_tensor[:, 4]) < angle_threshold_radians\n        # Clip the boxes that are nearly horizontal\n        x1[angle_cond], y1[angle_cond], x2[angle_cond], y2[angle_cond] = self.clip_boxes(x1[angle_cond], y1[angle_cond], x2[angle_cond], y2[angle_cond], box_size)\n        # Convert the boxes back to the format (center x, center y, width, height, angle)\n        widths = x2 - x1\n        heights = y2 - y1\n        box_tensor[:, 0] = (x1 + x2) / 2.0\n        box_tensor[:, 1] = (y1 + y2) / 2.0\n        box_tensor[:, 2] = widths\n        box_tensor[:, 3] = heights\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n\n        # Convert the box representation from (center x, center y, width, height, angle) format to (x1, y1, x2, y2), where (x1, y1) and (x2, y2) are the coordinates of the top-left and bottom-right corners, respectively.\n        corners = self.tensor.new_zeros((self.tensor.size(0), 4, 2))\n        sines = torch.sin(self.tensor[:, 4] * math.pi / 180)\n        cosines = torch.cos(self.tensor[:, 4] * math.pi / 180)\n\n        corners[:, :, 0] = self.tensor[:, 0:2] - self.tensor[:, 2:4] / 2\n        corners[:, 0, 1] += self.tensor[:, 3] / 2\n        corners[:, 1, 1] -= self.tensor[:, 3] / 2\n        corners[:, 2, 1] += self.tensor[:, 3] / 2\n        corners[:, 3, 1] -= self.tensor[:, 3] / 2\n\n        corners[:, :, 0] -= self.tensor[:, 2:4] * sines / 2\n        corners[:, :, 1] += self.tensor[:, 2:4] * cosines / 2\n\n        # For boxes that are nearly horizontal, clip the angles to be within (-45, 45] degrees to maintain backward compatibility.\n        clip_angle_threshold = float(clip_angle_threshold)\n        assert clip_angle_threshold > 0, \"clip_angle_threshold must be positive\"\n        angle_threshold_rad = clip_angle_threshold * math.pi / 180\n        angle_diff = torch.abs(torch.remainder(self.tensor[:, 4] * math.pi / 180, math.pi - angle_threshold_rad * 2))\n        angle_clipped_"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        # Compute the area of each box\n        box_areas = self.area()\n        # Identify the indices of the boxes that are nearly horizontal\n        box_is_horizontal = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n        # Convert the boxes to their representation as (x1, y1, x2, y2)\n        x1 = self.tensor[:, 0] - self.tensor[:, 2] / 2\n        y1 = self.tensor[:, 1] - self.tensor[:, 3] / 2\n        x2 = self.tensor[:, 0] + self.tensor[:, 2] / 2\n        y2 = self.tensor[:, 1] + self.tensor[:, 3] / 2\n        # Clamp the x and y coordinates to ensure they do not exceed the specified box_size limits\n        x1 = torch.clamp(x1, min=0, max=box_size[1] - 1)\n        y1 = torch.clamp(y1, min=0, max=box_size[0] - 1)\n        x2 = torch.clamp(x2, min=0, max=box_size[1] - 1)\n        y2 = torch.clamp(y2, min=0, max=box_size[0] - 1)\n        # Store the result in the tensor attribute of the RotatedBoxes instance\n        self.tensor[:, 0] = (x1 + x2) / 2\n        self.tensor[:, 1] = (y1 + y2) / 2\n        self.tensor[:, 2] = x2 - x1\n        self.tensor[:, 3] = y2 - y1\n        # Convert the boxes back to their original representation, ensuring that any numerical errors do not increase their sizes\n        self.tensor[box_is_horizontal, 4] = 0.0\n        self.tensor[~box_is_horizontal, 4] = torch.atan(torch.tan(self"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n\n        # Convert the box coordinates to (x1, y1, x2, y2) format\n        corners = self.tensor.clone()\n        corners[:, :2] = self.tensor[:, :2] - self.tensor[:, 2:4] / 2\n        corners[:, 2:] = self.tensor[:, :2] + self.tensor[:, 2:4] / 2\n\n        # Clip the boxes\n        corners[:, [0, 2]].clamp_(min=0, max=box_size[1])\n        corners[:, [1, 3]].clamp_(min=0, max=box_size[0])\n\n        # Convert the box coordinates back to (center x, center y, width, height, angle) format\n        self.tensor[:, :2] = (corners[:, [0, 2]] + corners[:, [1, 3]]) / 2\n        self.tensor[:, 2:4] = corners[:, [0, 2]] - corners[:, [1, 3]]\n\n        # Identify the boxes that are nearly horizontal and clip them\n        angles = self.tensor[:, 4]\n        abs_angles = torch.abs(angles)\n        horizontal_mask = (torch.abs(abs_angles) < clip_angle_threshold)\n\n        if horizontal_mask.sum() > 0:\n            self.tensor[horizontal_mask, :4] = corners[horizontal_mask, :]\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        clip_angle_threshold = float(clip_angle_threshold)\n        assert clip_angle_threshold > 0, \"clip_angle_threshold must be a positive number\"\n        angle_threshold_radians = clip_angle_threshold * math.pi / 180.0\n\n        # Get indices of boxes that are nearly horizontal\n        horizontal_indices = torch.abs(self.tensor[:, 4]) < angle_threshold_radians\n\n        # Convert the boxes to (x1, y1, x2, y2) format\n        x1 = self.tensor[:, 0] - self.tensor[:, 2] / 2\n        y1 = self.tensor[:, 1] - self.tensor[:, 3] / 2\n        x2 = self.tensor[:, 0] + self.tensor[:, 2] / 2\n        y2 = self.tensor[:, 1] + self.tensor[:, 3] / 2\n\n        # Clip the boxes\n        x1 = torch.clamp(x1, min=0, max=box_size[1])\n        y1 = torch.clamp(y1, min=0, max=box_size[0])\n        x2 = torch.clamp(x2, min=0, max=box_size[1])\n        y2 = torch.clamp(y2, min=0, max=box_size[0])\n\n        # Construct the new rotated boxes\n        width = x2 - x1\n        height = y2 - y1\n        new_boxes = torch.cat((x1, y1, width, height, self.tensor[:, 4]), dim=1)\n\n        # Convert the boxes to (cx, cy, w, h, angle) format\n        cx = new_boxes[:, 0] + width / 2\n        cy = new_boxes[:, 1] + height / 2\n        w = new_boxes[:, 2]\n        h = new_boxes[:, 3]"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        clip_angle_threshold = float(clip_angle_threshold)\n        assert clip_angle_threshold > 0.0\n        angle_threshold_radians = clip_angle_threshold * math.pi / 180.0\n\n        # Identify the boxes that are nearly horizontal (to avoid ambiguities in clipping them).\n        horizontal_indices = torch.abs(self.tensor[:, 4]) <= angle_threshold_radians\n\n        # Convert the boxes from (x, y, w, h, angle) format to (x1, y1, x2, y2) format.\n        boxes = self.tensor[horizontal_indices, :]\n        boxes[:, 2:] -= boxes[:, :2]\n        boxes = boxes[:, [0, 1, 2, 3]]\n\n        # Clamp the x and y coordinates to lie within the box_size limits.\n        boxes[:, 0::2].clamp_(min=0, max=box_size[1])\n        boxes[:, 1::2].clamp_(min=0, max=box_size[0])\n\n        # Convert the boxes back to (x, y, w, h, angle) format.\n        boxes[:, 2:] += boxes[:, :2]\n        boxes = boxes[:, [0, 1, 2, 3, 4]]\n\n        # Update the boxes tensor.\n        self.tensor[horizontal_indices, :] = boxes\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        # Clip boxes that are nearly horizontal.\n        # The angle threshold of 1.0 is chosen to approximate the case where the box is at exactly 180 degrees.\n        # This is done to avoid the complexities and ambiguities involved in clipping highly rotated boxes.\n        # This is done to avoid the complexities and ambiguities involved in clipping highly rotated boxes.\n        horizontal_indices = torch.abs(self.tensor[:, 4]) <= clip_angle_threshold\n        boxes = self.tensor[horizontal_indices, :]\n        x_min, y_min, x_max, y_max = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]\n        w_half, h_half = (x_max - x_min).half(), (y_max - y_min).half()\n        x_min_clip, y_min_clip = (torch.clamp(x_min - w_half, min=0), torch.clamp(y_min - h_half, min=0))\n        x_max_clip, y_max_clip = (torch.clamp(x_max + w_half, max=box_size[1]), torch.clamp(y_max + h_half, max=box_size[0]))\n        width, height = x_max_clip - x_min_clip, y_max_clip - y_min_clip\n        boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3] = x_min_clip, y_min_clip, width, height\n        self.tensor[horizontal_indices, :] = boxes\n\n        # Clip boxes that are nearly vertical.\n        vertical_indices = torch.abs(self.tensor[:, 4]) > 90.0 - clip_angle_threshold\n        boxes = self.tensor[vertical_indices, :]\n        x_min, y_min, x_max, y_max = boxes[:, 0], boxes[:, 1], boxes[:"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n\n        # Convert the boxes to their corner coordinates\n        box = self.tensor\n        box_xy = torch.cat((box[:, :2], box[:, :2]), dim=1)\n        box_wh = torch.cat((box[:, 2:4], box[:, 2:4]), dim=1)\n        box_angle = torch.cat((box[:, 4:5], box[:, 4:5]), dim=1)\n        box_xy = box_xy.flip(1).float()\n        box_wh = box_wh.flip(1).float()\n        box_angle = box_angle.flip(1).float()\n\n        # Identify the indices of the boxes that are nearly horizontal\n        abs_angle_diff = torch.abs(box_angle - torch.tensor([0.0]))\n        nearly_horizontal_indices = torch.where(abs_angle_diff < clip_angle_threshold)[0]\n\n        # Clip the nearly horizontal boxes\n        box_xy[:, 0] = torch.clamp(box_xy[:, 0], min=0, max=box_size[1])\n        box_xy[:, 1] = torch.clamp(box_xy[:, 1], min=0, max=box_size[0])\n        box_wh[:, 0] = torch.clamp(box_wh[:, 0], min=0, max=box_size[1])\n        box_wh[:, 1] = torch.clamp(box_wh[:, 1], min=0, max=box_size[0])\n\n        # Convert the boxes back to their original representation\n        box_xy = box_xy.flip(1).long()\n        box_wh = box_wh.flip(1).long()\n        box_angle = box_angle.flip(1).long()\n\n        # Update the boxes tensor\n        self.tensor[:, :2] = box_xy[:, :2]\n        self.tensor[:, 2:4] = box"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n\n        # Compute the x and y coordinates of the corners of the rotated boxes\n        x_corners = torch.cos(self.tensor[:, 4] * math.pi / 180) * self.tensor[:, 2] / 2\n        y_corners = torch.sin(self.tensor[:, 4] * math.pi / 180) * self.tensor[:, 3] / 2\n\n        # Compute the x and y coordinates of the top-left and bottom-right corners\n        x1 = self.tensor[:, 0] - x_corners\n        x2 = self.tensor[:, 0] + x_corners\n        y1 = self.tensor[:, 1] - y_corners\n        y2 = self.tensor[:, 1] + y_corners\n\n        # Compute the areas of the rotated boxes\n        area = self.area()\n\n        # Identify the indices of the boxes that are nearly horizontal\n        max_angle = (180 - clip_angle_threshold) * math.pi / 180\n        horizontal_idxs = torch.logical_and(self.tensor[:, 4] >= - max_angle, self.tensor[:, 4] <= max_angle)\n\n        # Clip the boxes that are nearly horizontal\n        if horizontal_idxs.any():\n\n            # Clip the x coordinates of the boxes\n            x1[horizontal_idxs] = torch.clamp(x1[horizontal_idxs], min=0, max=box_size[1])\n            x2[horizontal_idxs] = torch.clamp(x2[horizontal_idxs], min=0, max=box_size[1])\n\n            # Clip the y coordinates of the boxes\n            y1[horizontal_idxs] = torch.clamp(y1[horizontal_idxs], min=0, max=box_size[0])\n            y2[horizontal_idxs] = torch.clamp(y2[horizontal_idxs], min"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        clip_angle_threshold = float(clip_angle_threshold)\n        assert clip_angle_threshold >= 0.0\n        assert len(box_size) == 2, box_size\n        assert isinstance(box_size[0], int) and isinstance(box_size[1], int)\n\n        window = torch.tensor(box_size, dtype=torch.float32, device=self.tensor.device)\n        window = window.view(-1, 2)\n\n        boxes = self.tensor\n        boxes = boxes.view(-1, 5)\n        # convert (x_ctr, y_ctr, w, h, angle) to (x1, y1, x2, y2)\n        boxes_bef_clip = boxes\n        boxes = torch.cat((boxes[:, :2] - boxes[:, 2:4] / 2, boxes[:, :2] + boxes[:, 2:4] / 2), 1)\n        # boxes_bef_clip = boxes\n        # boxes = boxes_bef_clip\n\n        # clip boxes\n        boxes = boxes.clamp(min=0, max=window[None])\n\n        # convert (x1, y1, x2, y2) to (x_ctr, y_ctr, w, h, angle)\n        # boxes = torch.cat((\n        #     (boxes[:, :2] + boxes[:, 2:4]) / 2,\n        #     boxes[:, 2:4] - boxes[:, :2],\n        #     boxes[:, 4:5],\n        # ), 1)\n\n        # clamp angles to be within (-180, 180] degrees\n        boxes[:, 4] = torch.clamp(boxes[:, 4], min=-179.9999, max=180.0)\n\n        # convert (x_ctr, y_ctr, w, h, angle) to (x_ctr, y_ctr, w, h, angle) with clipped angles\n       "}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        clip_angle_threshold = float(clip_angle_threshold)\n\n        if clip_angle_threshold >= 180.0:\n            raise ValueError(\"clip_angle_threshold must be less than 180 degrees\")\n\n        # Compute the angle difference between the boxes and horizontal\n        box_tensor = self.tensor\n        angle_difference = torch.abs(box_tensor[:, 4] - torch.tensor(0.0))\n\n        # Clip the boxes that are nearly horizontal\n        horizontal_mask = angle_difference <= clip_angle_threshold\n        if not horizontal_mask.any():\n            return\n\n        # Convert the boxes to the format (x1, y1, x2, y2)\n        x = box_tensor[:, 0]\n        y = box_tensor[:, 1]\n        w = box_tensor[:, 2]\n        h = box_tensor[:, 3]\n        angle = box_tensor[:, 4]\n        x1 = x - w / 2\n        x2 = x + w / 2\n        y1 = y - h / 2\n        y2 = y + h / 2\n\n        # Clamp the coordinates to the box_size limits\n        x1 = torch.clamp(x1, 0, box_size[1] - 1)\n        y1 = torch.clamp(y1, 0, box_size[0] - 1)\n        x2 = torch.clamp(x2, 0, box_size[1] - 1)\n        y2 = torch.clamp(y2, 0, box_size[0] - 1)\n\n        # Convert back to the format (center x, center y, width, height, angle)\n        w = x2 - x1\n        h = y2 - y1\n        x = (x1 + x2) / 2\n        y = (y1 + y2) / 2\n        angle = torch.atan(torch.tan(angle * math.pi /"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stats = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            stats[item['type']] += 1\n        return stats"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stats = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            stats[item['type']] += 1\n        return stats"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stats = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for i in self.data:\n            stats[i['type']] += 1\n        return stats"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stats = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0,\n        }\n\n        for item in self.data:\n            stats[item['type']] += 1\n\n        return stats"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stats = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for datum in self.data:\n            stats[datum['type']] += 1\n        return stats"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0\n        }\n\n        for item in self.data:\n            statistics[item['type']] += 1\n\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0\n        }\n\n        for item in self.data:\n            if item['type'] in statistics.keys():\n                statistics[item['type']] += 1\n            else:\n                statistics['doc'] += 1\n\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stats = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for d in self.data:\n            if 'type' in d:\n                stats[d['type']] += 1\n        return stats"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stats = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0,\n        }\n\n        for item in self.data:\n            stats[item['type']] += 1\n\n        return stats\n\n"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stats = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for d in self.data:\n            stats[d['type']] += 1\n        return stats\n\n"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stats = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            stats[item['type']] += 1\n        return stats\n\n"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stats = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0\n        }\n\n        for item in self.data:\n            stats[item['type']] += 1\n\n        return stats\n\n"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        # Initializes a dictionary to store the statistics\n        stats = dict()\n\n        # Iterates over the 'data' attribute of the instance\n        for item in self.data:\n\n            # If the 'type' key is not found in the dictionary, the key is added to the dictionary with the value 1\n            if item['type'] not in stats:\n                stats[item['type']] = 1\n\n            # If the 'type' key is found in the dictionary, the value is incremented by 1\n            else:\n                stats[item['type']] += 1\n\n        # Returns the dictionary of statistics\n        return stats"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0\n        }\n\n        for d in self.data:\n            statistics[d['type']] += 1\n\n        return statistics\n\n"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stats = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0\n        }\n        for d in self.data:\n            stats[d['type']] += 1\n        return stats\n\n"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stats = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0\n        }\n        for datum in self.data:\n            stats[datum['type']] += 1\n\n        return stats\n\n"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stats = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0\n        }\n        for item in self.data:\n            stats[item['type']] += 1\n        return stats\n\n"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            if item['type'] == 'doc':\n                statistics['doc'] += 1\n            elif item['type'] == 'gen':\n                statistics['gen'] += 1\n            elif item['type'] == 'kno':\n                statistics['kno'] += 1\n            elif item['type'] == 'num':\n                statistics['num'] += 1\n            else:\n                print('Warning: Unknown type found in dataset:', item['type'])\n\n        return statistics\n\n"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stats = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for d in self.data:\n            stats[d['type']] += 1\n        return stats\n"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stats = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0\n        }\n\n        for item in self.data:\n            stats[item['type']] += 1\n\n        return stats\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMSEG_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMSEG_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMSEG_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMSEG_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMSEG_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMSEG_LOSSES.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMSEG_LOSSES.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMSEG_LOSSES.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMSEG_LOSSES.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return None"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return None"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMSEG_LOSSES.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn('train_cfg and test_cfg is deprecated, '\n                      'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMSEG_LOSSES.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError\n\n"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn('train_cfg and test_cfg is deprecated, '\n                      'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMSEG_LOSSES.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMSEG_LOSSES.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n\n"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    return SEGMENTORS.build(\n        cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMSEG_LOSSES.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMSEG_LOSSES.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n\n\n"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMSEG_LOSSES.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg have been deprecated. Please specify '\n            'them in the model configuration file instead.')\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, train_cfg=train_cfg, test_cfg=test_cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg, train_cfg=train_cfg, test_cfg=test_cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg have been deprecated, '\n            'please specify them in model')\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field'\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field'\n    return MMDET_DETECTORS.build(\n        cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg have been deprecated, '\n            'please specify them in model', UserWarning)\n\n    if train_cfg is not None:\n        assert cfg.get('train_cfg') is None, 'train_cfg has been deprecated'\n        cfg.setdefault('train_cfg', train_cfg)\n    if test_cfg is not None:\n        assert cfg.get('test_cfg') is None, 'test_cfg has been deprecated'\n        cfg.setdefault('test_cfg', test_cfg)\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg have been deprecated. Please specify '\n            'them in the model configuration file instead.')\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg,\n                               train_cfg=train_cfg,\n                               test_cfg=test_cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg,\n                                     train_cfg=train_cfg,\n                                     test_cfg=test_cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg have been deprecated, '\n            'please specify them in model', UserWarning)\n\n    if train_cfg is not None:\n        assert cfg.get('train_cfg') is None, 'train_cfg has been deprecated'\n        cfg.setdefault('train_cfg', train_cfg)\n    if test_cfg is not None:\n        assert cfg.get('test_cfg') is None, 'test_cfg has been deprecated'\n        cfg.setdefault('test_cfg', test_cfg)\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg have been deprecated, '\n            'please specify them in model', UserWarning)\n\n    if train_cfg is not None:\n        assert 'train_cfg' not in cfg\n        cfg.train_cfg = train_cfg\n    if test_cfg is not None:\n        assert 'test_cfg' not in cfg\n        cfg.test_cfg = test_cfg\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg have been deprecated, '\n            'please specify them in model', UserWarning)\n\n    if train_cfg is not None:\n        assert cfg.get('train_cfg') is None, 'train_cfg has been specified ' \\\n            'in both outer field and model field, the one in outer field will ' \\\n            'be used'\n        cfg.setdefault('train_cfg', train_cfg)\n    if test_cfg is not None:\n        assert cfg.get('test_cfg') is None, 'test_cfg has been specified ' \\\n            'in both outer field and model field, the one in outer field will ' \\\n            'be used'\n        cfg.setdefault('test_cfg', test_cfg)\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg have been deprecated. Please specify '\n            'them in the model configuration file instead.')\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, train_cfg=train_cfg, test_cfg=test_cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg, train_cfg=train_cfg, test_cfg=test_cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg have been deprecated. Please specify '\n            'them in the model configuration file instead.')\n\n    if 'type' not in cfg:\n        raise TypeError('cfg must contain the primary key \"type\"')\n    if cfg['type'] in MMDET_DETECTORS._module_dict.keys():\n        return MMDET_DETECTORS.build(cfg,\n                                     train_cfg=train_cfg,\n                                     test_cfg=test_cfg)\n    elif cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg,\n                               train_cfg=train_cfg,\n                               test_cfg=test_cfg)\n    else:\n        raise KeyError(f'{cfg[\"type\"]} is not in the DETECTORS registry')\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg have been deprecated. Please specify '\n            'them in the model configuration file instead.')\n\n    if 'type' not in cfg:\n        raise TypeError('\"type\" field must be specified in config dict')\n    if 'train_cfg' in cfg and train_cfg is None:\n        train_cfg = cfg.pop('train_cfg')\n    if 'test_cfg' in cfg and test_cfg is None:\n        test_cfg = cfg.pop('test_cfg')\n    obj_type = cfg.pop('type')\n\n    if obj_type in MMDET_DETECTORS._module_dict:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg have been deprecated. Please specify '\n            'them in the model configuration file instead.')\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg have been deprecated. '\n            'Please specify them in the model configuration file instead.')\n\n    if 'type' not in cfg:\n        raise TypeError('\"type\" field must be specified in config dict')\n    if 'train_cfg' in cfg and train_cfg is None:\n        warnings.warn(\n            'train_cfg has been deprecated. '\n            'Please specify it in the model configuration file instead.')\n        train_cfg = cfg.pop('train_cfg')\n    if 'test_cfg' in cfg and test_cfg is None:\n        warnings.warn(\n            'test_cfg has been deprecated. '\n            'Please specify it in the model configuration file instead.')\n        test_cfg = cfg.pop('test_cfg')\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg have been deprecated, '\n            'please specify them in model')\n\n    if train_cfg is not None:\n        cfg['model']['train_cfg'] = train_cfg\n    if test_cfg is not None:\n        cfg['model']['test_cfg'] = test_cfg\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, default_args=None)\n    else:\n        return MMDET_DETECTORS.build(cfg, default_args=None)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg have been deprecated. Please specify '\n            'them in the model configuration file instead.')\n\n    if 'type' not in cfg:\n        raise TypeError('cfg must contain the primary key \"type\"')\n    if cfg['type'] in DETECTORS._module_dict:\n        return DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg have been deprecated. Please specify '\n            'them in model. Please check out the example in '\n            'https://github.com/open-mmlab/mmdetection/tree/master/configs')\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg have been deprecated. Please specify '\n            'them in the model. BUT, if you really want to specify them '\n            'in the configuration file, you can move them to the '\n            'outer-most dictionary.')\n\n    if 'train_cfg' in cfg or 'test_cfg' in cfg:\n        assert (train_cfg is None or test_cfg is None), \\\n            'train_cfg and test_cfg cannot be specified at the same time'\n    if train_cfg is not None:\n        cfg['train_cfg'] = train_cfg\n    if test_cfg is not None:\n        cfg['test_cfg'] = test_cfg\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg have been deprecated. Please specify '\n            'them in model.train_cfg and model.test_cfg instead.')\n\n    if 'train_cfg' in cfg or 'test_cfg' in cfg:\n        assert (train_cfg is None or test_cfg is None), (\n            'train_cfg and test_cfg cannot be specified at the same time.')\n        if train_cfg is None:\n            train_cfg = cfg['train_cfg']\n        if test_cfg is None:\n            test_cfg = cfg['test_cfg']\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg have been deprecated. '\n            'Please specify them in the model configuration file instead.')\n\n    if 'type' not in cfg:\n        raise TypeError('cfg must contain the primary key \"type\"')\n    if cfg['type'] in MMDET_DETECTORS._module_dict:\n        return MMDET_DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    elif cfg['type'] in DETECTORS._module_dict:\n        return DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise KeyError(f'{cfg[\"type\"]} is not in the DETECTORS registry')\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg have been deprecated. Please specify '\n            'them in model.train_cfg and model.test_cfg respectively.')\n\n    if 'train_cfg' in cfg or 'test_cfg' in cfg:\n        # FIXME: remove `train_cfg` and `test_cfg` from model cfg\n        if train_cfg is not None or test_cfg is not None:\n            warnings.warn(\n                'train_cfg and test_cfg have been deprecated. Please specify '\n                'them in model.train_cfg and model.test_cfg respectively.')\n        else:\n            if 'train_cfg' in cfg:\n                train_cfg = cfg.train_cfg\n            if 'test_cfg' in cfg:\n                test_cfg = cfg.test_cfg\n    else:\n        train_cfg = None\n        test_cfg = None\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg have been deprecated. '\n            'Please specify them in the model configuration directly.'\n        )\n\n    if 'type' not in cfg:\n        raise TypeError('\"type\" key must be specified in detector config.')\n\n    if train_cfg is not None and 'train_cfg' in cfg:\n        raise ValueError(\n            'train_cfg has been deprecated as an input to '\n            'build_detector. Please specify it in the model '\n            'configuration directly.'\n        )\n\n    if test_cfg is not None and 'test_cfg' in cfg:\n        raise ValueError(\n            'test_cfg has been deprecated as an input to '\n            'build_detector. Please specify it in the model '\n            'configuration directly.'\n        )\n\n    if cfg['type'] in MMDET_DETECTORS._module_dict:\n        return MMDET_DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(gt_annos) == len(dt_annos)\n    num_imgs = len(gt_annos)\n    assert num_imgs > 0\n\n    cat_ids = gt_annos[0]['labels']\n    num_classes = len(cat_ids)\n    if num_classes == 0:\n        return\n\n    # initialize the evaluation results\n    evaluation = {}\n    for class_id in cat_ids:\n        evaluation[class_id] = {\n            'ap': np.zeros(len(metric), dtype=np.float32),\n            'ap_not_overlap': np.zeros(len(metric), dtype=np.float32),\n            'ap_50': np.zeros(len(metric), dtype=np.float32),\n            'ap_75': np.zeros(len(metric), dtype=np.float32),\n            'ap_s': np.zeros(len(metric), dtype=np.float32),\n            'ap_m': np.zeros(len(metric), dtype=np.float32),\n            'ap_l': np.zeros(len(metric), dtype=np.float32),\n            'num_pos': np.zeros(len(metric), dtype=np.int64),\n            'num_pos_not_overlap': np.zeros(len(metric), dtype=np.int64),\n            'num_pos_50': np.zeros(len(metric), dtype=np.int64),\n            'num_pos_75': np.zeros(len(metric), dtype=np.int64),\n            'num_pos_s': np.zeros(len(metric), dtype=np.int64),\n            'num_pos_m': np.zeros(len(metric), dtype=np.int64),\n            'num_pos_l': np.zeros(len(metric), dtype=np.int64),\n            'num_tp': np.zeros(len(metric), dtype=np.int64),\n           "}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(gt_annos) == len(dt_annos)\n\n    # initialize the output\n    num_classes = len(label2cat)\n    eval_results = {\n        'Car': {\n            'AP': 0,\n            'AR': 0,\n            'AP_50%': 0,\n            'AP_75%': 0,\n            'AP_small': 0,\n            'AP_medium': 0,\n            'AP_large': 0,\n            'AR_10%': 0,\n            'AR_20%': 0,\n            'AR_30%': 0,\n            'AR_50%': 0,\n            'AR_70%': 0,\n            'AR_90%': 0,\n            'AR_100%': 0\n        }\n    }\n\n    # initialize the iou thresholds\n    if metric is None:\n        metric = [0.25, 0.5]\n\n    # initialize the iou thresholds\n    if metric is None:\n        metric = [0.25, 0.5]\n\n    # initialize the iou thresholds\n    if metric is None:\n        metric = [0.25, 0.5]\n\n    # initialize the iou thresholds\n    if metric is None:\n        metric = [0.25, 0.5]\n\n    # initialize the iou thresholds\n    if metric is None:\n        metric = [0.25, 0.5]\n\n    # initialize the iou thresholds\n    if metric is None:\n        metric = [0.25, 0.5]\n\n    # initialize the iou thresholds\n    if metric is None:\n        metric = [0.25, 0.5]\n\n    # initialize the iou thresholds\n    if metric is None:\n        metric = [0.25, 0.5]\n\n    # initialize the iou thresholds\n    if metric is None:\n        metric = [0.2"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    if logger is None:\n        logger = print\n\n    assert len(gt_annos) == len(dt_annos)\n    num_imgs = len(gt_annos)\n    cat_names = list(label2cat.keys())\n\n    # initialize a dict to store the evaluation results\n    ret_dict = {'Car': {}, 'Pedestrian': {}, 'Cyclist': {}}\n    for metric_name in metric:\n        ret_dict['Car'][metric_name] = np.zeros((len(cat_names), len(metric)), dtype=np.float32)\n        ret_dict['Pedestrian'][metric_name] = np.zeros((len(cat_names), len(metric)), dtype=np.float32)\n        ret_dict['Cyclist'][metric_name] = np.zeros((len(cat_names), len(metric)), dtype=np.float32)\n\n    for class_name in cat_names:\n        # initialize a dict to store the evaluation results\n        ret_dict[class_name] = {}\n        for metric_name in metric:\n            ret_dict[class_name][metric_name] = np.zeros((len(cat_names), len(metric)), dtype=np.float32)\n\n    for i, (gt_anno, dt_anno) in enumerate(zip(gt_annos, dt_annos)):\n        gt_img_idxes = gt_anno['sample_idx']\n        dt_img_idxes = dt_anno['sample_idx']\n        assert np.all(gt_img_idxes == dt_img_idxes)\n        gt_annos_img = gt_anno['gt_annos']\n        dt_annos_img = dt_anno['dt_annos']\n\n        for class_name in cat_names:\n            gt_boxes_img = gt_annos_img[gt_annos_img['name'] == class_name]\n            dt_boxes_img = dt_annos_img[dt_annos_img['name'] == class_"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(gt_annos) == len(dt_annos)\n\n    # Initialize the default logger.\n    if logger is None:\n        logger = print_log\n\n    # Initialize the default box type and mode.\n    if box_type_3d is None:\n        box_type_3d = LiDARInstance3DBoxes\n    if box_mode_3d is None:\n        box_mode_3d = Box3DMode.LIDAR\n\n    # Initialize the evaluation results.\n    eval_results = dict()\n    iou_thrs = np.arange(0.5, 1.0, 0.05)\n    iou_thrs = np.append(iou_thrs, np.arange(0.5, 0.95, 0.05))\n    iou_thrs = np.append(iou_thrs, np.array([0.7]))\n    iou_thrs = np.append(iou_thrs, np.array([0.9]))\n    iou_thrs = np.append(iou_thrs, np.array([0.95]))\n    iou_thrs = np.append(iou_thrs, np.array([0.99]))\n    iou_thrs = np.append(iou_thrs, np.array([0.995]))\n    iou_thrs = np.append(iou_thrs, np.array([0.999]))\n    iou_thrs = np.append(iou_thrs, np.array([0.9995]))\n    iou_thrs = np.append(iou_thrs, np.array([0.9999]))\n    iou_thrs = np.append(iou_thrs, np.array([0.99995]))\n    iou_thrs = np.append(iou_thrs, np.array([0.99999]))\n    iou_thrs = np.append(iou_thrs, np.array([0."}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(gt_annos) == len(dt_annos)\n    num_imgs = len(gt_annos)\n    assert max(np.hstack([np.array([ann['num_lidar_pts'] for ann in ann_dict['gt_annos']]) for ann_dict in gt_annos])) > 0, \\\n        \"No ground truth boxes found in some of the samples. Please check your dataset and annotations.\"\n\n    # initialize the output dict\n    ret_dict = {}\n    detail_dict = {}\n    for metric in metrics:\n        ret_dict[f'AP_{metric}'] = 0\n        ret_dict[f'AR_{metric}'] = 0\n        ret_dict[f'AP_img_{metric}'] = [0] * num_imgs\n        ret_dict[f'AR_img_{metric}'] = [0] * num_imgs\n        ret_dict[f'AP_class_{metric}'] = [0] * len(label2cat)\n        ret_dict[f'AR_class_{metric}'] = [0] * len(label2cat)\n        for i in range(len(label2cat)):\n            detail_dict[f'{label2cat[i]}_AP_{metric}'] = []\n            detail_dict[f'{label2cat[i]}_AR_{metric}'] = []\n\n    # initialize the output dict\n    ret_dict = {}\n    detail_dict = {}\n    for metric in metrics:\n        ret_dict[f'AP_{metric}'] = 0\n        ret_dict[f'AR_{metric}'] = 0\n        ret_dict[f'AP_img_{metric}'] = [0] * num_imgs\n        ret_dict[f'AR_img_{metric}'] = [0] * num_imgs\n        ret_dict[f'AP_class_{metric}'] = [0] * len(label2cat)\n        ret_dict[f'AR_class_{metric}'] = [0] * len(label2cat)\n        for i in range(len(label2cat"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    if logger is None:\n        logger = print\n    ret = {}\n    # for each class\n    for class_name in label2cat:\n        # get gt and dt boxes\n        gt_boxes = []\n        dt_boxes = []\n        gt_ids = []\n        dt_ids = []\n        for gt_anno in gt_annos:\n            if class_name in gt_anno:\n                gt_boxes.append(gt_anno[class_name])\n                gt_ids.append(np.ones(len(gt_anno[class_name]), dtype=np.int) * gt_anno['frame_id'])\n        for dt_anno in dt_annos:\n            if class_name in dt_anno:\n                dt_boxes.append(dt_anno[class_name])\n                dt_ids.append(np.ones(len(dt_anno[class_name]), dtype=np.int) * dt_anno['frame_id'])\n        if len(gt_boxes) == 0 and len(dt_boxes) == 0:\n            continue\n        if len(gt_boxes) == 0:\n            gt_boxes = np.zeros((0, 7))\n        else:\n            gt_boxes = np.concatenate(gt_boxes, 0)\n        if len(dt_boxes) == 0:\n            dt_boxes = np.zeros((0, 7))\n        else:\n            dt_boxes = np.concatenate(dt_boxes, 0)\n        if len(gt_ids) == 0:\n            gt_ids = np.zeros((0, 1))\n        else:\n            gt_ids = np.concatenate(gt_ids, 0)\n        if len(dt_ids) == 0:\n            dt_ids = np.zeros((0, 1))\n        else:\n            dt_ids = np.concatenate(dt_ids, 0)\n\n        # get recall and precision\n        gt_"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(dt_annos) == len(gt_annos)\n    num_classes = len(label2cat)\n    eval_results = {}\n\n    # Calculate the AP and AR for each class\n    for class_id in range(num_classes):\n        class_name = label2cat[class_id]\n        gt_annos_class = []\n        dt_annos_class = []\n        for i in range(len(gt_annos)):\n            gt_annos_class.append(gt_annos[i][class_name])\n            dt_annos_class.append(dt_annos[i][class_name])\n        recall, precision, ap = eval_map_recall(dt_annos_class, gt_annos_class, ovthresh=metric)\n        for i in range(len(metric)):\n            if len(recall[i]) == 0:\n                eval_results['{}_{}'.format(class_name, 'recall')] = 0\n            else:\n                eval_results['{}_{}'.format(class_name, 'recall')] = np.mean(recall[i])\n            if len(precision[i]) == 0:\n                eval_results['{}_{}'.format(class_name, 'precision')] = 0\n            else:\n                eval_results['{}_{}'.format(class_name, 'precision')] = np.mean(precision[i])\n            if len(ap[i]) == 0:\n                eval_results['{}_{}'.format(class_name, 'ap')] = 0\n            else:\n                eval_results['{}_{}'.format(class_name, 'ap')] = np.mean(ap[i])\n\n    # Calculate the mAP and mAR for all classes\n    for i in range(len(metric)):\n        if len(recall[i]) == 0:\n            eval_results['mAP_{}'.format(str(metric[i]))] = 0\n        else:\n            eval_results['mAP_{}'.format(str"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(dt_annos) == len(gt_annos)\n\n    logger = print_log if logger is None else logger\n\n    # Convert the predicted bounding boxes to the format of the ground truth annotations\n    dt_annos = copy.deepcopy(dt_annos)\n    dt_annos = eval_det_annos(dt_annos, box_type_3d, box_mode_3d)\n\n    # Convert the ground truth bounding boxes to the format of the ground truth annotations\n    gt_annos = copy.deepcopy(gt_annos)\n    gt_annos = eval_det_annos(gt_annos, box_type_3d, box_mode_3d)\n\n    # Calculate the AP and AR for each IoU threshold\n    ret_dict = eval_map_recall(dt_annos, gt_annos, metric)\n\n    # Calculate the mAP and mAR\n    mAP = {\n        'Car': 0.0,\n        'Pedestrian': 0.0,\n        'Cyclist': 0.0,\n        'Van': 0.0,\n        'Truck': 0.0,\n        'Person_sitting': 0.0,\n        'Tram': 0.0,\n        'Misc': 0.0,\n        'DontCare': 0.0\n    }\n    mAR = {\n        'Car': 0.0,\n        'Pedestrian': 0.0,\n        'Cyclist': 0.0,\n        'Van': 0.0,\n        'Truck': 0.0,\n        'Person_sitting': 0.0,\n        'Tram': 0.0,\n        'Misc': 0.0,\n        'DontCare': 0.0\n    }\n    for label in gt_annos.keys():\n        if label in mAP:\n            mAP[label] = np.array([0.0])\n            mAR[label] = np.array(["}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(dt_annos) == len(gt_annos)\n    cat_ids = list(label2cat.keys())\n    cat_ids.sort()\n\n    # Compute the IoU thresholds for the evaluation.\n    if isinstance(metric, str):\n        metric = [metric]\n    elif not isinstance(metric, list):\n        raise TypeError('metric must be a list of str, but got {}'.format(\n            type(metric)))\n    assert all([isinstance(m, str) for m in metric])\n\n    # Compute the IoU thresholds for the evaluation.\n    if isinstance(metric, (list, tuple)):\n        metric = [\n            m if m in ['2d', '3d'] else ValueError(\n                f'metric shoule be \"2d\" or \"3d\", but got {m}')\n            for m in metric\n        ]\n    else:\n        metric = ['2d']\n\n    # Compute the IoU thresholds for the evaluation.\n    if isinstance(metric, (list, tuple)):\n        metric_iou = [\n            m if m in [0.25, 0.5] else ValueError(\n                f'metric_iou shoule be \"0.25\" or \"0.5\", but got {m}')\n            for m in metric\n        ]\n    else:\n        metric_iou = [metric]\n\n    # Compute the IoU thresholds for the evaluation.\n    if isinstance(metric, (list, tuple)):\n        metric_center = [\n            m if m in ['center'] else ValueError(\n                f'metric_center shoule be \"center\", but got {m}')\n            for m in metric\n        ]\n    else:\n        metric_center = [metric]\n\n    # Compute the IoU thresholds for the evaluation.\n    if isinstance(metric, (list, tuple)):\n        metric_iou_center = [\n            m if m in ['iou_center'] else ValueError(\n                f'metric_iou_center shoule be \"iou_center"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(gt_annos) == len(dt_annos)\n    cat_names = list(label2cat.keys())\n    cat_names.sort()\n    num_classes = len(cat_names)\n    logger = print_log(logger, 'Evaluating...')\n    logger.info('Class names: %s' % cat_names)\n    logger.info('Evaluating over %d images' % len(gt_annos))\n\n    # initialize a dict to store evaluation results\n    results = {\n        'Car': {\n            'Car': {\n                'AP': {},\n                'AR': {},\n                'AP_50': {},\n                'AR_50': {}\n            },\n            'Bus': {\n                'AP': {},\n                'AR': {},\n                'AP_50': {},\n                'AR_50': {}\n            },\n            'Van': {\n                'AP': {},\n                'AR': {},\n                'AP_50': {},\n                'AR_50': {}\n            },\n            'Truck': {\n                'AP': {},\n                'AR': {},\n                'AP_50': {},\n                'AR_50': {}\n            },\n            'Pedestrian': {\n                'AP': {},\n                'AR': {},\n                'AP_50': {},\n                'AR_50': {}\n            },\n            'Cyclist': {\n                'AP': {},\n                'AR': {},\n                'AP_50': {},\n                'AR_50': {}\n            },\n            'Tram': {\n                'AP': {},\n                'AR': {},\n                'AP_50': {},\n                'AR_50': {}\n            },\n            'Misc': {\n                'AP': {},\n                'AR': {},\n                'AP_50': {},\n                'AR_50': {}\n            },\n            'Total': {\n                'AP': {},\n                'AR': {},\n                'AP_50': {},\n                'AR_50': {}\n            }\n        },\n        'Vehicle':"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(gt_annos) == len(dt_annos)\n    num_classes = len(label2cat)\n\n    # Initialize the list of IoU thresholds used for computing AP and AR.\n    if isinstance(metric, list):\n        metrics = metric\n    elif isinstance(metric, float):\n        metrics = [metric]\n    else:\n        raise TypeError('metric must be a list or a float')\n\n    # Initialize a dictionary to store the evaluation results.\n    result = {}\n\n    # Initialize a dictionary to store the evaluation results for all classes.\n    for iou_thresh in metrics:\n        result[f'AP_{iou_thresh}'] = {}\n        result[f'AR_{iou_thresh}'] = {}\n\n    # Initialize a dictionary to store the evaluation results for all classes.\n    for iou_thresh in metrics:\n        result[f'AP_{iou_thresh}']['total'] = 0\n        result[f'AR_{iou_thresh}']['total'] = 0\n\n    # Initialize a dictionary to store the evaluation results for all classes.\n    for iou_thresh in metrics:\n        result[f'AP_{iou_thresh}']['not_overlap'] = 0\n        result[f'AR_{iou_thresh}']['not_overlap'] = 0\n\n    # Initialize a dictionary to store the evaluation results for all classes.\n    for iou_thresh in metrics:\n        result[f'AP_{iou_thresh}']['overlap'] = 0\n        result[f'AR_{iou_thresh}']['overlap'] = 0\n\n    # Initialize a dictionary to store the evaluation results for all classes.\n    for iou_thresh in metrics:\n        result[f'AP_{iou_thresh}']['score'] = 0\n        result[f'AR_{iou_thresh}']['score'] = 0\n\n    # Initialize a dictionary to store the evaluation results for all classes.\n    for iou_thresh in metrics:\n        result[f'AP_{iou_thresh}']['score_"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(gt_annos) == len(dt_annos)\n    num_examples = len(gt_annos)\n    logger = logger if logger is not None else print\n    if box_type_3d is None:\n        box_type_3d = LiDARInstance3DBoxes\n    if box_mode_3d is None:\n        box_mode_3d = 'LIDAR'\n\n    split_examples = dict()\n    for idx in range(num_examples):\n        gt_anno = gt_annos[idx]\n        dt_anno = dt_annos[idx]\n        example_idx = gt_anno['metadata']['image_idx']\n        split_name = gt_anno['metadata']['split']\n        if split_name not in split_examples:\n            split_examples[split_name] = []\n        split_examples[split_name].append((example_idx, gt_anno, dt_anno))\n\n    ret_dict = {}\n    for split, examples in split_examples.items():\n        gt_annos_split = [e[1] for e in examples]\n        dt_annos_split = [e[2] for e in examples]\n        # print(f\"split: {split}\")\n        # print(f\"gt_annos_split: {gt_annos_split}\")\n        # print(f\"dt_annos_split: {dt_annos_split}\")\n        ret_dict_split = eval_map_recall(dt_annos_split, gt_annos_split, metric)\n        ret_dict[split] = ret_dict_split\n\n    # calculate mean ap and mean ar over all classes\n    gt_num = np.zeros(len(metric))\n    dt_num = np.zeros(len(metric))\n    for value in ret_dict.values():\n        gt_num += value[0].values()\n        dt_num += value[1].values()\n    mean_gt_num = gt_num / len(ret_dict)\n    mean_dt_num = dt_num"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(gt_annos) == len(dt_annos)\n    num_imgs = len(gt_annos)\n    assert num_imgs > 0\n\n    if logger is None:\n        logger = print\n\n    if box_type_3d is None:\n        box_type_3d = type(dt_annos[0]['boxes_3d'][0])\n\n    if box_mode_3d is None:\n        box_mode_3d = dt_annos[0]['boxes_3d'].tensor.mode\n\n    if box_mode_3d == 'velodyne':\n        gt_annos = _transfer_ground_truth(gt_annos, box_type_3d, box_mode_3d)\n        dt_annos = _transfer_detection(dt_annos, box_type_3d, box_mode_3d)\n\n    num_classes = len(label2cat)\n\n    # Build dict for recall and AP.\n    gt_datas_thres = {}\n    dt_datas_thres = {}\n    for class_id in range(num_classes):\n        gt_datas_thres[class_id] = {}\n        dt_datas_thres[class_id] = {}\n        for iou_idx in range(len(metric)):\n            gt_datas_thres[class_id][iou_idx] = {}\n            dt_datas_thres[class_id][iou_idx] = {}\n\n    # Collect true positive detections.\n    for img_id in range(num_imgs):\n        for class_id in range(num_classes):\n            gt_datas_thres[class_id][0] = gt_annos[img_id][class_id]\n            dt_datas_thres[class_id][0] = dt_annos[img_id][class_id]\n\n    for class_id in range(num_classes):\n        for iou_idx in range(len(metric)):\n            gt_datas_thres[class"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(gt_annos) == len(dt_annos)\n\n    if box_type_3d is None:\n        box_type_3d = LiDARInstance3DBoxes\n    if box_mode_3d is None:\n        box_mode_3d = 'LIDAR'\n\n    # Initialize the evaluation results.\n    results = {}\n    results_perclass = {}\n    for class_name in label2cat:\n        results_perclass[class_name] = {'gt': 0, 'tp': 0, 'fp': 0}\n\n    # Iterate through the ground truth annotations and detection annotations.\n    for i in range(len(gt_annos)):\n        gt_annos_i = gt_annos[i]\n        dt_annos_i = dt_annos[i]\n\n        # Iterate through the annotations in the current image.\n        for gt_anno_i in gt_annos_i:\n            gt_boxes_i = box_type_3d(\n                gt_anno_i['gt_boxes_upright_depth'],\n                box_dim=gt_anno_i['boxes_dim'].shape[-1],\n                box_mode=box_mode_3d).convert_to(box_mode_3d)\n            gt_names_i = gt_anno_i['gt_names']\n\n            for dt_anno_i in dt_annos_i:\n                dt_boxes_i = box_type_3d(\n                    dt_anno_i['boxes_upright_depth'],\n                    box_dim=dt_anno_i['boxes_dim'].shape[-1],\n                    box_mode=box_mode_3d).convert_to(box_mode_3d)\n                dt_scores_i = dt_anno_i['scores']\n                dt_names_i = dt_anno_i['class']\n\n                for j in range(len(gt_names_i)):\n                    gt_name = gt_names_i[j]"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    if logger is None:\n        logger = print\n\n    if box_type_3d is None:\n        box_type_3d = LiDARInstance3DBoxes\n    if box_mode_3d is None:\n        box_mode_3d = 'LIDAR'\n\n    assert len(dt_annos) == len(gt_annos), 'The lengths of dt and gt should be same'\n    num_examples = len(gt_annos)\n    assert num_examples > 0, 'The number of examples should be greater than 0'\n    mAP_info = {\n        'Car': {\n            'ap': 0.0,\n            'ap_info': [0.0 for i in range(len(metric))],\n            'num_positives': 0.0\n        },\n        'Pedestrian': {\n            'ap': 0.0,\n            'ap_info': [0.0 for i in range(len(metric))],\n            'num_positives': 0.0\n        },\n        'Cyclist': {\n            'ap': 0.0,\n            'ap_info': [0.0 for i in range(len(metric))],\n            'num_positives': 0.0\n        },\n        'OVERALL': {\n            'ap': 0.0,\n            'ap_info': [0.0 for i in range(len(metric))],\n            'num_positives': 0.0\n        }\n    }\n\n    for i in range(num_examples):\n        gt_num_cars = 0\n        gt_num_pedestrians = 0\n        gt_num_cyclists = 0\n        dt_num_cars = 0\n        dt_num_pedestrians = 0\n        dt_num_cyclists = 0\n        gt_cars = []\n        gt_pedestrians = []\n        gt_cyclists = []\n        dt_cars = []\n        dt_pedestrians = []"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(dt_annos) == len(gt_annos)\n    assert len(dt_annos) > 0\n\n    # get the number of classes in the dataset\n    num_classes = len(gt_annos[0]['labels'])\n\n    # get the number of IoU thresholds\n    num_thresholds = len(metric)\n\n    # initialize the evaluation results\n    result = {}\n    for i in range(num_classes):\n        result[label2cat[i]] = {'recall': np.zeros((num_thresholds,)),\n                                'precision': np.zeros((num_thresholds,)),\n                                'ap': np.zeros((num_thresholds,)),\n                                'gt': 0,\n                                'num': 0}\n\n    # loop over the number of detections\n    for i in range(len(dt_annos)):\n        # get the number of ground truth objects\n        gt_num = len(gt_annos[i]['boxes_lidar'])\n\n        # get the number of detected objects\n        dt_num = len(dt_annos[i]['boxes_lidar'])\n\n        # initialize the number of true positives\n        tp = np.zeros((num_thresholds, num_classes))\n\n        # initialize the number of false positives\n        fp = np.zeros((num_thresholds, num_classes))\n\n        # initialize the number of false negatives\n        fn = np.zeros((num_thresholds, num_classes))\n\n        # loop over the number of ground truth objects\n        for j in range(gt_num):\n            # get the ground truth label\n            gt_label = gt_annos[i]['labels'][j]\n\n            # initialize the number of true positives for the current class\n            tp[:, gt_label] = 0\n\n            # initialize the number of false positives for the current class\n            fp[:, gt_label] = 0\n\n            # initialize the number of false negatives for the current class"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(gt_annos) == len(dt_annos)\n\n    if logger is None:\n        logger = print\n\n    # initialize mAP\n    map_total = 0\n    map_class = {}\n    map_class_table = []\n    map_class_table_title = ['Class', 'AP']\n\n    # initialize mAR\n    mar_total = 0\n    mar_class = {}\n    mar_class_table = []\n    mar_class_table_title = ['Class', 'AR']\n\n    # initialize mAP and mAR for each IoU threshold\n    map_thr = {}\n    map_thr_table = []\n    map_thr_table_title = ['IoU', 'AP']\n\n    mar_thr = {}\n    mar_thr_table = []\n    mar_thr_table_title = ['IoU', 'AR']\n\n    for iou_idx, iou_thr in enumerate(metric):\n        # initialize AP and AR for each IoU threshold\n        map_thr[iou_thr] = 0\n        map_thr_table.append([iou_thr, 0])\n\n        mar_thr[iou_thr] = 0\n        mar_thr_table.append([iou_thr, 0])\n\n    # initialize the number of true positive and detected objects\n    npos = 0\n\n    # iterate over each image\n    for i in range(len(gt_annos)):\n        # load the ground truth and detected annotations\n        cur_gt = gt_annos[i]\n        cur_dt = dt_annos[i]\n\n        # convert the ground truth and detected annotations to the desired format\n        gt_annos_keypoints = cur_gt['gt_boxes_ignored']\n        dt_annos_keypoints = cur_dt['dt_boxes_ignored']\n\n        # iterate over each class\n        for label in gt_annos_keypoints.keys():\n            # load the ground truth and detected bounding boxes for the current class"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    # Initialize the output dictionary.\n    ret_dict = {}\n\n    # Initialize the output table.\n    table_dict = {}\n\n    # Get the list of all class names.\n    cat_names = list(label2cat.values())\n\n    # Get the list of IoU thresholds.\n    if isinstance(metric, list):\n        iou_threshs = metric\n    elif isinstance(metric, float):\n        iou_threshs = [metric]\n    else:\n        raise TypeError('metric must be a float or a list of float')\n\n    # Calculate the AP and AR for each class.\n    for class_name in cat_names:\n        # Get the list of ground-truth and detected bounding boxes for the class.\n        gt_boxes_class = [\n            obj for obj in gt_annos if obj['name'] == class_name\n        ]\n        dt_boxes_class = [\n            obj for obj in dt_annos if obj['name'] == class_name\n        ]\n\n        # Get the list of IoU thresholds.\n        if isinstance(metric, list):\n            iou_threshs_class = metric\n        elif isinstance(metric, float):\n            iou_threshs_class = [metric]\n        else:\n            raise TypeError('metric must be a float or a list of float')\n\n        # Calculate the AP and AR for each IoU threshold.\n        for iou_thresh in iou_threshs_class:\n            # Calculate the AP and AR.\n            ap, recall, precision = eval_map_recall(\n                dt_boxes_class, gt_boxes_class, ovthresh=iou_thresh)\n\n            # Record the AP and AR.\n            ret_dict['{}-{}'.format(class_name, iou_thresh)] = ap\n            table_dict['{}-{}'.format(class_name, iou_thresh)] = [\n                iou_thresh, ap, recall[-1], precision[-1]\n            ]\n\n    # Calculate the mAP and"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(dt_annos) == len(gt_annos)\n    cat2label = {v: k for k, v in label2cat.items()}\n\n    # Evaluate the predictions by comparing them with the ground truth annotations.\n    dt_annos = dt_annos\n    gt_annos = gt_annos\n\n    # Convert the predicted bounding boxes and scores to a list of dictionaries.\n    dt_annos = deepcopy(dt_annos)\n    for i in range(len(dt_annos)):\n        for j in range(len(dt_annos[i]['boxes_lidar'])):\n            dt_annos[i]['boxes_lidar'][j] = np.array(dt_annos[i]['boxes_lidar'][j])\n            dt_annos[i]['scores'][j] = np.array(dt_annos[i]['scores'][j])\n\n    # Convert the ground truth bounding boxes to a list of dictionaries.\n    gt_annos = deepcopy(gt_annos)\n    for i in range(len(gt_annos)):\n        for j in range(len(gt_annos[i]['gt_boxes_lidar'])):\n            gt_annos[i]['gt_boxes_lidar'][j] = np.array(gt_annos[i]['gt_boxes_lidar'][j])\n\n    # Evaluate the predictions and gather the evaluation results.\n    result = eval_map_recall(dt_annos, gt_annos, ovthresh=metric, logger=logger)\n\n    # Print the evaluation results.\n    ret_dict = {}\n    for i, cls_name in enumerate(label2cat.keys()):\n        class_name = label2cat[cls_name]\n        # Map the class name to its numerical label.\n        if class_name not in cat2label.keys():\n            continue\n        cls_indexes = [i]\n        # Calculate the AP and AR for each IoU threshold."}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    # Evaluation function for different types of boxes\n    if box_type_3d == 'LiDAR':\n        from .kitti_utils import get_box_type\n        from .kitti_utils import get_box_dim\n        from .kitti_utils import get_velo2cam_mat\n        from .kitti_utils import boxes_lidar_to_aligned_camera\n        from .kitti_utils import calib_to_matricies\n        from .kitti_utils import project_to_image\n        from .kitti_utils import get_frustum\n        from .kitti_utils import get_2d_boxes\n        from .kitti_utils import boxes_aligned_to_camera\n        from .kitti_utils import boxes_camera_to_lidar\n        from .kitti_utils import remove_outside_points\n        from .kitti_utils import remove_points_in_boxes\n        from .kitti_utils import boxes_lidar_to_label\n        from .kitti_utils import boxes_camera_to_label\n        from .kitti_utils import boxes_lidar_to_img\n        from .kitti_utils import boxes_camera_to_img\n        from .kitti_utils import project_to_camera\n        from .kitti_utils import boxes_lidar_to_bev_camera\n        from .kitti_utils import boxes_to_corners\n        from .kitti_utils import points_in_boxes_part\n        from .kitti_utils import boxes_iou_3d\n        from .kitti_utils import boxes_iou_bev\n        from .kitti_utils import boxes_iou_bev_pytorch\n        from .kitti_utils import boxes_iou_3d_pytorch\n        from .kitti_utils import boxes_iou_bev_pytorch\n        from .kitti_utils import boxes_iou_bev_torch\n        from .kitti"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        box_class = LiDARInstance3DBoxes\n        box_mode = Box3DMode.LIDAR\n    elif box_type == 'Camera':\n        box_class = CameraInstance3DBoxes\n        box_mode = Box3DMode.CAM\n    elif box_type == 'Depth':\n        box_class = DepthInstance3DBoxes\n        box_mode = Box3DMode.DEPTH\n    else:\n        raise ValueError(f'Not supported box type {box_type}')\n\n    return box_class, box_mode\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        return (LiDARInstance3DBoxes, Box3DMode.LIDAR)\n    elif box_type == 'Camera':\n        return (CameraInstance3DBoxes, Box3DMode.CAM)\n    elif box_type == 'Depth':\n        return (DepthInstance3DBoxes, Box3DMode.DEPTH)\n    else:\n        raise ValueError(\"Only 'LiDAR', 'Camera', and 'Depth' are supported\"\n                         f' as box_type, but got {box_type}')\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        return (LiDARInstance3DBoxes, Box3DMode.LIDAR)\n    elif box_type == 'Camera':\n        return (CameraInstance3DBoxes, Box3DMode.CAM)\n    elif box_type == 'Depth':\n        return (DepthInstance3DBoxes, Box3DMode.DEPTH)\n    else:\n        raise ValueError(\"Input box_type is not supported\")\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        box_cls = LiDARInstance3DBoxes\n        box_mode = Box3DMode.LIDAR\n    elif box_type == 'Camera':\n        box_cls = CameraInstance3DBoxes\n        box_mode = Box3DMode.CAM\n    elif box_type == 'Depth':\n        box_cls = DepthInstance3DBoxes\n        box_mode = Box3DMode.DEPTH\n    else:\n        raise ValueError(f'Not supported box type {box_type}')\n\n    return box_cls, box_mode\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == \"LiDAR\":\n        box_class = LiDARInstance3DBoxes\n        box_mode = Box3DMode.LIDAR\n    elif box_type == \"Camera\":\n        box_class = CameraInstance3DBoxes\n        box_mode = Box3DMode.CAM\n    elif box_type == \"Depth\":\n        box_class = DepthInstance3DBoxes\n        box_mode = Box3DMode.DEPTH\n    else:\n        raise ValueError(\"Only 'LiDAR', 'Camera', and 'Depth' are supported now\")\n\n    return box_class, box_mode\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == \"LiDAR\":\n        box_cls = LiDARInstance3DBoxes\n        box_mode = Box3DMode.LIDAR\n    elif box_type == \"Camera\":\n        box_cls = CameraInstance3DBoxes\n        box_mode = Box3DMode.CAM\n    elif box_type == \"Depth\":\n        box_cls = DepthInstance3DBoxes\n        box_mode = Box3DMode.DEPTH\n    else:\n        raise NotImplementedError\n\n    return box_cls, box_mode\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    box_type = box_type.lower()\n    if box_type == 'lidar':\n        box_cls = LiDARInstance3DBoxes\n        box_mode = Box3DMode.LIDAR\n    elif box_type == 'camera':\n        box_cls = CameraInstance3DBoxes\n        box_mode = Box3DMode.CAM\n    elif box_type == 'depth':\n        box_cls = DepthInstance3DBoxes\n        box_mode = Box3DMode.DEPTH\n    else:\n        raise ValueError(f'Unsupported box type: {box_type}')\n\n    return box_cls, box_mode\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        box_cls = LiDARInstance3DBoxes\n        box_mode = Box3DMode.LIDAR\n    elif box_type == 'Camera':\n        box_cls = CameraInstance3DBoxes\n        box_mode = Box3DMode.CAM\n    elif box_type == 'Depth':\n        box_cls = DepthInstance3DBoxes\n        box_mode = Box3DMode.DEPTH\n    else:\n        raise ValueError(f'Not supported box type {box_type}')\n    return box_cls, box_mode\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    box_type = box_type.lower()\n    if box_type == \"lidar\":\n        box_class = LiDARInstance3DBoxes\n        box_mode = Box3DMode.LIDAR\n    elif box_type == \"camera\":\n        box_class = CameraInstance3DBoxes\n        box_mode = Box3DMode.CAM\n    elif box_type == \"depth\":\n        box_class = DepthInstance3DBoxes\n        box_mode = Box3DMode.DEPTH\n    else:\n        raise ValueError(\"box_type {} is not supported.\".format(box_type))\n    return box_class, box_mode\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    box_type_lower = box_type.lower()\n    if box_type_lower == \"lidar\":\n        box_cls = LiDARInstance3DBoxes\n        box_mode = Box3DMode.LIDAR\n    elif box_type_lower == \"camera\":\n        box_cls = CameraInstance3DBoxes\n        box_mode = Box3DMode.CAM\n    elif box_type_lower == \"depth\":\n        box_cls = DepthInstance3DBoxes\n        box_mode = Box3DMode.DEPTH\n    else:\n        raise ValueError(f\"Unsupported box_type '{box_type}'.\")\n    return box_cls, box_mode\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    # If the given box type is \"LiDAR\", then return the corresponding class and mode\n    if box_type == \"LiDAR\":\n        box_class = LiDARInstance3DBoxes\n        box_mode = Box3DMode.LIDAR\n\n    # If the given box type is \"Camera\", then return the corresponding class and mode\n    elif box_type == \"Camera\":\n        box_class = CameraInstance3DBoxes\n        box_mode = Box3DMode.CAM\n\n    # If the given box type is \"Depth\", then return the corresponding class and mode\n    elif box_type == \"Depth\":\n        box_class = DepthInstance3DBoxes\n        box_mode = Box3DMode.DEPTH\n\n    # If the given box type is not \"LiDAR\", \"Camera\", or \"Depth\", then raise an error\n    else:\n        raise ValueError(\"The given box type is not supported\")\n\n    # Return the corresponding class and mode\n    return box_class, box_mode\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    # Map the input box type identifier to the corresponding 3D box class and mode.\n    if box_type == \"LiDAR\":\n        box_class = LiDARInstance3DBoxes\n        box_mode = Box3DMode.LIDAR\n    elif box_type == \"Camera\":\n        box_class = CameraInstance3DBoxes\n        box_mode = Box3DMode.CAM\n    elif box_type == \"Depth\":\n        box_class = DepthInstance3DBoxes\n        box_mode = Box3DMode.DEPTH\n    else:\n        raise ValueError(f\"Unrecognized box type '{box_type}'\")\n\n    return box_class, box_mode\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    box_type_map = {\n        'LiDAR': (LiDARInstance3DBoxes, LiDAR_XYZWOHR_SCALE),\n        'Camera': (CameraInstance3DBoxes, Camera_XYLgWsA_SCALE),\n        'Depth': (DepthInstance3DBoxes, Depth_XYZWO_SCALE)\n    }\n\n    if box_type in box_type_map:\n        return box_type_map[box_type]\n    else:\n        raise ValueError(\"Input box_type is not supported\")\n\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == \"LiDAR\":\n        box_cls = LiDARInstance3DBoxes\n        box_mode = Box3DMode.LIDAR\n    elif box_type == \"Camera\":\n        box_cls = CameraInstance3DBoxes\n        box_mode = Box3DMode.CAM\n    elif box_type == \"Depth\":\n        box_cls = DepthInstance3DBoxes\n        box_mode = Box3DMode.DEPTH\n    else:\n        raise ValueError(f\"Unsupported box type: {box_type}\")\n\n    return box_cls, box_mode\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    # Check for valid box type\n    if box_type not in [\"LiDAR\", \"Camera\", \"Depth\"]:\n        raise ValueError(\"Invalid box type. Expected one of 'LiDAR', 'Camera', or 'Depth'.\")\n\n    # Get box class\n    if box_type == \"LiDAR\":\n        box_class = Box3DMode.LIDAR\n    elif box_type == \"Camera\":\n        box_class = Box3DMode.CAM\n    else:\n        box_class = Box3DMode.DEPTH\n\n    # Get box mode\n    if box_type == \"LiDAR\":\n        box_mode = Box3DMode.LIDAR\n    elif box_type == \"Camera\":\n        box_mode = Box3DMode.CAM\n    else:\n        box_mode = Box3DMode.DEPTH\n\n    return box_class, box_mode\n\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    # Check if the input is valid.\n    if box_type not in [\"LiDAR\", \"Camera\", \"Depth\"]:\n        raise ValueError(\"Invalid box type identifier: {}. Expected one of 'LiDAR', 'Camera', or 'Depth'.\".format(box_type))\n\n    # Map the input to the corresponding class and mode.\n    if box_type == \"LiDAR\":\n        box_class = Box3DMode\n        box_mode = Box3DMode.LIDAR\n    elif box_type == \"Camera\":\n        box_class = CameraInstance3DBoxes\n        box_mode = Box3DMode.CAM\n    elif box_type == \"Depth\":\n        box_class = DepthInstance3DBoxes\n        box_mode = Box3DMode.DEPTH\n\n    return box_class, box_mode\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        return (LiDARInstance3DBoxes, LiDAR_box_mode)\n    elif box_type == 'Camera':\n        return (CameraInstance3DBoxes, Camera_box_mode)\n    elif box_type == 'Depth':\n        return (DepthInstance3DBoxes, Depth_box_mode)\n    else:\n        raise ValueError(\"Input box_type is not supported\")\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    box_type = box_type.lower()\n    if box_type == \"lidar\":\n        box_cls = LiDARInstance3DBoxes\n        box_mode = Box3DMode.LIDAR\n    elif box_type == \"camera\":\n        box_cls = CameraInstance3DBoxes\n        box_mode = Box3DMode.CAM\n    elif box_type == \"depth\":\n        box_cls = DepthInstance3DBoxes\n        box_mode = Box3DMode.DEPTH\n    else:\n        raise ValueError(f\"Unsupported box_type '{box_type}'\")\n\n    return box_cls, box_mode\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        return (LiDARInstance3DBoxes, Box3DMode.LIDAR)\n    elif box_type == 'Camera':\n        return (CameraInstance3DBoxes, Box3DMode.CAM)\n    elif box_type == 'Depth':\n        return (DepthInstance3DBoxes, Box3DMode.DEPTH)\n    else:\n        raise ValueError(\"Input box_type is not supported\")\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    box_type = box_type.upper()\n\n    if box_type == 'LiDAR':\n        from .box_3d_mode import LiDARBox3DMode as Box3DMode\n        box_class = LiDARBox3D\n    elif box_type == 'CAMERA':\n        from .box_3d_mode import CameraBox3DMode as Box3DMode\n        box_class = CameraBox3D\n    elif box_type == 'DEPTH':\n        from .box_3d_mode import DepthBox3DMode as Box3DMode\n        box_class = DepthBox3D\n    else:\n        raise ValueError('Only \"LiDAR\", \"CAMERA\", and \"DEPTH\" are supported as box_type argument.')\n\n    return box_class, Box3DMode\n\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      raise RequestError('must provide messages')\n\n    messages = [\n      Message(message) if isinstance(message, dict) else message\n      for message in messages\n    ]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      raise RequestError('must provide messages')\n\n    if not isinstance(messages, list):\n      raise TypeError('messages must be a list of Message or dict-like objects')\n\n    messages = [_validate_message(message) for message in messages]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      raise RequestError('must provide messages')\n\n    if not isinstance(messages, list):\n      raise TypeError('messages must be a list')\n\n    for message in messages:\n      if not isinstance(message, Message):\n        if not isinstance(message, dict):\n          raise TypeError('messages must be a list of Message or dict-like objects')\n\n        message = Message(**message)\n\n      if not message.role:\n        raise RequestError('must provide a role for each message')\n\n      if not message.content:\n        raise RequestError('must provide content for each message')\n\n      if message.images:\n        message.images = [_encode_image(image) for image in message.images]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      raise RequestError('must provide messages')\n\n    if not isinstance(messages, list):\n      raise TypeError('messages must be a list')\n\n    if not all([isinstance(message, Message) for message in messages]):\n      raise TypeError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [message.dict() for message in messages],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      raise RequestError('must provide messages')\n\n    try:\n      messages = [_validate_message(message) for message in messages]\n    except TypeError as e:\n      raise RequestError(str(e)) from None\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      messages = []\n\n    for message in messages:\n      if not isinstance(message, Message):\n        message = Message(**message)\n\n      if not message.content:\n        raise RequestError('must provide content for each message')\n\n      if not message.role:\n        raise RequestError('must provide a role for each message')\n\n      if message.role not in ['system', 'user', 'assistant']:\n        raise RequestError(f'invalid role: {message.role}')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      raise RequestError('must provide messages')\n\n    if not isinstance(messages, list):\n      raise TypeError('messages must be a list of Message or dict-like objects')\n\n    for message in messages:\n      if not isinstance(message, Message):\n        message = Message(**message)\n\n      if not message.role or message.role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role (one of system, user, assistant)')\n\n      if not message.content:\n        raise RequestError('messages must contain content')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [message.dict() for message in messages],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages is None:\n      messages = []\n\n    for message in messages:\n      if not isinstance(message, Message):\n        message = Message(**message)\n\n      if not message.role:\n        raise RequestError('must provide a role for each message')\n\n      if not message.content:\n        raise RequestError('must provide content for each message')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [message.dict() for message in messages],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      raise RequestError('must provide messages')\n\n    for message in messages:\n      if not isinstance(message, Message):\n        try:\n          message = Message(**message)\n        except TypeError as e:\n          raise TypeError('messages must be a list of Message or dict-like objects') from e\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      raise RequestError('must provide messages')\n\n    if not isinstance(messages, list):\n      raise TypeError('messages must be a list')\n\n    messages = [_validate_message(message) for message in messages]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      raise RequestError('must provide messages')\n\n    if not isinstance(messages, list):\n      raise TypeError('messages must be a list')\n\n    for message in messages:\n      if not isinstance(message, Message):\n        try:\n          message = Message(**message)\n        except Exception as e:\n          raise TypeError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [message.dict() for message in messages],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      raise RequestError('must provide messages')\n\n    for message in messages:\n      if not isinstance(message, Message):\n        if not isinstance(message, dict):\n          raise TypeError('messages must be a list of Message or dict-like objects')\n        message = Message(**message)\n\n      if message.role not in ['system', 'user', 'assistant']:\n        raise RequestError('invalid message role')\n\n      if not message.content:\n        raise RequestError('message content must not be empty')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      raise RequestError('must provide messages')\n\n    for message in messages:\n      if not isinstance(message, Message):\n        try:\n          message = Message(**message)\n        except TypeError:\n          raise TypeError(f'messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [message.dict() for message in messages],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      raise RequestError('must provide messages')\n\n    if not isinstance(messages, Sequence):\n      raise TypeError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [\n          {\n            'role': message.get('role'),\n            'content': message.get('content'),\n            'images': [_encode_image(image) for image in message.get('images', [])],\n          } for message in messages\n        ],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      raise RequestError('must provide messages')\n\n    if not isinstance(messages, list):\n      raise TypeError('messages must be a list of Message or dict-like objects')\n\n    for message in messages:\n      if not isinstance(message, Message):\n        message = Message(**message)\n\n      if not message.role or message.role not in {'system', 'user', 'assistant'}:\n        raise RequestError('messages must have a valid role (one of \"system\", \"user\", \"assistant\")')\n\n      if not message.content:\n        raise RequestError('messages must have content')\n\n      if message.images:\n        message.images = [_encode_image(image) for image in message.images]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      messages = []\n\n    for message in messages:\n      if not isinstance(message, Message):\n        try:\n          message = Message(**message)\n        except Exception as e:\n          raise TypeError(f'invalid message: {message}') from e\n\n      if not message.content:\n        raise RequestError('must provide a message content')\n\n      if not message.role:\n        raise RequestError('must provide a message role')\n\n      if message.role not in ('system', 'user', 'assistant'):\n        raise RequestError('invalid message role')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      raise RequestError('must provide messages')\n\n    for message in messages:\n      if not isinstance(message, Message):\n        try:\n          message = Message(**message)\n        except Exception as e:\n          raise TypeError('messages must be a list of Message or dict-like objects') from e\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      raise RequestError('must provide messages')\n\n    for message in messages:\n      if not isinstance(message, dict):\n        raise TypeError(f'message must be a dict-like object, not {type(message).__name__}')\n\n      if 'role' not in message or 'content' not in message:\n        raise RequestError('message must contain role and content')\n\n      if message['role'] not in ('system', 'user', 'assistant'):\n        raise RequestError('message role must be one of system, user, assistant')\n\n      if not message['content']:\n        raise RequestError('message content must not be empty')\n\n      if 'images' in message:\n        message['images'] = [_encode_image(image) for image in message['images']]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      messages = []\n\n    if not isinstance(messages, list):\n      raise TypeError('messages must be a list of Message or dict-like objects')\n\n    for message in messages:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n\n      if not all(k in message for k in ['role', 'content']):\n        raise RequestError('messages must contain a \"role\" and \"content\"')\n\n      if message['role'] not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a \"role\" in [\"system\", \"user\", \"assistant\"]')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      raise RequestError('must provide messages')\n\n    if not isinstance(messages, list):\n      raise TypeError('messages must be a list')\n\n    for message in messages:\n      if not isinstance(message, Message):\n        if not isinstance(message, dict):\n          raise TypeError('message must be a Message or dict-like object')\n        message = Message(**message)\n\n      if message.role not in ['system', 'user', 'assistant']:\n        raise RequestError(f'invalid message role: {message.role}')\n\n      if not message.content:\n        raise RequestError('message content cannot be empty')\n\n      if message.images:\n        message.images = [_encode_image(image) for image in message.images]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      f'/api/pull/{model}',\n      json={\n        'insecure': insecure,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    params = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context or [],\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream('POST', '/generate', params=params, stream=stream)\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream(\n      'POST',\n      '/generate',\n      json=data,\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context or [],\n      'raw': raw,\n      'format': format,\n      'images': images or [],\n      'options': options or {},\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream('POST', '/generate', json=data, stream=stream)\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise ValueError('Model is required')\n\n    params = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream(\n      'POST',\n      '/generate',\n      stream=stream,\n      params=params,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('Model is required')\n\n    params = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream(\n      'POST',\n      '/generate',\n      params=params,\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise ValueError('The model parameter is required.')\n\n    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context or [],\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream('POST', '/generate', data=data, stream=stream)\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('Model is required.')\n\n    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context or [],\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream('POST', '/generate', json=data, stream=stream)\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise ValueError('Model is required.')\n\n    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context or [],\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream(\n      'POST',\n      '/generate',\n      json=data,\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    url = '/generate'\n\n    if not model:\n      raise RequestError('Model is required.')\n\n    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context or [],\n      'raw': raw,\n      'format': format or '',\n      'images': images or [],\n      'options': options or {},\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream(\n      'POST',\n      url,\n      data=json.dumps(data),\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    url = '/generate'\n\n    if not model:\n      raise RequestError('Model must be provided.')\n\n    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context or [],\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream(\n      'POST',\n      url,\n      json=data,\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise ValueError('model is required')\n\n    if images:\n      images = [self._encode_image(image) for image in images]\n\n    if context:\n      context = [str(c) for c in context]\n\n    if options:\n      options = {k: v for k, v in options.items() if v is not None}\n\n    if keep_alive:\n      keep_alive = str(keep_alive)\n\n    params = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream(\n      'POST',\n      '/generate',\n      stream=stream,\n      data=json.dumps(params),\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise ValueError('model is required')\n\n    if context is None:\n      context = []\n\n    if images is None:\n      images = []\n\n    if options is None:\n      options = {}\n\n    if keep_alive is not None:\n      options['keep_alive'] = keep_alive\n\n    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n    }\n\n    return self._request_stream(\n      'POST',\n      '/generate',\n      data=json.dumps(data),\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise ValueError('Model is required.')\n\n    if not context:\n      context = []\n\n    if options:\n      options = options.to_dict()\n\n    if images:\n      images = [self._encode_image(image) for image in images]\n\n    params = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream('GET', '/generate', params=params, stream=stream)\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('model is required')\n\n    if context is None:\n      context = []\n\n    if images is None:\n      images = []\n\n    if options is None:\n      options = {}\n\n    if keep_alive is None:\n      keep_alive = 0.0\n\n    if keep_alive == '':\n      keep_alive = 0.0\n\n    if isinstance(keep_alive, str):\n      try:\n        keep_alive = float(keep_alive)\n      except ValueError:\n        raise RequestError('keep_alive must be a float or a string representing a float')\n\n    if not isinstance(keep_alive, float):\n      raise RequestError('keep_alive must be a float or a string representing a float')\n\n    params = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream(\n      'POST',\n      '/generate',\n      stream=stream,\n      json=params,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('model is required')\n\n    if not options:\n      options = {}\n\n    if context:\n      options['context'] = context\n\n    if images:\n      options['images'] = images\n\n    if options:\n      options = json.dumps(options)\n\n    if keep_alive:\n      options['keep_alive'] = keep_alive\n\n    return self._request_stream(\n      'POST',\n      '/generate',\n      data=json.dumps({\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'options': options,\n      }),\n      params={\n        'raw': raw,\n        'format': format,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise ValueError('model is required')\n\n    if images:\n      images = [\n        _encode_image(image)\n        for image in images\n      ]\n\n    if options:\n      options = {\n        k: v\n        for k, v in options.items()\n        if v is not None\n      }\n\n    keep_alive = _parse_keep_alive(keep_alive)\n\n    params = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context or [],\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream('POST', '/generate', params=params, stream=stream)\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise ValueError('model is required')\n\n    if images is not None:\n      images = list(map(self._encode_image, images))\n\n    if options is not None:\n      options = options.dict(exclude_none=True)\n\n    if keep_alive is not None:\n      keep_alive = str(keep_alive)\n\n    return self._request_stream(\n      'POST',\n      'generate',\n      stream=stream,\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'raw': raw,\n        'format': format,\n        'images': images,\n        'options': options,\n        'keep_alive': keep_alive,\n      },\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise ValueError('model must be provided')\n\n    if options is not None:\n      if options.get('context'):\n        context = options.get('context')\n      if options.get('images'):\n        images = options.get('images')\n      if options.get('keep_alive'):\n        keep_alive = options.get('keep_alive')\n\n    if context is None:\n      context = []\n\n    if images is None:\n      images = []\n\n    if keep_alive is None:\n      keep_alive = 0\n\n    params = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream('POST', '/generate', stream=stream, json=params)\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('Model is required.')\n\n    if not context:\n      context = []\n\n    if options:\n      options = Options(options)\n\n    if images:\n      images = [b64encode(i).decode('ascii') for i in images]\n\n    if keep_alive:\n      if isinstance(keep_alive, str):\n        keep_alive = float(keep_alive)\n\n    params = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream(\n      'POST',\n      '/generate',\n      params=params,\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise ValueError('The model is required.')\n\n    if not isinstance(context, Sequence) and context is not None:\n      raise TypeError('The context must be a sequence.')\n\n    if not isinstance(options, Mapping) and options is not None:\n      raise TypeError('The options must be a mapping.')\n\n    if not isinstance(images, Sequence) and images is not None:\n      raise TypeError('The images must be a sequence.')\n\n    if not isinstance(keep_alive, (float, str)) and keep_alive is not None:\n      raise TypeError('The keep-alive parameter must be a float, a string, or None.')\n\n    if isinstance(keep_alive, str):\n      keep_alive = float(keep_alive)\n\n    if images:\n      images = [\n        _parse_image(image)\n        for image in images\n      ]\n\n    if options:\n      options = {\n        k: v\n        for k, v in options.items()\n        if k in {'prompt', 'stop_condition', 'max_tokens', 'max_time', 'max_length', 'min_length', 'temperature', 'top_k', 'top_p', 'repetition_penalty', 'length_penalty', 'num_beams', 'num_beam_groups', 'num_attention_heads', 'num_decoder_layers', 'no_repeat_ngram_size', 'early_stopping', 'use_cache', 'return_unfinished_sequences', 'bad_words_ids', 'force_bos_token', 'use_cache', 'return_cache'}\n      }\n\n    params = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream(\n     "}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('must provide a path or modelfile')\n\n    if path:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': b64encode(modelfile).decode('utf-8'),\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('must provide a path or modelfile')\n\n    if path:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('must provide a path or modelfile')\n\n    if not path:\n      with open(modelfile, 'r') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not (modelfile or path):\n      raise RequestError('must provide a path or modelfile')\n\n    if path:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': _encode_file(modelfile),\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('must provide either a path or a modelfile')\n\n    if path:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      data={\n        'name': model,\n        'modelfile': modelfile,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('must provide a path or a model file')\n\n    if path:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': b64encode(modelfile).decode('utf-8'),\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not (modelfile or path):\n      raise RequestError('must provide either a path or a model file')\n\n    if path:\n      with open(path, 'r') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not (path or modelfile):\n      raise RequestError('must provide a model file or path')\n\n    if not modelfile:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': _encode_file(modelfile),\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('must provide a path or a model file')\n\n    if path:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': _encode_file(modelfile),\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not (path or modelfile):\n      raise RequestError('must provide a path or modelfile')\n\n    if path:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': b64encode(modelfile).decode('utf-8'),\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('must provide a path or modelfile')\n\n    if path:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not (path or modelfile):\n      raise RequestError('must provide a model file or path')\n\n    if path:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': _encode_file(modelfile),\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if path:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    if not modelfile:\n      raise RequestError('must provide either path or modelfile')\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': b64encode(modelfile).decode('utf-8'),\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('must provide either path or modelfile')\n\n    if path:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': _encode_image(modelfile),\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('must provide either a model file path or the model file content')\n\n    if path:\n      modelfile = Path(path).read_text()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not (path or modelfile):\n      raise RequestError('must provide a model file path or content')\n\n    if not modelfile:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'model': model,\n        'modelfile': _encode_image(modelfile),\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('must provide a model file or path')\n\n    if path:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': _encode_image(modelfile),\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('must provide a model file or path')\n\n    if path:\n      path = Path(path)\n      if not path.exists():\n        raise RequestError('model file does not exist')\n      with path.open('rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': b64encode(modelfile).decode('utf-8'),\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('must provide either path or modelfile')\n\n    if path:\n      path = Path(path)\n      if not path.exists():\n        raise RequestError('path does not exist')\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'path': path.name if path else None,\n        'modelfile': _read_file(path) if path else modelfile,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not (path or modelfile):\n      raise RequestError('must provide either path or modelfile')\n\n    if path:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    if isinstance(path, str):\n      path = Path(path)\n\n    if not path.exists():\n      raise FileNotFoundError(f'{path} does not exist')\n\n    sha256sum = sha256()\n    with open(path, 'rb') as f:\n      for chunk in iter(lambda: f.read(io.DEFAULT_BUFFER_SIZE), b''):\n        sha256sum.update(chunk)\n\n    digest = sha256sum.hexdigest()\n    url = urllib.parse.urljoin(self._client.base_url, f'/blob/{digest}')\n    response = self._client.head(url)\n    if response.status_code == 404:\n      response = self._client.post(url, files={'file': open(path, 'rb')})\n      if response.status_code != 201:\n        raise ResponseError(response.text, response.status_code)\n\n    return f'sha256:{digest}'\n\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    sha256_hash = sha256()\n    with open(path, 'rb') as f:\n      for byte_block in iter(lambda: f.read(4096), b\"\"):\n        sha256_hash.update(byte_block)\n\n    digest = sha256_hash.hexdigest()\n    url = f'/api/blobs/{digest}'\n    if response := self._client.head(url):\n      return digest\n\n    with open(path, 'rb') as f:\n      self._client.post(url, data=f)\n\n    return digest\n\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    if isinstance(path, str):\n      path = Path(path)\n\n    if not path.exists():\n      raise FileNotFoundError(f'{path} does not exist')\n\n    sha256sum = sha256(path.read_bytes()).hexdigest()\n\n    try:\n      self._client.head(f'/api/blob/{sha256sum}')\n    except httpx.HTTPStatusError as e:\n      if e.response.status_code != 404:\n        raise ResponseError(e.response.text, e.response.status_code) from None\n\n    else:\n      return sha256sum\n\n    with open(path, 'rb') as f:\n      response = self._client.post(f'/api/blob/{sha256sum}', files={'file': f})\n\n    if response.status_code != 201:\n      raise ResponseError(response.text, response.status_code)\n\n    return sha256sum\n\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    # Calculate the SHA-256 checksum of the file.\n    with open(path, 'rb') as f:\n      checksum = sha256(f.read()).hexdigest()\n\n    # Check if a blob with the checksum already exists on the server.\n    try:\n      self._client.head(f'/api/blob/{checksum}')\n    except httpx.HTTPStatusError as e:\n      if e.response.status_code != 404:\n        raise\n    else:\n      return checksum\n\n    # Upload the file if it does not exist on the server.\n    with open(path, 'rb') as f:\n      self._client.post(f'/api/blob/{checksum}', files={'file': f})\n\n    return checksum\n\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    sha256_hash = sha256()\n    with open(path, 'rb') as f:\n      for byte_block in iter(lambda: f.read(4096), b''):\n        sha256_hash.update(byte_block)\n\n    digest = sha256_hash.hexdigest()\n    r = self._client.head(f'/api/blob/{digest}')\n    if r.status_code == 404:\n      self._client.post(f'/api/blob/{digest}', files={'file': open(path, 'rb')})\n\n    return f'sha256:{digest}'\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    if isinstance(path, str):\n      path = Path(path)\n\n    if not path.exists():\n      raise FileNotFoundError(f'{path} does not exist')\n\n    if not path.is_file():\n      raise FileNotFoundError(f'{path} is not a file')\n\n    if not path.is_absolute():\n      path = Path.cwd() / path\n\n    digest = sha256(path.read_bytes()).hexdigest()\n\n    try:\n      response = self._client.head(f'/api/blob/{digest}')\n      response.raise_for_status()\n    except httpx.HTTPStatusError as e:\n      if e.response.status_code == 404:\n        response = self._client.post(f'/api/blob/{digest}', files={'file': path.read_bytes()})\n        response.raise_for_status()\n      else:\n        raise ResponseError(response.text, response.status_code) from None\n\n    return f'sha256:{digest}'\n\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = Path(path)\n    sha256_hash = sha256()\n    with open(path, \"rb\") as f:\n      # Read and update hash string value in blocks of 4K\n      for byte_block in iter(lambda: f.read(4096), b\"\"):\n        sha256_hash.update(byte_block)\n\n    digest = sha256_hash.hexdigest()\n    url = f'/api/blob/{digest}'\n    response = self._client.head(url)\n    if response.status_code == 200:\n      return f'sha256:{digest}'\n    elif response.status_code == 404:\n      with open(path, \"rb\") as f:\n        response = self._client.post(url, data=f)\n      if response.status_code == 201:\n        return f'sha256:{digest}'\n      else:\n        raise ResponseError(response.text, response.status_code)\n    else:\n      raise ResponseError(response.text, response.status_code)\n\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    if isinstance(path, str):\n      path = Path(path)\n\n    if not path.exists():\n      raise FileNotFoundError(f'{path} does not exist')\n\n    if not path.is_file():\n      raise FileNotFoundError(f'{path} is not a file')\n\n    with open(path, 'rb') as f:\n      checksum = sha256(f.read()).hexdigest()\n\n    url = self._client.base_url.copy_with(\n      path=f'/blobs/{checksum}',\n    )\n\n    response = self._client.head(url)\n\n    if response.status_code == 200:\n      return f'sha256:{checksum}'\n\n    if response.status_code != 404:\n      raise ResponseError(response.text, response.status_code)\n\n    url = self._client.base_url.copy_with(\n      path=f'/blobs',\n    )\n\n    response = self._client.post(url, files={'blob': open(path, 'rb')})\n\n    if response.status_code != 201:\n      raise ResponseError(response.text, response.status_code)\n\n    return f'sha256:{checksum}'\n\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    if isinstance(path, str):\n      path = Path(path)\n\n    if not path.exists():\n      raise FileNotFoundError(f'{path} does not exist')\n\n    if not path.is_file():\n      raise FileNotFoundError(f'{path} is not a file')\n\n    with open(path, 'rb') as f:\n      file = f.read()\n\n    digest = sha256(file).hexdigest()\n    url = f'{self._client.base_url}/api/blob/{digest}'\n    response = self._client.head(url)\n    if response.status_code == 404:\n      response = self._client.post(url, data=file)\n      response.raise_for_status()\n\n    return f'sha256:{digest}'\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    # Calculate the SHA-256 checksum of the file.\n    with open(path, 'rb') as f:\n      checksum = sha256(f.read())\n\n    # Check if the file already exists on the server.\n    response = self._client.head(f'/blob/{checksum.hexdigest()}')\n    if response.status_code != 404:\n      return response.headers['Digest']\n\n    # Upload the file to the server.\n    with open(path, 'rb') as f:\n      response = self._client.post(\n        f'/blob/{checksum.hexdigest()}',\n        data=f,\n        headers={'Content-Type': 'application/octet-stream'},\n      )\n      response.raise_for_status()\n\n    return response.headers['Digest']\n\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    if not isinstance(path, Path):\n      path = Path(path)\n\n    if not path.exists():\n      raise FileNotFoundError(f'file does not exist: {path}')\n\n    if not path.is_file():\n      raise TypeError(f'path must be a file: {path}')\n\n    if not path.stat().st_size:\n      raise ValueError(f'path cannot be empty: {path}')\n\n    digest = sha256(path.read_bytes()).hexdigest()\n\n    try:\n      self._client.head(f'/api/blob/{digest}')\n    except httpx.HTTPStatusError as e:\n      if e.response.status_code != 404:\n        raise ResponseError(e.response.text, e.response.status_code) from None\n    else:\n      return digest\n\n    with path.open('rb') as f:\n      self._client.post(f'/api/blob/{digest}', files={'blob': f})\n\n    return digest\n\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = Path(path).expanduser()\n    if not path.exists():\n      raise FileNotFoundError(f'{path} does not exist')\n\n    if not path.is_file():\n      raise ValueError(f'{path} is not a file')\n\n    digest = sha256(path.read_bytes()).hexdigest()\n    url = f'{self._client.base_url}/api/blob/{digest}'\n    r = self._client.head(url)\n    if r.status_code == 404:\n      with open(path, 'rb') as f:\n        r = self._client.post(url, files={'file': f})\n        r.raise_for_status()\n\n    return f'sha256:{digest}'\n\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as f:\n      for chunk in iter(lambda: f.read(4096), b''):\n        sha256sum.update(chunk)\n    digest = sha256sum.digest()\n    digest_hex = binascii.hexlify(digest).decode('utf-8')\n    digest_b64 = b64encode(digest).decode('utf-8')\n    url = f'{self._client.base_url}/api/blob/{digest_b64}'\n    response = self._client.head(url)\n    if response.status_code == 200:\n      return f'sha256:{digest_hex}'\n    elif response.status_code == 404:\n      response = self._client.post(url, data=f'{path}')\n      response.raise_for_status()\n      return f'sha256:{digest_hex}'\n    else:\n      raise ResponseError(response.text, response.status_code)\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    if isinstance(path, str):\n      path = Path(path)\n\n    if not path.exists():\n      raise RequestError(f'{path} does not exist')\n\n    if not path.is_file():\n      raise RequestError(f'{path} is not a file')\n\n    if not path.stat().st_size:\n      raise RequestError(f'{path} is empty')\n\n    sha256sum = sha256()\n    with open(path, 'rb') as f:\n      for chunk in iter(lambda: f.read(io.DEFAULT_BUFFER_SIZE), b''):\n        sha256sum.update(chunk)\n\n    digest = sha256sum.digest()\n    digest = binascii.hexlify(digest).decode()\n    digest = f'sha256:{digest}'\n\n    url = urllib.parse.urljoin(self._client.base_url, f'blobs/sha256/{digest}')\n    response = self._client.head(url, allow_redirects=True)\n\n    if response.status_code == 200:\n      return digest\n\n    if response.status_code != 404:\n      raise ResponseError(response.text, response.status_code)\n\n    url = urllib.parse.urljoin(self._client.base_url, 'blobs/uploads/')\n    response = self._client.post(url, data=f'blobs/sha256/{digest}')\n\n    if response.status_code != 201:\n      raise ResponseError(response.text, response.status_code)\n\n    url = urllib.parse.urljoin(self._client.base_url, f'blobs/sha256/{digest}')\n    response = self._client.put(url, data=open(path, 'rb'))\n\n    if response.status_code != 201:\n      raise ResponseError(response.text, response.status_code)\n\n    return digest"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    if not isinstance(path, Path):\n      path = Path(path)\n\n    if not path.exists():\n      raise RequestError(f'file does not exist: {path}')\n\n    digest = sha256(path.read_bytes()).hexdigest()\n    if self._head(digest):\n      return digest\n\n    with path.open('rb') as f:\n      self._post(digest, f)\n\n    return digest\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = Path(path).expanduser()\n\n    if not path.exists():\n      raise FileNotFoundError(f'{path} does not exist')\n\n    with open(path, 'rb') as f:\n      sha256_hash = sha256()\n      while chunk := f.read(8192):\n        sha256_hash.update(chunk)\n\n      digest = sha256_hash.hexdigest()\n      digest_b64 = b64encode(bytes.fromhex(digest)).decode()\n\n      url = f'{self._client.base_url}/blob/{digest_b64}'\n      response = self._client.head(url)\n\n      if response.status_code == 404:\n        response = self._client.post(url, data=f.read())\n\n    if response.status_code != 200:\n      raise ResponseError(response.text, response.status_code)\n\n    return f'sha256:{digest}'\n\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as f:\n      for chunk in iter(lambda: f.read(4096), b''):\n        sha256sum.update(chunk)\n\n    digest = 'sha256:' + binascii.hexlify(sha256sum.digest()).decode('utf-8')\n\n    # Check if blob already exists on server\n    try:\n      self._request('HEAD', f'/api/blob/{digest}')\n    except httpx.HTTPStatusError as e:\n      if e.response.status_code != 404:\n        raise ResponseError(e.response.text, e.response.status_code) from None\n\n    # Upload blob if it does not exist on server\n    else:\n      self._request(\n        'POST',\n        f'/api/blob/{digest}',\n        files={'file': open(path, 'rb')},\n      )\n\n    return digest\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    # Open the file\n    if isinstance(path, str):\n      path = Path(path)\n    if not path.exists():\n      raise RequestError(f'{path} does not exist')\n    if path.is_dir():\n      raise RequestError(f'{path} is a directory')\n    with path.open('rb') as f:\n      # Calculate the SHA-256 checksum\n      sha256_hash = sha256()\n      while chunk := f.read(4096):\n        sha256_hash.update(chunk)\n      digest = sha256_hash.hexdigest()\n\n      # Check if the blob already exists\n      r = self._client.head(f'/api/blob/{digest}')\n      if r.status_code == 200:\n        return f'sha256:{digest}'\n\n      # Upload the blob if it does not exist\n      r = self._client.post(f'/api/blob/{digest}', data=f.read())\n      if r.status_code != 201:\n        raise RequestError(f'could not upload {path}')\n\n    return f'sha256:{digest}'\n\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = Path(path).expanduser()\n    if not path.exists():\n      raise RequestError(f'{path} does not exist')\n\n    sha256sum = sha256()\n    with open(path, 'rb') as f:\n      for chunk in iter(lambda: f.read(4096), b''):\n        sha256sum.update(chunk)\n    digest = sha256sum.hexdigest()\n    url = urllib.parse.urljoin(self._client.base_url, f'/blob/{digest}')\n    r = self._client.head(url)\n    if r.status_code == 200:\n      return f'sha256:{digest}'\n    elif r.status_code == 404:\n      self._client.post(url, files={'file': open(path, 'rb')})\n      return f'sha256:{digest}'\n    else:\n      raise RequestError(f'could not create blob: {r.status_code}')\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = Path(path)\n\n    if not path.exists():\n      raise RequestError(f'{path} does not exist')\n\n    if not path.is_file():\n      raise RequestError(f'{path} is not a file')\n\n    if not path.suffix:\n      raise RequestError(f'{path} does not have a file extension')\n\n    if not path.suffix[1:] in ['zip', 'tar', 'gz']:\n      raise RequestError(f'{path} must be a zip, tar, or gz file')\n\n    sha256_checksum = sha256()\n    with open(path, 'rb') as f:\n      for data in iter(lambda: f.read(io.DEFAULT_BUFFER_SIZE), b''):\n        sha256_checksum.update(data)\n    digest = sha256_checksum.hexdigest()\n\n    # check if blob already exists on server\n    response = self._client.head(f'/api/blob/{digest}')\n    if response.status_code == 200:\n      return digest\n\n    # upload blob to server\n    with open(path, 'rb') as f:\n      response = self._client.post(\n        f'/api/blob/{digest}',\n        data=f,\n      )\n\n    if response.status_code != 200:\n      raise ResponseError(response.text, response.status_code)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      async with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      async with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      async with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      async with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # The Pyright executable\n        pyright_executable = \"pyright\"\n\n        # The temporary file that will hold the combined user code and test code\n        with tempfile.NamedTemporaryFile(\n            mode=\"w\", encoding=\"utf-8\", suffix=\".py\", delete=False\n        ) as combined_file:\n            combined_file.write(user_code)\n            combined_file.write(\"\\n\")\n            combined_file.write(test_code)\n\n        # The temporary file that will hold the combined user code and test code\n        with tempfile.NamedTemporaryFile(\n            mode=\"w\", encoding=\"utf-8\", suffix=\".py\"\n        ) as combined_file:\n            combined_file.write(user_code)\n            combined_file.write(\"\\n\")\n            combined_file.write(test_code)\n\n            # The temporary file that will hold the combined user code and test code\n            with tempfile.NamedTemporaryFile(\n                mode=\"w\", encoding=\"utf-8\", suffix=\".py\"\n            ) as combined_file:\n                combined_file.write(user_code)\n                combined_file.write(\"\\n\")\n                combined_file.write(test_code)\n\n                # The temporary file that will hold the combined user code and test code\n                with tempfile.NamedTemporaryFile(\n                    mode=\"w\", encoding=\"utf-8\", suffix=\".py\"\n                ) as combined_file:\n                    combined_file.write(user_code)\n                    combined_file.write(\"\\n\")\n                    combined_file.write(test_code)\n\n                    # The temporary file that will hold the combined user code and test code\n                    with tempfile.NamedTemporaryFile(\n                        mode=\"w\", encoding=\"utf-8\", suffix=\".py\"\n                    ) as combined_file:\n                        combined_file.write(user_code)\n                        combined_file.write(\"\\n\")\n                        combined_file.write(test_code)\n\n                        # The temporary file that will hold the combined user code and test code\n                        with tempfile.NamedTemporaryFile("}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        with tempfile.NamedTemporaryFile(\n            mode=\"w\", suffix=\".py\", encoding=\"utf-8\", delete=False\n        ) as temp_file:\n            temp_file.write(user_code)\n            temp_file.write(\"\\n\")\n            temp_file.write(test_code)\n            temp_file.close()\n\n            # Run pyright on the temporary file\n            pyright_output = subprocess.run(\n                [\"pyright\", temp_file.name],\n                capture_output=True,\n                text=True,\n                check=False,\n            )\n\n            # Delete the temporary file\n            temp_file.close()\n            Path(temp_file.name).unlink()\n\n            # Parse the output to identify lines with expected type errors\n            expected_errors = cls._parse_pyright_output(pyright_output.stdout)\n\n            # Parse the output to identify lines with unexpected type errors\n            unexpected_errors = cls._parse_pyright_output(pyright_output.stderr)\n\n            # Parse the output to identify lines with warnings\n            warnings = cls._parse_pyright_output(pyright_output.stdout)\n\n            # Parse the output to identify lines with information\n            information = cls._parse_pyright_output(pyright_output.stdout)\n\n            # Create a dictionary of line numbers to the corresponding error messages\n            expected_errors_dict = {\n                int(line_no): error_message\n                for line_no, error_message in expected_errors\n            }\n\n            # Create a dictionary of line numbers to the corresponding error messages\n            unexpected_errors_dict = {\n                int(line_no): error_message\n                for line_no, error_message in unexpected_errors\n            }\n\n            # Create a dictionary of line numbers to the corresponding error messages\n            warnings_dict = {\n                int(line_no): error_message for line_no, error_message in warnings\n            }\n\n            # Create a dictionary of line numbers to the corresponding error messages\n            information_dict = {\n                int(line_no): error_message for line_no, error_"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create a temporary file to store the user-provided code.\n        with tempfile.NamedTemporaryFile(\n            mode=\"w\", suffix=\".py\", encoding=\"utf-8\", delete=False\n        ) as temp_file:\n            temp_file.write(user_code)\n\n        # Create a temporary file to store the test code.\n        with tempfile.NamedTemporaryFile(\n            mode=\"w\", suffix=\".py\", encoding=\"utf-8\", delete=False\n        ) as test_file:\n            test_file.write(test_code)\n\n        # Run Pyright on the temporary file.\n        proc = subprocess.run(\n            [\"pyright\", temp_file.name, \"--python\", test_file.name],\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            universal_newlines=True,\n        )\n\n        # Remove temporary files.\n        temp_file.close()\n        Path(temp_file.name).unlink()\n        test_file.close()\n        Path(test_file.name).unlink()\n\n        # Extract the line numbers of the expected type errors from the Pyright output.\n        expected_error_lines = set()\n        for line in proc.stdout.splitlines():\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                line_no = int(match.group(1))\n                if match.group(2).startswith(cls.EXPECT_ERROR_COMMENT):\n                    expected_error_lines.add(line_no)\n\n        # Extract the line numbers of the actual type errors from the Pyright output.\n        actual_error_lines = set()\n        for line in proc.stderr.splitlines():\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                line_no = int(match.group(1))\n                actual_error_lines.add(line_no)\n\n        # Determine if the type check passed.\n        passed ="}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        with tempfile.TemporaryDirectory() as tmp_dir:\n            tmp_dir_path = Path(tmp_dir)\n            user_code_file = tmp_dir_path / \"user_code.py\"\n            test_code_file = tmp_dir_path / \"test_code.py\"\n\n            user_code_file.write_text(user_code, encoding=\"utf-8\")\n            test_code_file.write_text(test_code, encoding=\"utf-8\")\n\n            # Run pyright on the combined code\n            proc = subprocess.run(\n                [\"pyright\", \"--outputjson\", str(user_code_file), str(test_code_file)],\n                cwd=tmp_dir_path,\n                capture_output=True,\n                text=True,\n            )\n\n            # Parse the output of pyright to identify lines with expected type errors\n            expected_error_lines = set()\n            for line in proc.stderr.splitlines():\n                match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n                if match:\n                    line_no = int(match.group(1))\n                    message = match.group(2)\n                    if message.startswith(cls.EXPECT_ERROR_COMMENT):\n                        expected_error_lines.add(line_no)\n\n            # Parse the output of pyright to identify lines with unexpected type errors\n            unexpected_error_lines = set()\n            for line in proc.stdout.splitlines():\n                match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n                if match:\n                    line_no = int(match.group(1))\n                    message = match.group(2)\n                    if message.startswith(\"error\") and line_no not in expected_error_lines:\n                        unexpected_error_lines.add(line_no)\n\n            # Construct the result of the type check\n            passed = not unexpected_error_lines\n            message = f\"{len(unexpected_error_lines)} unexpected type errors found on lines"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create temporary files to store the user-provided code and test code\n        with tempfile.NamedTemporaryFile(\n            mode=\"w\", suffix=\".py\", encoding=\"utf-8\", delete=False\n        ) as user_code_file, tempfile.NamedTemporaryFile(\n            mode=\"w\", suffix=\".py\", encoding=\"utf-8\", delete=False\n        ) as test_code_file:\n            user_code_filename = user_code_file.name\n            test_code_filename = test_code_file.name\n            user_code_file.write(user_code)\n            test_code_file.write(test_code)\n\n        # Run Pyright to perform type checking on the combined user-provided code and test code\n        try:\n            pyright_output = subprocess.run(\n                [\"pyright\", user_code_filename, test_code_filename],\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE,\n                check=True,\n                encoding=\"utf-8\",\n            )\n        except subprocess.CalledProcessError as e:\n            return TypeCheckResult(\n                message=f\"Pyright failed with exit code {e.returncode}\",\n                passed=False,\n            )\n\n        # Parse Pyright's output to identify lines with expected type errors\n        expected_error_lines = set()\n        for line in pyright_output.stdout.splitlines():\n            if cls.EXPECT_ERROR_COMMENT in line:\n                match = re.search(cls.PYRIGHT_MESSAGE_REGEX, line)\n                if match:\n                    expected_error_lines.add(int(match.group(1)))\n\n        # Parse Pyright's output to identify lines with actual type errors\n        actual_error_lines = set()\n        for line in pyright_output.stderr.splitlines():\n            match = re.search(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                actual_error_lines.add(int(match.group(1)))\n\n        # Create a"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create a temporary file to store the user code\n        user_code_file = tempfile.NamedTemporaryFile(\n            mode=\"w\", suffix=\".py\", delete=False\n        )\n        user_code_file.write(user_code)\n        user_code_file.close()\n\n        # Create a temporary file to store the test code\n        test_code_file = tempfile.NamedTemporaryFile(\n            mode=\"w\", suffix=\".py\", delete=False\n        )\n        test_code_file.write(test_code)\n        test_code_file.close()\n\n        # Create a temporary file to store the combined code\n        combined_code_file = tempfile.NamedTemporaryFile(\n            mode=\"w\", suffix=\".py\", delete=False\n        )\n        combined_code_file.write(user_code)\n        combined_code_file.write(\"\\n\")\n        combined_code_file.write(test_code)\n        combined_code_file.close()\n\n        # Run pyright on the combined code\n        # Note: We need to run pyright in a subprocess to avoid the issue described in https://github.com/microsoft/pyright/issues/1383\n        result = subprocess.run(\n            [\"pyright\", combined_code_file.name],\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n        )\n\n        # Clean up the temporary files\n        user_code_file.close()\n        test_code_file.close()\n        combined_code_file.close()\n        Path(user_code_file.name).unlink()\n        Path(test_code_file.name).unlink()\n        Path(combined_code_file.name).unlink()\n\n        # Extract the error messages from the output\n        messages = []\n        for line in result.stderr.decode(\"utf-8\").splitlines():\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                line_no = int(match.group(1))\n                message"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create temporary files for user code and test code\n        with tempfile.TemporaryDirectory() as temp_dir:\n            user_code_file = Path(temp_dir) / \"user_code.py\"\n            test_code_file = Path(temp_dir) / \"test_code.py\"\n            user_code_file.write_text(user_code, encoding=\"utf-8\")\n            test_code_file.write_text(test_code, encoding=\"utf-8\")\n\n            # Run pyright on the combined code\n            process = subprocess.run(\n                [\"pyright\", \"--outputjson\", str(user_code_file), str(test_code_file)],\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE,\n                encoding=\"utf-8\",\n            )\n\n            # Extract the relevant error messages\n            errors = []\n            for line in process.stderr.splitlines():\n                match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n                if match:\n                    line_no, message = match.groups()\n                    if message.startswith(cls.EXPECT_ERROR_COMMENT):\n                        continue\n                    errors.append(f\"Line {line_no}: {message}\")\n\n            # Return the result\n            return TypeCheckResult(\n                message=\"\\n\".join(errors),\n                passed=not errors,\n                debug_info={\n                    \"user_code\": user_code,\n                    \"test_code\": test_code,\n                    \"stdout\": process.stdout,\n                    \"stderr\": process.stderr,\n                },\n            )\n\n"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create a temporary file to store the user code and test code\n        with tempfile.NamedTemporaryFile(mode=\"w+\", encoding=\"utf-8\") as temp_file:\n            # Write the user code and test code to the temporary file\n            temp_file.write(user_code)\n            temp_file.write(test_code)\n            temp_file.flush()\n\n            # Run pyright on the temporary file\n            result = subprocess.run(\n                [\"pyright\", temp_file.name],\n                capture_output=True,\n                encoding=\"utf-8\",\n            )\n\n            # Extract the line numbers of the lines with expected type errors\n            expected_error_lines = set(\n                map(\n                    int,\n                    re.findall(\n                        cls.PYRIGHT_MESSAGE_REGEX,\n                        result.stderr,\n                    ),\n                )\n            )\n\n            # Extract the line numbers of the lines with actual type errors\n            actual_error_lines = set(\n                map(\n                    int,\n                    re.findall(\n                        cls.PYRIGHT_MESSAGE_REGEX,\n                        result.stdout,\n                    ),\n                )\n            )\n\n            # Extract the line numbers of the lines with actual type errors that are not expected\n            unexpected_error_lines = actual_error_lines - expected_error_lines\n\n            # Extract the line numbers of the lines with expected type errors that are not found\n            missing_error_lines = expected_error_lines - actual_error_lines\n\n            # Create a list of error messages\n            error_messages = []\n\n            # Iterate over the lines with expected type errors that are not found\n            for line_number in missing_error_lines:\n                error_messages.append(\n                    f\"Expected an error on line {line_number}, but no error was found.\"\n                )\n\n            # Iterate over the lines with expected type errors that are not found\n            for line_number in unexpected_error_lines:\n                error_messages.append(\n                    f\"Found"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create a temporary file to store the combined code for type checking\n        with tempfile.NamedTemporaryFile(\n            mode=\"w\", suffix=\".py\", encoding=\"utf-8\", delete=False\n        ) as f:\n            f.write(user_code)\n            f.write(\"\\n\")\n            f.write(test_code)\n\n        # Run Pyright on the temporary file\n        proc = subprocess.run(\n            [\"pyright\", f.name],\n            capture_output=True,\n            text=True,\n            encoding=\"utf-8\",\n        )\n\n        # If there is no output, the type check passed\n        if proc.stdout == \"\":\n            return TypeCheckResult(\n                message=\"Passed\",\n                passed=True,\n            )\n\n        # Parse the output to find the lines with expected type errors\n        lines = proc.stdout.splitlines()\n        expected_errors = []\n        for line in lines:\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                line_no = int(match.group(1))\n                message = match.group(2)\n                if message.startswith(cls.EXPECT_ERROR_COMMENT):\n                    expected_errors.append((line_no, message[len(cls.EXPECT_ERROR_COMMENT) + 1 :]))\n\n        # If there are no expected type errors, the type check failed\n        if len(expected_errors) == 0:\n            return TypeCheckResult(\n                message=\"\\n\".join(lines),\n                passed=False,\n            )\n\n        # If there are expected type errors, the type check passed\n        if len(expected_errors) == len(\n            [\n                line_no\n                for line_no, _ in expected_errors\n                if line_no <= len(user_code.splitlines())\n            ]\n        ):\n            return TypeCheckResult(\n                message=\"Passed\",\n                passed=True,\n            )\n\n        # If there are expected type errors but not all of them are found, the type check failed"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Write the user code to a temporary file\n        with tempfile.NamedTemporaryFile(\"w+\", suffix=\".py\") as user_code_file:\n            user_code_file.write(user_code)\n            user_code_file.seek(0)\n\n            # Write the test code to a temporary file\n            with tempfile.NamedTemporaryFile(\"w+\", suffix=\".py\") as test_code_file:\n                test_code_file.write(test_code)\n                test_code_file.seek(0)\n\n                # Run Pyright on the user code and test code\n                result = subprocess.run(\n                    [\"pyright\", user_code_file.name, test_code_file.name],\n                    stdout=subprocess.PIPE,\n                    stderr=subprocess.PIPE,\n                )\n\n                # Parse the output\n                error_lines = []\n                for line in result.stderr.decode(\"utf-8\").splitlines():\n                    match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n                    if match:\n                        line_no, error_message = match.groups()\n                        error_lines.append(\n                            {\n                                \"line_no\": int(line_no),\n                                \"error_message\": error_message,\n                            }\n                        )\n\n                # Identify lines with expected type errors\n                expected_error_lines = [\n                    line\n                    for line in error_lines\n                    if cls.EXPECT_ERROR_COMMENT in line[\"error_message\"]\n                ]\n\n                # If there are no expected errors, check if there are any errors at all\n                if not expected_error_lines:\n                    if error_lines:\n                        return TypeCheckResult(\n                            message=\"There was a type error in your code.\",\n                            passed=False,\n                        )\n                    else:\n                        return TypeCheckResult(\n                            message=\"Your code passed the type check.\",\n                            passed=True,\n                        )\n\n                # Otherwise, check"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create a temporary file to store the user code.\n        with tempfile.NamedTemporaryFile(\n            mode=\"w\", suffix=\".py\", encoding=\"utf-8\", delete=False\n        ) as tmp_file:\n            tmp_file.write(user_code)\n            tmp_file.write(\"\\n\")\n            tmp_file.write(test_code)\n\n        # Run Pyright on the user code.\n        proc = subprocess.run(\n            [\"pyright\", tmp_file.name],\n            capture_output=True,\n            text=True,\n            check=False,\n        )\n\n        # Read the output of the type check.\n        output = proc.stdout\n\n        # Clean up the temporary file.\n        tmp_file.close()\n        Path(tmp_file.name).unlink()\n\n        # If the type check passed, return a success message.\n        if proc.returncode == 0:\n            return TypeCheckResult(message=\"Type check passed\", passed=True)\n\n        # Otherwise, read the output and identify lines with expected type errors.\n        error_lines = []\n        for line in output.splitlines():\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                line_no = int(match.group(1))\n                message = match.group(2)\n                if cls.EXPECT_ERROR_COMMENT in message:\n                    error_lines.append(line_no)\n\n        # Return a failure message and the error lines.\n        return TypeCheckResult(\n            message=\"Type check failed on line(s) \"\n            + \", \".join(map(str, error_lines)),\n            passed=False,\n            debug_info={\"error_lines\": error_lines},\n        )"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create a temporary file to store the user code\n        with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\") as user_code_file:\n            user_code_file.write(user_code)\n            user_code_file.flush()\n\n            # Create a temporary file to store the test code\n            with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\") as test_code_file:\n                test_code_file.write(test_code)\n                test_code_file.flush()\n\n                # Create a temporary file to store the combined code\n                with tempfile.NamedTemporaryFile(\n                    mode=\"w\", suffix=\".py\"\n                ) as combined_code_file:\n                    combined_code_file.write(user_code)\n                    combined_code_file.write(\"\\n\")\n                    combined_code_file.write(test_code)\n                    combined_code_file.flush()\n\n                    # Run Pyright to check the combined code\n                    pyright_process = subprocess.run(\n                        [\"pyright\", \"--outputjson\", combined_code_file.name],\n                        stdout=subprocess.PIPE,\n                        stderr=subprocess.PIPE,\n                        encoding=\"utf-8\",\n                    )\n\n                    # Check if the process succeeded\n                    if pyright_process.returncode != 0:\n                        # If the process failed, return the error message\n                        return TypeCheckResult(\n                            message=pyright_process.stderr,\n                            passed=False,\n                            debug_info={\"pyright_process\": pyright_process},\n                        )\n\n                    # If the process succeeded, parse the output\n                    output = pyright_process.stdout\n                    error_messages = []\n                    expected_error_lines = set()\n                    for line in output.splitlines():\n                        # If the line is a comment with the expected error comment, add the line number to the set of expected error lines\n                        if line.strip().startswith(cls.EXPECT_ERROR_COMMENT"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Write the user code and test code to temporary files\n        with tempfile.TemporaryDirectory() as tmpdir:\n            user_code_file = Path(tmpdir) / \"user.py\"\n            test_code_file = Path(tmpdir) / \"test.py\"\n            user_code_file.write_text(user_code, encoding=\"utf-8\")\n            test_code_file.write_text(test_code, encoding=\"utf-8\")\n\n            # Run Pyright on the user code\n            proc = subprocess.run(\n                [\"pyright\", \"--outputjson\", user_code_file],\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE,\n                text=True,\n            )\n\n            # Parse the JSON output from Pyright\n            pyright_output = proc.stdout\n            pyright_errors = json.loads(pyright_output)\n\n            # Parse the error messages from the JSON output\n            error_messages = []\n            for error in pyright_errors:\n                if error[\"message\"] != \"No problems found.\":\n                    error_messages.append(error[\"message\"])\n\n            # Check if any lines in the user code contain the \"expect-type-error\" comment\n            expect_error_lines = [\n                line\n                for line in user_code.splitlines()\n                if cls.EXPECT_ERROR_COMMENT in line\n            ]\n\n            # Check if the expected error messages match the actual error messages\n            passed = set(error_messages) == set(expect_error_lines)\n\n            return TypeCheckResult(\n                message=\"\\n\".join(error_messages),\n                passed=passed,\n                debug_info={\"user_code\": user_code, \"test_code\": test_code},\n            )\n\n"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Write the user code and test code to a temporary file\n        with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\") as temp_file:\n            temp_file.write(user_code)\n            temp_file.write(\"\\n\")\n            temp_file.write(test_code)\n            temp_file.seek(0)\n\n            # Run Pyright on the temporary file\n            result = subprocess.run(\n                [\"pyright\", temp_file.name],\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE,\n                text=True,\n            )\n\n            # Extract the lines with expected errors\n            expected_errors = cls._extract_expected_errors(user_code, test_code)\n\n            # Parse the Pyright output\n            parsed_errors = cls._parse_pyright_output(result.stdout)\n\n            # Build the message\n            message = cls._build_message(parsed_errors, expected_errors)\n\n            # Build the result\n            passed = message == \"\"\n            return TypeCheckResult(message, passed)\n"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        with tempfile.NamedTemporaryFile(\n            mode=\"w\", suffix=\".py\", encoding=\"utf-8\", delete=False\n        ) as f:\n            f.write(user_code)\n            f.write(\"\\n\")\n            f.write(test_code)\n\n        # Run pyright on the temporary file.\n        # We use the --outputjson option to get the error messages in JSON format.\n        # We also use the --ignoreexternal to ignore errors from files outside the temporary folder.\n        # We use the --pythonversion option to set the Python version to 3.8 so that the type checker can parse the code correctly.\n        # We use the --usepyrightconfig to ignore the pyrightconfig file in the root directory.\n        # We use the --verbosity:1 option to suppress all debug messages.\n        # We use the --settings: --checkVariadicTuples=true to enable support for variadic tuples.\n        # We use the --settings: --checkUnreachableCode=false to disable support for unreachable code.\n        # We use the --settings: --checkImplicitReturn=false to disable support for implicit return.\n        # We use the --settings: --checkWideString=false to disable support for wide strings.\n        # We use the --settings: --checkUnusedIgnore=false to disable support for unused ignore.\n        # We use the --settings: --checkUnnecessaryCast=false to disable support for unnecessary cast.\n        # We use the --settings: --checkUnnecessaryComparison=false to disable support for unnecessary comparison.\n        # We use the --settings: --checkUnnecessaryParentheses=false to disable support for unnecessary parentheses.\n        # We use the --settings: --checkUnnecessaryStringCast=false to disable support for unnecessary string cast.\n        # We use the --settings: --checkUnnecessaryThrow=false to disable support for unnecessary throw.\n        # We use the --settings: --checkUnnecessaryWait=false to disable support for unnecessary wait.\n        # We use the --settings: --checkUnnecessaryYield=false to disable support for unnecessary yield.\n        # We use the --settings: --check"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Write user code to a temporary file for Pyright to type check.\n        with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as f:\n            f.write(user_code)\n            user_code_path = Path(f.name)\n\n        # Write test code to a temporary file for Pyright to type check.\n        with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as f:\n            f.write(test_code)\n            test_code_path = Path(f.name)\n\n        # Run Pyright on the user code.\n        # The --output json option is used to make Pyright output a JSON-formatted result.\n        # The --python-version option is used to set the Python version to 3.9, as that is the version used in the course.\n        # The --ignore-missing-imports option is used to suppress the error message that occurs when Pyright fails to find the test code.\n        # The --pretty option is used to make Pyright output a human-readable result.\n        # The --outputFormat code-span option is used to make Pyright output error messages with line numbers and column numbers.\n        # The --settings python.analysis.useLibraryCodeForTypes option is used to make Pyright use the test code for type checking.\n        # The --settings python.analysis.useLibraryCodeForDiagnostics option is used to make Pyright use the test code for type checking.\n        # The --settings python.analysis.diagnosticRuleSet option is used to make Pyright use the test code for type checking.\n        # The --settings python.analysis.openFiles option is used to make Pyright use the test code for type checking.\n        # The --settings python.analysis.reportEvenUnusedCode option is used to make Pyright use the test code for type checking.\n        # The --settings python.analysis.reportMissingImports option is used to make Pyright use the test code for type checking.\n        # The --settings python.analysis.reportMissingOverloads option is used to make Pyright use the test code for type checking.\n        # The --settings python."}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Write the user code and test code to temporary files.\n        with tempfile.TemporaryDirectory() as tmpdirname:\n            user_code_path = Path(tmpdirname) / \"user_code.py\"\n            test_code_path = Path(tmpdirname) / \"test_code.py\"\n            with open(user_code_path, \"w\", encoding=\"utf-8\") as f:\n                f.write(user_code)\n            with open(test_code_path, \"w\", encoding=\"utf-8\") as f:\n                f.write(test_code)\n\n            # Run pyright on the user code and test code.\n            # Pyright returns a non-zero exit code if there are any errors, so we use this to determine if the type check passed.\n            # Pyright also prints out the errors to stdout, so we need to suppress this to avoid cluttering the output.\n            proc = subprocess.run(\n                [\"pyright\", \"--outputjson\", str(user_code_path)],\n                stdout=subprocess.PIPE,\n                stderr=subprocess.DEVNULL,\n            )\n            proc2 = subprocess.run(\n                [\"pyright\", \"--outputjson\", str(test_code_path)],\n                stdout=subprocess.PIPE,\n                stderr=subprocess.DEVNULL,\n            )\n\n            # Parse the output of the type checker.\n            # The type checker outputs errors in the form of a JSON object with the following format:\n            # {\n            #   \"type\": \"error\",\n            #   \"message\": <error message>,\n            #   \"range\": {\n            #     \"start\": {\n            #       \"line\": <line number>,\n            #       \"character\": <character number>\n            #     },\n            #     \"end\": {\n            #       \"line\": <line number>,\n            #       \"character\": <character number>\n            #     }\n            #   }\n            # }\n            # The start and end character numbers are used to identify the lines with errors.\n            # We need to parse the output to extract the line numbers and error messages"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # We use a temporary file to store the user code and test code,\n        # because the Pyright CLI only accepts file paths as input.\n        with tempfile.NamedTemporaryFile(\n            mode=\"w\", suffix=\".py\", encoding=\"utf-8\", delete=False\n        ) as temp_file:\n            temp_file.write(user_code)\n            temp_file.write(\"\\n\")\n            temp_file.write(test_code)\n\n        # We use subprocess.run() to run the Pyright CLI in a subprocess.\n        # We use the check=True argument to ensure that the subprocess returns an exit code of 0,\n        # which indicates that there were no errors.\n        # We use stdout=subprocess.PIPE to capture the output from the subprocess.\n        # We use stderr=subprocess.PIPE to capture the stderr from the subprocess.\n        # We use universal_newlines=True to ensure that the output is captured as a string.\n        # We use encoding=\"utf-8\" to ensure that the output is in utf-8 encoding.\n        # We use text=True to ensure that the output is captured as a string.\n        # We use errors=\"replace\" to ensure that the output is captured as a string.\n        # We use timeout=30 to ensure that the subprocess terminates in 30 seconds.\n        # We use cwd=temp_file.name to ensure that the subprocess runs in the same directory as the temporary file.\n        # We use shell=True to ensure that the subprocess runs in the same shell as the current process.\n        # We use capture_output=True to ensure that the output is captured as a string.\n        # We use check=True to ensure that the subprocess returns an exit code of 0.\n        # We use encoding=\"utf-8\" to ensure that the output is in utf-8 encoding.\n        # We use universal_newlines=True to ensure that the output is captured as a string.\n        # We use errors=\"replace\" to ensure that the output is captured as a string.\n        # We use timeout=30 to ensure that the subprocess terminates in 30 seconds.\n       "}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # We use a temporary file to store the user code and test code, because Pyright's CLI expects the input to be a file.\n        with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\") as tmp_file:\n            tmp_file.write(user_code)\n            tmp_file.write(\"\\n\")\n            tmp_file.write(test_code)\n            tmp_file.seek(0)\n\n            # Run Pyright on the combined code.\n            # We use subprocess to run Pyright, because the Pyright Python API does not support running Pyright on a file.\n            pyright_output = subprocess.run(\n                [\"pyright\", tmp_file.name],\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE,\n            )\n\n            # The Pyright output is a byte string, so we need to decode it to a string.\n            pyright_output_string = pyright_output.stdout.decode(\"utf-8\")\n\n            # The Pyright output is a byte string, so we need to decode it to a string.\n            pyright_error_string = pyright_output.stderr.decode(\"utf-8\")\n\n            # We want to ignore the first few lines of the output, because they contain information about the temporary file.\n            pyright_output_lines = pyright_output_string.splitlines()[4:]\n\n            # We want to ignore the first few lines of the output, because they contain information about the temporary file.\n            pyright_error_lines = pyright_error_string.splitlines()[4:]\n\n            # We use a list to store the lines with expected type errors.\n            expected_error_lines = []\n\n            # We use a list to store the lines with unexpected type errors.\n            unexpected_error_lines = []\n\n            # We use a list to store the lines with unexpected warnings.\n            unexpected_warning_lines = []\n\n            # We use a list to store the lines with unexpected information.\n            unexpected_information_lines = []\n\n            # We use a list to store the lines with expected warnings.\n            expected_warning_lines"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create a temporary file to hold the user code.\n        user_code_file = tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\")\n        user_code_file.write(user_code)\n        user_code_file.flush()\n\n        # Create a temporary file to hold the test code.\n        test_code_file = tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\")\n        test_code_file.write(test_code)\n        test_code_file.flush()\n\n        # Run Pyright on the user code and test code.\n        # Pyright is run on a single file, so we need to combine the code into a single file.\n        # The code is combined into a single file by appending the test code to the end of the user code.\n        # We also need to make sure that the test code is properly formatted.\n        # For example, the first line of the test code needs to be `if __name__ == \"__main__\":`\n        # If the test code is not properly formatted, Pyright will not run and will return an empty list of errors.\n        # This will cause the type check to fail, even though the user code is correct.\n        # To avoid this, we print a warning if the test code is not properly formatted.\n        # The test code is properly formatted if it contains a line with the string `if __name__ == \"__main__\":`\n        # The test code is not properly formatted if it does not contain this line.\n        test_code_is_properly_formatted = False\n        for line in test_code.splitlines():\n            if \"if __name__ == \" in line:\n                test_code_is_properly_formatted = True\n                break\n\n        if not test_code_is_properly_formatted:\n            print(\n                \"Warning: The test code is not properly formatted. \"\n                \"The test code needs to be properly formatted to ensure that Pyright runs. \"\n                \"The test code is not properly formatted if it does not contain a line with the string `if __name__ == \\\"__main__\\\":`. \"\n                \"The test"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(\"Forward pass:\"))\n    else:\n        return aot_function(fn, get_compiler_fn(\"Forward pass:\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn())\n    else:\n        return aot_function(fn, get_compiler_fn())"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn())\n    else:\n        return aot_function(fn, get_compiler_fn())"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(\"Forward Compiler\"))\n    else:\n        return aot_function(fn, get_compiler_fn(\"Forward Compiler\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn())\n    else:\n        return aot_function(fn, get_compiler_fn())"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(\"Forward Compiler\"))\n    else:\n        return aot_function(fn, get_compiler_fn(\"Forward Compiler\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(\"Forward pass\"))\n    else:\n        return aot_function(fn, get_compiler_fn(\"Forward pass\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(\"Forward pass\"))\n    else:\n        return aot_function(fn, get_compiler_fn(\"Forward pass\"))\n\n"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(title=\"Forward Compiler:\"))\n    else:\n        return aot_function(fn, get_compiler_fn(title=\"Forward Compiler:\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(\"FORWARD\"))\n    else:\n        return aot_function(fn, get_compiler_fn(\"FORWARD\"))\n\n"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(title=\"Module Compiler\"))\n    else:\n        return aot_function(fn, get_compiler_fn(title=\"Function Compiler\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(\"Forward Compiler:\"))\n    else:\n        return aot_function(fn, get_compiler_fn(\"Forward Compiler:\"))\n\n"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(\"Forward pass:\"))\n    else:\n        return aot_function(fn, get_compiler_fn(\"Forward pass:\"))\n\n"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    # If the input is a module, use aot_module to compile it.\n    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(\"forward\"), get_compiler_fn(\"backward\"))\n\n    # If the input is a function, use aot_function to compile it.\n    else:\n        return aot_function(fn, get_compiler_fn(\"forward\"), get_compiler_fn(\"backward\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    # If the input argument is a PyTorch neural network module, then use aot_module.\n    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(\"Forward pass:\"))\n\n    # If the input argument is a PyTorch function, then use aot_function.\n    return aot_function(fn, get_compiler_fn(\"Forward pass:\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(title=\"FORWARD COMPILER\"))\n    elif callable(fn):\n        return aot_function(fn, get_compiler_fn(title=\"FORWARD COMPILER\"))\n    else:\n        raise TypeError(\"The input argument must be a neural network module or a function.\")"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(\"Forward Compiler\"))\n    elif callable(fn):\n        return aot_function(fn, get_compiler_fn(\"Forward Compiler\"))\n    else:\n        raise TypeError(\n            \"The input argument to the aot_printer function must be either a torch.nn.Module or a callable function.\"\n        )"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn())\n    elif callable(fn):\n        return aot_function(fn, get_compiler_fn())\n    else:\n        raise ValueError(\"Argument fn must be a function or a torch.nn.Module\")"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(title=\"Module\"))\n    else:\n        return aot_function(fn, get_compiler_fn(title=\"Function\"))\n\n"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, get_compiler_fn(\"Forward pass:\"))\n    elif callable(fn):\n        return aot_function(fn, get_compiler_fn(\"Forward pass:\"))\n    else:\n        raise Exception(\"The input argument must be a PyTorch neural network module or a function.\")\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.load(open(os.path.join(trial_path, 'config.yaml')), Loader=yaml.FullLoader)\n    config_dict = summary_df_to_yaml(summary_df, config_dict)\n    if output_path is not None:\n        with open(output_path, 'w') as f:\n            yaml.dump(config_dict, f)\n    return config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = summary_df_to_yaml(summary_df, config_dict=yaml.safe_load(open(os.path.join(trial_path, 'config.yaml'))))\n\n    if output_path is not None:\n        with open(output_path, 'w') as f:\n            yaml.safe_dump(config_dict, f)\n\n    return config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = summary_df_to_yaml(summary_df, yaml.load(open(os.path.join(trial_path, 'config.yaml')), Loader=yaml.FullLoader))\n\n    if output_path is not None:\n        with open(output_path, 'w') as f:\n            yaml.dump(config_dict, f)\n\n    return config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    # Load the summary file\n    summary_df = load_summary_file(trial_path)\n\n    # Load the config file\n    config_dict = yaml.load(open(os.path.join(trial_path, 'config.yaml')), Loader=yaml.FullLoader)\n\n    # Convert the summary file to a dictionary\n    config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    # Save the dictionary to a YAML file if an output path is provided\n    if output_path:\n        with open(output_path, 'w') as f:\n            yaml.dump(config_dict, f)\n\n    return config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    # Load the summary file\n    summary_df = load_summary_file(trial_path)\n\n    # Load the configuration file\n    with open(os.path.join(trial_path, 'config.yaml')) as f:\n        config_dict = yaml.safe_load(f)\n\n    # Convert the summary file to the pipeline configuration\n    pipeline_config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    # Save the pipeline configuration to file if specified\n    if output_path is not None:\n        with open(output_path, 'w') as f:\n            yaml.safe_dump(pipeline_config_dict, f)\n\n    return pipeline_config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = summary_df_to_yaml(summary_df, yaml.load(open(os.path.join(trial_path, 'config.yaml')), Loader=yaml.FullLoader))\n\n    if output_path is not None:\n        with open(output_path, 'w') as f:\n            yaml.dump(config_dict, f)\n\n    return config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    # Check if trial_path is a valid directory\n    if not os.path.isdir(trial_path):\n        raise ValueError(f\"The trial directory {trial_path} does not exist.\")\n\n    # Check if trial_path contains a summary file\n    summary_path = os.path.join(trial_path, \"summary.csv\")\n    if not os.path.exists(summary_path):\n        raise ValueError(f\"The trial directory {trial_path} does not contain a summary.csv file.\")\n\n    # Check if output_path is a valid file\n    if output_path is not None:\n        if not os.path.isfile(output_path):\n            raise ValueError(f\"The output file {output_path} does not exist.\")\n\n        # Check if output_path has a valid file extension\n        if not output_path.endswith(\".yaml\") and not output_path.endswith(\".yml\"):\n            raise ValueError(f\"The output file {output_path} must have a .yaml or .yml file extension.\")\n\n    # Load the summary file\n    summary_df = load_summary_file(summary_path)\n\n    # Load the config file\n    config_path = os.path.join(trial_path, \"config.yaml\")\n    with open(config_path, \"r\") as f:\n        config_dict = yaml.load(f, Loader=yaml.FullLoader)\n\n    # Extract the best pipeline configuration\n    best_config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    # Save the best pipeline configuration to a file if specified\n    if output_path is not None:\n        with open(output_path, \"w\") as f:\n            yaml.dump(best_config_dict, f)\n\n    return best_config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    # Check if the trial directory exists\n    if not os.path.isdir(trial_path):\n        raise ValueError(f'The trial directory {trial_path} does not exist.')\n\n    # Check if the trial directory contains a summary file\n    summary_path = os.path.join(trial_path, 'summary.csv')\n    if not os.path.isfile(summary_path):\n        raise ValueError(f'The trial directory {trial_path} does not contain a summary.csv file.')\n\n    # Load the summary file\n    summary_df = load_summary_file(summary_path)\n\n    # Load the config file\n    config_path = os.path.join(trial_path, 'config.yaml')\n    with open(config_path, 'r') as f:\n        config_dict = yaml.load(f, Loader=yaml.FullLoader)\n\n    # Extract the optimal pipeline configuration\n    best_config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    # Save the optimal pipeline configuration to a YAML file\n    if output_path is not None:\n        with open(output_path, 'w') as f:\n            yaml.dump(best_config_dict, f)\n\n    return best_config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    # Load the summary file\n    summary_df = load_summary_file(trial_path)\n\n    # Extract the configuration from the summary file\n    config_dict = summary_df_to_yaml(summary_df, load_yaml(os.path.join(trial_path, 'config.yaml')))\n\n    # Save the configuration to a file if provided\n    if output_path is not None:\n        with open(output_path, 'w') as f:\n            yaml.dump(config_dict, f)\n\n    return config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    # Load the summary file\n    summary_df = load_summary_file(trial_path)\n\n    # Load the config file\n    with open(os.path.join(trial_path, 'config.yaml')) as f:\n        config_dict = yaml.safe_load(f)\n\n    # Convert the summary file to a config file\n    config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    # Save the config file if output_path is specified\n    if output_path is not None:\n        with open(output_path, 'w') as f:\n            yaml.dump(config_dict, f)\n\n    return config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    if not os.path.exists(trial_path):\n        raise FileNotFoundError(f'Trial directory does not exist: {trial_path}')\n    if output_path is not None and not output_path.endswith('.yml') and not output_path.endswith('.yaml'):\n        raise ValueError(f'Output path must end with .yml or .yaml: {output_path}')\n\n    summary_df = load_summary_file(trial_path)\n    config_dict = summary_df_to_yaml(summary_df, yaml.load(open(os.path.join(trial_path, 'config.yaml')), Loader=yaml.FullLoader))\n\n    if output_path is not None:\n        with open(output_path, 'w') as f:\n            yaml.dump(config_dict, f)\n\n    return config_dict\n\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    # load the summary file\n    summary_df = load_summary_file(trial_path)\n    # load the config file\n    with open(os.path.join(trial_path, 'config.yaml'), 'r') as f:\n        config_dict = yaml.load(f, Loader=yaml.Loader)\n    # convert the summary file to the config file\n    config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    # save the config file\n    if output_path is not None:\n        with open(output_path, 'w') as f:\n            yaml.dump(config_dict, f, Dumper=yaml.Dumper)\n\n    return config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.load(open(os.path.join(trial_path, 'config.yaml')))\n\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path is not None:\n        with open(output_path, 'w') as f:\n            yaml.dump(best_config, f)\n\n    return best_config\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    # Check if the trial directory exists\n    if not os.path.exists(trial_path):\n        raise FileNotFoundError(f\"The trial directory {trial_path} does not exist.\")\n\n    # Check if the trial directory contains a summary.csv file\n    summary_file = os.path.join(trial_path, \"summary.csv\")\n    if not os.path.exists(summary_file):\n        raise FileNotFoundError(f\"The trial directory {trial_path} does not contain a summary.csv file.\")\n\n    # Check if the trial directory contains a config.yaml file\n    config_file = os.path.join(trial_path, \"config.yaml\")\n    if not os.path.exists(config_file):\n        raise FileNotFoundError(f\"The trial directory {trial_path} does not contain a config.yaml file.\")\n\n    # Load the summary file\n    summary_df = load_summary_file(summary_file)\n\n    # Load the config file\n    with open(config_file, \"r\") as f:\n        config_dict = yaml.safe_load(f)\n\n    # Extract the best config from the summary file\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    # Save the best config to a YAML file if specified\n    if output_path is not None:\n        if not output_path.endswith(\".yaml\") and not output_path.endswith(\".yml\"):\n            raise ValueError(f\"The output file path must have the extension .yaml or .yml.\")\n        with open(output_path, \"w\") as f:\n            yaml.safe_dump(best_config, f)\n\n    return best_config\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = summary_df_to_yaml(summary_df, load_yaml_file(os.path.join(trial_path, \"config.yaml\")))\n\n    if output_path is not None:\n        with open(output_path, 'w') as f:\n            yaml.dump(config_dict, f, default_flow_style=False)\n\n    return config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    # load summary file\n    summary_df = load_summary_file(trial_path)\n\n    # load config file\n    config_dict = yaml.load(open(os.path.join(trial_path, 'config.yaml'), 'r'), Loader=yaml.FullLoader)\n\n    # extract best config\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    # save to file\n    if output_path is not None:\n        with open(output_path, 'w') as f:\n            yaml.dump(best_config, f)\n\n    return best_config\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    # Load summary file\n    summary_df = load_summary_file(trial_path)\n    # Extract the optimal pipeline configuration from the summary file\n    best_config = summary_df_to_yaml(summary_df, load_yaml(os.path.join(trial_path, 'config.yaml')))\n    # Save the extracted optimal pipeline configuration to a YAML file if the output path is provided\n    if output_path is not None:\n        with open(output_path, 'w') as f:\n            yaml.dump(best_config, f)\n    # Return the extracted optimal pipeline configuration\n    return best_config\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    # load summary file\n    summary_df = load_summary_file(trial_path)\n    # load config file\n    config_dict = yaml.load(open(os.path.join(trial_path, 'config.yaml'), 'r'), Loader=yaml.FullLoader)\n\n    # extract best config\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    # save to file if output_path is not None\n    if output_path is not None:\n        with open(output_path, 'w') as f:\n            yaml.dump(best_config, f)\n\n    return best_config\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    if not os.path.isdir(trial_path):\n        raise ValueError(f'{trial_path} is not a valid directory.')\n\n    if output_path is not None and not output_path.endswith('.yaml') and not output_path.endswith('.yml'):\n        raise ValueError('The output file extension must be .yaml or .yml.')\n\n    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.load(open(os.path.join(trial_path, 'config.yaml')), Loader=yaml.FullLoader)\n\n    best_config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path is not None:\n        with open(output_path, 'w') as f:\n            yaml.dump(best_config_dict, f, default_flow_style=False)\n\n    return best_config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.load(open(os.path.join(trial_path, 'config.yaml'), 'r'), Loader=yaml.SafeLoader)\n    best_config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path is not None:\n        with open(output_path, 'w') as f:\n            yaml.dump(best_config_dict, f)\n\n    return best_config_dict\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    def wrapper(*args, **kwargs):\n        if not hasattr(wrapper, '_lock'):\n            wrapper._lock = threading.Lock()\n        with wrapper._lock:\n            if not hasattr(wrapper, '_cache'):\n                wrapper._cache = {}\n            if args not in wrapper._cache:\n                traced_module = better_trace(func, args, **kwargs_)\n                if ts_compiler is not None:\n                    traced_module = ts_compiler(traced_module)\n                wrapper._cache[args] = traced_module\n            return wrapper._cache[args]\n\n    return wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    def _lazy_trace(func, *args, **kwargs):\n        # Get the traced module from the cache if it exists\n        if func in _lazy_trace.cache:\n            traced_module = _lazy_trace.cache[func]\n        else:\n            # Trace the function or module's forward method\n            traced_module = better_trace(func, *args, **kwargs)\n            # Compile the traced module if a compiler function is provided\n            if ts_compiler is not None:\n                traced_module = ts_compiler(traced_module)\n            # Cache the traced module for future calls\n            _lazy_trace.cache[func] = traced_module\n        # Return the traced module\n        return traced_module\n\n    # Initialize the cache\n    _lazy_trace.cache = {}\n    # Return the wrapped function\n    return _lazy_trace\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    if isinstance(func, torch.nn.Module):\n        return lazy_trace_module(func, ts_compiler=ts_compiler, **kwargs_)\n    elif inspect.isfunction(func):\n        return lazy_trace_function(func, ts_compiler=ts_compiler, **kwargs_)\n    else:\n        raise ValueError(\n            'The function or module to be traced must be either a function or a torch.nn.Module.'\n        )\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    # Define a lock to ensure thread safety\n    lock = threading.Lock()\n\n    # Define a wrapper function that uses the lock\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n\n        # Acquire the lock\n        with lock:\n\n            # If the function is a module, use its forward method\n            if isinstance(func, torch.nn.Module):\n                func = func.forward\n\n            # If the function is in the cache, return the cached version\n            if (func, args, tuple(sorted(kwargs.items()))) in wrapper.cache:\n                return wrapper.cache[(func, args, tuple(sorted(kwargs.items())))]\n\n            # Otherwise, trace the function and cache the result\n            else:\n                traced_module = better_trace(func,\n                                             (tree_copy(args, detach=True),\n                                              tree_copy(kwargs, detach=True)),\n                                             **kwargs_)\n                if ts_compiler is not None:\n                    traced_module = ts_compiler(traced_module)\n                wrapper.cache[(func, args, tuple(sorted(kwargs.items())))] = traced_module\n                return traced_module\n\n    # Initialize the cache\n    wrapper.cache = {}\n\n    return wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    def traced_func(*args, **kwargs):\n        nonlocal traced_modules_cache\n        nonlocal traced_modules_lock\n        traced_modules_lock.acquire()\n        try:\n            traced_module = traced_modules_cache.get(\n                (args, tuple(sorted(kwargs.items())), ts_compiler, kwargs_),\n                None)\n            if traced_module is None:\n                traced_module = ts_compiler(\n                    better_trace(func, args, **kwargs_), **kwargs_)\n                traced_modules_cache[(args, tuple(\n                    sorted(kwargs.items())), ts_compiler, kwargs_)] = traced_module\n            return traced_module\n        finally:\n            traced_modules_lock.release()\n\n    traced_modules_cache = {}\n    traced_modules_lock = threading.Lock()\n    return traced_func\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    if isinstance(func, torch.nn.Module):\n        return lazy_trace_module(func, ts_compiler=ts_compiler, **kwargs_)\n    elif callable(func):\n        return lazy_trace_function(func, ts_compiler=ts_compiler, **kwargs_)\n    else:\n        raise TypeError(\n            f'lazy_trace can only be used with functions or modules, got {type(func)}'\n        )\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    # Check if the function is a module or a function\n    if isinstance(func, torch.nn.Module):\n        if isinstance(func, torch.jit.ScriptModule):\n            return func\n        else:\n            return lazy_trace_module(func, ts_compiler=ts_compiler, **kwargs_)\n    else:\n        return lazy_trace_function(func, ts_compiler=ts_compiler, **kwargs_)\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    if isinstance(func, torch.nn.Module):\n        func = func.forward\n\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        key = (args, tuple(sorted(kwargs.items())))\n        traced_func = None\n        with wrapper.lock:\n            if key not in wrapper.cache:\n                traced_func = better_trace(func, args, **kwargs_)\n                wrapper.cache[key] = ts_compiler(traced_func) if ts_compiler else traced_func\n            else:\n                traced_func = wrapper.cache[key]\n        return traced_func(*args, **kwargs)\n\n    wrapper.cache = {}\n    wrapper.lock = threading.Lock()\n\n    return wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    # Check if the function is a module\n    if isinstance(func, torch.nn.Module):\n        # If it is, then we need to wrap the forward method\n        func = TraceableModuleWrapper(func, ts_compiler=ts_compiler,\n                                      **kwargs_)\n    else:\n        # Otherwise, we need to wrap the function\n        func = TraceableFunctionWrapper(func, ts_compiler=ts_compiler,\n                                        **kwargs_)\n\n    return func\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    def tracer(func, ts_compiler, kwargs_, *args, **kwargs):\n        if ts_compiler is None:\n            ts_compiler = lambda m: m\n        key = (func, tuple(args), tuple(kwargs.items()))\n        with lazy_trace.lock:\n            if key in lazy_trace.cache:\n                return ts_compiler(lazy_trace.cache[key])\n        traced_func = better_trace(func, *args, **kwargs, **kwargs_)\n        traced_func = ts_compiler(traced_func)\n        with lazy_trace.lock:\n            lazy_trace.cache[key] = traced_func\n        return traced_func\n\n    if isinstance(func, torch.nn.Module):\n        traced_func = tracer(func.forward, ts_compiler, kwargs_, *args, **kwargs)\n        return TracedModuleWrapper(traced_func, func)\n    else:\n        return functools.partial(tracer, func, ts_compiler, kwargs_)\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    # This function is used to wrap the forward method of a module\n    def wrapper(module, *args, **kwargs):\n        # Lock to ensure thread safety\n        with lock:\n            # If the module is in the cache, return it\n            if module in cache:\n                return cache[module]\n            # Otherwise, trace the module and update the cache\n            else:\n                # Trace the module\n                traced_module = better_trace(module, args, **kwargs_)\n                # If a compiler is provided, compile the traced module\n                if ts_compiler is not None:\n                    traced_module = ts_compiler(traced_module)\n                # Update the cache\n                cache[module] = traced_module\n                # Return the traced module\n                return traced_module\n\n    # This function is used to wrap the function\n    def wrapper_func(func, *args, **kwargs):\n        # Lock to ensure thread safety\n        with lock:\n            # If the function is in the cache, return it\n            if func in cache:\n                return cache[func]\n            # Otherwise, trace the function and update the cache\n            else:\n                # Trace the function\n                traced_func = better_trace(func, args, **kwargs_)\n                # If a compiler is provided, compile the traced function\n                if ts_compiler is not None:\n                    traced_func = ts_compiler(traced_func)\n                # Update the cache\n                cache[func] = traced_func\n                # Return the traced function\n                return traced_func\n\n    # If the function is a module, wrap the forward method\n    if isinstance(func, torch.nn.Module):\n        lock = threading.Lock()\n        cache = {}\n        return apply_to_all_modules(func, wrapper)\n    # Otherwise, wrap the function\n    else:\n        lock = threading.Lock()\n        cache = {}\n        return wrapper_func(func)\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    # Wrap the function or module's forward method with a lock to ensure thread safety.\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        with wrapper._lock:\n            # Get the traced module from the cache if it exists.\n            if wrapper._traced_module is not None:\n                traced_module = wrapper._traced_module\n            else:\n                # If the traced module does not exist, trace the function or module's forward method.\n                traced_module = better_trace(\n                    TraceableModuleWrapper(func),\n                    flat_tensors.flattern((tree_copy(args, detach=True),\n                                           tree_copy(kwargs, detach=True))),\n                    **kwargs_)\n                # If a compiler function is provided, use it to process the traced module.\n                if ts_compiler is not None:\n                    traced_module = ts_compiler(traced_module)\n                # Update the cache with the traced module.\n                wrapper._traced_module = traced_module\n            return traced_module(*args, **kwargs)\n\n    # Create a lock to ensure thread safety.\n    wrapper._lock = threading.Lock()\n    wrapper._traced_module = None\n    return wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    # Check if the function is a module or a function\n    if isinstance(func, torch.nn.Module):\n        # Use the function's forward method\n        func = func.forward\n\n    # Define the decorator\n    def decorator(func):\n\n        # Define the wrapper function\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n\n            # Check if the traced module is already in the cache\n            with wrapper._lock:\n                if wrapper._traced_module is None:\n\n                    # Trace the function\n                    traced_module = better_trace(func,\n                                                 flat_tensors.flattern(\n                                                     (tree_copy(args,\n                                                               detach=True),\n                                                      tree_copy(kwargs,\n                                                               detach=True))),\n                                                 **kwargs_)\n\n                    # Apply any compiler enhancements\n                    if ts_compiler is not None:\n                        traced_module = ts_compiler(traced_module)\n\n                    # Update the cache\n                    wrapper._traced_module = traced_module\n\n                # Return the traced module\n                return wrapper._traced_module\n\n        # Initialize the cache\n        wrapper._traced_module = None\n\n        # Initialize the lock\n        wrapper._lock = threading.Lock()\n\n        # Return the wrapper function\n        return wrapper\n\n    # Return the decorator\n    return decorator\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    if ts_compiler is None:\n        ts_compiler = lambda x: x\n\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n\n        # Get the function name.\n        func_name = func.__name__ if isinstance(func,\n                                                type) else func.__qualname__\n\n        # Get the signature of the function.\n        args_spec = inspect.getfullargspec(func)\n\n        # Get the name of the first positional argument.\n        pos_arg_name = args_spec.args[0] if args_spec.args else None\n\n        # Get the name of the first positional argument.\n        kwarg_arg_name = args_spec.varkw if args_spec.varkw else None\n\n        # Get the positional arguments.\n        pos_args = args[1:] if pos_arg_name else args\n\n        # Get the keyword arguments.\n        kwarg_args = kwargs\n\n        # Get the keyword arguments.\n        kwargs_ = kwargs_ if kwarg_arg_name else {}\n\n        # Get the positional arguments.\n        pos_args = args[1:] if pos_arg_name else args\n\n        # Get the keyword arguments.\n        kwarg_args = kwargs if kwarg_arg_name else {}\n\n        # Get the keyword arguments.\n        kwargs_ = kwargs_ if kwarg_arg_name else {}\n\n        # Get the positional arguments.\n        pos_args = args[1:] if pos_arg_name else args\n\n        # Get the keyword arguments.\n        kwarg_args = kwargs if kwarg_arg_name else {}\n\n        # Get the keyword arguments.\n        kwargs_ = kwargs_ if kwarg_arg_name else {}\n\n        # Get the positional arguments.\n        pos_args = args[1:] if pos_arg_name else args\n\n        # Get the keyword arguments.\n        kwarg_args = kwargs if kwarg_arg_name else {}\n\n        # Get the keyword arguments.\n        kwargs_ = kwargs_ if kwarg_arg"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    # Wrap the function or module's forward method if a module is provided.\n    if isinstance(func, torch.nn.Module):\n        func = func.forward\n\n    # Define a wrapper function that uses a lock to ensure thread safety.\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n\n        # Acquire the lock.\n        with wrapper.lock:\n\n            # Get the current thread identifier.\n            thread_id = threading.get_ident()\n\n            # If the trace for the current thread is not cached, trace the function and cache the trace.\n            if thread_id not in wrapper.trace_cache:\n                wrapper.trace_cache[thread_id] = better_trace(\n                    TraceableModuleWrapper(func),\n                    flat_tensors.flattern((args, kwargs)),\n                    **kwargs_)\n\n            # Return the cached trace.\n            return wrapper.trace_cache[thread_id]\n\n    # Initialize the trace cache.\n    wrapper.trace_cache = {}\n\n    # Initialize the lock.\n    wrapper.lock = threading.Lock()\n\n    # If a compiler is provided, use it to compile the traced module or its call helper.\n    if ts_compiler is not None:\n        wrapper = ts_compiler(wrapper)\n\n    # Return the wrapper.\n    return wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    # Setup the lock.\n    lock = threading.Lock()\n\n    # If the function is a module, trace its forward method.\n    if isinstance(func, torch.nn.Module):\n        func = func.forward\n\n    # Define the wrapper function that uses the cache.\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n\n        # Acquire the lock.\n        with lock:\n\n            # If the cache is empty, trace the function or module's forward method.\n            if wrapper.cache is None:\n                wrapper.cache = trace_with_kwargs(func, *args, **kwargs)\n\n            # Return the traced function or module.\n            return wrapper.cache[0]\n\n    # Set the cache.\n    wrapper.cache = None\n\n    # If a compiler is provided, trace the function or module's forward method with the compiler.\n    if ts_compiler is not None:\n        wrapper.cache = trace_with_kwargs(ts_compiler(func), *args, **kwargs)\n\n    # Return the wrapper function.\n    return wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    def traced_func(*args, **kwargs):\n        nonlocal ts_compiler\n        if ts_compiler is None:\n            ts_compiler = lambda ts: ts\n        with trace_cache_lock:\n            if (args, tuple(kwargs.items())) in trace_cache:\n                ts = trace_cache[(args, tuple(kwargs.items()))]\n            else:\n                ts = ts_compiler(\n                    better_trace(func,\n                                 flat_tensors.flattern(\n                                     (tree_copy(args, detach=True),\n                                      tree_copy(kwargs, detach=True))),\n                                 **kwargs_))\n                trace_cache[(args, tuple(kwargs.items()))] = ts\n        return ts\n\n    trace_cache = {}\n    trace_cache_lock = threading.Lock()\n    return traced_func\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    # Create a lock to ensure thread safety when accessing the cache\n    lock = threading.Lock()\n\n    # Create a cache of traced modules\n    cache = {}\n\n    def traced_func(*args, **kwargs):\n\n        \"\"\"\n        This function is a wrapper around the original function or module's forward method. It checks if a cached version of the traced module exists for the given inputs. If so, it returns the cached version. Otherwise, it traces the original function or module's forward method, caches the traced module, and returns it.\n        \"\"\"\n\n        # Acquire the lock to ensure thread safety when accessing the cache\n        with lock:\n\n            # Create a key for the cache\n            key = (args, tuple(sorted(kwargs.items())))\n\n            # If a cached version of the traced module exists for the given inputs, return it\n            if key in cache:\n                return cache[key]\n\n            # Otherwise, trace the original function or module's forward method\n            traced_module = better_trace(func, args, **kwargs_)\n\n            # If a compiler function is provided, compile the traced module or its call helper with additional arguments\n            if ts_compiler is not None:\n                traced_module = ts_compiler(traced_module, args, **kwargs_)\n\n            # Cache the traced module\n            cache[key] = traced_module\n\n            # Return the traced module\n            return traced_module\n\n    # Return the wrapped version of the original function or module's forward method\n    return traced_func\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    if ts_compiler is None:\n        ts_compiler = lambda x: x\n\n    def tracing_wrapper(func, *args, **kwargs):\n        \"\"\"\n        This function is used to wrap the original function or module's forward method. It is used to cache the traced module for future calls.\n\n        Input-Output Arguments\n        :param func: Function or torch.nn.Module. The function or module to be traced.\n        :param args: Tuple. The positional arguments passed to the original function or module's forward method.\n        :param kwargs: Dict. The keyword arguments passed to the original function or module's forward method.\n        :return: Object. The traced module.\n        \"\"\"\n\n        # Acquire lock to prevent concurrent tracing.\n        tracing_lock.acquire()\n\n        # Check if the traced module already exists in the cache.\n        if func in traced_modules:\n            # Release lock.\n            tracing_lock.release()\n            return traced_modules[func]\n\n        # Trace the function or module.\n        traced_module = ts_compiler(trace(func, **kwargs_))\n\n        # Cache the traced module.\n        traced_modules[func] = traced_module\n\n        # Release lock.\n        tracing_lock.release()\n\n        return traced_module\n\n    # Create a lock for tracing.\n    tracing_lock = threading.Lock()\n\n    # Create a dictionary to cache traced modules.\n    traced_modules = {}\n\n    # Wrap the function or module's forward method.\n    return apply_to_all_modules(tracing_wrapper, func)\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    # Lock to ensure thread safety\n    lock = threading.Lock()\n\n    # Check if the function is a module\n    is_module = isinstance(func, torch.nn.Module)\n\n    # If the function is a module, check if it has a forward method\n    if is_module:\n        if not hasattr(func, 'forward'):\n            raise ValueError('The provided module does not have a forward method.')\n\n    # If the ts_compiler is not provided, use the identity function\n    if ts_compiler is None:\n        ts_compiler = lambda m: m\n\n    # Define the wrapper function\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n\n        # If the function is a module, check if the forward method is being called\n        if is_module and args[0] == func:\n\n            # If the forward method is being called, use the provided module\n            m = func\n\n        else:\n\n            # Otherwise, use the provided function\n            m = func\n\n        # Get the arguments\n        args = tuple(args[1:])\n\n        # If the module is a torch.nn.Module, get the keyword arguments\n        if is_module:\n            kwargs = kwargs.copy()\n\n        # Get the function's name\n        name = m.__name__ if isinstance(m, type(lambda: 0)) else m.__class__.__name__\n\n        # Acquire the lock\n        lock.acquire()\n\n        # Check if the module is already in the cache\n        if m in wrapper.cache:\n\n            # If it is, return the cached module\n            traced_module = wrapper.cache[m]\n\n        else:\n\n            # Otherwise, trace the module\n            traced_module = better_trace(m, args, **kwargs_)\n\n            # If the ts_compiler is provided, compile the traced module\n            if ts_compiler is not None:\n                traced_module = ts_compiler(traced_module)\n\n            # Add the traced module to the cache\n            wrapper.cache[m] = traced_module"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        summary_path = os.path.join(trial_path, 'summary.csv')\n        if not os.path.exists(summary_path):\n            raise ValueError(f\"summary.csv does not exist in {trial_path}.\")\n        trial_summary_df = load_summary_file(summary_path, dict_columns=['best_module_params'])\n        config_yaml_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_yaml_path, 'r') as f:\n            config_dict = yaml.safe_load(f)\n        yaml_dict = summary_df_to_yaml(trial_summary_df, config_dict)\n        return cls(yaml_dict, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        summary_path = os.path.join(trial_path, 'summary.csv')\n        if not os.path.exists(summary_path):\n            raise ValueError(f\"summary.csv does not exist in {trial_path}.\")\n        trial_summary_df = load_summary_file(summary_path, dict_columns=['best_module_params'])\n        config_yaml_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_yaml_path, 'r') as f:\n            config_dict = yaml.safe_load(f)\n        yaml_dict = summary_df_to_yaml(trial_summary_df, config_dict)\n        return cls(yaml_dict, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        summary_path = os.path.join(trial_path, 'summary.csv')\n        if not os.path.exists(summary_path):\n            raise ValueError(f\"summary.csv does not exist in {trial_path}.\")\n        trial_summary_df = load_summary_file(summary_path, dict_columns=['best_module_params'])\n        config_yaml_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_yaml_path, 'r') as f:\n            config_dict = yaml.safe_load(f)\n        yaml_dict = summary_df_to_yaml(trial_summary_df, config_dict)\n        return cls(yaml_dict, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        summary_path = os.path.join(trial_path, 'summary.csv')\n        if not os.path.exists(summary_path):\n            raise ValueError(f\"summary.csv does not exist in {trial_path}.\")\n        trial_summary_df = load_summary_file(summary_path, dict_columns=['best_module_params'])\n        config_yaml_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_yaml_path, 'r') as f:\n            config_dict = yaml.safe_load(f)\n        yaml_dict = summary_df_to_yaml(trial_summary_df, config_dict)\n        return cls(yaml_dict, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        if not os.path.exists(trial_path):\n            raise ValueError(f\"{trial_path} does not exist.\")\n        if not os.path.isdir(trial_path):\n            raise ValueError(f\"{trial_path} is not a directory.\")\n        if not os.path.exists(os.path.join(trial_path, 'summary.csv')):\n            raise ValueError(f\"summary.csv does not exist in {trial_path}.\")\n        if not os.path.exists(os.path.join(trial_path, 'config.yaml')):\n            raise ValueError(f\"config.yaml does not exist in {trial_path}.\")\n\n        config_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_path, 'r') as f:\n            try:\n                config = yaml.safe_load(f)\n            except yaml.YAMLError as exc:\n                logger.error(exc)\n                raise exc\n        project_dir = os.path.abspath(os.path.join(trial_path, os.pardir))\n        return cls(config, project_dir=project_dir)\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        summary_path = os.path.join(trial_path, 'summary.csv')\n        if not os.path.exists(summary_path):\n            raise ValueError(f\"summary.csv does not exist in {trial_path}.\")\n        trial_summary_df = load_summary_file(summary_path, dict_columns=['best_module_params'])\n        config_yaml_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_yaml_path, 'r') as f:\n            config_dict = yaml.safe_load(f)\n        yaml_dict = summary_df_to_yaml(trial_summary_df, config_dict)\n        return cls(yaml_dict, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        summary_path = os.path.join(trial_path, 'summary.csv')\n        if not os.path.exists(summary_path):\n            raise ValueError(f\"summary.csv does not exist in {trial_path}.\")\n        trial_summary_df = load_summary_file(summary_path, dict_columns=['best_module_params'])\n        config_yaml_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_yaml_path, 'r') as f:\n            config_dict = yaml.safe_load(f)\n        yaml_dict = summary_df_to_yaml(trial_summary_df, config_dict)\n        return cls(yaml_dict, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config = extract_best_config(trial_path)\n        project_dir = os.path.dirname(trial_path)\n        return cls(config, project_dir=project_dir)\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        summary_path = os.path.join(trial_path, 'summary.csv')\n        if not os.path.exists(summary_path):\n            raise ValueError(f\"summary.csv does not exist in {trial_path}.\")\n        trial_summary_df = load_summary_file(summary_path, dict_columns=['best_module_params'])\n        config_yaml_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_yaml_path, 'r') as f:\n            config_dict = yaml.safe_load(f)\n        yaml_dict = summary_df_to_yaml(trial_summary_df, config_dict)\n        return cls(yaml_dict, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        summary_path = os.path.join(trial_path, 'summary.csv')\n        if not os.path.exists(summary_path):\n            raise ValueError(f\"summary.csv does not exist in {trial_path}.\")\n        trial_summary_df = load_summary_file(summary_path, dict_columns=['best_module_params'])\n        config_yaml_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_yaml_path, 'r') as f:\n            config_dict = yaml.safe_load(f)\n        yaml_dict = summary_df_to_yaml(trial_summary_df, config_dict)\n        return cls(yaml_dict, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config_yaml_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_yaml_path, 'r') as f:\n            try:\n                config = yaml.safe_load(f)\n            except yaml.YAMLError as exc:\n                logger.error(exc)\n                raise exc\n        return cls(config, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        if not os.path.exists(trial_path):\n            raise ValueError(f\"{trial_path} does not exist.\")\n        if not os.path.isdir(trial_path):\n            raise ValueError(f\"{trial_path} is not a directory.\")\n        if not os.path.exists(os.path.join(trial_path, 'config.yaml')):\n            raise ValueError(f\"config.yaml does not exist in {trial_path}.\")\n        if not os.path.exists(os.path.join(trial_path, 'summary.csv')):\n            raise ValueError(f\"summary.csv does not exist in {trial_path}.\")\n        config = extract_best_config(trial_path)\n        return cls(config, project_dir=os.path.abspath(os.path.join(trial_path, os.pardir)))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        summary_path = os.path.join(trial_path, 'summary.csv')\n        if not os.path.exists(summary_path):\n            raise ValueError(f\"summary.csv does not exist in {trial_path}.\")\n        trial_summary_df = load_summary_file(summary_path, dict_columns=['best_module_params'])\n        config_yaml_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_yaml_path, 'r') as f:\n            config_dict = yaml.safe_load(f)\n        yaml_dict = summary_df_to_yaml(trial_summary_df, config_dict)\n        return cls(yaml_dict, project_dir=os.path.abspath(os.path.join(trial_path, os.pardir)))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config_path = os.path.join(trial_path, 'config.yaml')\n        if not os.path.exists(config_path):\n            raise ValueError(f\"config.yaml does not exist in {trial_path}.\")\n        with open(config_path, 'r') as f:\n            try:\n                config = yaml.safe_load(f)\n            except yaml.YAMLError as exc:\n                logger.error(exc)\n                raise exc\n        return cls(config, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        summary_path = os.path.join(trial_path, 'summary.csv')\n        if not os.path.exists(summary_path):\n            raise ValueError(f\"summary.csv does not exist in {trial_path}.\")\n        trial_summary_df = load_summary_file(summary_path, dict_columns=['best_module_params'])\n        config_yaml_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_yaml_path, 'r') as f:\n            config_dict = yaml.safe_load(f)\n        yaml_dict = summary_df_to_yaml(trial_summary_df, config_dict)\n        return cls(yaml_dict, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config_yaml_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_yaml_path, 'r') as f:\n            try:\n                config = yaml.safe_load(f)\n            except yaml.YAMLError as exc:\n                logger.error(exc)\n                raise exc\n        project_dir = os.path.dirname(trial_path)\n        return cls(config, project_dir=project_dir)\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        summary_path = os.path.join(trial_path, 'summary.csv')\n        if not os.path.exists(summary_path):\n            raise ValueError(f\"summary.csv does not exist in {trial_path}.\")\n        trial_summary_df = load_summary_file(summary_path, dict_columns=['best_module_params'])\n        config_yaml_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_yaml_path, 'r') as f:\n            config_dict = yaml.safe_load(f)\n        yaml_dict = summary_df_to_yaml(trial_summary_df, config_dict)\n        return cls(yaml_dict, project_dir=os.path.abspath(os.path.join(trial_path, os.pardir)))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        # The following code extracts the best configuration from the trial folder and sets the project directory to the parent directory of the trial folder.\n        if not os.path.exists(trial_path):\n            raise ValueError(f\"trial_path does not exist in {trial_path}.\")\n        summary_path = os.path.join(trial_path, 'summary.csv')\n        if not os.path.exists(summary_path):\n            raise ValueError(f\"summary.csv does not exist in {trial_path}.\")\n        trial_summary_df = load_summary_file(summary_path, dict_columns=['best_module_params'])\n        config_yaml_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_yaml_path, 'r') as f:\n            config_dict = yaml.safe_load(f)\n        yaml_dict = summary_df_to_yaml(trial_summary_df, config_dict)\n        project_dir = os.path.dirname(trial_path)\n        return cls(yaml_dict, project_dir=project_dir)\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        trial_summary_df = load_summary_file(os.path.join(trial_path, 'summary.csv'), dict_columns=['best_module_params'])\n        config_yaml_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_yaml_path, 'r') as f:\n            config = yaml.safe_load(f)\n        yaml_dict = summary_df_to_yaml(trial_summary_df, config)\n        return cls(yaml_dict, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        if not os.path.exists(trial_path):\n            raise ValueError(f\"{trial_path} does not exist.\")\n        config = extract_best_config(trial_path)\n        project_dir = os.path.dirname(trial_path)\n        return cls(config, project_dir=project_dir)\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # initialize the result dataframe\n    result = pd.DataFrame()\n\n    # initialize the speed dataframe\n    speed_df = pd.DataFrame()\n\n    # initialize the evaluation dataframe\n    eval_df = pd.DataFrame()\n\n    # initialize the summary dataframe\n    summary_df = pd.DataFrame()\n\n    # initialize the best result dataframe\n    best_result = pd.DataFrame()\n\n    # initialize the best speed dataframe\n    best_speed_df = pd.DataFrame()\n\n    # initialize the best evaluation dataframe\n    best_eval_df = pd.DataFrame()\n\n    # initialize the best summary dataframe\n    best_summary_df = pd.DataFrame()\n\n    # initialize the best module index\n    best_module_index = -1\n\n    # initialize the best module parameters\n    best_module_params = {}\n\n    # initialize the best module name\n    best_module_name = \"\"\n\n    # initialize the best module speed\n    best_module_speed = 0\n\n    # initialize the best module evaluation\n    best_module_eval = 0\n\n    # initialize the best module summary\n    best_module_summary = 0\n\n    # initialize the best module result\n    best_module_result = pd.DataFrame()\n\n    # iterate through the modules\n    for module_index, module in enumerate(modules):\n\n        # initialize the module result dataframe\n        module_result = pd.DataFrame()\n\n        # initialize the module speed dataframe\n        module_speed_df = pd.DataFrame()\n\n        # initialize the module evaluation dataframe\n        module_eval_df = pd.DataFrame()\n\n        # initialize the module summary dataframe\n        module_summary_df = pd.DataFrame()\n\n        # initialize the module best result dataframe\n        module_best_result = pd.DataFrame()\n\n        # initialize the module best speed dataframe\n        module_best_speed_df = pd.DataFrame()\n\n        # initialize the module best evaluation dataframe\n        module_best_eval_df = pd.DataFrame()\n\n        # initialize the module best summary dataframe\n        module_best_summary_df = pd.DataFrame()\n\n        # initialize the module best module index\n        module_best_module_"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Create a directory for this node line\n    os.makedirs(node_line_dir, exist_ok=True)\n\n    # Create a directory for the results of this node line\n    node_line_results_dir = os.path.join(node_line_dir, 'results')\n    os.makedirs(node_line_results_dir, exist_ok=True)\n\n    # Create a directory for the summaries of this node line\n    node_line_summaries_dir = os.path.join(node_line_dir, 'summaries')\n    os.makedirs(node_line_summaries_dir, exist_ok=True)\n\n    # Create a directory for the execution times of this node line\n    node_line_times_dir = os.path.join(node_line_dir, 'times')\n    os.makedirs(node_line_times_dir, exist_ok=True)\n\n    # Create a directory for the results of this node line\n    node_line_selected_dir = os.path.join(node_line_dir, 'selected')\n    os.makedirs(node_line_selected_dir, exist_ok=True)\n\n    # Create a directory for the results of this node line\n    node_line_final_dir = os.path.join(node_line_dir, 'final')\n    os.makedirs(node_line_final_dir, exist_ok=True)\n\n    # Create a directory for the results of this node line\n    node_line_selected_dir = os.path.join(node_line_dir, 'selected')\n    os.makedirs(node_line_selected_dir, exist_ok=True)\n\n    # Create a directory for the results of this node line\n    node_line_final_dir = os.path.join(node_line_dir, 'final')\n    os.makedirs(node_line_final_dir, exist_ok=True)\n\n    # Create a directory for the results of this node line\n    node_line_final_dir = os.path.join(node_line_"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Create the directory if it does not exist\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Run the retrieval modules\n    results = []\n    for module, params in zip(modules, module_params):\n        result = module(params)\n        results.append(result)\n\n    # Measure the execution times\n    speed_results = measure_speed(results)\n\n    # Evaluate the results\n    eval_results = evaluate_retrieval(results, previous_result, strategies)\n\n    # Combine the results\n    result_df = pd.concat([speed_results, eval_results], axis=1)\n\n    # Select the best result\n    best_result = select_best_average(result_df, strategies)\n\n    # Save the best result\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"), index=False)\n\n    # Save the result summary\n    summary_df = load_summary_file(node_line_dir)\n    summary_df = summary_df.append(best_result)\n    summary_df.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # create the node line directory if it doesn't exist\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # initialize the result dataframe\n    result = pd.DataFrame()\n\n    # run each module with the given parameters\n    for module, params in zip(modules, module_params):\n        logger.info(f\"Running module: {module.__name__}\")\n\n        # run the module\n        module_result = module(previous_result, **params)\n\n        # measure the module execution time\n        module_result = measure_speed(module_result, module.__name__)\n\n        # evaluate the module result\n        module_result = evaluate_retrieval(module_result, previous_result, **strategies)\n\n        # save the module result to disk\n        module_result_path = os.path.join(node_line_dir, f\"{module.__name__}_result.csv\")\n        module_result.to_csv(module_result_path, index=False)\n\n        # append the module result to the result dataframe\n        result = result.append(module_result)\n\n    # save the result summary to disk\n    result_summary_path = os.path.join(node_line_dir, \"result_summary.csv\")\n    result.to_csv(result_summary_path, index=False)\n\n    # select the best module result\n    best_result = select_best_average(result, **strategies)\n\n    # save the best result to disk\n    best_result_path = os.path.join(node_line_dir, \"best_result.csv\")\n    best_result.to_csv(best_result_path, index=False)\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # create a directory for this node line\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # run each module with given parameters\n    results = []\n    for module, params in zip(modules, module_params):\n        result = module(**params)\n        results.append(result)\n\n    # evaluate each result\n    eval_results = []\n    for result in results:\n        eval_result = evaluate_retrieval(result, previous_result, **strategies)\n        eval_results.append(eval_result)\n\n    # measure the execution time of each result\n    speed_results = []\n    for result in results:\n        speed_result = measure_speed(result)\n        speed_results.append(speed_result)\n\n    # combine results and speed metrics\n    combined_results = []\n    for i in range(len(results)):\n        result = pd.concat([results[i], eval_results[i], speed_results[i]], axis=1)\n        combined_results.append(result)\n\n    # select the best result\n    best_result = select_best_average(combined_results)\n\n    # save the best result\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"), index=False)\n\n    # save the combined results\n    combined_results_df = pd.concat(combined_results, axis=0)\n    combined_results_df.to_csv(os.path.join(node_line_dir, \"combined_results.csv\"), index=False)\n\n    # save the evaluation results\n    eval_results_df = pd.concat(eval_results, axis=0)\n    eval_results_df.to_csv(os.path.join(node_line_dir, \"eval_results.csv\"), index=False)\n\n    # save the speed results\n    speed_results_df = pd.concat(speed_results, axis=0)\n    speed_results_df.to_csv(os.path.join(node_line_"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Create directory for this node line\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Run each module with the given parameters\n    for module, params in zip(modules, module_params):\n        logger.info(f\"Running {module.__name__} with parameters {params}\")\n        result = module(**params)\n        result.to_csv(os.path.join(node_line_dir, f\"{module.__name__}.csv\"), index=False)\n\n    # Measure the execution times\n    speed_df = measure_speed(node_line_dir, module_params)\n    speed_df.to_csv(os.path.join(node_line_dir, \"speed.csv\"), index=False)\n\n    # Evaluate the results\n    eval_df = evaluate_retrieval(previous_result, speed_df, node_line_dir)\n    eval_df.to_csv(os.path.join(node_line_dir, \"eval.csv\"), index=False)\n\n    # Filter results by speed threshold\n    if \"speed_threshold\" in strategies:\n        speed_threshold = strategies[\"speed_threshold\"]\n        filtered_df = filter_by_threshold(eval_df, speed_df, speed_threshold)\n        filtered_df.to_csv(os.path.join(node_line_dir, \"filtered.csv\"), index=False)\n\n    # Select the best result\n    best_result = select_best_average(eval_df, speed_df, strategies[\"metrics\"])\n    best_result.to_csv(os.path.join(node_line_dir, \"best.csv\"), index=False)\n\n    # Save summary file\n    summary_df = load_summary_file(node_line_dir)\n    summary_df.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Create the node line directory if it does not exist\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create a summary file for the node line\n    summary_file = os.path.join(node_line_dir, \"summary.csv\")\n    if not os.path.exists(summary_file):\n        pd.DataFrame(columns=[\"module_name\", \"module_params\", \"speed_time\", \"speed_unit\", \"eval_metric\", \"eval_value\"]).to_csv(summary_file, index=False)\n\n    # Evaluate and select the best module\n    best_module = select_best_average(modules, module_params, previous_result, strategies)\n\n    # Run the best module\n    best_result = best_module(previous_result, **best_module.params)\n\n    # Measure the speed of the best module\n    speed_time, speed_unit = measure_speed(best_module, best_module.params, previous_result)\n\n    # Evaluate the best module\n    eval_metric, eval_value = evaluate_retrieval(best_result, previous_result)\n\n    # Save the best result\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"), index=False)\n\n    # Save the best module parameters\n    best_module_params = {\n        \"module_name\": best_module.__name__,\n        \"module_params\": best_module.params,\n        \"speed_time\": speed_time,\n        \"speed_unit\": speed_unit,\n        \"eval_metric\": eval_metric,\n        \"eval_value\": eval_value,\n    }\n    best_module_params = pd.DataFrame([best_module_params])\n    best_module_params.to_csv(summary_file, mode=\"a\", header=False, index=False)\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Set up directory for this node line\n    if not os.path.exists(node_line_dir):\n        os.makedirs(node_line_dir)\n\n    # Run each module with its parameters and save the results\n    results = []\n    for module, module_param in zip(modules, module_params):\n        result = module(previous_result, **module_param)\n        result.to_csv(os.path.join(node_line_dir, f\"{module.__name__}.csv\"))\n        results.append(result)\n\n    # Measure execution times and save the results\n    speed_results = measure_speed(results, node_line_dir)\n\n    # Evaluate retrieval results and save the results\n    evaluation_results = evaluate_retrieval(results, previous_result, node_line_dir)\n\n    # Select the best result by applying specified strategies\n    best_result = select_best_average(speed_results, evaluation_results, strategies)\n\n    # Save the best result\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"))\n\n    # Save the summary file\n    summary_file = os.path.join(node_line_dir, \"summary.csv\")\n    speed_results.to_csv(summary_file)\n    load_summary_file(summary_file)\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # create the directory if it does not exist\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # run each retrieval module with the given parameters\n    result_dfs = []\n    for module, module_param in zip(modules, module_params):\n        result_df = module(**module_param)\n        result_dfs.append(result_df)\n\n    # merge all the result dataframes\n    result_df = pd.concat(result_dfs, axis=1)\n\n    # measure the execution time of each module\n    result_df = measure_speed(result_df, node_line_dir)\n\n    # filter the results by the speed threshold\n    result_df = filter_by_threshold(result_df, node_line_dir, strategies['speed_threshold'])\n\n    # select the best average retrieval result\n    result_df = select_best_average(result_df, node_line_dir, strategies['metrics'])\n\n    # evaluate the retrieval results\n    result_df = evaluate_retrieval(result_df, previous_result, node_line_dir, strategies['metrics'])\n\n    # save the result dataframe to disk\n    result_df.to_csv(os.path.join(node_line_dir, 'result_df.csv'))\n\n    # save the summary file to disk\n    summary_df = load_summary_file(node_line_dir)\n    summary_df.to_csv(os.path.join(node_line_dir, 'summary_df.csv'))\n\n    return result_df\n\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # initialize variables\n    result = pd.DataFrame()\n    result_summary = pd.DataFrame()\n    speed_summary = pd.DataFrame()\n    best_result_summary = pd.DataFrame()\n    best_result = pd.DataFrame()\n\n    # run each module with its parameters\n    for module, module_param in zip(modules, module_params):\n        logger.info(f\"Running module {module.__name__}\")\n        # run the module\n        result = module(previous_result, **module_param)\n        # measure the execution time\n        speed_summary = measure_speed(result, module.__name__)\n        # evaluate the result\n        result_summary = evaluate_retrieval(result, previous_result, module.__name__)\n        # filter by speed\n        result = filter_by_threshold(result, speed_summary, module.__name__, strategies[\"speed_threshold\"])\n        # select the best result\n        best_result, best_result_summary = select_best_average(result, module.__name__, strategies[\"select_strategy\"])\n\n    # save the results\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"), index=False)\n    best_result_summary.to_csv(os.path.join(node_line_dir, \"best_result_summary.csv\"), index=False)\n    result.to_csv(os.path.join(node_line_dir, \"result.csv\"), index=False)\n    result_summary.to_csv(os.path.join(node_line_dir, \"result_summary.csv\"), index=False)\n    speed_summary.to_csv(os.path.join(node_line_dir, \"speed_summary.csv\"), index=False)\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Create the directory if it does not exist\n    if not os.path.exists(node_line_dir):\n        os.makedirs(node_line_dir)\n\n    # Get the results for each module and save them to disk\n    results = []\n    for module, params in zip(modules, module_params):\n        result = module(previous_result, **params)\n        result.to_csv(os.path.join(node_line_dir, f\"{module.__name__}.csv\"), index=False)\n        results.append(result)\n\n    # Evaluate and save the results to disk\n    results = evaluate_retrieval(results, previous_result, node_line_dir)\n\n    # Measure the execution times\n    speed_results = measure_speed(results, node_line_dir)\n\n    # Select the best result\n    best_result = select_best_average(results, speed_results, strategies)\n\n    # Save the best result to disk\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"), index=False)\n\n    # Save the summary file to disk\n    summary_file = os.path.join(node_line_dir, \"summary.csv\")\n    if os.path.exists(summary_file):\n        summary_df = load_summary_file(summary_file)\n    else:\n        summary_df = pd.DataFrame()\n\n    summary_df = summary_df.append(speed_results)\n    summary_df.to_csv(summary_file, index=False)\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Initialize the result DataFrame\n    result_df = pd.DataFrame()\n\n    # Initialize the speed DataFrame\n    speed_df = pd.DataFrame()\n\n    # Initialize the evaluation DataFrame\n    eval_df = pd.DataFrame()\n\n    # Iterate over the modules and their parameters\n    for module, params in zip(modules, module_params):\n\n        # Set the module name\n        module_name = module.__name__\n\n        # Set the module parameters\n        module_params = params\n\n        # Set the module parameters\n        module_params = params\n\n        # Set the module result path\n        module_result_path = os.path.join(node_line_dir, module_name)\n\n        # Create the module result directory\n        pathlib.Path(module_result_path).mkdir(parents=True, exist_ok=True)\n\n        # Set the module result file path\n        module_result_file_path = os.path.join(module_result_path, \"result.csv\")\n\n        # Set the module speed file path\n        module_speed_file_path = os.path.join(module_result_path, \"speed.csv\")\n\n        # Set the module evaluation file path\n        module_eval_file_path = os.path.join(module_result_path, \"eval.csv\")\n\n        # Run the module\n        module_result_df = module(previous_result, **module_params)\n\n        # Save the module result\n        module_result_df.to_csv(module_result_file_path, index=False)\n\n        # Measure the module execution time\n        module_speed_df = measure_speed(module_result_df, module_speed_file_path)\n\n        # Evaluate the module\n        module_eval_df = evaluate_retrieval(module_result_df, module_eval_file_path, previous_result)\n\n        # Append the module speed and evaluation DataFrames to the overall result DataFrames\n        speed_df = speed_df.append(module_speed_df)\n        eval_df = eval_df.append(module_eval"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # create a directory for the current node line\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # create a summary file for the current node line\n    summary_file = os.path.join(node_line_dir, 'summary.csv')\n\n    # initialize the result dataframe\n    result = pd.DataFrame()\n\n    # iterate over the modules\n    for i, module in enumerate(modules):\n\n        # set the module parameters\n        module_params[i]['previous_result'] = previous_result\n        module_params[i]['summary_file'] = summary_file\n\n        # run the module and get the result\n        result = module(**module_params[i])\n\n        # measure the execution time\n        time_file = os.path.join(node_line_dir, f'time_module_{i}.csv')\n        time_df = measure_speed(result, time_file)\n\n        # evaluate the retrieval\n        eval_file = os.path.join(node_line_dir, f'eval_module_{i}.csv')\n        eval_df = evaluate_retrieval(result, eval_file, previous_result)\n\n        # append the time and evaluation files to the summary file\n        time_df.to_csv(time_file, index=False)\n        eval_df.to_csv(eval_file, index=False)\n        time_eval_df = pd.concat([time_df, eval_df], axis=1)\n        time_eval_df.to_csv(summary_file, index=False)\n\n        # load the summary file\n        summary_df = load_summary_file(summary_file)\n\n        # apply the strategies\n        result = select_best_average(summary_df, strategies['average_metrics'])\n        result = filter_by_threshold(result, strategies['speed_thresholds'])\n\n    return result\n\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Create the node line directory if it does not exist\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Initialize the result dataframe\n    result = pd.DataFrame()\n\n    # Run each module with the given parameters\n    for module, params in zip(modules, module_params):\n        logger.info(f\"Running retrieval module: {module.__name__}\")\n\n        # Run the module and save the result\n        module_result = module(**params)\n        module_result.to_csv(os.path.join(node_line_dir, module.__name__ + \".csv\"))\n\n        # Measure the execution time\n        module_speed = measure_speed(module, params)\n\n        # Evaluate the module result\n        module_result = evaluate_retrieval(module_result, previous_result)\n\n        # Append the result to the result dataframe\n        result = pd.concat([result, module_result], axis=1)\n\n        # Append the speed to the result dataframe\n        result = pd.concat([result, module_speed], axis=1)\n\n    # Apply the strategies\n    result = apply_strategies(result, strategies)\n\n    # Save the result dataframe\n    result.to_csv(os.path.join(node_line_dir, \"result.csv\"))\n\n    # Save the summary file\n    summary = load_summary_file(node_line_dir)\n    summary = summary.append(\n        {\"module\": \"All\", \"speed_threshold\": strategies[\"speed_threshold\"], \"metric\": strategies[\"metric\"],\n         \"filter\": strategies[\"filter\"], \"selection\": strategies[\"selection\"]}, ignore_index=True)\n    summary.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    return result\n\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # create a directory for this node line\n    node_line_dir = pathlib.Path(node_line_dir)\n    node_line_dir.mkdir(parents=True, exist_ok=True)\n\n    # create a summary file for this node line\n    summary_file_path = node_line_dir / 'summary.csv'\n    summary_file_path.touch(exist_ok=True)\n\n    # run each module with the specified parameters\n    for module, module_param in zip(modules, module_params):\n\n        # create a directory for this module\n        module_dir = node_line_dir / module.__name__\n        module_dir.mkdir(parents=True, exist_ok=True)\n\n        # create a summary file for this module\n        module_summary_file_path = module_dir / 'summary.csv'\n        module_summary_file_path.touch(exist_ok=True)\n\n        # run the module and save the results to disk\n        result = module(previous_result, **module_param)\n        result_file_path = module_dir / 'result.csv'\n        result.to_csv(result_file_path, index=False)\n\n        # evaluate the module results and save the results to disk\n        result_eval = evaluate_retrieval(result, previous_result, module_summary_file_path)\n        result_eval.to_csv(module_summary_file_path, index=False)\n\n        # measure the module execution time and save the results to disk\n        module_speed = measure_speed(module, module_param)\n        module_speed.to_csv(module_dir / 'speed.csv', index=False)\n\n        # add the execution time to the summary file\n        summary_file_path = _add_speed_to_summary(summary_file_path, module_speed)\n\n    # apply strategies to select the best result\n    best_result = select_best_average(node_line_dir, strategies)\n\n    # add the best result to the summary file\n    summary_file_path = _add_best_to_"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Create a directory for the node line\n    node_line_dir = pathlib.Path(node_line_dir)\n    node_line_dir.mkdir(parents=True, exist_ok=True)\n\n    # Run the retrieval modules\n    node_line_results = []\n    for module, module_param in zip(modules, module_params):\n        # Run the module\n        logger.info(f\"Running retrieval module {module.__name__} with parameters {module_param}\")\n        module_result = module(**module_param)\n\n        # Measure the speed\n        logger.info(f\"Measuring speed of module {module.__name__}\")\n        module_result = measure_speed(module_result, module_param)\n\n        # Evaluate the retrieval module\n        logger.info(f\"Evaluating retrieval module {module.__name__}\")\n        module_result = evaluate_retrieval(module_result, previous_result, node_line_dir, **strategies)\n\n        # Save the result\n        module_result.to_csv(node_line_dir / f\"{module.__name__}.csv\", index=False)\n\n        # Append the result to the list of results\n        node_line_results.append(module_result)\n\n    # Concatenate the results\n    node_line_results = pd.concat(node_line_results, axis=0, ignore_index=True)\n\n    # Save the result\n    node_line_results.to_csv(node_line_dir / \"results.csv\", index=False)\n\n    # Save a summary of the results\n    node_line_summary = node_line_results.groupby(\"module\").agg(\n        mean_ndcg=(\"ndcg\", \"mean\"),\n        mean_recall=(\"recall\", \"mean\"),\n        mean_map=(\"map\", \"mean\"),\n        mean_precision=(\"precision\", \"mean\"),\n        mean_fallout=(\"fallout\", \"mean\"),\n        mean_mrr=(\"mrr\", \"mean\"),\n        mean_speed=(\"speed\", \"mean\"),"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # create the node line directory if it doesn't exist\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # list to hold all the results\n    all_results = []\n\n    # iterate over the modules and their parameters\n    for module, module_param in zip(modules, module_params):\n\n        # create a directory for this module\n        module_dir = os.path.join(node_line_dir, module.__name__)\n        pathlib.Path(module_dir).mkdir(parents=True, exist_ok=True)\n\n        # run the module and save the results\n        results = module(previous_result, **module_param)\n        results.to_csv(os.path.join(module_dir, \"results.csv\"), index=False)\n\n        # measure the execution time\n        speed_results = measure_speed(results, module, module_param)\n        speed_results.to_csv(os.path.join(module_dir, \"speed.csv\"), index=False)\n\n        # filter by speed threshold\n        filtered_results = filter_by_threshold(speed_results, module, module_param, strategies)\n        filtered_results.to_csv(os.path.join(module_dir, \"filtered_results.csv\"), index=False)\n\n        # select the best result\n        best_result = select_best_average(filtered_results, module, module_param, strategies)\n        best_result.to_csv(os.path.join(module_dir, \"best_result.csv\"), index=False)\n\n        # add the best result to the list\n        all_results.append(best_result)\n\n    # save the summary of all results\n    summary_file = os.path.join(node_line_dir, \"summary.csv\")\n    summary = pd.concat(all_results)\n    summary.to_csv(summary_file, index=False)\n\n    # return the best result\n    return summary\n\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Create the node line directory if it does not exist\n    if not os.path.exists(node_line_dir):\n        os.makedirs(node_line_dir)\n\n    # Create a summary file for the current node line\n    summary_file = os.path.join(node_line_dir, \"summary.csv\")\n    if not os.path.exists(summary_file):\n        with open(summary_file, \"w\") as f:\n            f.write(\"node_line,module,module_params,strategy,speed_threshold,metrics,metric_values,best_result,best_result_params,best_result_metrics,best_result_metric_values\\n\")\n\n    # Run each module with the given parameters\n    for module, module_param in zip(modules, module_params):\n\n        # Create a sub-directory for the module\n        module_dir = os.path.join(node_line_dir, module.__name__)\n        if not os.path.exists(module_dir):\n            os.makedirs(module_dir)\n\n        # Run the module and save the result\n        result = module(**module_param)\n        result_file = os.path.join(module_dir, \"result.csv\")\n        result.to_csv(result_file, index=False)\n\n        # Measure the execution speed and save the result\n        speed_result = measure_speed(result, module_dir)\n        speed_file = os.path.join(module_dir, \"speed.csv\")\n        speed_result.to_csv(speed_file, index=False)\n\n        # Evaluate the retrieval node result\n        evaluation_result = evaluate_retrieval(result, previous_result, module_dir)\n        evaluation_file = os.path.join(module_dir, \"evaluation.csv\")\n        evaluation_result.to_csv(evaluation_file, index=False)\n\n        # Apply the strategies\n        for strategy, strategy_params in strategies.items():\n\n            # Apply the strategy\n            filtered_result = filter_by_th"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # initialize results dataframe\n    node_results = pd.DataFrame()\n\n    # initialize speed results dataframe\n    speed_results = pd.DataFrame()\n\n    # initialize summary dataframe\n    summary_results = pd.DataFrame()\n\n    # initialize summary dataframe\n    speed_summary_results = pd.DataFrame()\n\n    # initialize module counter\n    module_counter = 0\n\n    # iterate over modules\n    for module in modules:\n\n        # iterate over module parameters\n        for params in module_params:\n\n            # run module with current parameters\n            result = module(**params)\n\n            # measure execution time\n            speed_result = measure_speed(result)\n\n            # append module execution time to speed results dataframe\n            speed_results = speed_results.append(speed_result)\n\n            # evaluate module\n            summary_result = evaluate_retrieval(result, previous_result)\n\n            # append module evaluation metrics to summary results dataframe\n            summary_results = summary_results.append(summary_result)\n\n            # apply strategies\n            result = select_best_average(result, strategies)\n\n            # append module results to results dataframe\n            node_results = node_results.append(result)\n\n            # append module results to results dataframe\n            node_results = node_results.append(result)\n\n            # append module execution time to speed results dataframe\n            speed_results = speed_results.append(speed_result)\n\n            # append module evaluation metrics to summary results dataframe\n            summary_results = summary_results.append(summary_result)\n\n            # append module execution time to speed summary results dataframe\n            speed_summary_results = speed_summary_results.append(speed_result)\n\n            # append module evaluation metrics to summary results dataframe\n            summary_results = summary_results.append(summary_result)\n\n            # save results to disk\n            result.to_csv(os.path.join(node_line_dir, f\"result_{module_counter}.csv\"), index=False)\n\n            # save speed results to disk\n            speed_result.to_csv(os.path.join(node_line_dir, f\"speed_result"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Run each retrieval module with the specified parameters and measure their execution times\n    node_line_dir = pathlib.Path(node_line_dir)\n    node_line_dir.mkdir(parents=True, exist_ok=True)\n    results = []\n    for module, params in zip(modules, module_params):\n        logger.info(f\"Evaluating {module.__name__} with parameters {params}\")\n        result = evaluate_retrieval(module, params, previous_result)\n        result[\"module_name\"] = module.__name__\n        results.append(result)\n\n        # Measure execution time and save to disk\n        speed_result = measure_speed(module, params, previous_result)\n        speed_result[\"module_name\"] = module.__name__\n        speed_result.to_csv(node_line_dir / f\"{module.__name__}_speed.csv\", index=False)\n\n    # Combine all results into one dataframe\n    results = pd.concat(results, axis=0, ignore_index=True)\n\n    # Apply strategies\n    if \"filter_threshold\" in strategies:\n        results = filter_by_threshold(results, strategies[\"filter_threshold\"])\n\n    if \"select_best_average\" in strategies:\n        results = select_best_average(results, strategies[\"select_best_average\"])\n\n    # Save results to disk\n    results.to_csv(node_line_dir / \"retrieval_results.csv\", index=False)\n\n    # Save summary to disk\n    summary = results.groupby([\"module_name\", \"strategy\"]).agg({\n        \"map\": [\"mean\", \"std\"],\n        \"recall\": [\"mean\", \"std\"],\n        \"ndcg\": [\"mean\", \"std\"],\n        \"time\": [\"mean\", \"std\"],\n        \"n_queries\": \"sum\"\n    })\n    summary.columns = [\"_\".join(col).strip() for col in summary.columns.values]\n    summary.reset_index(inplace=True)\n    summary.to_csv(node_"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # create a directory for the node line\n    node_line_dir = pathlib.Path(node_line_dir)\n    node_line_dir.mkdir(parents=True, exist_ok=True)\n\n    # create a directory for the results of the node line\n    node_line_dir = node_line_dir / \"query_expansion\"\n    node_line_dir.mkdir(parents=True, exist_ok=True)\n\n    # create a directory for the results of the node line\n    node_line_dir = node_line_dir / \"results\"\n    node_line_dir.mkdir(parents=True, exist_ok=True)\n\n    # create a directory for the summaries of the node line\n    node_line_dir = node_line_dir / \"summaries\"\n    node_line_dir.mkdir(parents=True, exist_ok=True)\n\n    # create a directory for the plots of the node line\n    node_line_dir = node_line_dir / \"plots\"\n    node_line_dir.mkdir(parents=True, exist_ok=True)\n\n    # create a directory for the plots of the node line\n    node_line_dir = node_line_dir / \"plots\"\n    node_line_dir.mkdir(parents=True, exist_ok=True)\n\n    # create a directory for the plots of the node line\n    node_line_dir = node_line_dir / \"plots\"\n    node_line_dir.mkdir(parents=True, exist_ok=True)\n\n    # create a directory for the plots of the node line\n    node_line_dir = node_line_dir / \"plots\"\n    node_line_dir.mkdir(parents=True, exist_ok=True)\n\n    # create a directory for the plots of the node line\n    node_line_dir = node_line_dir / \"plots\"\n    node_line_dir.mkdir(parents=True, exist_ok=True)\n\n    # create a directory for the plots of the node line\n    node_"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # create a directory for the node line\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # create a directory for the results\n    results_dir = os.path.join(node_line_dir, \"results\")\n    pathlib.Path(results_dir).mkdir(parents=True, exist_ok=True)\n\n    # create a directory for the summaries\n    summaries_dir = os.path.join(node_line_dir, \"summaries\")\n    pathlib.Path(summaries_dir).mkdir(parents=True, exist_ok=True)\n\n    # create a directory for the results of the best module\n    best_module_dir = os.path.join(node_line_dir, \"best_module\")\n    pathlib.Path(best_module_dir).mkdir(parents=True, exist_ok=True)\n\n    # create a directory for the results of the best module\n    best_module_results_dir = os.path.join(best_module_dir, \"results\")\n    pathlib.Path(best_module_results_dir).mkdir(parents=True, exist_ok=True)\n\n    # create a directory for the summaries of the best module\n    best_module_summaries_dir = os.path.join(best_module_dir, \"summaries\")\n    pathlib.Path(best_module_summaries_dir).mkdir(parents=True, exist_ok=True)\n\n    # create a directory for the results of the best module\n    best_module_results_dir = os.path.join(best_module_dir, \"results\")\n    pathlib.Path(best_module_results_dir).mkdir(parents=True, exist_ok=True)\n\n    # create a directory for the summaries of the best module\n    best_module_summaries_dir = os.path.join(best_module_dir, \"summaries\")\n    pathlib.Path(best_module_summaries_dir).mkdir(parents="}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # create a directory for query expansion node\n    node_dir = os.path.join(node_line_dir, \"query_expansion\")\n    os.makedirs(node_dir, exist_ok=True)\n\n    # create a directory for query expansion node results\n    node_results_dir = os.path.join(node_dir, \"results\")\n    os.makedirs(node_results_dir, exist_ok=True)\n\n    # create a directory for query expansion node summaries\n    node_summaries_dir = os.path.join(node_dir, \"summaries\")\n    os.makedirs(node_summaries_dir, exist_ok=True)\n\n    # create a directory for query expansion node execution times\n    node_times_dir = os.path.join(node_dir, \"times\")\n    os.makedirs(node_times_dir, exist_ok=True)\n\n    # create a directory for query expansion node evaluation metrics\n    node_metrics_dir = os.path.join(node_dir, \"metrics\")\n    os.makedirs(node_metrics_dir, exist_ok=True)\n\n    # create a directory for query expansion node results\n    node_best_dir = os.path.join(node_dir, \"best\")\n    os.makedirs(node_best_dir, exist_ok=True)\n\n    # create a directory for query expansion node best results\n    node_best_results_dir = os.path.join(node_best_dir, \"results\")\n    os.makedirs(node_best_results_dir, exist_ok=True)\n\n    # create a directory for query expansion node best summaries\n    node_best_summaries_dir = os.path.join(node_best_dir, \"summaries\")\n    os.makedirs(node_best_summaries_dir, exist_ok=True)\n\n    # create a directory for query expansion node best execution times\n    node_best_times_dir = os.path.join(node_best_dir, \"times\")\n    os."}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # create directory for query expansion node\n    node_line_dir = os.path.join(node_line_dir, \"query_expansion\")\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # run each module with given parameters\n    module_results = []\n    for module, params in zip(modules, module_params):\n        logger.info(f\"Running query expansion module: {module.__name__}\")\n        module_result = module(previous_result, **params)\n        module_results.append(module_result)\n\n    # measure execution times\n    module_results = [measure_speed(result) for result in module_results]\n\n    # evaluate each module based on specified strategies\n    module_results = [evaluate_retrieval_node(result, strategies) for result in module_results]\n\n    # save results and summaries\n    for result, module in zip(module_results, modules):\n        result.to_csv(os.path.join(node_line_dir, f\"{module.__name__}.csv\"))\n        result.describe().to_csv(os.path.join(node_line_dir, f\"{module.__name__}_summary.csv\"))\n\n    # select best module\n    best_result = select_best_average(module_results, strategies[\"average_metrics\"])\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"))\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # create a directory for the current node line\n    node_line_dir = os.path.join(node_line_dir, \"query_expansion\")\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # run all modules with their parameters\n    results = []\n    for module, params in zip(modules, module_params):\n        result = evaluate_retrieval_node(module, params, previous_result)\n        result[\"module\"] = module.__name__\n        results.append(result)\n\n    # save the results\n    results = pd.concat(results)\n    results.to_csv(os.path.join(node_line_dir, \"results.csv\"), index=False)\n\n    # measure the execution times\n    results = measure_speed(results)\n    results.to_csv(os.path.join(node_line_dir, \"results_with_speed.csv\"), index=False)\n\n    # filter the results by speed threshold\n    results = filter_by_threshold(results, \"speed\", strategies[\"speed_threshold\"])\n    results.to_csv(os.path.join(node_line_dir, \"results_with_speed_filtered.csv\"), index=False)\n\n    # select the best result based on the average evaluation metrics\n    results = select_best_average(results, strategies[\"metrics\"])\n    results.to_csv(os.path.join(node_line_dir, \"results_with_speed_filtered_selected.csv\"), index=False)\n\n    # save the summary\n    summary = results.groupby(\"module\").agg({\n        \"speed\": [\"mean\", \"std\"],\n        \"recall\": [\"mean\", \"std\"],\n        \"precision\": [\"mean\", \"std\"],\n        \"f1\": [\"mean\", \"std\"],\n    })\n    summary.columns = ['_'.join(col).strip() for col in summary.columns.values]\n    summary.reset_index(inplace=True)\n    summary.to_csv(os.path.join(node_line_dir, \"summary"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # create the node line directory if it does not exist\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # run the query expansion modules\n    results = []\n    for module, params in zip(modules, module_params):\n        logger.info(f\"Running {module.__name__} with params: {params}\")\n        result = evaluate_retrieval_node(module, params, previous_result, node_line_dir)\n        results.append(result)\n\n    # save the results to a csv file\n    results = pd.concat(results)\n    results.to_csv(os.path.join(node_line_dir, \"results.csv\"), index=False)\n\n    # measure the execution times\n    results = measure_speed(results, \"query_expansion_module\")\n\n    # filter the results by speed\n    results = filter_by_threshold(results, \"query_expansion_module\", strategies[\"speed_thresholds\"])\n\n    # evaluate the results\n    results = evaluate_retrieval_node(select_best_average, {}, results, node_line_dir)\n\n    # save the results to a csv file\n    results.to_csv(os.path.join(node_line_dir, \"results_summary.csv\"), index=False)\n\n    return results\n\n"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # create directory if it does not exist\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # create results dataframe\n    results = pd.DataFrame(columns=['module_name', 'module_params', 'speed', 'precision', 'recall', 'f1'])\n\n    # run each module with its parameters\n    for module, params in zip(modules, module_params):\n        module_name = module.__name__\n        logger.info(f\"Evaluating module {module_name}\")\n\n        # run module and save results\n        result = evaluate_retrieval_node(module, params, previous_result, node_line_dir)\n        results = results.append(result, ignore_index=True)\n\n    # save results\n    results.to_csv(os.path.join(node_line_dir, 'results.csv'), index=False)\n\n    # measure speed\n    results = measure_speed(results, node_line_dir)\n\n    # filter results by speed\n    results = filter_by_threshold(results, node_line_dir, threshold=strategies['speed_threshold'])\n\n    # select best average\n    results = select_best_average(results, node_line_dir)\n\n    return results\n\n"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # create a directory to save the results of each module\n    node_line_dir = os.path.join(node_line_dir, \"query_expansion\")\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # run each module with the given parameters\n    results = []\n    for module, params in zip(modules, module_params):\n        logger.info(f\"Running query expansion module {module.__name__}\")\n        result = evaluate_retrieval_node(module, params, previous_result)\n        result[\"module\"] = module.__name__\n        results.append(result)\n\n    # concatenate the results\n    results = pd.concat(results)\n\n    # measure the execution times\n    results = measure_speed(results, \"query_expansion\", node_line_dir)\n\n    # evaluate the results\n    results = filter_by_threshold(results, strategies[\"speed_threshold\"], \"query_expansion\", node_line_dir)\n    results = select_best_average(results, strategies[\"average_strategy\"], \"query_expansion\", node_line_dir)\n\n    return results\n\n"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Create a directory for the results and summaries\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Run all modules with the given parameters\n    results = []\n    for module, params in zip(modules, module_params):\n        logger.info(f\"Evaluating {module.__name__}\")\n        result = evaluate_retrieval_node(module, params, previous_result)\n        results.append(result)\n\n    # Save the results\n    results_df = pd.concat(results)\n    results_df.to_csv(os.path.join(node_line_dir, \"results.csv\"), index=False)\n\n    # Measure execution time\n    results_df = measure_speed(results_df, node_line_dir)\n\n    # Evaluate the results\n    results_df = filter_by_threshold(results_df, strategies[\"speed_threshold\"])\n    results_df = select_best_average(results_df, strategies[\"metrics\"])\n\n    # Save the results\n    results_df.to_csv(os.path.join(node_line_dir, \"results_filtered.csv\"), index=False)\n\n    # Save the summary\n    results_df.describe().to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=True)\n\n    # Select the best result\n    best_result = results_df.loc[results_df[\"best\"] == True]\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"), index=False)\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Make combinations of modules and parameters\n    module_combinations = make_combinations(modules, module_params)\n\n    # Run all combinations of modules and parameters\n    results = []\n    for module, params in module_combinations:\n        # Run the module with the specified parameters\n        result = evaluate_retrieval_node(module, previous_result, params)\n        # Measure the execution time\n        time = measure_speed(module, params)\n        # Evaluate the result with the specified strategies\n        result = filter_by_threshold(result, strategies)\n        # Add the execution time to the result\n        result['time'] = time\n        # Append the result to the results list\n        results.append(result)\n\n    # Explode the results\n    results = explode(results)\n\n    # Save the results\n    results.to_csv(os.path.join(node_line_dir, 'results.csv'), index=False)\n\n    # Select the best result\n    best_result = select_best_average(results, strategies)\n\n    # Save the best result\n    best_result.to_csv(os.path.join(node_line_dir, 'best_result.csv'), index=False)\n\n    # Save the summary\n    summary = best_result.describe()\n    summary.to_csv(os.path.join(node_line_dir, 'summary.csv'), index=True)\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # create a directory for the current node line\n    node_line_dir = os.path.join(node_line_dir, \"query_expansion\")\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # create a dataframe to store the results\n    results = pd.DataFrame(columns=[\"module\", \"params\", \"speed\", \"accuracy\", \"recall\", \"precision\", \"f1\"])\n\n    # iterate over all modules and run them\n    for module, params in zip(modules, module_params):\n\n        # run the module\n        logger.info(f\"Running {module.__name__} with parameters {params}\")\n        result = evaluate_retrieval_node(module, params, previous_result)\n\n        # measure the execution time\n        speed = measure_speed(module, params, previous_result)\n\n        # evaluate the module\n        metrics = result.evaluate(strategies)\n\n        # save the results to the results dataframe\n        results = results.append({\"module\": module.__name__,\n                                  \"params\": params,\n                                  \"speed\": speed,\n                                  \"accuracy\": metrics[\"accuracy\"],\n                                  \"recall\": metrics[\"recall\"],\n                                  \"precision\": metrics[\"precision\"],\n                                  \"f1\": metrics[\"f1\"]}, ignore_index=True)\n\n        # save the results to a csv file\n        results.to_csv(os.path.join(node_line_dir, \"results.csv\"), index=False)\n\n    # save the results to a csv file\n    results.to_csv(os.path.join(node_line_dir, \"results.csv\"), index=False)\n\n    # select the best module\n    best_module = select_best_average(results, strategies)\n\n    # save the best module to a csv file\n    best_module.to_csv(os.path.join(node_line_dir, \"best_module.csv\"), index=False)\n\n    return best_module\n\n"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Create the directory if it does not exist\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create a list of all combinations of modules and parameters\n    module_combinations = make_combinations(modules, module_params)\n\n    # Create a list of all combinations of modules and parameters\n    module_combinations = make_combinations(modules, module_params)\n\n    # Run all combinations of modules and parameters\n    result_list = []\n    for module, params in module_combinations:\n        result = evaluate_retrieval_node(module, params, previous_result)\n        result_list.append(result)\n\n    # Create a dataframe from the result list\n    result_df = pd.concat(result_list)\n\n    # Save the dataframe to the specified directory\n    result_df.to_csv(os.path.join(node_line_dir, \"results.csv\"), index=False)\n\n    # Measure the execution time for each module\n    time_df = measure_speed(module_combinations, result_df)\n\n    # Save the execution time dataframe to the specified directory\n    time_df.to_csv(os.path.join(node_line_dir, \"time.csv\"), index=False)\n\n    # Filter the results based on the specified threshold\n    filtered_df = filter_by_threshold(time_df, strategies[\"speed_threshold\"])\n\n    # Save the filtered results dataframe to the specified directory\n    filtered_df.to_csv(os.path.join(node_line_dir, \"filtered.csv\"), index=False)\n\n    # Select the best module based on the specified strategies\n    best_module = select_best_average(filtered_df, strategies)\n\n    # Save the best module to the specified directory\n    best_module.to_csv(os.path.join(node_line_dir, \"best.csv\"), index=False)\n\n    # Save the best module to the specified directory\n    best_module.to_csv(os.path.join(node"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Create the node line directory if it does not exist\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create a dataframe to save the results of each module\n    results = pd.DataFrame()\n\n    # Create a dataframe to save the summaries of each module\n    summaries = pd.DataFrame()\n\n    # Loop over all modules and their parameters\n    for module, module_param in zip(modules, module_params):\n\n        # Create a directory for the module results\n        module_dir = os.path.join(node_line_dir, module.__name__)\n        pathlib.Path(module_dir).mkdir(parents=True, exist_ok=True)\n\n        # Execute the module with the specified parameters\n        result, summary = evaluate_retrieval_node(module, module_param, previous_result, module_dir)\n\n        # Save the results and summaries of each module\n        result.to_csv(os.path.join(module_dir, \"results.csv\"), index=False)\n        summary.to_csv(os.path.join(module_dir, \"summary.csv\"), index=False)\n\n        # Append the results and summaries of each module to the overall results and summaries\n        results = pd.concat([results, result], ignore_index=True)\n        summaries = pd.concat([summaries, summary], ignore_index=True)\n\n    # Save the overall results and summaries\n    results.to_csv(os.path.join(node_line_dir, \"results.csv\"), index=False)\n    summaries.to_csv(os.path.join(node_line_dir, \"summaries.csv\"), index=False)\n\n    # Select the best module based on the specified strategies\n    best_result = select_best_average(results, strategies[\"metrics\"], strategies[\"thresholds\"])\n\n    # Save the best result\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"), index=False)\n\n    return best"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # make combinations of modules and parameters\n    module_combinations = make_combinations(modules, module_params)\n\n    # create a dataframe to store the results\n    node_df = pd.DataFrame(columns=['module_name', 'module_params', 'speed', 'accuracy', 'precision', 'recall', 'f1', 'support'])\n\n    # run each module\n    for i, module_combination in enumerate(module_combinations):\n        module, params = module_combination\n        logger.info(f\"Running module {i + 1}/{len(module_combinations)}: {module.__name__} with parameters {params}\")\n        result = evaluate_retrieval_node(module, params, previous_result)\n        node_df = node_df.append(result, ignore_index=True)\n\n    # save the results\n    node_df.to_csv(os.path.join(node_line_dir, \"results.csv\"), index=False)\n\n    # measure the execution time of each module\n    node_df['speed'] = node_df.apply(lambda x: measure_speed(x['module_name'], x['module_params']), axis=1)\n\n    # evaluate each module based on the specified strategies\n    node_df = filter_by_threshold(node_df, strategies['speed_threshold'])\n    node_df = select_best_average(node_df, strategies['metrics'])\n\n    # save the summary\n    node_df.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    # select the best result\n    best_result = node_df.loc[node_df['selected'] == 1]\n    best_result = best_result.drop(columns=['selected'])\n\n    # save the best result\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"), index=False)\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Create the directory if it does not exist\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create a dataframe to store the results\n    results = pd.DataFrame()\n\n    # Evaluate all combinations of modules and parameters\n    for module, params in make_combinations(modules, module_params):\n\n        # Get the module name\n        module_name = module.__name__\n\n        # Get the module parameters\n        params_str = str(params).replace(\"'\", '\"')\n\n        # Run the module\n        logger.info(f\"Running {module_name} with parameters: {params_str}\")\n        result = module(previous_result, **params)\n\n        # Measure the execution time\n        time_result = measure_speed(result)\n\n        # Evaluate the module\n        logger.info(f\"Evaluating {module_name} with parameters: {params_str}\")\n        eval_result = evaluate_retrieval_node(result, strategies)\n\n        # Save the results\n        module_result = pd.concat([time_result, eval_result], axis=1)\n        module_result.to_csv(f\"{node_line_dir}/{module_name}_{params_str}_result.csv\", index=False)\n\n        # Append the results to the results dataframe\n        results = pd.concat([results, module_result], axis=0)\n\n    # Save the results\n    results.to_csv(f\"{node_line_dir}/results.csv\", index=False)\n\n    # Select the best module\n    best_result = select_best_average(results, strategies)\n    best_result.to_csv(f\"{node_line_dir}/best_result.csv\", index=False)\n\n    # Save the summary\n    summary = explode(results)\n    summary.to_csv(f\"{node_line_dir}/summary.csv\", index=False)\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # get all combinations of modules and parameters\n    combs = make_combinations(modules, module_params)\n\n    # create a list for storing the results of each module\n    results = []\n\n    # run all combinations\n    for i, (module, params) in enumerate(combs):\n        logger.info(f\"Running module {i+1}/{len(combs)}: {module.__name__}\")\n\n        # run the module with the given parameters\n        result = module(previous_result, **params)\n\n        # measure the execution time\n        time = measure_speed(module, previous_result, **params)\n\n        # evaluate the result\n        result = evaluate_retrieval_node(result, strategies)\n\n        # save the result\n        result.to_csv(os.path.join(node_line_dir, f\"{module.__name__}.csv\"), index=False)\n\n        # append the result to the list\n        results.append(deepcopy(result))\n\n        # log the result\n        logger.info(f\"Result: {result}\")\n\n    # explode the results\n    results = explode(results)\n\n    # save the results\n    results.to_csv(os.path.join(node_line_dir, \"results.csv\"), index=False)\n\n    # select the best result\n    best_result = select_best_average(results, strategies)\n\n    # save the best result\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"), index=False)\n\n    # log the best result\n    logger.info(f\"Best result: {best_result}\")\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # create a directory for the node line if it does not exist\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # create a dataframe to save the results of the evaluation\n    node_line_results = pd.DataFrame(columns=[\"module\", \"module_params\", \"speed\", \"accuracy\", \"precision\", \"recall\", \"f1\", \"support\"])\n\n    # run each module with given parameters\n    for module, module_param in zip(modules, module_params):\n\n        # run the module and save the results\n        module_results = evaluate_retrieval_node(module=module,\n                                                 module_params=module_param,\n                                                 previous_result=previous_result,\n                                                 node_line_dir=node_line_dir,\n                                                 )\n\n        # measure the execution time\n        speed = measure_speed(module_results)\n\n        # evaluate the module based on specified strategies\n        module_results = filter_by_threshold(module_results,\n                                             speed_threshold=strategies[\"speed_threshold\"],\n                                             )\n\n        module_results = select_best_average(module_results,\n                                             metric=strategies[\"metric\"],\n                                             )\n\n        # save the results to the dataframe\n        node_line_results = node_line_results.append(module_results)\n\n    # save the results to the specified directory\n    node_line_results.to_csv(os.path.join(node_line_dir, \"node_line_results.csv\"))\n\n    # save the summary of the results to the specified directory\n    node_line_summary = node_line_results.groupby([\"module\", \"module_params\"]).mean().reset_index()\n    node_line_summary.to_csv(os.path.join(node_line_dir, \"node_line_summary.csv\"))\n\n    # select the best module\n    best_module = node_line_summary.sort_values(by=strategies[\"metric\"], ascending=False).il"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # create a directory for the current node line\n    node_line_dir = os.path.join(node_line_dir, \"query_expansion\")\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # create a dataframe to store the results\n    results = pd.DataFrame()\n\n    # run all combinations of the modules and parameters\n    for module, params in make_combinations(modules, module_params):\n        logger.info(f\"Running {module.__name__} with parameters: {params}\")\n\n        # run the module and save the results\n        result = evaluate_retrieval_node(\n            module,\n            params,\n            previous_result,\n            node_line_dir,\n            module_name=module.__name__\n        )\n\n        # measure the module execution time\n        time = measure_speed(module, params, previous_result)\n\n        # add the results to the dataframe\n        result[\"module\"] = module.__name__\n        result[\"params\"] = params\n        result[\"time\"] = time\n        results = pd.concat([results, result], ignore_index=True)\n\n    # save the results\n    results.to_csv(os.path.join(node_line_dir, \"results.csv\"), index=False)\n\n    # filter the results by speed threshold\n    filtered_results = filter_by_threshold(results, strategies[\"speed_threshold\"])\n\n    # select the best result by average performance\n    best_result = select_best_average(filtered_results, strategies[\"metrics\"])\n\n    # save the best result\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"), index=False)\n\n    # save the summary\n    summary = pd.DataFrame(best_result.drop(columns=[\"result\"]).groupby(\n        [\"module\", \"params\"]).mean().reset_index())\n    summary[\"count\"] = filtered_results.groupby(\n        [\"module\", \"params\"]).count().result.to_list()\n    summary.to_csv"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Create the directory for query expansion results\n    node_line_dir = pathlib.Path(node_line_dir)\n    node_line_dir.mkdir(parents=True, exist_ok=True)\n\n    # Create a dataframe to store results\n    results = pd.DataFrame()\n\n    # Evaluate each module with the specified parameters\n    for module, params in zip(modules, module_params):\n        logger.info(f\"Evaluating {module.__name__}\")\n        # Evaluate the module with the specified parameters\n        module_results = evaluate_retrieval_node(module=module,\n                                                 params=params,\n                                                 previous_result=previous_result,\n                                                 node_line_dir=node_line_dir)\n\n        # Add the results to the results dataframe\n        results = pd.concat([results, module_results])\n\n    # Measure the execution time for each module\n    results[\"time\"] = results.progress_apply(measure_speed, axis=1)\n\n    # Save the results to the specified directory\n    results.to_csv(node_line_dir / \"results.csv\", index=False)\n\n    # Filter the results based on the specified speed threshold\n    results = filter_by_threshold(results, threshold=strategies[\"speed_threshold\"])\n\n    # Select the best module based on the specified strategy\n    best_result = select_best_average(results, strategy=strategies[\"strategy\"])\n\n    # Save the best result to the specified directory\n    best_result.to_csv(node_line_dir / \"best_result.csv\", index=False)\n\n    # Save the summary of the best result to the specified directory\n    best_result.describe().to_csv(node_line_dir / \"best_result_summary.csv\")\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # make combinations of all parameters\n    params = make_combinations(module_params)\n\n    # create a list to store results\n    results = []\n\n    # iterate over all combinations\n    for param in params:\n        # execute the module with the given parameters\n        result = evaluate_retrieval_node(modules[0], param, previous_result)\n        # measure the execution time\n        execution_time = measure_speed(modules[0], param, previous_result)\n        # append the result to the list\n        results.append(result)\n        # append the execution time to the list\n        results.append(execution_time)\n\n    # explode the results\n    results = explode(results)\n\n    # evaluate the results\n    results = evaluate_query_expansion_node(results, strategies)\n\n    # select the best result\n    best_result = select_best_average(results, strategies)\n\n    # save the results\n    best_result.to_csv(os.path.join(node_line_dir, \"results.csv\"), index=False)\n\n    # save the summary\n    best_result.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # create necessary directories\n    node_line_dir = pathlib.Path(node_line_dir)\n    node_line_dir.mkdir(parents=True, exist_ok=True)\n\n    # create a subdirectory for the prompt maker results\n    prompt_maker_dir = node_line_dir / 'prompt_maker'\n    prompt_maker_dir.mkdir(parents=True, exist_ok=True)\n\n    # create a subdirectory for the prompt maker results\n    prompt_maker_dir = node_line_dir / 'prompt_maker'\n    prompt_maker_dir.mkdir(parents=True, exist_ok=True)\n\n    # create a subdirectory for the prompt maker results\n    prompt_maker_dir = node_line_dir / 'prompt_maker'\n    prompt_maker_dir.mkdir(parents=True, exist_ok=True)\n\n    # create a subdirectory for the prompt maker results\n    prompt_maker_dir = node_line_dir / 'prompt_maker'\n    prompt_maker_dir.mkdir(parents=True, exist_ok=True)\n\n    # create a subdirectory for the prompt maker results\n    prompt_maker_dir = node_line_dir / 'prompt_maker'\n    prompt_maker_dir.mkdir(parents=True, exist_ok=True)\n\n    # create a subdirectory for the prompt maker results\n    prompt_maker_dir = node_line_dir / 'prompt_maker'\n    prompt_maker_dir.mkdir(parents=True, exist_ok=True)\n\n    # create a subdirectory for the prompt maker results\n    prompt_maker_dir = node_line_dir / 'prompt_maker'\n    prompt_maker_dir.mkdir(parents=True, exist_ok=True)\n\n    # create a subdirectory for the prompt maker results\n    prompt_maker_dir = node_line_dir / 'prompt_maker'\n    prompt_maker_dir.mkdir(parents=True, exist_ok=True)\n\n    #"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create necessary directories\n    node_line_dir = pathlib.Path(node_line_dir)\n    node_line_dir.mkdir(parents=True, exist_ok=True)\n    node_line_dir = str(node_line_dir)\n\n    # Create a directory for the best prompt maker module\n    best_prompt_maker_dir = os.path.join(node_line_dir, 'best_prompt_maker')\n    os.makedirs(best_prompt_maker_dir, exist_ok=True)\n\n    # Create a directory for the best prompt maker module's results\n    best_prompt_maker_result_dir = os.path.join(best_prompt_maker_dir, 'result')\n    os.makedirs(best_prompt_maker_result_dir, exist_ok=True)\n\n    # Create a directory for the best prompt maker module's summary\n    best_prompt_maker_summary_dir = os.path.join(best_prompt_maker_dir, 'summary')\n    os.makedirs(best_prompt_maker_summary_dir, exist_ok=True)\n\n    # Create a directory for the best prompt maker module's execution time\n    best_prompt_maker_time_dir = os.path.join(best_prompt_maker_dir, 'time')\n    os.makedirs(best_prompt_maker_time_dir, exist_ok=True)\n\n    # Create a directory for the best prompt maker module's evaluation metrics\n    best_prompt_maker_metrics_dir = os.path.join(best_prompt_maker_dir, 'metrics')\n    os.makedirs(best_prompt_maker_metrics_dir, exist_ok=True)\n\n    # Create a directory for the best prompt maker module's evaluation metrics\n    best_prompt_maker_metrics_dir = os.path.join(best_prompt_maker_dir, 'metrics')\n    os.makedirs(best_prompt_maker_metrics_dir,"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create necessary directories\n    if not os.path.exists(node_line_dir):\n        os.makedirs(node_line_dir)\n\n    # Create a list of the combinations of prompt maker modules and their parameters\n    module_combinations = make_combinations(modules, module_params)\n\n    # Create a list of the combinations of prompt maker modules and their parameters\n    module_combinations = make_combinations(modules, module_params)\n\n    # Create a list of the combinations of prompt maker modules and their parameters\n    module_combinations = make_combinations(modules, module_params)\n\n    # Create a list of the combinations of prompt maker modules and their parameters\n    module_combinations = make_combinations(modules, module_params)\n\n    # Create a list of the combinations of prompt maker modules and their parameters\n    module_combinations = make_combinations(modules, module_params)\n\n    # Create a list of the combinations of prompt maker modules and their parameters\n    module_combinations = make_combinations(modules, module_params)\n\n    # Create a list of the combinations of prompt maker modules and their parameters\n    module_combinations = make_combinations(modules, module_params)\n\n    # Create a list of the combinations of prompt maker modules and their parameters\n    module_combinations = make_combinations(modules, module_params)\n\n    # Create a list of the combinations of prompt maker modules and their parameters\n    module_combinations = make_combinations(modules, module_params)\n\n    # Create a list of the combinations of prompt maker modules and their parameters\n    module_combinations = make_combinations(modules, module_params)\n\n    # Create a list of the combinations of prompt maker modules and their parameters\n    module_combinations = make_combinations(modules, module_params)\n\n    # Create a list of the combinations of prompt maker modules and their parameters\n    module_combinations = make_combinations(modules, module_params)\n\n    # Create a list"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create a directory for the node's output\n    node_dir = os.path.join(node_line_dir, \"prompt_maker\")\n    os.makedirs(node_dir, exist_ok=True)\n\n    # Create a directory for the best prompt maker's output\n    best_prompt_dir = os.path.join(node_dir, \"best_prompt\")\n    os.makedirs(best_prompt_dir, exist_ok=True)\n\n    # Create a directory for the other prompt maker's output\n    other_prompt_dir = os.path.join(node_dir, \"other_prompt\")\n    os.makedirs(other_prompt_dir, exist_ok=True)\n\n    # Create a directory for the best prompt maker's evaluation\n    best_prompt_eval_dir = os.path.join(best_prompt_dir, \"eval\")\n    os.makedirs(best_prompt_eval_dir, exist_ok=True)\n\n    # Create a directory for the other prompt maker's evaluation\n    other_prompt_eval_dir = os.path.join(other_prompt_dir, \"eval\")\n    os.makedirs(other_prompt_eval_dir, exist_ok=True)\n\n    # Create a directory for the best prompt maker's speed\n    best_prompt_speed_dir = os.path.join(best_prompt_dir, \"speed\")\n    os.makedirs(best_prompt_speed_dir, exist_ok=True)\n\n    # Create a directory for the other prompt maker's speed\n    other_prompt_speed_dir = os.path.join(other_prompt_dir, \"speed\")\n    os.makedirs(other_prompt_speed_dir, exist_ok=True)\n\n    # Create a directory for the best prompt maker's support\n    best_prompt_support_dir = os.path.join(best_prompt_dir, \"support\")\n    os.makedirs(best_prompt_support"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # create necessary directories\n    os.makedirs(node_line_dir, exist_ok=True)\n    results_dir = os.path.join(node_line_dir, 'results')\n    os.makedirs(results_dir, exist_ok=True)\n\n    # get the best prompt maker module\n    best_module = select_best_prompt_maker(modules, module_params, strategies)\n\n    # run the best prompt maker module\n    best_module_params = strategies['best_module_params']\n    best_module_result = best_module(**best_module_params)\n\n    # save the best prompt maker module's result\n    best_module_result_path = os.path.join(results_dir, 'best_module_result.csv')\n    best_module_result.to_csv(best_module_result_path)\n\n    # combine the best prompt maker module's result with the previous result\n    combined_result = pd.concat([previous_result, best_module_result], axis=1)\n\n    # save the combined result\n    combined_result_path = os.path.join(results_dir, 'combined_result.csv')\n    combined_result.to_csv(combined_result_path)\n\n    # save a summary of the combined result\n    summary_path = os.path.join(results_dir, 'summary.csv')\n    combined_result.describe().to_csv(summary_path)\n\n    return combined_result\n\n"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # create necessary directories\n    os.makedirs(node_line_dir, exist_ok=True)\n\n    # create a dataframe to store the results\n    node_result = pd.DataFrame(columns=['prompt_maker', 'params', 'metrics'])\n\n    # create a dictionary to store the execution times\n    node_times = {}\n\n    # create a dictionary to store the evaluation metrics\n    node_metrics = {}\n\n    # create a dictionary to store the best prompt maker module\n    node_best = {}\n\n    # create a dictionary to store the best prompt maker module's parameters\n    node_best_params = {}\n\n    # create a dictionary to store the best prompt maker module's metrics\n    node_best_metrics = {}\n\n    # create a dictionary to store the best prompt maker module's execution times\n    node_best_times = {}\n\n    # create a dictionary to store the best prompt maker module's evaluation metrics\n    node_best_metrics = {}\n\n    # create a dictionary to store the best prompt maker module's generation results\n    node_best_generation = {}\n\n    # create a dictionary to store the best prompt maker module's generation results\n    node_best_generation_metrics = {}\n\n    # create a dictionary to store the best prompt maker module's generation results\n    node_best_generation_times = {}\n\n    # create a dictionary to store the best prompt maker module's generation results\n    node_best_generation_metrics = {}\n\n    # create a dictionary to store the best prompt maker module's generation results\n    node_best_generation_times = {}\n\n    # create a dictionary to store the best prompt maker module's generation results\n    node_best_generation_metrics = {}\n\n    # create a dictionary to store the best prompt maker module's generation results\n    node_best_generation_times = {}\n\n    # create a dictionary to store the best prompt maker module's generation results\n    node_best_generation_metrics = {}\n\n    # create a dictionary to store the best prompt maker"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # create necessary subdirectories\n    os.makedirs(node_line_dir, exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, 'results'), exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, 'summary'), exist_ok=True)\n\n    # create a dataframe to store the results of the best prompt maker module\n    best_prompt_maker_result = pd.DataFrame()\n\n    # iterate over the modules and parameters\n    for module, module_param in zip(modules, module_params):\n\n        # create a subdirectory for the current prompt maker module\n        module_dir = os.path.join(node_line_dir, module.__name__)\n        os.makedirs(module_dir, exist_ok=True)\n\n        # create a subdirectory for the current prompt maker module's results\n        module_result_dir = os.path.join(module_dir, 'results')\n        os.makedirs(module_result_dir, exist_ok=True)\n\n        # create a subdirectory for the current prompt maker module's summary\n        module_summary_dir = os.path.join(module_dir, 'summary')\n        os.makedirs(module_summary_dir, exist_ok=True)\n\n        # execute the current prompt maker module and evaluate its performance\n        module_result = module(**module_param)\n        module_result['module'] = module.__name__\n        module_result['params'] = str(module_param)\n\n        # save the module's result\n        module_result_path = os.path.join(module_result_dir, 'result.csv')\n        module_result.to_csv(module_result_path, index=False)\n\n        # save the module's summary\n        module_summary_path = os.path.join(module_summary_dir, 'summary.csv')\n        module_summary = measure_speed(module_result)\n        module_summary.to_csv(module_summary_path, index=False"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create necessary directories\n    node_line_dir = pathlib.Path(node_line_dir)\n    node_line_dir.mkdir(parents=True, exist_ok=True)\n    result_dir = node_line_dir / 'results'\n    result_dir.mkdir(parents=True, exist_ok=True)\n\n    # Create a dataframe to store the results of all prompt maker modules\n    result_df = pd.DataFrame()\n\n    # Iterate over all prompt maker modules\n    for module, params in zip(modules, module_params):\n\n        # Create a directory for the current prompt maker module\n        module_dir = result_dir / module.__name__\n        module_dir.mkdir(parents=True, exist_ok=True)\n\n        # Run the current prompt maker module\n        result = module(**params)\n\n        # Save the results of the current prompt maker module\n        result_path = module_dir / 'result.csv'\n        result.to_csv(result_path)\n\n        # Append the results of the current prompt maker module to the result dataframe\n        result_df = pd.concat([result_df, result])\n\n        # Evaluate the current prompt maker module\n        result_eval = evaluate_generation(result, params['eval_path'])\n\n        # Save the evaluation results of the current prompt maker module\n        result_eval_path = module_dir / 'result_eval.csv'\n        result_eval.to_csv(result_eval_path)\n\n        # Calculate the execution time of the current prompt maker module\n        result_time = measure_speed(result, params['eval_path'])\n\n        # Save the execution time of the current prompt maker module\n        result_time_path = module_dir / 'result_time.csv'\n        result_time.to_csv(result_time_path)\n\n        # Calculate the execution time of the current prompt maker module\n        result_time = measure_speed(result, params['eval_path'])\n\n        # Save the execution time of the current prompt maker module\n        result_time"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create necessary directories\n    os.makedirs(node_line_dir, exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, 'results'), exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, 'results', 'summary'), exist_ok=True)\n\n    # Create a dataframe to store the results\n    result = pd.DataFrame()\n\n    # Run each module\n    for module, module_param in zip(modules, module_params):\n\n        # Create a subdirectory for each module\n        module_dir = os.path.join(node_line_dir, module.__name__)\n        os.makedirs(module_dir, exist_ok=True)\n\n        # Run the module and save the results\n        result = module(module_param, result, module_dir)\n\n        # Evaluate the module and save the results\n        result = evaluate_generation(result, module_dir)\n\n        # Measure the speed of the module and save the results\n        result = measure_speed(result, module_dir)\n\n        # Filter the results by speed threshold\n        result = filter_by_threshold(result, module_dir, 'speed', strategies['speed_threshold'])\n\n    # Select the best module based on specified strategies\n    result = select_best_average(result, strategies['metrics'], strategies['threshold'])\n\n    # Combine the results with the previous result\n    result = pd.concat([previous_result, result], axis=1)\n\n    # Save the results\n    result.to_csv(os.path.join(node_line_dir, 'results', 'summary', 'result.csv'), index=False)\n\n    # Save the summary\n    result.describe().to_csv(os.path.join(node_line_dir, 'results', 'summary', 'summary.csv'))\n\n    return result\n\n"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create necessary directories\n    os.makedirs(node_line_dir, exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, \"results\"), exist_ok=True)\n\n    # Run each module with its parameters\n    for module, module_param in zip(modules, module_params):\n        # Create a subdirectory for the module\n        module_dir = os.path.join(node_line_dir, module.__name__)\n        os.makedirs(module_dir, exist_ok=True)\n\n        # Run the module and save the results\n        module_result = module(**module_param)\n        module_result.to_csv(os.path.join(module_dir, \"results.csv\"))\n\n        # Evaluate the module\n        if \"evaluation\" in strategies:\n            # Load the module's results\n            module_result = pd.read_csv(os.path.join(module_dir, \"results.csv\"))\n            module_result = cast_metrics(module_result)\n\n            # Load the evaluation parameters\n            evaluation_params = deepcopy(strategies[\"evaluation\"])\n            evaluation_params[\"input_dir\"] = module_dir\n            evaluation_params[\"output_dir\"] = os.path.join(module_dir, \"evaluation\")\n            evaluation_params[\"result_dir\"] = os.path.join(node_line_dir, \"results\")\n\n            # Evaluate the module\n            evaluate_generation(**evaluation_params)\n\n        # Measure the module's speed\n        if \"speed\" in strategies:\n            # Load the module's results\n            module_result = pd.read_csv(os.path.join(module_dir, \"results.csv\"))\n            module_result = cast_metrics(module_result)\n\n            # Load the speed parameters\n            speed_params = deepcopy(strategies[\"speed\"])\n            speed_params[\"input_dir\"] = module_dir\n            speed_params[\"output_dir\"] = os.path.join(module_dir, \"speed\")"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # validate the node line directory\n    node_line_dir = os.path.expanduser(node_line_dir)\n    if not os.path.isdir(node_line_dir):\n        os.makedirs(node_line_dir)\n\n    # validate the strategies\n    if strategies is None:\n        strategies = {}\n    if \"metrics\" not in strategies:\n        strategies[\"metrics\"] = [\"bleu\", \"rouge1\", \"rouge2\", \"rougeL\"]\n    if \"speed_threshold\" not in strategies:\n        strategies[\"speed_threshold\"] = 0.0\n    if \"best_average\" not in strategies:\n        strategies[\"best_average\"] = False\n    if \"gen_module\" not in strategies:\n        strategies[\"gen_module\"] = \"gpt2\"\n    if \"gen_params\" not in strategies:\n        strategies[\"gen_params\"] = {}\n\n    # validate the prompt maker modules\n    if modules is None:\n        modules = []\n    if module_params is None:\n        module_params = []\n    if len(modules) != len(module_params):\n        raise ValueError(\"The number of modules and parameters must be the same!\")\n\n    # validate the previous result\n    if previous_result is None:\n        previous_result = pd.DataFrame()\n    if not isinstance(previous_result, pd.DataFrame):\n        raise ValueError(\"The previous result must be a pandas dataframe!\")\n\n    # validate the metrics\n    metrics = strategies[\"metrics\"]\n    if not isinstance(metrics, list):\n        metrics = [metrics]\n\n    # validate the speed threshold\n    speed_threshold = strategies[\"speed_threshold\"]\n    if not isinstance(speed_threshold, float):\n        raise ValueError(\"The speed threshold must be a float!\")\n\n    # validate the best average\n    best_average = strategies[\"best_average\"]\n    if not isinstance(best_average, bool):\n        raise ValueError(\"The best average flag must be a boolean!\")"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create necessary subdirectories\n    if not os.path.exists(node_line_dir):\n        os.makedirs(node_line_dir)\n    if not os.path.exists(os.path.join(node_line_dir, \"results\")):\n        os.makedirs(os.path.join(node_line_dir, \"results\"))\n    if not os.path.exists(os.path.join(node_line_dir, \"summary\")):\n        os.makedirs(os.path.join(node_line_dir, \"summary\"))\n\n    # Get support modules\n    support_modules = get_support_modules(modules, module_params)\n\n    # Get default parameters for prompt maker modules\n    prompt_maker_params = support_modules[\"prompt_maker\"]\n\n    # Get default parameters for the generation module\n    gen_params = support_modules[\"gen\"]\n\n    # Get default parameters for the evaluation module\n    eval_params = support_modules[\"eval\"]\n\n    # Get default parameters for the speed measurement module\n    speed_params = support_modules[\"speed\"]\n\n    # Get default parameters for the evaluation module\n    filter_params = support_modules[\"filter\"]\n\n    # Get default parameters for the selection module\n    select_params = support_modules[\"select\"]\n\n    # Get the default parameters for the prompt maker module\n    prompt_maker_params = prompt_maker_params[\"default\"]\n\n    # Get the default parameters for the generation module\n    gen_params = gen_params[\"default\"]\n\n    # Get the default parameters for the evaluation module\n    eval_params = eval_params[\"default\"]\n\n    # Get the default parameters for the speed measurement module\n    speed_params = speed_params[\"default\"]\n\n    # Get the default parameters for the evaluation module\n    filter_params = filter_params[\"default\"]\n\n    # Get the default parameters for the selection module\n    select_params = select_params[\"default\"]\n\n    # Get the default parameters for the prompt maker module\n    prompt_maker_params = prompt_maker_params[\"default\"]\n\n    # Get the default parameters for the generation module"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create necessary directories\n    os.makedirs(node_line_dir, exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, \"results\"), exist_ok=True)\n\n    # Initialize dataframe to store results\n    result_df = pd.DataFrame()\n\n    # Run each prompt maker module with given parameters\n    for module, module_param in zip(modules, module_params):\n        # Create a subdirectory for each prompt maker module\n        module_dir = os.path.join(node_line_dir, module.__name__)\n        os.makedirs(module_dir, exist_ok=True)\n\n        # Run the prompt maker module\n        result = module(**module_param)\n\n        # Save the prompt maker module's results to a csv file\n        result_path = os.path.join(module_dir, \"result.csv\")\n        result.to_csv(result_path)\n\n        # Save the prompt maker module's results to a dataframe\n        result_df = pd.concat([result_df, result])\n\n        # Evaluate the prompt maker module\n        if \"eval_metrics\" in strategies:\n            # Get the evaluation metrics\n            eval_metrics = strategies[\"eval_metrics\"]\n\n            # Evaluate the prompt maker module\n            eval_result = evaluate_generation(result, eval_metrics)\n\n            # Save the evaluation results to a csv file\n            eval_result_path = os.path.join(module_dir, \"eval_result.csv\")\n            eval_result.to_csv(eval_result_path)\n\n            # Save the evaluation results to a dataframe\n            result_df = pd.concat([result_df, eval_result])\n\n        # Measure the prompt maker module's execution speed\n        if \"speed_threshold\" in strategies:\n            # Measure the execution speed\n            speed_result = measure_speed(module, module_param)\n\n            # Save the execution speed results to a csv file\n            speed_result_path = os.path.join("}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # create necessary subdirectories\n    os.makedirs(node_line_dir, exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, \"results\"), exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, \"results\", \"raw\"), exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, \"results\", \"combined\"), exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, \"results\", \"summary\"), exist_ok=True)\n\n    # create a dataframe to store the results\n    result = pd.DataFrame()\n\n    # run the modules\n    for module, params in zip(modules, module_params):\n\n        # create the module's name\n        module_name = module.__name__\n\n        # create the module's directory\n        module_dir = os.path.join(node_line_dir, \"results\", \"raw\", module_name)\n        os.makedirs(module_dir, exist_ok=True)\n\n        # run the module\n        print(f\"Running module: {module_name}\")\n        result_module = module(**params)\n\n        # save the module's results\n        result_module.to_csv(os.path.join(module_dir, \"result.csv\"))\n\n        # append the module's results to the result dataframe\n        result = pd.concat([result, result_module], axis=0)\n\n    # save the result dataframe\n    result.to_csv(os.path.join(node_line_dir, \"results\", \"combined\", \"result.csv\"))\n\n    # evaluate the result dataframe\n    print(\"Evaluating results\")\n    result_eval = evaluate_generation(result)\n\n    # save the result dataframe\n    result_eval.to_csv(os.path.join(node_line_dir, \"results\", \"combined\", \"result_eval.csv\"))\n\n    # combine the result dataframe with the previous result\n    if"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # create necessary directories\n    os.makedirs(node_line_dir, exist_ok=True)\n\n    # create a list of the prompt maker modules' names\n    module_names = [module.__name__ for module in modules]\n\n    # create a list of the prompt maker modules' parameters\n    module_params = deepcopy(module_params)\n\n    # create a list of the prompt maker modules' results\n    module_results = []\n\n    # run each prompt maker module\n    for module, module_param in zip(modules, module_params):\n\n        # create a subdirectory for each prompt maker module\n        module_dir = os.path.join(node_line_dir, module.__name__)\n        os.makedirs(module_dir, exist_ok=True)\n\n        # run the prompt maker module\n        module_result = module(**module_param)\n\n        # save the prompt maker module's results\n        module_result.to_csv(os.path.join(module_dir, 'result.csv'))\n\n        # save the prompt maker module's execution time\n        with open(os.path.join(module_dir, 'execution_time.txt'), 'w') as f:\n            f.write(str(module_param['execution_time']))\n\n        # save the prompt maker module's parameters\n        with open(os.path.join(module_dir, 'parameters.txt'), 'w') as f:\n            for key, value in module_param.items():\n                f.write(f'{key}: {value}\\n')\n\n        # append the prompt maker module's results to the list\n        module_results.append(module_result)\n\n    # create a summary dataframe\n    summary = pd.DataFrame()\n\n    # create a summary column for the prompt maker module names\n    summary['module_name'] = module_names\n\n    # create a summary column for the prompt maker module's parameters\n    summary['parameters'] = module_params\n\n    # create a summary column for the prompt maker module's results\n    summary['result'] = module"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create necessary subdirectories.\n    node_line_dir = pathlib.Path(node_line_dir)\n    node_line_dir.mkdir(parents=True, exist_ok=True)\n    node_line_dir = node_line_dir.as_posix()\n\n    # Create the results directory.\n    results_dir = os.path.join(node_line_dir, 'results')\n    os.makedirs(results_dir, exist_ok=True)\n\n    # Create the summary directory.\n    summary_dir = os.path.join(node_line_dir, 'summary')\n    os.makedirs(summary_dir, exist_ok=True)\n\n    # Create the support directory.\n    support_dir = os.path.join(node_line_dir, 'support')\n    os.makedirs(support_dir, exist_ok=True)\n\n    # Create the dataframe to store results.\n    results_df = pd.DataFrame()\n\n    # Run the prompt maker modules.\n    for module, module_param in zip(modules, module_params):\n        module_name = module.__name__\n\n        # Run the module.\n        module_result = module(**module_param)\n\n        # Save the module's result.\n        module_result_path = os.path.join(results_dir, f'{module_name}.csv')\n        module_result.to_csv(module_result_path, index=False)\n\n        # Update the results dataframe.\n        module_result = module_result.assign(module=module_name)\n        results_df = pd.concat([results_df, module_result], axis=0)\n\n    # Save the results dataframe.\n    results_df_path = os.path.join(results_dir, 'results.csv')\n    results_df.to_csv(results_df_path, index=False)\n\n    # Evaluate the prompt maker modules.\n    for module, module_param in zip(modules, module_params):\n        module_name = module.__name__\n\n        # Get the module"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create directories if they do not exist\n    os.makedirs(node_line_dir, exist_ok=True)\n\n    # Create a subdirectory for the results of each prompt maker module\n    for module in modules:\n        os.makedirs(os.path.join(node_line_dir, module.__name__), exist_ok=True)\n\n    # Create a subdirectory for the results of each prompt maker module\n    for module in modules:\n        os.makedirs(os.path.join(node_line_dir, module.__name__), exist_ok=True)\n\n    # Create a subdirectory for the results of each prompt maker module\n    for module in modules:\n        os.makedirs(os.path.join(node_line_dir, module.__name__), exist_ok=True)\n\n    # Run all modules with given parameters\n    for module, params in zip(modules, module_params):\n\n        # Run the module with given parameters\n        result = module(**params)\n\n        # Save the result to a csv file\n        result.to_csv(os.path.join(node_line_dir, module.__name__, \"result.csv\"), index=False)\n\n        # Save the execution time to a csv file\n        pd.DataFrame(data=[[module.__name__, params, measure_speed(result)]],\n                     columns=[\"module\", \"parameters\", \"execution_time\"]).to_csv(\n            os.path.join(node_line_dir, module.__name__, \"execution_time.csv\"), index=False)\n\n        # Save the evaluation metrics to a csv file\n        pd.DataFrame(data=[[module.__name__, params, cast_metrics(result)]],\n                     columns=[\"module\", \"parameters\", \"metrics\"]).to_csv(\n            os.path.join(node_line_dir, module.__name__, \"metrics.csv\"), index=False)\n\n    # Combine the results of all modules\n    all_results = pd.concat([pd.read_csv(os.path.join(node_line_dir, module.__name__,"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create directories\n    node_line_dir = pathlib.Path(node_line_dir)\n    node_line_dir.mkdir(parents=True, exist_ok=True)\n    prompt_maker_dir = node_line_dir / \"prompt_maker\"\n    prompt_maker_dir.mkdir(parents=True, exist_ok=True)\n\n    # Create a copy of the previous result\n    previous_result = previous_result.copy()\n\n    # Run prompt maker modules\n    results = []\n    for module, params in zip(modules, module_params):\n        print(f\"Running {module.__name__} with params {params}\")\n        result = measure_speed(module, params)\n        result = filter_by_threshold(result, strategies[\"speed_threshold\"])\n        results.append(result)\n\n    # Select the best prompt maker module based on specified strategies\n    results = pd.concat(results)\n    best_prompt_maker = select_best_average(results, strategies[\"metrics\"])\n\n    # Evaluate the best prompt maker module\n    best_prompt_maker_params = best_prompt_maker[\"params\"].iloc[0]\n    best_prompt_maker_result = measure_speed(best_prompt_maker[\"module\"], best_prompt_maker_params)\n    best_prompt_maker_result = evaluate_generation(best_prompt_maker_result, strategies[\"eval_params\"])\n    best_prompt_maker_result = filter_by_threshold(best_prompt_maker_result, strategies[\"speed_threshold\"])\n\n    # Combine the best prompt maker's result with the previous result\n    combined_result = pd.concat([previous_result, best_prompt_maker_result])\n\n    # Save the results and a summary, including execution times and evaluation metrics, to the specified directory\n    combined_result.to_csv(prompt_maker_dir / \"result.csv\")\n    with open(prompt_maker_dir / \"summary.txt\", \"w\") as f:\n        f."}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # create the necessary directories\n    node_line_dir = pathlib.Path(node_line_dir)\n    node_line_dir.mkdir(parents=True, exist_ok=True)\n    results_dir = node_line_dir / 'results'\n    results_dir.mkdir(parents=True, exist_ok=True)\n\n    # load the previous results\n    if previous_result is not None:\n        previous_result.to_csv(results_dir / 'previous_result.csv', index=False)\n\n    # create a list of all combinations of modules and module params\n    combinations = make_combinations(modules, module_params)\n\n    # initialize the results dataframe\n    results = pd.DataFrame()\n\n    # iterate over the combinations\n    for i, (module, module_param) in enumerate(combinations):\n        # create a subdirectory for the current module\n        module_dir = results_dir / f'module_{i}'\n        module_dir.mkdir(parents=True, exist_ok=True)\n\n        # run the current module\n        print(f'Running module {module.__name__} with params {module_param}')\n        result = module(**module_param)\n\n        # save the results\n        result.to_csv(module_dir / 'result.csv', index=False)\n\n        # evaluate the results\n        if 'evaluation_metric' in strategies:\n            print('Evaluating results')\n            result = evaluate_generation(result, strategies['evaluation_metric'])\n\n        # measure the execution time\n        if 'speed_threshold' in strategies:\n            print('Measuring execution time')\n            result = measure_speed(result, strategies['speed_threshold'])\n\n        # filter the results by speed\n        if 'speed_threshold' in strategies:\n            print('Filtering results by speed')\n            result = filter_by_threshold(result, 'speed', strategies['speed_threshold'])\n\n        # select the best average\n        if 'select_best_average' in strategies:\n            print('Selecting best"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # create necessary directories\n    os.makedirs(os.path.join(node_line_dir, 'results'), exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, 'summary'), exist_ok=True)\n\n    # create a list of combinations of prompt maker modules and their parameters\n    module_combinations = make_combinations(modules, module_params)\n\n    # create a dataframe to store the results of the execution\n    results_df = pd.DataFrame()\n\n    # run each module and evaluate its performance\n    for module_combination in module_combinations:\n\n        # get the module and its parameters\n        module = module_combination[0]\n        params = module_combination[1]\n\n        # run the module and get its results\n        result = module(**params)\n\n        # evaluate the results\n        eval_result = evaluate_generation(result, **strategies['evaluation'])\n\n        # create a dictionary to store the results\n        result_dict = {'module': module.__name__,\n                       'params': params,\n                       'speed': measure_speed(module, params),\n                       **eval_result}\n\n        # create a dataframe from the results dictionary\n        result_df = pd.DataFrame(result_dict, index=[0])\n\n        # append the results to the dataframe\n        results_df = results_df.append(result_df, ignore_index=True)\n\n        # save the results to the results directory\n        result_df.to_csv(os.path.join(node_line_dir, 'results', f'{module.__name__}.csv'), index=False)\n\n    # save the results to the results directory\n    results_df.to_csv(os.path.join(node_line_dir, 'results', 'results.csv'), index=False)\n\n    # select the best module based on the specified strategies\n    best_module = select_best_average(results_df, strategies['selection'])\n\n    # get the best module's results\n    best_result = results_"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = []\n    for node in nodes:\n        values.extend(extract_values(node, key))\n    return list(set(values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = []\n    for node in nodes:\n        values.extend(extract_values(node, key))\n    return list(set(values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = []\n    for node in nodes:\n        values.extend(extract_values(node, key))\n    return list(set(values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = []\n    for node in nodes:\n        values.extend(extract_values(node, key))\n    return list(set(values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = []\n    for node in nodes:\n        values.extend(extract_values(node, key))\n    return list(set(values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(itertools.chain.from_iterable(list(map(lambda x: extract_values(x, key), nodes))))\n    return list(set(values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda node: extract_values(node, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(itertools.chain.from_iterable(list(map(lambda x: extract_values(x, key), nodes))))\n    return list(set(values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = []\n    for node in nodes:\n        values.extend(extract_values(node, key))\n    return list(set(values))\n\n"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = []\n    for node in nodes:\n        values.extend(extract_values(node, key))\n    return list(set(values))\n\n"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = []\n    for node in nodes:\n        values.extend(extract_values(node, key))\n    return list(set(values))\n\n"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = []\n    for node in nodes:\n        node_values = extract_values(node, key)\n        values.extend(node_values)\n    return list(set(values))\n\n"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = []\n    for node in nodes:\n        values.extend(extract_values(node, key))\n    return list(set(values))\n\n"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(itertools.chain.from_iterable(list(map(lambda x: extract_values(x, key), nodes))))\n    return list(set(values))\n\n"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    # Get the list of values associated with the specified key from each node's module_param\n    values = [extract_values(node, key) for node in nodes]\n\n    # Flatten the list of lists of values\n    values = list(itertools.chain.from_iterable(values))\n\n    # Remove duplicate values\n    values = list(set(values))\n\n    return values\n\n"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = []\n    for node in nodes:\n        values.extend(extract_values(node, key))\n    return list(set(values))\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_model('all-mpnet-base-v2')\n\n    gt_embeddings = list(map(lambda x: embedding_model.encode(x), generation_gt))\n    pred_embedding = embedding_model.encode(pred)\n\n    return max(list(map(lambda x: calculate_cosine_similarity(x, pred_embedding), gt_embeddings)))\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if not embedding_model:\n        embedding_model = embedding_models.load('all-mpnet-base-v2')\n\n    gt_embeddings = list(map(lambda x: embedding_model.encode(x), generation_gt))\n    pred_embedding = embedding_model.encode(pred)\n    return max(list(map(lambda x: calculate_cosine_similarity(pred_embedding, x), gt_embeddings)))\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_default_model()\n    cos_sim_scores = []\n    for gt in generation_gt:\n        cos_sim_scores.append(calculate_cosine_similarity(gt, pred, embedding_model))\n    return max(cos_sim_scores)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_model('all-mpnet-base-v2')\n\n    return max(list(map(lambda x: calculate_cosine_similarity(embedding_model.encode(pred), embedding_model.encode(x)), generation_gt)))\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_model('all-mpnet-base-v2')\n\n    scores = list(map(lambda x: calculate_cosine_similarity(embedding_model, pred, x), generation_gt))\n    return max(scores)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_model('all-mpnet-base-v2')\n    gt_embeddings = list(map(lambda x: embedding_model.encode(x), generation_gt))\n    pred_embedding = embedding_model.encode(pred)\n    return max(list(map(lambda x: calculate_cosine_similarity(x, pred_embedding), gt_embeddings)))\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_default_model()\n    embedding_model.to(\"cuda\")\n    gt_embeddings = [embedding_model.encode(gt) for gt in generation_gt]\n    pred_embedding = embedding_model.encode(pred)\n    return max(list(map(lambda x: calculate_cosine_similarity(pred_embedding, x), gt_embeddings)))\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_model(\"all-mpnet-base-v2\")\n\n    return max(list(map(lambda x: calculate_cosine_similarity(embedding_model, pred, x), generation_gt)))\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_model('all-mpnet-base-v2')\n\n    return max(list(map(lambda x: calculate_cosine_similarity(pred, x, embedding_model), generation_gt)))\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        model_name = 'all-mpnet-base-v2'\n        embedding_model = embedding_models.get_model(model_name)\n\n    cosine_similarities = list(map(lambda x: calculate_cosine_similarity(pred, x, embedding_model), generation_gt))\n    return max(cosine_similarities)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if not embedding_model:\n        embedding_model = embedding_models.get_model(\"all-mpnet-base-v2\")\n    return max(list(map(lambda x: calculate_cosine_similarity(embedding_model.encode(pred), embedding_model.encode(x)),\n                        generation_gt)))\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_default_model()\n\n    return max(list(map(lambda x: calculate_cosine_similarity(embedding_model.encode(pred), embedding_model.encode(x)), generation_gt)))\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_model(\"all-mpnet-base-v2\")\n\n    return max(list(map(lambda x: calculate_cosine_similarity(embedding_model, pred, x), generation_gt)))\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.load_default_model()\n\n    return max(list(map(\n        lambda x: calculate_cosine_similarity(embedding_model.encode(pred), embedding_model.encode(x)), generation_gt)))\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if not embedding_model:\n        embedding_model = embedding_models.get_model('all-mpnet-base-v2')\n    return max(list(map(lambda x: calculate_cosine_similarity(embedding_model, x, pred), generation_gt)))\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.load_model('all-mpnet-base-v2')\n\n    return max(list(map(lambda x: calculate_cosine_similarity(embedding_model, pred, x), generation_gt)))\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if not embedding_model:\n        embedding_model = embedding_models.get_model('all-mpnet-base-v2')\n\n    # convert strings to embeddings\n    gt_embeddings = list(map(embedding_model.encode, generation_gt))\n    pred_embedding = embedding_model.encode(pred)\n\n    # calculate cosine similarity\n    return max(list(map(lambda x: calculate_cosine_similarity(pred_embedding, x), gt_embeddings)))\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.load_default_model()\n\n    gt_embeddings = embedding_model.encode_sentences(generation_gt)\n    pred_embedding = embedding_model.encode_sentences([pred])\n\n    return max(list(map(lambda x: calculate_cosine_similarity(pred_embedding[0], x), gt_embeddings)))\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_model('all-mpnet-base-v2')\n    cos_sim_scores = []\n    for gt in generation_gt:\n        cos_sim_scores.append(calculate_cosine_similarity(pred, gt, embedding_model))\n    return max(cos_sim_scores)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_model('all-mpnet-base-v2')\n\n    def compute_score(gt: str, pred: str) -> float:\n        return calculate_cosine_similarity(embedding_model.encode(gt), embedding_model.encode(pred))\n\n    return max(list(map(lambda x: compute_score(x, pred), generation_gt)))\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer not set up\")\n        return np_image\n\n    return gfpgan_face_restorer.restore(np_image)\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer not set up, returning original image\")\n        return np_image\n    return gfpgan_face_restorer.restore(np_image)\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN not set up\")\n        return np_image\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.Error as err:\n        logger.warning(err)\n        return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        logger.warning(\n            \"GFPGAN face restorer is not set up. Cannot restore faces.\"\n        )\n        return np_image\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except Exception as e:\n        logger.warning(f\"Failed to restore faces: {e}\")\n        return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer not set up. Returning original image.\")\n        return np_image\n\n    return gfpgan_face_restorer.restore(np_image)\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer not set up, skipping face restoration\")\n        return np_image\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.Error as e:\n        logger.warning(f\"GFPGAN face restoration failed with error: {e}\")\n        return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer is not set up, so faces will not be restored.\")\n        return np_image\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.FaceRestoreError as e:\n        logger.warning(f\"GFPGAN face restorer failed with the following error: {e}\")\n        return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer is not set up. Returning the original image.\")\n        return np_image\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except Exception as e:\n        logger.warning(\"GFPGAN face restorer failed to restore faces in the image. Returning the original image.\")\n        logger.warning(e)\n        return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer is not set up, so faces are not restored\")\n        return np_image\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except Exception as e:\n        logger.warning(f\"Failed to restore faces in the image: {e}\")\n        return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer not set up, unable to restore faces\")\n        return np_image\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.ModelLoadingError:\n        logger.warning(\"GFPGAN face restorer failed to load, unable to restore faces\")\n        return np_image\n    except Exception as e:\n        logger.warning(f\"GFPGAN face restorer failed with exception: {e}\")\n        return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer is not set up. Cannot restore faces.\")\n        return np_image\n\n    return gfpgan_face_restorer.restore(np_image)\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer is not set up, cannot restore faces\")\n        return np_image\n\n    return gfpgan_face_restorer.restore(np_image)\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer is not set up. Cannot perform face restoration.\")\n        return np_image\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except Exception as e:\n        logger.warning(f\"GFPGAN face restorer failed with error: {e}\")\n        return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN not set up, skipping face restoration\")\n        return np_image\n    return gfpgan_face_restorer.restore(np_image)\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer not set up. Cannot restore faces.\")\n        return np_image\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.FaceRestorationError as e:\n        logger.warning(f\"Error while restoring faces: {e}\")\n        return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer is not set up, cannot restore faces\")\n        return np_image\n\n    return gfpgan_face_restorer.restore(np_image)\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer is not set up, so faces will not be restored.\")\n        return np_image\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.FaceRestoreError as e:\n        logger.warning(f\"GFPGAN face restoration failed with error: {e}\")\n        return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\n            \"GFPGAN is not set up. Cannot restore faces in the image.\"\n        )\n        return np_image\n\n    return gfpgan_face_restorer.restore(np_image)\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\n            \"GFPGAN face restorer is not set up. Cannot restore faces.\"\n        )\n        return np_image\n\n    return gfpgan_face_restorer.restore(np_image)\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer is not set up. Returning original image.\")\n        return np_image\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except Exception as e:\n        logger.warning(\"GFPGAN face restorer failed. Returning original image.\")\n        logger.warning(e)\n        return np_image\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.ModelError as e:\n        logger.error(e)\n        codeformer = None"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.ModelError as e:\n        logger.error(f\"Error setting up CodeFormer: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.ModelError as e:\n        logger.error(f\"CodeFormer: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.ModelError as e:\n        logger.error(f\"Error while setting up codeformer: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.ModelError as e:\n        logger.error(f\"Failed to setup CodeFormer model: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.ModelError as e:\n        logger.error(f\"Codeformer model could not be initialized: {e}\")\n        codeformer = None"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(model_path=dirname)\n    except errors.ModelLoadingError as e:\n        logger.error(f\"CodeFormer model loading error: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except (errors.ModelLoadingError, errors.ModelInitializationError, errors.ModelRuntimeError) as e:\n        logger.warning(f\"Could not set up CodeFormer model: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except (errors.ModelLoadingError, errors.ModelInitializingError, errors.ModelUsingError) as e:\n        logger.error(f\"Failed to set up CodeFormer model: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except (errors.ModelError, errors.ModelFileError, errors.ModelFormatError, errors.ModelNotSupportedError) as e:\n        logger.error(f\"Codeformer model could not be initialized: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except (errors.ModelError, errors.ModelFileError) as err:\n        logger.error(f\"CodeFormer model could not be loaded: {err}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.ModelError as e:\n        logger.error(f\"CodeFormer: {e}\")\n    except Exception as e:\n        logger.error(f\"CodeFormer: {e}\")\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    codeformer = FaceRestorerCodeFormer(dirname)\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    codeformer = FaceRestorerCodeFormer(dirname)\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.ModelLoadError as e:\n        logger.error(f\"Could not load CodeFormer model: {e}\")\n    except Exception as e:\n        logger.error(f\"Could not initialize CodeFormer model: {e}\")\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        global codeformer\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.ModelLoadError as e:\n        logger.error(f'Failed to initialize CodeFormer model: {e}')\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.ModelError as e:\n        logger.error(f\"CodeFormer model error: {e}\")\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.ModelError as e:\n        logger.error(e)\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except (errors.ModelError, errors.ModelNotFoundError) as e:\n        logger.error(f\"CodeFormer: {e}\")\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n        codeformer.setup_net()\n    except errors.ModelSetupError as e:\n        logger.error(f\"Could not set up model: {e}\")\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        shared.patch_facexlib(dirname)\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN()\n    except Exception as e:\n        errors.catch_error_and_exit_process(e)"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n    except errors.ModelLoadError as e:\n        logger.warning(f\"Failed to load GFPGAN model: {e}\")\n    except Exception as e:\n        logger.warning(f\"Failed to initialize GFPGAN face restorer: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n    except Exception as e:\n        errors.catch_error(e, \"Failed to setup GFPGAN face restoration\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n    except errors.ModelLoadingError as e:\n        logger.warning(f\"Could not load GFPGAN model: {e}\")\n        gfpgan_face_restorer = None"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n    except errors.ModelLoadError as e:\n        logger.error(f\"Could not load GFPGAN model: {e}\")\n        gfpgan_face_restorer = None\n    except Exception as e:\n        logger.error(f\"Could not initialize GFPGAN face restorer: {e}\")\n        gfpgan_face_restorer = None\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n    except errors.ModelLoadingError as e:\n        logger.error(f\"{e.message}\")\n    except Exception as e:\n        logger.error(f\"Failed to initialize GFPGAN face restorer: {e}\")\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n\n    try:\n        # Patch the facexlib\n        shared.patch_facexlib(dirname)\n    except errors.FacexPatchError as e:\n        logger.warning(f\"Failed to patch facexlib: {e}\")\n        return\n\n    # Initialize the GFPGAN face restorer\n    gfpgan_face_restorer = FaceRestorerGFPGAN(\n        model_path=os.path.join(dirname, \"GFPGANv1.4.pth\"),\n        device=devices.device_gfpgan,\n    )"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n\n    try:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n    except Exception as e:\n        gfpgan_face_restorer = None\n        logger.error(f\"GFPGAN face restorer not set up: {e}\")\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n    except (errors.ModelFileMissing, errors.ModelFileMismatch, errors.ModelNotLoaded):\n        logger.warning(\"GFPGAN face restorer not set up\")\n    except Exception as ex:\n        logger.error(f\"Error setting up GFPGAN face restorer: {ex}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        face_restoration_utils.patch_facexlib(dirname)\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(\n            model_path=os.path.join(dirname, 'GFPGANv1.4.pth'),\n            device=devices.device_gfpgan,\n        )\n        logger.info(\"GFPGAN face restorer successfully set up\")\n    except Exception as e:\n        logger.error(\"Error setting up GFPGAN face restorer\")\n        raise errors.FaceXLibError(e)"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n        gfpgan_face_restorer.setup_model()\n    except (\n        errors.ModelError,\n        errors.ModelNotFoundError,\n        errors.ModelNotLoadedError,\n        errors.ModelNotSavedError,\n        errors.ModelNotTrainedError,\n        errors.ModelTrainError,\n        errors.ModelValidationError,\n    ) as e:\n        logger.error(e)"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        # Patch the facexlib\n        shared.patch_facexlib(dirname)\n    except errors.FacexPatchError as e:\n        logger.error(f\"Failed to patch the facexlib: {e}\")\n        return\n    except Exception as e:\n        logger.error(f\"Failed to patch the facexlib: {e}\")\n        return\n\n    try:\n        # Initialize the GFPGAN face restorer\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN()\n        gfpgan_face_restorer.setup(model_path=os.path.join(dirname, \"GFPGANv1.4.pth\"))\n    except errors.FacexModelError as e:\n        logger.error(f\"Failed to initialize the GFPGAN face restorer: {e}\")\n        return\n    except Exception as e:\n        logger.error(f\"Failed to initialize the GFPGAN face restorer: {e}\")\n        return"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(model_path=dirname)\n    except errors.ModelLoadingError as e:\n        logger.error(f\"Error loading GFPGAN model: {e}\")\n        gfpgan_face_restorer = None\n    except Exception as e:\n        logger.error(f\"Unexpected error loading GFPGAN model: {e}\")\n        gfpgan_face_restorer = None\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n    except errors.ModelFileNotFoundError as e:\n        logger.error(f\"{e.__class__.__name__}: {e}\")\n    except Exception as e:\n        logger.error(f\"{e.__class__.__name__}: {e}\")\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        shared.patch_facexlib_dir(dirname)\n    except Exception as e:\n        logger.error(\"Error patching facexlib with GFPGAN model directory: %s\", e)\n        raise errors.FacexArtistError(\"Error patching facexlib with GFPGAN model directory\")\n\n    try:\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN()\n    except Exception as e:\n        logger.error(\"Error initializing GFPGAN face restorer: %s\", e)\n        raise errors.FacexArtistError(\"Error initializing GFPGAN face restorer\")\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        face_restoration_utils.patch_facexlib(dirname)\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(\n            model_path=os.path.join(dirname, \"GFPGANv1.4.pth\"),\n            device=devices.device_gfpgan,\n        )\n    except (errors.ModelError, errors.ModelSetupError) as e:\n        logger.error(f\"{e.__class__.__name__}: {e}\")\n    except Exception as e:\n        logger.error(f\"{e.__class__.__name__}: {e}\")\n        logger.error(f\"Unexpected error occurred while setting up GFPGAN model\")\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n    except errors.ModelError as e:\n        logger.error(f\"{e}\")\n    except Exception as e:\n        logger.error(f\"Failed to initialize GFPGAN model: {e}\")\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        face_restoration_utils.patch_facexlib(dirname)\n    except errors.FacexlibPatchError:\n        logger.error(\"Failed to patch facexlib\", exc_info=True)\n        return\n\n    try:\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n    except Exception:\n        logger.error(\"Failed to initialize GFPGAN face restorer\", exc_info=True)\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n\n    if not dirname:\n        raise ValueError(\"No directory specified\")\n\n    try:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n    except errors.ModelLoadError as e:\n        logger.error(f\"Error loading GFPGAN model: {e}\")\n    except Exception as e:\n        logger.error(f\"Error setting up GFPGAN face restorer: {e}\")\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion\n  v_q = jnp.concatenate([jnp.zeros(v.shape[:-1] + (1,)), v], axis=-1)\n\n  # Convert the quaternion into a rotation matrix\n  R = quat2rotmat(q)\n\n  # Rotate the vector\n  v_rotated = jnp.matmul(R, v_q)\n\n  # Return the rotated vector\n  return v_rotated[Ellipsis, 1:]\n\n"}
{"namespace": "quaternion.rotate", "completion": "  q_v = jnp.concatenate([v, jnp.zeros(v.shape[:-1] + (1,))], axis=-1)\n  return multiply(multiply(q, q_v), inverse(q))[..., :-1]\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector into a quaternion\n  v_quat = jnp.concatenate([jnp.zeros(v.shape[:-1]), v], axis=-1)\n\n  # Apply the rotation\n  v_rotated_quat = multiply(q, multiply(v_quat, conjugate(q)))\n\n  # Convert the quaternion back into a vector\n  return v_rotated_quat[Ellipsis, 1:]\n\n"}
{"namespace": "quaternion.rotate", "completion": "  v = jnp.concatenate([v, jnp.ones_like(v[..., 0:1])], axis=-1)\n  v = multiply(q, v)\n  v = multiply(v, conjugate(q))\n  return v[..., :-1]\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector into a quaternion\n  v_q = jnp.concatenate([jnp.zeros(v.shape[:-1] + (1,)), v], axis=-1)\n\n  # Apply the rotation\n  v_q_rot = multiply(multiply(q, v_q), inverse(q))\n\n  # Return the rotated vector\n  return v_q_rot[Ellipsis, 1:]\n\n"}
{"namespace": "quaternion.rotate", "completion": "  v_ = jnp.concatenate([v, jnp.array([0])])\n  q_ = jnp.concatenate([jnp.array([0]), q])\n  v_prime = multiply(multiply(q_, v_), inverse(q_))\n  return v_prime[:-1]\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector into a quaternion.\n  v_q = jnp.concatenate([jnp.zeros(v.shape[:-1] + (1,)), v], axis=-1)\n\n  # Apply the rotation.\n  r_v_q = multiply(q, v_q)\n\n  # Convert the quaternion back into a vector.\n  r_v = im(r_v_q)\n\n  return r_v\n\n"}
{"namespace": "quaternion.rotate", "completion": "  q = jnp.array(q)\n  v = jnp.array(v)\n  v = jnp.append(v, 0)\n  v = normalize(v)\n  v = multiply(q, v)\n  v = multiply(v, conjugate(q))\n  return v[:-1]\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert vector to quaternion.\n  v_q = jnp.zeros(4)\n  v_q = jnp.concatenate([v, jnp.array([0])], axis=-1)\n  # Convert quaternion to rotation matrix.\n  R = quat2rotmat(q)\n  # Rotate vector.\n  v_rot = R @ v_q\n  # Convert back to vector.\n  v_rot = v_rot[0:3]\n  return v_rot\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector into a quaternion\n  v = jnp.concatenate([jnp.zeros(v.shape[:-1] + (1,)), v], axis=-1)\n\n  # Apply the quaternion rotation\n  v = multiply(q, v)\n\n  # Convert the quaternion back into a vector\n  return v[..., 1:]\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector into a quaternion\n  v_quat = jnp.concatenate([jnp.zeros(v.shape[:-1] + (1,)), v], axis=-1)\n\n  # Apply the rotation\n  v_rot = multiply(multiply(q, v_quat), inverse(q))\n\n  # Return the rotated vector\n  return v_rot[Ellipsis, 1:]\n\n"}
{"namespace": "quaternion.rotate", "completion": "  q_v = jnp.concatenate([v, jnp.zeros(v.shape[:-1] + (1,))], axis=-1)\n  return multiply(multiply(q, q_v), inverse(q))[..., :-1]\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert vector to quaternion\n  v_q = jnp.concatenate([jnp.zeros(v.shape[:-1]), v], axis=-1)\n\n  # Apply rotation\n  v_q = multiply(q, v_q)\n  v_q = multiply(v_q, inverse(q))\n\n  # Convert quaternion back to vector\n  return v_q[Ellipsis, 1:]\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion\n  v = jnp.concatenate([v, jnp.array([0])], axis=-1)\n\n  # Apply the rotation\n  v = multiply(q, v)\n  v = multiply(v, inverse(q))\n\n  # Return the vector\n  return im(v)\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion\n  v = jnp.concatenate([jnp.zeros(q.shape[:-1] + (1,)), v], axis=-1)\n\n  # Apply the rotation\n  v = multiply(q, v)\n  v = multiply(v, inverse(q))\n\n  # Return the rotated vector\n  return v[..., 1:]\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector into a quaternion\n  v_q = jnp.concatenate([jnp.zeros(v.shape[:-1]), v], axis=-1)\n\n  # Apply the rotation\n  v_q_rot = multiply(q, multiply(v_q, conjugate(q)))\n\n  # Extract the vector from the quaternion\n  v_rot = v_q_rot[Ellipsis, 1:]\n\n  return v_rot\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion\n  v_quat = jnp.concatenate([jnp.zeros(v.shape[:-1] + (1,)), v], axis=-1)\n\n  # Apply the rotation\n  v_rotated = multiply(multiply(q, v_quat), conjugate(q))\n\n  # Return the rotated vector\n  return v_rotated[Ellipsis, 1:]\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Create a quaternion from the vector\n  q_vector = jnp.concatenate([jnp.zeros(q.shape[:-1]), v], axis=-1)\n\n  # Rotate the vector using the quaternion\n  q_vector_rotated = multiply(multiply(q, q_vector), inverse(q))\n\n  # Return the vector\n  return q_vector_rotated[Ellipsis, 1:]\n\n"}
{"namespace": "quaternion.rotate", "completion": "  q_v = jnp.concatenate([v, jnp.zeros(v.shape[:-1] + (1,))], axis=-1)\n  return multiply(multiply(q, q_v), inverse(q))[..., :-1]\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion\n  v_quat = jnp.concatenate([jnp.zeros(q.shape[:-1]), v], axis=-1)\n\n  # Apply the rotation\n  v_rotated = multiply(multiply(q, v_quat), inverse(q))\n\n  # Return the rotated vector\n  return v_rotated[Ellipsis, 1:]\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis_angle = jnp.array(axis_angle)\n  axis_angle = axis_angle / jnp.linalg.norm(axis_angle)\n\n  angle = jnp.linalg.norm(axis_angle)\n  axis = axis_angle / (angle + eps)\n\n  s = jnp.sin(angle / 2)\n  c = jnp.cos(angle / 2)\n\n  return jnp.concatenate([axis * s, [c]], axis=-1)\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis_angle = jnp.array(axis_angle)\n  angle = jnp.linalg.norm(axis_angle)\n  axis = axis_angle / (angle + eps)\n  s = jnp.sin(angle)\n  c = jnp.cos(angle)\n  return jnp.concatenate([axis * s, [c]])\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  angle = jnp.linalg.norm(axis_angle, axis=-1, keepdims=True)\n  axis = axis_angle / (angle + eps)\n  s = jnp.sin(angle)\n  c = jnp.cos(angle)\n  return jnp.concatenate([axis * s, [c]], axis=-1)\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis_angle = jnp.asarray(axis_angle)\n  axis = axis_angle[:3]\n  angle = axis_angle[3]\n\n  axis = axis / jnp.linalg.norm(axis)\n\n  s = jnp.sin(angle / 2)\n  c = jnp.cos(angle / 2)\n\n  return jnp.concatenate([axis * s, [c]])\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis_angle = jnp.asarray(axis_angle)\n  angle = jnp.linalg.norm(axis_angle)\n  axis = axis_angle / (angle + eps)\n\n  s = jnp.sin(angle)\n  c = jnp.cos(angle)\n\n  return jnp.concatenate([axis * s, [c]])\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  # Get the angle.\n  angle = jnp.linalg.norm(axis_angle)\n\n  # Normalize the axis.\n  axis = axis_angle / (angle + eps)\n\n  # Get the sine and cosine of the angle.\n  s = jnp.sin(angle)\n  c = jnp.cos(angle)\n\n  # Get the quaternion.\n  return jnp.concatenate((axis * s, [c]), axis=-1)\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  # Normalize the axis-angle vector.\n  axis_angle = spin_math.normalize(axis_angle)\n\n  # Compute the rotation angle.\n  angle = jnp.linalg.norm(axis_angle)\n\n  # Compute the quaternion.\n  quaternion = jnp.concatenate(\n      [\n          jnp.cos(angle / 2),\n          axis_angle * jnp.sin(angle / 2) / (angle + eps),\n      ],\n      axis=-1,\n  )\n\n  return quaternion\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis_angle = jnp.array(axis_angle)\n\n  axis_angle = axis_angle / jnp.linalg.norm(axis_angle)\n\n  angle = jnp.linalg.norm(axis_angle)\n\n  axis = axis_angle / (angle + eps)\n\n  s = jnp.sin(angle)\n  c = jnp.cos(angle)\n\n  w = c\n  x = axis[0] * s\n  y = axis[1] * s\n  z = axis[2] * s\n\n  return jnp.array([x, y, z, w])\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis_angle = jnp.array(axis_angle)\n  angle = jnp.linalg.norm(axis_angle)\n  axis = axis_angle / (angle + eps)\n  s = jnp.sin(angle)\n  c = jnp.cos(angle)\n  return jnp.concatenate([axis * s, [c]])\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis, angle = axis_angle[..., :3], axis_angle[..., 3]\n  axis = axis / jnp.linalg.norm(axis, axis=-1, keepdims=True)\n  angle = angle / 2.0\n  return jnp.concatenate(\n      [jnp.cos(angle)[..., jnp.newaxis],\n       jnp.sin(angle)[..., jnp.newaxis] * axis],\n      axis=-1)\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  theta = linalg.norm(axis_angle, axis=-1, keepdims=True)\n  axis = axis_angle / jnp.maximum(theta, eps)\n  s = jnp.sin(0.5 * theta)\n  c = jnp.cos(0.5 * theta)\n  return jnp.concatenate([s * axis, c], axis=-1)\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis, angle = axis_angle[..., :3], axis_angle[..., 3:]\n  axis /= jnp.linalg.norm(axis, axis=-1, keepdims=True)\n  angle = angle[..., None]\n  half_angle = angle * 0.5\n  s = jnp.sin(half_angle)\n  c = jnp.cos(half_angle)\n  return jnp.concatenate([axis * s, c], axis=-1)\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis_angle = jnp.asarray(axis_angle)\n  axis = axis_angle[:3]\n  angle = axis_angle[3]\n  axis /= jnp.linalg.norm(axis) + eps\n  s = jnp.sin(angle / 2)\n  c = jnp.cos(angle / 2)\n  return jnp.concatenate([axis * s, [c]], axis=-1)\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  # Normalize the axis-angle vector to have unit length\n  axis_norm = jnp.linalg.norm(axis_angle)\n  axis = axis_angle / axis_norm\n\n  # Calculate the rotation angle\n  angle = axis_norm / 2\n\n  # Calculate the sine and cosine of the rotation angle\n  s = jnp.sin(angle)\n  c = jnp.cos(angle)\n\n  # Calculate the quaternion\n  w = c\n  x = axis[0] * s\n  y = axis[1] * s\n  z = axis[2] * s\n\n  return jnp.array([x, y, z, w])\n\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  # Normalize the axis-angle vector to have unit length\n  axis_angle = spin_math.normalize(axis_angle, eps = eps)\n\n  # Extract the axis and angle from the axis-angle vector\n  axis = axis_angle[Ellipsis, :3]\n  angle = axis_angle[Ellipsis, 3:]\n\n  # Compute the quaternion from the axis and angle\n  return jnp.concatenate([jnp.cos(angle / 2), axis * jnp.sin(angle / 2)], axis = -1)\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis_angle = jnp.array(axis_angle)\n  axis = axis_angle[..., 0:3]\n  angle = axis_angle[..., 3]\n\n  # Normalize axis\n  axis_norm = jnp.linalg.norm(axis, axis=-1, keepdims=True)\n  axis = axis / (axis_norm + eps)\n\n  # Build quaternion\n  quaternion = jnp.concatenate((jnp.cos(angle / 2), jnp.sin(angle / 2) * axis), axis=-1)\n\n  return quaternion\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  # The axis-angle vector is normalized to unit length.\n  axis_angle = spin_math.normalize(axis_angle)\n  # The angle is clamped to the range of valid values.\n  angle = jnp.clip(jnp.linalg.norm(axis_angle), eps, jnp.pi)\n  # The quaternion is calculated as the cosine of the angle multiplied by the unit quaternion.\n  quaternion = jnp.concatenate([jnp.cos(angle/2), jnp.sin(angle/2) * axis_angle])\n  return quaternion\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  # Normalize the axis-angle vector.\n  axis_angle = spin_math.normalize(axis_angle, eps=eps)\n  # Calculate the angle.\n  angle = jnp.linalg.norm(axis_angle, axis=-1, keepdims=True)\n  # Calculate the quaternion.\n  quaternion = jnp.concatenate(\n      [jnp.cos(angle / 2.0), jnp.sin(angle / 2.0) * axis_angle], axis=-1\n  )\n  return quaternion\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  # Convert the axis-angle vector to a quaternion.\n  # The quaternion is normalized, so we don't need to normalize it again.\n  theta = jnp.linalg.norm(axis_angle)\n  axis = axis_angle / (theta + eps)\n  half_theta = theta * 0.5\n  s = jnp.sin(half_theta)\n  c = jnp.cos(half_theta)\n  return jnp.concatenate([axis * s, [c]], axis=-1)\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  angle = jnp.linalg.norm(axis_angle)\n  axis = axis_angle / (angle + eps)\n  s = jnp.sin(angle / 2)\n  c = jnp.cos(angle / 2)\n  return jnp.concatenate([axis * s, [c]], axis=-1)\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    num_calls = k\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    mid = (high + 0) / 2\n    while high >= 0 + 1e-8:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return -mid, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    num_calls = k\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    while True:\n        mid = (high + low) / 2\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        num_calls += k\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    num_calls = k\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    low = 0\n    mid = (high + low) / 2\n    while high >= low + 1e-8:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return -mid, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    num_calls = k\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    while high >= 0:\n        logit_bias[idx] = high\n        if model.argmax(prefix, logit_bias) == idx:\n            return high, num_calls\n        else:\n            high /= 2\n        num_calls += k\n    return -math.inf, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    num_calls = k\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    while high > 0:\n        logit_bias[idx] = high\n        if model.argmax(prefix, logit_bias) == idx:\n            high = 0\n        else:\n            high /= 2\n        num_calls += k\n    return -high, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    num_calls = k\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    while True:\n        logit_bias[idx] = high\n        if model.argmax(prefix, logit_bias) == idx:\n            break\n        high *= 2\n        num_calls += k\n\n    # binary search\n    low = 0\n    mid = (high + low) / 2\n    while high >= low + 1e-8:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return -mid, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    num_calls = k\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    topk_words = model.topk(prefix, logit_bias)\n    success_idxs = list(i for i in idx if i in topk_words)\n    fail_idxs = set(idx) - set(topk_words)\n    biased_top_logprob = max(\n        logprob for i, logprob in topk_words.items() if i not in idx\n    )\n    biased_logprobs = np.array([topk_words[i] for i in success_idxs])\n    logprobs = biased_logprobs - biased_top_logprob\n    return dict(zip(success_idxs, logprobs)), fail_idxs, 1\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    num_calls = k\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    logit_bias[idx] = high\n    topk_words = model.topk(prefix, logit_bias)\n    topk_logprobs = np.array([topk_words[i] for i in topk_words])\n    log_biased_prob = logsumexp(topk_logprobs)\n    logprobs = topk_logprobs - np.logaddexp(\n        high + np.log1p(-np.exp(log_biased_prob)), log_biased_prob\n    )\n    return logprobs[idx], num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    num_calls = k\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    log_prob = 0\n    while True:\n        logit_bias[idx] = high\n        topk_words = model.topk(prefix, logit_bias)\n        if idx in topk_words:\n            log_prob = topk_words[idx]\n            break\n        else:\n            high *= 2\n            num_calls += k\n    return log_prob, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    num_calls = k\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    topk_words = model.topk(prefix, logit_bias)\n    success_idxs = list(i for i in idx if i in topk_words)\n    fail_idxs = set(idx) - set(topk_words)\n    biased_top_logprob = max(\n        logprob for i, logprob in topk_words.items() if i not in idx\n    )\n    biased_logprobs = np.array([topk_words[i] for i in success_idxs])\n    logprobs = biased_logprobs - biased_top_logprob\n    return dict(zip(success_idxs, logprobs)), fail_idxs, 1\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    num_calls = k\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    while high > 0:\n        logit_bias[idx] = high\n        if model.argmax(prefix, logit_bias) == idx:\n            break\n        high /= 2\n        num_calls += k\n    return -high, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    num_calls = 0\n    logit_bias = {idx: high}\n    topk = model.topk(prefix, logit_bias)\n    num_calls += k\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        topk = model.topk(prefix, logit_bias)\n        num_calls += k\n    return topk[idx], num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    num_calls = k\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    logprobs = []\n    for i in range(k):\n        logprobs.append(model.logprob(prefix, logit_bias))\n        num_calls += 1\n\n    # binary search\n    low = logprobs[0]\n    while high >= low + 1e-8:\n        mid = (low + high) / 2\n        logit_bias[idx] = mid\n        logprobs[0] = model.logprob(prefix, logit_bias)\n        num_calls += 1\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n    return -mid, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    num_calls = k\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    topk_words = model.topk(prefix, logit_bias)\n    topk_idx = [i for i in topk_words if i in idx]\n    topk_logprobs = [topk_words[i] for i in topk_idx]\n    topk_logprobs = np.array(topk_logprobs)\n    topk_logprobs = topk_logprobs - logsumexp(topk_logprobs)\n    topk_logprobs = topk_logprobs + np.log(np.arange(len(topk_logprobs)) + 1)\n    topk_logprobs = topk_logprobs - np.log(len(topk_logprobs))\n    topk_logprobs = topk_logprobs[topk_idx.index(idx)]\n    return topk_logprobs, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    num_calls = k\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    while True:\n        logit_bias[idx] = high\n        logprobs = model.topk(prefix, logit_bias, k=k+1)\n        if logprobs[idx] == max(logprobs.values()):\n            break\n        else:\n            high = high * 2\n            num_calls += k\n    return -logprobs[idx], num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    num_calls = k\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    logit_bias[idx] = high\n    topk_words = model.topk(prefix, logit_bias)\n    topk_idxs = [i for i in topk_words if i != idx]\n    topk_logprobs = [topk_words[i] for i in topk_idxs]\n    log_topk_prob = logsumexp(topk_logprobs)\n    log_target_prob = log_topk_prob - math.log(len(topk_logprobs) + 1)\n    target_logprob = log_target_prob + math.log(len(topk_logprobs))\n    return target_logprob, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    num_calls = k\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    while high > 0:\n        logit_bias[idx] = high\n        if model.argmax(prefix, logit_bias) == idx:\n            return high, num_calls\n        else:\n            high /= 2\n        num_calls += k\n\n    return 0, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    num_calls = k\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    log_probs = np.array([model.logprob(prefix, token, logit_bias) for token in model.topk(prefix, logit_bias)])\n    log_probs_max = log_probs.max()\n    log_probs_min = log_probs.min()\n    log_probs_range = log_probs_max - log_probs_min\n    log_probs_range_inv = -log_probs_range\n    log_probs_range_inv_sum = log_probs_range_inv.sum()\n    log_probs_range_inv_sum_inv = -log_probs_range_inv_sum\n    log_probs_range_inv_sum_inv_log = logsumexp([log_probs_range_inv_sum_inv, log_probs_max])\n    log_probs_range_inv_sum_inv_log_inv = -log_probs_range_inv_sum_inv_log\n    log_probs_range_inv_sum_inv_log_inv_log = logsumexp([log_probs_range_inv_sum_inv_log_inv, log_probs_min])\n    log_probs_range_inv_sum_inv_log_inv_log_inv = -log_probs_range_inv_sum_inv_log_inv_log\n\n    # adjust bias\n    logit_bias[idx] = high * math.exp(log_probs_range_inv_sum_inv_log_inv_log_inv)\n\n    # calculate log"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    num_calls = 0\n    # get raw topk, could be done outside and passed in\n    logit_bias = {idx: high}\n    topk_words = model.topk(prefix, logit_bias)\n    topk_words = [i for i in topk_words if i[0] == idx]\n    topk_words = sorted(topk_words, key=lambda x: x[1], reverse=True)\n\n    # check if idx is the argmax\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    if topk_words[0][0] != idx:\n        logit_bias[idx] = high\n        while model.argmax(prefix, logit_bias) != idx:\n            logit_bias[idx] *= 2\n            num_calls += 1\n        high = logit_bias[idx]\n\n    # improve estimate\n    mid = (high + logit_bias[idx]) / 2\n    while high >= logit_bias[idx] + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += 1\n\n    # adjust bias\n    logit_bias[idx] = mid\n    topk_words = model.topk(prefix, logit_bias)\n    topk_words = [i for i in topk_words if i[0] == idx]\n    topk_words = sorted(topk_words, key=lambda x: x[1], reverse=True)\n\n    # calculate log probability\n    log_prob = 0\n    for i in range(k):\n        log_prob += topk_words[i][1]\n    return log_prob, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    num_calls = 0\n    # get topk\n    topk_words = model.topk(prefix, {idx: high})\n    num_calls += 1\n    # get topk idx\n    topk_idx = [i for i, _ in topk_words.items()]\n    # get topk logprobs\n    topk_logprobs = [logprob for _, logprob in topk_words.items()]\n    # get topk logprobs\n    topk_logprobs = np.array(topk_logprobs)\n    # get topk logprobs\n    topk_logprobs = topk_logprobs - logsumexp(topk_logprobs)\n    # get topk probs\n    topk_probs = np.exp(topk_logprobs)\n    # get topk probs\n    topk_probs = topk_probs / sum(topk_probs)\n    # get topk probs\n    topk_probs = list(topk_probs)\n    # get topk probs\n    topk_idx = list(topk_idx)\n    # get topk probs\n    topk_idx[idx] = -1\n    # get topk probs\n    topk_probs[idx] = -1\n    # get topk probs\n    topk_idx = [i for i in topk_idx if i != -1]\n    # get topk probs\n    topk_probs = [i for i in topk_probs if i != -1]\n    # get topk probs\n    topk_probs = np.array(topk_probs)\n    # get topk probs\n    topk_probs = topk_probs / sum(topk_probs)\n    # get topk probs\n    topk_probs = list(topk_probs)\n    # get topk probs\n    topk_idx = list(topk_idx)\n    # get topk probs\n    topk_idx.sort(key=lambda x"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'TRILINEAR':\n    return resample_3d_trilinear(data, locations, edge_behavior, constant_values, coordinate_order, half_pixel_center)\n  elif method == 'NEAREST':\n    return resample_3d_nearest(data, locations, edge_behavior, constant_values, coordinate_order, half_pixel_center)\n  else:\n    raise ValueError('Invalid interpolation method.')\n\n"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'TRILINEAR':\n    return trilinear_interpolation(\n        data,\n        locations,\n        edge_behavior=edge_behavior,\n        constant_values=constant_values,\n        coordinate_order=coordinate_order,\n        half_pixel_center=half_pixel_center,\n    )\n  elif method == 'NEAREST':\n    return nearest_neighbor_interpolation(\n        data,\n        locations,\n        edge_behavior=edge_behavior,\n        constant_values=constant_values,\n        coordinate_order=coordinate_order,\n        half_pixel_center=half_pixel_center,\n    )\n  else:\n    raise ValueError(f'Invalid interpolation method {method}')\n\n"}
{"namespace": "resample.resample_3d", "completion": "  if coordinate_order == 'xyz':\n    x_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    z_coordinate = locations[Ellipsis, 2]\n  elif coordinate_order == 'zyx':\n    z_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    x_coordinate = locations[Ellipsis, 2]\n\n  if half_pixel_center:\n    x_coordinate = x_coordinate + 0.5\n    y_coordinate = y_coordinate + 0.5\n    z_coordinate = z_coordinate + 0.5\n\n  # Use Advanced indexing to gather data data.\n  if method == 'TRILINEAR':\n    x_floor = jnp.floor(x_coordinate)\n    y_floor = jnp.floor(y_coordinate)\n    z_floor = jnp.floor(z_coordinate)\n    x_ceil = x_floor + 1\n    y_ceil = y_floor + 1\n    z_ceil = z_floor + 1\n\n    x_weight = x_coordinate - x_floor\n    y_weight = y_coordinate - y_floor\n    z_weight = z_coordinate - z_floor\n\n    x_weight_ceil = 1 - x_weight\n    y_weight_ceil = 1 - y_weight\n    z_weight_ceil = 1 - z_weight\n\n    x_weight = x_weight[Ellipsis, jnp.newaxis]\n    y_weight = y_weight[Ellipsis, jnp.newaxis]\n    z_weight = z_weight[Ellipsis, jnp.newaxis]\n\n    x_weight_ceil = x_weight_ceil[Ellipsis, jnp.newaxis]\n    y_weight_ceil = y_weight_ceil[Ellipsis, jnp.newaxis]\n    z_weight_ceil = z_weight_ceil[Ellipsis, jnp.newaxis]"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'TRILINEAR':\n    return trilinear_interpolate(\n        data,\n        locations,\n        edge_behavior=edge_behavior,\n        constant_values=constant_values,\n        coordinate_order=coordinate_order,\n        half_pixel_center=half_pixel_center,\n    )\n  elif method == 'NEAREST':\n    return nearest_neighbor_interpolate(\n        data,\n        locations,\n        edge_behavior=edge_behavior,\n        constant_values=constant_values,\n        coordinate_order=coordinate_order,\n        half_pixel_center=half_pixel_center,\n    )\n  else:\n    raise ValueError(\n        'Method must be either TRILINEAR or NEAREST, got {}'.format(method))\n\n"}
{"namespace": "resample.resample_3d", "completion": "  if coordinate_order == 'xyz':\n    x_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    z_coordinate = locations[Ellipsis, 2]\n  elif coordinate_order == 'zyx':\n    z_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    x_coordinate = locations[Ellipsis, 2]\n\n  if half_pixel_center:\n    x_coordinate = x_coordinate + 0.5\n    y_coordinate = y_coordinate + 0.5\n    z_coordinate = z_coordinate + 0.5\n\n  # Compute the sample locations in the input tensor.\n  x_floor = jnp.floor(x_coordinate)\n  y_floor = jnp.floor(y_coordinate)\n  z_floor = jnp.floor(z_coordinate)\n  x_ceil = x_floor + 1\n  y_ceil = y_floor + 1\n  z_ceil = z_floor + 1\n\n  # Compute the interpolation weights.\n  x_weight = x_coordinate - x_floor\n  y_weight = y_coordinate - y_floor\n  z_weight = z_coordinate - z_floor\n\n  # Compute the interpolation weight factors.\n  x_weight_factor = 1.0 - x_weight\n  y_weight_factor = 1.0 - y_weight\n  z_weight_factor = 1.0 - z_weight\n\n  # Compute the indices of the four corners.\n  x_index_floor = x_floor.astype(jnp.int32)\n  y_index_floor = y_floor.astype(jnp.int32)\n  z_index_floor = z_floor.astype(jnp.int32)\n  x_index_ceil = x_ceil.astype(jnp.int32)\n  y_index_ceil = y_ceil.astype(jnp.int32)\n  z"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'NEAREST':\n    return _resample_3d_nearest(data, locations, edge_behavior, constant_values, coordinate_order, half_pixel_center)\n  elif method == 'TRILINEAR':\n    return _resample_3d_trilinear(data, locations, edge_behavior, constant_values, coordinate_order, half_pixel_center)\n  else:\n    raise NotImplementedError('Only \"TRILINEAR\" and \"NEAREST\" interpolation methods are currently supported.')\n\n"}
{"namespace": "resample.resample_3d", "completion": "  # Check if the method is supported.\n  if method not in ['TRILINEAR', 'NEAREST']:\n    raise ValueError('Method must be either TRILINEAR or NEAREST.')\n\n  # Check if the coordinate order is supported.\n  if coordinate_order not in ['xyz', 'zyx']:\n    raise ValueError('Coordinate order must be xyz or zyx.')\n\n  # Check if the edge behavior is supported.\n  if edge_behavior not in ['CONSTANT_OUTSIDE', 'CLAMP']:\n    raise ValueError('Edge behavior must be either CONSTANT_OUTSIDE or CLAMP.')\n\n  # Check if the half pixel centering is supported.\n  if half_pixel_center not in [True, False]:\n    raise ValueError('Half pixel centering must be either True or False.')\n\n  # Check if the edge behavior is supported.\n  if edge_behavior not in ['CONSTANT_OUTSIDE', 'CLAMP']:\n    raise ValueError('Edge behavior must be either CONSTANT_OUTSIDE or CLAMP.')\n\n  # Check if the coordinate order is supported.\n  if coordinate_order not in ['xyz', 'zyx']:\n    raise ValueError('Coordinate order must be xyz or zyx.')\n\n  # Check if the half pixel centering is supported.\n  if half_pixel_center not in [True, False]:\n    raise ValueError('Half pixel centering must be either True or False.')\n\n  # Check if the method is supported.\n  if method not in ['TRILINEAR', 'NEAREST']:\n    raise ValueError('Method must be either TRILINEAR or NEAREST.')\n\n  # Check if the coordinate order is supported.\n  if coordinate_order not in ['xyz', 'zyx']:\n    raise ValueError('Coordinate order must be xyz or zyx.')\n\n  # Check if the edge behavior is supported.\n  if edge_behavior not in ['CONSTANT_OUTSIDE', 'CLAMP']:\n    raise ValueError('"}
{"namespace": "resample.resample_3d", "completion": "  if half_pixel_center:\n    locations = locations + 0.5\n\n  if coordinate_order == 'xyz':\n    x_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    z_coordinate = locations[Ellipsis, 2]\n  elif coordinate_order == 'zyx':\n    z_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    x_coordinate = locations[Ellipsis, 2]\n\n  if method == 'NEAREST':\n    x_coordinate_f = jnp.floor(x_coordinate)\n    y_coordinate_f = jnp.floor(y_coordinate)\n    z_coordinate_f = jnp.floor(z_coordinate)\n\n    x_coordinate_c = jnp.ceil(x_coordinate)\n    y_coordinate_c = jnp.ceil(y_coordinate)\n    z_coordinate_c = jnp.ceil(z_coordinate)\n\n    x_coordinate_d = jnp.abs(x_coordinate - x_coordinate_f)\n    y_coordinate_d = jnp.abs(y_coordinate - y_coordinate_f)\n    z_coordinate_d = jnp.abs(z_coordinate - z_coordinate_f)\n\n    x_coordinate_d = jnp.expand_dims(x_coordinate_d, axis=-1)\n    y_coordinate_d = jnp.expand_dims(y_coordinate_d, axis=-1)\n    z_coordinate_d = jnp.expand_dims(z_coordinate_d, axis=-1)\n\n    data_x_l = gather_volume(data, jnp.stack([z_coordinate_f, y_coordinate_f, x_coordinate_f], axis=-1), coordinate_order)\n    data_x_r = gather_volume(data, jnp.stack([z_coordinate_f, y_coordinate_f, x_coordinate_c], axis=-1), coordinate_order)\n    data_y_"}
{"namespace": "resample.resample_3d", "completion": "  # Check if the input data is in the correct format.\n  if len(data.shape) != 4:\n    raise ValueError('Input data must be a 4D tensor.')\n\n  # Check if the input locations is in the correct format.\n  if len(locations.shape) < 2 or locations.shape[-1] != 3:\n    raise ValueError('Input locations must be a [D, ..., 3] tensor.')\n\n  # Check if the input edge behavior is valid.\n  if edge_behavior not in ['CONSTANT_OUTSIDE', 'CLAMP']:\n    raise ValueError('Input edge behavior must be either CONSTANT_OUTSIDE or CLAMP.')\n\n  # Check if the input coordinate order is valid.\n  if coordinate_order not in ['xyz', 'zyx']:\n    raise ValueError('Input coordinate order must be either xyz or zyx.')\n\n  # Check if the input interpolation method is valid.\n  if method not in ['TRILINEAR', 'NEAREST']:\n    raise ValueError('Input interpolation method must be either TRILINEAR or NEAREST.')\n\n  # Check if the input half-pixel centering is valid.\n  if not isinstance(half_pixel_center, bool):\n    raise ValueError('Input half-pixel centering must be a boolean.')\n\n  # Check if the input data is in the correct format.\n  if len(locations.shape) < 2 or locations.shape[-1] != 3:\n    raise ValueError('Input locations must be a [D, ..., 3] tensor.')\n\n  # Check if the input locations is in the correct format.\n  if len(locations.shape) < 2 or locations.shape[-1] != 3:\n    raise ValueError('Input locations must be a [D, ..., 3] tensor.')\n\n  # Check if the input edge behavior is valid.\n  if edge_behavior not in ['CONSTANT_OUTSIDE', 'CLAMP']:\n    raise ValueError('Input edge behavior must be either CONSTANT_OUTSIDE"}
{"namespace": "resample.resample_3d", "completion": "  # Make sure the input data is a float32 tensor.\n  data = jnp.asarray(data, dtype=jnp.float32)\n\n  # Make sure the input locations is a float32 tensor.\n  locations = jnp.asarray(locations, dtype=jnp.float32)\n\n  # Make sure the edge behavior is a string.\n  edge_behavior = str(edge_behavior)\n\n  # Make sure the constant value is a float.\n  constant_values = float(constant_values)\n\n  # Make sure the coordinate order is a string.\n  coordinate_order = str(coordinate_order)\n\n  # Make sure the interpolation method is a string.\n  method = str(method)\n\n  # Make sure the half pixel centering is a bool.\n  half_pixel_center = bool(half_pixel_center)\n\n  # Make sure the edge behavior is valid.\n  if edge_behavior not in ['CONSTANT_OUTSIDE', 'CLAMP']:\n    raise ValueError('Edge behavior must be CONSTANT_OUTSIDE or CLAMP.')\n\n  # Make sure the coordinate order is valid.\n  if coordinate_order not in ['xyz', 'zyx']:\n    raise ValueError('Coordinate order must be xyz or zyx.')\n\n  # Make sure the interpolation method is valid.\n  if method not in ['TRILINEAR', 'NEAREST']:\n    raise ValueError('Interpolation method must be TRILINEAR or NEAREST.')\n\n  # Make sure the half pixel centering is valid.\n  if not half_pixel_center:\n    raise ValueError('Half pixel centering must be True.')\n\n  # Get the shape of the input data.\n  data_shape = data.shape\n\n  # Get the shape of the input locations.\n  locations_shape = locations.shape\n\n  # Get the number of dimensions of the input data.\n  data_ndim = len(data_shape)\n\n  # Get the number of dimensions of the input locations.\n  locations_ndim = len(locations"}
{"namespace": "resample.resample_3d", "completion": "  if edge_behavior == 'CONSTANT_OUTSIDE':\n    data = jnp.pad(data, [[1, 1], [1, 1], [1, 1], [0, 0]], mode='constant', constant_values=constant_values)\n\n  if half_pixel_center:\n    locations = locations + 0.5\n\n  if coordinate_order == 'xyz':\n    x_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    z_coordinate = locations[Ellipsis, 2]\n  elif coordinate_order == 'zyx':\n    z_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    x_coordinate = locations[Ellipsis, 2]\n\n  # Compute the four corners of the output volume.\n  x_corner_0 = x_coordinate - 0.5\n  x_corner_1 = x_corner_0 + 1\n  y_corner_0 = y_coordinate - 0.5\n  y_corner_1 = y_corner_0 + 1\n  z_corner_0 = z_coordinate - 0.5\n  z_corner_1 = z_corner_0 + 1\n\n  # Compute the interpolation weights.\n  x_weight_0 = 1 - (x_coordinate - x_corner_0)\n  x_weight_1 = x_coordinate - x_corner_1\n  y_weight_0 = 1 - (y_coordinate - y_corner_0)\n  y_weight_1 = y_coordinate - y_corner_1\n  z_weight_0 = 1 - (z_coordinate - z_corner_0)\n  z_weight_1 = z_coordinate - z_corner_1\n\n  # Compute the indices of the four corners.\n  x_corner_0 = jnp.floor(x_corner_0).astype(jnp.int32)"}
{"namespace": "resample.resample_3d", "completion": "  if edge_behavior not in ['CONSTANT_OUTSIDE', 'CLAMP']:\n    raise ValueError(\n        f'edge_behavior must be one of CONSTANT_OUTSIDE or CLAMP. '\n        f'Got: {edge_behavior}')\n\n  if method not in ['TRILINEAR', 'NEAREST']:\n    raise ValueError(\n        f'method must be one of TRILINEAR or NEAREST. Got: {method}')\n\n  if coordinate_order not in ['xyz', 'zyx']:\n    raise ValueError(\n        f'coordinate_order must be one of xyz or zyx. Got: {coordinate_order}')\n\n  if half_pixel_center:\n    locations = locations + 0.5\n\n  if coordinate_order == 'xyz':\n    x_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    z_coordinate = locations[Ellipsis, 2]\n  elif coordinate_order == 'zyx':\n    z_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    x_coordinate = locations[Ellipsis, 2]\n\n  if method == 'TRILINEAR':\n    x_fraction, x_coordinate = jnp.modf(x_coordinate)\n    y_fraction, y_coordinate = jnp.modf(y_coordinate)\n    z_fraction, z_coordinate = jnp.modf(z_coordinate)\n\n    x_coordinate = jnp.asarray(x_coordinate).astype(jnp.int32)\n    y_coordinate = jnp.asarray(y_coordinate).astype(jnp.int32)\n    z_coordinate = jnp.asarray(z_coordinate).astype(jnp.int32)\n\n    x_fraction = jnp.asarray(x_fraction)\n    y_fraction = jnp.asarray(y_fraction)"}
{"namespace": "resample.resample_3d", "completion": "  if edge_behavior == 'CONSTANT_OUTSIDE':\n    data = jnp.pad(data, 1, mode='constant', constant_values=constant_values)\n    data = jnp.asarray(data)\n    locations = locations + 1\n  elif edge_behavior == 'CLAMP':\n    data = jnp.asarray(data)\n    locations = jnp.maximum(locations, 0)\n    locations = jnp.minimum(locations, data.shape[1:4])\n  else:\n    raise ValueError('Edge behavior not supported: ' + edge_behavior)\n\n  if half_pixel_center:\n    locations = locations + 0.5\n\n  if method == 'TRILINEAR':\n    return trilinear_interpolation(data, locations, coordinate_order)\n  elif method == 'NEAREST':\n    return nearest_neighbor_interpolation(data, locations, coordinate_order)\n  else:\n    raise ValueError('Interpolation method not supported: ' + method)\n\n"}
{"namespace": "resample.resample_3d", "completion": "  # Check if the coordinate order is valid.\n  if coordinate_order not in ['xyz', 'zyx']:\n    raise ValueError(\n        'Invalid coordinate order: {}. Must be one of [\"xyz\", \"zyx\"].'.format(\n            coordinate_order))\n\n  # Check if the interpolation method is valid.\n  if method not in ['TRILINEAR', 'NEAREST']:\n    raise ValueError(\n        'Invalid interpolation method: {}. Must be one of [\"TRILINEAR\", \"NEAREST\"].'.format(\n            method))\n\n  # Check if the edge behavior is valid.\n  if edge_behavior not in ['CONSTANT_OUTSIDE', 'CLAMP']:\n    raise ValueError(\n        'Invalid edge behavior: {}. Must be one of [\"CONSTANT_OUTSIDE\", \"CLAMP\"].'.format(\n            edge_behavior))\n\n  # Check if the input data is a tensor.\n  if not isinstance(data, jnp.ndarray):\n    raise TypeError(\n        'Input data must be a tensor. Got {}'.format(type(data)))\n\n  # Check if the input locations is a tensor.\n  if not isinstance(locations, jnp.ndarray):\n    raise TypeError(\n        'Input locations must be a tensor. Got {}'.format(type(locations)))\n\n  # Check if the input locations is a tensor.\n  if not isinstance(locations, jnp.ndarray):\n    raise TypeError(\n        'Input locations must be a tensor. Got {}'.format(type(locations)))\n\n  # Check if the input data is a 4D tensor.\n  if len(data.shape) != 4:\n    raise ValueError(\n        'Input data must be a 4D tensor. Got {}D tensor.'.format(len(data.shape)))\n\n  # Check if the input locations is a 3D tensor.\n  if len(locations.shape) != 3:\n    raise ValueError(\n        'Input locations must be a 3D tensor. Got {}D tensor.'.format(len(locations.shape)))\n\n  # Check if"}
{"namespace": "resample.resample_3d", "completion": "  # Convert to float32.\n  data = data.astype(jnp.float32)\n  locations = locations.astype(jnp.float32)\n\n  # Handle half-pixel centering.\n  if half_pixel_center:\n    locations = locations + 0.5\n\n  # Get the input volume shape.\n  input_shape = data.shape\n\n  # Get the output volume shape.\n  output_shape = locations.shape[0:3]\n\n  # Get the output volume size.\n  output_size = output_shape[0] * output_shape[1] * output_shape[2]\n\n  # Get the input volume size.\n  input_size = input_shape[0] * input_shape[1] * input_shape[2]\n\n  # Get the input volume spacing.\n  input_spacing = [\n      input_size / output_size,\n      input_shape[1] / output_shape[1],\n      input_shape[2] / output_shape[2],\n  ]\n\n  # Get the output volume spacing.\n  output_spacing = [\n      input_size / output_size,\n      input_shape[1] / output_shape[1],\n      input_shape[2] / output_shape[2],\n  ]\n\n  # Get the output volume origin.\n  output_origin = [\n      -0.5 * output_spacing[0] * output_shape[0],\n      0.5 * output_spacing[1] * output_shape[1],\n      -0.5 * output_spacing[2] * output_shape[2],\n  ]\n\n  # Get the input volume origin.\n  input_origin = [\n      -0.5 * input_spacing[0] * input_shape[0],\n      -0.5 * input_spacing[1] * input_shape[1],\n      -0.5 * input_spacing[2] * input_shape[2],\n  ]\n\n  # Get the output volume bounds.\n  output_bounds = [\n      output_origin[0"}
{"namespace": "resample.resample_3d", "completion": "  # Get the shape of the input volume.\n  data_shape = data.shape\n  # Get the number of dimensions of the input volume.\n  data_ndim = len(data_shape)\n\n  # Get the shape of the sample locations.\n  locations_shape = locations.shape\n  # Get the number of dimensions of the sample locations.\n  locations_ndim = len(locations_shape)\n\n  # Get the number of dimensions of the output volume.\n  output_ndim = locations_ndim - 1\n\n  # Check if the input volume and sample locations have the same number of dimensions.\n  if data_ndim != output_ndim:\n    raise ValueError(\n        f'The input volume and sample locations must have the same number of dimensions. The input volume has {data_ndim} dimensions, and the sample locations have {locations_ndim} dimensions.')\n\n  # Check if the input volume and sample locations have the same number of dimensions.\n  if data_ndim != 3:\n    raise ValueError(\n        f'The input volume and sample locations must have 3 dimensions. The input volume has {data_ndim} dimensions, and the sample locations have {locations_ndim} dimensions.')\n\n  # Check if the input volume and sample locations have the same number of dimensions.\n  if coordinate_order != 'xyz' and coordinate_order != 'zyx':\n    raise ValueError(\n        f'The coordinate order must be either \"xyz\" or \"zyx\". The coordinate order is {coordinate_order}.')\n\n  # Check if the input volume and sample locations have the same number of dimensions.\n  if method != 'TRILINEAR' and method != 'NEAREST':\n    raise ValueError(\n        f'The interpolation method must be either \"TRILINEAR\" or \"NEAREST\". The interpolation method is {method}.')\n\n  # Check if the input volume and sample locations have the same number of dimensions.\n  if half_pixel_center:\n    raise ValueError(\n        f'Half pixel centering is not yet supported.')\n\n  # Get the shape of the output volume.\n  output_shape"}
{"namespace": "resample.resample_3d", "completion": "  if method not in ['TRILINEAR', 'NEAREST']:\n    raise ValueError(f'Unsupported method {method}')\n\n  if edge_behavior not in ['CONSTANT_OUTSIDE', 'CLAMP']:\n    raise ValueError(f'Unsupported edge behavior {edge_behavior}')\n\n  if coordinate_order not in ['xyz', 'zyx']:\n    raise ValueError(f'Unsupported coordinate order {coordinate_order}')\n\n  if half_pixel_center:\n    if coordinate_order == 'xyz':\n      locations = locations + 0.5\n    elif coordinate_order == 'zyx':\n      locations = locations + 0.5\n      locations = locations[Ellipsis, ::-1]\n\n  # Extract the shape of the data.\n  data_shape = data.shape\n\n  # Extract the shape of the locations.\n  locations_shape = locations.shape\n\n  # Extract the number of dimensions.\n  num_dims = len(data_shape) - 1\n\n  # Extract the spatial dimensions.\n  spatial_dims = tuple(range(1, num_dims + 1))\n\n  # Extract the batch dimension.\n  batch_dim = 0\n\n  # Extract the channel dimension.\n  channel_dim = num_dims + 1\n\n  # Extract the spatial shape of the data.\n  data_spatial_shape = data_shape[1:-1]\n\n  # Extract the spatial shape of the locations.\n  locations_spatial_shape = locations_shape[1:-1]\n\n  # Extract the number of spatial dimensions.\n  num_spatial_dims = len(data_spatial_shape)\n\n  # Extract the batch size.\n  batch_size = data_shape[batch_dim]\n\n  # Extract the number of channels.\n  num_channels = data_shape[channel_dim]\n\n  # Extract the spatial shape of the locations.\n  num_locations = locations_shape[1]\n\n  # Extract the"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'TRILINEAR':\n    # Trilinear interpolation\n    # See https://en.wikipedia.org/wiki/Trilinear_interpolation for details\n\n    # Determine the locations of the four corners closest to the sample point\n    # in the input volume.\n    if coordinate_order == 'xyz':\n      x_coordinate = locations[Ellipsis, 0]\n      y_coordinate = locations[Ellipsis, 1]\n      z_coordinate = locations[Ellipsis, 2]\n    elif coordinate_order == 'zyx':\n      z_coordinate = locations[Ellipsis, 0]\n      y_coordinate = locations[Ellipsis, 1]\n      x_coordinate = locations[Ellipsis, 2]\n\n    # Get the coordinates of the four corners closest to the sample point\n    # in the input volume.\n    x_floor = jnp.floor(x_coordinate)\n    y_floor = jnp.floor(y_coordinate)\n    z_floor = jnp.floor(z_coordinate)\n\n    x_ceil = x_floor + 1\n    y_ceil = y_floor + 1\n    z_ceil = z_floor + 1\n\n    # Calculate the interpolation weights.\n    if half_pixel_center:\n      x_weight = x_coordinate - x_floor\n      y_weight = y_coordinate - y_floor\n      z_weight = z_coordinate - z_floor\n    else:\n      x_weight = x_ceil - x_coordinate\n      y_weight = y_ceil - y_coordinate\n      z_weight = z_ceil - z_coordinate\n\n    # Calculate the interpolation weight factors.\n    x_weight_0 = (1 - x_weight) * (1 - z_weight) * (1 - y_weight)\n    x_weight_1 = x_weight * (1 - z_weight) * (1 - y_weight)\n    x_weight_2 = (1 - x_weight) * z_weight * (1 - y_weight)\n    x_weight_3 = x_"}
{"namespace": "resample.resample_3d", "completion": "  if coordinate_order == 'xyz':\n    x_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    z_coordinate = locations[Ellipsis, 2]\n  elif coordinate_order == 'zyx':\n    z_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    x_coordinate = locations[Ellipsis, 2]\n\n  # Get the shape of the locations tensor.\n  locations_shape = locations.shape\n  num_dims = len(locations_shape)\n\n  # Get the shape of the data tensor.\n  data_shape = data.shape\n\n  # Get the number of dimensions.\n  num_dims = len(data_shape)\n\n  # Get the spatial dimensions of the data tensor.\n  data_spatial_shape = data_shape[1:4]\n\n  # Get the size of the data.\n  data_size = np.prod(data_spatial_shape)\n\n  # Get the size of the locations tensor.\n  locations_size = np.prod(locations_shape[1:4])\n\n  # Get the size of the output tensor.\n  output_size = np.prod(locations_shape[1:num_dims])\n\n  # Compute the sample locations.\n  if half_pixel_center:\n    # Get the size of the output tensor.\n    output_size = np.prod(locations_shape[1:num_dims])\n\n    # Compute the sample locations.\n    x_coordinate = x_coordinate + 0.5\n    y_coordinate = y_coordinate + 0.5\n    z_coordinate = z_coordinate + 0.5\n\n  # Get the lower bound of the data.\n  data_lower_bound = np.zeros(3)\n  data_lower_bound[0] = 0\n  data_lower_bound[1] = 0\n  data_lower_bound[2] = 0\n\n  # Get the upper bound of the"}
{"namespace": "resample.resample_3d", "completion": "  # If half-pixel centering is used, we need to adjust the sample locations.\n  if half_pixel_center:\n    if coordinate_order == 'xyz':\n      locations = locations + 0.5\n    elif coordinate_order == 'zyx':\n      locations = locations + jnp.array([0.5, 0.5, 0.0])\n\n  # Compute the sample locations.\n  locations = locations.astype(jnp.int32)\n\n  # Compute the output shape.\n  output_shape = locations.shape[:-1]\n\n  # Compute the minimum and maximum sample locations.\n  min_locations = jnp.minimum(locations, jnp.array([0, 0, 0]))\n  max_locations = jnp.maximum(locations, jnp.array([data.shape[0] - 1,\n                                                    data.shape[1] - 1,\n                                                    data.shape[2] - 1]))\n\n  # Compute the padding.\n  padding = jnp.maximum(jnp.max(max_locations - data.shape[0] + 1), 0)\n  padding = jnp.stack([padding, padding], axis=0)\n\n  # Pad the data.\n  padded_data = jnp.pad(data, padding, mode='constant',\n                        constant_values=constant_values)\n\n  # Compute the locations of the four corners.\n  corner_locations = jnp.stack([jnp.minimum(max_locations,\n                                            jnp.array([data.shape[0] - 1,\n                                                       data.shape[1] - 1,\n                                                       data.shape[2] - 1])),\n                                jnp.maximum(min_locations, jnp.array([0, 0, 0]))],\n                               axis=0)\n\n  # Compute the output locations.\n  output_locations = jnp.stack([jnp.arange(output_shape[0]),\n                                jnp.ar"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, x)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, x)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, x)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, x)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, x)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, x)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, x)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, x)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, x)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, x)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, x)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, x)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, x)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, x)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, x)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, x)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, x)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, x)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(x < tiny_val, tiny_val, x)\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, x)\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (-max_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (-max_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (-tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (-tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (-max_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (-max_val, -tiny_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (-tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (-100, 100),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (-max_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (-max_val, -tiny_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (-tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (-max_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: x_dot * y,\n      (-tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (-tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (-max_val, -tiny_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (-tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: x_dot * y,\n      (-tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (-max_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (-max_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, grad_fn=lambda x, y, x_dot: x_dot / y, x_range=(tiny_val, max_val)(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / y, (tiny_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  safe_log_fn = generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / y, (-1, 0))\n\n  return safe_log_fn(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, safe_div, (tiny_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, grad_fn=safe_div, x_range=(tiny_val, max_val)(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, grad_fn=lambda x, y, x_dot: x_dot / y, x_range=(tiny_val, max_val)(x)\n\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, safe_div, (-tiny_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / y, (-tiny_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / y, (-max_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, grad_fn=lambda x, y, x_dot: x_dot / y,\n                          x_range=(tiny_val, max_val)(x)\n                         )(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, grad_fn=grad_log, x_range=(tiny_val, max_val)(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / y, (-1, 0))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  safe_log_fn = generate_safe_fn(jnp.log, jax.grad(jnp.log), x_range=(tiny_val, max_val))\n  return safe_log_fn(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  def grad_fn(x, y, x_dot):\n    return 1 / x\n\n  safe_log_fn = generate_safe_fn(jnp.log, grad_fn, (-tiny_val, max_val))\n  return safe_log_fn(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, safe_div, (tiny_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, grad_log, (tiny_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, safe_div, (tiny_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, grad_log, (-tiny_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, grad_fn=grad_log, x_range=(tiny_val, max_val)(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, grad_log, (tiny_val, max_val))(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: 0.5 * x_dot * y / x,\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: 0.5 * x_dot * y / x,\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: 0.5 * x_dot * y / x,\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: 0.5 * x_dot * y / x,\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: 0.5 * x_dot / y,\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: 0.5 * x_dot * y / x,\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: 0.5 * x_dot * y / x,\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: 0.5 * y * x_dot,\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: 0.5 * y * x_dot,\n      (0, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: 0.5 * y * x_dot,\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: 0.5 * x_dot * y / x,\n      (0, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: 0.5 * x_dot * y / x,\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: 0.5 * x_dot * y / x,\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: 0.5 * x_dot * y / x,\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: 0.5 * y * x_dot,\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: x_dot * 0.5 * y / x,\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: 0.5 * x_dot * y / x,\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: 0.5 * x_dot * y / x,\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: x_dot * 0.5 * y / x,\n      (tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: 0.5 * x_dot * y / x,\n      (0, max_val),\n  )(x)\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return 1\n  elif p == 2:\n    return 2\n  elif p == 3:\n    return 3\n  elif p == 4:\n    return 2\n  elif p == 5:\n    return 3\n  elif p == 6:\n    return 2\n  elif p == 7:\n    return 3\n  elif p == 8:\n    return 2\n  elif p == 9:\n    return 3\n  elif p == 10:\n    return 2\n  elif p == 11:\n    return 3\n  elif p == 12:\n    return 2\n  elif p == 13:\n    return 3\n  elif p == 14:\n    return 2\n  elif p == 15:\n    return 3\n  elif p == 16:\n    return 2\n  elif p == 17:\n    return 3\n  elif p == 18:\n    return 2\n  elif p == 19:\n    return 3\n  elif p == 20:\n    return 2\n  elif p == 21:\n    return 3\n  elif p == 22:\n    return 2\n  elif p == 23:\n    return 3\n  elif p == 24:\n    return 2\n  elif p == 25:\n    return 3\n  elif p == 26:\n    return 2\n  elif p == 27:\n    return 3\n  elif p == 28:\n    return 2\n  elif p == 29:\n    return 3\n  elif p == 30:\n    return 2\n  elif p == 31:\n    return 3\n  elif p == 32:\n    return 2\n  elif p == 33:\n    return 3\n  elif p == 34:\n    return 2\n  elif p == 35:\n    return 3\n  elif p == 36:\n    return 2\n  elif p"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return 1\n  elif p == 0:\n    return 0\n  elif p == -1:\n    return jnp.inf\n  elif p == jnp.inf:\n    return 1\n  elif p == -jnp.inf:\n    return 0\n  else:\n    return jnp.inf\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p < 0:\n    return 0\n  elif p == 0:\n    return 1\n  else:\n    return np.inf\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return 1\n  elif p == 2:\n    return np.inf\n  elif p == 0:\n    return 0\n  else:\n    return np.inf\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p > 1:\n    return np.inf\n  elif p < 1:\n    return 0\n  else:\n    return 1\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return jnp.inf\n  elif p == 2:\n    return jnp.sqrt(jnp.inf)\n  elif p == 3:\n    return jnp.cbrt(jnp.inf)\n  else:\n    return jnp.power(jnp.inf, 1 / p)\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p > 1:\n    return np.inf\n  elif p < 1:\n    return 0\n  else:\n    return 1\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return 1\n  elif p == 2:\n    return np.inf\n  elif p == 0:\n    return 0\n  else:\n    return np.inf\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p >= 1:\n    return np.inf\n  elif p < 1:\n    return np.nan\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p < 0:\n    return 0\n  elif p == 0:\n    return 1\n  else:\n    return np.inf\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 0:\n    return jnp.inf\n  elif p == 1:\n    return 1\n  elif p == 2:\n    return jnp.sqrt(jnp.inf)\n  elif p == 3:\n    return jnp.cbrt(jnp.inf)\n  else:\n    return (p - 1) / (p - 2)\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return 1\n  elif p == 2:\n    return np.inf\n  else:\n    return (2 ** p - 1) / (p - 1)\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return 1\n  elif p == 2:\n    return np.inf\n  elif p == 4:\n    return np.sqrt(2)\n  elif p == np.inf:\n    return 1 / np.e\n  else:\n    return 1 / (1 - p)\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return 1\n  if p == 2:\n    return np.inf\n  if p == 4:\n    return np.sqrt(2) * np.inf\n  if p == np.inf:\n    return np.sqrt(2)\n  if p > 0 and p < 1:\n    return np.sqrt(p / (1 - p)) * np.inf\n  if p < 4 and p > 0:\n    return np.sqrt(p / (1 - p)) * np.inf\n  if p < np.inf and p > 2:\n    return np.sqrt(2) * np.inf\n  if p == 0:\n    return 0\n  if p < 0 and p > -1:\n    return -np.sqrt((1 - p) / p) * np.inf\n  if p > -4 and p < -1:\n    return -np.sqrt((1 - p) / p) * np.inf\n  if p == -np.inf:\n    return -np.sqrt(2)\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return 1\n  if p == 2:\n    return np.inf\n  if p == 0:\n    return 0\n  if p < 0:\n    return -np.inf\n  else:\n    return np.inf\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return 1\n  elif p == 2:\n    return np.inf\n  elif p == np.inf:\n    return 1\n  else:\n    return np.nan\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p > 1:\n    return float('inf')\n  if p < 1:\n    return 0\n  else:\n    return 1\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return np.inf\n  elif p == 2:\n    return np.sqrt(np.inf)\n  elif p == 3:\n    return np.cbrt(np.inf)\n  elif p == 4:\n    return np.sqrt(np.sqrt(np.inf))\n  elif p == 0.5:\n    return np.sqrt(np.sqrt(np.sqrt(np.inf)))\n  elif p == 0:\n    return np.sqrt(np.sqrt(np.sqrt(np.sqrt(np.inf))))\n  else:\n    return np.sqrt(np.sqrt(np.sqrt(np.sqrt(np.sqrt(np.inf)))))\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p > 1:\n    return max_val\n  elif p == 1:\n    return max_val / 2\n  else:\n    return 0\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 0:\n    return 1\n  elif p == 1:\n    return np.inf\n  elif p == 2:\n    return np.sqrt(np.inf)\n  elif p == np.inf:\n    return np.sign(p)\n  else:\n    return np.sign(p) * np.sqrt(p)\n\n"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array([[1, 1, 1], [-1, -1, 1], [-1, 1, -1], [1, -1, -1]])\n    base_faces = np.array([[0, 1, 2], [0, 2, 3], [0, 3, 1], [1, 3, 2]])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array(\n        [\n            [0, 1, 2],\n            [0, 2, 3],\n            [0, 3, 4],\n            [0, 4, 5],\n            [0, 5, 1],\n            [11, 7, 8],\n            [11, 8, 9],\n            [11, 9, 10],\n            [11, 10, 7],\n            [1, 6, 7],\n            [1, 7, 2],\n            [2, 7, 3],\n            [3, 7, 4],\n            [4, 7, 5],\n            [5, 7, 1],\n            [1, 8, 9],\n            [2, 9, 10],\n            [3, 10, 11],\n            [4, 11, 8],\n            [5, 8, 11],\n        ]\n    )\n    base_faces = np.array(\n        [\n            [0, 1, 2],\n            [0, 2, 3],\n            [0, 3, 4],\n            [0, 4, 5],\n            [0, 5, 1],\n            [1, 6, 7],\n            [1, 7, 2],\n            [2, 7, 3],\n            [3, 7, 4],\n            [4, 7, 5],\n            [5, "}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n      [1, 1, 1],\n      [-1, -1, 1],\n      [1, -1, -1],\n      [-1, 1, -1]\n    ])\n    base_faces = np.array([\n      [0, 1, 2],\n      [0, 1, 3],\n      [0, 2, 3],\n      [1, 2, 3]\n    ])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array([\n      [0, 1, 1],\n      [0, -1, 1],\n      [1, 0, 1],\n      [1, 1, 0],\n      [1, -1, 0],\n      [1, 0, -1],\n      [0, 1, -1],\n      [0, -1, -1],\n      [-1, 0, 1],\n      [-1, 1, 0],\n      [-1, 0, -1],\n      [-1, -1, 0]\n    ])\n    base_faces = np.array([\n      [0, 1, 2],\n      [0, 1, 3],\n      [0, 1, 4],\n      [0, 1, 5],\n      [0, 2, 6],\n      [0, 2, 7],\n      [0, 3, 8],\n      [0, 3, 9],\n      [0, 4, 10],\n      [0, 4, 11],\n      [0, 5, 12],\n      [0, 5, 13],\n      [1, 2, 6],\n      [1, 2, 7],\n      [1, 3, 8],\n      [1, 3, 9],\n      [1, 4, 10],\n      [1, 4, 1"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(\n        f'base_shape {base_shape} must be either tetrahedron, icosahedron, or octahedron'\n    )\n\n  if angular_tesselation < 1:\n    raise ValueError(\n        f'angular_tesselation {angular_tesselation} must be >= 1')\n\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [-1, -1, 1],\n        [1, -1, -1],\n        [-1, 1, -1],\n    ]) / np.sqrt(3)\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 2, 3],\n        [0, 3, 1],\n        [1, 3, 2],\n    ])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array([\n        [0, 1, 1],\n        [0, -1, 1],\n        [1, 0, 1],\n        [-1, 0, 1],\n        [1, 1, 0],\n        [1, -1, 0],\n        [-1, 1, 0],\n        [-1, -1, 0],\n        [1, 0, -1],\n        [-1, 0, -1],\n        [0, 1, -1],\n        [0, -1, -1],\n    ]) / np.sqrt(3)\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 2, 3],\n        [0, 3, 4],\n        [0, 4, 5],\n        [0, 5, 1],\n        [11, 7, 5],\n        [11, 4, 7"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(\n        f'base_shape {base_shape} must be either \"tetrahedron\", \"icosahedron\", or \"octahedron\"'\n    )\n\n  if not isinstance(angular_tesselation, int):\n    raise ValueError(\n        f'angular_tesselation {angular_tesselation} must be an integer'\n    )\n\n  if angular_tesselation < 1:\n    raise ValueError(\n        f'angular_tesselation {angular_tesselation} must be >= 1'\n    )\n\n  if not isinstance(remove_symmetries, bool):\n    raise ValueError(\n        f'remove_symmetries {remove_symmetries} must be a boolean'\n    )\n\n  if not isinstance(eps, float):\n    raise ValueError(f'eps {eps} must be a float')\n\n  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n        [\n            [1, 1, 1],\n            [1, -1, 1],\n            [-1, 1, -1],\n            [-1, -1, -1],\n        ],\n        dtype=np.float32,\n    )\n    base_faces = np.array(\n        [\n            [0, 1, 2],\n            [0, 2, 3],\n            [0, 3, 1],\n            [1, 3, 2],\n        ],\n        dtype=np.int32,\n    )\n  elif base_shape == 'icosahedron':\n    base_verts = np.array(\n        [\n            [0, 1, 1],\n            [0, -1, 1],\n            [0, 1, -1],\n            [0, -1, -1],\n            [1, 1, 0],\n            [1, -1, 0],\n            [-1, 1, "}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n        [\n            [1, 0, 0],\n            [0, 1, 0],\n            [0, 0, 1],\n            [0, 0, 0],\n        ],\n        dtype=np.float32,\n    )\n    base_faces = np.array(\n        [\n            [0, 1, 2],\n            [0, 1, 3],\n            [0, 2, 3],\n            [1, 2, 3],\n        ],\n        dtype=np.int32,\n    )\n  elif base_shape == 'icosahedron':\n    base_verts = np.array(\n        [\n            [0.000, 0.000, 1.000],\n            [0.000, 1.000, 0.000],\n            [0.000, 1.000, 1.000],\n            [0.000, 1.000, -1.000],\n            [0.000, 1.000, 2.000],\n            [0.000, 1.000, -2.000],\n            [0.000, 1.000, 3.000],\n            [0.000, 1.000, -3.000],\n            [0.000, 1.000, 4.000],\n            [0.000, 1.000, -4.000],\n            [0.000, 1.000, 5.000],\n            [0.000, 1.000, -5.000],\n            [0.000, 1.000, 6.000],\n            [0.000, 1.0"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n      [1, 1, 1],\n      [-1, -1, 1],\n      [1, -1, -1],\n      [-1, 1, -1]\n    ])\n    base_faces = np.array([\n      [0, 1, 2],\n      [0, 1, 3],\n      [0, 2, 3],\n      [1, 2, 3]\n    ])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array([\n      [0, 1, 1.73205],\n      [0, -1, 1.73205],\n      [0, 1, -1.73205],\n      [0, -1, -1.73205],\n      [1, 0, 1.73205],\n      [1, 0, -1.73205],\n      [-1, 0, 1.73205],\n      [-1, 0, -1.73205],\n      [1.73205, 1, 0],\n      [1.73205, -1, 0],\n      [-1.73205, 1, 0],\n      [-1.73205, -1, 0],\n      [0, 1.73205, 1],\n      [0, -1.73205, 1],\n      [0, 1.73205, -1],\n      [0, -1.73205, -1]\n    ])\n    base_faces = np.array([\n      [0, 1, 2],\n      [0, 2, 3],\n      [0, 3, 4],\n      [0, 4, 5],\n      [0, 5, 6],\n      [0, 6"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1], [-1, 0, 0]])\n    base_faces = np.array([[0, 1, 2], [0, 1, 3], [0, 2, 3], [1, 2, 3]])\n\n  elif base_shape == 'icosahedron':\n    base_verts = np.array(\n        [\n            [0.0000000, 0.0000000, 1.0000000],\n            [0.0000000, 0.0000000, -1.0000000],\n            [0.0000000, 1.0000000, 0.0000000],\n            [0.0000000, -1.0000000, 0.0000000],\n            [1.0000000, 0.0000000, 0.0000000],\n            [-1.0000000, 0.0000000, 0.0000000],\n            [0.8660254, 0.5000000, 0.0000000],\n            [0.8660254, -0.5000000, 0.0000000],\n            [0.5000000, 0.8660254, 0.0000000],\n            [0.5000000, -0.8660254, 0.0000000],\n            [0.0000000, 0"}
{"namespace": "geopoly.generate_basis", "completion": "  # Generate the initial basis\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [1, -1, 1],\n        [-1, 1, -1],\n        [1, -1, -1],\n    ]) / np.sqrt(3)\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 2, 3],\n        [0, 3, 1],\n        [1, 3, 2],\n    ])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array([\n        [0, 1, 1],\n        [0, -1, 1],\n        [0, 1, -1],\n        [0, -1, -1],\n        [1, 1, 0],\n        [1, -1, 0],\n        [-1, 1, 0],\n        [-1, -1, 0],\n        [1, 0, 1],\n        [1, 0, -1],\n        [-1, 0, 1],\n        [-1, 0, -1],\n    ]) / np.sqrt(3)\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 2, 3],\n        [0, 3, 4],\n        [0, 4, 5],\n        [0, 5, 1],\n        [1, 5, 6],\n        [1, 6, 2],\n        [2, 6, 7],\n        [2, 7, 3],\n        [3, 7, 8],\n        [3, 8, 4],\n        [4, 8, 9],\n        [4, 9, 5],\n        [5, 9, 6],\n        [6, 9, 7],\n        [7, 9, 8],\n        [8"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n      [1, 1, 1],\n      [1, -1, -1],\n      [-1, 1, -1],\n      [-1, -1, 1]\n    ]) / np.sqrt(3)\n    base_faces = np.array([\n      [0, 1, 2],\n      [0, 3, 1],\n      [0, 2, 3],\n      [1, 3, 2]\n    ])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array([\n      [0, 1, 1],\n      [0, -1, 1],\n      [0, 1, -1],\n      [0, -1, -1],\n      [1, 1, 0],\n      [1, -1, 0],\n      [-1, 1, 0],\n      [-1, -1, 0],\n      [1, 0, 1],\n      [1, 0, -1],\n      [-1, 0, 1],\n      [-1, 0, -1]\n    ]) / np.sqrt(3)\n    base_faces = np.array([\n      [0, 1, 2],\n      [0, 1, 3],\n      [0, 2, 4],\n      [0, 3, 5],\n      [0, 4, 6],\n      [0, 5, 1],\n      [1, 7, 2],\n      [1, 8, 3],\n      [1, 9, 4],\n      [1, 10, 5],\n      [1, 11, 6],\n      [2, 7, 4],\n      [2, 8, 5],\n      [2, 9, 6],\n      [3, 7, 5],\n      [3, 8, 6],\n      [4, 7, 6"}
{"namespace": "geopoly.generate_basis", "completion": "  # Set up the base vertices and faces.\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [-1, -1, 1],\n        [1, -1, -1],\n        [-1, 1, -1]\n    ])\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 3, 1],\n        [0, 2, 3],\n        [1, 3, 2]\n    ])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array([\n        [0, 1, 1],\n        [0, 1, -1],\n        [0, -1, 1],\n        [0, -1, -1],\n        [1, 0, 1],\n        [1, 0, -1],\n        [-1, 0, 1],\n        [-1, 0, -1],\n        [1, 1, 0],\n        [1, -1, 0],\n        [-1, 1, 0],\n        [-1, -1, 0]\n    ])\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 2, 3],\n        [0, 3, 4],\n        [0, 4, 5],\n        [0, 5, 1],\n        [11, 7, 6],\n        [11, 8, 7],\n        [11, 9, 8],\n        [11, 10, 9],\n        [11, 6, 10],\n        [1, 6, 2],\n        [2, 7, 3],\n        [3, 8, 4],\n        [4, 9, 5],\n        [5, 10, 1],\n        [6, 7, 2],\n        [7, 8"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(f'base_shape {base_shape} must be either tetrahedron, icosahedron, or octahedron')\n\n  if not isinstance(angular_tesselation, int):\n    raise ValueError(f'angular_tesselation {angular_tesselation} must be an integer')\n\n  if angular_tesselation < 1:\n    raise ValueError(f'angular_tesselation {angular_tesselation} must be >= 1')\n\n  if not isinstance(remove_symmetries, bool):\n    raise ValueError(f'remove_symmetries {remove_symmetries} must be a boolean')\n\n  if not isinstance(eps, float):\n    raise ValueError(f'eps {eps} must be a float')\n\n  if eps <= 0:\n    raise ValueError(f'eps {eps} must be > 0')\n\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1], [-1, 0, 0]])\n    base_faces = np.array([[0, 1, 2], [0, 1, 3], [0, 2, 3], [1, 2, 3]])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array([\n      [0, 1, 2], [0, 2, 3], [0, 3, 4], [0, 4, 5], [0, 5, 1], [1, 6, 7],\n      [1, 7, 2], [2, 7, 3], [3, 7, 4], [4, 7, 5], [5, 7, 1], [6, 8, 9],\n      [6, 9, 10], [6,"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(f'base_shape {base_shape} is not supported')\n\n  if angular_tesselation < 1:\n    raise ValueError(f'angular_tesselation {angular_tesselation} is not supported')\n\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([[1, 1, 1], [-1, -1, 1], [-1, 1, -1], [1, -1, -1]])\n    base_faces = np.array([[0, 1, 2], [0, 2, 3], [0, 3, 1], [1, 3, 2]])\n\n  elif base_shape == 'icosahedron':\n    base_verts = np.array(\n        [\n            [0.0000000, 0.0000000, 1.0000000],\n            [0.0000000, 1.0000000, 0.0000000],\n            [0.0000000, 1.0000000, 1.0000000],\n            [0.0000000, 1.0000000, -1.0000000],\n            [0.0000000, 1.0000000, -1.0000000],\n            [0.0000000, 1.0000000, -1.0000000],\n            [0.0000000, 1.0000000, 1.0000000],\n            [0.0000000, 1.0000000, 0.0000000],"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(f'base_shape {base_shape} must be tetrahedron, icosahedron, or octahedron')\n\n  if not isinstance(angular_tesselation, int):\n    raise ValueError(f'angular_tesselation {angular_tesselation} must be an integer')\n\n  if not isinstance(remove_symmetries, bool):\n    raise ValueError(f'remove_symmetries {remove_symmetries} must be a bool')\n\n  if not isinstance(eps, float):\n    raise ValueError(f'eps {eps} must be a float')\n\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([[1, 1, 1], [-1, -1, 1], [-1, 1, -1], [1, -1, -1]])\n    base_faces = np.array([[0, 1, 2], [0, 2, 3], [0, 3, 1], [1, 3, 2]])\n\n  elif base_shape == 'icosahedron':\n    base_verts = np.array([\n      [0, 1, 2], [0, 2, 3], [0, 3, 4], [0, 4, 5], [0, 5, 1], [1, 5, 6],\n      [1, 6, 2], [2, 6, 7], [2, 7, 3], [3, 7, 8], [3, 8, 4], [4, 8, 9],\n      [4, 9, 5], [5, 9, 6], [6, 9, 7], [7, 9, 8], [8, 9, 1], [1, 10, 7],\n      [2, 10, 8], [3, 10, 9], [4,"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(f'base_shape {base_shape} must be one of \"tetrahedron\", \"icosahedron\", or \"octahedron\"')\n\n  if angular_tesselation < 1:\n    raise ValueError(f'angular_tesselation {angular_tesselation} must be >= 1')\n\n  if eps <= 0:\n    raise ValueError(f'eps {eps} must be > 0')\n\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n      [1, 0, 0],\n      [-1, 0, 0],\n      [0, 1, 0],\n      [0, -1, 0],\n      [0, 0, 1],\n      [0, 0, -1]\n    ])\n    base_faces = np.array([\n      [0, 1, 2],\n      [0, 2, 3],\n      [0, 3, 4],\n      [0, 4, 1],\n      [5, 1, 2],\n      [5, 2, 3],\n      [5, 3, 4],\n      [5, 4, 1]\n    ])\n\n  if base_shape == 'icosahedron':\n    base_verts = np.array([\n      [0.0000000,  0.0000000,  1.0000000],\n      [0.0000000,  1.0000000,  0.0000000],\n      [0.0000000,  1.0000000,  1.0000000],\n      [0.0000000,  1.0000000,  -1.0000000],\n      [0"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [-1, -1, 1],\n        [1, -1, -1],\n        [-1, 1, -1]\n    ])\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 2, 3],\n        [0, 3, 1],\n        [1, 3, 2]\n    ])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array([\n        [0, 1, 1.319125],\n        [0, 1.319125, 0],\n        [0, -1.319125, 0],\n        [0, -1, 1.319125],\n        [1.319125, 0, 0],\n        [1.319125, 0, 1.319125],\n        [1.319125, 0, -1.319125],\n        [1, 1.319125, 0],\n        [-1, 1.319125, 0],\n        [1, -1.319125, 0],\n        [-1, -1.319125, 0],\n        [1.319125, 1, 0],\n        [-1.319125, 1, 0],\n        [1.319125, -1, 0],\n        [-1.319125, -1, 0],\n        [1.319125, 1, 1.319125],\n        [1.319125, 1, -1.319125],\n        [-1.319125, "}
{"namespace": "geopoly.generate_basis", "completion": "  # Validate the input parameters.\n  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(f'base_shape {base_shape} must be one of \"tetrahedron\", \"icosahedron\", or \"octahedron\"')\n  if not isinstance(angular_tesselation, int):\n    raise ValueError(f'angular_tesselation {angular_tesselation} must be an integer')\n  if angular_tesselation < 1:\n    raise ValueError(f'angular_tesselation {angular_tesselation} must be >= 1')\n\n  # Generate the base vertices.\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([[1, 1, 1], [-1, -1, 1], [-1, 1, -1], [1, -1, -1]]) / np.sqrt(3)\n  elif base_shape == 'icosahedron':\n    base_verts = np.array([\n        [0, 1, 1], [0, -1, 1], [0, -1, -1], [0, 1, -1], [1, 1, 0], [1, -1, 0], [-1, 1, 0], [-1, -1, 0],\n        [1, 0, 1], [1, 0, -1], [-1, 0, 1], [-1, 0, -1], [1, 1, 0], [1, -1, 0], [-1, 1, 0], [-1, -1, 0]\n    ]) / np.sqrt(3)\n  elif base_shape == 'octahedron':\n    base_verts = np.array([[1, 0, 0], [-1, 0, 0], [0, 1, 0], [0, -1, 0], [0, 0, 1], [0, 0, -1]])\n\n  # Generate the base"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError('base_shape must be one of \\'tetrahedron\\', \\'icosahedron\\', or \\'octahedron\\'')\n\n  if angular_tesselation < 1:\n    raise ValueError('angular_tesselation must be greater than or equal to 1')\n\n  if not isinstance(remove_symmetries, bool):\n    raise ValueError('remove_symmetries must be a boolean value')\n\n  if not isinstance(eps, float):\n    raise ValueError('eps must be a float value')\n\n  # Tesselate the base shape.\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([[1, 0, 0], [-1, 0, 0], [0, 1, 0], [0, -1, 0]])\n    base_faces = np.array([[0, 1, 2], [0, 2, 3], [0, 3, 1], [1, 3, 2]])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array([\n        [0.0, 0.0, 1.0], [0.0, 0.0, -1.0], [0.0, 1.0, 0.0], [0.0, -1.0, 0.0],\n        [1.0, 0.0, 0.0], [-1.0, 0.0, 0.0], [0.0, 0.7, 0.7], [0.0, -0.7, 0.7],\n        [0.0, 0.7, -0.7], [0.0, -0.7, -0.7], [0.7, 0.7, 0.0], [0.7, -0.7, 0.0],\n        [-0.7, 0.7, 0."}
{"namespace": "geopoly.generate_basis", "completion": "  # Check base_shape\n  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(f'Invalid base shape {base_shape}.')\n\n  # Check angular_tesselation\n  if not isinstance(angular_tesselation, int):\n    raise ValueError(f'angular_tesselation {angular_tesselation} must be an integer.')\n\n  # Check eps\n  if not isinstance(eps, float):\n    raise ValueError(f'eps {eps} must be a float.')\n\n  # Generate vertices and faces of the base shape\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([[1, 1, 1], [-1, -1, 1], [1, -1, -1], [-1, 1, -1]])\n    base_faces = np.array([[0, 1, 2], [0, 2, 3], [0, 3, 1], [1, 3, 2]])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array(\n      [\n        [0.000, 0.000, 0.000],\n        [0.894, 0.000, 0.447],\n        [0.276, 0.851, 0.447],\n        [0.276, 0.276, 0.724],\n        [-0.724, 0.276, 0.447],\n        [-0.894, 0.000, 0.447],\n        [-0.724, -0.276, 0.447],\n        [-0.276, -0.851, 0.447],\n        [-0.276, -0.276, 0.724],\n        [0.724"}
{"namespace": "geopoly.generate_basis", "completion": "  # Validate input arguments\n  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(\n        'Invalid base_shape. Must be either \"tetrahedron\", \"icosahedron\", or \"octahedron\".'\n    )\n\n  if angular_tesselation < 1:\n    raise ValueError(\n        'Invalid angular_tesselation. Must be a positive integer greater than 1.'\n    )\n\n  # Generate the initial basis\n  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n        [[1, 0, 0], [-1, 0, 0], [0, 1, 0], [0, -1, 0], [0, 0, 1], [0, 0, -1]],\n        dtype=np.float32)\n    base_faces = np.array([[0, 1, 2], [0, 2, 3], [0, 3, 4], [0, 4, 1],\n                           [1, 4, 5], [1, 5, 2], [2, 5, 3], [3, 5, 4]])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array([\n        [0, 0, 1],\n        [0, 0, -1],\n        [0, 1, 0],\n        [0, -1, 0],\n        [1, 0, 0],\n        [-1, 0, 0],\n        [0.5, 0.5, 0.5],\n        [0.5, 0.5, -0.5],\n        [0.5, -0.5, 0.5],\n        [0.5, -0.5, -0.5],\n        [-0.5, 0.5, 0.5],\n        [-0.5, 0.5, -0.5],\n        [-0.5,"}
{"namespace": "geopoly.generate_basis", "completion": "  # Check if base_shape is valid\n  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(\n        'Invalid base_shape. It must be either \"tetrahedron\", \"icosahedron\", or \"octahedron\".'\n    )\n\n  # Check if angular_tesselation is valid\n  if not isinstance(angular_tesselation, int):\n    raise ValueError('Invalid angular_tesselation. It must be an integer.')\n\n  # Check if eps is valid\n  if not isinstance(eps, float):\n    raise ValueError('Invalid eps. It must be a float.')\n\n  # Define the base vertices of the polyhedron\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([[1, 1, 1], [-1, -1, 1], [1, -1, -1], [-1, 1, -1]])\n  elif base_shape == 'icosahedron':\n    base_verts = np.array([\n        [0, 1, 14], [0, 2, 8], [0, 4, 6], [0, 6, 4], [0, 8, 2], [0, 10, 0],\n        [0, 10, 2], [0, 10, 4], [0, 10, 6], [0, 10, 8], [0, 10, 10], [2, 1, 1],\n        [2, 3, 5], [2, 5, 3], [2, 6, 0], [2, 8, 2], [2, 10, 4], [4, 1, 1],\n        [4, 3, 5], [4, 5, 3], [4, 6, 0], [4, 7, 4], [4, 9, 6], [6, 1, 1],\n        [6,"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + jnp.abs(x)),\n      (-tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + jnp.maximum(tiny_val, x)),\n      (-tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1.0 + jnp.abs(x)),\n      (-tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1.0 + jnp.abs(x)),\n      (-1, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + jnp.abs(x)),\n      (-tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  @jax.custom_jvp\n  def safe_log1p(x):\n    \"\"\"log1p() with clipped inputs.\"\"\"\n    return jnp.log1p(jnp.clip(x, min_val, max_val))\n\n  @safe_log1p.defjvp\n  def safe_log1p_jvp(primals, tangents):\n    \"\"\"Backpropagate using the gradient and clipped inputs.\"\"\"\n    (x,) = primals\n    (x_dot,) = tangents\n    y = safe_log1p(x)\n    y_dot = x_dot / (1 + x)\n    return y, y_dot\n\n  return safe_log1p\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + jnp.abs(x)),\n      (-tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + jnp.minimum(x, tiny_val)),\n      (-tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1.0 + jnp.abs(x)),\n      (-tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + jnp.minimum(x, max_val)),\n      (-tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + jnp.minimum(x, max_val)),\n      (-max_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + jnp.minimum(x, max_val)),\n      (-1, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1.0 + jnp.abs(x)),\n      (-1, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1.0 + jnp.clip(x, min_val, max_val)),\n      (-tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + jnp.abs(x)),\n      (-1, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1.0 + x),\n      (-tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + jnp.minimum(x, tiny_val)),\n      (-tiny_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is None:\n    premult = 1\n  if postmult is None:\n    postmult = 1\n\n  if p == 1:\n    return postmult * x\n  elif p == 0:\n    return postmult * jnp.log(premult * x)\n  elif p == -jnp.inf:\n    return postmult * jnp.sign(x) * jnp.sqrt(premult * jnp.abs(x))\n  elif p == jnp.inf:\n    return postmult * jnp.sign(x) * jnp.exp(premult * jnp.abs(x))\n  else:\n    return postmult * jnp.sign(x) * safe_div(\n        premult * jnp.abs(x)**(p - 1),\n        power_ladder_max_output(p),\n    )**p\n\n"}
{"namespace": "math.power_ladder", "completion": "  # Pre-multiplication.\n  if premult is not None:\n    x = x * premult\n\n  # Special case: p = -inf.\n  if p == -jnp.inf:\n    x = jnp.sign(x)\n\n  # Special case: p = 1.\n  if p == 1:\n    x = jnp.abs(x)\n\n  # Special case: p = 0.\n  if p == 0:\n    x = jnp.ones_like(x)\n\n  # Normal case: p != 0, 1, -inf.\n  if p != 1 and p != 0 and p != -jnp.inf:\n    x = jnp.power(x, p)\n\n  # Post-multiplication.\n  if postmult is not None:\n    x = x * postmult\n\n  return x\n\n"}
{"namespace": "math.power_ladder", "completion": "  # If x is 0, we want to return 0.\n  x = jnp.where(x == 0, 0, x)\n\n  # If x is negative, we want to return -1.\n  x = jnp.where(x < 0, -1, x)\n\n  # If x is positive, we want to return 1.\n  x = jnp.where(x > 0, 1, x)\n\n  # If x is inf or -inf, we want to return 0.\n  x = jnp.where(x == jnp.inf, 0, x)\n  x = jnp.where(x == -jnp.inf, 0, x)\n\n  # If x is 1, we want to return 1.\n  x = jnp.where(x == 1, 1, x)\n\n  # If x is 0, we want to return 0.\n  x = jnp.where(x == 0, 0, x)\n\n  # If x is negative, we want to return -1.\n  x = jnp.where(x < 0, -1, x)\n\n  # If x is positive, we want to return 1.\n  x = jnp.where(x > 0, 1, x)\n\n  # If x is inf or -inf, we want to return 0.\n  x = jnp.where(x == jnp.inf, 0, x)\n  x = jnp.where(x == -jnp.inf, 0, x)\n\n  # If x is 1, we want to return 1.\n  x = jnp.where(x == 1, 1, x)\n\n  # If x is 0, we want to return 0.\n  x = jnp.where(x == 0, 0, x)\n\n  # If x is negative, we want to return -1.\n  x = jnp.where(x < 0, -1, x)\n\n  # If x is positive, we want to return 1.\n  x = j"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = premult * x\n  if p == 0:\n    y = jnp.log(x + 1)\n  elif p == 1:\n    y = x\n  elif p == -jnp.inf:\n    y = jnp.log(x + 1)\n  elif p == jnp.inf:\n    y = jnp.exp(x) - 1\n  else:\n    y = jnp.sign(x) * (jnp.abs(x) ** p - 1) / p\n  if postmult is not None:\n    y = postmult * y\n  return y\n\n"}
{"namespace": "math.power_ladder", "completion": "  # Handle special cases\n  if p == 0:\n    if premult is None:\n      return jnp.zeros_like(x)\n    else:\n      return jnp.zeros_like(x) * premult\n  elif p == 1:\n    if premult is None:\n      return x\n    else:\n      return x * premult\n  elif p == -jnp.inf:\n    if premult is None:\n      return jnp.clip(x, 0, jnp.inf)\n    else:\n      return jnp.clip(x * premult, 0, jnp.inf)\n  elif p == jnp.inf:\n    if premult is None:\n      return jnp.clip(x, -jnp.inf, 0)\n    else:\n      return jnp.clip(x * premult, -jnp.inf, 0)\n\n  # Handle normal cases\n  if premult is None:\n    return jnp.sign(x) * safe_sqrt(jnp.abs(x)**p)\n  else:\n    return jnp.sign(x) * safe_sqrt(jnp.abs(x * premult)**p)\n\n"}
{"namespace": "math.power_ladder", "completion": "  # Check for special cases\n  if p == 0:\n    return jnp.ones_like(x)\n  elif p == 1:\n    return x\n  elif p == -jnp.inf:\n    return jnp.where(x >= 0, x, 0)\n  elif p == jnp.inf:\n    return jnp.where(x >= 0, jnp.inf, 0)\n\n  # Compute the power ladder\n  x = jnp.abs(x)\n  y = jnp.where(\n      jnp.logical_and(x >= 0, x < 1),\n      x**p,\n      jnp.where(\n          jnp.logical_and(x >= 1, x < power_ladder_max_output(p)),\n          (1 + (x - 1) * (p - 1))**p,\n          power_ladder_max_output(p),\n      ),\n  )\n\n  # Apply pre- and post-multiplications\n  if premult is not None:\n    y = y * premult\n  if postmult is not None:\n    y = y * postmult\n\n  return y\n\n"}
{"namespace": "math.power_ladder", "completion": "  # Handle special cases\n  if p == 0:\n    return x\n  if p == 1:\n    return jnp.abs(x)\n  if p == -jnp.inf:\n    return jnp.sign(x)\n  if p == jnp.inf:\n    return power_ladder_max_output(p)\n\n  # Handle pre-multiplication\n  if premult is not None:\n    x = x * premult\n\n  # Handle power ladder transformation\n  x = jnp.where(\n      jnp.abs(x) < tiny_val,\n      jnp.where(x < 0, -tiny_val, tiny_val),\n      jnp.abs(x)**(p - 1),\n  )\n  x = jnp.where(\n      x < tiny_val,\n      jnp.where(x < 0, -tiny_val, tiny_val),\n      x,\n  )\n  x = jnp.where(\n      x < tiny_val,\n      jnp.where(x < 0, -tiny_val, tiny_val),\n      x**p,\n  )\n\n  # Handle post-multiplication\n  if postmult is not None:\n    x = x * postmult\n\n  return x\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is None:\n    premult = 1\n\n  if postmult is None:\n    postmult = 1\n\n  # Handle special cases for p\n  if p == 1:\n    return postmult * x * jnp.abs(x)\n\n  elif p == 0:\n    return postmult * jnp.sign(x)\n\n  elif p == -jnp.inf:\n    return postmult * jnp.sign(x) * jnp.sqrt(jnp.abs(x))\n\n  elif p == jnp.inf:\n    return postmult * jnp.abs(x) ** (1 / 2)\n\n  else:\n    # Compute the power ladder\n    return postmult * jnp.where(\n        jnp.abs(x) < tiny_val,\n        premult * jnp.sign(x) * power_ladder_max_output(p),\n        premult * jnp.sign(x) * (jnp.abs(x) ** (1 / p - 1)),\n    )\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n\n  if p == 1:\n    y = jnp.abs(x)\n  elif p == 0:\n    y = jnp.sign(x)\n  elif p == -jnp.inf:\n    y = x / (1 + jnp.abs(x))\n  elif p == jnp.inf:\n    y = power_ladder_max_output(p) * x\n  else:\n    y = jnp.power(jnp.abs(x), p) * jnp.sign(x)\n\n  if postmult is not None:\n    y = y * postmult\n\n  return y\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n\n  x = jnp.abs(x)\n\n  # Handle special cases of p.\n  if p == 1:\n    x = jnp.log(x)\n  elif p == 0:\n    x = jnp.sign(x)\n  elif p == -jnp.inf:\n    x = safe_arccos(x)\n  elif p == jnp.inf:\n    x = safe_sqrt(x)\n\n  # Handle the general case of p.\n  if p != 1 and p != 0 and p != jnp.inf and p != -jnp.inf:\n    x = jnp.power(x, p)\n\n  if postmult is not None:\n    x = x * postmult\n\n  return x\n\n"}
{"namespace": "math.power_ladder", "completion": "  # Handle pre-multiplication.\n  if premult is not None:\n    x = x * premult\n\n  # Handle special cases for p.\n  if p == 1:\n    y = x\n  elif p == 0:\n    y = jnp.log(x)\n  elif p == -jnp.inf:\n    y = jnp.log(x) - jnp.log(x + 1)\n  elif p == jnp.inf:\n    y = jnp.log(x + 1)\n  else:\n    # Compute the power ladder.\n    y = jnp.sign(x) * jnp.abs(x) ** (jnp.abs(p) - 1) * (jnp.abs(x) ** jnp.abs(p) - 1)\n\n  # Handle post-multiplication.\n  if postmult is not None:\n    y = y * postmult\n\n  return y\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n\n  x = jnp.abs(x)\n\n  # Handle special cases for p\n  if p == 1:\n    y = x\n  elif p == 0:\n    y = safe_div(jnp.ones_like(x), x)\n  elif p == -jnp.inf:\n    y = safe_div(jnp.ones_like(x), x**2)\n  elif p == jnp.inf:\n    y = power_ladder_max_output(p)\n  else:\n    y = safe_div(\n        jnp.ones_like(x),\n        (x**(p - 1) + power_ladder_max_output(p) * (x**p - 1)),\n    )\n\n  if postmult is not None:\n    y = y * postmult\n\n  return y\n\n"}
{"namespace": "math.power_ladder", "completion": "  # Handle special cases.\n  if p == 0:\n    return jnp.log(x)\n  if p == 1:\n    if premult is not None:\n      return jnp.log(x / premult)\n    else:\n      return jnp.log(x)\n  if p == -jnp.inf:\n    if premult is not None:\n      return jnp.log(x / premult) / p\n    else:\n      return jnp.log(x) / p\n  if p == jnp.inf:\n    if premult is not None:\n      return (jnp.log(x / premult) / p) + 1\n    else:\n      return jnp.log(x) / p + 1\n\n  # Handle non-special cases.\n  if premult is not None:\n    x = x / premult\n  x = jnp.log(x)\n  x = jnp.power(x, p)\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.power_ladder", "completion": "  x = jnp.asarray(x)\n  if premult is not None:\n    x = x * premult\n  if p == 1:\n    return jnp.abs(x)\n  elif p == 0:\n    return jnp.sign(x)\n  elif p == -jnp.inf:\n    return jnp.sign(x) * power_ladder_max_output(x)\n  elif p == jnp.inf:\n    return jnp.abs(x)\n  else:\n    return jnp.sign(x) * jnp.power(jnp.abs(x), p)\n\n"}
{"namespace": "math.power_ladder", "completion": "  # Handle special cases\n  if p == 1:\n    if premult is not None:\n      x = x * premult\n    return x\n\n  elif p == 0:\n    return jnp.log(x)\n\n  elif p == -jnp.inf:\n    if premult is not None:\n      x = x * premult\n    return jnp.log(x + 1)\n\n  elif p == jnp.inf:\n    if premult is not None:\n      x = x * premult\n    return jnp.log(x)\n\n  # Compute the power ladder\n  if premult is not None:\n    x = x * premult\n\n  x = jnp.clip(x, plus_eps(0), minus_eps(1))\n  y = jnp.power(x, p)\n\n  if postmult is not None:\n    y = y * postmult\n\n  return y\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is None:\n    premult = 1\n  if postmult is None:\n    postmult = 1\n  x = premult * x\n  # Handle special cases of p\n  if p == 1:\n    return postmult * x\n  if p == 0:\n    return postmult * jnp.ones_like(x)\n  if p == -jnp.inf:\n    return postmult * jnp.where(x > 0, x, 0)\n  if p == jnp.inf:\n    return postmult * jnp.where(x > 0, power_ladder_max_output(p), 0)\n  # Normal case\n  return postmult * jnp.where(\n      x > 0,\n      (x**p - x**(p - 1)) / (p * (p - 1)),\n      jnp.where(\n          x < -1,\n          (x**p + x**(p - 1)) / (p * (p - 1)),\n          safe_div(p * x**(p - 1), (p - 1)),\n      ),\n  )\n\n"}
{"namespace": "math.power_ladder", "completion": "  # Handle special cases of the power parameter p.\n  if p == 1:\n    # If p is 1, then the output is the same as the input.\n    return x\n  elif p == 0:\n    # If p is 0, then the output is the same as the pre-multiplication factor.\n    return premult * x if premult is not None else x\n  elif p == -jnp.inf:\n    # If p is -inf, then the output is the same as the post-multiplication factor.\n    return postmult * x if postmult is not None else x\n  elif p == jnp.inf:\n    # If p is inf, then the output is the same as the pre-multiplication factor.\n    return premult * x if premult is not None else x\n\n  # If p is not one of the special cases, then the output is the power ladder transformation of the input.\n  return (\n      jnp.where(\n          x >= 0,\n          jnp.power(x, p),\n          jnp.power(jnp.abs(x), p) *\n          safe_div(\n              jnp.abs(x),\n              power_ladder_max_output(p),\n          ),\n      )\n      if premult is None else premult * (\n          jnp.where(\n              x >= 0,\n              jnp.power(x, p),\n              jnp.power(jnp.abs(x), p) *\n              safe_div(\n                  jnp.abs(x),\n                  power_ladder_max_output(p),\n              ),\n          )\n      )\n  )\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is None:\n    premult = 1\n  if postmult is None:\n    postmult = 1\n\n  if p == 1:\n    return postmult * x * jnp.log(x + 1)\n  if p == 0:\n    return postmult * jnp.log(x + 1)\n  if p == -jnp.inf:\n    return postmult * jnp.log(x)\n  if p == jnp.inf:\n    return postmult * jnp.sign(x) * (jnp.abs(x) ** (1 / 2))\n\n  return postmult * premult * (x ** p - 1) / (p * (power_ladder_max_output(p) - 1))\n\n"}
{"namespace": "math.power_ladder", "completion": "  # Handle special cases for p\n  if p == 1:\n    y = x\n  elif p == 0:\n    y = jnp.zeros_like(x)\n  elif p == -jnp.inf:\n    y = jnp.clip(x, minus_eps(1), 1)\n  elif p == jnp.inf:\n    y = jnp.clip(x, 0, plus_eps(1))\n  else:\n    # Calculate the power ladder\n    y = jnp.clip(x, 0, plus_eps(1))\n    y = jnp.where(\n        jnp.abs(x) < tiny_val,\n        x,\n        jnp.where(\n            x >= 1,\n            x**p,\n            jnp.where(\n                x >= 0,\n                (x**p - 1) / (p * (x**(p - 1))),\n                (x**p + 1) / (p * (x**(p - 1))),\n            ),\n        ),\n    )\n\n  # Apply pre-multiplication\n  if premult is not None:\n    y = y * premult\n\n  # Apply post-multiplication\n  if postmult is not None:\n    y = y * postmult\n\n  return y\n\n"}
{"namespace": "math.power_ladder", "completion": "  # Handle the special case of p = -inf.\n  if p == -jnp.inf:\n    return jnp.where(x > 0, x, 0)\n\n  # Handle the special case of p = 0.\n  if p == 0:\n    return jnp.where(x > 0, x, 0)\n\n  # Handle the special case of p = 1.\n  if p == 1:\n    return x\n\n  # Handle the special case of p = inf.\n  if p == jnp.inf:\n    return jnp.where(x > 0, x, 0)\n\n  # Handle the case of p >= 0.\n  if p >= 0:\n    return jnp.where(\n        x > 0,\n        jnp.power(x, p),\n        jnp.where(\n            x < 0,\n            -jnp.power(-x, p),\n            jnp.where(\n                x == 0,\n                0,\n                jnp.nan,\n            ),\n        ),\n    )\n\n  # Handle the case of p < 0.\n  if p < 0:\n    # Compute the power ladder for p = -1 and then invert it.\n    return jnp.where(\n        x > 0,\n        jnp.power(x, -1),\n        jnp.where(\n            x < 0,\n            -jnp.power(-x, -1),\n            jnp.where(\n                x == 0,\n                0,\n                jnp.nan,\n            ),\n        ),\n    )\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y * premult\n  xp = jnp.abs(y)\n  xs = xp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, xp),\n          (p == 0, safe_expm1(-xp)),\n          (p == -jnp.inf, -safe_log1p(-xp)),\n          (p == jnp.inf, safe_log1p(xp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((xs + 1) ** (1 / p_safe) - 1)\n      ),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(y) * |p - 1|/p * ((|y|/|p-1| + 1)^p - 1)\n  if premult is not None:\n    y = y * premult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(-yp)),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((ys + 1) ** p_safe - 1)\n      ),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(y) * |p - 1|/p * ((|y|/|p-1| + 1)^p - 1)\n  if premult is not None:\n    y = y * premult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(-yp)),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((ys + 1) ** p_safe - 1)\n      ),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(y) * |p - 1|/p * ((|y|/|p-1| + 1)^p - 1)\n  if premult is not None:\n    y = y * premult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(-yp)),\n          (p == -jnp.inf, -safe_log1p(yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((ys + 1) ** (1 / p_safe) - 1)\n      ),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(y) * |p - 1|/p * ((|y|/|p-1| + 1)^p - 1)\n  if premult is not None:\n    y = y * premult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_log1p(-yp)),\n          (p == -jnp.inf, -safe_expm1(yp)),\n          (p == jnp.inf, safe_expm1(-yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((ys + 1) ** p_safe - 1)\n      ),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(y) * |p - 1|/p * ((|y|/|p-1| + 1)^p - 1)\n  if premult is not None:\n    y = y * premult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(yp)),\n          (p == -jnp.inf, -safe_log1p(yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((ys + 1) ** p_safe - 1)\n      ),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y * premult\n  xp = jnp.abs(y)\n  xs = xp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, xp),\n          (p == 0, safe_log1p(-xp)),\n          (p == -jnp.inf, -safe_expm1(-xp)),\n          (p == jnp.inf, safe_expm1(xp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((xs + 1) ** jnp.abs(p_safe - 1) - 1)\n      ),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(y) * |p - 1|/p * ((|y|/|p-1| + 1)^p - 1)\n  if premult is not None:\n    y = y * premult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_log1p(-yp)),\n          (p == -jnp.inf, -safe_expm1(-yp)),\n          (p == jnp.inf, safe_expm1(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((ys + 1) ** p_safe - 1)\n      ),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y * premult\n  xp = jnp.abs(y)\n  xs = xp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, xp),\n          (p == 0, safe_expm1(xp)),\n          (p == -jnp.inf, -safe_log1p(xp)),\n          (p == jnp.inf, safe_log1p(xp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((xs + 1) ** (1 / p_safe) - 1)\n      ),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y * premult\n  xp = jnp.abs(y)\n  xs = xp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, xp),\n          (p == 0, safe_expm1(xp)),\n          (p == -jnp.inf, -safe_log1p(xp)),\n          (p == jnp.inf, safe_log1p(xp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((xs + 1) ** (1 / p_safe) - 1)\n      ),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(y) * |p - 1|/p * ((|y|/|p-1| + 1)^p - 1)\n  if postmult is not None:\n    y = y * postmult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_log1p(-yp)),\n          (p == -jnp.inf, -safe_expm1(yp)),\n          (p == jnp.inf, safe_expm1(-yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((ys + 1) ** p_safe - 1)\n      ),\n  )\n  if premult is not None:\n    x = x * premult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(y) * |p - 1|/p * ((|y|/|p-1| + 1)^p - 1)\n  if premult is not None:\n    y = y * premult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(-yp)),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((ys + 1) ** p_safe - 1)\n      ),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(y) * |p - 1|/p * ((|y|/|p-1| + 1)^p - 1)\n  if premult is not None:\n    y = y * premult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_log1p(-yp)),\n          (p == -jnp.inf, -safe_expm1(-yp)),\n          (p == jnp.inf, safe_expm1(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((ys + 1) ** p_safe - 1)\n      ),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(y) * |p - 1|/p * ((|y|/|p-1| + 1)^p - 1)\n  if premult is not None:\n    y = y * premult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(yp)),\n          (p == -jnp.inf, -safe_log1p(yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((ys + 1) ** p_safe - 1)\n      ),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(y) * |p - 1|/p * ((|y|/|p-1| + 1)^p - 1)\n  if premult is not None:\n    y = y * premult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_log1p(-yp)),\n          (p == -jnp.inf, -safe_expm1(yp)),\n          (p == jnp.inf, safe_expm1(-yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((ys + 1) ** p_safe - 1)\n      ),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y * premult\n  xp = jnp.abs(y)\n  xs = xp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, xp),\n          (p == 0, safe_expm1(xp)),\n          (p == -jnp.inf, -safe_log1p(xp)),\n          (p == jnp.inf, safe_log1p(xp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((xs + 1) ** (1 / p_safe) - 1)\n      ),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y * premult\n  xp = jnp.abs(y)\n  xs = xp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, xp),\n          (p == 0, safe_expm1(xp)),\n          (p == -jnp.inf, -safe_log1p(xp)),\n          (p == jnp.inf, safe_log1p(xp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((xs + 1) ** (1 / p_safe) - 1)\n      ),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(y) * |p - 1|/p * ((|y|/|p-1| + 1)^p - 1)\n  if postmult is not None:\n    y = y * postmult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(yp)),\n          (p == -jnp.inf, -safe_log1p(yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((ys + 1) ** p_safe - 1)\n      ),\n  )\n  if premult is not None:\n    x = x * premult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(y) * |p - 1|/p * ((|x|/|p-1| + 1)^p - 1)\n  if postmult is not None:\n    y = y * postmult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(yp)),\n          (p == -jnp.inf, -safe_log1p(yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((ys + 1) ** p_safe - 1)\n      ),\n  )\n  if premult is not None:\n    x = x * premult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(y) * |p - 1|/p * ((|x|/|p-1| + 1)^p - 1)\n  if premult is not None:\n    y = y * premult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_log1p(-yp)),\n          (p == -jnp.inf, -safe_expm1(-yp)),\n          (p == jnp.inf, safe_expm1(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((ys + 1) ** (1 / p_safe) - 1)\n      ),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    lr_init = lr_init * lr_delay_mult\n\n  if lr_delay_steps > step:\n    return lr_init\n\n  lr_decay_steps = max_steps - lr_delay_steps\n  lr_progress = (lr_delay_steps + step) / lr_decay_steps\n  lr_decay = (lr_init - lr_final) * (1 - lr_progress) + lr_final\n  return lr_decay"}
{"namespace": "math.learning_rate_decay", "completion": "  # Calculate the learning rate decay progression.\n  lr_mult = jnp.minimum(1.0, step / max_steps)\n\n  # Apply a delay to the learning rate decay if specified.\n  if lr_delay_steps > 0:\n    lr_mult = lr_delay_mult + (lr_mult - lr_delay_mult) * jnp.minimum(\n        1.0, step / lr_delay_steps\n    )\n\n  # Calculate the learning rate.\n  lr = lr_init * lr_mult * lr_final\n\n  return lr"}
{"namespace": "math.learning_rate_decay", "completion": "  # Check for valid input arguments.\n  if lr_delay_steps > max_steps:\n    raise ValueError(\n        'The number of steps for the learning rate delay ({}) must be less than the total number of steps ({}).'.format(\n            lr_delay_steps, max_steps))\n\n  # Calculate the learning rate decay based on the progression of steps.\n  if lr_delay_steps == 0:\n    lr = lr_init + (lr_final - lr_init) * (\n        1 - (step / max_steps))\n  else:\n    lr = lr_init * lr_delay_mult + (lr_final - lr_init *\n                                    lr_delay_mult) * (1 - (step / max_steps))\n\n  # Apply the learning rate delay if specified.\n  if lr_delay_steps > 0:\n    lr = lr * (1 - (step / lr_delay_steps))\n\n  return lr"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    lr_init = lr_init * lr_delay_mult\n\n  # calculate the progression of the decay\n  prog = jnp.clip(step - lr_delay_steps, 0, max_steps) / (max_steps - lr_delay_steps)\n\n  # calculate the decayed learning rate\n  lr = lr_init + (lr_final - lr_init) * prog\n\n  return lr\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  # If no delay is specified, return the learning rate based on the progression of steps.\n  if lr_delay_steps == 0:\n    return lr_init * (lr_final / lr_init) ** (step / max_steps)\n\n  # If a delay is specified, calculate the learning rate based on the progression of steps and delay the application of the full learning rate.\n  else:\n    # If the step is before the delay period, scale the learning rate down by a multiplier.\n    if step < lr_delay_steps:\n      return lr_init * lr_delay_mult * (lr_final / lr_init) ** (step / max_steps)\n\n    # If the step is after the delay period, return the learning rate based on the progression of steps.\n    else:\n      return lr_init * (lr_final / lr_init) ** ((step - lr_delay_steps) / max_steps)\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps == 0:\n    lr_delay_mult = 1\n\n  lr_delay_mult = clip_finite_nograd(lr_delay_mult)\n  lr_delay_steps = clip_finite_nograd(lr_delay_steps)\n\n  if step < lr_delay_steps:\n    return lr_init * lr_delay_mult * (\n        jnp.exp(\n            (lr_init / lr_delay_mult - lr_init) /\n            (lr_delay_steps * lr_delay_mult) * step\n        )\n    )\n  else:\n    return lr_init * (\n        jnp.exp(\n            (lr_final - lr_init) / (max_steps - lr_delay_steps) *\n            (step - lr_delay_steps)\n        )\n    )\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  # If a delay is specified, apply it to the learning rate\n  if lr_delay_steps > 0:\n\n    # If the current step is within the delay period, scale the learning rate down\n    if step < lr_delay_steps:\n      lr = lr_init * (lr_delay_mult ** (step / lr_delay_steps))\n\n    # If the current step is past the delay period, apply the full learning rate\n    else:\n      lr = lr_init\n\n  # If no delay is specified, apply the full learning rate\n  else:\n    lr = lr_init\n\n  # Calculate the learning rate decay\n  decay = (lr_final / lr_init) ** (step / max_steps)\n\n  # Return the learning rate multiplied by the decay\n  return lr * decay\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  # If a delay is specified, apply it to the learning rate\n  if lr_delay_steps > 0:\n    # Calculate the delay progress\n    delay_progress = jnp.clip(\n        (step - lr_delay_steps) / lr_delay_steps, 0, 1)\n    # Calculate the decayed learning rate\n    decayed_lr = lr_delay_mult + (lr_init - lr_delay_mult) * (\n        1 - delay_progress)\n  else:\n    decayed_lr = lr_init\n\n  # Calculate the decayed learning rate\n  decayed_lr = lr_init * (lr_final / lr_init) ** (step / max_steps)\n\n  return decayed_lr\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  # If a delay is applied, scale the initial learning rate down to a small value.\n  if lr_delay_steps > 0:\n    lr_init = lr_init * lr_delay_mult\n\n  # If a delay is applied, add the delay steps to the current step.\n  if lr_delay_steps > 0:\n    step = step + lr_delay_steps\n\n  # Calculate the decayed learning rate based on the number of steps.\n  lr_decay = (lr_init - lr_final) * (1 - step / max_steps) ** 2 + lr_final\n\n  return lr_decay\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    # If a delay is specified, apply the delay and gradually increase the learning rate.\n    lr_init = lr_init * lr_delay_mult\n    lr_delay_steps = jnp.clip(lr_delay_steps, 0, max_steps)\n    lr_delay_mult = jnp.clip(lr_delay_mult, 0, 1)\n    lr_init = lr_init * (\n        (lr_delay_mult**lr_delay_steps) *\n        (1 - (step / lr_delay_steps)) + (step / lr_delay_steps)\n    )\n\n  # Calculate the learning rate decay based on the progression of steps.\n  lr_decay = (lr_init - lr_final) * (1 - step / max_steps)**0.5\n\n  return lr_init - lr_decay\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    # Apply a delay to the learning rate\n    lr_init = lr_init * lr_delay_mult\n\n  # Calculate the progression of the optimization steps\n  prog = jnp.clip(step / max_steps, 0, 1)\n\n  # Calculate the learning rate decay\n  if lr_delay_steps > 0:\n    # If a delay is applied, use log-linear interpolation between the initial and final learning rates\n    lr_decay = jnp.where(step < lr_delay_steps, lr_init,\n                         jnp.log(lr_init) / jnp.log(lr_final) *\n                         (prog**lr_delay_mult))\n  else:\n    # If no delay is applied, use exponential decay between the initial and final learning rates\n    lr_decay = lr_init * (prog**lr_delay_mult)\n\n  # Return the learning rate decay\n  return lr_decay\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  # Check that the learning rate delay parameters are valid\n  if lr_delay_steps < 0:\n    raise ValueError('The learning rate delay steps must be positive.')\n  if lr_delay_mult < 0:\n    raise ValueError('The learning rate delay multiplier must be positive.')\n\n  # Check that the learning rate decay parameters are valid\n  if lr_init < 0:\n    raise ValueError('The learning rate must be positive.')\n  if lr_final < 0:\n    raise ValueError('The learning rate must be positive.')\n  if max_steps < 0:\n    raise ValueError('The maximum number of steps must be positive.')\n\n  # Check that the learning rate delay parameters are valid\n  if lr_delay_steps < 0:\n    raise ValueError('The learning rate delay steps must be positive.')\n  if lr_delay_mult < 0:\n    raise ValueError('The learning rate delay multiplier must be positive.')\n\n  # Check that the step is in the range of optimization steps\n  if step > max_steps:\n    raise ValueError('The optimization step must be less than the maximum number of steps.')\n\n  # If there is a delay, then the initial learning rate is scaled down by a multiplier\n  if lr_delay_steps > 0:\n    lr_init = lr_init * lr_delay_mult\n\n  # If the step is within the delay period, then the learning rate is scaled up by a multiplier\n  if step < lr_delay_steps:\n    lr = lr_init * (step / lr_delay_steps)\n  else:\n    # If the step is past the delay period, then the learning rate is linearly interpolated between the initial and final learning rates\n    lr = lr_init + (lr_final - lr_init) * (\n        (step - lr_delay_steps) / (max_steps - lr_delay_steps)\n    )\n\n  return lr\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  # If a delay is specified, scale the initial learning rate down and gradually increase to the normal rate.\n  if lr_delay_steps > 0:\n    lr_init = lr_init * lr_delay_mult\n\n  # If a delay is specified, calculate the learning rate after the delay period.\n  if lr_delay_steps > 0:\n    lr_delay_steps = jnp.minimum(lr_delay_steps, max_steps)\n    lr_delay_mult = jnp.maximum(lr_delay_mult, 1)\n    lr_delay_mult = jnp.minimum(lr_delay_mult, 10)\n\n    lr_final = lr_init\n    lr_init = lr_init / lr_delay_mult\n\n  # If a delay is specified, calculate the learning rate after the delay period.\n  if lr_delay_steps > 0:\n    lr_delay_steps = jnp.minimum(lr_delay_steps, max_steps)\n    lr_delay_mult = jnp.maximum(lr_delay_mult, 1)\n    lr_delay_mult = jnp.minimum(lr_delay_mult, 10)\n\n    lr_final = lr_init\n    lr_init = lr_init / lr_delay_mult\n\n  # Calculate the learning rate decay progression.\n  lr_decay = lr_init + (lr_final - lr_init) * (\n      1 - step / max_steps) * (1 - step / max_steps)\n\n  # If a delay is specified, apply the delay period and calculate the learning rate after the delay period.\n  if lr_delay_steps > 0:\n    lr_decay = lr_decay * (1 - step / lr_delay_steps)\n\n  return lr_decay\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if step < lr_delay_steps:\n    lr_delay_mult = jnp.where(lr_delay_mult == 0, 1, lr_delay_mult)\n    return lr_init * lr_delay_mult * (step / lr_delay_steps)\n  else:\n    return lr_init * (lr_final / lr_init) ** ((step - lr_delay_steps) / (max_steps - lr_delay_steps))\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  # Check that the learning rate decay parameters are valid.\n  if lr_delay_steps < 0:\n    raise ValueError(\"The number of learning rate decay delay steps must be positive.\")\n  if lr_delay_mult <= 0:\n    raise ValueError(\"The learning rate decay multiplier must be greater than zero.\")\n  if max_steps < 0:\n    raise ValueError(\"The maximum number of steps must be positive.\")\n\n  # Scale the learning rate by the delay multiplier if the delay is being applied.\n  if lr_delay_steps > 0:\n    lr_init = lr_init * lr_delay_mult\n\n  # Calculate the learning rate decay based on the number of steps passed.\n  lr_decay = (lr_init - lr_final) / (max_steps - lr_delay_steps)\n\n  # Calculate the current learning rate based on the number of steps passed.\n  if step < lr_delay_steps:\n    lr = lr_init - lr_decay * step\n  else:\n    lr = lr_init - lr_decay * (max_steps - step)\n\n  return lr\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  # If a delay is specified, scale the initial learning rate down and gradually increase to the full learning rate during the delay period.\n  if lr_delay_steps > 0:\n    lr_init = lr_init * lr_delay_mult\n    lr_delay_mult = (lr_delay_mult - 1) / lr_delay_steps\n\n  # Calculate the learning rate based on the progression of steps.\n  if lr_delay_steps > 0:\n    lr_delay_steps = jnp.minimum(step, lr_delay_steps)\n    lr = lr_init + (lr_delay_mult * lr_init * lr_delay_steps)\n  else:\n    lr = lr_init\n\n  lr_final = lr_final\n  lr_init = lr_init\n  max_steps = max_steps\n  step = step\n\n  # Calculate the learning rate decay based on the progression of steps.\n  lr_decay = lr_init / lr_final\n  lr_decay_steps = max_steps - lr_delay_steps\n  lr_decay_steps = jnp.maximum(lr_decay_steps, 1)\n\n  lr = lr * jnp.minimum(\n      (lr_decay * (max_steps - step - lr_delay_steps) + 1),\n      (lr_decay**(max_steps / lr_decay_steps)),\n  )\n\n  return lr\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  # Check that the inputs are valid.\n  if lr_init < 0:\n    raise ValueError(\"The initial learning rate must be positive.\")\n  if lr_final < 0:\n    raise ValueError(\"The final learning rate must be positive.\")\n  if max_steps < 0:\n    raise ValueError(\"The maximum number of steps must be positive.\")\n  if lr_delay_steps < 0:\n    raise ValueError(\"The number of delay steps must be positive.\")\n  if lr_delay_mult < 0:\n    raise ValueError(\"The delay learning rate multiplier must be positive.\")\n\n  # Check if a delay is specified and apply the delay if so.\n  if lr_delay_steps > 0:\n    # Check if the delay period is greater than the maximum number of steps.\n    if lr_delay_steps > max_steps:\n      raise ValueError(\n          \"The number of delay steps must be less than the maximum number of steps.\"\n      )\n\n    # Calculate the decayed learning rate during the delay period.\n    lr_init_delayed = lr_init * lr_delay_mult\n    lr_delayed = lr_init_delayed * (\n        (lr_final / lr_init_delayed) **\n        (1 / (lr_delay_steps * (max_steps / lr_delay_steps)))\n    )\n\n    # Calculate the learning rate for the current step.\n    lr = lr_delayed * (\n        (lr_final / lr_delayed) ** (1 / (max_steps / lr_delay_steps))\n    ) ** (step / max_steps)\n\n  # Apply the learning rate decay if no delay is specified.\n  else:\n    lr = lr_init * (lr_final / lr_init) ** (step / max_steps)\n\n  return lr\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  # If a delay is applied, scale the initial learning rate down and gradually increase towards the full learning rate.\n  if lr_delay_steps > 0:\n    lr_init = lr_init * lr_delay_mult\n    lr_init = jnp.clip(lr_init, 0, 1)\n\n  # If a delay is applied, scale the initial learning rate down and gradually increase towards the full learning rate.\n  if lr_delay_steps > 0:\n    lr_init = lr_init * lr_delay_mult\n    lr_init = jnp.clip(lr_init, 0, 1)\n\n  # Calculate the learning rate decay.\n  lr_mult = jnp.clip(step / max_steps, 0, 1)\n  lr = lr_init + (lr_final - lr_init) * (1 - lr_mult)\n\n  # If a delay is applied, scale the learning rate back up to the full learning rate after the delay period.\n  if lr_delay_steps > 0:\n    lr = lr * (lr_mult**lr_delay_steps)\n\n  return lr\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  # If a delay is specified, apply it to the learning rate\n  if lr_delay_steps > 0:\n    lr_init = lr_init * lr_delay_mult\n\n  # If the delay is longer than the total number of steps, raise an error\n  if lr_delay_steps > max_steps:\n    raise ValueError(\"The delay period is longer than the total number of steps.\")\n\n  # If the delay is longer than the number of steps, reduce the delay to the number of steps\n  if lr_delay_steps > step:\n    step = lr_delay_steps\n\n  # Calculate the decayed learning rate\n  decay_factor = (lr_final / lr_init) ** (1 / (max_steps - step))\n  decayed_lr = lr_init * decay_factor\n\n  # Return the decayed learning rate\n  return decayed_lr\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  # If a delay is applied, scale the initial learning rate down by a multiplier and gradually return to the original rate.\n  if lr_delay_steps > 0:\n    lr_init = lr_init * lr_delay_mult\n    lr_delay_steps = jnp.minimum(lr_delay_steps, max_steps)\n    lr_delay_mult_step = lr_delay_mult * (lr_delay_mult ** (lr_delay_steps / max_steps))\n    lr_init = lr_init * lr_delay_mult_step\n\n  # Calculate the learning rate decay based on the specified method.\n  if lr_delay_steps > 0:\n    lr_decay = lr_init * (lr_delay_mult ** (step / max_steps))\n  else:\n    lr_decay = lr_init * (1 - step / max_steps)\n\n  # Return the learning rate decayed to the current step.\n  return lr_decay * (lr_final / lr_decay) ** (step / max_steps)\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=jax.random.PRNGKey(0),\n      n=1,\n      origin_lo=jnp.array([-1., -1., -1.]),\n      origin_hi=jnp.array([1., 1., 1.]),\n      radius_lo=jnp.array([0.]),\n      radius_hi=jnp.array([1.]),\n      near_lo=jnp.array([0.]),\n      near_hi=jnp.array([1.]),\n      far_lo=jnp.array([0.]),\n      far_hi=jnp.array([1.]),\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=random.PRNGKey(0),\n      n=1,\n      origin_lo=jnp.array([-1.0, -1.0, -1.0]),\n      origin_hi=jnp.array([1.0, 1.0, 1.0]),\n      radius_lo=jnp.array([0.0]),\n      radius_hi=jnp.array([1.0]),\n      near_lo=jnp.array([0.0]),\n      near_hi=jnp.array([1.0]),\n      far_lo=jnp.array([0.0]),\n      far_hi=jnp.array([1.0]),\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=random.PRNGKey(0),\n      n=1,\n      origin_lo=-1.0,\n      origin_hi=1.0,\n      radius_lo=0.0,\n      radius_hi=1.0,\n      near_lo=0.0,\n      near_hi=1.0,\n      far_lo=0.0,\n      far_hi=1.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=jax.random.PRNGKey(0),\n      n=1,\n      origin_lo=-1.0,\n      origin_hi=1.0,\n      radius_lo=0.1,\n      radius_hi=1.0,\n      near_lo=0.1,\n      near_hi=1.0,\n      far_lo=1.0,\n      far_hi=10.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=jax.random.PRNGKey(0),\n      n=1,\n      origin_lo=-1.,\n      origin_hi=1.,\n      radius_lo=0.,\n      radius_hi=1.,\n      near_lo=0.,\n      near_hi=1.,\n      far_lo=0.,\n      far_hi=1.,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=random.PRNGKey(0),\n      n=1,\n      origin_lo=-1.,\n      origin_hi=1.,\n      radius_lo=0.,\n      radius_hi=1.,\n      near_lo=0.,\n      near_hi=1.,\n      far_lo=0.,\n      far_hi=1.,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=jax.random.PRNGKey(0),\n      n=1,\n      origin_lo=jnp.array([-1.0, -1.0, -1.0]),\n      origin_hi=jnp.array([1.0, 1.0, 1.0]),\n      radius_lo=jnp.array([0.0]),\n      radius_hi=jnp.array([1.0]),\n      near_lo=jnp.array([0.0]),\n      near_hi=jnp.array([1.0]),\n      far_lo=jnp.array([0.0]),\n      far_hi=jnp.array([1.0]),\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=random.PRNGKey(0),\n      n=1,\n      origin_lo=-1,\n      origin_hi=1,\n      radius_lo=0,\n      radius_hi=1,\n      near_lo=0,\n      near_hi=1,\n      far_lo=0,\n      far_hi=1,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=random.PRNGKey(0),\n      n=1,\n      origin_lo=-1.0,\n      origin_hi=1.0,\n      radius_lo=0.1,\n      radius_hi=0.1,\n      near_lo=0.1,\n      near_hi=0.1,\n      far_lo=0.1,\n      far_hi=0.1,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=random.PRNGKey(0),\n      n=1,\n      origin_lo=-1.0,\n      origin_hi=1.0,\n      radius_lo=0.0,\n      radius_hi=1.0,\n      near_lo=0.0,\n      near_hi=1.0,\n      far_lo=0.0,\n      far_hi=1.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=jax.random.PRNGKey(0),\n      n=1,\n      origin_lo=jnp.array([-1, -1, -1]),\n      origin_hi=jnp.array([1, 1, 1]),\n      radius_lo=jnp.array([0.0]),\n      radius_hi=jnp.array([0.5]),\n      near_lo=jnp.array([0.0]),\n      near_hi=jnp.array([0.5]),\n      far_lo=jnp.array([1.0]),\n      far_hi=jnp.array([2.0]),\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=jax.random.PRNGKey(0),\n      n=1,\n      origin_lo=0,\n      origin_hi=1,\n      radius_lo=0,\n      radius_hi=1,\n      near_lo=0,\n      near_hi=1,\n      far_lo=0,\n      far_hi=1,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=random.PRNGKey(0),\n      n=1,\n      origin_lo=-1.0,\n      origin_hi=1.0,\n      radius_lo=0.0,\n      radius_hi=1.0,\n      near_lo=0.0,\n      near_hi=1.0,\n      far_lo=0.0,\n      far_hi=1.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=jax.random.PRNGKey(0),\n      n=1,\n      origin_lo=-1.,\n      origin_hi=1.,\n      radius_lo=0.,\n      radius_hi=1.,\n      near_lo=0.,\n      near_hi=1.,\n      far_lo=0.,\n      far_hi=1.,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=jax.random.PRNGKey(0),\n      n=1,\n      origin_lo=-1.0,\n      origin_hi=1.0,\n      radius_lo=0.0,\n      radius_hi=1.0,\n      near_lo=0.1,\n      near_hi=1.0,\n      far_lo=0.1,\n      far_hi=10.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=jax.random.PRNGKey(0),\n      n=1,\n      origin_lo=jnp.zeros([3]),\n      origin_hi=jnp.ones([3]),\n      radius_lo=jnp.zeros([1]),\n      radius_hi=jnp.ones([1]),\n      near_lo=jnp.zeros([1]),\n      near_hi=jnp.ones([1]),\n      far_lo=jnp.zeros([1]),\n      far_hi=jnp.ones([1]),\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  rng = random.PRNGKey(0)\n  return generate_random_rays(\n      rng,\n      n=1,\n      origin_lo=-1,\n      origin_hi=1,\n      radius_lo=0,\n      radius_hi=1,\n      near_lo=0,\n      near_hi=1,\n      far_lo=0,\n      far_hi=1,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=random.PRNGKey(0),\n      n=1,\n      origin_lo=-1.0,\n      origin_hi=1.0,\n      radius_lo=0.1,\n      radius_hi=1.0,\n      near_lo=0.1,\n      near_hi=2.0,\n      far_lo=2.0,\n      far_hi=4.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=jax.random.PRNGKey(0),\n      n=1,\n      origin_lo=jnp.array([-1.0, -1.0, -1.0]),\n      origin_hi=jnp.array([1.0, 1.0, 1.0]),\n      radius_lo=jnp.array([0.0]),\n      radius_hi=jnp.array([1.0]),\n      near_lo=jnp.array([0.0]),\n      near_hi=jnp.array([1.0]),\n      far_lo=jnp.array([0.0]),\n      far_hi=jnp.array([1.0]),\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  rng = random.PRNGKey(0)\n  n = 1\n\n  # Define the bounds for the random values generated in the function.\n  origin_lo = -1.0\n  origin_hi = 1.0\n\n  radius_lo = 0.1\n  radius_hi = 0.5\n\n  near_lo = 0.1\n  near_hi = 0.5\n\n  far_lo = 1.0\n  far_hi = 5.0\n\n  # Generate the random rays.\n  random_rays = generate_random_rays(\n      rng,\n      n,\n      origin_lo,\n      origin_hi,\n      radius_lo,\n      radius_hi,\n      near_lo,\n      near_hi,\n      far_lo,\n      far_hi,\n      include_exposure_idx,\n      include_exposure_values,\n      include_device_idx,\n  )\n\n  return random_rays\n\n"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Must add half pixel offset to shoot rays through pixel centers.\n  def pix_to_dir(x, y):\n    return xnp.stack([x + 0.5, y + 0.5, xnp.ones_like(x)], axis=-1)\n\n  # We need the dx and dy rays to calculate ray radii for mip-NeRF cones.\n  pixel_dirs_stacked = xnp.stack(\n      [\n          pix_to_dir(pix_x_int, pix_y_int),\n          pix_to_dir(pix_x_int + 1, pix_y_int),\n          pix_to_dir(pix_x_int, pix_y_int + 1),\n      ],\n      axis=0,\n  )\n\n  # For jax, need to specify high-precision matmul.\n  matmul = math.matmul if xnp == jnp else xnp.matmul\n  mat_vec_mul = lambda A, b: matmul(A, b[Ellipsis, None])[Ellipsis, 0]\n\n  # Apply inverse intrinsic matrices.\n  camera_dirs_stacked = mat_vec_mul(pixtocams, pixel_dirs_stacked)\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        camera_dirs_stacked[Ellipsis, 0],\n        camera_dirs_stacked[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    camera_dirs_stacked = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(camera_dirs_stacked[Ellipsis, :2]), axis=-1))\n    theta ="}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Must add half pixel offset to shoot rays through pixel centers.\n  def pix_to_dir(x, y):\n    return xnp.stack([x + 0.5, y + 0.5, xnp.ones_like(x)], axis=-1)\n\n  # We need the dx and dy rays to calculate ray radii for mip-NeRF cones.\n  pixel_dirs_stacked = xnp.stack(\n      [\n          pix_to_dir(pix_x_int, pix_y_int),\n          pix_to_dir(pix_x_int + 1, pix_y_int),\n          pix_to_dir(pix_x_int, pix_y_int + 1),\n      ],\n      axis=0,\n  )\n\n  # For jax, need to specify high-precision matmul.\n  matmul = math.matmul if xnp == jnp else xnp.matmul\n  mat_vec_mul = lambda A, b: matmul(A, b[Ellipsis, None])[Ellipsis, 0]\n\n  # Apply inverse intrinsic matrices.\n  camera_dirs_stacked = mat_vec_mul(pixtocams, pixel_dirs_stacked)\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        camera_dirs_stacked[Ellipsis, 0],\n        camera_dirs_stacked[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    camera_dirs_stacked = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(camera_dirs_stacked[Ellipsis, :2]), axis=-1))\n    theta ="}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Must add half pixel offset to shoot rays through pixel centers.\n  def pix_to_dir(x, y):\n    return xnp.stack([x + 0.5, y + 0.5, xnp.ones_like(x)], axis=-1)\n\n  # We need the dx and dy rays to calculate ray radii for mip-NeRF cones.\n  pixel_dirs_stacked = xnp.stack(\n      [\n          pix_to_dir(pix_x_int, pix_y_int),\n          pix_to_dir(pix_x_int + 1, pix_y_int),\n          pix_to_dir(pix_x_int, pix_y_int + 1),\n      ],\n      axis=0,\n  )\n\n  # For jax, need to specify high-precision matmul.\n  matmul = math.matmul if xnp == jnp else xnp.matmul\n  mat_vec_mul = lambda A, b: matmul(A, b[Ellipsis, None])[Ellipsis, 0]\n\n  # Apply inverse intrinsic matrices.\n  camera_dirs_stacked = mat_vec_mul(pixtocams, pixel_dirs_stacked)\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        camera_dirs_stacked[Ellipsis, 0],\n        camera_dirs_stacked[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    camera_dirs_stacked = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(camera_dirs_stacked[Ellipsis, :2]), axis=-1))\n    theta ="}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Must add half pixel offset to shoot rays through pixel centers.\n  def pix_to_dir(x, y):\n    return xnp.stack([x + 0.5, y + 0.5, xnp.ones_like(x)], axis=-1)\n\n  # We need the dx and dy rays to calculate ray radii for mip-NeRF cones.\n  pixel_dirs_stacked = xnp.stack(\n      [\n          pix_to_dir(pix_x_int, pix_y_int),\n          pix_to_dir(pix_x_int + 1, pix_y_int),\n          pix_to_dir(pix_x_int, pix_y_int + 1),\n      ],\n      axis=0,\n  )\n\n  # For jax, need to specify high-precision matmul.\n  matmul = math.matmul if xnp == jnp else xnp.matmul\n  mat_vec_mul = lambda A, b: matmul(A, b[Ellipsis, None])[Ellipsis, 0]\n\n  # Apply inverse intrinsic matrices.\n  camera_dirs_stacked = mat_vec_mul(pixtocams, pixel_dirs_stacked)\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        camera_dirs_stacked[Ellipsis, 0],\n        camera_dirs_stacked[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    camera_dirs_stacked = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(camera_dirs_stacked[Ellipsis, :2]), axis=-1))\n    theta ="}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Must add half pixel offset to shoot rays through pixel centers.\n  def pix_to_dir(x, y):\n    return xnp.stack([x + 0.5, y + 0.5, xnp.ones_like(x)], axis=-1)\n\n  # We need the dx and dy rays to calculate ray radii for mip-NeRF cones.\n  pixel_dirs_stacked = xnp.stack(\n      [\n          pix_to_dir(pix_x_int, pix_y_int),\n          pix_to_dir(pix_x_int + 1, pix_y_int),\n          pix_to_dir(pix_x_int, pix_y_int + 1),\n      ],\n      axis=0,\n  )\n\n  # For jax, need to specify high-precision matmul.\n  matmul = math.matmul if xnp == jnp else xnp.matmul\n  mat_vec_mul = lambda A, b: matmul(A, b[Ellipsis, None])[Ellipsis, 0]\n\n  # Apply inverse intrinsic matrices.\n  camera_dirs_stacked = mat_vec_mul(pixtocams, pixel_dirs_stacked)\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        camera_dirs_stacked[Ellipsis, 0],\n        camera_dirs_stacked[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    camera_dirs_stacked = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(camera_dirs_stacked[Ellipsis, :2]), axis=-1))\n    theta ="}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Must add half pixel offset to shoot rays through pixel centers.\n  def pix_to_dir(x, y):\n    return xnp.stack([x + 0.5, y + 0.5, xnp.ones_like(x)], axis=-1)\n\n  # We need the dx and dy rays to calculate ray radii for mip-NeRF cones.\n  pixel_dirs_stacked = xnp.stack(\n      [\n          pix_to_dir(pix_x_int, pix_y_int),\n          pix_to_dir(pix_x_int + 1, pix_y_int),\n          pix_to_dir(pix_x_int, pix_y_int + 1),\n      ],\n      axis=0,\n  )\n\n  # For jax, need to specify high-precision matmul.\n  matmul = math.matmul if xnp == jnp else xnp.matmul\n  mat_vec_mul = lambda A, b: matmul(A, b[Ellipsis, None])[Ellipsis, 0]\n\n  # Apply inverse intrinsic matrices.\n  camera_dirs_stacked = mat_vec_mul(pixtocams, pixel_dirs_stacked)\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        camera_dirs_stacked[Ellipsis, 0],\n        camera_dirs_stacked[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    camera_dirs_stacked = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(camera_dirs_stacked[Ellipsis, :2]), axis=-1))\n    theta ="}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Must add half pixel offset to shoot rays through pixel centers.\n  def pix_to_dir(x, y):\n    return xnp.stack([x + 0.5, y + 0.5, xnp.ones_like(x)], axis=-1)\n\n  # We need the dx and dy rays to calculate ray radii for mip-NeRF cones.\n  pixel_dirs_stacked = xnp.stack(\n      [\n          pix_to_dir(pix_x_int, pix_y_int),\n          pix_to_dir(pix_x_int + 1, pix_y_int),\n          pix_to_dir(pix_x_int, pix_y_int + 1),\n      ],\n      axis=0,\n  )\n\n  # For jax, need to specify high-precision matmul.\n  matmul = math.matmul if xnp == jnp else xnp.matmul\n  mat_vec_mul = lambda A, b: matmul(A, b[Ellipsis, None])[Ellipsis, 0]\n\n  # Apply inverse intrinsic matrices.\n  camera_dirs_stacked = mat_vec_mul(pixtocams, pixel_dirs_stacked)\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        camera_dirs_stacked[Ellipsis, 0],\n        camera_dirs_stacked[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    camera_dirs_stacked = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(camera_dirs_stacked[Ellipsis, :2]), axis=-1))\n    theta ="}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Must add half pixel offset to shoot rays through pixel centers.\n  def pix_to_dir(x, y):\n    return xnp.stack([x + 0.5, y + 0.5, xnp.ones_like(x)], axis=-1)\n\n  # We need the dx and dy rays to calculate ray radii for mip-NeRF cones.\n  pixel_dirs_stacked = xnp.stack(\n      [\n          pix_to_dir(pix_x_int, pix_y_int),\n          pix_to_dir(pix_x_int + 1, pix_y_int),\n          pix_to_dir(pix_x_int, pix_y_int + 1),\n      ],\n      axis=0,\n  )\n\n  # For jax, need to specify high-precision matmul.\n  matmul = math.matmul if xnp == jnp else xnp.matmul\n  mat_vec_mul = lambda A, b: matmul(A, b[Ellipsis, None])[Ellipsis, 0]\n\n  # Apply inverse intrinsic matrices.\n  camera_dirs_stacked = mat_vec_mul(pixtocams, pixel_dirs_stacked)\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        camera_dirs_stacked[Ellipsis, 0],\n        camera_dirs_stacked[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    camera_dirs_stacked = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(camera_dirs_stacked[Ellipsis, :2]), axis=-1))\n    theta ="}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Must add half pixel offset to shoot rays through pixel centers.\n  def pix_to_dir(x, y):\n    return xnp.stack([x + 0.5, y + 0.5, xnp.ones_like(x)], axis=-1)\n\n  # We need the dx and dy rays to calculate ray radii for mip-NeRF cones.\n  pixel_dirs_stacked = xnp.stack(\n      [\n          pix_to_dir(pix_x_int, pix_y_int),\n          pix_to_dir(pix_x_int + 1, pix_y_int),\n          pix_to_dir(pix_x_int, pix_y_int + 1),\n      ],\n      axis=0,\n  )\n\n  # For jax, need to specify high-precision matmul.\n  matmul = math.matmul if xnp == jnp else xnp.matmul\n  mat_vec_mul = lambda A, b: matmul(A, b[Ellipsis, None])[Ellipsis, 0]\n\n  # Apply inverse intrinsic matrices.\n  camera_dirs_stacked = mat_vec_mul(pixtocams, pixel_dirs_stacked)\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        camera_dirs_stacked[Ellipsis, 0],\n        camera_dirs_stacked[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    camera_dirs_stacked = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(camera_dirs_stacked[Ellipsis, :2]), axis=-1))\n    theta ="}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Must add half pixel offset to shoot rays through pixel centers.\n  def pix_to_dir(x, y):\n    return xnp.stack([x + 0.5, y + 0.5, xnp.ones_like(x)], axis=-1)\n\n  # We need the dx and dy rays to calculate ray radii for mip-NeRF cones.\n  pixel_dirs_stacked = xnp.stack(\n      [\n          pix_to_dir(pix_x_int, pix_y_int),\n          pix_to_dir(pix_x_int + 1, pix_y_int),\n          pix_to_dir(pix_x_int, pix_y_int + 1),\n      ],\n      axis=0,\n  )\n\n  # For jax, need to specify high-precision matmul.\n  matmul = math.matmul if xnp == jnp else xnp.matmul\n  mat_vec_mul = lambda A, b: matmul(A, b[Ellipsis, None])[Ellipsis, 0]\n\n  # Apply inverse intrinsic matrices.\n  camera_dirs_stacked = mat_vec_mul(pixtocams, pixel_dirs_stacked)\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        camera_dirs_stacked[Ellipsis, 0],\n        camera_dirs_stacked[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    camera_dirs_stacked = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(camera_dirs_stacked[Ellipsis, :2]), axis=-1))\n    theta ="}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Must add half pixel offset to shoot rays through pixel centers.\n  def pix_to_dir(x, y):\n    return xnp.stack([x + 0.5, y + 0.5, xnp.ones_like(x)], axis=-1)\n\n  # Apply inverse intrinsic matrices.\n  camera_dirs_stacked = mat_vec_mul(pixtocams, pixel_dirs_stacked)\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        camera_dirs_stacked[Ellipsis, 0],\n        camera_dirs_stacked[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    camera_dirs_stacked = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(camera_dirs_stacked[Ellipsis, :2]), axis=-1))\n    theta = xnp.minimum(xnp.pi, theta)\n\n    sin_theta_over_theta = xnp.sin(theta) / theta\n    camera_dirs_stacked = xnp.stack(\n        [\n            camera_dirs_stacked[Ellipsis, 0] * sin_theta_over_theta,\n            camera_dirs_stacked[Ellipsis, 1] * sin_theta_over_theta,\n            xnp.cos(theta),\n        ],\n        axis=-1,\n    )\n\n  elif camtype == ProjectionType.PANORAMIC:\n    theta = camera_dirs_stacked[Ellipsis, 0]\n    phi = camera_dirs_stacked[Ellipsis, 1]\n    # Negation on y and z components accounts for expected Open"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Must add half pixel offset to shoot rays through pixel centers.\n  def pix_to_dir(x, y):\n    return xnp.stack([x + 0.5, y + 0.5, xnp.ones_like(x)], axis=-1)\n\n  # Apply camera rotation matrices.\n  camera_dirs_stacked = mat_vec_mul(\n      camtoworlds[Ellipsis, :3, :3], points\n  )\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        camera_dirs_stacked[Ellipsis, 0],\n        camera_dirs_stacked[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    camera_dirs_stacked = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(camera_dirs_stacked[Ellipsis, :2]), axis=-1))\n    theta = xnp.minimum(xnp.pi, theta)\n\n    sin_theta_over_theta = xnp.sin(theta) / theta\n    camera_dirs_stacked = xnp.stack(\n        [\n            camera_dirs_stacked[Ellipsis, 0] * sin_theta_over_theta,\n            camera_dirs_stacked[Ellipsis, 1] * sin_theta_over_theta,\n            xnp.cos(theta),\n        ],\n        axis=-1,\n    )\n\n  elif camtype == ProjectionType.PANORAMIC:\n    theta = camera_dirs_stacked[Ellipsis, 0]\n    phi = camera_dirs_stacked[Ellipsis, 1]\n    # Negation"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # We need the dx and dy rays to calculate ray radii for mip-NeRF cones.\n  pixel_dirs_stacked = xnp.stack(\n      [\n          xnp.array([1, 0, 0]),\n          xnp.array([0, 1, 0]),\n          xnp.array([0, 0, 1]),\n      ],\n      axis=0,\n  )\n\n  # For jax, need to specify high-precision matmul.\n  matmul = math.matmul if xnp == jnp else xnp.matmul\n  mat_vec_mul = lambda A, b: matmul(A, b[Ellipsis, None])[Ellipsis, 0]\n\n  # Apply inverse intrinsic matrices.\n  camera_dirs_stacked = mat_vec_mul(pixtocams, pixel_dirs_stacked)\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        camera_dirs_stacked[Ellipsis, 0],\n        camera_dirs_stacked[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    camera_dirs_stacked = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(camera_dirs_stacked[Ellipsis, :2]), axis=-1))\n    theta = xnp.minimum(xnp.pi, theta)\n\n    sin_theta_over_theta = xnp.sin(theta) / theta\n    camera_dirs_stacked = xnp.stack(\n        [\n            camera_dirs_stacked[Ellipsis, 0] * sin_theta_over_theta,\n            camera_dirs_stacked[El"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Must add half pixel offset to shoot rays through pixel centers.\n  def pix_to_dir(x, y):\n    return xnp.stack([x + 0.5, y + 0.5, xnp.ones_like(x)], axis=-1)\n\n  # Apply camera rotation matrices.\n  directions_stacked = xnp.stack(\n      [\n          pix_to_dir(points[Ellipsis, 0], points[Ellipsis, 1]),\n          pix_to_dir(points[Ellipsis, 0] + 1, points[Ellipsis, 1]),\n          pix_to_dir(points[Ellipsis, 0], points[Ellipsis, 1] + 1),\n      ],\n      axis=0,\n  )\n\n  # For jax, need to specify high-precision matmul.\n  matmul = math.matmul if xnp == jnp else xnp.matmul\n  mat_vec_mul = lambda A, b: matmul(A, b[Ellipsis, None])[Ellipsis, 0]\n\n  # Apply inverse intrinsic matrices.\n  camera_dirs_stacked = mat_vec_mul(pixtocams, directions_stacked)\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        camera_dirs_stacked[Ellipsis, 0],\n        camera_dirs_stacked[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    camera_dirs_stacked = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(camera_dirs_stacked[Ellipsis, :2]), axis=-1))\n    theta ="}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Must add half pixel offset to shoot rays through pixel centers.\n  def pix_to_dir(x, y):\n    return xnp.stack([x + 0.5, y + 0.5, xnp.ones_like(x)], axis=-1)\n\n  # Apply camera rotation matrices.\n  directions_stacked = xnp.stack(\n      [\n          pix_to_dir(points[Ellipsis, 0], points[Ellipsis, 1]),\n          pix_to_dir(points[Ellipsis, 0] + 1, points[Ellipsis, 1]),\n          pix_to_dir(points[Ellipsis, 0], points[Ellipsis, 1] + 1),\n      ],\n      axis=0,\n  )\n\n  # For jax, need to specify high-precision matmul.\n  matmul = math.matmul if xnp == jnp else xnp.matmul\n  mat_vec_mul = lambda A, b: matmul(A, b[Ellipsis, None])[Ellipsis, 0]\n\n  # Apply inverse intrinsic matrices.\n  camera_dirs_stacked = mat_vec_mul(pixtocams, directions_stacked)\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        camera_dirs_stacked[Ellipsis, 0],\n        camera_dirs_stacked[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    camera_dirs_stacked = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(camera_dirs_stacked[Ellipsis, :2]), axis=-1))\n    theta ="}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Must add half pixel offset to shoot rays through pixel centers.\n  def pix_to_dir(x, y):\n    return xnp.stack([x + 0.5, y + 0.5, xnp.ones_like(x)], axis=-1)\n\n  # We need the dx and dy rays to calculate ray radii for mip-NeRF cones.\n  pixel_dirs_stacked = xnp.stack(\n      [\n          pix_to_dir(x, y)\n          for x in xnp.arange(points.shape[1])\n          for y in xnp.arange(points.shape[2])\n      ],\n      axis=0,\n  )\n\n  # For jax, need to specify high-precision matmul.\n  matmul = math.matmul if xnp == jnp else xnp.matmul\n  mat_vec_mul = lambda A, b: matmul(A, b[Ellipsis, None])[Ellipsis, 0]\n\n  # Apply inverse intrinsic matrices.\n  camera_dirs_stacked = mat_vec_mul(pixtocams, pixel_dirs_stacked)\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        camera_dirs_stacked[Ellipsis, 0],\n        camera_dirs_stacked[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    camera_dirs_stacked = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(camera_dirs_stacked[Ellipsis, :2]), axis=-1))\n    theta = xnp.minimum(xnp.pi, theta)\n\n    sin_theta_over_"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Apply camera rotation matrices.\n  directions = mat_vec_mul(\n      camtoworlds[Ellipsis, :3, :3], points\n  )\n\n  # Apply camera translation vectors.\n  directions = directions + camtoworlds[Ellipsis, :3, -1]\n\n  # Apply inverse intrinsic matrices.\n  camera_dirs_stacked = mat_vec_mul(pixtocams, directions)\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        camera_dirs_stacked[Ellipsis, 0],\n        camera_dirs_stacked[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    camera_dirs_stacked = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(camera_dirs_stacked[Ellipsis, :2]), axis=-1))\n    theta = xnp.minimum(xnp.pi, theta)\n\n    sin_theta_over_theta = xnp.sin(theta) / theta\n    camera_dirs_stacked = xnp.stack(\n        [\n            camera_dirs_stacked[Ellipsis, 0] * sin_theta_over_theta,\n            camera_dirs_stacked[Ellipsis, 1] * sin_theta_over_theta,\n            xnp.cos(theta),\n        ],\n        axis=-1,\n    )\n\n  elif camtype == ProjectionType.PANORAMIC:\n    theta = camera_dirs_stacked[Ellipsis, 0]\n    phi = camera_dirs_stacked[Ellipsis, 1]\n    # Negation on y and z components accounts"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Apply camera rotation matrices.\n  directions_stacked = xnp.stack(\n      [\n          points[Ellipsis, :3],\n          xnp.ones_like(points[Ellipsis, 0:1]),\n      ],\n      axis=-1,\n  )\n  directions = mat_vec_mul(camtoworlds[Ellipsis, :3, :3], directions_stacked)\n  origins = xnp.broadcast_to(camtoworlds[Ellipsis, :3, -1], directions.shape)\n\n  # Flip from OpenCV to OpenGL coordinate system.\n  directions = xnp.stack(\n      [\n          directions[Ellipsis, 0],\n          -directions[Ellipsis, 1],\n          directions[Ellipsis, 2],\n      ],\n      axis=-1,\n  )\n\n  # Apply inverse intrinsic matrices.\n  camera_dirs_stacked = mat_vec_mul(pixtocams, directions)\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        camera_dirs_stacked[Ellipsis, 0],\n        camera_dirs_stacked[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    camera_dirs_stacked = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(camera_dirs_stacked[Ellipsis, :2]), axis=-1))\n    theta = xnp.minimum(xnp.pi, theta)\n\n    sin_theta_over_theta = xnp.sin(theta) / theta\n    camera_dirs_stacked = xnp.stack(\n        [\n            camera_dirs_stack"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Apply camera rotation matrices.\n  points_rotated = xnp.matmul(\n      points, xnp.swapaxes(camtoworlds[Ellipsis, :3, :3], -1, -2)\n  )\n\n  # Apply camera translation vectors.\n  points_rotated = points_rotated + camtoworlds[Ellipsis, :3, -1, None]\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(points_rotated[Ellipsis, :2]), axis=-1))\n    theta = xnp.minimum(xnp.pi, theta)\n\n    sin_theta_over_theta = xnp.sin(theta) / theta\n    points_rotated = xnp.stack(\n        [\n            points_rotated[Ellipsis, 0] * sin_theta_over_theta,\n            points_rotated[Ellipsis, 1] * sin_theta_over_theta,\n            xnp.cos(theta),\n        ],\n        axis=-1,\n    )\n\n  elif camtype == ProjectionType.PANORAMIC:\n    theta = points_rotated[Ellipsis, 0]\n    phi = points_rotated[Ellipsis, 1]\n    # Negation on y and z components accounts for expected OpenCV convention.\n    points_rotated = xnp.stack(\n        [\n            -xnp.sin(phi) * xnp.sin(theta),\n            -xnp.cos(phi),\n            -xnp.sin(phi) * xnp.cos(theta),\n        ],\n        axis=-1,\n    )\n\n  # Flip from OpenCV to OpenGL coordinate system.\n  points_rotated = xnp.matmul(\n      points_rotated, xnp.diag(xnp.array([1.0, -1.0, -1.0]))\n  )\n\n  # Apply inverse intrinsic matrices.\n  points_project"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Apply camera rotation matrices.\n  directions_stacked = xnp.stack(\n      [\n          points[Ellipsis, :3],\n          xnp.ones_like(points[Ellipsis, 0:1]),\n      ],\n      axis=-1,\n  )\n  directions_stacked = mat_vec_mul(\n      camtoworlds[Ellipsis, :3, :3], directions_stacked\n  )\n  directions = directions_stacked[Ellipsis, :3]\n\n  # Apply camera translation vectors.\n  origins = xnp.broadcast_to(camtoworlds[Ellipsis, :3, -1], directions.shape)\n\n  # Convert ray origins and directions into projective NDC space.\n  ndc_fn = functools.partial(convert_to_ndc, pixtocam=pixtocam_ndc, xnp=xnp)\n  origins, directions = ndc_fn(origins, directions)\n\n  # Convert ray origins and directions into pixel coordinates.\n  imageplane = xnp.stack(\n      [directions[Ellipsis, 0], directions[Ellipsis, 1]], axis=-1\n  )\n  depth = directions[Ellipsis, 2]\n\n  return imageplane, depth\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta_squared = jnp.sum(screw_axis**2, axis=-1)\n  theta = _safe_sqrt(theta_squared)\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  X_taylor = jnp.eye(4)\n  W = skew(screw_axis[:3])\n\n  # Prevent bad gradients from propagating back when theta is small.\n  screw_axis_safe = jnp.where(theta_squared > eps**2, screw_axis, 0.0)\n  theta_safe = jnp.where(theta_squared > eps**2, theta, 1.0)\n  axis = screw_axis_safe[:3] / theta_safe\n  X = (\n      jnp.eye(4)\n      + jnp.sin(theta_safe) * W\n      + (1.0 - jnp.cos(theta_safe)) * spin_math.matmul(W, W)\n  )\n  X = jnp.where(theta_squared > eps**2, X, X_taylor)\n  X[:3, 3] = screw_axis_safe[3:]\n  return X\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = jnp.linalg.norm(screw_axis)\n  axis = screw_axis / theta\n  R = exp_so3(axis, eps)\n  p = theta * axis\n  return rp_to_se3(R, p)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = jnp.linalg.norm(screw_axis)\n  screw_axis_normalized = screw_axis / (theta + eps)\n  w = screw_axis_normalized[:3]\n  v = screw_axis_normalized[3:]\n  R = exp_so3(w, eps)\n  p = theta * v\n  X = rp_to_se3(R, p)\n  return X\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta_squared = jnp.sum(screw_axis**2, axis=-1)\n  theta = _safe_sqrt(theta_squared)\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  X_taylor = jnp.eye(4)\n  X_taylor = X_taylor.at[0:3, 3].set(screw_axis[0:3])\n\n  # Prevent bad gradients from propagating back when theta is small.\n  screw_axis_safe = jnp.where(theta_squared > eps**2, screw_axis, 0.0)\n  theta_safe = jnp.where(theta_squared > eps**2, theta, 1.0)\n  axis = screw_axis_safe / theta_safe\n  W = skew(axis)\n  V = jnp.eye(3) + (1.0 - jnp.cos(theta_safe)) * spin_math.matmul(W, W) + (\n      theta_safe - jnp.sin(theta_safe)) * spin_math.matmul(W, W, W)\n  V = jnp.block([[V, jnp.zeros((3, 3))], [jnp.zeros((3, 3)), V]])\n  X = jnp.eye(4)\n  X = X.at[0:3, 0:3].set(V)\n  X = X.at[0:3, 3].set(screw_axis[0:3] * theta_safe)\n\n  return jnp.where(theta_squared > eps**2, X, X_taylor)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  w = screw_axis[0:3]\n  v = screw_axis[3:6]\n  theta = jnp.linalg.norm(w)\n  # Near zero, we switch to using the first order Taylor expansion.\n  X_taylor = jnp.eye(4)\n  X_taylor[0:3, 3] = v\n  # Prevent bad gradients from propagating back when theta is small.\n  w_safe = jnp.where(theta > eps, w, 0.0)\n  theta_safe = jnp.where(theta > eps, theta, 1.0)\n  axis = w_safe / theta_safe\n  W = skew(axis)\n  X = (\n      jnp.eye(4)\n      + jnp.sin(theta_safe) * W\n      + (1.0 - jnp.cos(theta_safe)) * spin_math.matmul(W, W)\n  )\n  X[0:3, 3] = X[0:3, 3] + theta_safe * v\n  return jnp.where(theta > eps, X, X_taylor)\n\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = jnp.linalg.norm(screw_axis, axis=-1)\n  w = screw_axis / (theta + eps)\n  S = jnp.concatenate([skew(w[:3]), w[3:]], axis=-1)\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  X_taylor = jnp.eye(4) + S\n\n  # Prevent bad gradients from propagating back when theta is small.\n  screw_axis_safe = jnp.where(theta > eps, screw_axis, 0.0)\n  theta_safe = jnp.where(theta > eps, theta, 1.0)\n  w_safe = screw_axis_safe / theta_safe\n  W = skew(w_safe[:3])\n\n  X = jnp.eye(4) + jnp.sin(theta_safe) * W + (1.0 - jnp.cos(theta_safe)) * spin_math.matmul(W, W)\n\n  return jnp.where(theta_safe > eps, X, X_taylor)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = jnp.linalg.norm(screw_axis)\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  X_taylor = jnp.eye(4)\n  X_taylor[:3, :3] = jnp.eye(3) + spin_math.hat(screw_axis) / theta\n  X_taylor[:3, 3] = screw_axis / theta\n\n  # Prevent bad gradients from propagating back when theta is small.\n  screw_axis_safe = jnp.where(theta > eps, screw_axis, 0.0)\n  theta_safe = jnp.where(theta > eps, theta, 1.0)\n  w = screw_axis_safe[:3] / theta_safe\n  v = screw_axis_safe[3:] / theta_safe\n\n  W = skew(w)\n  X = jnp.eye(4)\n  X = X + jnp.sin(theta_safe) * W\n  X = X + (1.0 - jnp.cos(theta_safe)) * spin_math.matmul(W, W)\n  X = X + (1.0 - jnp.cos(theta_safe)) * spin_math.matmul(W, spin_math.hat(v))\n  X = X + (theta_safe - jnp.sin(theta_safe)) * spin_math.matmul(spin_math.hat(w),\n                                                                spin_math.hat(v))\n  X = X + (1.0 / theta_safe - 0.5 + (1.0 - jnp.cos(theta_safe)) / theta_safe**2) * spin_math.matmul(\n      spin_math.hat(w), spin_math.hat(w))\n\n  return jnp.where(theta > eps, X, X_taylor)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  w = screw_axis[0:3]\n  v = screw_axis[3:6]\n  theta = jnp.linalg.norm(w)\n  if theta < eps:\n    return rp_to_se3(jnp.eye(3), v)\n  else:\n    return rp_to_se3(exp_so3(w, eps), v)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = jnp.linalg.norm(screw_axis)\n  if theta < eps:\n    return jnp.eye(4)\n\n  w = screw_axis[:3]\n  v = screw_axis[3:]\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  R_taylor = jnp.eye(3) + (1.0 - jnp.cos(theta)) / (theta**2) * skew(w) + (\n      (1.0 - jnp.cos(theta)) / (theta**3) - 0.5 * (1.0 - jnp.cos(theta)) /\n      (theta**2)) * jnp.outer(w, w)\n  p_taylor = theta / (theta**2) * v + (\n      (1.0 - jnp.cos(theta)) / theta - 0.5 * (1.0 - jnp.cos(theta)) /\n      (theta**2)) * jnp.cross(w, v)\n\n  # Prevent bad gradients from propagating back when theta is small.\n  w_safe = jnp.where(theta > eps, w, 0.0)\n  v_safe = jnp.where(theta > eps, v, 0.0)\n  theta_safe = jnp.where(theta > eps, theta, 1.0)\n  W = skew(w_safe)\n\n  R = (\n      jnp.eye(3)\n      + jnp.sin(theta_safe) / theta_safe * W\n      + (1.0 - jnp.cos(theta_safe)) / (theta_safe**2) * spin_math.matmul(W, W)\n  )\n  p = theta_safe / (theta_safe**2) * v_safe + (\n      (1.0 - jnp.cos(theta_safe)) / theta_safe - 0.5 *\n      (1.0 - jnp.cos(theta_safe)) / (theta_safe**2))"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta_squared = jnp.sum(screw_axis**2, axis=-1)\n  theta = _safe_sqrt(theta_squared)\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  X_taylor = jnp.eye(4)\n  X_taylor = X_taylor.at[0:3, 3].add(screw_axis[0:3])\n  X_taylor = X_taylor.at[0:3, 0:3].add(exp_so3(screw_axis[3:6], eps))\n\n  # Prevent bad gradients from propagating back when theta is small.\n  screw_axis_safe = jnp.where(theta_squared > eps**2, screw_axis, 0.0)\n  theta_safe = jnp.where(theta_squared > eps**2, theta, 1.0)\n  axis = screw_axis_safe[3:6] / theta_safe\n  W = skew(axis)\n  R = (\n      jnp.eye(3)\n      + jnp.sin(theta_safe) * W\n      + (1.0 - jnp.cos(theta_safe)) * spin_math.matmul(W, W)\n  )\n  p = screw_axis_safe[0:3] * (1.0 - jnp.cos(theta_safe)) / theta_safe\n\n  X = jnp.eye(4)\n  X = X.at[0:3, 0:3].add(R)\n  X = X.at[0:3, 3].add(p)\n  X = X.at[0:3, 0:3].add(\n      jnp.eye(3) * jnp.cos(theta_safe)\n      + (1.0 - jnp.cos(theta_safe)) * spin_math.matmul(R, R) / theta_safe\n      + jnp.sin(theta_safe) * W\n  )"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = jnp.linalg.norm(screw_axis)\n  if theta < eps:\n    return jnp.eye(4)\n\n  w = screw_axis / theta\n  V = jnp.array([[0, -w[2], w[1]], [w[2], 0, -w[0]], [-w[1], w[0], 0]])\n  W = jnp.array([[0, -w[5], w[4]], [w[5], 0, -w[3]], [-w[4], w[3], 0]])\n\n  R = jnp.eye(3) + jnp.sin(theta) * W + (1.0 - jnp.cos(theta)) * spin_math.matmul(W, W)\n  p = theta * (jnp.eye(3) - jnp.cos(theta) * jnp.eye(3) + (1.0 - jnp.cos(theta)) * spin_math.matmul(W, W)) @ w\n\n  return jnp.block([[R, p], [jnp.array([[0.0, 0.0, 0.0, 1.0]])]])\n\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = jnp.linalg.norm(screw_axis)\n  w = screw_axis / (theta + eps)\n  V = jnp.reshape(w[3:], (3, 1))\n  W = skew(w[:3])\n  # Near zero, we switch to using the first order Taylor expansion.\n  X_taylor = jnp.eye(4)\n  X_taylor = X_taylor.at[:3, :3].add(jnp.eye(3) + W * theta + (1.0 - jnp.cos(theta)) * spin_math.matmul(W, W))\n  X_taylor = X_taylor.at[:3, 3].add(theta * V)\n\n  # Prevent bad gradients from propagating back when theta is small.\n  w_safe = jnp.where(theta > eps, w, 0.0)\n  theta_safe = jnp.where(theta > eps, theta, 1.0)\n  V_safe = jnp.where(theta > eps, V, 0.0)\n  W_safe = skew(w_safe[:3])\n  X = jnp.eye(4)\n  X = X.at[:3, :3].add(jnp.eye(3) + jnp.sin(theta_safe) * W_safe + (1.0 - jnp.cos(theta_safe)) * spin_math.matmul(W_safe, W_safe))\n  X = X.at[:3, 3].add(theta_safe * V_safe)\n  return jnp.where(theta > eps, X, X_taylor)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # Extract the rotation and translation from the screw axis\n  theta = jnp.linalg.norm(screw_axis)\n  w = screw_axis / theta\n  R = exp_so3(w, eps)\n  p = screw_axis[3:]\n\n  # Calculate the homogeneous transformation matrix\n  X = rp_to_se3(R, p)\n\n  return X\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # Extracting the screw axis\n  w = screw_axis[0:3]\n  v = screw_axis[3:6]\n\n  # Extracting the magnitude of the screw axis\n  theta = jnp.linalg.norm(w)\n\n  # Preventing division by zero\n  theta = jnp.where(theta > eps, theta, 1)\n\n  # Preventing numerical instability\n  w = jnp.where(theta > eps, w / theta, jnp.zeros(3))\n  v = jnp.where(theta > eps, v / theta, jnp.zeros(3))\n\n  # Calculating the rotation matrix\n  R = exp_so3(w)\n\n  # Calculating the translation vector\n  p = theta * v\n\n  # Calculating the homogeneous transformation matrix\n  X = rp_to_se3(R, p)\n\n  return X\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = jnp.linalg.norm(screw_axis, axis=-1)\n  w = screw_axis / (theta + eps)\n  V = jnp.stack([w[2], -w[1], w[0]], axis=-1)\n  W = jnp.stack([V[2], -V[0], V[1]], axis=-1)\n  R = jnp.cos(theta) * jnp.eye(3) + (1 - jnp.cos(theta)) * W + jnp.sin(theta) * W @ W\n  p = (jnp.eye(3) - jnp.sin(theta) * W + (1 - jnp.cos(theta)) * W @ W) @ w[Ellipsis, None]\n  p = jnp.squeeze(p, axis=-1)\n  return rp_to_se3(R, p)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = jnp.linalg.norm(screw_axis, ord=2)\n  w = screw_axis[:3]\n  v = screw_axis[3:]\n  W = skew(w)\n  W_norm = jnp.linalg.norm(W, ord=2)\n  # Near zero, we switch to using the first order Taylor expansion.\n  X_taylor = jnp.eye(4)\n  if theta < eps:\n    return X_taylor\n  else:\n    W_norm = jnp.where(theta > eps, W_norm, 1.0)\n    W_norm_safe = jnp.where(theta > eps, W_norm, 1.0)\n    W_normalized = W / W_norm_safe\n    V = jnp.eye(3) + jnp.sin(theta) * W_normalized + (1.0 - jnp.cos(theta)) * spin_math.matmul(W_normalized, W_normalized)\n    X = jnp.eye(4)\n    X = X.at[0:3, 0:3].set(V)\n    X = X.at[0:3, 3].set(theta * v / W_norm_safe)\n    return X\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = jnp.linalg.norm(screw_axis, ord=2)\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  X_taylor = jnp.eye(4)\n\n  # Prevent bad gradients from propagating back when theta is small.\n  screw_axis_safe = jnp.where(theta > eps, screw_axis, 0.0)\n  theta_safe = jnp.where(theta > eps, theta, 1.0)\n  w = screw_axis_safe[:3]\n  v = screw_axis_safe[3:]\n\n  # The unit vector along the screw axis.\n  w_unit = w / theta_safe\n\n  # The rotation matrix about the axis.\n  R = exp_so3(w_unit, eps)\n\n  # The cross-product matrix about the axis.\n  W = skew(w_unit)\n\n  # The translation in the direction of the screw axis.\n  p = theta_safe * jnp.matmul(W, v)\n\n  # The exponential map.\n  X = rp_to_se3(R, p)\n\n  return jnp.where(theta > eps, X, X_taylor)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # Extracting the magnitude of theta from the screw axis\n  theta = jnp.linalg.norm(screw_axis, axis=-1)\n\n  # Preventing division by zero\n  theta_safe = jnp.where(theta > eps, theta, 1.0)\n\n  # Extracting the direction of theta from the screw axis\n  w = jnp.divide(screw_axis, theta_safe)\n\n  # Preventing division by zero\n  w_safe = jnp.where(theta > eps, w, 0.0)\n\n  # Preventing division by zero\n  theta_safe = jnp.where(theta > eps, theta, 1.0)\n\n  # Calculating the rotation matrix from the axis-angle\n  R = exp_so3(w_safe, eps)\n\n  # Preventing division by zero\n  theta_safe = jnp.where(theta > eps, theta, 1.0)\n\n  # Calculating the translation vector\n  p = jnp.divide(screw_axis[:, 3:], theta_safe)\n\n  # Preventing division by zero\n  p_safe = jnp.where(theta > eps, p, 0.0)\n\n  # Calculating the homogeneous transformation matrix\n  X = rp_to_se3(R, p_safe)\n\n  return X\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # The first three elements of the screw axis are the rotation axis.\n  axis = screw_axis[0:3]\n  # The last three elements of the screw axis are the translation.\n  p = screw_axis[3:6]\n  # The magnitude of the rotation axis is the magnitude of rotation.\n  theta = jnp.linalg.norm(axis)\n  # The rotation axis is normalized.\n  axis = axis / theta\n  # The rotation angle is the magnitude of the rotation axis.\n  axis_angle = theta * axis\n  # The rotation matrix is calculated from the rotation axis.\n  R = exp_so3(axis_angle, eps)\n  # The rotation matrix is combined with the translation to form the homogeneous transformation matrix.\n  return rp_to_se3(R, p)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # Extract the translation and rotation from the screw axis.\n  v = screw_axis[:3]\n  theta = jnp.linalg.norm(screw_axis[:3])\n  w = screw_axis[3:]\n  w_hat = w / theta\n\n  # Compute the exponential map.\n  # We use the first-order Taylor expansion to compute the exponential map.\n  # This is a more stable way to compute the exponential map than computing the matrix exponential.\n  # The first-order Taylor expansion is used in the quaternion library.\n  # The translation term is computed as the first-order Taylor approximation of the translation.\n  p = v / theta\n\n  # The rotation term is computed as the first-order Taylor approximation of the rotation.\n  # The rotation term is the exponential map of the rotation axis.\n  R = exp_so3(w_hat, eps)\n\n  # The exponential map is the homogeneous transformation matrix that represents the motion of a body for one second about the screw axis S with magnitude theta.\n  X = rp_to_se3(R, p)\n\n  return X\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  # Convert the input axis-angle to a unit vector\n  axis_angle = axis_angle / jnp.linalg.norm(axis_angle)\n\n  # Compute the rotation matrix using Rodrigues' formula\n  R = jnp.eye(3) + jnp.sin(axis_angle[2]) * skew(axis_angle) + (1 - jnp.cos(axis_angle[2])) * jnp.matmul(skew(axis_angle), skew(axis_angle))\n\n  return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  # Convert the axis-angle representation to a rotation matrix\n  theta = jnp.linalg.norm(axis_angle)\n  if theta < eps:\n    return jnp.eye(3)\n  else:\n    axis = axis_angle / theta\n    K = jnp.array([[0.0, -axis[2], axis[1]],\n                   [axis[2], 0.0, -axis[0]],\n                   [-axis[1], axis[0], 0.0]])\n    R = jnp.eye(3) + jnp.sin(theta) * K + (1 - jnp.cos(theta)) * jnp.matmul(K, K)\n    return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  # Get the angle of rotation from the axis-angle representation\n  theta = jnp.linalg.norm(axis_angle)\n\n  # If the rotation is small, use the first-order Taylor expansion to compute the rotation matrix\n  small_angle_rotation = jnp.where(theta < eps,\n                                   jnp.eye(3) + 0.5 * skew(axis_angle) * theta,\n                                   jnp.eye(3) + (1.0 - jnp.cos(theta)) / theta * skew(axis_angle) + (theta - jnp.sin(theta)) / theta**2 * skew(axis_angle) @ skew(axis_angle))\n\n  # If the rotation is not small, use Rodrigues' formula to compute the rotation matrix\n  large_angle_rotation = jnp.eye(3) + jnp.sin(theta) / theta * skew(axis_angle) + (1.0 - jnp.cos(theta)) / theta**2 * skew(axis_angle) @ skew(axis_angle)\n\n  # Return the rotation matrix, computed using either the first-order or second-order Taylor expansion, depending on the magnitude of the rotation\n  return jnp.where(theta < eps, small_angle_rotation, large_angle_rotation)\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  axis_angle = jnp.reshape(axis_angle, (3,))\n  theta = jnp.linalg.norm(axis_angle)\n  if theta < eps:\n    return jnp.eye(3)\n  axis = axis_angle / theta\n  k = skew(axis)\n  R = (\n      jnp.eye(3)\n      + jnp.sin(theta) * k\n      + (1 - jnp.cos(theta)) * jnp.matmul(k, k)\n  )\n  return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  if theta < eps:\n    return jnp.eye(3)\n  axis = axis_angle / theta\n  skew_axis = skew(axis)\n  R = jnp.eye(3) + jnp.sin(theta) * skew_axis + (1 - jnp.cos(theta)) * jnp.matmul(skew_axis, skew_axis)\n  return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  axis = axis_angle / (theta + eps)\n  k = jnp.array([[0, -axis[2], axis[1]], [axis[2], 0, -axis[0]],\n                 [-axis[1], axis[0], 0]])\n  R = jnp.eye(3) + jnp.sin(theta) * k + (1 - jnp.cos(theta)) * jnp.matmul(k, k)\n  return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  # Convert the input axis-angle to a unit vector.\n  axis_norm = jnp.linalg.norm(axis_angle)\n  axis_norm = jnp.where(axis_norm > eps, axis_norm, jnp.zeros_like(axis_norm))\n  axis = axis_angle / axis_norm\n\n  # Compute the rotation matrix using Rodrigues' formula.\n  K = jnp.array([[    0, -axis[2],  axis[1]],\n                 [ axis[2],     0, -axis[0]],\n                 [-axis[1], axis[0],     0]])\n  R = jnp.eye(3) + jnp.sin(axis_norm) * K + (1 - jnp.cos(axis_norm)) * jnp.matmul(K, K)\n  return R\n\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  # The axis-angle must be a 3-vector.\n  axis_angle = jnp.reshape(axis_angle, (3,))\n\n  # The angle of rotation.\n  theta = jnp.linalg.norm(axis_angle)\n\n  # The normalized axis of rotation.\n  axis = axis_angle / (theta + eps)\n\n  # Compute the rotation matrix using Rodrigues' formula.\n  R = (jnp.eye(3) * jnp.cos(theta) +\n       (1 - jnp.cos(theta)) * jnp.outer(axis, axis) +\n       jnp.sin(theta) * skew(axis))\n\n  return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  # The axis-angle must be a 3-vector.\n  assert axis_angle.shape == (3,)\n\n  # The angle of rotation must be non-zero.\n  axis_angle_norm = jnp.linalg.norm(axis_angle)\n  assert axis_angle_norm > eps\n\n  # Normalize the axis-angle vector.\n  axis = axis_angle / axis_angle_norm\n\n  # Compute the rotation matrix.\n  R = jnp.eye(3) + jnp.sin(axis_angle_norm) * skew(axis) + (1 - jnp.cos(axis_angle_norm)) * jnp.matmul(skew(axis), skew(axis))\n\n  return R\n\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  # Get the angle of rotation from the axis-angle representation.\n  angle = jnp.linalg.norm(axis_angle)\n  # Get the normalized axis of rotation from the axis-angle representation.\n  axis = axis_angle / (angle + eps)\n  # Compute the rotation matrix using Rodrigues' formula.\n  R = jnp.cos(angle) * jnp.eye(3) + (1 - jnp.cos(angle)) * jnp.outer(axis, axis) + jnp.sin(angle) * skew(axis)\n  return R\n\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  axis_angle = jnp.reshape(axis_angle, (3))\n\n  # Numerical stability\n  theta = jnp.linalg.norm(axis_angle)\n  theta = jnp.where(theta < eps, theta, _safe_sqrt(theta))\n\n  # Rodrigues' formula\n  K = jnp.array([[      0, -axis_angle[2],  axis_angle[1]],\n                 [axis_angle[2],       0, -axis_angle[0]],\n                 [-axis_angle[1], axis_axis[0],       0]])\n  R = jnp.eye(3) + jnp.sin(theta) * K + (1 - jnp.cos(theta)) * jnp.matmul(K, K)\n\n  return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  # Get the angle of rotation\n  angle = jnp.linalg.norm(axis_angle)\n\n  # If the angle is close to zero, use the first-order Taylor expansion\n  first_order_approx = jnp.reshape(jnp.array([[0, -axis_angle[2], axis_angle[1]],\n                                              [axis_angle[2], 0, -axis_angle[0]],\n                                              [-axis_angle[1], axis_angle[0], 0]]), (3, 3))\n\n  # Otherwise, use Rodrigues' formula\n  theta = jnp.where(angle < eps, angle, angle)\n  theta_sq = theta * theta\n  sin_theta = jnp.where(angle < eps, angle, jnp.sin(theta))\n  cos_theta = jnp.where(angle < eps, 1.0, jnp.cos(theta))\n  return (first_order_approx * (1.0 - cos_theta) + jnp.reshape(jnp.array([[cos_theta, 0, -sin_theta],\n                                                                           [0, cos_theta, sin_theta],\n                                                                           [sin_theta, -cos_theta, 0]]), (3, 3)) * theta_sq)\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n\n  # Avoid division by zero\n  if theta < eps:\n    return jnp.eye(3)\n\n  axis = axis_angle / theta\n\n  # Compute the rotation matrix using Rodrigues' formula\n  K = jnp.array([[      0, -axis[2],  axis[1]],\n                 [ axis[2],       0, -axis[0]],\n                 [-axis[1],  axis[0],       0]])\n  R = jnp.eye(3) + jnp.sin(theta) * K + (1 - jnp.cos(theta)) * jnp.matmul(K, K)\n\n  return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  # Check if the input is a 3-element numpy array. If not, raise a value error.\n  if axis_angle.shape != (3,):\n    raise ValueError('The input axis-angle representation must be a 3-element numpy array.')\n\n  # Compute the rotation matrix using Rodrigues' formula.\n  angle = jnp.linalg.norm(axis_angle)\n  axis = axis_angle / (angle + eps)\n  K = jnp.array([[0, -axis[2], axis[1]],\n                 [axis[2], 0, -axis[0]],\n                 [-axis[1], axis[0], 0]])\n  R = jnp.eye(3) + jnp.sin(angle) * K + (1 - jnp.cos(angle)) * jnp.matmul(K, K)\n\n  # Return the rotation matrix.\n  return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  axis_angle = jnp.reshape(axis_angle, (3))\n  angle = jnp.linalg.norm(axis_angle)\n\n  # The angle is small, perform exact computation with sine and cosine\n  small_angle_condition = angle < eps\n  small_angle_output = jnp.array([[1.0, 0.0, 0.0],\n                                  [0.0, 1.0, 0.0],\n                                  [0.0, 0.0, 1.0]])\n\n  # The angle is large, perform approximate computation\n  large_angle_output = (jnp.eye(3)\n                        + jnp.sin(angle) / angle * skew(axis_angle)\n                        + (1 - jnp.cos(angle)) / angle**2 * jnp.matmul(skew(axis_angle), skew(axis_angle)))\n\n  output = jnp.where(small_angle_condition, small_angle_output, large_angle_output)\n  return output\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  # Check if the input is a numpy array\n  axis_angle = jnp.array(axis_angle)\n\n  # Check if the input is a valid 3D vector\n  assert axis_angle.size == 3, \"Input axis-angle must be a 3-vector\"\n\n  # Extract the angle of rotation\n  theta = jnp.linalg.norm(axis_angle)\n\n  # Check if the rotation is small\n  if theta < eps:\n\n    # Use first-order Taylor approximation to compute the rotation\n    R = jnp.eye(3) + jnp.dot(skew(axis_angle), skew(axis_angle))\n\n  else:\n\n    # Normalize the axis of rotation\n    axis = axis_angle / theta\n\n    # Use Rodrigues' rotation formula to compute the rotation\n    R = jnp.cos(theta) * jnp.eye(3) + (1 - jnp.cos(theta)) * jnp.dot(skew(axis),\n                                                                     axis) + jnp.sin(\n        theta) * skew(axis)\n\n  # Return the rotation matrix\n  return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n\n  # Avoid dividing by zero or small values that could lead to numerical instability.\n  theta = jnp.where(theta < eps, eps, theta)\n\n  # Compute rotation matrix using Rodrigues' formula.\n  R = jnp.cos(theta) * jnp.eye(3) + (1 - jnp.cos(theta)) * jnp.outer(\n      axis_angle, axis_angle) / theta + jnp.sin(theta) * skew(axis_angle)\n\n  return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  # Check if the input is a numpy array. If not, convert it to one.\n  axis_angle = jnp.array(axis_angle)\n  # Check if the input is a vector. If not, raise an error.\n  if axis_angle.ndim != 1 or axis_angle.shape[0] != 3:\n    raise ValueError(\"Input axis_angle must be a 3-vector.\")\n\n  # Normalize the input axis-angle representation.\n  axis_angle = axis_angle / jnp.linalg.norm(axis_angle)\n  # Get the angle of rotation from the input axis-angle representation.\n  angle = jnp.linalg.norm(axis_angle)\n\n  # If the rotation is small, use the first-order Taylor expansion of the exponential map.\n  first_order_taylor_series_approx = jnp.array([[0.0, -axis_angle[2], axis_angle[1]],\n                                                [axis_angle[2], 0.0, -axis_angle[0]],\n                                                [-axis_angle[1], axis_angle[0], 0.0]])\n  if angle < eps:\n    return first_order_taylor_series_approx\n\n  # Otherwise, use the second-order Taylor expansion of the exponential map.\n  angle_sin_over_angle = angle * jnp.sin(angle) / angle\n  angle_cos_minus_one = (1.0 - jnp.cos(angle)) / angle\n  second_order_taylor_series_approx = jnp.array([[1.0 + angle_sin_over_angle, axis_angle[2] * angle_cos_minus_one, axis_angle[1] * angle_cos_minus_one],\n                                                 [axis_angle[2] * angle_cos_minus_one, 1.0 + angle_sin_over_angle, axis_angle[0] * angle_cos_minus_one],\n                                                 [axis_angle[1] * angle_cos_minus_one, axis_angle[0] * angle_cos_minus_one, 1."}
{"namespace": "rigid_body.exp_so3", "completion": "  # get the angle of rotation from the axis-angle representation\n  angle = jnp.linalg.norm(axis_angle)\n\n  # if the rotation is small, use the first-order Taylor expansion\n  # around theta=0 to compute the rotation matrix\n  # otherwise, use Rodrigues' formula\n  return jnp.where(angle < eps, _safe_sqrt(1.0 - angle**2) * jnp.identity(3),\n                   jnp.reshape(\n                       jnp.sin(angle) * jnp.eye(3, 3) +\n                       (1.0 - jnp.cos(angle)) * jnp.outer(axis_angle, axis_angle) +\n                       jnp.cos(angle) * jnp.diag(axis_angle**2), (3, 3)))\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  # Check that the input axis-angle has the correct dimensions.\n  axis_angle = jnp.reshape(axis_angle, (3))\n\n  # Extract the angle from the axis-angle representation.\n  angle = jnp.linalg.norm(axis_angle)\n\n  # Check if the input angle is small.\n  angle_is_small = angle < eps\n\n  # If the angle is small, use an alternative computation that is stable for small angles.\n  # The angle is small if the norm of the rotation axis is close to zero.\n  # Use the identity: cos(theta) = (1 - (theta**2 / 6) + ...) if theta < sqrt(6*eps)\n  # See https://github.com/numpy/numpy/issues/13293\n  # and https://github.com/tensorflow/probability/commit/efd7418c1b2865cd7f6709c458b189df0146b767\n  # for more details.\n  angle_is_small = angle_is_small | (angle < jnp.sqrt(6 * eps))\n\n  # If the angle is small, just use the first-order Taylor expansion.\n  # Otherwise, use the Rodrigues formula.\n  R = jnp.where(\n      angle_is_small,\n      jnp.reshape(jnp.eye(3), (3, 3)),\n      jnp.reshape(\n          jnp.sin(angle) * jnp.eye(3) +\n          (1 - jnp.cos(angle)) * jnp.outer(axis_angle, axis_angle) +\n          (jnp.eye(3) - jnp.sin(angle) * jnp.outer(axis_angle, axis_angle) /\n           angle) * (jnp.sin(angle) / angle) * jnp.outer(axis_angle, axis_angle),\n          (3, 3)),\n  )\n\n  # Return the rotation matrix.\n  return R\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  # calculate the mean and covariance of the Gaussian\n  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  # Calculate the mean and variance of the Gaussian approximation of the conical frustum.\n  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n\n  # Calculate the radius at the mean distance of the Gaussian approximation of the conical frustum.\n  r_mean = base_radius * t_mean\n\n  # Calculate the radius at the end of the Gaussian approximation of the conical frustum.\n  r_1 = base_radius * t1\n\n  # Calculate the radius at the start of the Gaussian approximation of the conical frustum.\n  r_0 = base_radius * t0\n\n  # Calculate the radius at the mean distance of the Gaussian approximation of the conical frustum.\n  r_mean = base_radius * t_mean\n\n  # Calculate the radius at the end of the Gaussian approximation of the conical frustum.\n  r_1 = base_radius * t1\n\n  # Calculate the radius at the start of the Gaussian approximation of the conical frustum.\n  r_0 = base_radius * t0\n\n  # Calculate the radius at the mean distance of the Gaussian approximation of the conical frustum.\n  r_mean = base_radius * t_mean\n\n  # Calculate the radius at the end of the Gaussian approximation of the conical frustum.\n  r_1 = base_radius * t1\n\n  # Calculate the radius at the start of the Gaussian approximation of the conical frustum.\n  r_0 = base_radius * t0\n\n  # Calculate the radius at the mean distance of the Gaussian approximation of the conical frustum.\n  r_mean = base_radius * t_mean\n\n  # Calculate the radius at the end of the Gaussian approximation of the conical frustum.\n  r_1 = base_radius * t1\n\n  # Calculate the radius at the start of the Gaussian approximation of the conical frustum.\n  r_0 = base_radius * t0\n\n  # Calculate the radius at the mean distance of the Gaussian approximation of the conical frust"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  # Approximate a conical frustum as a Gaussian distribution\n  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  t_mean = t_mean * d\n  t_var = t_var * d**2\n  r_var = r_var * base_radius\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  # The axis of the cone is used to determine the direction of the conical frustum.\n  d = jnp.array(d, dtype=jnp.float32)\n\n  # The starting and ending distances of the frustum from the origin. They mark the beginning and the end of the conical section being approximated.\n  t0 = jnp.array(t0, dtype=jnp.float32)\n  t1 = jnp.array(t1, dtype=jnp.float32)\n\n  # The scale of the radius as a function of distance from the origin. It determines how the radius of the frustum changes with distance.\n  base_radius = jnp.array(base_radius, dtype=jnp.float32)\n\n  # Indicates whether the resulting Gaussian distribution will have a diagonal covariance matrix or a full-covariance matrix. This affects the complexity and the information contained in the covariance.\n  diag = jnp.array(diag, dtype=jnp.bool_)\n\n  # Approximate the 3D conical frustum as a Gaussian distribution by calculating its mean and covariance.\n  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n  return mean, cov\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  t_mean = t_mean * d\n  t_var = t_var * d**2\n  r_var = r_var * base_radius**2\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  # Convert the conical frustum into a Gaussian distribution.\n  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  # Convert the conical frustum into a Gaussian distribution.\n  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  # Ensure that the axis of the cone is a unit vector.\n  d = math.normalize(d)\n\n  # Calculate the mean and covariance of the Gaussian distribution.\n  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  # Calculate the mean and variance of the Gaussian distribution based on the cylinder's axis, start and end distances, radius, and whether the Gaussian should be diagonal or full-covariance.\n  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  # Calculate the mean and variance of the Gaussian based on the cylinder's axis, start and end distances, and radius.\n  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n\n  # Calculate the mean and covariance of the Gaussian based on the mean and variance of the Gaussian and the radius of the cylinder.\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  # The following code is based on the following paper: https://arxiv.org/pdf/2103.13415.pdf\n  # The original code is in the following file: https://github.com/google/nerfies/blob/main/nerfies/utils.py\n\n  t_mean = (t0 + t1) / 2\n  t_var = (t1 - t0)**2 / 12\n  r_var = radius**2\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  # Calculate the mean and variance of the Gaussian from the cylinder's axis, start and end distances, and radius.\n  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  # Calculate the mean and covariance of the Gaussian from the mean and variance of the Gaussian.\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  # Return the Gaussian.\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  # Calculate the mean and variance of the Gaussian.\n  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Define some constants.\n  # The following are the parameters for the camera projection model.\n  # The following are the parameters for the camera projection model.\n  # The following are the parameters for the camera projection model.\n  # The following are the parameters for the camera projection model.\n  # The following are the parameters for the camera projection model.\n  # The following are the parameters for the camera projection model.\n  # The following are the parameters for the camera projection model.\n  # The following are the parameters for the camera projection model.\n  # The following are the parameters for the camera projection model.\n  # The following are the parameters for the camera projection model.\n  # The following are the parameters for the camera projection model.\n  # The following are the parameters for the camera projection model.\n  # The following are the parameters for the camera projection model.\n  # The following are the parameters for the camera projection model.\n  # The following are the parameters for the camera projection model.\n  # The following are the parameters for the camera projection model.\n  # The following are the parameters for the camera projection model.\n  # The following are the parameters for the camera projection model.\n  # The following are the parameters for the camera projection model.\n  # The following are the parameters for the camera projection model.\n  # The following are the parameters for the camera projection model.\n  # The following are the parameters for the camera projection model.\n  # The following are the parameters for the camera projection model.\n  # The following are the parameters for the camera projection model.\n  # The following are the parameters for the camera projection model.\n  # The following are the parameters for the camera projection model.\n  # The following are the parameters for the camera projection model.\n  # The following are the parameters for the camera projection model.\n  # The following are the parameters for the camera projection model.\n  # The following are the parameters for the camera projection model.\n  # The following are the parameters for the camera projection model.\n  # The following are the parameters for the camera projection model.\n  # The following are the parameters for the camera projection model.\n  # The following are the parameters for the camera projection model.\n  # The following are the parameters for the camera projection model.\n "}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Convert pixel coordinates to camera coordinates.\n  if pixtocam_ndc is not None:\n    # Convert to NDC space.\n    pix_x, pix_y = _radial_and_tangential_undistort(\n        x=pix_x_int,\n        y=pix_y_int,\n        xd=pix_x_int,\n        yd=pix_y_int,\n        k1=distortion_params['k1'] if distortion_params is not None else 0.0,\n        k2=distortion_params['k2'] if distortion_params is not None else 0.0,\n        k3=distortion_params['k3'] if distortion_params is not None else 0.0,\n        k4=distortion_params['k4'] if distortion_params is not None else 0.0,\n        p1=distortion_params['p1'] if distortion_params is not None else 0.0,\n        p2=distortion_params['p2'] if distortion_params is not None else 0.0,\n        xnp=xnp,\n    )\n    pix_x, pix_y = xnp.dot(pixtocam_ndc, xnp.array([pix_x, pix_y, 1.0]))\n  else:\n    pix_x, pix_y = xnp.broadcast_arrays(pix_x_int[..., None], pix_y_int[..., None])\n    pix_x, pix_y = xnp.moveaxis(pix_x, -1, 0), xnp.moveaxis(pix_y, -1, 0)\n    pix_x, pix_y = xnp.array(pix_x), xnp.array(pix_y)\n    pix_x, pix_y = _radial_and_tangential_undistort(\n        x=pix_x,\n        y=pix_y,\n        xd=pix_x,"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  if camtype == ProjectionType.PERSPECTIVE:\n    # Compute ray origins and directions.\n    ray_origins = xnp.broadcast_to(camtoworlds[Ellipsis, :3, -1],\n                                   pix_x_int.shape + (3,))\n    ray_dirs = xnp.stack([\n        (pix_x_int - pixtocams[Ellipsis, 0, 2]) / pixtocams[Ellipsis, 0, 0],\n        (pix_y_int - pixtocams[Ellipsis, 1, 2]) / pixtocams[Ellipsis, 1, 1],\n        -xnp.ones_like(pix_x_int)\n    ],\n                         axis=-1)\n    ray_dirs_norm = xnp.linalg.norm(ray_dirs, axis=-1, keepdims=True)\n    ray_dirs /= ray_dirs_norm\n\n    # Compute ray differential radii.\n    ray_radii = xnp.sqrt(\n        xnp.square(pixtocams[Ellipsis, 0, 0]) +\n        xnp.square(pixtocams[Ellipsis, 1, 1])) / pixtocams[Ellipsis, 0, 0]\n\n  elif camtype == ProjectionType.FISHEYE:\n    # Compute ray origins and directions.\n    ray_origins = xnp.broadcast_to(camtoworlds[Ellipsis, :3, -1],\n                                   pix_x_int.shape + (3,))\n    ray_dirs = xnp.stack([\n        (pix_x_int - pixtocams[Ellipsis, 0, 2]) / pixtocams[Ellipsis, 0, 0],\n        (pix_y_int - pixtocams[Ellipsis, 1, 2]) / pixtocams["}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Compute ray origins.\n  if pixtocam_ndc is not None:\n    # Convert to NDC space.\n    pix_x_int, pix_y_int = _radial_and_tangential_undistort(\n        xd=pix_x_int,\n        yd=pix_y_int,\n        k1=distortion_params['k1'] if distortion_params is not None else 0.0,\n        k2=distortion_params['k2'] if distortion_params is not None else 0.0,\n        k3=distortion_params['k3'] if distortion_params is not None else 0.0,\n        k4=distortion_params['k4'] if distortion_params is not None else 0.0,\n        p1=distortion_params['p1'] if distortion_params is not None else 0.0,\n        p2=distortion_params['p2'] if distortion_params is not None else 0.0,\n        xnp=xnp,\n    )\n    pix_x_int, pix_y_int = xnp.einsum(\n        'SH, SH -> SH', pixtocam_ndc[0, 0], pix_x_int\n    ) + xnp.einsum('SH, SH -> SH', pixtocam_ndc[0, 1], pix_y_int)\n  origins = xnp.einsum('SH, SH -> SH', pixtocams[..., 0, 0], pix_x_int\n                      ) + xnp.einsum('SH, SH -> SH', pixtocams[..., 0, 1],\n                                     pix_y_int) + pixtocams[..., 0, 2]\n  origins = xnp.einsum('SH, SH -> SH', camtoworlds[..., 0, 0], origins\n                      ) + xnp.einsum('SH, SH -> SH', camtoworlds[...,"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Convert to numpy if using jax.numpy.\n  if xnp == jnp:\n    pix_x_int = pix_x_int.astype(np.int32)\n    pix_y_int = pix_y_int.astype(np.int32)\n    pixtocams = pixtocams.astype(np.float32)\n    camtoworlds = camtoworlds.astype(np.float32)\n    if distortion_params is not None:\n      distortion_params = {\n          k: v.astype(np.float32) for k, v in distortion_params.items()\n      }\n    if pixtocam_ndc is not None:\n      pixtocam_ndc = pixtocam_ndc.astype(np.float32)\n\n  # Compute ray origins and directions.\n  if camtype == ProjectionType.PERSPECTIVE:\n    # Perspective projection.\n    origins = xnp.broadcast_to(camtoworlds[:, :3, -1], pix_x_int.shape + (3,))\n    directions = xnp.stack([\n        (pix_x_int - pixtocams[0, 0, 2]) / pixtocams[0, 0, 0],\n        (pix_y_int - pixtocams[0, 1, 2]) / pixtocams[0, 1, 1],\n        -xnp.ones_like(pix_y_int),\n    ], -1)\n  elif camtype == ProjectionType.FISHEYE:\n    # Fisheye projection.\n    # Compute ray origins.\n    origins = xnp.broadcast_to(camtoworlds[:, :3, -1], pix_x_int.shape + (3,))\n\n    # Compute ray directions.\n    directions = xnp.stack([\n        (pix_x_int - pixtocams[0, 0, 2])"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Convert pixel coordinates to camera coordinates.\n  pix_x_cam = xnp.einsum('SH,SH->SH', pixtocams[Ellipsis, 0, 0], pix_x_int)\n  pix_y_cam = xnp.einsum('SH,SH->SH', pixtocams[Ellipsis, 1, 1], pix_y_int)\n\n  # Apply distortion correction.\n  if distortion_params is not None:\n    if camtype != ProjectionType.PERSPECTIVE:\n      raise NotImplementedError(\n          'Distortion correction is only implemented for perspective cameras.'\n      )\n    pix_x_cam, pix_y_cam = _radial_and_tangential_undistort(\n        x=pix_x_cam,\n        y=pix_y_cam,\n        k1=distortion_params['k1'],\n        k2=distortion_params['k2'],\n        k3=distortion_params['k3'],\n        k4=distortion_params['k4'],\n        p1=distortion_params['p1'],\n        p2=distortion_params['p2'],\n    )\n\n  # Convert camera coordinates to world coordinates.\n  world_x_cam = xnp.einsum('SH,SH->SH', camtoworlds[Ellipsis, 0, 0], pix_x_cam)\n  world_y_cam = xnp.einsum('SH,SH->SH', camtoworlds[Ellipsis, 1, 1], pix_y_cam)\n  world_z_cam = xnp.einsum('SH,SH->SH', camtoworlds[Ellipsis, 2, 2], pix_y_cam)\n\n  # Compute ray origins.\n  origins = xnp.stack([world_x_cam, world_y_cam, world_z_cam], axis=-1)\n\n  # Compute ray directions.\n  if camtype =="}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Compute ray origins and directions.\n  if camtype == ProjectionType.PERSPECTIVE:\n    # Compute ray origins and directions.\n    origins = xnp.broadcast_to(camtoworlds[Ellipsis, :3, 3], pix_x_int.shape + (3,))\n    directions = xnp.stack(\n        [pix_x_int, pix_y_int, xnp.ones_like(pix_x_int)], axis=-1\n    )\n    directions = xnp.einsum('...ij,...kj->...ik', pixtocams, directions)\n    directions /= directions[Ellipsis, -1, None]\n  elif camtype == ProjectionType.FISHEYE:\n    # Compute ray origins and directions.\n    origins = xnp.broadcast_to(camtoworlds[Ellipsis, :3, 3], pix_x_int.shape + (3,))\n    directions = xnp.stack(\n        [pix_x_int, pix_y_int, xnp.ones_like(pix_x_int)], axis=-1\n    )\n    directions = xnp.einsum('...ij,...kj->...ik', pixtocams, directions)\n    directions /= directions[Ellipsis, -1, None]\n\n    # Apply fisheye distortion correction.\n    if distortion_params is not None:\n      # Unpack distortion parameters.\n      k1 = distortion_params['k1']\n      k2 = distortion_params['k2']\n      k3 = distortion_params['k3']\n      k4 = distortion_params['k4']\n      p1 = distortion_params['p1']\n      p2 = distortion_params['p2']\n\n      # Apply distortion correction.\n      xd, yd = _radial_and_tangential_undistort(\n          x=directions[Ellipsis, "}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Compute ray origins and directions.\n  if camtype == ProjectionType.PANORAMIC:\n    # For panoramic cameras, the ray origin is the camera center.\n    origins = camtoworlds[:, :, :3, -1]\n    # For panoramic cameras, the ray direction is the unit vector from the camera center to the pixel.\n    directions = xnp.stack([\n        (pix_x_int - camtoworlds[:, :, 0, 0]) / camtoworlds[:, :, 0, 0],\n        (pix_y_int - camtoworlds[:, :, 1, 1]) / camtoworlds[:, :, 1, 1],\n        xnp.ones_like(pix_x_int),\n    ],\n                           axis=-1)\n  else:\n    # For perspective cameras, the ray origin is the camera center.\n    origins = camtoworlds[:, :, :3, -1]\n    # For perspective cameras, the ray direction is the unit vector from the camera center to the pixel.\n    directions = xnp.stack([\n        (pix_x_int - camtoworlds[:, :, 0, 0]) / camtoworlds[:, :, 0, 2],\n        (pix_y_int - camtoworlds[:, :, 1, 1]) / camtoworlds[:, :, 1, 2],\n        xnp.ones_like(pix_x_int),\n    ],\n                           axis=-1)\n\n  # Compute ray differential radii.\n  # For perspective cameras, the differential radius is the distance between the camera center and the pixel.\n  if camtype == ProjectionType.PANORAMIC:\n    radii = xnp.sqrt(\n        (pix_x_int - camtoworlds[:, :, 0, 0])**2 +\n        (pix_y_int - camtoworlds[:, :, 1, "}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # The following code is adapted from https://github.com/google/nerfies/blob/main/nerfies/camera.py\n  # This function computes ray origins, directions, and image plane coordinates.\n  #\n  # The camera model is defined as:\n  #   x_cam = (x_img - c_x) * f_x + (y_img - c_y) * f_y + n\n  #   y_cam = z_img\n  #\n  # The camera model is used to transform image plane coordinates to camera\n  # coordinates, which are then used to transform to world coordinates.\n  #\n  # The camera model is defined as:\n  #   x_cam = (x_img - c_x) * f_x + (y_img - c_y) * f_y + n\n  #   y_cam = z_img\n  #\n  # The camera model is used to transform image plane coordinates to camera\n  # coordinates, which are then used to transform to world coordinates.\n  #\n  # The camera model is defined as:\n  #   x_cam = (x_img - c_x) * f_x + (y_img - c_y) * f_y + n\n  #   y_cam = z_img\n  #\n  # The camera model is used to transform image plane coordinates to camera\n  # coordinates, which are then used to transform to world coordinates.\n  #\n  # The camera model is defined as:\n  #   x_cam = (x_img - c_x) * f_x + (y_img - c_y) * f_y + n\n  #   y_cam = z_img\n  #\n  # The camera model is used to transform image plane coordinates to camera\n  # coordinates, which are then used to transform to world coordinates.\n  #\n  # The camera model is defined as:\n  #   x_cam = (x_img - c_x) * f_x + (y_img - c_y) * f_y + n\n  #   y_cam = z_img\n  #\n  # The camera model is used to"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Get the shape of the input rays.\n  sh = pix_x_int.shape\n\n  # Convert pixel coordinates to camera coordinates.\n  if pixtocam_ndc is not None:\n    # If the camera intrinsics are in NDC space, convert to camera space.\n    pix_x_cam, pix_y_cam, pix_z_cam = xnp.dot(\n        pixtocam_ndc,\n        xnp.stack([pix_x_int, pix_y_int, xnp.ones_like(pix_x_int)], -1),\n    )\n  else:\n    # If the camera intrinsics are in camera space, use them directly.\n    pix_x_cam, pix_y_cam, pix_z_cam = xnp.dot(\n        pixtocams,\n        xnp.stack([pix_x_int, pix_y_int, xnp.ones_like(pix_x_int)], -1),\n    )\n\n  # If the camera is a fisheye camera, apply distortion correction.\n  if camtype == ProjectionType.FISHEYE:\n    # Get the distortion parameters.\n    k1 = distortion_params['k1']\n    k2 = distortion_params['k2']\n    k3 = distortion_params.get('k3', 0.0)\n    k4 = distortion_params.get('k4', 0.0)\n    p1 = distortion_params.get('p1', 0.0)\n    p2 = distortion_params.get('p2', 0.0)\n\n    # Apply distortion correction.\n    pix_x_undist, pix_y_undist = _radial_and_tangential_undistort(\n        pix_x_cam,\n        pix_y_cam,\n        k1=k1,\n        k2=k2,\n        k3=k3,\n        k4=k4,\n        p1=p1,\n        p2="}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Calculate ray origins and directions in camera coordinates.\n  if camtype == ProjectionType.PERSPECTIVE:\n    x, y = _radial_and_tangential_undistort(\n        pix_x_int,\n        pix_y_int,\n        k1=distortion_params['k1'] if distortion_params is not None else 0.0,\n        k2=distortion_params['k2'] if distortion_params is not None else 0.0,\n        k3=distortion_params['k3'] if distortion_params is not None else 0.0,\n        k4=distortion_params['k4'] if distortion_params is not None else 0.0,\n        p1=distortion_params['p1'] if distortion_params is not None else 0.0,\n        p2=distortion_params['p2'] if distortion_params is not None else 0.0,\n    )\n    x, y = xnp.broadcast_arrays(x, y)\n    x = xnp.reshape(x, (-1))\n    y = xnp.reshape(y, (-1))\n    xy = xnp.stack([x, y], axis=-1)\n    xy = xnp.tile(xy, (1, 1, 1))\n    xy = xnp.reshape(xy, (-1, 2))\n    xy = xnp.broadcast_to(xy, (xnp.shape(xy)[0], 3))\n    xy = xnp.concatenate([xy, xnp.ones_like(xy[Ellipsis, :1])], axis=-1)\n    ray_dirs = xnp.einsum('ij,ik->ik', pixtocams, xy)\n    ray_dirs = ray_dirs / xnp.linalg.norm(ray_dirs, axis=-1, keepdims=True)\n  elif camtype == ProjectionType.FISHEYE:"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Shape of input tensors\n  sh = pix_x_int.shape\n\n  # Initialize ray origins, directions, and differential radii\n  origins = xnp.broadcast_to(camtoworlds[Ellipsis, None, :3, -1], sh + (3,))\n  directions = xnp.zeros(sh + (3,), dtype=pixtocams.dtype)\n  radii = xnp.zeros(sh + (1,), dtype=pixtocams.dtype)\n\n  # Initialize image plane coordinates\n  imageplane = xnp.stack([pix_x_int, pix_y_int], axis=-1)\n\n  # Compute ray differential radii\n  if camtype == ProjectionType.FISHEYE:\n    radii = xnp.sqrt(pix_x_int**2 + pix_y_int**2)\n  elif camtype == ProjectionType.PANORAMIC:\n    radii = xnp.ones(sh + (1,), dtype=pixtocams.dtype)\n\n  # Compute ray directions\n  if camtype == ProjectionType.PERSPECTIVE:\n    # Compute ray directions in camera coordinates\n    directions[Ellipsis, 0] = (\n        (pix_x_int - camtoworlds[Ellipsis, 0, 2]) / camtoworlds[Ellipsis, 0, 0]\n    )\n    directions[Ellipsis, 1] = (\n        (pix_y_int - camtoworlds[Ellipsis, 1, 2]) / camtoworlds[Ellipsis, 1, 1]\n    )\n    directions[Ellipsis, 2] = -1.0\n\n    # Convert ray directions to world coordinates\n    directions = directions[Ellipsis, None, :] @ camtoworlds[Ellipsis, :3, :3]\n\n  elif camtype == ProjectionType.FISHEYE:\n    # Compute ray directions"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Convert pixel coordinates to camera coordinates.\n  if pixtocam_ndc is None:\n    # If pixtocam_ndc is not provided, assume a standard pinhole camera.\n    pixtocam_ndc = get_pixtocam(focal=1.0, width=1.0, height=1.0, xnp=xnp)\n\n  camcoords = xnp.einsum('SH,...ij->...ji', pixtocams,\n                         xnp.concatenate([\n                             xnp.stack(pixel_coordinates(\n                                 pix_x_int, pix_y_int, xnp=xnp), axis=-1),\n                             xnp.ones_like(pix_x_int)[..., None],\n                         ],\n                                          axis=-1))\n  # Convert camera coordinates to world coordinates.\n  worldcoords = xnp.einsum('SH,...ij->...ji', camtoworlds, camcoords)\n\n  # Compute ray origins and directions.\n  origins = worldcoords[Ellipsis, 0, :]\n  directions = worldcoords[Ellipsis, 1:, :] - origins\n\n  # Compute ray differential radii.\n  radii = xnp.linalg.norm(directions, axis=-1, keepdims=True)\n\n  # Compute image plane coordinates.\n  imageplane = xnp.einsum('...ij,...j->...i', pixtocam_ndc, camcoords[Ellipsis, 1:])\n\n  # Apply distortion correction.\n  if distortion_params is not None:\n    # Unpack distortion parameters.\n    k1 = distortion_params['k1']\n    k2 = distortion_params['k2']\n    k3 = distortion_params['k3']\n    k4 = distortion_params['k4']\n    p1 = distortion_params['p1']\n    p2 = distortion_params['p2']"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Get ray origins and directions in world space.\n  # origins: shape SH + [3]\n  # directions: shape SH + [3]\n  origins, directions = ray_utils.camera_rays_from_pixels(\n      pix_x_int,\n      pix_y_int,\n      pixtocams,\n      camtoworlds,\n      pixtocam_ndc=pixtocam_ndc,\n      camtype=camtype,\n      xnp=xnp,\n  )\n\n  # Get ray differential radii.\n  # radii: shape SH + [1]\n  radii = ray_utils.ray_radii(\n      origins,\n      directions,\n      xnp=xnp,\n  )\n\n  # Get image plane coordinates.\n  # imageplane: shape SH + [2]\n  imageplane = ray_utils.ray_pixels(\n      origins,\n      directions,\n      pixtocams,\n      xnp=xnp,\n  )\n\n  # Get normalized view directions.\n  # viewdirs: shape SH + [3]\n  viewdirs = ray_utils.normalize(directions, xnp=xnp)\n\n  # Apply distortion correction.\n  if distortion_params is not None:\n    # Apply distortion correction.\n    # directions: shape SH + [3]\n    directions = ray_utils.distort_rays(\n        directions,\n        distortion_params,\n        xnp=xnp,\n    )\n\n    # Get normalized view directions.\n    # viewdirs: shape SH + [3]\n    viewdirs = ray_utils.normalize(directions, xnp=xnp)\n\n  return origins, directions, viewdirs, radii, imageplane\n\n"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  if camtype == ProjectionType.PANORAMIC:\n    # Pano cameras have no distortion or tangential distortion.\n    x, y = pix_x_int, pix_y_int\n    xd, yd = x, y\n  else:\n    # Distortion correction.\n    if distortion_params is None:\n      x, y = pix_x_int, pix_y_int\n      xd, yd = x, y\n    else:\n      # Distortion correction.\n      x, y = _radial_and_tangential_undistort(\n          xd=pix_x_int,\n          yd=pix_y_int,\n          k1=distortion_params['k1'],\n          k2=distortion_params['k2'],\n          k3=distortion_params['k3'],\n          k4=distortion_params['k4'],\n          p1=distortion_params['p1'],\n          p2=distortion_params['p2'],\n          xnp=xnp,\n      )\n\n  # Convert pixel coordinates to camera coordinates.\n  x_cam, y_cam = xnp.einsum('SH,...ij->...ji', x, pixtocams)\n\n  # Convert camera coordinates to world coordinates.\n  x_world, y_world, z_world = xnp.einsum('SH,...ij->...ji', x_cam, camtoworlds)\n\n  # Normalize ray directions.\n  ray_dirs = xnp.stack([x_world, y_world, z_world], axis=-1)\n  ray_dirs_norm = xnp.linalg.norm(ray_dirs, axis=-1, keepdims=True)\n  ray_dirs_normed = ray_dirs / ray_dirs_norm\n\n  # Compute ray origins and directions.\n  if camtype == ProjectionType.PANORAMIC:\n    # Pano cameras have no distortion or tangential distortion.\n    orig"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Compute ray origins in world coordinates.\n  if pixtocam_ndc is not None:\n    # Convert pix_x_int and pix_y_int to NDC space.\n    pix_x_int, pix_y_int = xnp.dot(pixtocam_ndc, xnp.stack([pix_x_int, pix_y_int, xnp.ones_like(pix_x_int)]))\n\n  if camtype == ProjectionType.PANORAMIC:\n    # Compute ray origins in world coordinates.\n    # In panoramic projection, ray origins are the camera centers.\n    origins = xnp.broadcast_to(camtoworlds[:, :3, 3], pix_x_int.shape + (3,))\n\n    # Compute ray directions in world coordinates.\n    # In panoramic projection, ray directions are the camera forward vectors.\n    directions = xnp.broadcast_to(camtoworlds[:, :3, 2], pix_x_int.shape + (3,))\n\n    # Compute ray differential radii in world coordinates.\n    # In panoramic projection, ray differential radii are the same as the ray directions.\n    radii = xnp.linalg.norm(directions, axis=-1, keepdims=True)\n\n    # Compute image plane coordinates in world coordinates.\n    # In panoramic projection, image plane coordinates are the same as the ray directions.\n    imageplane = directions\n\n  else:\n    # Compute ray origins in world coordinates.\n    # In perspective projection, ray origins are the camera centers.\n    origins = xnp.broadcast_to(camtoworlds[:, :3, 3], pix_x_int.shape + (3,))\n\n    # Compute ray directions in world coordinates.\n    # In perspective projection, ray directions are the normalized vectors from camera centers to pixel coordinates.\n    directions = xnp.stack(\n        [\n            (pix_x_int - camtoworlds[:,"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Get the number of pixels and number of cameras.\n  sh = pix_x_int.shape\n  sh_cam = camtoworlds.shape[:-2]\n  sh_out = sh + sh_cam + (3,)\n\n  # Create a grid of pixel coordinates.\n  pix_x, pix_y = pixel_coordinates(width=sh[-1], height=sh[-2], xnp=xnp)\n  pix_x = xnp.broadcast_to(pix_x, sh)\n  pix_y = xnp.broadcast_to(pix_y, sh)\n\n  # Convert pixel coordinates to camera coordinates.\n  pix_x_int = xnp.broadcast_to(pix_x_int, sh)\n  pix_y_int = xnp.broadcast_to(pix_y_int, sh)\n  cam_x, cam_y = xnp.einsum('SH,...ij->...Sj', xnp.sqrt(pix_x_int**2 + pix_y_int**2), pixtocams)\n\n  # Compute ray origins.\n  if camtype == ProjectionType.PANORAMIC:\n    # For panoramic cameras, the ray origin is the camera position.\n    origins = xnp.broadcast_to(camtoworlds[Ellipsis, :3, -1], sh_out)\n  else:\n    # For other camera types, the ray origin is the camera position plus the camera offset.\n    origins = xnp.broadcast_to(camtoworlds[Ellipsis, :3, -1], sh_out) + xnp.stack([cam_x, cam_y, xnp.zeros_like(cam_x)], axis=-1)\n\n  # Compute ray directions.\n  if camtype == ProjectionType.PANORAMIC:\n    # For panoramic cameras, the ray direction is the normalized camera offset.\n    directions = xnp.stack([cam_x, cam_y, xnp.ones"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Define the shape of the input arguments.\n  SH = pix_x_int.shape\n  if camtype == ProjectionType.PANORAMIC:\n    SH = SH[:-1]\n\n  # Convert pixel coordinates to camera coordinates.\n  if pixtocam_ndc is not None:\n    # If pixtocam_ndc is provided, use it to convert to NDC space.\n    pix_x_ndc = (pix_x_int - (pixtocam_ndc[0, 2] + pixtocam_ndc[0, 0]) / 2) / (pixtocam_ndc[0, 2] - pixtocam_ndc[0, 0])\n    pix_y_ndc = (pix_y_int - (pixtocam_ndc[1, 2] + pixtocam_ndc[1, 0]) / 2) / (pixtocam_ndc[1, 2] - pixtocam_ndc[1, 0])\n    pix_z_ndc = xnp.ones(SH, dtype=pixtocams.dtype)\n    pix_ndc = xnp.stack([pix_x_ndc, pix_y_ndc, pix_z_ndc], axis=-1)\n    pix_cam = xnp.matmul(pix_ndc, pixtocams.reshape(3, 3))\n  else:\n    # If pixtocam is provided, use it to convert to camera space.\n    pix_x_cam = (pix_x_int - pixtocams[0, 2]) / pixtocams[0, 0]\n    pix_y_cam = (pix_y_int - pixtocams[1, 2]) / pixtocams[1, 1]\n    pix_z_cam = xnp.ones(SH, dtype=pixtocams.dtype)\n    pix_cam = xnp.stack([pix_x_cam, pix_y_cam, pix_z_cam], axis"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Convert pixel coordinates to camera coordinates.\n  pix_x, pix_y = xnp.broadcast_arrays(pix_x_int, pix_y_int)\n  pix_x = pix_x.astype(pixtocams.dtype)\n  pix_y = pix_y.astype(pixtocams.dtype)\n  pix_x = xnp.reshape(pix_x, (-1, 1))\n  pix_y = xnp.reshape(pix_y, (-1, 1))\n  pix_xy = xnp.concatenate([pix_x, pix_y, xnp.ones_like(pix_x)], axis=-1)\n  cam_xy = pixtocams @ pix_xy\n  # Convert camera coordinates to world coordinates.\n  cam_xy = xnp.reshape(cam_xy, (-1, 3))\n  cam_xy = xnp.concatenate([cam_xy, xnp.ones_like(cam_xy[:, :1])], axis=-1)\n  world_xy = camtoworlds @ cam_xy\n\n  # Compute ray origins, directions, and view directions.\n  origins = xnp.broadcast_to(world_xy[:, :3], pix_xy.shape)\n  directions = world_xy[:, 3:] - origins\n  directions = xnp.linalg.norm(directions, axis=-1, keepdims=True)\n  viewdirs = directions / directions.mean()\n\n  # Compute differential radii.\n  radii = directions / directions.mean(keepdims=True)\n\n  # Convert ray origins and directions to NDC space.\n  if pixtocam_ndc is not None:\n    origins = pixtocam_ndc @ origins\n    directions = pixtocam_ndc @ directions\n\n  # Apply distortion correction.\n  if distortion_params is not None:\n    if camtype == ProjectionType.PERSPECTIVE:\n      # Convert to pixel coordinates in N"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Camera to world space.\n  cam_x_int, cam_y_int, cam_z_int = xnp.moveaxis(\n      xnp.einsum('SH,SH->SH', pixtocams, xnp.stack([pix_x_int, pix_y_int], -1)),\n      -1,\n      1,\n  )\n  cam_z_int = -cam_z_int\n\n  if camtype == ProjectionType.PERSPECTIVE:\n    # Perspective projection.\n    cam_z_int = xnp.broadcast_to(cam_z_int, pix_x_int.shape + (3,))\n    origins = xnp.concatenate([cam_x_int, cam_y_int, cam_z_int], -1)\n    directions = xnp.concatenate([cam_x_int, cam_y_int, cam_z_int], -1)\n\n  elif camtype == ProjectionType.FISHEYE:\n    # Fish-eye projection.\n    # Convert to normalized device coordinates.\n    if pixtocam_ndc is None:\n      raise ValueError('pixtocam_ndc is required for fisheye cameras.')\n    # TODO(jainaj): support non-square images.\n    # TODO(jainaj): support non-square pixtocam matrices.\n    image_plane = xnp.stack([\n        pix_x_int / (pix_x_int.shape[1] / 2.0) - 1.0,\n        -pix_y_int / (pix_y_int.shape[0] / 2.0) + 1.0,\n    ], -1)\n    image_plane = xnp.einsum('SH,SH->SH', pixtocam_ndc, image_plane)\n    cam_x_int = xnp.broadcast_to(image_plane[:, 0], pix_x_int.shape + (3,))\n    cam_y_int = xnp.broadcast_"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * (tdist[Ellipsis, 1:] - tdist[Ellipsis, :-1])\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * (tdist[Ellipsis, 1:] - tdist[Ellipsis, :-1])\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * (tdist[Ellipsis, 1:] - tdist[Ellipsis, :-1])\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * (tdist[Ellipsis, 1:] - tdist[Ellipsis, :-1])\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist[Ellipsis, :-1]\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * (tdist[Ellipsis, 1:] - tdist[Ellipsis, :-1])\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * (tdist[Ellipsis, 1:] - tdist[Ellipsis, :-1])\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * (tdist[Ellipsis, 1:] - tdist[Ellipsis, :-1])\n  weights = compute_alpha_weights_helper(density_delta, **kwargs)\n\n  return weights\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * (tdist[Ellipsis, 1:] - tdist[Ellipsis, :-1])\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * (tdist[Ellipsis, 1:] - tdist[Ellipsis, :-1])\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * (tdist[Ellipsis, 1:] - tdist[Ellipsis, :-1])\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # Sample from the inverse CDF.\n  u = jax.random.uniform(rng, (num_samples,), minval=eps, maxval=1 - eps)\n  t_new = invert_cdf(u, t, w_logits)\n  # Jitter the samples.\n  if single_jitter:\n    t_new = t_new + jax.random.uniform(\n        rng, t_new.shape, minval=eps, maxval=1 - eps)\n  else:\n    t_new = t_new + jax.random.uniform(\n        rng, t_new.shape, minval=-eps, maxval=eps)\n  # If desired, center the samples in each interval.\n  if deterministic_center:\n    t_new = t_new - 0.5 * (cw[Ellipsis, 1:] + cw[Ellipsis, :-1])\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  w = jax.nn.softmax(w_logits, axis=-1)\n\n  if rng is None:\n    # Use linspace for deterministic sampling.\n    samples = jnp.linspace(t[0], t[-1], num_samples)\n    if deterministic_center:\n      samples = samples - (samples[1] - samples[0]) / 2\n    return samples\n\n  # Sample from the CDF.\n  cw = integrate_weights(w)\n  u = jax.random.uniform(rng, (num_samples,), minval=eps, maxval=1 - eps)\n  t_new = invert_cdf(u, t, w_logits)\n\n  # Jitter the samples.\n  if single_jitter:\n    jitter = jax.random.uniform(rng, (), minval=eps, maxval=1 - eps)\n    t_new = t_new + jitter\n  else:\n    jitter = jax.random.uniform(rng, (num_samples,), minval=eps, maxval=1 - eps)\n    t_new = t_new + jitter\n\n  # Center the samples if desired.\n  if deterministic_center:\n    t_new = t_new - (t_new[1] - t_new[0]) / 2\n\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  # Check if the input arguments are valid.\n  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # Compute the range of uniform sampling.\n  if deterministic_center:\n    u = jnp.linspace(0.5 / num_samples, 1 - 0.5 / num_samples, num_samples)\n  else:\n    u = jnp.linspace(0, 1, num_samples)\n  # Sample from the inverse CDF.\n  t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n  if single_jitter:\n    t_new += jax.random.uniform(rng, t_new.shape, minval=-eps, maxval=eps)\n  else:\n    t_new += jax.random.uniform(rng, t_new.shape, minval=-eps, maxval=eps)\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  # Sample from the CDF.\n  u = jax.random.uniform(rng, (num_samples,))\n  t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n\n  # Jitter the samples.\n  if single_jitter:\n    t_new = t_new + jax.random.uniform(rng, t_new.shape) * eps\n  else:\n    t_new = t_new + jax.random.uniform(rng, t_new.shape) * eps\n\n  # Determine the center of each bin.\n  t_center = 0.5 * (t[Ellipsis, 1:] + t[Ellipsis, :-1])\n\n  # Determine the center of the step function.\n  t_step_center = 0.5 * (t[Ellipsis, 1:] + t[Ellipsis, :-1])\n\n  # Determine the width of each bin.\n  t_width = t[Ellipsis, 1:] - t[Ellipsis, :-1]\n\n  # Determine the width of the step function.\n  t_step_width = t[Ellipsis, 1:] - t[Ellipsis, :-1]\n\n  # Determine the width of the distribution.\n  t_dist_width = t[Ellipsis, -1] - t[Ellipsis, 0]\n\n  # Determine the width of the distribution.\n  t_step_dist_width = t[Ellipsis, -1] - t[Ellipsis, 0]\n\n  # Determine the center of the distribution.\n  t_dist_center = 0.5 * (t"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  w = jax.nn.softmax(w_logits, axis=-1)\n  # Compute the cumulative sum of the weights.\n  cw = integrate_weights(w)\n  # Compute the PDF.\n  p = weight_to_pdf(t, w)\n  # Compute the CDF.\n  cw_logits = jnp.log(cw)\n  cw_logits = jnp.where(jnp.isnan(cw_logits), jnp.zeros_like(cw_logits), cw_logits)\n  cw_logits = jnp.where(jnp.isinf(cw_logits), jnp.zeros_like(cw_logits), cw_logits)\n  cdf = jnp.cumsum(cw_logits, axis=-1)\n  # Compute the inverse CDF.\n  u = jax.random.uniform(rng, (num_samples,), minval=eps, maxval=1 - eps)\n  t_new = invert_cdf(u, t, cdf)\n  # Compute the jitter.\n  if single_jitter:\n    jitter = jax.random.uniform(rng, (1,), minval=eps, maxval=1 - eps)\n  else:\n    jitter = jax.random.uniform(rng, (num_samples,), minval=eps, maxval=1 - eps)\n  # Compute the samples.\n  if deterministic_center:\n    t_new = t_new - 0.5 * jnp.diff(t)\n  samples = query(t_new, t, p) + jitter * jnp.diff(t)\n  return samples\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # Compute the bin endpoints for each sample.\n  if rng is None:\n    # Use deterministic sampling if no random number generator is provided.\n    t_sample = jnp.linspace(0, 1, num_samples)\n  else:\n    # Use random sampling if a random number generator is provided.\n    if single_jitter:\n      # Use the same jitter amount for all samples.\n      jitter = jax.random.uniform(rng, (1,))\n      t_sample = jnp.linspace(jitter, 1 - jitter, num_samples)\n    else:\n      # Use different jitter amounts for each sample.\n      jitter = jax.random.uniform(rng, (num_samples,))\n      t_sample = jnp.linspace(jitter, 1 - jitter, num_samples)\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(t_sample, cw, t, utils.device_is_tpu())\n  # Determine the center of each bin.\n  if deterministic_center:\n    t_new = t_new - 0.5 * jnp.diff(t)\n  return t_new\n\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # Compute the PDF and CDF for each weight vector.\n  pdf = weight_to_pdf(t, w)\n  cdf = integrate_weights(pdf)\n\n  if rng is None:\n    # Deterministic sampling.\n    u = jnp.linspace(0, 1, num_samples)\n    u = jnp.expand_dims(u, axis=0)\n    if deterministic_center:\n      # Center the samples in each interval of the PDF.\n      u = u - 0.5 * (cdf[Ellipsis, 1:] - cdf[Ellipsis, :-1])\n    samples = invert_cdf(u, t, w_logits)\n  else:\n    # Random sampling.\n    if single_jitter:\n      u = jax.random.uniform(rng, (num_samples,))\n      u = jnp.expand_dims(u, axis=0)\n    else:\n      u = jax.random.uniform(rng, (num_samples,))\n    u = u + jnp.linspace(0, 1, num_samples) * eps\n    u = jnp.expand_dims(u, axis=0)\n    if deterministic_center:\n      # Center the samples in each interval of the PDF.\n      u = u - 0.5 * (cdf[Ellipsis, 1:] - cdf[Ellipsis, :-1])\n    samples = invert_cdf(u, t, w_logits)\n\n  return samples\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Sample from the CDF.\n  if rng is None:\n    # Use deterministic sampling if no rng is provided.\n    u = jnp.linspace(0, 1, num_samples, axis=0)\n  else:\n    # Use random sampling if an rng is provided.\n    if single_jitter:\n      # Use the same jitter amount for all samples.\n      u = jax.random.uniform(rng, (num_samples,))\n    else:\n      # Use different jitter amounts for each sample.\n      u = jax.random.uniform(rng, (num_samples,))\n\n  # Invert the CDF to get samples.\n  t_new = invert_cdf(u, t, w_logits)\n\n  # If using deterministic_center, shift the samples to the center of the interval.\n  if deterministic_center:\n    t_new = t_new - (t[1:] - t[:-1]) / 2\n\n  # Add a small amount of eps to avoid numerical issues.\n  return t_new + eps\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Get the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # Sample from the CDF.\n  u = jax.random.uniform(rng, shape=(num_samples,), minval=eps, maxval=1 - eps)\n  t_new = invert_cdf(u, t, w_logits)\n  # Jitter the samples.\n  if rng is not None:\n    if single_jitter:\n      jitter = jax.random.uniform(rng, shape=(num_samples,), minval=eps, maxval=1 - eps)\n      t_new = t_new + jitter\n    else:\n      jitter = jax.random.uniform(\n          jax.random.fold_in(rng, jnp.arange(num_samples)),\n          shape=(num_samples,),\n          minval=eps,\n          maxval=1 - eps,\n      )\n      t_new = t_new + jitter\n  # Deterministic sampling.\n  if deterministic_center:\n    t_new = jnp.where(jnp.abs(t_new - t[..., :-1]) < eps, t[..., 1:-1], t_new)\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  if rng is None:\n    # If no random number generator is provided, use deterministic sampling.\n    if deterministic_center:\n      # If the samples are centered in each interval, use the midpoints of the intervals.\n      t_samples = (t[Ellipsis, 1:] + t[Ellipsis, :-1]) / 2\n    else:\n      # If the samples are not centered, use the endpoints of the intervals.\n      t_samples = t\n  else:\n    # If a random number generator is provided, use random sampling.\n    if single_jitter:\n      # If all samples should be jittered by the same amount, use the same jitter value for all samples.\n      jitter = jax.random.uniform(rng, (1,)) * (t[Ellipsis, 1:] - t[Ellipsis, :-1])\n    else:\n      # If each sample should be jittered independently, use a random jitter value for each sample.\n      jitter = jax.random.uniform(rng, (num_samples,)) * (t[Ellipsis, 1:] - t[Ellipsis, :-1])\n\n    if deterministic_center:\n      # If the samples are centered in each interval, use the midpoints of the intervals.\n      t_samples = (t[Ellipsis, 1:] + t[Ellipsis, :-1]) / 2\n    else:\n      # If the samples are not centered, use the endpoints of the intervals.\n      t_samples = t\n\n    t_samples = t_samples + jitter\n\n  # Convert the samples to the range [0, 1].\n  u_samples = (t_samples - t[Ellipsis, :-1]) / (t[Ellipsis, 1:] - t[Ellipsis, :-1] + eps)\n "}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # Compute the center of each bin.\n  t_center = 0.5 * (t[Ellipsis, 1:] + t[Ellipsis, :-1])\n  # Compute the width of each bin.\n  t_width = t[Ellipsis, 1:] - t[Ellipsis, :-1]\n  # Compute the inverse CDF.\n  u = jnp.linspace(eps, 1 - eps, num_samples)\n  t_new = invert_cdf(u, t, w_logits)\n  # If using random sampling, generate samples and jitter them.\n  if rng is not None:\n    # Generate samples.\n    if single_jitter:\n      # Sample uniformly from the bin centers.\n      t_new_center = jax.random.uniform(\n          rng, shape=(num_samples,), minval=0, maxval=1)\n      # Jitter the samples.\n      t_new_center = jnp.where(t_new_center < cw[Ellipsis, 1:-1],\n                               t_new_center + eps, t_new_center - eps)\n      # Interpolate the samples to the bin endpoints.\n      t_new = math.sorted_interp(t_new_center, cw[Ellipsis, 1:-1], t,\n                                 utils.device_is_tpu())\n    else:\n      # Sample uniformly from the bin endpoints.\n      t_new = jax.random.uniform(\n          rng, shape=(num_samples,), minval=t[Ellipsis, :-1], maxval=t[Ellipsis, 1:])\n      # Jitter the samples.\n      t_new = jnp.where(t_new"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the CDF and PDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  p = weight_to_pdf(t, w)\n  # Compute the uniform sampling points.\n  if rng is None:\n    # Deterministic sampling.\n    u = jnp.linspace(0, 1, num_samples, axis=-1)\n  else:\n    # Random sampling.\n    if single_jitter:\n      # Use the same jittering amount for all samples.\n      u = jax.random.uniform(rng, (num_samples,), minval=eps, maxval=1.0)\n    else:\n      # Use different jittering amounts for each sample.\n      u = jax.random.uniform(rng, (num_samples,), minval=eps, maxval=1.0)\n  # Sample from the CDF.\n  t_new = invert_cdf(u, t, w_logits)\n  # Compute the bin indices.\n  i = math.searchsorted(t, t_new, side='right')\n  # Compute the bin weights.\n  w = jnp.take_along_axis(w, i, axis=-1)\n  # Compute the bin weights.\n  p = jnp.take_along_axis(p, i, axis=-1)\n  # Compute the bin weights.\n  cw = jnp.take_along_axis(cw, i, axis=-1)\n  # Compute the bin weights.\n  if deterministic_center:\n    # Center the samples in each bin.\n    w = w - 0.5 * (w[Ellipsis, 1:] + w[Ellipsis, :-1])\n    p = p - 0.5 * (p[Ellipsis, 1:] + p[Ellipsis, :-1])\n    cw = cw - 0"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  if single_jitter:\n    # Generate a random jitter for all samples.\n    jitter = jax.random.uniform(\n        jax.random.PRNGKey(0),\n        shape=[num_samples],\n        minval=-eps,\n        maxval=eps,\n        dtype=jnp.float32,\n    )\n  else:\n    # Generate a random jitter for each sample.\n    jitter = jax.random.uniform(\n        jax.random.PRNGKey(0),\n        shape=[num_samples, 1],\n        minval=-eps,\n        maxval=eps,\n        dtype=jnp.float32,\n    )\n\n  if rng is not None:\n    # Use random sampling.\n    # If the center of the distribution is to be focused on, we generate samples in the center of each interval.\n    if deterministic_center:\n      # Sample uniformly in the center of each interval.\n      samples = jnp.zeros(shape=[num_samples, len(t) - 1])\n      for i in range(len(t) - 1):\n        samples = samples.at[:, i].set(\n            jax.random.uniform(\n                rng,\n                shape=[num_samples],\n                minval=t[i] + (t[i + 1] - t[i]) / 2 - (t[i + 1] - t[i]) / 4,\n                maxval=t[i] + (t[i + 1] - t[i]) / 2 + (t[i + 1] - t[i]) / 4,\n            ))\n    else:\n      # Sample uniformly in each interval.\n      samples = jnp.zeros(shape=[num_samples, len(t) - 1])\n      for i in range(len(t) - 1):\n        samples ="}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  w = jax.nn.softmax(w_logits, axis=-1)\n\n  # Compute the CDF for each weight vector.\n  cw = integrate_weights(w)\n\n  # Compute the PDF for each weight vector.\n  p = weight_to_pdf(t, w)\n\n  # Determine the range of uniform sampling.\n  if deterministic_center:\n    # Center the samples in each interval.\n    t_range = 0.5 * (t[Ellipsis, 1:] + t[Ellipsis, :-1])\n  else:\n    # Spread the samples over the entire interval.\n    t_range = t[Ellipsis, 1:] - t[Ellipsis, :-1]\n\n  # Compute the range of uniform sampling.\n  u_range = t_range / (cw[Ellipsis, 1:] - cw[Ellipsis, :-1])\n\n  # Compute the inverse CDF.\n  u = jax.random.uniform(\n      rng, shape=[num_samples], minval=0.0, maxval=1.0, dtype=jnp.float32)\n  t_new = invert_cdf(u, t, w_logits)\n\n  # Sample uniformly in the range of each interval.\n  if single_jitter:\n    # Add a small amount of uniform jitter to each sample.\n    t_new = t_new + jnp.expand_dims(\n        jax.random.uniform(rng, shape=[num_samples], minval=0.0, maxval=1.0,\n                           dtype=jnp.float32),\n        axis=-1) * eps\n  else:\n    # Add a small amount of uniform jitter to each sample.\n    t_new = t_new + jax.random.uniform(\n        rng, shape=[num_samples, t_new.shape[-1]], minval=0.0, maxval=1.0,"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  w = jax.nn.softmax(w_logits, axis=-1)\n\n  # Compute the PDF and CDF for each weight vector.\n  cw = integrate_weights(w)\n\n  # If using random sampling, generate samples in [0, 1) and invert the CDF to get samples in the range of the step function.\n  if rng is not None:\n    # Generate random samples in [0, 1).\n    if single_jitter:\n      u = jax.random.uniform(\n          rng, (num_samples,), minval=0, maxval=1, dtype=jnp.float32)\n    else:\n      u = jax.random.uniform(\n          rng, (num_samples, t.shape[-1]), minval=0, maxval=1, dtype=jnp.float32)\n\n    # Invert the CDF to get samples in the range of the step function.\n    t_new = invert_cdf(u, t, w_logits)\n\n    # Jitter the samples.\n    if single_jitter:\n      t_new = t_new + eps * jax.random.uniform(\n          rng, (num_samples,), minval=-0.5, maxval=0.5, dtype=jnp.float32)\n    else:\n      t_new = t_new + eps * jax.random.uniform(\n          rng,\n          (num_samples, t.shape[-1]),\n          minval=-0.5,\n          maxval=0.5,\n          dtype=jnp.float32)\n\n    # If using deterministic sampling, center the samples in each interval of the step function.\n    if deterministic_center:\n      t_new = t_new - 0.5 * (t[1:] + t[:-1])\n\n    # Return the samples.\n    return t_new\n\n  # If using deterministic sampling, generate samples in the range of the step function and then jitter them"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  # If single jitter is used, use the same jitter for all samples.\n  if single_jitter:\n    jitter = 1 / (1 + num_samples)\n  else:\n    jitter = 1 / (1 + 2 * num_samples)\n\n  # If deterministic sampling is used, use linspace instead of random sampling.\n  if deterministic_center:\n    # Compute the center of the intervals.\n    t_center = (t[Ellipsis, 1:] + t[Ellipsis, :-1]) / 2\n    # Sample from the uniform distribution.\n    u = jnp.linspace(jitter, 1 - jitter, num_samples)\n    # Interpolate into the inverse CDF.\n    t_new = math.sorted_interp(u, cw, t_center, utils.device_is_tpu())\n\n  # If random sampling is used, generate random samples and jitter them.\n  else:\n    # Sample from the uniform distribution.\n    u = jax.random.uniform(rng, (num_samples,))\n    # Jitter the samples.\n    u = u + jitter * jax.random.choice([-1, 1], (num_samples,), rng)\n    # Interpolate into the inverse CDF.\n    t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n\n  # Add a small value to the samples to avoid numerical issues.\n  t_new = t_new + eps\n\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  if rng is not None:\n    if single_jitter:\n      u = jax.random.uniform(rng, (num_samples,), minval=eps, maxval=1 - eps)\n    else:\n      u = jax.random.uniform(rng, (num_samples,), minval=0, maxval=1)\n  else:\n    u = jnp.linspace(eps, 1 - eps, num_samples, dtype=jnp.float32)\n  if deterministic_center:\n    t = jnp.concatenate([t[..., :1] - (t[..., 1:] - t[..., :1]) / 2, t], axis=-1)\n    cw = jnp.concatenate([cw[..., :1:], cw], axis=-1)\n  t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  batch_shape = w_logits.shape[:-1]\n  num_bins = w_logits.shape[-1]\n\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  # Compute the bin sizes.\n  dt = jnp.diff(t)\n\n  # Compute the sample points.\n  if rng is None:\n    # Use linspace to generate samples.\n    u = jnp.linspace(0, 1, num_samples, dtype=jnp.float32)\n    if deterministic_center:\n      # Center the samples in each interval.\n      u = 0.5 * (u + 1)\n  else:\n    # Use random uniform sampling.\n    if single_jitter:\n      u = jax.random.uniform(\n          rng, (num_samples,), minval=eps, maxval=1.0 - eps)\n    else:\n      u = jax.random.uniform(\n          rng, (num_samples, num_bins), minval=eps, maxval=1.0 - eps)\n    if deterministic_center:\n      # Center the samples in each interval.\n      u = 0.5 * (u + 1)\n\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n\n  # Sample from the bin sizes.\n  t_new = t_new + dt * jax.random.uniform(\n      rng, t_new.shape, minval=0.0, maxval=1.0)\n\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # Compute the center points of each bin.\n  t_center = (t[Ellipsis, 1:] + t[Ellipsis, :-1]) / 2.0\n  # Compute the width of each bin.\n  t_width = jnp.diff(t)\n  # Compute the PDF of the step function.\n  pdf = weight_to_pdf(t, w)\n  # Compute the CDF of the step function.\n  cdf = integrate_weights(pdf)\n\n  # If single_jitter is True, jitter each sample by the same amount.\n  if single_jitter:\n    # We use the eps value to add a small amount to the uniform samples.\n    u = jax.random.uniform(\n        rng, shape=(num_samples,), minval=eps, maxval=1.0 - eps)\n  # If single_jitter is False, jitter each sample independently.\n  else:\n    # We use the eps value to add a small amount to the uniform samples.\n    u = jax.random.uniform(\n        rng, shape=(num_samples, len(t_center)), minval=eps, maxval=1.0 - eps)\n\n  # If deterministic_center is True, the samples are centered in each bin.\n  if deterministic_center:\n    # Compute the samples from the PDF.\n    t_new = t_center + t_width * u\n  # If deterministic_center is False, the samples are distributed across the bins.\n  else:\n    # Compute the samples from the PDF.\n    t_new = t + t_width * u\n\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(cdf, cw, t_new, utils.device_"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  batch_size = w_logits.shape[0]\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  # If we're using deterministic sampling, we need to generate samples in a\n  # deterministic way.\n  if rng is None:\n    # Compute the center of the bins.\n    t_center = (t[Ellipsis, 1:] + t[Ellipsis, :-1]) / 2\n    # If we're centering the samples, we need to shift the samples by a small\n    # amount so that they're centered in the bin.\n    if deterministic_center:\n      t_center = t_center + eps\n    # Use linspace to generate samples.\n    samples = jnp.expand_dims(jnp.linspace(0, 1, num_samples), axis=0)\n    samples = jnp.tile(samples, [batch_size, 1])\n    # Convert the samples to the desired range.\n    samples = samples * (t_center[-1] - t_center[0]) + t_center[0]\n\n  # Otherwise, we're using random sampling.\n  else:\n    # Generate uniform samples in [0, 1).\n    samples = jax.random.uniform(\n        rng,\n        shape=(batch_size, num_samples),\n        minval=eps,\n        maxval=1 - eps,\n    )\n    # If we're using single jitter, we want to add a small amount of jitter to\n    # each sample.\n    if single_jitter:\n      samples = samples + jax.random.uniform(\n          rng,\n          shape=(batch_size, num_samples),\n          minval=0,\n          maxval=eps,\n      )\n\n  # Interpolate into the inverse CDF.\n  samples = math.sorted_inter"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1.0 - eps, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = eps + (1 - eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n\n  # Calculate midpoints between adjacent samples.\n  t_mid = 0.5 * (t_new[Ellipsis, 1:] + t_new[Ellipsis, :-1])\n\n  # Adjust first and last intervals to fit within the specified domain.\n  t_new = jnp.concatenate([jnp.array([domain[0]]), t_mid, jnp.array([domain[1]])], axis=-1)\n\n  return t_new\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1.0 - eps, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = eps + (1 - eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n\n  # Calculate midpoints between adjacent samples.\n  t_mid = (t_new[..., 1:] + t_new[..., :-1]) / 2\n\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n  t_mid = jnp.concatenate([t_mid, t_new[..., -1:]], axis=-1)\n  t_new = jnp.concatenate([domain[0] * jnp.ones(t_mid.shape), t_mid, domain[1] * jnp.ones(t_mid.shape)], axis=-1"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u_max = eps + (1 - eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = eps + (1 - eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Invert the CDF to get samples from the step function.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Calculate midpoints between adjacent samples.\n  t_midpoints = (t_samples[..., 1:] + t_samples[..., :-1]) / 2\n\n  # Adjust the first and last samples to ensure they are within the specified domain.\n  t_samples = jnp.concatenate([jnp.array([domain[0]]), t_midpoints, jnp.array([domain[1]])], axis=-1)\n\n  return t_samples\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1.0 - eps, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = eps + (1 - eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Invert the CDF to get the samples.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Calculate the midpoints between adjacent samples.\n  t_midpoints = (t_samples[..., 1:] + t_samples[..., :-1]) / 2\n\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n  t_samples = jnp.concatenate(\n      [jnp.array([domain[0]]), t_midpoints, jnp.array([domain[1]])], axis=-1\n  )\n\n  return t_samples\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1.0 - eps, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = eps + (1 - eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Calculate midpoints between adjacent samples.\n  t_samples = invert_cdf(u, t, w_logits)\n  t_samples = 0.5 * (t_samples[..., 1:] + t_samples[..., :-1])\n\n  # Adjust first and last intervals to ensure they are within the specified domain.\n  t_samples = jnp.concatenate([jnp.array([domain[0]]), t_samples], axis=-1)\n  t_samples = jnp.concatenate([t_samples, jnp.array([domain[1]])], axis=-1)\n\n  return t_samples\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u_max = eps + (1 - eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = eps + (1 - eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Invert the CDF to get samples from the step function.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Calculate midpoints between adjacent samples.\n  t_midpoints = (t_samples[..., 1:] + t_samples[..., :-1]) / 2\n\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n  t_midpoints = jnp.concatenate([t_midpoints[..., 0:1], t_midpoints], axis=-1)\n  t_midpoints = jnp.concatenate([t_midpoints, t_midpoints[..., -1:]], axis=-1)\n  t_midpoints"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1.0 - eps, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = eps + (1 - eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Invert the CDF to get samples of the step function.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Calculate the midpoints between adjacent samples.\n  t_midpoints = (t_samples[Ellipsis, 1:] + t_samples[Ellipsis, :-1]) / 2\n\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n  t_samples = jnp.concatenate((jnp.array([domain[0]]), t_midpoints, jnp.array([domain[1]])), axis=-1)\n\n  return t_samples\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1.0 - eps, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = eps + (1 - eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Invert the CDF to get samples.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Calculate midpoints between adjacent samples.\n  t_midpoints = (t_samples[..., 1:] + t_samples[..., :-1]) / 2\n\n  # Adjust the first and last samples to ensure they are within the domain.\n  t_samples = jnp.concatenate([t_samples[..., 0:1], t_midpoints, t_samples[..., -1:]], axis=-1)\n\n  # Ensure the samples are within the domain.\n  t_samples = jnp.maximum(t_samples, domain[0])\n  t_samples = jnp.minimum(t_samples, domain[1])\n\n  return t_samples\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1.0 - eps, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = eps + (1 - eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Invert the CDF to get samples from the step function.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Calculate midpoints between adjacent samples.\n  t_midpoints = (t_samples[..., 1:] + t_samples[..., :-1]) / 2\n\n  # Adjust the first and last interval to fit within the specified domain.\n  t_samples = jnp.concatenate(\n      [\n          jnp.array([domain[0]]),\n          t_midpoints,\n          jnp.array([domain[1]]),\n      ],\n      axis=-1,\n  )\n\n  return t_samples\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1.0 - eps, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = eps + (1 - eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Invert the CDF to get the sampled points.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Calculate the midpoints between adjacent samples.\n  t_midpoints = (t_samples[Ellipsis, 1:] + t_samples[Ellipsis, :-1]) / 2\n\n  # Calculate the interval midpoints.\n  t_intervals = jnp.concatenate([t_samples[Ellipsis, 0:1], t_midpoints, t_samples[Ellipsis, -1:]], axis=-1)\n\n  # Adjust the first and last interval to ensure they are within the specified domain.\n  t_intervals = jnp.maximum(t_intervals, domain[0])\n  t_intervals = jnp.minimum(t_intervals, domain[1])\n\n  return t_intervals\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1.0 - eps, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = eps + (1 - eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Convert uniform samples to interval samples.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Adjust first and last interval to fit within domain.\n  t_samples = jnp.where(t_samples == t[Ellipsis, 0], domain[0], t_samples)\n  t_samples = jnp.where(t_samples == t[Ellipsis, -1], domain[1], t_samples)\n\n  return t_samples\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u_max = eps + (1 - eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = eps + (1 - eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Invert the CDF to get samples from the step function.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Calculate the midpoints between adjacent samples.\n  midpoints = (t_samples[Ellipsis, 1:] + t_samples[Ellipsis, :-1]) / 2\n\n  # Adjust the first and last samples to ensure they are within the specified domain.\n  midpoints = jnp.concatenate([jnp.array([domain[0]]), midpoints, jnp.array([domain[1]])], axis=-1)\n\n  return midpoints\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    u = jnp.linspace(0, 1.0 - eps, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = eps + (1 - eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n\n  # Compute the midpoints between adjacent samples.\n  t_mid = (t_new[..., 1:] + t_new[..., :-1]) / 2\n\n  # Adjust the first and last samples to ensure they are within the specified domain.\n  t_mid = jnp.concatenate([jnp.array([domain[0]]), t_mid, jnp.array([domain[1]])], axis=-1)\n\n  return t_mid\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1 - eps, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = eps + (1 - eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Invert the CDF to get the samples.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Calculate midpoints between adjacent samples.\n  midpoints = (t_samples[..., 1:] + t_samples[..., :-1]) / 2\n\n  # Calculate the interval widths.\n  widths = t_samples[..., 1:] - t_samples[..., :-1]\n\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n  midpoints = jnp.concatenate(\n      [jnp.array([domain[0]]), midpoints, jnp.array([domain[1]])], axis=-1\n  )\n  widths = jnp.concatenate(\n      [jnp.array([midpoints[..., 1] - domain[0]]), widths, jnp.array([midpoints[..., -1] - midpoints[..., -2]])], axis=-1\n  )\n\n  #"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1.0 - eps, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = eps + (1 - eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Invert the CDF to get the samples.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Calculate the midpoints between adjacent samples.\n  t_midpoints = (t_samples[..., 1:] + t_samples[..., :-1]) / 2\n\n  # Adjust the first and last intervals to ensure they are within the domain.\n  t_samples = jnp.concatenate([jnp.expand_dims(domain[0], -1), t_midpoints, jnp.expand_dims(domain[1], -1)], axis=-1)\n\n  return t_samples\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1.0 - eps, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = eps + (1 - eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Invert the CDF to get the sampled intervals.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Adjust the first and last intervals to ensure they are within the specified domain.\n  t_samples = jnp.concatenate([jnp.expand_dims(domain[0], axis=-2), t_samples], axis=-2)\n  t_samples = jnp.concatenate([t_samples, jnp.expand_dims(domain[1], axis=-2)], axis=-2)\n\n  # Calculate the midpoints between adjacent intervals.\n  t_samples_midpoints = (t_samples[Ellipsis, 1:] + t_samples[Ellipsis, :-1]) / 2\n\n  # Calculate the midpoints of the first and last intervals.\n  t_samples_midpoints = jnp.concatenate(\n      [jnp.expand_dims(t_samples[Ellipsis"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1.0 - eps, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = eps + (1 - eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Invert the CDF to get the interval midpoints.\n  t_mid = invert_cdf(u, t, w_logits)\n\n  # Adjust the first and last intervals to fit within the domain.\n  t_mid = jnp.concatenate([t[Ellipsis, :1], t_mid, t[Ellipsis, -1:]], axis=-1)\n  t_mid = jnp.cumsum(t_mid, axis=-1)\n  t_mid = jnp.concatenate([jnp.array([domain[0]]), t_mid], axis=-1)\n  t_mid = jnp.concatenate([t_mid, jnp.array([domain[1]])], axis=-1)\n\n  return t_mid\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1.0 - eps, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = eps + (1 - eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Invert the CDF to get the samples.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Calculate the midpoints between adjacent samples.\n  t_midpoints = (t_samples[..., 1:] + t_samples[..., :-1]) / 2\n\n  # Calculate the interval sizes.\n  interval_sizes = jnp.diff(t_samples, axis=-1)\n\n  # Calculate the interval sizes for the midpoints.\n  midpoint_interval_sizes = jnp.diff(t_midpoints, axis=-1)\n\n  # Calculate the midpoints of the intervals.\n  t_midpoints_of_intervals = (t_midpoints[..., :-1] + t_midpoints[..., 1:]) / 2\n\n  # Calculate the midpoints of the intervals, adjusted to fit within the specified domain.\n  t_midpoints_of_intervals = jnp.where(\n      t_mid"}
{"namespace": "stepfun.sample_intervals", "completion": "  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u_max = 1 - (1 / num_samples)\n    max_jitter = (1 - u_max) / (num_samples - 1)\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = 1 - (1 / num_samples)\n    max_jitter = (1 - u_max) / (num_samples - 1)\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Calculate midpoints between adjacent samples.\n  t_samples = invert_cdf(u, t, w_logits)\n  t_samples_mid = (t_samples[..., 1:] + t_samples[..., :-1]) / 2\n\n  # Adjust first and last intervals to fit within the domain.\n  t_samples_mid = jnp.concatenate([t_samples[..., 0:1], t_samples_mid, t_samples[..., -1:]], axis=-1)\n  t_samples_mid = jnp.maximum(t_samples_mid, domain[0])\n  t_samples_mid = jnp.minimum(t_samples_mid, domain[1])\n\n  return t_samples_mid\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  # Check that the input arguments are valid.\n  utils.assert_valid_stepfun(t, w_logits)\n  assert domain[0] <= domain[1]\n\n  # Sample points from the step function.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1.0 - eps, num_samples)\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = eps + (1 - eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Invert the CDF to get samples from the step function.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Calculate midpoints between adjacent samples.\n  t_midpoints = (t_samples[..., 1:] + t_samples[..., :-1]) / 2\n\n  # Adjust the first and last samples to ensure they are within the specified domain.\n  t_samples = jnp.concatenate(\n      [\n          jnp.array([domain[0]]),\n          t_midpoints,\n          jnp.array([domain[1]]),\n      ],\n      axis=-1,\n  )\n\n  return t_samples\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Compute the cumulative sum of w, assuming all weight vectors sum to 1.\n  cw = integrate_weights(w)\n  # Interpolate into the inverse CDF.\n  p_new = math.sorted_interp(ps, cw, t, utils.device_is_tpu())\n  return p_new\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Compute the cumulative sum of w, assuming all weight vectors sum to 1.\n  cw = integrate_weights(w)\n  # Interpolate into the inverse CDF.\n  p_new = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n  return p_new\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Compute the cumulative sum of w, assuming all weight vectors sum to 1.\n  cw = integrate_weights(w)\n\n  # Interpolate into the inverse CDF.\n  ps = jnp.array(ps) / 100\n  t_new = math.sorted_interp(ps, cw, t, utils.device_is_tpu())\n  return t_new\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  # Ensure that the weights sum to 1.\n  w = w / jnp.sum(w)\n\n  # Compute the cumulative sum of the weights.\n  cw = integrate_weights(w)\n\n  # Interpolate into the cumulative weights.\n  p_new = math.sorted_interp(ps, cw, t, utils.device_is_tpu())\n\n  return p_new\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  ps = jnp.array(ps)\n\n  # Compute the cumulative sum of w, assuming all weight vectors sum to 1.\n  cw = integrate_weights(w)\n\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n  return t_new\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  # Ensure that the weights sum to 1.\n  w = w / jnp.sum(w)\n  # Integrate the weights.\n  cw = integrate_weights(w)\n  # Interpolate into the integrated weights.\n  p = math.sorted_interp(ps, cw, t, utils.device_is_tpu())\n  return p\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  ps = jnp.array(ps)\n  ps = jnp.clip(ps, 0, 100)\n  ps = ps / 100\n  cw = integrate_weights(w)\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(ps, cw, t, utils.device_is_tpu())\n  return t_new\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Compute the CDF for each weight vector.\n  w = jax.nn.softmax(w, axis=-1)\n  cw = integrate_weights(w)\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(ps/100, cw, t, utils.device_is_tpu())\n  return t_new\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  ps = jnp.asarray(ps)\n  ps = jnp.clip(ps, 0, 100)\n  ps = ps / 100.0\n  cw = integrate_weights(w)\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(ps, cw, t, utils.device_is_tpu())\n  return t_new\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  w = jnp.minimum(1, jnp.maximum(0, w))\n  ps = jnp.array(ps)\n  ps = jnp.where(ps < 0, 0, ps)\n  ps = jnp.where(ps > 100, 100, ps)\n  cw = integrate_weights(w)\n  t_new = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n  return t_new\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  # Ensure that the weights sum to 1.\n  w = w / jnp.sum(w)\n  # Compute the cumulative sum of the weights.\n  cw = integrate_weights(w)\n  # Interpolate into the integrated weights.\n  cw_ps = math.sorted_interp(ps, cw, t, utils.device_is_tpu())\n  # Compute the weighted percentiles.\n  w_ps = jnp.sum(w * cw_ps, axis=-1)\n\n  return w_ps\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Convert percentiles to fractions.\n  ps = jnp.asarray(ps)\n  ps = ps / 100\n\n  # Compute the cumulative sum of the weights.\n  cw = integrate_weights(w)\n\n  # Interpolate into the cumulative weights to get the percentiles.\n  p = math.sorted_interp(ps, cw, t, utils.device_is_tpu())\n\n  return p\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  ps = jnp.asarray(ps)\n  ps = jnp.clip(ps, 0, 100)\n  ps = ps / 100\n  cw = integrate_weights(w)\n  t_new = math.sorted_interp(ps, cw, t, utils.device_is_tpu())\n  return t_new\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  ps = jnp.array(ps)\n\n  # Compute the cumulative sum of the weights.\n  w_cumsum = jnp.cumsum(w, axis=-1)\n\n  # Interpolate into the integrated weights.\n  p_int = math.sorted_interp(ps / 100, w_cumsum, t, utils.device_is_tpu())\n\n  return p_int\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  # Check that the inputs are valid.\n  utils.assert_valid_stepfun(t, w)\n  ps = jnp.array(ps)\n  if jnp.any(ps < 0) or jnp.any(ps > 100):\n    raise ValueError(f'Percentiles must be between 0 and 100, but got {ps}.')\n\n  # Compute the cumulative sum of the weights.\n  cw = integrate_weights(w)\n\n  # Interpolate into the cumulative weights to find the target percentiles.\n  p_target = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n\n  return p_target\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  # Ensure that the weights sum to 1.\n  w = w / jnp.sum(w)\n\n  # Compute the cumulative sum of the weights.\n  cw = integrate_weights(w)\n\n  # Interpolate the percentiles into the cumulative sum.\n  p = math.sorted_interp(ps, cw, t, utils.device_is_tpu())\n\n  return p\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  # Ensure that the input values are valid.\n  utils.assert_valid_stepfun(t, w)\n  utils.assert_valid_percentiles(ps)\n\n  # Compute the cumulative sum of the weights.\n  cw = integrate_weights(w)\n\n  # Compute the interpolated values.\n  t_new = linspline.interpolate(ps, cw, t, utils.device_is_tpu())\n\n  return t_new\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  ps = jnp.array(ps)\n  ps = jnp.reshape(ps, (-1,))\n  ps = jnp.sort(ps)\n  ps = jnp.concatenate([jnp.array([0]), ps, jnp.array([100])])\n  ps = ps / 100\n  ps = jnp.array(ps)\n  cw = integrate_weights(w)\n  t_new = math.sorted_interp(ps, cw, t, utils.device_is_tpu())\n  return t_new\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Compute the cumulative sum of w, assuming all weight vectors sum to 1.\n  cw = integrate_weights(w)\n  # Interpolate into the integral to find the percentile values.\n  p_new = math.sorted_interp(ps, cw, t, utils.device_is_tpu())\n  return p_new\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  # Ensure that the weights sum to 1.\n  w = w / jnp.sum(w)\n\n  # Compute the cumulative sum of the weights.\n  cw = integrate_weights(w)\n\n  # Interpolate into the integrated weights.\n  p_new = math.sorted_interp(ps, cw, t, utils.device_is_tpu())\n\n  return p_new\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert the histogram to a PDF\n  w_pdf = weight_to_pdf(t, w)\n\n  # Blur the PDF\n  w_pdf_blurred = linspline.blur(t, w_pdf, blur_halfwidth)\n\n  # Convert the blurred PDF back to a histogram\n  w_resampled = resample(tq, t, w_pdf_blurred)\n\n  return w_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert the histogram to a PDF\n  w_pdf = weight_to_pdf(t, w)\n  # Blur the PDF\n  w_blur = linspline.blur(t, w_pdf, blur_halfwidth)\n  # Resample the blurred PDF to the new time points\n  w_resampled = resample(tq, t, w_blur)\n  return w_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert the histogram to a PDF\n  w_pdf = weight_to_pdf(t, w)\n\n  # Blur the PDF\n  w_pdf_blurred = linspline.blur(w_pdf, blur_halfwidth)\n\n  # Resample the blurred PDF to the new time points\n  w_resampled = resample(tq, t, w_pdf_blurred)\n\n  return w_resampled\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert the histogram into a PDF.\n  w_pdf = weight_to_pdf(t, w)\n\n  # Blur the PDF.\n  w_pdf_blurred = linspline.blur(t, w_pdf, blur_halfwidth)\n\n  # Convert the blurred PDF back into a histogram.\n  w_resampled = resample(tq, t, w_pdf_blurred)\n\n  return w_resampled\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert the histogram to a PDF.\n  pdf = weight_to_pdf(t, w)\n  pdf = pdf / jnp.sum(pdf)\n\n  # Blur the PDF.\n  pdf = linspline.blur(pdf, blur_halfwidth)\n\n  # Convert the blurred PDF back to a histogram.\n  w_blurred = pdf_to_weight(t, pdf)\n\n  # Resample the histogram to the new time points.\n  w_resampled = resample(tq, t, w_blurred)\n\n  return w_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Compute the PDF of the histogram.\n  pdf = weight_to_pdf(t, w)\n\n  # Blur the PDF.\n  pdf_blurred = linspline.blur_pdf(pdf, blur_halfwidth)\n\n  # Resample the blurred PDF to match the new time points.\n  w_resampled = resample(tq, t, pdf_blurred)\n\n  return w_resampled\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Converting the histogram to a PDF\n  pdf = weight_to_pdf(t, w)\n  # Blurring the PDF\n  pdf_blurred = linspline.blur_pdf(pdf, blur_halfwidth)\n  # Resampling the PDF to match the new time points\n  wq = resample(tq, t, pdf_blurred)\n  return wq\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Convert the histogram to a PDF.\n  w = weight_to_pdf(t, w)\n\n  # Blur the PDF.\n  w = linspline.blur_pdf(t, w, blur_halfwidth)\n\n  # Resample the PDF to match the new time points.\n  w = resample(tq, t, w)\n\n  return w\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Converts the histogram to a PDF\n  pdf = weight_to_pdf(t, w)\n  # Blurs the PDF\n  pdf_blurred = linspline.blur_pdf(pdf, blur_halfwidth)\n  # Resamples the blurred PDF to the new time points\n  w_resampled = resample(tq, t, pdf_blurred)\n  return w_resampled\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert the histogram to a PDF\n  pdf = weight_to_pdf(t, w)\n\n  # Blur the PDF\n  pdf_blurred = linspline.blur(pdf, blur_halfwidth)\n\n  # Resample the blurred PDF to the new time points\n  w_blurred_resampled = resample(tq, t, pdf_blurred)\n\n  return w_blurred_resampled\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert the weights to a PDF\n  pdf = weight_to_pdf(t, w)\n  # Blur the PDF\n  pdf_blur = linspline.blur(pdf, blur_halfwidth)\n  # Resample the blurred PDF to the new time points\n  w_blur_resampled = resample(tq, t, pdf_blur)\n  return w_blur_resampled\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert to numpy arrays\n  tq = np.array(tq)\n  t = np.array(t)\n  w = np.array(w)\n\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w, axis=-1)\n  cw = integrate_weights(w)\n\n  # Compute the blurred CDF.\n  cw_blurred = linspline.blur_cdf(t, cw, blur_halfwidth)\n\n  # Compute the blurred PDF.\n  w_blurred = math.safe_div(w, jnp.diff(t))\n  w_blurred = linspline.blur_pdf(t, w_blurred, blur_halfwidth)\n\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(tq, cw_blurred, t, utils.device_is_tpu())\n  w_new = math.sorted_interp(tq, cw_blurred, w_blurred, utils.device_is_tpu())\n\n  return w_new\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # First, convert the histogram into a PDF\n  w = math.safe_div(w, jnp.sum(w))\n  w_pdf = weight_to_pdf(t, w)\n\n  # Next, blur the PDF\n  w_pdf_blurred = linspline.blur(w_pdf, blur_halfwidth)\n\n  # Finally, resample the PDF to match the new time points\n  w_resampled = resample(tq, t, w_pdf_blurred)\n\n  return w_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert the histogram to a PDF, and blur it.\n  w_pdf = weight_to_pdf(t, w)\n  w_pdf_blurred = linspline.blur(w_pdf, blur_halfwidth)\n\n  # Convert the blurred PDF to a histogram, and resample it to the new time points.\n  w_blurred = pdf_to_weight(t, w_pdf_blurred)\n  w_resampled = resample(tq, t, w_blurred, use_avg=False)\n\n  return w_resampled\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert the weights to a PDF\n  pdf = weight_to_pdf(t, w)\n\n  # Blur the PDF\n  blurred_pdf = linspline.blur(pdf, blur_halfwidth)\n\n  # Resample the blurred PDF to match the new time points\n  resampled_w = resample(tq, t, blurred_pdf)\n\n  return resampled_w\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert the histogram into a PDF.\n  w_pdf = weight_to_pdf(t, w)\n  # Blur the PDF.\n  w_blurred = linspline.blur_pdf(w_pdf, blur_halfwidth)\n  # Resample the blurred PDF.\n  w_resampled = resample(tq, t, w_blurred)\n  return w_resampled\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Compute the PDF and CDF for each weight vector.\n  w_pdf = weight_to_pdf(t, w)\n  w_cdf = integrate_weights(w)\n\n  # Blur the CDF.\n  w_cdf_blurred = blur_cdf(w_cdf, blur_halfwidth)\n\n  # Convert the blurred CDF back to a PDF.\n  w_pdf_blurred = math.safe_div(w_pdf, w_cdf_blurred)\n\n  # Resample the blurred PDF to match the query time points.\n  w_resampled = resample(tq, t, w_pdf_blurred, use_avg=True)\n\n  return w_resampled\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert the histogram to a PDF\n  pdf = weight_to_pdf(t, w)\n\n  # Blur the PDF\n  pdf_blur = linspline.blur(pdf, blur_halfwidth)\n\n  # Resample the PDF to the new time points\n  wq = resample(tq, t, pdf_blur, use_avg=True)\n\n  return wq\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert to numpy arrays\n  tq = np.array(tq)\n  t = np.array(t)\n  w = np.array(w)\n\n  # Compute the cumulative sum of the weights\n  cw = np.cumsum(w)\n\n  # Compute the PDF and CDF for each weight vector\n  pdf = w / np.diff(t)\n  cdf = integrate_weights(pdf)\n\n  # Interpolate into the inverse CDF\n  t_new = linspline.interp(cdf, t, tq)\n\n  # Convert the new time points back into PDF and CDF\n  pdf_new = weight_to_pdf(t_new, w)\n  cdf_new = integrate_weights(pdf_new)\n\n  # Compute the blurred CDF\n  cdf_blur = math.gaussian_filter1d(cdf_new, blur_halfwidth)\n\n  # Interpolate back into the PDF\n  pdf_blur = linspline.interp(cdf_blur, t_new, t)\n\n  # Convert back into weights\n  w_blur = pdf_to_weight(t, pdf_blur)\n\n  return w_blur"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Check for valid input arguments\n  utils.assert_valid_stepfun(t, w)\n\n  # Convert to numpy arrays\n  t = np.array(t)\n  w = np.array(w)\n  tq = np.array(tq)\n\n  # Compute the PDF and CDF for each weight vector.\n  w_pdf = weight_to_pdf(t, w)\n  w_cdf = integrate_weights(w)\n\n  # Blur the CDF and PDF\n  w_cdf_blur = linspline.blur_and_resample(t, w_cdf, blur_halfwidth)\n  w_pdf_blur = linspline.blur_and_resample(t, w_pdf, blur_halfwidth)\n\n  # Compute the blurred PDF and CDF\n  w_pdf_blur = w_pdf_blur / np.sum(w_pdf_blur, axis=-1, keepdims=True)\n  w_cdf_blur = integrate_weights(w_pdf_blur)\n\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(tq, w_cdf_blur, t, utils.device_is_tpu())\n\n  # Resample the PDF\n  w_pdf_blur_resampled = resample(t_new, t, w_pdf_blur)\n\n  # Return the resampled weights\n  return w_pdf_blur_resampled\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Convert the vectors to homogeneous coordinates\n  homogeneous_vectors = to_homogeneous(vectors)\n\n  # Apply the transformation to the homogeneous coordinates\n  homogeneous_transformed_vectors = matmul(transform, homogeneous_vectors)\n\n  # Convert the vectors back to non-homogeneous coordinates\n  transformed_vectors = from_homogeneous(homogeneous_transformed_vectors)\n\n  return transformed_vectors\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Convert the points to homogeneous coordinates\n  h_vectors = to_homogeneous(vectors)\n\n  # Apply the transformation to the points\n  h_transformed = matmul(transform, h_vectors)\n\n  # Convert the transformed points back to non-homogeneous coordinates\n  transformed = from_homogeneous(h_transformed)\n\n  return transformed\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Add a homogeneous coordinate to the vectors.\n  vectors = to_homogeneous(vectors)\n\n  # Transform the vectors.\n  vectors = matmul(transform, vectors)\n\n  # Remove the homogeneous coordinate from the vectors.\n  vectors = from_homogeneous(vectors)\n\n  return vectors\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Add a homogeneous coordinate to each point.\n  homogeneous_vectors = to_homogeneous(vectors)\n\n  # Transform the points.\n  transformed_vectors = matmul(transform, homogeneous_vectors)\n\n  # Return the transformed points without the homogeneous coordinate.\n  return from_homogeneous(transformed_vectors)\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # TODO: This is a bit of a hack. It would be better to use the jax.ops.segment_sum function.\n\n  # TODO: This is a bit of a hack. It would be better to use the jax.ops.segment_sum function.\n\n  # TODO: This is a bit of a hack. It would be better to use the jax.ops.segment_sum function.\n\n  # TODO: This is a bit of a hack. It would be better to use the jax.ops.segment_sum function.\n\n  # TODO: This is a bit of a hack. It would be better to use the jax.ops.segment_sum function.\n\n  # TODO: This is a bit of a hack. It would be better to use the jax.ops.segment_sum function.\n\n  # TODO: This is a bit of a hack. It would be better to use the jax.ops.segment_sum function.\n\n  # TODO: This is a bit of a hack. It would be better to use the jax.ops.segment_sum function.\n\n  # TODO: This is a bit of a hack. It would be better to use the jax.ops.segment_sum function.\n\n  # TODO: This is a bit of a hack. It would be better to use the jax.ops.segment_sum function.\n\n  # TODO: This is a bit of a hack. It would be better to use the jax.ops.segment_sum function.\n\n  # TODO: This is a bit of a hack. It would be better to use the jax.ops.segment_sum function.\n\n  # TODO: This is a bit of a hack. It would be better to use the jax.ops.segment_sum function.\n\n  # TODO: This is a bit of a hack. It would be better to use the jax.ops.segment_sum function.\n\n  # TODO: This is a bit of a hack. It would be better to use the jax.ops.segment_sum function.\n\n  # TODO: This is a bit of a hack. It would be better to use the jax.ops.segment_sum function.\n\n  #"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Apply the transformation to the vectors.\n  transformed_vectors = matmul(transform, to_homogeneous(vectors))\n\n  # Return the transformed points.\n  return from_homogeneous(transformed_vectors)\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Add homogeneous coordinate to vectors.\n  vectors = jnp.concatenate([vectors, jnp.ones_like(vectors[Ellipsis, :1])], axis=-1)\n\n  # Transform vectors.\n  vectors = matmul(transform, vectors)\n\n  # Remove homogeneous coordinate from vectors.\n  return vectors[Ellipsis, :-1] / vectors[Ellipsis, -1:]\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Convert the vectors to homogeneous coordinates\n  homo_vectors = to_homogeneous(vectors)\n\n  # Apply the transformation to the homogeneous coordinates\n  homo_result = matmul(transform, homo_vectors)\n\n  # Convert the result back to non-homogeneous coordinates\n  result = from_homogeneous(homo_result)\n\n  return result\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # (C+1,C+1)\n  transform_shape = transform.shape\n\n  # (C+1,C+1)\n  transform_t = jnp.transpose(transform)\n\n  # (*,C+1)\n  vectors_h = to_homogeneous(vectors)\n\n  # (*,C+1)\n  return from_homogeneous(matmul(matmul(transform_t, vectors_h), transform))\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # transform = jnp.moveaxis(transform, -1, 0)\n  # transform = jnp.moveaxis(transform, -1, 1)\n  # transform = transform[None, None, :, :]\n  # transform = jnp.tile(transform, [vectors.shape[0], vectors.shape[1], 1, 1])\n  # vectors = jnp.expand_dims(vectors, axis=-2)\n  # vectors = jnp.tile(vectors, [1, 1, transform.shape[1], 1])\n  # vectors = jnp.concatenate([vectors, jnp.ones_like(vectors[Ellipsis, :1])], axis=-1)\n  # vectors = jnp.matmul(vectors, transform)\n  # return vectors[Ellipsis, :-1] / vectors[Ellipsis, -1:]\n  return from_homogeneous(matmul(transform, to_homogeneous(vectors)))\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  vectors = jnp.concatenate([vectors, jnp.ones_like(vectors[Ellipsis, :1])], axis=-1)\n  return jnp.einsum('...ij,...i->...j', transform, vectors)\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Convert the input vectors to homogeneous vectors.\n  homogeneous_vectors = to_homogeneous(vectors)\n\n  # Transform the homogeneous vectors.\n  transformed_vectors = matmul(transform, homogeneous_vectors)\n\n  # Convert the transformed homogeneous vectors to non-homogeneous vectors.\n  return from_homogeneous(transformed_vectors)\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return from_homogeneous(matmul(transform, to_homogeneous(vectors)))\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Apply the transformation to the points.\n  transformed_vectors = matmul(transform, to_homogeneous(vectors))\n\n  # Return the transformed points.\n  return from_homogeneous(transformed_vectors)\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # TODO: Implement this function.\n  raise NotImplementedError\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Check that the input matrix is a homogeneous transform.\n  assert transform.shape[-1] == transform.shape[-2], \"The transform matrix must be square.\"\n  assert transform.shape[-1] == vectors.shape[-1] + 1, \"The transform matrix must have one more column than the dimensionality of the points.\"\n\n  # Add a column of ones to the vector array, and then multiply the transform by the array.\n  vectors_hom = jnp.concatenate([vectors, jnp.ones_like(vectors[Ellipsis, :1])], axis=-1)\n  vectors_hom_transformed = matmul(transform, vectors_hom[Ellipsis, None, :, :])[Ellipsis, 0, :]\n\n  return vectors_hom_transformed\n\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # TODO: Implement this.\n\n  # Compute the number of dimensions.\n  num_dimensions = vectors.shape[-1]\n\n  # Check if the dimensionality of the points is 3.\n  if num_dimensions != 3:\n    raise NotImplementedError(\"The dimensionality of the points must be 3.\")\n\n  # Check if the transformation matrix is homogeneous.\n  if transform.shape[-1] != transform.shape[-2]:\n    raise NotImplementedError(\"The transformation matrix must be homogeneous.\")\n\n  # Check if the dimensionality of the transformation matrix is 4.\n  if transform.shape[-1] != 4:\n    raise NotImplementedError(\"The dimensionality of the transformation matrix must be 4.\")\n\n  # Check if the number of dimensions of the transformation matrix matches the number of dimensions of the points.\n  if transform.shape[-1] != num_dimensions:\n    raise NotImplementedError(\"The dimensionality of the transformation matrix must match the dimensionality of the points.\")\n\n  # Check if the transformation matrix is invertible.\n  if not math.is_invertible(transform):\n    raise NotImplementedError(\"The transformation matrix must be invertible.\")\n\n  # Transform the points.\n  vectors_transformed = jnp.matmul(transform, to_homogeneous(vectors))\n\n  # Return the transformed points.\n  return from_homogeneous(vectors_transformed)\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # 1. Add a dimension to the transform matrix to make it homogeneous.\n  transform = to_homogeneous(transform)\n\n  # 2. Add a dimension to the input vectors to make them homogeneous.\n  vectors = to_homogeneous(vectors)\n\n  # 3. Apply the homogeneous transformation to the homogeneous vectors.\n  transformed_vectors = matmul(transform, vectors)\n\n  # 4. Remove the dimension added in step 2.\n  transformed_vectors = from_homogeneous(transformed_vectors)\n\n  return transformed_vectors\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Transform the vectors\n  transformed_vectors = to_homogeneous(vectors)\n  transformed_vectors = matmul(transform, transformed_vectors[Ellipsis, :, None])\n\n  return from_homogeneous(transformed_vectors)\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # The number of dimensions of the points.\n  num_dimensions = vectors.shape[-1]\n\n  # The shape of the input 'vectors' array.\n  input_shape = vectors.shape\n\n  # Reshape the input 'vectors' array into a 2D array, with an extra final dimension of size 1, so that we can use matrix multiplication to apply the transformation.\n  vectors = vectors.reshape(-1, num_dimensions)\n\n  # Add an extra dimension of size 1 to the end of the transformation matrix, so that we can use matrix multiplication to apply the transformation.\n  transform = transform[..., None]\n\n  # Transform the points.\n  transformed_vectors = matmul(transform, to_homogeneous(vectors).T).T\n\n  # Remove the extra final dimension from the transformed points, and reshape the array back to its original shape.\n  return from_homogeneous(transformed_vectors).reshape(input_shape)\n\n"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  utils.assert_valid_stepfun(t, vp)\n\n  # Interpolate into the step function to recover the interval value.\n  (i0, i1), ((vp, _),) = math.sorted_lookup(t, tp, (vp,), utils.device_is_tpu())\n\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(vp, axis=-1)\n  cw = integrate_weights(w)\n\n  # Interpolate into the inverse CDF.\n  if use_avg:\n    vp_new = math.sorted_interp(cw, t, vp, utils.device_is_tpu())\n    vp_new = math.sorted_interp(cw, t, vp_new, utils.device_is_tpu())\n  else:\n    vp_new = math.sorted_interp(cw, t, vp, utils.device_is_tpu())\n\n  return vp_new\n\n"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n\n  # Compute the weights of the resampling\n  tp_diff = tp[1:] - tp[:-1]\n  t_diff = t[1:] - t[:-1]\n  w = tp_diff / t_diff\n\n  # Compute the resampled values\n  if use_avg:\n    vp_resampled = w * vp\n    vp_resampled = jnp.sum(vp_resampled, axis=-1) / jnp.sum(w, axis=-1)\n  else:\n    vp_resampled = vp * w\n    vp_resampled = jnp.sum(vp_resampled, axis=-1)\n\n  return vp_resampled\n\n"}
{"namespace": "stepfun.resample", "completion": "  # TODO: Add a check to make sure that t is a subset of tp.\n  # TODO: Add a check to make sure that tp and vp have the same shape.\n\n  # TODO: Add a check to make sure that tp is sorted.\n\n  # TODO: Add a check to make sure that t is sorted.\n\n  # TODO: Add a check to make sure that tp and t have the same number of intervals.\n\n  # TODO: Add a check to make sure that tp and t do not have overlapping intervals.\n\n  # TODO: Add a check to make sure that tp and t do not have adjacent intervals with zero width.\n\n  # TODO: Add a check to make sure that tp and t do not have adjacent intervals with zero width.\n\n  # TODO: Add a check to make sure that tp and t do not have adjacent intervals with zero width.\n\n  # TODO: Add a check to make sure that tp and t do not have adjacent intervals with zero width.\n\n  # TODO: Add a check to make sure that tp and t do not have adjacent intervals with zero width.\n\n  # TODO: Add a check to make sure that tp and t do not have adjacent intervals with zero width.\n\n  # TODO: Add a check to make sure that tp and t do not have adjacent intervals with zero width.\n\n  # TODO: Add a check to make sure that tp and t do not have adjacent intervals with zero width.\n\n  # TODO: Add a check to make sure that tp and t do not have adjacent intervals with zero width.\n\n  # TODO: Add a check to make sure that tp and t do not have adjacent intervals with zero width.\n\n  # TODO: Add a check to make sure that tp and t do not have adjacent intervals with zero width.\n\n  # TODO: Add a check to make sure that tp and t do not have adjacent intervals with zero width.\n\n  # TODO: Add a check to make sure that tp and t do not have adjacent intervals with zero width.\n\n  # TODO: Add a check to make sure that tp and t do not have adjacent intervals with zero width.\n\n  # TODO: Add a check"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  utils.assert_valid_stepfun(t, vp)\n\n  # Get the widths of the intervals in tp\n  dt = jnp.diff(tp)\n\n  # Get the widths of the intervals in t\n  dt_new = jnp.diff(t)\n\n  # Get the cumulative sum of the widths of the intervals in tp\n  cw_tp = integrate_weights(jnp.ones_like(vp))\n\n  # Get the cumulative sum of the widths of the intervals in t\n  cw_t = integrate_weights(jnp.ones_like(vp))\n\n  # Get the indices of the intervals in tp that correspond to the intervals in t\n  i_t = jnp.searchsorted(tp, t, side='right')\n\n  # Get the indices of the intervals in tp that correspond to the intervals in t\n  i_tp = jnp.searchsorted(tp, t, side='left')\n\n  # Get the widths of the intervals in tp that correspond to the intervals in t\n  dt_t = dt[i_tp]\n\n  # Get the widths of the intervals in tp that correspond to the intervals in t\n  dt_tp = dt[i_t - 1]\n\n  # Get the indices of the intervals in tp that correspond to the intervals in t\n  i_tp = jnp.clip(i_tp, 0, tp.shape[-1] - 1)\n\n  # Get the indices of the intervals in tp that correspond to the intervals in t\n  i_t = jnp.clip(i_t, 0, tp.shape[-1] - 1)\n\n  # Get the cumulative sum of the widths of the intervals in tp that correspond to the intervals in t\n  cw_t = cw_tp[i_t]\n\n  # Get the cumulative sum of the widths of the intervals in tp that correspond to the intervals in t\n  cw_tp = cw_tp[i_tp]"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  t = t.squeeze()\n  tp = tp.squeeze()\n  vp = vp.squeeze()\n  t_new = jnp.zeros(t.shape)\n  for i in range(t.shape[0]):\n    if i == 0:\n      t_new[i] = vp[0]\n    elif i == t.shape[0] - 1:\n      t_new[i] = vp[-1]\n    else:\n      if use_avg:\n        t_new[i] = jnp.sum(vp[jnp.logical_and(tp[j] >= t[i - 1], tp[j] < t[i])] * (tp[j] - tp[j - 1])) / (t[i] - t[i - 1])\n      else:\n        t_new[i] = jnp.sum(vp[jnp.logical_and(tp[j] >= t[i - 1], tp[j] < t[i])])\n  return t_new\n\n"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n\n  # We will use the midpoints of the intervals in tp to interpolate into the values of the original step function.\n  tm = (tp[Ellipsis, 1:] + tp[Ellipsis, :-1]) / 2\n  # We will use the widths of the intervals in tp to weight the values of the original step function.\n  dw = tp[Ellipsis, 1:] - tp[Ellipsis, :-1]\n\n  # We will use the midpoints of the intervals in t to interpolate into the values of the original step function.\n  tq = (t[Ellipsis, 1:] + t[Ellipsis, :-1]) / 2\n  # We will use the widths of the intervals in t to weight the values of the original step function.\n  dt = t[Ellipsis, 1:] - t[Ellipsis, :-1]\n\n  # We will use the widths of the intervals in tp to weight the values of the original step function.\n  dw = jnp.where(dw == 0, 1, dw)\n\n  # We will use the widths of the intervals in t to weight the values of the original step function.\n  dt = jnp.where(dt == 0, 1, dt)\n\n  # We will use the midpoints of the intervals in tp to interpolate into the values of the original step function.\n  vq = jnp.vectorize(jnp.interp, signature='(n),(m),(m)->(n)')(tq, tm, vp)\n\n  if use_avg:\n    # We will use the widths of the intervals in t to weight the values of the original step function.\n    vq = vq * dw\n    # We will use the widths of the intervals in t to weight the values of the original step function.\n    vq = vq / dt\n  else:\n    # We will use the widths of the intervals in t to weight the values of the original step function.\n    vq = vq"}
{"namespace": "stepfun.resample", "completion": "  # If use_avg is True, we return the average value of the resampled step function.\n  if use_avg:\n    # The width of each interval in t.\n    dt = jnp.diff(t)\n\n    # The width of each interval in tp.\n    dtp = jnp.diff(tp)\n\n    # The weight of each interval in tp.\n    wtp = dtp / jnp.sum(dtp)\n\n    # The weight of each interval in t.\n    wt = dt / jnp.sum(dt)\n\n    # The weighted average of the resampled step function.\n    return jnp.sum(wtp * vp, axis=-1) * jnp.sum(wt) / jnp.sum(wt * wtp)\n\n  # If use_avg is False, we return the sum of the resampled step function.\n  else:\n    # The width of each interval in t.\n    dt = jnp.diff(t)\n\n    # The width of each interval in tp.\n    dtp = jnp.diff(tp)\n\n    # The weight of each interval in tp.\n    wtp = dtp / jnp.sum(dtp)\n\n    # The weight of each interval in t.\n    wt = dt / jnp.sum(dt)\n\n    # The sum of the resampled step function.\n    return jnp.sum(wtp * vp, axis=-1) * jnp.sum(wt)\n\n"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  utils.assert_valid_stepfun(t, None)\n  t = jnp.array(t)\n  tp = jnp.array(tp)\n  vp = jnp.array(vp)\n\n  # Compute the width of each interval in t.\n  dt = jnp.diff(t)\n\n  # Compute the width of each interval in tp.\n  dtp = jnp.diff(tp)\n\n  # Compute the weight of each interval in tp.\n  wp = jnp.divide(dtp, dt)\n\n  # Compute the cumulative sum of wp.\n  wp_cumsum = jnp.cumsum(wp)\n\n  # Compute the cumulative sum of vp.\n  vp_cumsum = jnp.cumsum(vp)\n\n  # Compute the weighted average of vp at the new intervals defined by t.\n  if use_avg:\n    vp_new = jnp.divide(vp_cumsum[Ellipsis, :-1], wp_cumsum[Ellipsis, :-1])\n  else:\n    vp_new = vp_cumsum[Ellipsis, :-1]\n\n  return vp_new\n\n"}
{"namespace": "stepfun.resample", "completion": "  # Find the indices of the intervals that the resampling points belong to.\n  i = math.searchsorted(tp, t, side='right') - 1\n  # Compute the width of each interval.\n  w = tp[i + 1] - tp[i]\n  # Compute the values of the resampled step function.\n  if use_avg:\n    v = (vp[i] * w + vp[i + 1] * w) / (w + w)\n  else:\n    v = vp[i] * w + vp[i + 1] * w\n  return v\n\n"}
{"namespace": "stepfun.resample", "completion": "  # Check if the input tensors are valid.\n  utils.assert_valid_stepfun(tp, vp)\n  utils.assert_valid_stepfun(t, vp)\n\n  # Compute the new values of the step function.\n  if use_avg:\n    # Compute the width of each interval in t.\n    dt = jnp.diff(t)\n    # Compute the cumulative sum of the widths of the intervals in t.\n    cdt = jnp.cumsum(dt)\n    # Compute the width of each interval in tp.\n    dtp = jnp.diff(tp)\n    # Compute the cumulative sum of the widths of the intervals in tp.\n    cdtp = jnp.cumsum(dtp)\n    # Compute the width of each interval in the resampled step function.\n    dw = jnp.diff(cdt)\n    # Compute the cumulative sum of the widths of the intervals in the resampled step function.\n    cdw = jnp.cumsum(dw)\n    # Compute the values of the resampled step function.\n    v = vp * dtp\n    v = jnp.cumsum(v)\n    v = v / dw\n    v = v - v[Ellipsis, 0][:, None]\n    v = v / cdw\n  else:\n    # Compute the values of the resampled step function.\n    v = jnp.interp(cdt, cdtp, vp)\n\n  return v\n\n"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  utils.assert_valid_stepfun(t, vp)\n\n  # If the new time points are the same as the original ones, return the original values.\n  if jnp.allclose(t, tp):\n    return vp\n\n  # If the new time points are outside the original ones, return 0.\n  if jnp.any(t < tp[0]) or jnp.any(t > tp[-1]):\n    return jnp.zeros_like(vp)\n\n  # If the new time points are the same as the original ones, return the original values.\n  if jnp.allclose(t, tp):\n    return vp\n\n  # If the new time points are outside the original ones, return 0.\n  if jnp.any(t < tp[0]) or jnp.any(t > tp[-1]):\n    return jnp.zeros_like(vp)\n\n  # Compute the width of each interval in the new time points.\n  dt = jnp.diff(t)\n\n  # Compute the width of each interval in the original time points.\n  dtp = jnp.diff(tp)\n\n  # Compute the indices of the original time points that are inside the new time points.\n  idx = jnp.where(jnp.logical_and(tp[1:] > t[0], tp[:-1] < t[-1]))[0]\n\n  # Compute the indices of the new time points that are inside the original time points.\n  idxt = jnp.where(jnp.logical_and(t[1:] > tp[0], t[:-1] < tp[-1]))[0]\n\n  # If the indices of the new time points that are inside the original time points are empty, return 0.\n  if len(idxt) == 0:\n    return jnp.zeros_like(vp)\n\n  # If the indices of the original time points that are inside the new time points are empty, return 0."}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  utils.assert_valid_stepfun(t, vp)\n\n  # Compute the weighted percentiles of the original step function.\n  wp = weighted_percentile(tp, vp, ps=np.arange(0, 101, 1))\n\n  # Compute the weighted percentiles of the new step function.\n  wq = weighted_percentile(t, vp, ps=np.arange(0, 101, 1))\n\n  # Compute the loss between the two step functions.\n  loss = lossfun_distortion(wp, wq)\n\n  # Compute the gradient of the loss.\n  grad_loss = jax.grad(loss)\n\n  # Compute the optimal weights to minimize the loss.\n  wq_opt = jax.scipy.optimize.minimize_scalar(\n      lambda x: grad_loss(x), bounds=(0, 1), method='bounded'\n  ).x\n\n  # Compute the optimal values of the resampled step function.\n  if use_avg:\n    vq_opt = wq_opt * vp\n  else:\n    vq_opt = jnp.cumsum(vp) * wq_opt\n\n  return vq_opt\n\n"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  utils.assert_valid_stepfun(t, None)\n\n  # The resampled values of the step function at the new intervals defined by t.\n  vp_resampled = jnp.zeros(t.shape)\n\n  # The indices of the new intervals defined by t.\n  ti = jnp.searchsorted(tp, t)\n\n  # The indices of the new intervals defined by t, shifted by -1.\n  tii = ti - 1\n\n  # The indices of the new intervals defined by t, shifted by +1.\n  tii1 = ti + 1\n\n  # The indices of the new intervals defined by t, shifted by +2.\n  tii2 = ti + 2\n\n  # The indices of the new intervals defined by t, shifted by -2.\n  tii2m = ti - 2\n\n  # The indices of the new intervals defined by t, shifted by -3.\n  tii3m = ti - 3\n\n  # The indices of the new intervals defined by t, shifted by +3.\n  tii3 = ti + 3\n\n  # The indices of the new intervals defined by t, shifted by -4.\n  tii4m = ti - 4\n\n  # The indices of the new intervals defined by t, shifted by +4.\n  tii4 = ti + 4\n\n  # The width of each new interval defined by t.\n  dt = jnp.diff(t)\n\n  # The width of each new interval defined by t, shifted by +1.\n  dt1 = dt[Ellipsis, 1:]\n\n  # The width of each new interval defined by t, shifted by -1.\n  dtm1 = dt[Ellipsis, :-1]\n\n  # The width of each new interval defined by t, shifted by +2.\n  dt2 = dt[Ellipsis, 2:]\n\n  # The width of each new interval defined by t, shifted by -2.\n  dtm2"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n\n  # If the original step function is defined by a single point, the resampled step function is also defined by a single point.\n  if tp.shape[-1] == 1:\n    v = vp\n\n  # If the original step function is defined by multiple points, the resampled step function is defined by the average value of the original step function within each interval in `t`.\n  else:\n    # The width of each interval in `t`.\n    dt = jnp.diff(t)\n\n    # The width of each interval in `tp`.\n    dtp = jnp.diff(tp)\n\n    # The number of intervals in `t`.\n    nt = t.shape[-1]\n\n    # The number of intervals in `tp`.\n    ntp = tp.shape[-1]\n\n    # The index of the last interval in `t`.\n    nt_1 = nt - 1\n\n    # The index of the last interval in `tp`.\n    ntp_1 = ntp - 1\n\n    # The index of the first interval in `t`.\n    nt_0 = 0\n\n    # The index of the first interval in `tp`.\n    ntp_0 = 0\n\n    # The number of intervals in the overlap between `t` and `tp`.\n    nt_overlap = ntp_1 - nt_0 + 1\n\n    # The number of intervals in the overlap between `t` and `tp`.\n    ntp_overlap = nt_1 - ntp_0 + 1\n\n    # The number of intervals in the non-overlap between `t` and `tp`.\n    nt_nonoverlap = nt - nt_overlap\n\n    # The number of intervals in the non-overlap between `t` and `tp`.\n    ntp_nonoverlap = ntp - ntp_overlap\n\n    # The indices of the intervals in `t` that are not in the overlap with `tp`.\n    nt_nonoverlap_indices = jnp.arange"}
{"namespace": "stepfun.resample", "completion": "  # utils.assert_valid_stepfun(t, w)\n  # utils.assert_valid_stepfun(tp, vp)\n\n  # # Check that the step function is valid.\n  # assert jnp.all(jnp.diff(tp) > 0), 'tp must be strictly increasing.'\n  # assert jnp.all(jnp.diff(t) > 0), 't must be strictly increasing.'\n\n  # # Check that tp is contained in [t[0], t[-1]].\n  # assert tp[0] >= t[0] and tp[-1] <= t[-1], 'tp must be contained in [t[0], t[-1]]'\n\n  # # Check that the step function is non-decreasing.\n  # assert jnp.all(jnp.diff(vp) >= 0), 'vp must be non-decreasing.'\n\n  # # Check that the step function is non-negative.\n  # assert jnp.all(vp >= 0), 'vp must be non-negative.'\n\n  # # Check that the step function is normalized.\n  # assert jnp.allclose(jnp.sum(vp), 1), 'vp must sum to 1.'\n\n  # # Check that t is sorted.\n  # assert jnp.all(jnp.diff(t) >= 0), 't must be strictly increasing.'\n\n  # # Check that t is contained in [tp[0], tp[-1]].\n  # assert t[0] >= tp[0] and t[-1] <= tp[-1], 't must be contained in [tp[0], tp[-1]]'\n\n  # # Check that the step function is non-decreasing.\n  # assert jnp.all(jnp.diff(t) >= 0), 't must be non-decreasing.'\n\n  # # Check that the step function is non-negative.\n  # assert jnp.all(t >= 0), 't must be non-negative.'\n\n  # # Check that the step function is normalized.\n "}
{"namespace": "stepfun.resample", "completion": "  # Checking the input arguments.\n  if not isinstance(t, jnp.ndarray):\n    raise TypeError('Input argument `t` must be a JAX tensor.')\n  if not isinstance(tp, jnp.ndarray):\n    raise TypeError('Input argument `tp` must be a JAX tensor.')\n  if not isinstance(vp, jnp.ndarray):\n    raise TypeError('Input argument `vp` must be a JAX tensor.')\n  if not isinstance(use_avg, bool):\n    raise TypeError('Input argument `use_avg` must be a bool.')\n\n  # Resampling.\n  t = jnp.array(t)\n  tp = jnp.array(tp)\n  vp = jnp.array(vp)\n  if use_avg:\n    # Resampling with averaging.\n    # The number of intervals in t.\n    num_t = t.shape[-1]\n    # The number of intervals in tp.\n    num_tp = tp.shape[-1]\n    # The width of each interval in t.\n    dt = jnp.diff(t)\n    # The width of each interval in tp.\n    dtp = jnp.diff(tp)\n    # The number of samples in each interval in tp.\n    ns = jnp.sum(dtp / dtp, axis=-1)\n    # The number of samples in each interval in t.\n    nt = jnp.sum(dt / dt, axis=-1)\n    # The width of each interval in t divided by the number of samples in each interval in t.\n    wt = dt / nt\n    # The width of each interval in tp divided by the number of samples in each interval in tp.\n    wtp = dtp / ns\n    # The weighted average of the values in each interval in tp.\n    vtp = jnp.sum(wtp[Ellipsis, :, None] * vp, axis=-1)\n    # The weighted average of the values in each interval in t.\n    vt = jnp.sum(wt"}
{"namespace": "stepfun.resample", "completion": "  # Check the validity of the inputs.\n  assert len(t.shape) == 1\n  assert len(tp.shape) == 1\n  assert len(vp.shape) == 1\n  assert tp.shape[0] == vp.shape[0]\n  assert tp.shape[0] >= 2\n  assert tp.shape[0] == t.shape[0] + 1\n  assert t.shape[0] == 1 or t.shape[0] == tp.shape[0] - 1\n\n  # Compute the width of each interval in tp.\n  dt = tp[1:] - tp[:-1]\n\n  # Compute the width of each interval in t.\n  dt_new = t[1:] - t[:-1]\n\n  # Compute the weight of each interval in tp.\n  w = dt / dt.sum()\n\n  # Compute the weight of each interval in t.\n  w_new = dt_new / dt_new.sum()\n\n  # Compute the weighted average of the values of the step function at the original time points.\n  vp_avg = (vp[:-1] * dt).sum() / dt.sum()\n\n  # Resample the step function.\n  if use_avg:\n    vp_new = jnp.interp(t, tp, vp_avg * jnp.ones_like(vp))\n  else:\n    vp_new = jnp.interp(t, tp, vp * w)\n\n  # Resample the step function.\n  return vp_new * w_new\n\n"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n\n  # Compute the weighted percentile of each interval in tp.\n  wtp = weighted_percentile(tp, vp, [0, 50, 100])\n\n  # Compute the indices of the intervals in tp that fall into each interval in t.\n  # If an interval in t falls between two intervals in tp, then it is assigned to the interval in tp that contains its midpoint.\n  # If an interval in t falls outside of all intervals in tp, then it is assigned to the interval in tp that contains its left endpoint.\n  # If an interval in t falls outside of all intervals in tp, then it is assigned to the interval in tp that contains its right endpoint.\n  t_left = t[Ellipsis, :-1]\n  t_right = t[Ellipsis, 1:]\n  t_mid = (t_left + t_right) / 2\n  t_left_idx = jnp.searchsorted(tp, t_left, side='right') - 1\n  t_right_idx = jnp.searchsorted(tp, t_right, side='right')\n  t_mid_idx = jnp.searchsorted(tp, t_mid, side='right') - 1\n  t_left_idx = jnp.maximum(t_left_idx, 0)\n  t_right_idx = jnp.minimum(t_right_idx, tp.shape[-1] - 1)\n  t_mid_idx = jnp.maximum(t_mid_idx, 0)\n  t_mid_idx = jnp.minimum(t_mid_idx, tp.shape[-1] - 1)\n  t_idx = jnp.where(t_left_idx == t_right_idx, t_mid_idx, jnp.where(t_left_idx < t_right_idx, t_left_idx, t_right_idx))\n\n  # Compute the width of each interval in t.\n  dt = jnp.diff"}
{"namespace": "stepfun.resample", "completion": "  # Check if the input tensors are valid.\n  utils.assert_valid_stepfun(tp, vp)\n  utils.assert_valid_stepfun(t, vp)\n\n  # Get the width of each interval in t.\n  dt = jnp.diff(t)\n\n  # Get the width of each interval in tp.\n  dtp = jnp.diff(tp)\n\n  # Get the index of the interval in tp that is closest to each point in t.\n  # Note that the index is the index of the interval in tp that ends at the point in t.\n  ind = jnp.argmin(jnp.abs(tp[Ellipsis, None] - t[Ellipsis, :]), axis=-1)\n\n  # Get the width of each interval in tp that is closest to each point in t.\n  dt_ind = dtp[Ellipsis, ind]\n\n  # Get the value of each interval in tp that is closest to each point in t.\n  vp_ind = vp[Ellipsis, ind]\n\n  # Get the resampled value of each interval in t.\n  if use_avg:\n    # Weighted average.\n    v_resampled = vp_ind / dt_ind\n  else:\n    # Sum.\n    v_resampled = vp_ind * dt_ind\n\n  return v_resampled\n\n"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  utils.assert_valid_stepfun(t, vp)\n\n  # First, we compute the indices of the intervals in which each value in tp lies.\n  # The indices are then used to compute the resampled values.\n  tp_indices = jnp.searchsorted(t, tp)\n  vp_resampled = jnp.zeros(t.shape[:-1] + (tp.shape[-1],))\n\n  # If use_avg is True, we compute the weighted average of the values in vp for each interval in t.\n  if use_avg:\n    # The width of each interval in t.\n    t_width = jnp.diff(t, axis=-1)\n    # The width of each interval in tp.\n    tp_width = jnp.diff(tp, axis=-1)\n    # The indices of the intervals in which each value in tp lies.\n    tp_indices = jnp.searchsorted(t, tp)\n\n    # We compute the weighted average of the values in vp for each interval in t.\n    for i in range(t.shape[-1]):\n      vp_resampled = vp_resampled.at[Ellipsis, i].set(jnp.sum(vp * tp_width / t_width[Ellipsis, i], axis=-1))\n\n  # If use_avg is False, we simply sum the values in vp for each interval in t.\n  else:\n    for i in range(t.shape[-1]):\n      vp_resampled = vp_resampled.at[Ellipsis, i].set(jnp.sum(vp[Ellipsis, tp_indices[Ellipsis, i]], axis=-1))\n\n  return vp_resampled\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance.\n  scaled_mean = mean * (2 ** jnp.arange(min_deg, max_deg))\n  scaled_var = var * (2 ** (2 * jnp.arange(min_deg, max_deg)))\n\n  # Concatenate the scaled mean and variance.\n  concat_mean_var = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n\n  # Apply the sinusoidal encoding.\n  encoded_vars = math.pos_enc(concat_mean_var)\n\n  return encoded_vars\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # scale the mean and variance\n  scaled_mean = jnp.exp(math.log(2) * (min_deg - 1) / (max_deg - min_deg) +\n                        math.log(mean))\n  scaled_var = jnp.exp(math.log(2) * (min_deg - 1) / (max_deg - min_deg) +\n                       math.log(var))\n\n  # concatenate the scaled mean and variance\n  scaled_coords = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n\n  # apply sinusoidal encoding\n  encoded_coords = math.pos_enc(scaled_coords, min_deg, max_deg)\n\n  return encoded_coords\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # scale the mean and variance\n  scaled_mean = mean * (2**min_deg)\n  scaled_var = var * ((2**min_deg)**2)\n\n  # concatenate the scaled mean and variance\n  concat_mean_var = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n\n  # apply sinusoidal encoding\n  pos_enc = jnp.concatenate(\n      [jnp.sin(concat_mean_var), jnp.cos(concat_mean_var)], axis=-1)\n\n  # scale the encoding\n  scaled_pos_enc = pos_enc * (2**(max_deg - min_deg))\n\n  return scaled_pos_enc\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # scale the mean and variance\n  scaled_mean = jnp.sqrt(2**min_deg) * mean\n  scaled_var = jnp.sqrt(2**min_deg) * jnp.sqrt(var)\n\n  # concatenate the scaled mean and variance\n  scaled_mean_and_var = jnp.concatenate((scaled_mean, scaled_var), axis=-1)\n\n  # apply sinusoidal encoding\n  encoded_mean_and_var = math.positional_encoding(scaled_mean_and_var,\n                                                  max_deg - min_deg)\n\n  return encoded_mean_and_var\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance of the input coordinates.\n  mean_scaled = mean * 2**(min_deg / 2)\n  var_scaled = var * (2**(min_deg / 2))**2\n\n  # Concatenate the scaled mean and variance.\n  concat_scaled = jnp.concatenate((mean_scaled, var_scaled), axis=1)\n\n  # Apply a sinusoidal encoding to the concatenated scaled mean and variance.\n  encoded = math.positional_encoding(concat_scaled, min_deg, max_deg)\n\n  return encoded\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # scale the mean and variance\n  scaled_mean = mean * 2**jnp.arange(min_deg, max_deg)\n  scaled_var = var * 2**(2*jnp.arange(min_deg, max_deg))\n  # concatenate the scaled mean and variance\n  scaled_coords = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n  # apply sinusoidal encoding\n  encoded_coords = math.pos_enc(scaled_coords)\n  return encoded_coords\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance to be in the range [2**min_deg, 2**max_deg]\n  scaled_mean = jnp.exp(min_deg * jnp.log(2) + (max_deg - min_deg) * mean / jnp.pi)\n  scaled_var = jnp.exp(min_deg * jnp.log(2) + (max_deg - min_deg) * var / jnp.pi)\n\n  # Concatenate the scaled mean and variance\n  scaled_coords = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n\n  # Apply a sinusoidal encoding to the concatenated scaled mean and variance\n  return math.pos_enc(scaled_coords, 2, 10, 10)\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # TODO: Add type checking for input arguments.\n\n  # Scale the mean and variance of the input coordinates.\n  mean_scaled = jnp.exp(0.5 * var) * mean\n  var_scaled = jnp.exp(var) - 1\n\n  # Concatenate the scaled mean and variance.\n  mean_var_scaled = jnp.concatenate([mean_scaled, var_scaled], axis=-1)\n\n  # Apply sinusoidal encoding.\n  encoding = math.pos_enc(mean_var_scaled, min_deg, max_deg)\n\n  return encoding\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance to the desired range.\n  mean_scaled = jnp.clip(mean, 0, math.pi) * (max_deg - min_deg) / math.pi\n  var_scaled = jnp.clip(var, 0, math.pi) * (max_deg - min_deg) / math.pi\n  # Encode the scaled mean and variance.\n  encoded = jnp.concatenate([jnp.sin(mean_scaled), jnp.cos(mean_scaled),\n                             jnp.sin(var_scaled), jnp.cos(var_scaled)])\n  # Scale the encoding to the desired range.\n  encoded = encoded * (max_deg - min_deg) / 4\n  return encoded\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # scale the mean and variance\n  mean_scaled = mean * (2 ** min_deg)\n  var_scaled = var * (2 ** min_deg)\n\n  # concatenate the scaled mean and variance\n  concat_mean_var = jnp.concatenate((mean_scaled, var_scaled), axis=-1)\n\n  # apply the sinusoidal encoding\n  encoded_variables = math.pos_enc(concat_mean_var, min_deg, max_deg)\n\n  return encoded_variables\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance to the range [0, 2pi]\n  mean_scaled = jnp.mod(mean, 2 * jnp.pi)\n  var_scaled = jnp.mod(var, 2 * jnp.pi)\n\n  # Compute the scaling factor for each dimension\n  scale_factor = 2 ** jnp.linspace(min_deg, max_deg, mean.shape[-1])\n\n  # Scale the mean and variance by the scaling factor\n  mean_scaled_by_factor = mean_scaled * scale_factor\n  var_scaled_by_factor = var_scaled * scale_factor ** 2\n\n  # Concatenate the scaled mean and variance\n  scaled_mean_and_var = jnp.concatenate([mean_scaled_by_factor, var_scaled_by_factor], axis=-1)\n\n  # Encode the scaled mean and variance\n  encoded_variables = math.pos_enc(scaled_mean_and_var)\n\n  return encoded_variables\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance to the range of the degrees of the sinusoidal functions.\n  scaled_mean = jnp.exp(jnp.log(min_deg) + (jnp.log(max_deg) - jnp.log(min_deg)) * mean)\n  scaled_var = jnp.exp(jnp.log(min_deg) + (jnp.log(max_deg) - jnp.log(min_deg)) * var)\n  # Construct the sinusoidal encoding.\n  encoded_mean = jnp.concatenate([jnp.sin(scaled_mean), jnp.cos(scaled_mean)], axis=-1)\n  encoded_var = jnp.concatenate([jnp.sin(scaled_var), jnp.cos(scaled_var)], axis=-1)\n  # Concatenate the mean and variance to the encoded values.\n  encoded_mean = jnp.concatenate([encoded_mean, scaled_mean], axis=-1)\n  encoded_var = jnp.concatenate([encoded_var, scaled_var], axis=-1)\n  return encoded_mean, encoded_var\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance of the coordinates\n  mean_scaled = mean * jnp.power(2, jnp.linspace(min_deg, max_deg, max_deg - min_deg))\n  var_scaled = var * jnp.power(2, 2 * jnp.linspace(min_deg, max_deg, max_deg - min_deg))\n\n  # Concatenate the scaled mean and variance\n  concat_mean_var = jnp.concatenate([mean_scaled, var_scaled], axis=-1)\n\n  # Apply sinusoidal encoding\n  return math.pos_enc(concat_mean_var)\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance to the range [min_deg, max_deg]\n  # Note: this is a linear transformation, and it does not change the\n  # distribution of the variables.\n  scaled_mean = (mean - jnp.min(mean)) / (jnp.max(mean) - jnp.min(mean))\n  scaled_mean = scaled_mean * (max_deg - min_deg) + min_deg\n  scaled_var = var / (jnp.max(mean) - jnp.min(mean))\n  scaled_var = scaled_var * (max_deg - min_deg)\n\n  # Encode the scaled mean and variance with sinusoidal functions\n  encoded_mean = math.pos_enc(scaled_mean, scaled_var, min_deg, max_deg)\n\n  return encoded_mean\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance\n  scaled_mean = jnp.power(2, min_deg) * mean\n  scaled_var = jnp.power(2, min_deg + 1) * var\n\n  # Concatenate the scaled mean and variance\n  concat_input = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n\n  # Get the degrees for the sinusoidal encoding\n  degrees = jnp.arange(min_deg, max_deg)\n\n  # Apply the sinusoidal encoding\n  encoded_input = math.pos_enc(concat_input, degrees)\n\n  return encoded_input\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance of the coordinates.\n  scaled_mean = jnp.power(2, jnp.linspace(min_deg, max_deg, max_deg - min_deg + 1)) * mean\n  scaled_var = jnp.power(2, jnp.linspace(min_deg, max_deg, max_deg - min_deg + 1)) * jnp.power(2, min_deg) * var\n\n  # Concatenate the scaled mean and variance.\n  scaled_coords = jnp.concatenate((scaled_mean, scaled_var), axis=-1)\n\n  # Apply sinusoidal encoding.\n  return math.pos_enc(scaled_coords)\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale mean and variance to be in range [2**min_deg, 2**max_deg]\n  min_scale = 2**min_deg\n  max_scale = 2**max_deg\n  mean = mean * (max_scale - min_scale) + min_scale\n  var = var * (max_scale - min_scale)\n\n  # Apply sinusoidal encoding\n  deg = jnp.arange(min_deg, max_deg)\n  deg = jnp.expand_dims(deg, 0)\n  deg = jnp.expand_dims(deg, 0)\n  deg = jnp.expand_dims(deg, 0)\n  deg = jnp.expand_dims(deg, 0)\n  deg = jnp.tile(deg, (mean.shape[0], mean.shape[1], mean.shape[2], 1))\n  deg = jnp.tile(deg, (1, 1, 1, mean.shape[-1]))\n  deg = jnp.expand_dims(deg, -1)\n  deg = jnp.tile(deg, (1, 1, 1, 1, 2))\n  deg = jnp.transpose(deg, (4, 0, 1, 2, 3))\n  sin_coords = jnp.sin(deg * mean)\n  cos_coords = jnp.cos(deg * mean)\n  encoded_coords = jnp.concatenate((sin_coords, cos_coords), axis=-1)\n\n  # Scale encoded coordinates to be in range [0, 1]\n  encoded_coords = encoded_coords * 0.5 + 0.5\n\n  return encoded_coords\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance\n  mean_scaled = mean * (2**jnp.linspace(min_deg, max_deg, max_deg - min_deg + 1))\n  var_scaled = var * (2**jnp.linspace(min_deg, max_deg, max_deg - min_deg + 1))**2\n\n  # Concatenate the scaled mean and variance\n  scaled_coords = jnp.concatenate((mean_scaled, var_scaled), axis=-1)\n\n  # Apply sinusoidal encoding\n  return math.pos_enc(scaled_coords)\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # scale the mean and variance\n  scaled_mean = mean * (2 ** jnp.arange(min_deg, max_deg))\n  scaled_var = var * (2 ** (2 * jnp.arange(min_deg, max_deg)))\n\n  # concatenate the scaled mean and variance\n  scaled_coords = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n\n  # apply sinusoidal encoding\n  return math.pos_enc(scaled_coords)\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance of the coordinates by powers of 2.\n  mean_scaled = jnp.power(2, mean)\n  var_scaled = jnp.power(2, var)\n\n  # Concatenate the scaled mean and variance.\n  scaled_coords = jnp.concatenate([mean_scaled, var_scaled], axis=-1)\n\n  # Apply the sinusoidal encoding.\n  scaled_coords_enc = math.positional_encoding(scaled_coords, min_deg, max_deg)\n\n  return scaled_coords_enc\n\n"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def integrated_dir_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning integrated directional encoding (IDE).\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting IDE.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Apply attenuation function using the von Mises-Fisher distribution\n    # concentration parameter, kappa.\n    sigma = 0.5 * ml"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def dir_enc_fn(xyz):\n    \"\"\"\n    Function returning directional encoding (DE).\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n\n    Returns:\n      An array with the resulting DE.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Split into real and imaginary parts and return\n    return jnp.concatenate([jnp.real(sph_harms), jnp.imag(sph_harms)], axis=-1)\n\n  return dir_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  def integrated_dir_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning integrated directional encoding (IDE).\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting IDE.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Apply attenuation function using the von Mises-Fisher distribution\n    # concentration parameter, kappa.\n    sigma = 0.5 * ml_array[1, :] * (ml_array[1, :] + 1)\n    ide = sph_harms * jnp.exp(-sigma * kappa_inv)\n\n    # Split into real and imaginary parts and return\n    return jnp.concatenate([jnp.real(ide), jnp.imag(ide)], axis=-1)\n\n  return integrated_dir_enc_fn\n\n"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def dir_enc_fn(xyz):\n    \"\"\"\n    Function returning the directional encoding of a 3D point (or points).\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Split into real and imaginary parts and return\n    return jnp.concatenate([jnp.real(sph_harms), jnp.imag(sph_harms)], axis=-1)\n\n  return dir_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Function returning directional encoding (IDE).\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting IDE.\n\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Apply attenuation function using the von Mises-Fisher distribution\n    # concentration parameter, kappa.\n    sigma = 0.5 * ml_array"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def dir_enc_fn(xyz):\n    \"\"\"\n    Function returning directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Split into real and imaginary parts and return\n    return jnp.concatenate([jnp.real(sph_harms), jnp.imag(sph_harms)], axis=-1)\n\n  return dir_enc_fn\n\n\n"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def directional_encoding_fn(xyz):\n    \"\"\"\n    Function returning directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Split into real and imaginary parts and return\n    return jnp.concatenate([jnp.real(sph_harms), jnp.imag(sph_harms)], axis=-1)\n\n  return directional_encoding_fn\n\n"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  def integrated_dir_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning integrated directional encoding (IDE).\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting IDE.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Apply attenuation function using the von Mises-Fisher distribution\n    # concentration parameter, kappa.\n    sigma = 0.5 * ml_array[1, :] * (ml_array[1, :] + 1)\n    ide = sph_harms * jnp.exp(-sigma * kappa_inv)\n\n    # Split into real and imaginary parts and return\n    return jnp.concatenate([jnp.real(ide), jnp.imag(ide)], axis=-1)\n\n  return integrated_dir_enc_fn\n\n"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def dir_enc_fn(xyz):\n    \"\"\"\n    Function that evaluates the directional encoding for given inputs.\n\n    Input-Output Arguments\n    :param xyz: 3D point (or points) as input.\n    :return: Directional encoding of the input 3D point (or points).\n\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Split into real and imaginary parts and return\n    return jnp.concatenate([jnp.real(sph_harms), jnp.imag(sph_harms)], axis=-1)\n\n  return dir_enc_fn\n\n"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Function returning directional encoding (DE).\n\n    Input-Output Arguments:\n    :param xyz: 3D point (or points) as input.\n    :param kappa_inv: Reciprocal of the concentration parameter of the von Mises-Fisher distribution.\n    :return: Directional encoding (DE) for the given input.\n\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z ** i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Apply attenuation function using the von Mises-Fisher distribution\n    # concentration parameter, kappa.\n    sigma = 0.5 * ml_"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Function that evaluates the directional encoding for given inputs.\n    :param xyz: 3D point (or points) to be encoded.\n    :param kappa_inv: Reciprocal of the concentration parameter of the von Mises-Fisher distribution.\n    :return: Directional encoding of the input point(s).\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z ** i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Apply attenuation function using the von Mises-Fisher distribution\n    # concentration parameter, kappa.\n    sigma = 0.5 * ml_array[1, :]"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  def dir_enc_fn(xyz):\n    \"\"\"\n    Function returning directional encoding (DE).\n\n    :param xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n    :return: An array with the resulting DE.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Split into real and imaginary parts and return\n    return jnp.concatenate([jnp.real(sph_harms), jnp.imag(sph_harms)], axis=-1)\n\n  return dir_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def dir_enc_fn(xyz):\n    \"\"\"\n    This function takes a 3D point (or points) as input and returns its directional encoding.\n\n    Input-Output Arguments\n    :param xyz: ndarray. A 3D point (or points) as input.\n    :return: ndarray. The directional encoding of the input point(s).\n    \"\"\"\n\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Split into real and imaginary parts and return\n    return jnp.concatenate([jnp.real(sph_harms), jnp.imag(sph_harms)], axis=-1)\n\n "}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def dir_enc_fn(xyz):\n    \"\"\"\n    Function returning directional encoding (IDE).\n\n    Input-Output Arguments\n    :param xyz: 3D point (or points) to be encoded.\n    :return: 3D directional encoding (or encodings) of the input point(s).\n\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z ** i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Split into real and imaginary parts and return\n    return jnp.concatenate([jnp.real(sph_harms), jnp.imag(sph_harms)], axis=-1)\n\n  return dir_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  def dir_enc_fn(xyz):\n    \"\"\"\n    Function returning directional encoding (DE).\n\n    Input-Output Arguments\n    :param xyz: 3D point (or points) as input.\n    :return: Directional encoding (DE) as output.\n\n    \"\"\"\n\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Split into real and imaginary parts and return\n    return jnp.concatenate([jnp.real(sph_harms), jnp.imag(sph_harms)], axis=-1)\n\n  return dir_enc_fn\n\n\n"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  def dir_enc_fn(xyz):\n\n    \"\"\"\n    Function returning directional encoding (DE).\n\n    Input-Output Arguments:\n    :param xyz: 3D point (or points) to be encoded.\n    :return: 2D array. The directional encoding of the input point (or points).\n\n    \"\"\"\n\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Split into real and imaginary parts and return\n    return jnp.concatenate([jnp.real(sph_harms), jnp.imag(sph_harms)], axis=-1)\n\n  return dir_enc_fn\n\n"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  ide_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz):\n    \"\"\"\n    A function that evaluates the directional encoding for given inputs.\n\n    Input-Output Arguments\n    :param xyz: Tensor. A 3D point (or points) as input.\n    :return: Tensor. The directional encoding for the given input.\n    \"\"\"\n    xyz = jnp.atleast_2d(xyz)\n    kappa_inv = jnp.ones(xyz.shape[0])\n    return ide_fn(xyz, kappa_inv)\n\n  return dir_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  def dir_enc_fn(xyz):\n    \"\"\"\n    Generates the directional encoding function based on the specified number of spherical harmonics degrees.\n\n    Input-Output Arguments\n    :param xyz: 3D Point (or points) to be encoded.\n    :return: 1D or 2D array. The directional encoding of the input 3D point (or points).\n\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z ** i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Split into real and imaginary parts and return\n    return jnp.concatenate([jnp.real(sph_harms), jnp.imag(sph_harms)], axis=-1)\n\n  return dir_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  def dir_enc_fn(xyz):\n    \"\"\"\n    Evaluates the directional encoding for the given inputs.\n\n    Input-Output Arguments\n    :param xyz: ndarray. A 3D point (or points) to be encoded.\n    :return: ndarray. The directional encoding of the input 3D point (or points).\n    \"\"\"\n    return generate_integrated_dir_enc_fn(deg_view)(xyz)\n\n  return dir_enc_fn\n\n"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  # Create a function for evaluating integrated directional encoding (IDE).\n  integrated_dir_enc_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz):\n    \"\"\"\n    Function that evaluates the directional encoding for given inputs.\n\n    Input-Output Arguments\n    :param xyz: 3D point (or points) as input.\n    :return: Directional encoding of the input 3D point (or points).\n    \"\"\"\n\n    # Generate a random number for the concentration parameter of the von Mises-Fisher distribution.\n    kappa_inv = jnp.random.uniform(low=0.0, high=1.0, size=(1,))\n\n    # Evaluate the integrated directional encoding (IDE).\n    ide = integrated_dir_enc_fn(xyz, kappa_inv)\n\n    return ide\n\n  return dir_enc_fn\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # print(lines)\n    # print(len(lines))\n    # print(len(lines[0]))\n    # print(len(lines[1]))\n    # print(len(lines[2]))\n    # print(len(lines[3]))\n    # print(len(lines[4]))\n    # print(len(lines[5]))\n    # print(len(lines[6]))\n    # print(len(lines[7]))\n    # print(len(lines[8]))\n    # print(len(lines[9]))\n    # print(len(lines[10]))\n    # print(len(lines[11]))\n    # print(len(lines[12]))\n    # print(len(lines[13]))\n    # print(len(lines[14]))\n    # print(len(lines[15]))\n    # print(len(lines[16]))\n    # print(len(lines[17]))\n    # print(len(lines[18]))\n    # print(len(lines[19]))\n    # print(len(lines[20]))\n    # print(len(lines[21]))\n    # print(len(lines[22]))\n    # print(len(lines[23]))\n    # print(len(lines[24]))\n    # print(len(lines[25]))\n    # print(len(lines[26]))\n    # print(len(lines[27]))\n    # print(len(lines[28]))\n    # print(len(lines[29]))\n    # print(len(lines[30]))\n    # print(len(lines[31]))\n    # print(len(lines[32]))\n    # print(len(lines[33]))\n    # print(len(lines[34]))\n    # print(len(lines[35]))\n    # print(len(lines[36]))\n    # print(len(lines[37]))\n    # print(len(lines[38]))\n    # print(len(lines[39]))\n    # print(len(lines[40]))"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # TODO: add support for xml\n    # TODO: add support for xml\n    # TODO: add support for xml\n\n    # TODO: add support for xml\n    # TODO: add support for xml\n    # TODO: add support for xml\n\n    # TODO: add support for xml\n    # TODO: add support for xml\n    # TODO: add support for xml\n\n    # TODO: add support for xml\n    # TODO: add support for xml\n    # TODO: add support for xml\n\n    # TODO: add support for xml\n    # TODO: add support for xml\n    # TODO: add support for xml\n\n    # TODO: add support for xml\n    # TODO: add support for xml\n    # TODO: add support for xml\n\n    # TODO: add support for xml\n    # TODO: add support for xml\n    # TODO: add support for xml\n\n    # TODO: add support for xml\n    # TODO: add support for xml\n    # TODO: add support for xml\n\n    # TODO: add support for xml\n    # TODO: add support for xml\n    # TODO: add support for xml\n\n    # TODO: add support for xml\n    # TODO: add support for xml\n    # TODO: add support for xml\n\n    # TODO: add support for xml\n    # TODO: add support for xml\n    # TODO: add support for xml\n\n    # TODO: add support for xml\n    # TODO: add support for xml\n    # TODO: add support for xml\n\n    # TODO: add support for xml\n    # TODO: add support for xml\n    # TODO: add support for xml\n\n    # TODO: add support for xml\n    # TODO: add support for xml\n    # TODO: add support for xml\n\n    # TODO: add support for xml\n    # TODO: add support for xml\n    # TODO: add support for xml\n\n    # TODO: add support for xml\n    # TODO: add support for xml\n    # TODO: add support for xml\n\n    # TODO: add support for xml\n    # TODO: add support for xml\n    # TODO: add support for xml\n\n    # TODO: add support for xml\n    # TODO: add support for xml\n    # TODO:"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # print(lines)\n    # print(len(lines))\n    # print(\"-------------------------------------------------------------\")\n    # print(lines)\n    # print(\"-------------------------------------------------------------\")\n    # print(len(lines))\n    # print(\"-------------------------------------------------------------\")\n    # print(lines)\n    # print(\"-------------------------------------------------------------\")\n    # print(len(lines))\n    # print(\"-------------------------------------------------------------\")\n    # print(lines)\n    # print(\"-------------------------------------------------------------\")\n    # print(len(lines))\n    # print(\"-------------------------------------------------------------\")\n    # print(lines)\n    # print(\"-------------------------------------------------------------\")\n    # print(len(lines))\n    # print(\"-------------------------------------------------------------\")\n    # print(lines)\n    # print(\"-------------------------------------------------------------\")\n    # print(len(lines))\n    # print(\"-------------------------------------------------------------\")\n    # print(lines)\n    # print(\"-------------------------------------------------------------\")\n    # print(len(lines))\n    # print(\"-------------------------------------------------------------\")\n    # print(lines)\n    # print(\"-------------------------------------------------------------\")\n    # print(len(lines))\n    # print(\"-------------------------------------------------------------\")\n    # print(lines)\n    # print(\"-------------------------------------------------------------\")\n    # print(len(lines))\n    # print(\"-------------------------------------------------------------\")\n    # print(lines)\n    # print(\"-------------------------------------------------------------\")\n    # print(len(lines))\n    # print(\"-------------------------------------------------------------\")\n    # print(lines)\n    # print(\"-------------------------------------------------------------\")\n    # print(len(lines))\n    # print(\"-------------------------------------------------------------\")\n    # print(lines)\n    # print(\"-------------------------------------------------------------\")\n    # print(len(lines))\n    # print(\"-------------------------------------------------------------\")\n    # print(lines)\n    # print(\"-------------------------------------------------------------\")\n    # print(len(lines))\n    # print(\"-------------------------------------------------------------\")\n    # print(lines)\n    # print(\"-------------------------------------------------------------"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # print(len(lines))\n    # print(lines[0])\n    # print(lines[-1])\n\n    # print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # print(\"clean_lines\")\n    result = []\n    # print(len(lines))\n    # print(lines)\n    # print(len(result))\n    # print(result)\n    # print(len(result))\n    # print(result)\n    # print(len(result))\n    # print(result)\n    # print(len(result))\n    # print(result)\n    # print(len(result))\n    # print(result)\n    # print(len(result))\n    # print(result)\n    # print(len(result))\n    # print(result)\n    # print(len(result))\n    # print(result)\n    # print(len(result))\n    # print(result)\n    # print(len(result))\n    # print(result)\n    # print(len(result))\n    # print(result)\n    # print(len(result))\n    # print(result)\n    # print(len(result))\n    # print(result)\n    # print(len(result))\n    # print(result)\n    # print(len(result))\n    # print(result)\n    # print(len(result))\n    # print(result)\n    # print(len(result))\n    # print(result)\n    # print(len(result))\n    # print(result)\n    # print(len(result))\n    # print(result)\n    # print(len(result))\n    # print(result)\n    # print(len(result))\n    # print(result)\n    # print(len(result))\n    # print(result)\n    # print(len(result))\n    # print(result)\n    # print(len(result))\n    # print(result)\n    # print(len(result))\n    # print(result)\n    # print(len(result))\n    # print(result)\n    # print(len(result))\n    # print(result)\n    # print(len(result))\n    # print(result)\n    # print(len(result))\n    # print(result)\n    # print(len"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # print(lines)\n    # print(\"*\"*100)\n    # print(len(lines))\n    lines = [line.strip() for line in lines]\n    # print(lines)\n    # print(\"*\"*100)\n    # print(len(lines))\n    lines = [line for line in lines if line]\n    # print(lines)\n    # print(\"*\"*100)\n    # print(len(lines))\n    # print(lines)\n    # print(\"*\"*100)\n    # print(len(lines))\n    # print(lines)\n    # print(\"*\"*100)\n    # print(len(lines))\n    # print(lines)\n    # print(\"*\"*100)\n    # print(len(lines))\n    # print(lines)\n    # print(\"*\"*100)\n    # print(len(lines))\n    # print(lines)\n    # print(\"*\"*100)\n    # print(len(lines))\n    # print(lines)\n    # print(\"*\"*100)\n    # print(len(lines))\n    # print(lines)\n    # print(\"*\"*100)\n    # print(len(lines))\n    # print(lines)\n    # print(\"*\"*100)\n    # print(len(lines))\n    # print(lines)\n    # print(\"*\"*100)\n    # print(len(lines))\n    # print(lines)\n    # print(\"*\"*100)\n    # print(len(lines))\n    # print(lines)\n    # print(\"*\"*100)\n    # print(len(lines))\n    # print(lines)\n    # print(\"*\"*100)\n    # print(len(lines))\n    # print(lines)\n    # print(\"*\"*100)\n    # print(len(lines))\n    # print(lines)\n    # print(\"*\"*100)\n    # print(len(lines))\n    # print(lines)\n    # print(\"*\""}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # Initialize the result list\n    result = []\n\n    # Initialize the block index\n    block_index = 0\n\n    # Initialize the header index\n    header_index = 0\n\n    # Initialize the list index\n    list_index = 0\n\n    # Initialize the list of lists\n    list_of_lists = []\n\n    # Initialize the list of headers\n    list_of_headers = []\n\n    # Initialize the list of blocks\n    list_of_blocks = []\n\n    # Initialize the list of lists\n    list_of_lists = []\n\n    # Initialize the list of headers\n    list_of_headers = []\n\n    # Initialize the list of blocks\n    list_of_blocks = []\n\n    # Initialize the list of blocks\n    list_of_blocks = []\n\n    # Initialize the list of blocks\n    list_of_blocks = []\n\n    # Initialize the list of blocks\n    list_of_blocks = []\n\n    # Initialize the list of blocks\n    list_of_blocks = []\n\n    # Initialize the list of blocks\n    list_of_blocks = []\n\n    # Initialize the list of blocks\n    list_of_blocks = []\n\n    # Initialize the list of blocks\n    list_of_blocks = []\n\n    # Initialize the list of blocks\n    list_of_blocks = []\n\n    # Initialize the list of blocks\n    list_of_blocks = []\n\n    # Initialize the list of blocks\n    list_of_blocks = []\n\n    # Initialize the list of blocks\n    list_of_blocks = []\n\n    # Initialize the list of blocks\n    list_of_blocks = []\n\n    # Initialize the list of blocks\n    list_of_blocks = []\n\n    # Initialize the list of blocks\n    list_of_blocks = []\n\n    # Initialize the list of blocks\n    list_of_blocks = []\n\n    # Initialize the list of blocks\n    list_of_blocks = []\n\n    # Initialize the list of blocks\n    list_of_blocks = []\n\n    # Initialize the"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # Initialize the result list\n    result = []\n\n    # Initialize the index of the current block\n    block_index = 0\n\n    # Initialize the index of the current header block\n    header_index = 0\n\n    # Initialize the index of the current list item\n    list_index = 0\n\n    # Initialize the index of the current table\n    table_index = 0\n\n    # Initialize the index of the current table row\n    table_row_index = 0\n\n    # Initialize the index of the current table cell\n    table_cell_index = 0\n\n    # Initialize the index of the current figure\n    figure_index = 0\n\n    # Initialize the index of the current equation\n    equation_index = 0\n\n    # Initialize the index of the current equation\n    equation_index = 0\n\n    # Initialize the index of the current equation\n    equation_index = 0\n\n    # Initialize the index of the current equation\n    equation_index = 0\n\n    # Initialize the index of the current equation\n    equation_index = 0\n\n    # Initialize the index of the current equation\n    equation_index = 0\n\n    # Initialize the index of the current equation\n    equation_index = 0\n\n    # Initialize the index of the current equation\n    equation_index = 0\n\n    # Initialize the index of the current equation\n    equation_index = 0\n\n    # Initialize the index of the current equation\n    equation_index = 0\n\n    # Initialize the index of the current equation\n    equation_index = 0\n\n    # Initialize the index of the current equation\n    equation_index = 0\n\n    # Initialize the index of the current equation\n    equation_index = 0\n\n    # Initialize the index of the current equation\n    equation_index = 0\n\n    # Initialize the index of the current equation\n    equation_index = 0\n\n    # Initialize the index of the current equation\n    equation_index = 0\n\n    # Initialize the index of the current equation\n    equation_index = 0\n\n    # Initialize the index of the current equation\n    equation_index = 0\n\n    #"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # lines = [line.lower() for line in lines]\n    # lines = [line.replace(\"'s\", \"\") for line in lines]\n    # lines = [line.replace(\"\u2019s\", \"\") for line in lines]\n    # lines = [line.replace(\"\u2019\", \"\") for line in lines]\n    # lines = [line.replace(\"\u2019\", \"\") for line in lines]\n    # lines = [line.replace(\"'\", \"\") for line in lines]\n    # lines = [line.replace(\"\u2019\", \"\") for line in lines]\n    # lines = [line.replace(\"\u2019\", \"\") for line in lines]\n    # lines = [line.replace(\"-\", \" \") for line in lines]\n    # lines = [line.replace(\"-\", \" \") for line in lines]\n    # lines = [line.replace(\"-\", \" \") for line in lines]\n    # lines = [line.replace(\"-\", \" \") for line in lines]\n    # lines = [line.replace(\"-\", \" \") for line in lines]\n    # lines = [line.replace(\"-\", \" \") for line in lines]\n    # lines = [line.replace(\"-\", \" \") for line in lines]\n    # lines = [line.replace(\"-\", \" \") for line in lines]\n    # lines = [line.replace(\"-\", \" \") for line in lines]\n    # lines = [line.replace(\"-\", \" \") for line in lines]\n    # lines = [line.replace(\"-\", \" \") for line in lines]\n    # lines = [line.replace(\"-\", \" \") for line in lines]\n    # lines = [line.replace(\"-\", \" \") for line in lines]\n    # lines = [line.replace(\"-\", \" \") for line in lines]\n    # lines = [line.replace(\"-\", \" \") for line in lines]\n    # lines = [line.replace(\"-\", \" \") for line in lines]\n    # lines = [line.replace(\"-\", \" \") for line in lines]\n    # lines = [line.replace(\"-\", \" \") for line in lines]\n    # lines = [line.replace(\"-\", \" \")"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # initialize the result list\n    result = []\n    # initialize the list of processed lines\n    processed_lines = []\n    # initialize the list of processed blocks\n    processed_blocks = []\n    # initialize the list of processed blocks\n    processed_blocks_dict = defaultdict(list)\n    # initialize the list of header blocks\n    header_blocks = []\n    # initialize the list of header blocks\n    header_blocks_dict = defaultdict(list)\n    # initialize the list of processed lines\n    processed_lines_dict = defaultdict(list)\n    # initialize the list of processed lines\n    processed_lines_dict_index = defaultdict(list)\n    # initialize the list of processed lines\n    processed_lines_dict_index_list = defaultdict(list)\n    # initialize the list of processed lines\n    processed_lines_dict_index_list_list = defaultdict(list)\n    # initialize the list of processed lines\n    processed_lines_dict_index_list_list_list = defaultdict(list)\n    # initialize the list of processed lines\n    processed_lines_dict_index_list_list_list_list = defaultdict(list)\n    # initialize the list of processed lines\n    processed_lines_dict_index_list_list_list_list_list = defaultdict(list)\n    # initialize the list of processed lines\n    processed_lines_dict_index_list_list_list_list_list_list = defaultdict(list)\n    # initialize the list of processed lines\n    processed_lines_dict_index_list_list_list_list_list_list_list = defaultdict(list)\n    # initialize the list of processed lines\n    processed_lines_dict_index_list_list_list_list_list_list_list_list = defaultdict(\n        list\n    )\n    # initialize the list of processed lines\n    processed_lines_dict_index_list_list_list_list_list_list_list_list_list = defaultdict(\n        list\n    )\n    # initialize the list of processed lines\n    processed_lines_dict_index_list_list_list_list_list_list_"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # Remove empty lines\n    lines = [line for line in lines if not should_skip(line, xml)]\n\n    # Remove duplicate lines\n    lines = [lines[0]] + [\n        line for line in lines[1:] if line != lines[0] or line.isdigit()\n    ]\n\n    # Remove duplicate lines\n    lines = [lines[0]] + [\n        line for line in lines[1:] if line != lines[0] or line.isdigit()\n    ]\n\n    # Fix spaced characters\n    lines = [line.replace(\" - \", \" -\") for line in lines]\n\n    # Connect incomplete lines\n    lines = [\n        line.replace(\" - \", \" - \")\n        for line in lines\n        if not check_parentheses(line) and not find_floating_chars(line)\n    ]\n\n    # Remove duplicate lines\n    lines = [lines[0]] + [\n        line for line in lines[1:] if line != lines[0] or line.isdigit()\n    ]\n\n    # Remove duplicate lines\n    lines = [lines[0]] + [\n        line for line in lines[1:] if line != lines[0] or line.isdigit()\n    ]\n\n    # Remove duplicate lines\n    lines = [lines[0]] + [\n        line for line in lines[1:] if line != lines[0] or line.isdigit()\n    ]\n\n    # Remove duplicate lines\n    lines = [lines[0]] + [\n        line for line in lines[1:] if line != lines[0] or line.isdigit()\n    ]\n\n    # Remove duplicate lines\n    lines = [lines[0]] + [\n        line for line in lines[1:] if line != lines[0] or line.isdigit()\n    ]\n\n    # Remove duplicate lines\n    lines = [lines[0]] + [\n        line for line in lines[1:] if line != lines[0] or line.isdigit()\n    ]\n\n    # Remove duplicate lines\n    lines = [lines[0]] + [\n        line for line in lines[1:] if line != lines[0] or line"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # TODO: add the option to have a list of allowed words to filter out\n    # TODO: add the option to have a list of allowed words to filter out\n    # TODO: add the option to have a list of allowed words to filter out\n\n    # TODO: add the option to have a list of allowed words to filter out\n    # TODO: add the option to have a list of allowed words to filter out\n    # TODO: add the option to have a list of allowed words to filter out\n\n    # TODO: add the option to have a list of allowed words to filter out\n    # TODO: add the option to have a list of allowed words to filter out\n    # TODO: add the option to have a list of allowed words to filter out\n\n    # TODO: add the option to have a list of allowed words to filter out\n    # TODO: add the option to have a list of allowed words to filter out\n    # TODO: add the option to have a list of allowed words to filter out\n\n    # TODO: add the option to have a list of allowed words to filter out\n    # TODO: add the option to have a list of allowed words to filter out\n    # TODO: add the option to have a list of allowed words to filter out\n\n    # TODO: add the option to have a list of allowed words to filter out\n    # TODO: add the option to have a list of allowed words to filter out\n    # TODO: add the option to have a list of allowed words to filter out\n\n    # TODO: add the option to have a list of allowed words to filter out\n    # TODO: add the option to have a list of allowed words to filter out\n    # TODO: add the option to have a list of allowed words to filter out\n\n    # TODO: add the option to have a list of allowed words to filter out\n    # TODO: add the option to have a list of allowed words to filter out\n    # TODO: add the option to have a list of allowed words to filter out\n\n    # TODO: add the option to have a list of allowed words to filter out\n    # TODO: add the option to have a list of allowed words to filter out\n    # TODO: add the option to have a list of allowed words to filter out\n\n    # TODO"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # print(len(lines))\n    # print(lines)\n\n    # remove empty lines\n    lines = [line for line in lines if line]\n\n    # remove duplicate lines\n    lines = list(set(lines))\n\n    # remove lines with only numbers\n    lines = [line for line in lines if not line.isdigit()]\n\n    # remove lines with only a single character\n    lines = [line for line in lines if len(line) > 1]\n\n    # remove lines with only a single word\n    lines = [line for line in lines if len(line.split(\" \")) > 1]\n\n    # remove lines with only one character\n    lines = [line for line in lines if len(line) > 1]\n\n    # remove lines with only a single word\n    lines = [line for line in lines if len(line.split(\" \")) > 1]\n\n    # remove lines with only a single word\n    lines = [line for line in lines if len(line.split(\" \")) > 1]\n\n    # remove lines with only a single word\n    lines = [line for line in lines if len(line.split(\" \")) > 1]\n\n    # remove lines with only a single word\n    lines = [line for line in lines if len(line.split(\" \")) > 1]\n\n    # remove lines with only a single word\n    lines = [line for line in lines if len(line.split(\" \")) > 1]\n\n    # remove lines with only a single word\n    lines = [line for line in lines if len(line.split(\" \")) > 1]\n\n    # remove lines with only a single word\n    lines = [line for line in lines if len(line.split(\" \")) > 1]\n\n    # remove lines with only a single word\n    lines = [line for line in lines if len(line.split(\" \")) > 1]\n\n    # remove lines with only a single word\n    lines = [line for line in lines if len(line.split(\" \")) > 1]\n\n    # remove lines with only a single word\n    lines = [line for line in"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # List of dictionaries representing each block of text\n    result = []\n\n    # List of dictionaries representing each line of text\n    line_list = []\n\n    # List of dictionaries representing each line of text with metadata\n    line_meta_list = []\n\n    # List of dictionaries representing each line of text with metadata\n    # line_meta_list = []\n\n    # List of dictionaries representing each header block\n    header_list = []\n\n    # List of dictionaries representing each list block\n    list_list = []\n\n    # List of dictionaries representing each table block\n    table_list = []\n\n    # List of dictionaries representing each figure block\n    figure_list = []\n\n    # List of dictionaries representing each equation block\n    equation_list = []\n\n    # List of dictionaries representing each reference block\n    reference_list = []\n\n    # List of dictionaries representing each line of text with metadata\n    # line_meta_list = []\n\n    # List of dictionaries representing each line of text with metadata\n    # line_meta_list = []\n\n    # List of dictionaries representing each line of text with metadata\n    # line_meta_list = []\n\n    # List of dictionaries representing each line of text with metadata\n    # line_meta_list = []\n\n    # List of dictionaries representing each line of text with metadata\n    # line_meta_list = []\n\n    # List of dictionaries representing each line of text with metadata\n    # line_meta_list = []\n\n    # List of dictionaries representing each line of text with metadata\n    # line_meta_list = []\n\n    # List of dictionaries representing each line of text with metadata\n    # line_meta_list = []\n\n    # List of dictionaries representing each line of text with metadata\n    # line_meta_list = []\n\n    # List of dictionaries representing each line of text with metadata\n    # line_meta_list = []\n\n    # List of dictionaries representing each line of text with metadata\n    # line_meta_list = []\n\n    # List of dictionaries representing each line of text with metadata\n    # line_meta_list ="}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    lines = [line for line in lines if line]\n    lines = [line.strip() for line in lines]\n    lines = [line for line in lines if line]\n    lines = [line for line in lines if not should_skip(line, xml)]\n    lines = [line for line in lines if not find_floating_chars(line)]\n    lines = [line for line in lines if not is_table_row(line)]\n\n    lines = [line_parser.Line(line) for line in lines]\n\n    lines = [line for line in lines if line.is_valid]\n\n    lines = [line for line in lines if not line.is_table_row]\n\n    lines = [line for line in lines if not line.is_table_header]\n\n    lines = [line for line in lines if not line.is_table_cell]\n\n    lines = [line for line in lines if not line.is_table_row]\n\n    lines = [line for line in lines if not line.is_table_cell]\n\n    lines = [line for line in lines if not line.is_table_header]\n\n    lines = [line for line in lines if not line.is_table_header]\n\n    lines = [line for line in lines if not line.is_table_header]\n\n    lines = [line for line in lines if not line.is_table_header]\n\n    lines = [line for line in lines if not line.is_table_header]\n\n    lines = [line for line in lines if not line.is_table_header]\n\n    lines = [line for line in lines if not line.is_table_header]\n\n    lines = [line for line in lines if not line.is_table_header]\n\n    lines = [line for line in lines if not line.is_table_header]\n\n    lines = [line for line in lines if not line.is_table_header]\n\n    lines = [line for line in lines if not line.is_table_header]\n\n    lines = [line for line in lines if not line.is_table_header]"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    result = []\n    # list of indices of lines that have been processed\n    processed = []\n    # list of indices of lines that have been processed and are duplicates\n    duplicates = []\n    # list of indices of lines that have been processed and are table rows\n    table_rows = []\n    # list of indices of lines that have been processed and are headers\n    headers = []\n    # list of indices of lines that have been processed and are lists\n    lists = []\n    # list of indices of lines that have been processed and are in tables\n    table_lines = []\n    # list of indices of lines that have been processed and are in tables\n    table_lines = []\n    # list of indices of lines that have been processed and are in tables\n    table_lines = []\n    # list of indices of lines that have been processed and are in tables\n    table_lines = []\n    # list of indices of lines that have been processed and are in tables\n    table_lines = []\n    # list of indices of lines that have been processed and are in tables\n    table_lines = []\n    # list of indices of lines that have been processed and are in tables\n    table_lines = []\n    # list of indices of lines that have been processed and are in tables\n    table_lines = []\n    # list of indices of lines that have been processed and are in tables\n    table_lines = []\n    # list of indices of lines that have been processed and are in tables\n    table_lines = []\n    # list of indices of lines that have been processed and are in tables\n    table_lines = []\n    # list of indices of lines that have been processed and are in tables\n    table_lines = []\n    # list of indices of lines that have been processed and are in tables\n    table_lines = []\n    # list of indices of lines that have been processed and are in tables\n    table_lines = []\n    # list of indices of lines that have been processed and are in tables\n    table_lines = []\n    # list of indices of lines that have been processed and are in tables\n    table_lines = []\n    # list of indices of lines that have been processed and are in tables\n    table_lines = []\n    #"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # remove empty lines\n    lines = [line.strip() for line in lines if line.strip()]\n\n    # remove lines that are just numbers\n    lines = [line for line in lines if not line.isdigit()]\n\n    # remove lines that are just single characters\n    lines = [line for line in lines if len(line) > 1]\n\n    # remove lines that are just single characters\n    lines = [line for line in lines if not find_floating_chars(line)]\n\n    # remove lines that are just single characters\n    lines = [line for line in lines if line.replace(\" \", \"\").strip()]\n\n    # remove lines that are just single characters\n    lines = [line for line in lines if not check_parentheses(line)]\n\n    # remove lines that are just single characters\n    lines = [line for line in lines if not is_table_row(line)]\n\n    # remove lines that are just single characters\n    lines = [line for line in lines if not should_skip(line, xml)]\n\n    # remove lines that are just single characters\n    lines = [line for line in lines if not should_skip(line.lower(), xml)]\n\n    # remove lines that are just single characters\n    lines = [line for line in lines if not should_skip(line.lower().strip(), xml)]\n\n    # remove lines that are just single characters\n    lines = [line for line in lines if not should_skip(line.lower().strip(), xml)]\n\n    # remove lines that are just single characters\n    lines = [line for line in lines if not should_skip(line.lower().strip(), xml)]\n\n    # remove lines that are just single characters\n    lines = [line for line in lines if not should_skip(line.lower().strip(), xml)]\n\n    # remove lines that are just single characters\n    lines = [line for line in lines if not should_skip(line.lower().strip(), xml)]\n\n    # remove lines that are just single characters\n    lines = [line for line in lines if not should_skip(line.lower().strip(), xml)]\n\n    # remove lines that are just single characters\n    lines"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    result = []\n    # print(lines)\n    # print(len(lines))\n    # print(len(result))\n    for i in range(len(lines)):\n        line = lines[i]\n        # print(line)\n        if should_skip(line, xml):\n            continue\n        if find_floating_chars(line):\n            continue\n        if check_parentheses(line):\n            continue\n        if is_table_row(line):\n            continue\n        # print(line)\n        line = line_parser.Line(line)\n        # print(line)\n        if line.is_list_item:\n            line.text = line.text.replace(\"-\", \"\")\n            line.text = line.text.replace(\"*\", \"\")\n            line.text = line.text.replace(\"\u2022\", \"\")\n            line.text = line.text.replace(\":\", \"\")\n            line.text = line.text.replace(\"\u00b7\", \"\")\n            line.text = line.text.replace(\"\u00b7\", \"\")\n            line.text = line.text.replace(\"\u00b7\", \"\")\n            line.text = line.text.replace(\"\u00b7\", \"\")\n            line.text = line.text.replace(\"\u00b7\", \"\")\n            line.text = line.text.replace(\"\u00b7\", \"\")\n            line.text = line.text.replace(\"\u00b7\", \"\")\n            line.text = line.text.replace(\"\u00b7\", \"\")\n            line.text = line.text.replace(\"\u00b7\", \"\")\n            line.text = line.text.replace(\"\u00b7\", \"\")\n            line.text = line.text.replace(\"\u00b7\", \"\")\n            line.text = line.text.replace(\"\u00b7\", \"\")\n            line.text = line.text.replace(\"\u00b7\", \"\")\n            line.text = line.text.replace(\"\u00b7\", \"\")\n            line.text = line.text.replace(\"\u00b7\", \"\")\n            line.text = line.text.replace(\"\u00b7\", \"\")\n            line.text = line.text.replace(\"\u00b7\", \"\")\n            line.text = line.text.replace(\"\u00b7\", \"\")\n            line.text = line.text.replace(\"\u00b7\", \"\")\n           "}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    if len(lines) == 0:\n        return []\n\n    # remove duplicate lines\n    lines = remove_duplicate_lines(lines)\n\n    # fix spacing issues\n    lines = fix_spacing_issues(lines)\n\n    # connect incomplete lines\n    lines = connect_incomplete_lines(lines)\n\n    # clean lines\n    lines = clean_line_contents(lines)\n\n    # categorize lines into paragraphs, headers, or list items\n    lines = categorize_lines(lines, xml)\n\n    # remove empty lines\n    lines = [line for line in lines if len(line[\"text\"]) > 0]\n\n    # remove lines that only contain numbers\n    lines = [line for line in lines if not line[\"text\"].isdigit()]\n\n    # remove lines that only contain a few characters\n    lines = [line for line in lines if not find_floating_chars(line[\"text\"])]\n\n    # remove lines that only contain a few characters\n    lines = [line for line in lines if not find_floating_chars(line[\"text\"])]\n\n    # remove lines that are tables\n    lines = [line for line in lines if not is_table_row(line[\"text\"])]\n\n    # remove lines that are tables\n    lines = [line for line in lines if not is_table_row(line[\"text\"])]\n\n    # remove lines that are tables\n    lines = [line for line in lines if not is_table_row(line[\"text\"])]\n\n    # remove lines that are tables\n    lines = [line for line in lines if not is_table_row(line[\"text\"])]\n\n    # remove lines that are tables\n    lines = [line for line in lines if not is_table_row(line[\"text\"])]\n\n    # remove lines that are tables\n    lines = [line for line in lines if not is_table_row(line[\"text\"])]\n\n    # remove lines that are tables\n    lines = [line for line in lines if not is_table_row(line[\"text\"])]\n\n    # remove lines that are tables\n    lines = [line for line in lines if"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # remove empty lines\n    lines = [line for line in lines if not should_skip(line, xml)]\n    # print(lines)\n    if len(lines) == 0:\n        return []\n\n    # remove duplicate lines\n    lines = remove_duplicate_lines(lines)\n\n    # clean lines\n    lines = clean_lines_and_fix_spaced_characters(lines)\n\n    # connect incomplete lines\n    lines = connect_incomplete_lines(lines)\n\n    # remove floating characters\n    lines = [line for line in lines if not find_floating_chars(line)]\n\n    # remove table rows\n    lines = [line for line in lines if not is_table_row(line)]\n\n    # process lines\n    lines = process_lines(lines)\n\n    # remove duplicate lines\n    lines = remove_duplicate_lines(lines)\n\n    # remove floating characters\n    lines = [line for line in lines if not find_floating_chars(line)]\n\n    # remove table rows\n    lines = [line for line in lines if not is_table_row(line)]\n\n    # remove empty lines\n    lines = [line for line in lines if not should_skip(line, xml)]\n\n    # print(lines)\n    # print(len(lines))\n    return lines\n\n"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # Normalize quotation marks\n    text = quotation_pattern.sub('\"', org_texts)\n\n    # Remove any space between punctuations (.')\n    text = space_rule.sub(r\"\\1\", text)\n\n    # Remove any space between brackets\n    text = bracket_rule.sub(r\"\\1\", text)\n\n    # Apply tokenization rules\n    for rule, replaced in rules:\n        text = rule.sub(replaced, text)\n\n    # Tokenize sentences\n    sentences = nltk_tokenzier.tokenize(text)\n\n    return sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # Normalize quotation marks\n    text = quotation_pattern.sub('\"', org_texts)\n\n    # Remove any space between punctuations (.')\n    text = space_rule.sub(r'\\1', text)\n\n    # Apply the rules to the text\n    for rule, replaced in rules:\n        text = rule.sub(replaced, text)\n\n    # Apply the rule to the text to match content inside brackets\n    text = bracket_rule.sub(r\" \\1 \", text)\n\n    # Split the text into sentences\n    sentences = nltk_tokenzier.tokenize(text)\n\n    return sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    # Empty input\n    if not org_texts:\n        return [org_texts]\n\n    # Normalize quotation marks\n    text = quotation_pattern.sub('\"', org_texts)\n\n    # Remove any space between punctuations (.')\n    text = space_rule.sub(r'\\1', text)\n\n    # Tokenize into sentences\n    sents = nltk_tokenzier.tokenize(text)\n\n    # Apply the rules\n    for i, sent in enumerate(sents):\n        for rule, replaced in rules:\n            sents[i] = rule.sub(replaced, sent)\n\n        # Handle brackets\n        sents[i] = bracket_rule.sub(r\" \\1 \", sents[i])\n\n    return sents"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return [org_texts]\n\n    # Remove any space between punctuations (.')\n    text = space_rule.sub(r\"\\1\", org_texts)\n\n    # Normalize quotation marks\n    text = quotation_pattern.sub('\"', text)\n\n    # Split text into sentences\n    sents = nltk_tokenzier.tokenize(text)\n\n    # Apply sentence tokenization rules\n    for i, sent in enumerate(sents):\n        for rule, replaced in rules:\n            sents[i] = rule.sub(replaced, sent)\n\n        # Replace content inside brackets\n        sents[i] = bracket_rule.sub(r\" \\1 \", sents[i])\n\n    return sents"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # normalize quotation marks\n    text = quotation_pattern.sub('\"', org_texts)\n\n    # replace abbreviations with _\n    for rule, replaced in rules:\n        text = rule.sub(replaced, text)\n\n    # remove space between punctuations\n    text = space_rule.sub(r'\\1', text)\n\n    # tokenize text into sentences\n    sents = nltk_tokenzier.tokenize(text)\n\n    # remove brackets\n    sents = [bracket_rule.sub(r'', sent) for sent in sents]\n\n    return sents"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    # If the input is empty or None, return the input as is\n    if not org_texts:\n        return org_texts\n\n    # Remove any space between punctuations (.')\n    text = space_rule.sub(r'\\1', org_texts)\n\n    # Replace quotation marks with standardized quotation mark\n    text = quotation_pattern.sub('\"', text)\n\n    # Replace abbreviations with standardized abbreviations\n    for rule, replaced in rules:\n        text = rule.sub(replaced, text)\n\n    # Split the text into sentences\n    sentences = nltk_tokenzier.tokenize(text)\n\n    # Remove any sentence that is contained within brackets\n    sentences = [sentence for sentence in sentences if not bracket_rule.search(sentence)]\n\n    return sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # remove quotation marks\n    text = quotation_pattern.sub(\"'\", org_texts)\n\n    # remove space between punctuations\n    text = space_rule.sub(r\"\\1\", text)\n\n    # tokenize paragraphs separated by new lines\n    text = text.replace(\"\\n\", \" \")\n\n    # tokenize sentences that are inside brackets\n    text = bracket_rule.sub(r\"_\\1_\", text)\n\n    # tokenize sentences that are not inside brackets\n    sentences = nltk_tokenzier.tokenize(text)\n\n    # apply abbreviation rules\n    for rule, replaced in rules:\n        for i in range(len(sentences)):\n            sentences[i] = rule.sub(replaced, sentences[i])\n\n    return sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    # if the input is empty or None, return it as is\n    if not org_texts:\n        return org_texts\n\n    # remove quotation marks\n    text = quotation_pattern.sub(\"\", org_texts)\n\n    # split the text into paragraphs\n    paragraphs = text.split(\"\\n\")\n\n    # iterate over the paragraphs\n    for i in range(len(paragraphs)):\n\n        # split the paragraph into sentences\n        sentences = nltk_tokenzier.tokenize(paragraphs[i])\n\n        # iterate over the sentences\n        for j in range(len(sentences)):\n\n            # normalize the sentence\n            sentences[j] = normalize_sentence(sentences[j])\n\n        # join the sentences into a paragraph\n        paragraphs[i] = \" \".join(sentences)\n\n    # join the paragraphs into a text\n    text = \" \".join(paragraphs)\n\n    return text\n\n"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    # check if the input text is empty or None\n    if not org_texts:\n        return [org_texts]\n\n    # normalize quotation marks\n    text = quotation_pattern.sub('\"', org_texts)\n\n    # split the text into paragraphs\n    paragraphs = text.split(\"\\n\")\n\n    # iterate over the paragraphs\n    for i in range(len(paragraphs)):\n        # split the paragraph into sentences\n        sentences = nltk_tokenzier.tokenize(paragraphs[i])\n\n        # iterate over the sentences\n        for j in range(len(sentences)):\n            # remove any space between punctuations\n            sentences[j] = space_rule.sub(r\"\\1\", sentences[j])\n\n            # check if the sentence starts with any abbreviation\n            for rule, replaced in rules:\n                sentences[j] = rule.sub(replaced, sentences[j])\n\n            # check if the sentence has any content inside brackets\n            sentences[j] = bracket_rule.sub(r\" \\1 \", sentences[j])\n\n        # join the sentences back to a paragraph\n        paragraphs[i] = \" \".join(sentences)\n\n    # join the paragraphs back to the original text\n    text = \"\\n\".join(paragraphs)\n\n    # split the text into sentences\n    sentences = nltk_tokenzier.tokenize(text)\n\n    # return the list of sentences\n    return sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # remove all the new lines\n    text = org_texts.replace(\"\\n\", \" \")\n\n    # remove any space between punctuations (.')\n    text = space_rule.sub(r\"\\1\", text)\n\n    # normalize quotation marks\n    text = quotation_pattern.sub('\"', text)\n\n    # tokenize the text into sentences\n    sentences = nltk_tokenzier.tokenize(text)\n\n    # apply the rules to the sentences\n    for i, sentence in enumerate(sentences):\n        for rule, replaced in rules:\n            sentence = rule.sub(replaced, sentence)\n\n        # remove brackets and their contents\n        sentence = bracket_rule.sub(\"\", sentence)\n\n        # remove any space at the beginning of the sentence\n        sentence = sentence.lstrip()\n\n        # add a space between the sentence and the previous sentence\n        if i > 0:\n            sentence = \" \" + sentence\n\n        sentences[i] = sentence\n\n    return sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    # If the input is None or empty, return as is\n    if not org_texts or org_texts.strip() == \"\":\n        return [org_texts]\n\n    # Remove special characters at the beginning of the text\n    text = re.sub(r\"^[^\\w\\s]\", \"\", org_texts)\n\n    # Replace quotation marks with double quotes\n    text = quotation_pattern.sub('\"', text)\n\n    # Tokenize text into sentences\n    sentences = nltk_tokenzier.tokenize(text)\n\n    # Replace abbreviations in sentences\n    for i, sentence in enumerate(sentences):\n        for rule, replaced in rules:\n            sentence = rule.sub(replaced, sentence)\n        # Remove space between punctuations\n        sentence = space_rule.sub(r'\\1', sentence)\n        # Replace content inside brackets\n        sentence = bracket_rule.sub(r'_\\1_', sentence)\n        sentences[i] = sentence\n\n    return sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # remove any space before a punctuation\n    text = space_rule.sub(r'\\1', org_texts)\n\n    # replace all the abbreviations with the underscore (_)\n    for rule, replaced in rules:\n        text = rule.sub(replaced, text)\n\n    # replace all the quotation marks with the single quotation mark (')\n    text = quotation_pattern.sub(\"'\", text)\n\n    # split the text into sentences\n    sentences = nltk_tokenzier.tokenize(text)\n\n    # replace the abbreviations in the sentences with the original abbreviations\n    for rule, replaced in rules:\n        sentences = [rule.sub(replaced, sent) for sent in sentences]\n\n    # remove any space between the punctuations\n    sentences = [space_rule.sub(r'\\1', sent) for sent in sentences]\n\n    # remove any space before the punctuations\n    sentences = [space_rule.sub(r'\\1', sent) for sent in sentences]\n\n    # remove any space after the punctuations\n    sentences = [space_rule.sub(r'\\1', sent) for sent in sentences]\n\n    return sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # Normalize quotation marks\n    text = quotation_pattern.sub('\"', org_texts)\n\n    # Handle new lines\n    text = text.replace(\"\\n\", \" \")\n\n    # Handle beginning punctuations\n    text = space_rule.sub(r'\\1', text)\n\n    # Handle brackets\n    text = bracket_rule.sub(r' \\1 ', text)\n\n    # Handle abbreviations\n    for rule, replaced in rules:\n        text = rule.sub(replaced, text)\n\n    # Handle sentences\n    sentences = nltk_tokenzier.tokenize(text)\n\n    return sentences\n\n"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # Remove quotation marks\n    text = quotation_pattern.sub(\"'\", org_texts)\n\n    # Remove any space between punctuations (.')\n    text = space_rule.sub(r\"\\1\", text)\n\n    # Tokenize the text into sentences\n    sentences = nltk_tokenzier.tokenize(text)\n\n    # Apply the rules to the sentences\n    for i, sentence in enumerate(sentences):\n        for rule, replaced in rules:\n            sentence = rule.sub(replaced, sentence)\n        sentences[i] = sentence\n\n    # Apply the rule to sentences within brackets\n    sentences = [bracket_rule.sub(r\"_ \\1 _\", sentence) for sentence in sentences]\n\n    # Remove any space between punctuations (.')\n    sentences = [space_rule.sub(r\"\\1\", sentence) for sentence in sentences]\n\n    return sentences\n\n"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # Remove extra spaces\n    text = re.sub(r\"\\s+\", \" \", org_texts)\n\n    # Remove special characters\n    text = re.sub(r\"[^A-Za-z0-9.()\\s]\", \"\", text)\n\n    # Remove extra spaces\n    text = re.sub(r\"\\s+\", \" \", text)\n\n    # Remove space before punctuations\n    text = re.sub(r\"\\s([.!?])\", r\"\\1\", text)\n\n    # Remove space after quotations\n    text = re.sub(r'([.\"])(\\s)', r\"\\1\", text)\n\n    # Remove space after quotations\n    text = re.sub(r'(\\s)([.\"])', r\"\\1\\2\", text)\n\n    # Remove space after quotations\n    text = re.sub(r'([.!?])(\\s)', r\"\\1\", text)\n\n    # Remove space after quotations\n    text = re.sub(r'(\\s)([.!?])', r\"\\1\\2\", text)\n\n    # Replace all the abbreviations with the underscore\n    for rule, replaced in rules:\n        text = rule.sub(replaced, text)\n\n    # Remove space before punctuations\n    text = re.sub(r\"\\s([.!?])\", r\"\\1\", text)\n\n    # Remove space after quotations\n    text = re.sub(r'([.\"])(\\s)', r\"\\1\", text)\n\n    # Remove space after quotations\n    text = re.sub(r'(\\s)([.\"])', r\"\\1\\2\", text)\n\n    # Replace all the abbreviations with the underscore\n    for rule, replaced in rules:\n        text = rule.sub(replaced, text)\n\n    # Replace all the abbreviations with the underscore\n    for rule, replaced in rules:\n        text = rule.sub(replaced, text)\n\n    # Replace all the abbreviations with the underscore\n    for"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    # If the input text is empty or None, return the input as is\n    if not org_texts:\n        return org_texts\n\n    # Remove quotation marks\n    text = quotation_pattern.sub(\"'\", org_texts)\n\n    # Tokenize the text using NLTK Punkt tokenizer\n    sents = nltk_tokenzier.tokenize(text)\n\n    # Remove any space between punctuations (.')\n    sents = [space_rule.sub(r\"\\1\", sent) for sent in sents]\n\n    # Apply the bracket rule\n    sents = [bracket_rule.sub(r\"\\1\", sent) for sent in sents]\n\n    # Apply the rules\n    for rule, replaced in rules:\n        sents = [rule.sub(replaced, sent) for sent in sents]\n\n    return sents\n\n"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    # If the input text is empty or None, return the input as is\n    if not org_texts:\n        return org_texts\n\n    # Normalize quotation marks\n    text = quotation_pattern.sub('\"', org_texts)\n\n    # Split the text into sentences using the nltk tokenizer\n    sentences = nltk_tokenzier.tokenize(text)\n\n    # Apply the rules to the sentences\n    for i, sentence in enumerate(sentences):\n        # Apply the rules to the sentence\n        for rule, replaced in rules:\n            sentence = rule.sub(replaced, sentence)\n\n        # Remove the space between the punctuation and the next letter\n        sentence = space_rule.sub(r'\\1', sentence)\n\n        # Remove the content inside brackets\n        sentence = bracket_rule.sub(r'', sentence)\n\n        # Replace the sentence with the normalized one\n        sentences[i] = sentence\n\n    return sentences\n\n"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    text = org_texts.strip()\n\n    # remove all the extra spaces\n    text = re.sub(r\" +\", \" \", text)\n\n    # replace all the special characters with space\n    text = re.sub(r\"[^\\w\\s]\", \" \", text)\n\n    # remove all the extra spaces\n    text = re.sub(r\" +\", \" \", text)\n\n    # replace all the abbreviations with their full forms\n    for rule, replaced in rules:\n        text = rule.sub(replaced, text)\n\n    # remove any space between punctuations\n    text = space_rule.sub(r\"\\1\", text)\n\n    # replace all the quotations with normal quotes\n    text = quotation_pattern.sub('\"', text)\n\n    # tokenize the text into sentences\n    sentences = nltk_tokenzier.tokenize(text)\n\n    # remove all the extra spaces\n    sentences = [re.sub(r\" +\", \" \", sentence).strip() for sentence in sentences]\n\n    # remove all the sentences within brackets\n    sentences = [bracket_rule.sub(\"\", sentence) for sentence in sentences]\n\n    # remove all the extra spaces\n    sentences = [re.sub(r\" +\", \" \", sentence).strip() for sentence in sentences]\n\n    # remove all the sentences that are empty\n    sentences = [sentence for sentence in sentences if sentence]\n\n    return sentences\n\n"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    # if the input is None or empty, return the input as is\n    if not org_texts:\n        return org_texts\n\n    # normalize quotation marks\n    text = quotation_pattern.sub('\"', org_texts)\n\n    # split the text into paragraphs\n    paragraphs = text.split(\"\\n\")\n\n    # initialize the list of sentences\n    sentences = []\n\n    # iterate through each paragraph\n    for paragraph in paragraphs:\n\n        # if the paragraph is empty, skip it\n        if not paragraph:\n            continue\n\n        # if the paragraph starts with punctuation, add it to the list of sentences\n        if paragraph[0] in \".!?\":\n            sentences.append(paragraph[0])\n            paragraph = paragraph[1:]\n\n        # split the paragraph into sentences\n        sentences_ = nltk_tokenzier.tokenize(paragraph)\n\n        # iterate through each sentence\n        for sentence in sentences_:\n\n            # remove any space between punctuations\n            sentence = space_rule.sub(r\"\\1\", sentence)\n\n            # iterate through each bracket\n            for match in bracket_rule.finditer(sentence):\n\n                # get the content of the bracket\n                content = match.group(0)\n\n                # normalize the content of the bracket\n                content = content.strip()\n                content = content.replace(\"-\", \" \")\n                content = content.replace(\"/\", \" \")\n                content = content.replace(\":\", \" \")\n\n                # split the content into words\n                words = content.split(\" \")\n\n                # iterate through each word\n                for idx, word in enumerate(words):\n\n                    # iterate through each abbreviation\n                    for rule, replaced in rules:\n                        word = rule.sub(replaced, word)\n\n                    # add the word to the list of words\n                    words[idx] = word\n\n                # join the words back into the content\n                content = \" \".join(words)\n\n                # add the content to the sentence\n                sentence = sentence.replace(match.group(0), content)\n\n            # add the"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # normalize quotation marks\n    text = quotation_pattern.sub('\"', org_texts)\n\n    # split text into sentences\n    sentences = nltk_tokenzier.tokenize(text)\n\n    # remove special characters\n    sentences = [re.sub(r\"[^\\w\\s]\", \"\", s) for s in sentences]\n\n    # remove empty sentences\n    sentences = [s for s in sentences if s]\n\n    # apply bracket rule\n    sentences = [re.sub(bracket_rule, r\" \\1 \", s) for s in sentences]\n\n    # apply space rule\n    sentences = [re.sub(space_rule, r\"\\1\", s) for s in sentences]\n\n    # apply rules\n    sentences = [re.sub(r, r\"\", s) for s in sentences for r in rules]\n\n    # remove empty sentences\n    sentences = [s for s in sentences if s]\n\n    return sentences\n\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        # Check to see if token is a string\n        if not isinstance(token, str):\n            raise TypeError(\"Expected a string\")\n\n        # Check to see if key is a string\n        if not isinstance(key, str) and key is not None:\n            raise TypeError(\"Expected a string\")\n\n        # Check to see if token is a list\n        if isinstance(token, list):\n            raise TypeError(\"Expected a string\")\n\n        # Check to see if token is a list\n        if isinstance(token, list):\n            raise TypeError(\"Expected a string\")\n\n        # Check to see if key is a list\n        if isinstance(key, list):\n            raise TypeError(\"Expected a string\")\n\n        # Check to see if token is a list\n        if isinstance(token, list):\n            raise TypeError(\"Expected a string\")\n\n        # Check to see if key is a list\n        if isinstance(key, list):\n            raise TypeError(\"Expected a string\")\n\n        # Check to see if key is a list\n        if isinstance(key, list):\n            raise TypeError(\"Expected a string\")\n\n        # Check to see if token is a list\n        if isinstance(token, list):\n            raise TypeError(\"Expected a string\")\n\n        # Check to see if key is a list\n        if isinstance(key, list):\n            raise TypeError(\"Expected a string\")\n\n        # Check to see if token is a list\n        if isinstance(token, list):\n            raise TypeError(\"Expected a string\")\n\n        # Check to see if key is a list\n        if isinstance(key, list):\n            raise TypeError(\"Expected a string\")\n\n        # Check to see if token is a list\n        if isinstance(token, list):\n            raise TypeError(\"Expected a string\")\n\n        # Check to see if key is a list\n        if isinstance(key, list):\n            raise TypeError(\"Expected a string\")\n\n        # Check to see if token is a list\n        if isinstance(token, list):\n            raise TypeError(\"Expected a string\")\n\n        # Check to see if key is a list"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        token = self._check_token_arg(token)\n        if isinstance(token, list):\n            return self.phrase_positions(token)\n        else:\n            return self.term_positions(token, key)\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if not isinstance(token, str):\n            raise TypeError(\"Expected a string\")\n\n        if key is None:\n            doc_ids = np.arange(len(self))\n        else:\n            doc_ids = [key]\n\n        try:\n            term_id = self.term_dict.get_term_id(token)\n            return self.posns.positions(term_id, doc_ids=doc_ids)\n        except TermMissingError:\n            return []\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        token = self._check_token_arg(token)\n        if isinstance(token, list):\n            return self.phrase_positions(token)\n        try:\n            term_id = self.term_dict.get_term_id(token)\n            if key is None:\n                return self.posns.positions(term_id)\n            else:\n                return self.posns.positions(term_id, doc_id=key)\n        except TermMissingError:\n            return []\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if not isinstance(token, str):\n            raise TypeError(\"Expected a string\")\n\n        if key is None:\n            doc_ids = self.term_mat.rows\n        else:\n            doc_ids = [key]\n\n        positions = []\n        for doc_id in doc_ids:\n            try:\n                term_id = self.term_dict.get_term_id(token)\n                posns = self.posns.positions(term_id, doc_id)\n                positions.append(posns)\n            except TermMissingError:\n                positions.append(np.array([]))\n\n        return positions\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if not isinstance(token, str):\n            raise TypeError(\"Expected a string\")\n        # Count number of rows where the term appears\n        try:\n            term_id = self.term_dict.get_term_id(token)\n            if self.term_mat.subset:\n                if key is not None:\n                    if not isinstance(key, int):\n                        raise TypeError(\"Expected an integer for key\")\n                    if key < 0:\n                        key += len(self)\n                    if key >= len(self):\n                        raise ValueError(\"Key out of bounds\")\n                    if key not in self.term_mat.rows:\n                        raise ValueError(\"Key not in term_mat\")\n                    doc_ids, term_positions = self.posns.term_positions(term_id,\n                                                                        doc_ids=[key])\n                    return term_positions\n                else:\n                    doc_ids, term_positions = self.posns.term_positions(term_id)\n                    return term_positions\n            else:\n                if key is not None:\n                    if not isinstance(key, int):\n                        raise TypeError(\"Expected an integer for key\")\n                    if key < 0:\n                        key += len(self)\n                    if key >= len(self):\n                        raise ValueError(\"Key out of bounds\")\n                    if key not in self.term_mat.rows:\n                        raise ValueError(\"Key not in term_mat\")\n                    doc_ids, term_positions = self.posns.term_positions(term_id,\n                                                                        doc_ids=[key])\n                    return term_positions\n                else:\n                    doc_ids, term_positions = self.posns.term_positions(term_id)\n                    return term_positions\n        except TermMissingError:\n            return np.zeros(len(self), dtype=int)\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        token = self._check_token_arg(token)\n        if isinstance(token, list):\n            return self.phrase_positions(token)\n\n        if key is None:\n            doc_ids = self.term_mat.rows\n        else:\n            doc_ids = [key]\n\n        try:\n            term_id = self.term_dict.get_term_id(token)\n            return self.posns.positions(term_id, doc_ids)\n        except TermMissingError:\n            return []\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if not isinstance(token, str):\n            raise TypeError(\"Expected a string\")\n        if key is not None:\n            if not isinstance(key, int):\n                raise TypeError(\"Expected an integer\")\n\n        try:\n            term_id = self.term_dict.get_term_id(token)\n            if key is None:\n                doc_ids, positions = self.posns.positions(term_id)\n                return positions\n            else:\n                doc_ids, positions = self.posns.positions(term_id, doc_ids=[key])\n                return positions\n        except TermMissingError:\n            return np.array([])\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        token = self._check_token_arg(token)\n        if isinstance(token, list):\n            return self.phrase_positions(token)\n        try:\n            term_id = self.term_dict.get_term_id(token)\n            if key is None:\n                return self.posns.positions(term_id)\n            else:\n                return self.posns.positions(term_id, doc_id=key)\n        except TermMissingError:\n            return []\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if not isinstance(token, str):\n            raise TypeError(\"Expected a string\")\n\n        if key is not None:\n            if not isinstance(key, int):\n                raise TypeError(\"Expected an integer\")\n\n        try:\n            term_id = self.term_dict.get_term_id(token)\n            if key is None:\n                return self.posns.positions(term_id)\n            else:\n                return self.posns.positions(term_id, key)\n        except TermMissingError:\n            return []\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        # Check to see if the token is in the term dictionary\n        if not isinstance(token, str):\n            raise TypeError(\"Expected a string\")\n\n        # If the token is not in the term dictionary, return an empty list\n        if not self.term_dict.contains_term(token):\n            return []\n\n        # If a key is provided, check to see if the document is in the array\n        if key is not None:\n            if not isinstance(key, int):\n                raise TypeError(\"Expected an integer\")\n\n            # If the document is not in the array, return an empty list\n            if not self.contains_doc(key):\n                return []\n\n        # If no key is provided, search across all documents\n        if key is None:\n\n            # Get the term ID\n            term_id = self.term_dict.get_term_id(token)\n\n            # Get the positions for the term across all documents\n            positions = self.posns.get_positions(term_id)\n\n        # If a key is provided, search within the document\n        else:\n\n            # Get the term ID\n            term_id = self.term_dict.get_term_id(token)\n\n            # Get the positions for the term within the document\n            positions = self.posns.get_positions(term_id, doc_id=key)\n\n        # Return the positions\n        return positions\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is None:\n            return self.posns.positions(self.term_dict.get_term_id(token))\n        else:\n            return self.posns.positions(self.term_dict.get_term_id(token), key=key)\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if not isinstance(token, str):\n            raise TypeError(\"Expected a string\")\n\n        if key is not None:\n            if not isinstance(key, int):\n                raise TypeError(\"Expected an integer\")\n\n        try:\n            term_id = self.term_dict.get_term_id(token)\n            if key is None:\n                doc_ids, positions = self.posns.term_positions(term_id)\n                return positions\n            else:\n                doc_ids, positions = self.posns.term_positions(term_id)\n                if key in doc_ids:\n                    return positions[doc_ids.index(key)]\n                else:\n                    return np.array([])\n        except TermMissingError:\n            return []\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        # Check that token is a string\n        if not isinstance(token, str):\n            raise TypeError(\"Expected a string\")\n\n        # Check that key is None or a string\n        if not (key is None or isinstance(key, str)):\n            raise TypeError(\"Expected key to be None or a string\")\n\n        # Check that token is in the SearchArray\n        if token not in self.term_dict:\n            raise ValueError(\"Expected token to be in SearchArray\")\n\n        # Check that key is in the SearchArray\n        if key is not None and key not in self.term_dict:\n            raise ValueError(\"Expected key to be in SearchArray\")\n\n        # Get the term id\n        term_id = self.term_dict.get_term_id(token)\n\n        # Get the positions\n        if key is None:\n            # Get the positions across all documents\n            positions = self.posns.positions(term_id)\n        else:\n            # Get the positions for a specific document\n            positions = self.posns.positions(term_id, key=key)\n\n        return positions\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if not isinstance(token, str):\n            raise TypeError(\"Expected a string\")\n        if key is not None and not isinstance(key, int):\n            raise TypeError(\"Expected an integer\")\n\n        # Get the term id for the given token\n        term_id = self.term_dict.get_term_id(token)\n\n        # If no key is provided, return positions across all documents\n        if key is None:\n\n            # Get the document ids for the given term\n            doc_ids = self.posns.doc_ids(term_id)\n\n            # If no documents contain the given term, return an empty list\n            if len(doc_ids) == 0:\n                return []\n\n            # Otherwise, return a list containing a numpy array for each document containing the given term\n            else:\n                return [self.posns.term_positions(term_id, doc_id) for doc_id in doc_ids]\n\n        # If a key is provided, return positions for the given document\n        else:\n\n            # If the given document does not contain the given term, return an empty array\n            if not self.match(token, slop=0)[key]:\n                return np.array([])\n\n            # Otherwise, return a numpy array containing the positions of the given term in the given document\n            else:\n                return self.posns.term_positions(term_id, key)\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if not isinstance(token, str):\n            raise TypeError(\"Expected a string\")\n\n        if key is None:\n            doc_ids = np.arange(len(self))\n        else:\n            doc_ids = np.where(self.term_mat.rows == key)[0]\n\n        try:\n            term_id = self.term_dict.get_term_id(token)\n            return self.posns.positions(term_id, doc_ids=doc_ids)\n        except TermMissingError:\n            return [np.array([])] * len(doc_ids)\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        # Check that token is a string\n        if not isinstance(token, str):\n            raise TypeError(\"Expected a string\")\n\n        # Check that key is a string\n        if key is not None and not isinstance(key, str):\n            raise TypeError(\"Expected a string\")\n\n        # Check that token is in the SearchArray\n        if token not in self.term_dict:\n            raise ValueError(\"Token not in SearchArray\")\n\n        # Check that key is in the SearchArray\n        if key is not None and key not in self.term_dict:\n            raise ValueError(\"Key not in SearchArray\")\n\n        # If key is None, positions are searched across all documents\n        if key is None:\n            # Get the positions for the given token\n            positions = self.posns.positions(self.term_dict.get_term_id(token))\n\n            # Convert the positions to a list of numpy arrays\n            positions = [np.asarray(position) for position in positions]\n\n            # Return the list of numpy arrays\n            return positions\n\n        # If key is not None, positions are searched within the document\n        # specified by the key\n        else:\n            # Get the positions for the given token\n            positions = self.posns.positions(self.term_dict.get_term_id(token), key)\n\n            # Convert the positions to a numpy array\n            positions = np.asarray(positions)\n\n            # Return the numpy array\n            return positions\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        # Check that token is a string\n        if not isinstance(token, str):\n            raise TypeError(\"Expected a string\")\n\n        # If key is not None, check that it is a string\n        if key is not None and not isinstance(key, str):\n            raise TypeError(\"Expected a string\")\n\n        # Get term id\n        try:\n            term_id = self.term_dict.get_term_id(token)\n        except TermMissingError:\n            raise ValueError(\"Token not found in the index\")\n\n        # If key is None, search across all documents\n        if key is None:\n\n            # Get positions of term\n            positions = self.posns.positions(term_id)\n\n            # Get number of documents containing term\n            num_docs = self.posns.docfreq(term_id)\n\n            # Get number of documents\n            num_docs = len(self)\n\n            # Get number of positions\n            num_positions = self.posns.num_positions(term_id)\n\n            # Get average number of positions per document\n            avg_num_positions = num_positions / num_docs\n\n            # Get document lengths\n            doc_lens = self.doclengths()\n\n            # Get term frequencies\n            term_freqs = self.termfreqs(token)\n\n            # Compute BM25 scores\n            scores = default_bm25(term_freqs, num_docs, avg_num_positions, doc_lens)\n\n            # Return list of numpy arrays\n            return [np.array(positions[i]) * scores[i] for i in range(num_docs)]\n\n        # If key is not None, search within specific document\n        else:\n\n            # Get positions of term\n            positions = self.posns.positions(term_id, doc_id=key)\n\n            # Return numpy array\n            return np.array(positions)\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        # Get term freqs per token\n        token = self._check_token_arg(token)\n        if isinstance(token, list):\n            term_freq = self.phrase_freq(token)\n        else:\n            term_freq = self.termfreqs(token)\n\n        # If key is None, positions are searched across all documents\n        if key is None:\n            # Get the positions for the term\n            term_id = self.term_dict.get_term_id(token)\n            posns = self.posns.positions(term_id)\n\n            # Return a list of numpy arrays where each array contains the positions of the given term\n            return posns\n\n        # If key is not None, positions are searched within the document specified by key\n        else:\n            # Get the positions for the term\n            term_id = self.term_dict.get_term_id(token)\n            posns = self.posns.positions(term_id, key=key)\n\n            # Return a list of numpy arrays where each array contains the positions of the given term\n            return posns\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if not isinstance(token, str):\n            raise TypeError(\"Expected a string\")\n\n        # If key is provided, retrieve the positions for that document only\n        if key is not None:\n            try:\n                term_id = self.term_dict.get_term_id(token)\n                return self.posns.positions(term_id, doc_id=key)\n            except TermMissingError:\n                return np.zeros(0, dtype=int)\n\n        # If key is not provided, retrieve the positions across all documents\n        else:\n            try:\n                term_id = self.term_dict.get_term_id(token)\n                return self.posns.positions(term_id)\n            except TermMissingError:\n                return np.zeros(0, dtype=int)\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # Check if the 'mm' spec is a conditional expression.\n    if '<' in spec:\n        # Parse the conditional expression.\n        # The expression is assumed to be in the form 'min_clauses < condition < max_clauses'.\n        # The condition is assumed to be a percentage.\n        # The condition is assumed to be a percentage of the total number of clauses.\n        # The condition is assumed to be a percentage of the total number of clauses.\n        # The condition is assumed to be a percentage of the total number of clauses.\n        # The condition is assumed to be a percentage of the total number of clauses.\n        # The condition is assumed to be a percentage of the total number of clauses.\n        # The condition is assumed to be a percentage of the total number of clauses.\n        # The condition is assumed to be a percentage of the total number of clauses.\n        # The condition is assumed to be a percentage of the total number of clauses.\n        # The condition is assumed to be a percentage of the total number of clauses.\n        # The condition is assumed to be a percentage of the total number of clauses.\n        # The condition is assumed to be a percentage of the total number of clauses.\n        # The condition is assumed to be a percentage of the total number of clauses.\n        # The condition is assumed to be a percentage of the total number of clauses.\n        # The condition is assumed to be a percentage of the total number of clauses.\n        # The condition is assumed to be a percentage of the total number of clauses.\n        # The condition is assumed to be a percentage of the total number of clauses.\n        # The condition is assumed to be a percentage of the total number of clauses.\n        # The condition is assumed to be a percentage of the total number of clauses.\n        # The condition is assumed to be a percentage of the total number of clauses.\n        # The condition is assumed to be a percentage of the total number of clauses.\n        # The condition is assumed to be a percentage of the total number of clauses.\n        # The condition is assumed to be a percentage of the total number of clauses.\n        # The condition is assumed to be a percentage of the"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if re.match(r'^\\d+$', spec):\n        return int(spec)\n    elif re.match(r'^\\d+\\.\\d+$', spec):\n        return int(float(spec) * num_clauses)\n    elif re.match(r'^\\d+%$', spec):\n        return int(float(spec[:-1]) / 100 * num_clauses)\n    elif re.match(r'^\\d+%$', spec):\n        return int(float(spec[:-1]) / 100 * num_clauses)\n    elif re.match(r'^<\\d+$', spec):\n        return int(spec[1:])\n    elif re.match(r'^<\\d+\\.\\d+$', spec):\n        return int(float(spec[1:-1]) * num_clauses)\n    elif re.match(r'^<\\d+%$', spec):\n        return int(float(spec[1:-1]) / 100 * num_clauses)\n    elif re.match(r'^<\\d+%$', spec):\n        return int(float(spec[1:-1]) / 100 * num_clauses)\n    else:\n        raise ValueError(f'Unrecognized mm spec: {spec}')\n\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # If the spec is a number, return it.\n    try:\n        return int(spec)\n    except ValueError:\n        pass\n\n    # If the spec is a percentage, return the corresponding number of clauses.\n    try:\n        return int(num_clauses * float(spec[:-1]) / 100)\n    except ValueError:\n        pass\n\n    # If the spec is a conditional expression, parse the number and the condition.\n    if spec[-1] == '>':\n        num, condition = int(spec[:-1]), '>'\n    else:\n        num, condition = int(spec[:-2]), '<'\n\n    # If the condition is '<', return the number of clauses that must match.\n    if condition == '<':\n        return num\n\n    # If the condition is '>', return the number of clauses that must match, unless it's 0, in which case return 1.\n    if num == 0:\n        return 1\n    else:\n        return num\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():\n        return int(spec)\n\n    if spec.endswith('%'):\n        return int(num_clauses * float(spec[:-1]) / 100)\n\n    if '<' in spec:\n        lower, upper = spec.split('<')\n        if lower.isdigit():\n            lower = int(lower)\n        else:\n            lower = int(num_clauses * float(lower[:-1]) / 100)\n        if upper.isdigit():\n            upper = int(upper)\n        else:\n            upper = int(num_clauses * float(upper[:-1]) / 100)\n        return np.random.randint(lower, upper + 1)\n\n    raise ValueError(f'Invalid mm specification: {spec}')\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isnumeric():\n        return int(spec)\n\n    if spec[-1] == '%':\n        return int(num_clauses * float(spec[:-1]) / 100)\n\n    if '<' in spec:\n        min_clauses, max_clauses = spec.split('<')\n        return int(np.random.uniform(int(min_clauses), int(max_clauses)))\n\n    raise ValueError(f'Could not parse mm spec: {spec}')\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if re.match(r\"^\\d+$\", spec):\n        return int(spec)\n    elif re.match(r\"^\\d+\\.\\d+$\", spec):\n        return int(float(spec) * num_clauses)\n    elif re.match(r\"^\\d+%$\", spec):\n        return int(float(spec[:-1]) / 100 * num_clauses)\n    elif re.match(r\"^\\d+%$\", spec):\n        return int(float(spec[:-1]) / 100 * num_clauses)\n    elif re.match(r\"^<\\d+$\", spec):\n        return int(spec[1:])\n    elif re.match(r\"^<\\d+\\.\\d+$\", spec):\n        return int(float(spec[1:]) * num_clauses)\n    elif re.match(r\"^<\\d+%$\", spec):\n        return int(float(spec[1:-1]) / 100 * num_clauses)\n    else:\n        raise ValueError(\n            \"min_should_match specification must be an absolute number, percentage, or conditional expression.\"\n        )\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # Check if the spec is a percentage\n    if spec.endswith('%'):\n        return int(num_clauses * float(spec[:-1]) / 100.0)\n\n    # Check if the spec is an absolute number\n    if spec.isdigit():\n        return int(spec)\n\n    # Check if the spec is a conditional expression\n    if spec.startswith('<'):\n        if spec.endswith('%'):\n            return int(num_clauses * float(spec[1:-1]) / 100.0)\n        return int(num_clauses * float(spec[1:]))\n\n    raise ValueError(f'Invalid mm spec: {spec}')\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.endswith('%'):\n        return int(round(num_clauses * float(spec[:-1]) / 100))\n    elif spec.endswith('<'):\n        return int(spec[:-1])\n    else:\n        return int(spec)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():\n        return int(spec)\n\n    if re.match(r'^\\d+\\%$', spec):\n        return int(round(num_clauses * float(spec[:-1]) / 100))\n\n    if re.match(r'^>\\d+\\%$', spec):\n        return max(1, int(round(num_clauses * float(spec[1:-1]) / 100)))\n\n    raise ValueError(f\"Unknown min_should_match specification: {spec}\")\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if not isinstance(num_clauses, int) or num_clauses < 1:\n        raise ValueError(\"num_clauses must be a positive integer\")\n    if not isinstance(spec, str) or len(spec) == 0:\n        raise ValueError(\"spec must be a non-empty string\")\n\n    if spec.isnumeric():\n        return int(spec)\n    elif spec.endswith(\"%\"):\n        return int(float(spec[:-1]) / 100.0 * num_clauses)\n    elif \">\" in spec:\n        cond_spec = spec.split(\">\")\n        if len(cond_spec) != 2:\n            raise ValueError(\n                \"conditional specification must be of the form 'min_should_match>threshold'\"\n            )\n        threshold = float(cond_spec[1])\n        if threshold < 0 or threshold > 1:\n            raise ValueError(\"threshold must be between 0 and 1\")\n        return int(num_clauses * threshold)\n    else:\n        raise ValueError(\n            \"min_should_match must be a positive integer, a percentage, or a conditional expression\"\n        )\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec == \"100%\":\n        return num_clauses\n\n    # Split the spec into its components.\n    spec_components = re.split(r\"([<>=]+)\", spec)\n    spec_components = [comp for comp in spec_components if comp]\n\n    # If there is only one component, it must be an absolute number.\n    if len(spec_components) == 1:\n        return int(spec_components[0])\n\n    # If there are two components, the first must be an absolute number and the second must be a percentage.\n    if len(spec_components) == 2:\n        return int(spec_components[0]) + int(spec_components[0]) * int(spec_components[1]) / 100\n\n    # If there are three components, the first must be an absolute number, the second must be a percentage, and the third must be a conditional expression.\n    if len(spec_components) == 3:\n        if spec_components[1] == \"<\":\n            return int(spec_components[0]) + int(spec_components[0]) * int(spec_components[2]) / 100\n        else:\n            raise ValueError(f\"Invalid conditional expression in 'mm' spec: '{spec_components[1]}'\")\n\n    # If there are more than three components, something is wrong.\n    raise ValueError(f\"Invalid 'mm' spec: '{spec}'\")\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # Check for absolute number of clauses that must match\n    if spec.isdigit():\n        return int(spec)\n\n    # Check for percentage of clauses that must match\n    elif spec.endswith('%'):\n        return int(float(spec[:-1]) / 100 * num_clauses)\n\n    # Check for conditional expression\n    elif spec.startswith('<'):\n        # Parse the conditional expression\n        num_clauses_min = int(spec[1:])\n        if num_clauses_min > num_clauses:\n            raise ValueError(\n                'Conditional expression in mm spec cannot have a minimum value greater than the total number of clauses in the query.'\n            )\n        return num_clauses - num_clauses_min + 1\n\n    else:\n        raise ValueError(\n            'Invalid specification for min should match. Must be an absolute number, percentage, or conditional expression.'\n        )\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # if the 'mm' spec is an absolute number, we can just return it\n    if spec.isdigit():\n        return int(spec)\n\n    # if the 'mm' spec is a percentage, we can calculate the minimum number of clauses that must match\n    if spec.endswith(\"%\"):\n        return int(round(num_clauses * float(spec[:-1]) / 100))\n\n    # if the 'mm' spec is a conditional expression, we need to parse it\n    if spec.startswith(\"<\"):\n\n        # if the condition is a percentage, we can calculate the minimum number of clauses that must match\n        if spec[1].endswith(\"%\"):\n            return int(round(num_clauses * float(spec[1:-1]) / 100))\n\n        # otherwise, we can just return the condition as an int\n        return int(spec[1:])\n\n    raise ValueError(\"Unable to parse 'mm' spec: {}\".format(spec))\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # Check if the 'mm' spec is an absolute number.\n    try:\n        mm = int(spec)\n        if mm < 0:\n            raise ValueError\n        return mm\n    except ValueError:\n        pass\n\n    # Check if the 'mm' spec is a percentage.\n    if re.match(r'^\\d+%$', spec):\n        mm = int(spec[:-1]) / 100 * num_clauses\n        return max(1, mm)\n\n    # Check if the 'mm' spec is a conditional expression.\n    if re.match(r'^<(\\d+|[\\d\\.]+%)$', spec):\n        mm = int(spec[1:])\n        if mm < 0:\n            raise ValueError\n        return max(1, mm)\n\n    raise ValueError(f\"Invalid 'mm' spec '{spec}'.\")\n\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if not isinstance(spec, str):\n        raise TypeError(\n            \"The 'min_should_match' specification must be a string.\")\n\n    if spec.isnumeric():\n        return int(spec)\n\n    if spec.endswith('%'):\n        return int(num_clauses * float(spec.strip('%')) / 100)\n\n    if '<' in spec:\n        cond_spec = spec.split('<')\n        if len(cond_spec) != 2:\n            raise ValueError(\n                \"The 'min_should_match' specification is invalid. \"\n                \"A conditional specification must be of the form 'min_should_match: x < y'.\"\n            )\n        return int(cond_spec[0]) if int(cond_spec[0]) < int(cond_spec[1]) else int(cond_spec[1])\n\n    raise ValueError(\n        \"The 'min_should_match' specification is invalid. \"\n        \"It must be a number, a percentage, or a conditional expression of the form 'x < y'.\"\n    )\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # Parse the specification\n    if spec.endswith('%'):\n        # Percentage-based specification\n        percent = float(spec[:-1])\n        return int(np.ceil(percent * num_clauses / 100))\n    elif spec.isdigit():\n        # Absolute specification\n        return int(spec)\n    else:\n        # Conditional specification\n        if '<' in spec:\n            # Parse the conditional specification\n            if spec[1] == '=':\n                # Parse the conditional specification with an equality condition\n                condition = spec[2]\n                condition_value = int(spec[3:-1])\n                if condition == '*':\n                    # Parse the conditional specification with an equality condition and a wildcard\n                    return num_clauses - condition_value + 1\n                elif condition == '+':\n                    # Parse the conditional specification with an equality condition and a plus\n                    return condition_value\n                else:\n                    # Parse the conditional specification with an equality condition and a specified number\n                    return condition_value\n            else:\n                # Parse the conditional specification with a less-than condition\n                condition = spec[1]\n                condition_value = int(spec[2:-1])\n                if condition == '*':\n                    # Parse the conditional specification with a less-than condition and a wildcard\n                    return condition_value - num_clauses + 1\n                elif condition == '+':\n                    # Parse the conditional specification with a less-than condition and a plus\n                    return num_clauses - condition_value\n                else:\n                    # Parse the conditional specification with a less-than condition and a specified number\n                    return num_clauses - condition_value\n        else:\n            raise ValueError(f'The mm spec {spec} is not valid.')\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # Regex to match absolute numbers and percentages\n    num_spec = re.compile(r'^[0-9]+$')\n    perc_spec = re.compile(r'^[0-9]+%$')\n\n    # Regex to match conditional expressions\n    cond_spec = re.compile(r'^<[0-9]+%$')\n\n    # If the spec is a number, return it\n    if num_spec.match(spec):\n        return int(spec)\n\n    # If the spec is a percentage, return the corresponding number of clauses\n    if perc_spec.match(spec):\n        return int(float(spec.strip('%')) / 100 * num_clauses)\n\n    # If the spec is a conditional expression, parse the percentage and return the corresponding number of clauses\n    if cond_spec.match(spec):\n        return int(float(spec.strip('<')) / 100 * num_clauses)\n\n    # If the spec is neither a number, percentage, nor a conditional expression, raise an error\n    raise ValueError(\"Invalid 'min should match' specification: {}\".format(spec))\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # Parse the specification as a float\n    try:\n        spec_val = float(spec)\n    except:\n        raise ValueError(\"mm spec must be a float.\")\n\n    # If the specification is a percentage, calculate the minimum number of clauses that must match\n    if 0 <= spec_val <= 1:\n        return int(num_clauses * spec_val)\n\n    # If the specification is an absolute number, return it\n    if spec_val > 0:\n        return int(spec_val)\n\n    # If the specification is a conditional expression, parse it and calculate the minimum number of clauses that must match\n    if spec.startswith(\"<\"):\n        if len(spec) == 1:\n            raise ValueError(\"mm spec must be a float.\")\n        if spec[1] != \"=\":\n            raise ValueError(\"mm spec must be a float.\")\n        if spec.endswith(\"%\"):\n            percent = float(spec[2:-1])\n            return int(num_clauses * percent / 100)\n        else:\n            num = float(spec[2:])\n            return int(num)\n\n    # If the specification is not a float, raise an error\n    raise ValueError(\"mm spec must be a float.\")\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # If the 'min should match' specification is an absolute number, return it.\n    if spec.isnumeric():\n        return int(spec)\n\n    # If the 'min should match' specification is a percentage, return the corresponding number of clauses.\n    if spec[-1] == '%':\n        return int(spec[:-1]) * num_clauses / 100\n\n    # If the 'min should match' specification is a conditional expression, parse it and return the corresponding number of clauses.\n    if spec[0] == '<':\n        if spec[1:].isnumeric():\n            return num_clauses - int(spec[1:])\n        else:\n            raise ValueError(\n                f\"The conditional expression {spec} in the 'min should match' specification is invalid. Conditional expressions must be in the form '<n', where 'n' is an integer.\")\n\n    # If the 'min should match' specification is not a valid absolute number, percentage, or conditional expression, raise an error.\n    raise ValueError(\n        f\"The 'min should match' specification {spec} is invalid. It must be an absolute number, percentage, or conditional expression.\")\n\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # Absolute specification\n    if re.match(r'^\\d+$', spec):\n        return int(spec)\n\n    # Percentage specification\n    elif re.match(r'^\\d+%$', spec):\n        return int(num_clauses * float(spec[:-1]) / 100)\n\n    # Conditional specification\n    elif re.match(r'^<(\\d+%?)$', spec):\n        return int(num_clauses * float(spec[1:-1]) / 100)\n\n    else:\n        raise ValueError('Invalid min_should_match specification.')\n\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # Check if the tokens are unique\n        if len(set(tokens)) != len(tokens):\n            return self._phrase_freq_non_unique_tokens(tokens, slop)\n        else:\n            return self._phrase_freq_unique_tokens(tokens, slop)\n\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # If slop is 1 and tokens are unique, calculate the phrase frequencies directly using the positions of terms.\n        if slop == 1 and len(set(tokens)) == len(tokens):\n            return self._phrase_freq_unique_tokens(tokens)\n\n        # Otherwise, calculate the phrase frequencies using the positions of terms.\n        return self._phrase_freq_non_unique_tokens(tokens, slop)\n\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop != 1 or len(set(tokens)) != len(tokens):\n            return self._phrase_freq_slow(tokens, slop)\n        else:\n            return self._phrase_freq_fast(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # Check if the slop is 1 and if the tokens are unique\n        if slop == 1 and len(set(tokens)) == len(tokens):\n            return self._phrase_freq_slop_1_unique_tokens(tokens)\n        else:\n            return self._phrase_freq_slop_n(tokens, slop)\n\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # If slop is 1 and all tokens are unique, we can calculate the phrase frequencies directly using the positions of terms.\n        if slop == 1 and len(set(tokens)) == len(tokens):\n            return self._phrase_freq_slop_1_unique_tokens(tokens)\n        # Otherwise, we delegate the calculation to another method.\n        else:\n            return self._phrase_freq_slop_n_non_unique_tokens(tokens, slop)\n\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop != 1:\n            return self.phrase_freq_slow(tokens, slop)\n        else:\n            return self.phrase_freq_fast(tokens)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # If slop is 1 and all tokens are unique, calculate the phrase frequency directly using the positions of terms.\n        if slop == 1 and len(set(tokens)) == len(tokens):\n            return self._phrase_freq_slop_1_unique_tokens(tokens)\n\n        # Otherwise, calculate the phrase frequency using another method that handles different slop or non-unique tokens.\n        return self._phrase_freq_slop_not_1_or_unique_tokens(tokens, slop)\n\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop != 1 or len(set(tokens)) != len(tokens):\n            return self.phrase_freq_slow(tokens, slop)\n\n        # If the slop is 1 and all tokens are unique, we can directly calculate the phrase frequencies using the positions of terms.\n        else:\n            # Get the positions of the tokens in the SearchArray instance.\n            token_positions = [self.positions(token) for token in tokens]\n\n            # Calculate the phrase frequencies.\n            phrase_freqs = self._calculate_phrase_freqs(token_positions)\n\n            return phrase_freqs\n\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # If slop is 1 and tokens are unique, try to calculate phrase freq directly\n        if slop == 1 and len(set(tokens)) == len(tokens):\n            return self._phrase_freq_direct(tokens)\n        else:\n            return self._phrase_freq_general(tokens, slop)\n\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # If the slop is 1 and all tokens are unique, we can calculate the phrase frequencies directly using the positions of terms.\n        if slop == 1 and len(set(tokens)) == len(tokens):\n            return self._phrase_freq_slop_1_unique_tokens(tokens)\n        # Otherwise, we need to calculate the phrase frequencies using the positions of terms.\n        else:\n            return self._phrase_freq_slop_not_1_or_unique_tokens(tokens, slop)\n\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop != 1 or len(set(tokens)) != len(tokens):\n            return self.phrase_freq_slow(tokens, slop)\n\n        token_ids = [self.term_dict.get_term_id(token) for token in tokens]\n        term_freqs = self.termfreqs(token_ids)\n        doc_ids, term_positions = self.posns.positions(token_ids[0])\n        for token_id in token_ids[1:]:\n            new_doc_ids, new_term_positions = self.posns.positions(token_id)\n            doc_ids = np.intersect1d(doc_ids, new_doc_ids)\n            term_positions = np.intersect1d(term_positions, new_term_positions)\n\n        if len(doc_ids) == 0:\n            return np.zeros(len(self))\n\n        posn_diffs = np.diff(term_positions)\n        mask = posn_diffs <= slop\n        term_freqs[doc_ids] += 1\n        term_freqs[doc_ids[mask]] -= 1\n        return term_freqs\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # If slop is 1, we can directly calculate the phrase frequencies using the positions of terms.\n        if slop == 1:\n            # If tokens are unique, we can directly calculate the phrase frequencies using the positions of terms.\n            if len(set(tokens)) == len(tokens):\n                return self._phrase_freq_unique_tokens_slop_1(tokens)\n            # If tokens are not unique, we can calculate the phrase frequencies using the positions of terms.\n            else:\n                return self._phrase_freq_non_unique_tokens_slop_1(tokens)\n        # If slop is not 1, we cannot directly calculate the phrase frequencies using the positions of terms.\n        else:\n            return self._phrase_freq_unique_tokens_non_slop_1(tokens, slop)\n\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # Check if tokens are unique and slop is 1\n        if len(set(tokens)) == len(tokens) and slop == 1:\n            return self._phrase_freq_unique_tokens_slop_1(tokens)\n        else:\n            return self._phrase_freq_general(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # Check if tokens are unique. If not, delegate to the slower method.\n        if len(set(tokens)) != len(tokens):\n            return self._phrase_freq_slow(tokens, slop)\n\n        # Check if slop is 1. If so, delegate to the faster method.\n        elif slop == 1:\n            return self._phrase_freq_fast(tokens)\n\n        # Otherwise, delegate to the slower method.\n        else:\n            return self._phrase_freq_slow(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(set(tokens)) == len(tokens):\n            return self.phrase_freq_with_slop_1_and_unique_tokens(tokens)\n        else:\n            return self.phrase_freq_with_slop_not_1_or_unique_tokens(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if len(tokens) == 1:\n            return self.termfreqs(tokens[0])\n\n        if slop > 1:\n            return self._phrase_freq_slop(tokens, slop)\n\n        if len(set(tokens)) == len(tokens):\n            return self._phrase_freq_unique_terms(tokens, slop)\n\n        return self._phrase_freq_non_unique_terms(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # If the slop is not 1 or tokens are not unique, we must use a slower method\n        if slop != 1 or len(set(tokens)) != len(tokens):\n            return self.phrase_freq_slow(tokens, slop)\n\n        # If the slop is 1 and tokens are unique, we can calculate the phrase frequencies directly\n        else:\n            # Get the positions of the tokens\n            token_positions = [self.positions(token) for token in tokens]\n\n            # Calculate the phrase frequencies\n            return self.phrase_freq_direct(token_positions)\n\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if len(tokens) == 0:\n            return np.zeros(len(self), dtype=int)\n\n        if slop == 1 and len(set(tokens)) == len(tokens):\n            return self._phrase_freq_adjacent_tokens(tokens)\n        else:\n            return self._phrase_freq_non_adjacent_tokens(tokens, slop)\n\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop != 1 or len(set(tokens)) != len(tokens):\n            return self.phrase_freq_slow(tokens, slop)\n\n        # Get the positions of the first token in the phrase\n        first_token = tokens[0]\n        first_token_posns = self.positions(first_token)\n\n        # If the token does not appear in the SearchArray instance, return an array of zeros\n        if len(first_token_posns) == 0:\n            return np.zeros(len(self))\n\n        # Get the positions of the other tokens in the phrase\n        other_token_posns = [self.positions(token) for token in tokens[1:]]\n\n        # Get the position of the last token in the phrase\n        last_token_posns = other_token_posns[-1]\n\n        # Get the positions of the tokens that are within the slop window of the last token in the phrase\n        last_token_slop_posns = scan_merge_ins(last_token_posns, slop)\n\n        # Get the positions of the tokens that are within the slop window of the first token in the phrase\n        first_token_slop_posns = scan_merge_ins(first_token_posns, slop)\n\n        # Get the positions of the tokens that are within the slop window of the first token in the phrase\n        # and the positions of the tokens that are within the slop window of the last token in the phrase\n        slop_posns = scan_merge_ins(first_token_slop_posns, slop, other_token_posns)\n\n        # Get the positions of the tokens that are within the slop window of the first token in the phrase\n        # and the positions of the tokens that are within the slop window of the last token in the phrase\n        # and are within the slop window of each other\n        posns = scan_merge_ins(slop_posns, slop)\n\n        # Get the number of documents that contain the phrase\n        phrase_freqs = compute_phrase_freqs(pos"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop != 1:\n            return self.phrase_freq_non_unique(tokens, slop)\n\n        if len(tokens) == 0:\n            return np.zeros(len(self), dtype=int)\n\n        if len(tokens) == 1:\n            return self.termfreqs(tokens[0])\n\n        # If slop is 1 and all tokens are unique, we can directly calculate the phrase frequencies using the positions of terms.\n        if len(set(tokens)) == len(tokens):\n            positions = [self.positions(token) for token in tokens]\n            return self.phrase_freq_unique_tokens(tokens, positions)\n\n        # If slop is 1 and tokens are not unique, we delegate the calculation to another method.\n        return self.phrase_freq_non_unique(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        term_mat, posns, term_dict, avg_doc_length, doc_lens = build_index_from_terms_list(array, Terms, tokenizer,\n                                                                                           truncate, batch_size,\n                                                                                           avoid_copies)\n        return cls(term_mat, tokenizer, avoid_copies)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        term_mat, posns, term_dict, avg_doc_length, doc_lens = build_index_from_terms_list(\n            array, Terms, tokenizer, truncate, batch_size, avoid_copies)\n\n        return cls(term_mat, tokenizer, avoid_copies)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        term_mat, posns, term_dict, avg_doc_length, doc_lens = build_index_from_terms_list(array, Terms, tokenizer,\n                                                                                            truncate, batch_size,\n                                                                                            avoid_copies)\n        return cls(term_mat, tokenizer, avoid_copies)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        term_mat, posns, \\\n            term_dict, avg_doc_length, \\\n            doc_lens = build_index_from_terms_list(array, Terms,\n                                                   tokenizer=tokenizer,\n                                                   truncate=truncate,\n                                                   batch_size=batch_size,\n                                                   avoid_copies=avoid_copies)\n        return cls(term_mat, tokenizer=tokenizer, avoid_copies=avoid_copies)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check if the input array is empty\n        if len(array) == 0:\n            raise ValueError(\"The input array is empty\")\n\n        # Check if the input array is a list\n        if not isinstance(array, list):\n            raise ValueError(\"The input array is not a list\")\n\n        # Check if the input array is a list of strings\n        if not isinstance(array[0], str):\n            raise ValueError(\"The input array is not a list of strings\")\n\n        # Check if the tokenizer is a function\n        if not callable(tokenizer):\n            raise ValueError(\"The tokenizer is not a function\")\n\n        # Check if the truncate parameter is a boolean\n        if not isinstance(truncate, bool):\n            raise ValueError(\"The truncate parameter is not a boolean\")\n\n        # Check if the batch_size parameter is an integer\n        if not isinstance(batch_size, int):\n            raise ValueError(\"The batch_size parameter is not an integer\")\n\n        # Check if the avoid_copies parameter is a boolean\n        if not isinstance(avoid_copies, bool):\n            raise ValueError(\"The avoid_copies parameter is not a boolean\")\n\n        # Check if the batch_size parameter is a valid integer\n        if batch_size <= 0:\n            raise ValueError(\"The batch_size parameter is not a valid integer\")\n\n        # Check if the avoid_copies parameter is a valid boolean\n        if not (avoid_copies):\n            raise ValueError(\"The avoid_copies parameter is not a valid boolean\")\n\n        # Check if the truncate parameter is a valid boolean\n        if not (truncate):\n            raise ValueError(\"The truncate parameter is not a valid boolean\")\n\n        # Check if the batch_size parameter is a valid integer\n        if batch_size <= 0:\n            raise ValueError(\"The batch_size parameter is not a valid integer\")\n\n        # Check if the avoid_copies parameter is a valid boolean\n        if not (avoid_copies):\n            raise ValueError(\"The avoid_copies parameter is not a valid boolean\")\n\n        # Check if"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check array, raise TypeError\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Check tokenizer, raise TypeError\n        if not callable(tokenizer):\n            raise TypeError(\"Expected a callable object, got {}\".format(type(tokenizer)))\n\n        # Check batch_size, raise TypeError\n        if not isinstance(batch_size, int):\n            raise TypeError(\"Expected an integer, got {}\".format(type(batch_size)))\n\n        # Check truncate, raise TypeError\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected a boolean, got {}\".format(type(truncate)))\n\n        # Check avoid_copies, raise TypeError\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected a boolean, got {}\".format(type(avoid_copies)))\n\n        # Check if array is empty, raise ValueError\n        if len(array) == 0:\n            raise ValueError(\"Expected a non-empty array\")\n\n        # Check if batch_size is negative, raise ValueError\n        if batch_size < 0:\n            raise ValueError(\"Expected a positive batch_size\")\n\n        # Check if truncate is negative, raise ValueError\n        if truncate and batch_size < 0:\n            raise ValueError(\"Expected a positive batch_size\")\n\n        # Check if avoid_copies is negative, raise ValueError\n        if avoid_copies and batch_size < 0:\n            raise ValueError(\"Expected a positive batch_size\")\n\n        # Check if tokenizer is None, raise ValueError\n        if tokenizer is None:\n            raise ValueError(\"Expected a callable object, got {}\".format(type(tokenizer)))\n\n        # Check if tokenizer is None, raise ValueError\n        if tokenizer is None:\n            raise ValueError(\"Expected a callable object, got {}\".format(type(tokenizer)))\n\n        # Check if tokenizer is None, raise ValueError\n        if tokenizer is None:\n           "}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        if not callable(tokenizer):\n            raise TypeError(\"Expected a callable tokenizer, got {}\".format(type(tokenizer)))\n\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected a bool for truncate, got {}\".format(type(truncate)))\n\n        if not isinstance(batch_size, int):\n            raise TypeError(\"Expected an int for batch_size, got {}\".format(type(batch_size)))\n\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected a bool for avoid_copies, got {}\".format(type(avoid_copies)))\n\n        term_mat, posns, term_dict, avg_doc_length, doc_lens = build_index_from_terms_list(array, Terms, tokenizer,\n                                                                                           truncate, batch_size,\n                                                                                           avoid_copies)\n\n        return cls(term_mat, tokenizer, avoid_copies)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        if not callable(tokenizer):\n            raise TypeError(\"Expected callable object, got {}\".format(type(tokenizer)))\n\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected boolean, got {}\".format(type(truncate)))\n\n        if not isinstance(batch_size, int):\n            raise TypeError(\"Expected int, got {}\".format(type(batch_size)))\n\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected boolean, got {}\".format(type(avoid_copies)))\n\n        if batch_size < 1:\n            raise ValueError(\"Expected batch_size >= 1, got {}\".format(batch_size))\n\n        if truncate:\n            raise NotImplementedError(\"Truncation not yet implemented\")\n\n        if avoid_copies:\n            raise NotImplementedError(\"Avoiding copies not yet implemented\")\n\n        term_mat, posns, term_dict, avg_doc_length, doc_lens = build_index_from_terms_list(array, Terms, batch_size=batch_size, tokenizer=tokenizer)\n\n        return cls(term_mat, tokenizer=tokenizer, avoid_copies=avoid_copies)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n        if not isinstance(tokenizer, types.FunctionType):\n            raise TypeError(\"Expected a function for tokenizer, got {}\".format(type(tokenizer)))\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected a boolean for truncate, got {}\".format(type(truncate)))\n        if not isinstance(batch_size, int):\n            raise TypeError(\"Expected an integer for batch_size, got {}\".format(type(batch_size)))\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected a boolean for avoid_copies, got {}\".format(type(avoid_copies)))\n\n        term_mat, posns, term_dict, avg_doc_length, doc_lens = build_index_from_terms_list(array, Terms, tokenizer,\n                                                                                           truncate, batch_size,\n                                                                                           avoid_copies)\n\n        return cls(term_mat, tokenizer, avoid_copies)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check input-output arguments\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n        if not callable(tokenizer):\n            raise TypeError(\"Expected a callable tokenizer, got {}\".format(type(tokenizer)))\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected a bool for truncate, got {}\".format(type(truncate)))\n        if not isinstance(batch_size, int):\n            raise TypeError(\"Expected an int for batch_size, got {}\".format(type(batch_size)))\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected a bool for avoid_copies, got {}\".format(type(avoid_copies)))\n\n        # Check memory constraints\n        if not truncate:\n            if sys.maxsize > 2 ** 32:\n                if array.shape[0] * array.shape[1] > 2 ** 31:\n                    raise MemoryError(\"Array is too large to fit in memory. \"\n                                      \"Consider using truncate=True.\")\n            else:\n                if array.shape[0] * array.shape[1] > 2 ** 30:\n                    raise MemoryError(\"Array is too large to fit in memory. \"\n                                      \"Consider using truncate=True.\")\n\n        # Check tokenizer\n        if not callable(tokenizer):\n            raise TypeError(\"Expected a callable tokenizer, got {}\".format(type(tokenizer)))\n\n        # Check batch_size\n        if not isinstance(batch_size, int):\n            raise TypeError(\"Expected an int for batch_size, got {}\".format(type(batch_size)))\n\n        # Check avoid_copies\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected a bool for avoid_copies, got {}\".format(type(avoid_copies)))\n\n        # Check truncate\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected a"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        if not isinstance(tokenizer, types.FunctionType):\n            raise TypeError(\"Expected a function for tokenizer, got {}\".format(type(tokenizer)))\n\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected a boolean for truncate, got {}\".format(type(truncate)))\n\n        if not isinstance(batch_size, int):\n            raise TypeError(\"Expected an integer for batch_size, got {}\".format(type(batch_size)))\n\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected a boolean for avoid_copies, got {}\".format(type(avoid_copies)))\n\n        if truncate:\n            if not isinstance(batch_size, int):\n                raise TypeError(\"Expected an integer for batch_size, got {}\".format(type(batch_size)))\n\n        if truncate and batch_size > 10000000:\n            raise ValueError(\"batch_size cannot be greater than 10000000\")\n\n        if truncate and batch_size <= 0:\n            raise ValueError(\"batch_size must be greater than 0\")\n\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected a boolean for avoid_copies, got {}\".format(type(avoid_copies)))\n\n        if avoid_copies:\n            if not isinstance(batch_size, int):\n                raise TypeError(\"Expected an integer for batch_size, got {}\".format(type(batch_size)))\n\n        if avoid_copies and batch_size > 10000000:\n            raise ValueError(\"batch_size cannot be greater than 10000000\")\n\n        if avoid_copies and batch_size <= 0:\n            raise ValueError(\"batch_size must be greater than 0\")\n\n        if truncate:\n            if not isinstance(batch_size,"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        if not callable(tokenizer):\n            raise TypeError(\"Expected callable tokenizer, got {}\".format(type(tokenizer)))\n\n        if not isinstance(batch_size, int) or batch_size < 1:\n            raise TypeError(\"Expected positive integer for batch_size, got {}\".format(batch_size))\n\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected boolean for truncate, got {}\".format(truncate))\n\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected boolean for avoid_copies, got {}\".format(avoid_copies))\n\n        term_mat, posns, term_dict, avg_doc_length, doc_lens = build_index_from_terms_list(array, Terms, tokenizer, truncate, batch_size, avoid_copies)\n\n        return cls(term_mat, tokenizer, avoid_copies)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # check if array is iterable\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # check if tokenizer is callable\n        if not callable(tokenizer):\n            raise TypeError(\"Expected callable object, got {}\".format(type(tokenizer)))\n\n        # check if truncate is bool\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(truncate)))\n\n        # check if batch_size is int\n        if not isinstance(batch_size, int):\n            raise TypeError(\"Expected int, got {}\".format(type(batch_size)))\n\n        # check if avoid_copies is bool\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(avoid_copies)))\n\n        # check if batch_size is greater than 0\n        if batch_size < 0:\n            raise ValueError(\"Expected batch_size to be greater than 0, got {}\".format(batch_size))\n\n        # check if truncate is True and batch_size is greater than 0\n        if truncate and batch_size > 0:\n            raise ValueError(\"Expected batch_size to be 0 if truncate is True, got {}\".format(batch_size))\n\n        # check if avoid_copies is False and truncate is False\n        if not avoid_copies and not truncate:\n            raise ValueError(\"Expected avoid_copies to be True if truncate is False, got {}\".format(avoid_copies))\n\n        # check if avoid_copies is True and truncate is True\n        if avoid_copies and truncate:\n            raise ValueError(\"Expected avoid_copies to be False if truncate is True, got {}\".format(avoid_copies))\n\n        # check if array is empty\n        if len(array) == 0:\n            raise ValueError(\"Expected array to be non-empty, got {}\".format(array))"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n        if not isinstance(tokenizer, callable):\n            raise TypeError(\"Expected a callable tokenizer, got {}\".format(type(tokenizer)))\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected a bool for truncate, got {}\".format(type(truncate)))\n        if not isinstance(batch_size, int):\n            raise TypeError(\"Expected an int for batch_size, got {}\".format(type(batch_size)))\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected a bool for avoid_copies, got {}\".format(type(avoid_copies)))\n\n        if truncate:\n            array = array[:batch_size]\n        else:\n            if len(array) > batch_size:\n                warnings.warn(f\"Indexing {len(array)} documents. \"\n                              f\"Consider using batch_size={len(array)} to avoid truncation.\")\n\n        term_mat, posns, \\\n            term_dict, avg_doc_length, \\\n            doc_lens = build_index_from_terms_list(array, Terms, tokenizer=tokenizer,\n                                                   avoid_copies=avoid_copies)\n        return cls(term_mat, tokenizer=tokenizer, avoid_copies=avoid_copies)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        term_mat, posns, \\\n            term_dict, avg_doc_length, \\\n            doc_lens = build_index_from_terms_list(array, Terms, tokenizer,\n                                                   truncate, batch_size, avoid_copies)\n        return cls(term_mat, tokenizer, avoid_copies)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        if not callable(tokenizer):\n            raise TypeError(\"Expected a callable tokenizer, got {}\".format(type(tokenizer)))\n\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected a boolean for truncate, got {}\".format(type(truncate)))\n\n        if not isinstance(batch_size, int):\n            raise TypeError(\"Expected an integer for batch_size, got {}\".format(type(batch_size)))\n\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected a boolean for avoid_copies, got {}\".format(type(avoid_copies)))\n\n        term_mat, posns, term_dict, avg_doc_length, doc_lens = build_index_from_terms_list(array, Terms,\n                                                                                           tokenizer=tokenizer,\n                                                                                           truncate=truncate,\n                                                                                           batch_size=batch_size,\n                                                                                           avoid_copies=avoid_copies)\n\n        return cls(term_mat, tokenizer=tokenizer, avoid_copies=avoid_copies)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check input arguments\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Check tokenizer\n        if not callable(tokenizer):\n            raise TypeError(\"Expected callable object, got {}\".format(type(tokenizer)))\n\n        # Check batch_size\n        if not isinstance(batch_size, int):\n            raise TypeError(\"Expected int, got {}\".format(type(batch_size)))\n\n        # Check truncate\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(truncate)))\n\n        # Check avoid_copies\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(avoid_copies)))\n\n        # Check if the data is too big to fit in memory\n        if truncate:\n            # Compute the number of batches\n            num_batches = len(array) // batch_size\n            if len(array) % batch_size != 0:\n                num_batches += 1\n\n            # Compute the number of documents in the last batch\n            num_docs_last_batch = len(array) % batch_size\n            if num_docs_last_batch == 0:\n                num_docs_last_batch = batch_size\n\n            # Compute the number of documents in the first batch\n            num_docs_first_batch = batch_size - num_docs_last_batch\n\n            # Compute the number of terms in the first batch\n            num_terms_first_batch = num_docs_first_batch * sum(len(tokenizer(doc)) for doc in array[:batch_size])\n\n            # Compute the number of terms in the last batch\n            num_terms_last_batch = num_docs_last_batch * sum(len(tokenizer(doc)) for doc in array[-batch_size:])\n\n            # Compute the number of terms in the data\n            num_terms = num_docs_first_batch *"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # TODO: Add support for other tokenizers\n\n        # Check if the input is a list-like object\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Check if the input is a string\n        if isinstance(array, str):\n            raise TypeError(\"Expected an iterable object, got string\")\n\n        # Check if the tokenizer is a function\n        if not callable(tokenizer):\n            raise TypeError(\"Expected a function, got {}\".format(type(tokenizer)))\n\n        # Check if the truncate parameter is a boolean\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected a boolean, got {}\".format(type(truncate)))\n\n        # Check if the batch size is an integer\n        if not isinstance(batch_size, int):\n            raise TypeError(\"Expected an integer, got {}\".format(type(batch_size)))\n\n        # Check if the avoid copies parameter is a boolean\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected a boolean, got {}\".format(type(avoid_copies)))\n\n        # Check if the array is a string\n        if isinstance(array, str):\n            raise TypeError(\"Expected an iterable object, got string\")\n\n        # Check if the array is an empty list\n        if len(array) == 0:\n            raise ValueError(\"Expected a non-empty list\")\n\n        # Check if the batch size is greater than zero\n        if batch_size <= 0:\n            raise ValueError(\"Expected a positive integer for batch size\")\n\n        # Check if the array is a list of strings\n        if not all(isinstance(element, str) for element in array):\n            raise TypeError(\"Expected a list of strings\")\n\n        # Check if the truncate parameter is a boolean\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected a boolean, got {}\".format(type(truncate)))\n\n        # Check if the avoid copies parameter is a boolean\n        if not isinstance"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check input arguments\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        if not callable(tokenizer):\n            raise TypeError(\"Expected callable object, got {}\".format(type(tokenizer)))\n\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected boolean, got {}\".format(type(truncate)))\n\n        if not isinstance(batch_size, int):\n            raise TypeError(\"Expected integer, got {}\".format(type(batch_size)))\n\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected boolean, got {}\".format(type(avoid_copies)))\n\n        # Initialize variables\n        term_mat = []\n        posns = PosnBitArray()\n        term_dict = TermDict()\n        doc_lens = []\n        doc_len = 0\n        avg_doc_length = 0\n\n        # Initialize variables for batch processing\n        batch_counter = 0\n        batch_size_limit = batch_size\n        batch_index = 0\n\n        # Process the data in batches\n        for doc_id, doc in enumerate(array):\n            # Process batch\n            if batch_counter == batch_size_limit:\n                # Reset variables\n                batch_counter = 0\n                batch_size_limit = batch_size\n                batch_index += 1\n\n                # Process the batch\n                batch_term_mat, batch_posns, \\\n                    batch_term_dict, batch_avg_doc_length, \\\n                    batch_doc_lens = build_index_from_terms_list(batch_term_mat, Terms)\n\n                # Update variables\n                term_mat.append(batch_term_mat)\n                posns.append(batch_posns)\n                term_dict.update(batch_term_dict)\n                avg_doc_length += batch_avg_doc_length\n                doc_lens.append(batch_doc_lens)\n\n                #"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n        if not callable(tokenizer):\n            raise TypeError(\"Expected callable object, got {}\".format(type(tokenizer)))\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected boolean, got {}\".format(type(truncate)))\n        if not isinstance(batch_size, int):\n            raise TypeError(\"Expected integer, got {}\".format(type(batch_size)))\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected boolean, got {}\".format(type(avoid_copies)))\n        if batch_size <= 0:\n            raise ValueError(\"Expected batch_size > 0, got {}\".format(batch_size))\n\n        # Check if we need to truncate the data\n        if truncate:\n            # Check if the data is too large to fit in memory\n            if sys.getsizeof(array) > 1000000000:\n                raise MemoryError(\"Array is too large to fit in memory.\")\n            else:\n                # If not too large, truncate the data\n                array = array[:1000000]\n\n        # Check if we need to avoid copies\n        if avoid_copies:\n            # If we need to avoid copies, we need to check if the data is already in the right format\n            if isinstance(array, SearchArray):\n                return array\n            elif isinstance(array, pd.Series):\n                return SearchArray(array.values, tokenizer, avoid_copies)\n            elif isinstance(array, np.ndarray):\n                return SearchArray(array, tokenizer, avoid_copies)\n            else:\n                # If we can't avoid copies, we need to convert the data to a list\n                array = list(array)\n\n        # If we can't avoid copies, we need to convert the data to a list\n        array = list(array)\n\n        # If the data is too large to fit in memory, we need to process it in"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config)\n        self.server.start()\n        self.connections = {}\n        self.lock = threading.Lock()\n\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.connections = {}\n        self.lock = threading.Lock()\n\n        self.server = Server(self.config['serverHost'], self.config['serverPort'], self.logger)\n        self.server.start()\n\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.connections = {}\n        self.lock = threading.Lock()\n\n        self.server = Server(self.config['serverHost'], self.config['serverPort'], self.config['proxyHost'], self.config['proxyPort'], self.logger)\n        self.server.start()\n\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.connections = {}\n        self.lock = threading.Lock()\n\n        self.server = Server(self.config['serverHost'], self.config['serverPort'], self.logger)\n        self.server.start()\n\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.connections = {}\n        self.lock = threading.Lock()\n\n        strategy_name = self.config.get('strategy')\n        strategy_config = self.config.get('strategies').get(strategy_name)\n        strategy = get_strategy(strategy_name, strategy_config)\n        self.server = Server(self.config.get('serverHost'), self.config.get('serverPort'), strategy)\n        self.server.start()\n\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['serverHost'], self.config['serverPort'])\n        self.server.start()\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.connections = {}\n        self.lock = threading.Lock()\n\n        self.server = Server(\n            self.config['proxyHost'],\n            self.config['proxyPort'],\n            self.config['strategy'],\n            self.config['strategies'],\n            self.config['autoCloseConnections'],\n            self.config['multipleConnections'],\n            self.logger\n        )\n        self.server.start()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.connections = {}\n        self.lock = threading.Lock()\n\n        strategy = self.config.get('strategy')\n        self.server = Server(self.config.get('serverHost'), self.config.get('serverPort'), strategy, self.config.get('strategies').get(strategy))\n        self.server.start()\n\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['serverHost'], self.config['serverPort'])\n        self.server.init(self.config)\n        self.server.start()\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['serverHost'], self.config['serverPort'], self.logger)\n        self.server.start()\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['serverHost'], self.config['serverPort'], self.logger)\n        self.server.start()\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.connections = {}\n        self.lock = threading.Lock()\n        self.server = Server(self.config['serverHost'], self.config['serverPort'])\n        self.server.start()\n        self.logger.info('Proxifier started')\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(\n            self.config['serverHost'],\n            self.config['serverPort'],\n            self.config['proxyHost'],\n            self.config['proxyPort'],\n            self.config['strategy'],\n            self.config['strategies'],\n            self.logger,\n        )\n        self.server.start()\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.connections = {}\n        self.lock = threading.Lock()\n\n        self.server = Server(self.config['serverHost'], self.config['serverPort'], self.config['proxyHost'], self.config['proxyPort'])\n        self.server.start()\n\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.connections = {}\n        self.lock = threading.Lock()\n\n        strategy_name = self.config['strategy']\n        strategy_config = self.config['strategies'][strategy_name]\n\n        strategy = STRATEGIES[strategy_name](strategy_config)\n\n        self.server = Server(self.config['serverHost'], self.config['serverPort'], strategy)\n        self.server.start()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.connections = {}\n        self.lock = threading.Lock()\n        self.server = Server(self.config['serverHost'], self.config['serverPort'])\n        self.server.start()\n        self.logger.info('Server started on port %s', self.config['serverPort'])\n\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['serverHost'], self.config['serverPort'], self.logger)\n        self.server.start()\n        self.connections = {}\n        self.lock = threading.Lock()\n\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.connections = {}\n        self.lock = threading.Lock()\n\n        self.server = Server(self.config['serverHost'], self.config['serverPort'], self.logger)\n        self.server.start()\n\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.connections = {}\n        self.lock = threading.Lock()\n\n        strategy = self.config.get('strategy')\n        self.server = Server(self.config.get('serverHost'), self.config.get('serverPort'), strategy, self.config.get('strategies'))\n        self.server.start()\n\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['serverHost'], self.config['serverPort'])\n        self.connections = {}\n        self.lock = threading.Lock()\n\n        self.server.start()\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # arr = np.asarray(arr, dtype=np.uint64)\n    # arr = np.asarray(arr, dtype=np.uint64)\n    # arr = np.asarray(arr, dtype=np.uint64)\n    # arr = np.asarray(arr, dtype=np.uint64)\n    # arr = np.asarray(arr, dtype=np.uint64)\n    # arr = np.asarray(arr, dtype=np.uint64)\n    # arr = np.asarray(arr, dtype=np.uint64)\n    # arr = np.asarray(arr, dtype=np.uint64)\n    # arr = np.asarray(arr, dtype=np.uint64)\n    # arr = np.asarray(arr, dtype=np.uint64)\n    # arr = np.asarray(arr, dtype=np.uint64)\n    # arr = np.asarray(arr, dtype=np.uint64)\n    # arr = np.asarray(arr, dtype=np.uint64)\n    # arr = np.asarray(arr, dtype=np.uint64)\n    # arr = np.asarray(arr, dtype=np.uint64)\n    # arr = np.asarray(arr, dtype=np.uint64)\n    # arr = np.asarray(arr, dtype=np.uint64)\n    # arr = np.asarray(arr, dtype=np.uint64)\n    # arr = np.asarray(arr, dtype=np.uint64)\n    # arr = np.asarray(arr, dtype=np.uint64)\n    # arr = np.asarray(arr, dtype=np.uint64)\n    # arr = np.asarray(arr, dtype=np.uint64)\n    # arr = np.asarray(arr, dtype=np.uint64)\n    # arr = np.asarray(arr, dtype=np.uint64)\n    # arr = np.asarray(arr, dtype=np.uint64)"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr = np.bitwise_and(arr, s55).astype(np.uint64)\n    arr = np.bitwise_and(arr, s33).astype(np.uint64)\n    arr = np.bitwise_and(arr, s0F).astype(np.uint64)\n    arr = np.bitwise_and(arr, s01).astype(np.uint64)\n\n    arr = np.bitwise_or(arr, np.right_shift(arr, _1)).astype(np.uint64)\n    arr = np.bitwise_or(arr, np.right_shift(arr, _2)).astype(np.uint64)\n    arr = np.bitwise_or(arr, np.right_shift(arr, _4)).astype(np.uint64)\n\n    arr = np.bitwise_or(arr, np.right_shift(arr, _1)).astype(np.uint64)\n    arr = np.bitwise_or(arr, np.right_shift(arr, _2)).astype(np.uint64)\n    arr = np.bitwise_or(arr, np.right_shift(arr, _4)).astype(np.uint64)\n\n    arr = np.bitwise_or(arr, np.right_shift(arr, _1)).astype(np.uint64)\n    arr = np.bitwise_or(arr, np.right_shift(arr, _2)).astype(np.uint64)\n    arr = np.bitwise_or(arr, np.right_shift(arr, _4)).astype(np.uint64)\n\n    arr = np.bitwise_or(arr, np.right_shift(arr, _1)).astype(np.uint64)\n    arr = np.bitwise_or(arr, np.right_shift(arr, _2)).astype(np.uint64)\n    arr = np.bitwise_or(arr, np.right_shift(arr, _4)).astype(np"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr = np.bitwise_and(arr, s55)\n    arr = np.bitwise_and(arr >> _1, s33)\n    arr = np.bitwise_and(arr >> _2, s0F)\n    arr = np.bitwise_and(arr >> _4, s01)\n    arr = np.bitwise_or(arr, np.bitwise_and(arr >> _1, _1))\n    arr = np.bitwise_or(arr, np.bitwise_and(arr >> _2, _2))\n    arr = np.bitwise_or(arr, np.bitwise_and(arr >> _4, _4))\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr = np.bitwise_and(arr, s55).astype(np.uint64)\n    arr = np.bitwise_and(arr >> _1, s33).astype(np.uint64)\n    arr = np.bitwise_and(arr >> _2, s0F).astype(np.uint64)\n    arr = np.bitwise_and(arr >> _4, s01).astype(np.uint64)\n    arr = np.bitwise_or(arr >> _1, arr).astype(np.uint64)\n    arr = np.bitwise_or(arr >> _2, arr).astype(np.uint64)\n    arr = np.bitwise_or(arr >> _4, arr).astype(np.uint64)\n    arr = np.bitwise_or(arr >> _8, arr).astype(np.uint64)\n    arr = np.bitwise_or(arr >> _16, arr).astype(np.uint64)\n    arr = np.bitwise_or(arr >> _32, arr).astype(np.uint64)\n    arr = np.bitwise_or(arr >> all_but_one_bit, arr).astype(np.uint64)\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr = np.bitwise_and(arr, s55).astype(np.uint64)\n    arr = np.left_shift(arr, _1).astype(np.uint64)\n    arr = np.bitwise_and(arr, s33).astype(np.uint64)\n    arr = np.left_shift(arr, _2).astype(np.uint64)\n    arr = np.bitwise_and(arr, s0F).astype(np.uint64)\n    arr = np.left_shift(arr, _4).astype(np.uint64)\n    arr = np.bitwise_and(arr, s01).astype(np.uint64)\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr = np.array(arr, dtype=np.uint64)\n    arr = np.right_shift(arr, all_but_one_bit)\n    arr = np.bitwise_and(arr, _1)\n    arr = np.bitwise_or(arr, np.right_shift(arr, _1))\n    arr = np.bitwise_or(arr, np.right_shift(arr, _2))\n    arr = np.bitwise_or(arr, np.right_shift(arr, _4))\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # 64 bit popcount\n    # http://stackoverflow.com/questions/109023/how-to-count-the-number-of-set-bits-in-a-32-bit-integer\n\n    # 64 bit popcount\n    # http://stackoverflow.com/questions/109023/how-to-count-the-number-of-set-bits-in-a-32-bit-integer\n\n    # 64 bit popcount\n    # http://stackoverflow.com/questions/109023/how-to-count-the-number-of-set-bits-in-a-32-bit-integer\n\n    # 64 bit popcount\n    # http://stackoverflow.com/questions/109023/how-to-count-the-number-of-set-bits-in-a-32-bit-integer\n\n    # 64 bit popcount\n    # http://stackoverflow.com/questions/109023/how-to-count-the-number-of-set-bits-in-a-32-bit-integer\n\n    # 64 bit popcount\n    # http://stackoverflow.com/questions/109023/how-to-count-the-number-of-set-bits-in-a-32-bit-integer\n\n    # 64 bit popcount\n    # http://stackoverflow.com/questions/109023/how-to-count-the-number-of-set-bits-in-a-32-bit-integer\n\n    # 64 bit popcount\n    # http://stackoverflow.com/questions/109023/how-to-count-the-number-of-set-bits-in-a-32-bit-integer\n\n    # 64 bit popcount\n    # http://stackoverflow.com/questions/109023/how-to-count-the-number-of-set-bits-in-a-32-bit-integer\n\n    # 64 bit popcount\n    # http"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr = np.bitwise_and(arr, s55)\n    arr = np.bitwise_and(arr >> _1, s33)\n    arr = np.bitwise_and(arr >> _2, s0F)\n    arr = np.bitwise_and(arr >> _4, s01)\n    arr = np.bitwise_or(arr, np.bitwise_and(arr >> _1, _1))\n    arr = np.bitwise_or(arr, np.bitwise_and(arr >> _2, _2))\n    arr = np.bitwise_or(arr, np.bitwise_and(arr >> _4, _4))\n    arr = np.bitwise_or(arr, np.bitwise_and(arr >> _8, _8))\n    arr = np.bitwise_or(arr, np.bitwise_and(arr >> _16, _16))\n    arr = np.bitwise_or(arr, np.bitwise_and(arr >> _32, _32))\n    arr = np.bitwise_or(arr, np.bitwise_and(arr >> _64, _64))\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr = (arr & s55) + ((arr >> _1) & s55)\n    arr = (arr & s33) + ((arr >> _2) & s33)\n    arr = (arr & s0F) + ((arr >> _4) & s0F)\n    arr = (arr & s01) + ((arr >> _8) & s01)\n\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # arr = np.array(arr, dtype=np.uint64)\n    # arr = np.asarray(arr, dtype=np.uint64)\n\n    arr = np.array(arr, dtype=np.uint64)\n    # arr = np.asarray(arr, dtype=np.uint64)\n\n    # 1st pass\n    arr = (arr & s55) + ((arr >> _1) & s55)\n\n    # 2nd pass\n    arr = (arr & s33) + ((arr >> _2) & s33)\n\n    # 3rd pass\n    arr = (arr & s0F) + ((arr >> _4) & s0F)\n\n    # 4th pass\n    arr = (arr & s01) + ((arr >> _8) & s01)\n\n    # 5th pass\n    arr = (arr & s01) + ((arr >> _16) & s01)\n\n    # 6th pass\n    arr = (arr & s01) + ((arr >> _32) & s01)\n\n    # 7th pass\n    arr = (arr & s01) + ((arr >> _64) & s01)\n\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr = np.bitwise_and(arr, s55).astype(np.uint64)\n    arr = np.bitwise_and(arr >> _1, s33).astype(np.uint64)\n    arr = np.bitwise_and(arr >> _2, s0F).astype(np.uint64)\n    arr = np.bitwise_and(arr >> _4, s01).astype(np.uint64)\n    arr = np.bitwise_and(arr >> _8, _1).astype(np.uint64)\n    arr = np.bitwise_and(arr >> _16, _1).astype(np.uint64)\n    arr = np.bitwise_and(arr >> _32, _1).astype(np.uint64)\n    arr = np.bitwise_and(arr >> _64, _1).astype(np.uint64)\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr = np.bitwise_and(arr, m1)\n    arr = np.bitwise_and(arr, s55)\n    arr = np.bitwise_or(arr, np.right_shift(arr, 1))\n    arr = np.bitwise_and(arr, s55)\n    arr = np.bitwise_or(arr, np.right_shift(arr, 2))\n    arr = np.bitwise_and(arr, s33)\n    arr = np.bitwise_or(arr, np.right_shift(arr, 4))\n    arr = np.bitwise_and(arr, s0F)\n    arr = np.bitwise_or(arr, np.right_shift(arr, 8))\n    arr = np.bitwise_and(arr, s01)\n    arr = np.bitwise_or(arr, np.right_shift(arr, 16))\n    arr = np.bitwise_and(arr, s01)\n    arr = np.bitwise_or(arr, np.right_shift(arr, 32))\n\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr = np.bitwise_and(arr, s55)\n    arr = np.bitwise_and(arr, s33)\n    arr = np.bitwise_and(arr, s0F)\n    arr = np.bitwise_and(arr, s01)\n\n    arr = np.bitwise_or(arr, np.right_shift(arr, _1))\n    arr = np.bitwise_or(arr, np.right_shift(arr, _2))\n    arr = np.bitwise_or(arr, np.right_shift(arr, _4))\n\n    arr = np.bitwise_or(arr, np.left_shift(arr, all_but_one_bit))\n    arr = np.bitwise_and(arr, s55)\n    arr = np.bitwise_and(arr, s33)\n    arr = np.bitwise_and(arr, s0F)\n    arr = np.bitwise_and(arr, s01)\n\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # arr = arr.astype(np.uint64)\n    arr = np.bitwise_and(arr, s55)\n    arr = np.bitwise_and(arr, s33)\n    arr = np.bitwise_and(arr, s0F)\n    arr = np.bitwise_and(arr, s01)\n\n    arr = np.bitwise_or(arr, np.right_shift(arr, _1))\n    arr = np.bitwise_or(arr, np.right_shift(arr, _2))\n    arr = np.bitwise_or(arr, np.right_shift(arr, _4))\n\n    arr = np.bitwise_or(arr, np.left_shift(arr, _1))\n    arr = np.bitwise_or(arr, np.left_shift(arr, _2))\n    arr = np.bitwise_or(arr, np.left_shift(arr, _4))\n\n    arr = np.bitwise_or(arr, np.right_shift(arr, all_but_one_bit))\n    arr = np.bitwise_or(arr, np.left_shift(arr, all_but_one_bit))\n\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr = np.bitwise_and(arr, s55)\n    arr = np.bitwise_and(arr >> _1, s33)\n    arr = np.bitwise_and(arr >> _2, s0F)\n    arr = np.bitwise_and(arr >> _4, s01)\n    arr = np.bitwise_or(arr >> _1, arr)\n    arr = np.bitwise_or(arr >> _2, arr)\n    arr = np.bitwise_or(arr >> _4, arr)\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr = (arr & s55) + ((arr >> _1) & s55)\n    arr = (arr & s33) + ((arr >> _2) & s33)\n    arr = (arr & s0F) + ((arr >> _4) & s0F)\n    arr = (arr & s01) + ((arr >> _8) & s01)\n\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # This is the main part of the algorithm, where the bit count is calculated using a series of bitwise operations\n    arr = arr - ((arr >> _1) & s55)\n    arr = (arr & s33) + ((arr >> _2) & s33)\n    arr = (arr + (arr >> _4)) & s0F\n    arr = (arr * _2 + (arr >> _4)) & s01\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # arr = arr & (arr - 1)\n    # arr = arr ^ (arr - 1)\n    # return arr\n\n    # arr = arr - (arr >> 1)\n    # arr = arr & (arr + 1)\n    # return arr\n\n    arr = arr - (arr >> _1)\n    arr = arr & (arr + _1)\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # Convert to 64-bit unsigned integer\n    arr = arr.astype(np.uint64)\n\n    # Count the number of set bits in each element\n    arr = (arr & m1).astype(np.uint64)\n    arr += (arr >> _1).astype(np.uint64)\n    arr += (arr >> _2).astype(np.uint64)\n    arr += (arr >> _4).astype(np.uint64)\n\n    # Add the number of bits set in each element to itself shifted by 32 bits\n    arr += (arr << _32).astype(np.uint64)\n\n    # Mask the lower 32 bits of each element to remove the bits set in the higher 32 bits\n    arr &= all_but_one_bit\n\n    # Add the number of bits set in each element to itself shifted by 16 bits\n    arr += (arr << _16).astype(np.uint64)\n\n    # Mask the lower 16 bits of each element to remove the bits set in the higher 16 bits\n    arr &= all_but_one_bit\n\n    # Add the number of bits set in each element to itself shifted by 8 bits\n    arr += (arr << _8).astype(np.uint64)\n\n    # Mask the lower 8 bits of each element to remove the bits set in the higher 8 bits\n    arr &= all_but_one_bit\n\n    # Add the number of bits set in each element to itself shifted by 4 bits\n    arr += (arr << _4).astype(np.uint64)\n\n    # Mask the lower 4 bits of each element to remove the bits set in the higher 4 bits\n    arr &= all_but_one_bit\n\n    # Add the number of bits set in each element to itself shifted by 2 bits\n    arr += (arr << _2).astype(np.uint64)\n\n    # Mask the lower 2 bits of each element to remove the bits set in the higher 2 bits\n    arr &= all_"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    # Note: the following code is a modified version of the bit_count64 function from numpy_ext.py\n    # https://github.com/numpy/numpy/blob/master/numpy/core/src/multiarray/bitcount.c.src\n    # https://github.com/numpy/numpy/blob/master/numpy/core/src/multiarray/bitcount.c.src\n    # https://github.com/numpy/numpy/blob/master/numpy/core/src/multiarray/bitcount.c.src\n\n    # This code is based on the bit_count64 function from numpy_ext.py\n    # https://github.com/numpy/numpy/blob/master/numpy/core/src/multiarray/bitcount.c.src\n    # This function is based on the bit_count64 function from numpy_ext.py\n    # https://github.com/numpy/numpy/blob/master/numpy/core/src/multiarray/bitcount.c.src\n    # This function is based on the bit_count64 function from numpy_ext.py\n    # https://github.com/numpy/numpy/blob/master/numpy/core/src/multiarray/bitcount.c.src\n\n    # Note: the following code is a modified version of the bit_count64 function from numpy_ext.py\n    # https://github.com/numpy/numpy/blob/master/numpy/core/src/multiarray/bitcount.c.src\n    # https://github.com/numpy/numpy/blob/master/numpy/core/src/multiarray/bitcount.c.src\n    # https://github.com/numpy/numpy/blob/master/numpy/core/src/multiarray/bitcount.c.src\n\n    # This code is based on the bit_count64 function from numpy_ext.py\n    # https://github.com/numpy/numpy/blob/master/numpy/core/src/multiarray/bitcount.c.src\n    # This function is based on the bit_count64 function from numpy_ext.py\n    # https://github.com/numpy/numpy/blob/master/numpy/"}
{"namespace": "searcharray.solr.edismax", "completion": "    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame,\n                                                   query_fields,\n                                                   num_search_terms,\n                                                   search_terms,\n                                                   mm,\n                                                   similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame,\n                                                    query_fields,\n                                                    num_search_terms,\n                                                    search_terms,\n                                                    mm,\n                                                    similarity)\n\n    return qf_scores, explain"}
{"namespace": "searcharray.solr.edismax", "completion": "    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    return qf_scores, explain"}
{"namespace": "searcharray.solr.edismax", "completion": "    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame,\n                                     query_fields,\n                                     num_search_terms,\n                                     search_terms,\n                                     mm,\n                                     similarity)\n    else:\n        return _edismax_field_centric(frame,\n                                      query_fields,\n                                      num_search_terms,\n                                      search_terms,\n                                      mm,\n                                      similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    # Parse query terms\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    # Parse field boosts\n    query_fields = parse_field_boosts(qf)\n    if pf is not None:\n        query_fields.update(parse_field_boosts(pf))\n    if pf2 is not None:\n        query_fields.update(parse_field_boosts(pf2))\n    if pf3 is not None:\n        query_fields.update(parse_field_boosts(pf3))\n\n    # Perform edismax search\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    if q_op not in [\"OR\", \"AND\"]:\n        raise ValueError(\"q_op must be 'OR' or 'AND'\")\n\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    query_fields = parse_field_boosts(qf)\n    if pf:\n        query_fields.update(parse_field_boosts(pf))\n    if pf2:\n        query_fields.update(parse_field_boosts(pf2))\n    if pf3:\n        query_fields.update(parse_field_boosts(pf3))\n\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    if not isinstance(frame, pd.DataFrame):\n        raise ValueError(\"frame must be a pandas DataFrame\")\n\n    if not isinstance(q, str):\n        raise ValueError(\"q must be a string\")\n\n    if not isinstance(qf, list):\n        raise ValueError(\"qf must be a list of strings\")\n\n    if mm is not None and not isinstance(mm, str):\n        raise ValueError(\"mm must be a string\")\n\n    if pf is not None and not isinstance(pf, list):\n        raise ValueError(\"pf must be a list of strings\")\n\n    if pf2 is not None and not isinstance(pf2, list):\n        raise ValueError(\"pf2 must be a list of strings\")\n\n    if pf3 is not None and not isinstance(pf3, list):\n        raise ValueError(\"pf3 must be a list of strings\")\n\n    if q_op not in [\"AND\", \"OR\"]:\n        raise ValueError(\"q_op must be 'AND' or 'OR'\")\n\n    if not isinstance(similarity, Similarity):\n        raise ValueError(\"similarity must be a Similarity object\")\n\n    if not isinstance(frame, pd.DataFrame):\n        raise ValueError(\"frame must be a pandas DataFrame\")\n\n    if not isinstance(q, str):\n        raise ValueError(\"q must be a string\")\n\n    if not isinstance(qf, list):\n        raise ValueError(\"qf must be a list of strings\")\n\n    if mm is not None and not isinstance(mm, str):\n        raise ValueError(\"mm must be a string\")\n\n    if pf is not None and not isinstance(pf, list):\n        raise ValueError(\"pf must be a list of strings\")\n\n    if pf2 is not None and not isinstance(pf2, list):\n        raise ValueError(\"pf2 must be a list of strings\")\n\n    if pf3 is not None and not isinstance(pf3, list):\n        raise ValueError(\"pf3 must be a list of strings\")\n\n    if q_op not in [\"AND\", \"OR"}
{"namespace": "searcharray.solr.edismax", "completion": "    if not isinstance(frame, pd.DataFrame):\n        raise ValueError(\"frame must be a pandas.DataFrame\")\n\n    if not isinstance(q, str):\n        raise ValueError(\"q must be a string\")\n\n    if not isinstance(qf, list):\n        raise ValueError(\"qf must be a list of strings\")\n\n    if mm is not None and not isinstance(mm, str):\n        raise ValueError(\"mm must be a string\")\n\n    if pf is not None and not isinstance(pf, list):\n        raise ValueError(\"pf must be a list of strings\")\n\n    if pf2 is not None and not isinstance(pf2, list):\n        raise ValueError(\"pf2 must be a list of strings\")\n\n    if pf3 is not None and not isinstance(pf3, list):\n        raise ValueError(\"pf3 must be a list of strings\")\n\n    if q_op not in [\"OR\", \"AND\"]:\n        raise ValueError(\"q_op must be either 'OR' or 'AND'\")\n\n    if not isinstance(similarity, Similarity):\n        raise ValueError(\"similarity must be a Similarity object\")\n\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame,\n                                                   parse_field_boosts(qf),\n                                                   num_search_terms,\n                                                   search_terms,\n                                                   mm,\n                                                   similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame,\n                                                    parse_field_boosts(qf),\n                                                    num_search_terms,\n                                                    search_terms,\n                                                    mm,\n                                                    similarity)\n\n    if pf is not None:\n        pf_scores = np.zeros(len(frame))\n        for field"}
{"namespace": "searcharray.solr.edismax", "completion": "    if not isinstance(frame, pd.DataFrame):\n        raise ValueError(\"Input frame must be a pandas DataFrame\")\n\n    if not isinstance(q, str):\n        raise ValueError(\"Input q must be a string\")\n\n    if not isinstance(qf, list):\n        raise ValueError(\"Input qf must be a list\")\n\n    if mm is not None and not isinstance(mm, str):\n        raise ValueError(\"Input mm must be a string\")\n\n    if pf is not None and not isinstance(pf, list):\n        raise ValueError(\"Input pf must be a list\")\n\n    if pf2 is not None and not isinstance(pf2, list):\n        raise ValueError(\"Input pf2 must be a list\")\n\n    if pf3 is not None and not isinstance(pf3, list):\n        raise ValueError(\"Input pf3 must be a list\")\n\n    if q_op not in [\"OR\", \"AND\"]:\n        raise ValueError(\"Input q_op must be either 'OR' or 'AND'\")\n\n    if not isinstance(similarity, Similarity):\n        raise ValueError(\"Input similarity must be a Similarity object\")\n\n    if not qf:\n        raise ValueError(\"Input qf must have at least one field\")\n\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame,\n                                                   parse_field_boosts(qf),\n                                                   num_search_terms,\n                                                   search_terms,\n                                                   mm,\n                                                   similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame,\n                                                    parse_field_boosts(qf),\n                                                    num_search_terms,\n                                                    search_terms,\n                                                    mm,\n                                                    similarity)\n\n    if"}
{"namespace": "searcharray.solr.edismax", "completion": "    # Parse query terms\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    # Parse field boosts\n    query_fields = parse_field_boosts(qf)\n    phrase_fields = parse_field_boosts(pf)\n    bigram_fields = parse_field_boosts(pf2)\n    trigram_fields = parse_field_boosts(pf3)\n\n    # Calculate scores\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    # Phrase and bigram matches\n    if phrase_fields:\n        for field, boost in phrase_fields.items():\n            post_arr = get_field(frame, field)\n            field_scores = np.array([post_arr.score(term, similarity=similarity)\n                                    for term in search_terms[field]])\n            matches_gt_mm = np.sum(field_scores > 0, axis=0) >= 1\n            sum_terms_bm25 = np.sum(field_scores, axis=0)\n            sum_terms_bm25[~matches_gt_mm] = 0\n            qf_scores += sum_terms_bm25 * (1 if boost is None else boost)\n            explain += f\" +({field}:{' '.join(search_terms[field])})^{boost}\"\n\n    if bigram_fields:\n        for field, boost in bigram_fields.items():\n            post_arr = get_field(frame, field)\n            field_scores = np.array([post_arr.score(term, similarity=similarity)\n                                    for term in search_terms[field]])\n            matches"}
{"namespace": "searcharray.solr.edismax", "completion": "    # Parse query\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    # Parse field boosts\n    query_fields = parse_field_boosts(qf)\n    if pf is not None:\n        query_fields.update(parse_field_boosts(pf))\n    if pf2 is not None:\n        query_fields.update(parse_field_boosts(pf2))\n    if pf3 is not None:\n        query_fields.update(parse_field_boosts(pf3))\n\n    # Perform edismax search\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    return qf_scores, explain\n\n"}
{"namespace": "searcharray.solr.edismax", "completion": "    if q_op not in [\"OR\", \"AND\"]:\n        raise ValueError(\"Invalid q_op. Expecting 'OR' or 'AND'\")\n\n    if not qf:\n        raise ValueError(\"qf cannot be empty\")\n\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame,\n                                                   parse_field_boosts(qf),\n                                                   num_search_terms,\n                                                   search_terms,\n                                                   mm,\n                                                   similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame,\n                                                    parse_field_boosts(qf),\n                                                    num_search_terms,\n                                                    search_terms,\n                                                    mm,\n                                                    similarity)\n\n    if pf:\n        pf_scores = np.zeros(len(frame))\n        for field in pf:\n            post_arr = get_field(frame, field)\n            pf_scores = np.maximum(pf_scores, post_arr.score(q, similarity=similarity))\n        qf_scores = qf_scores + pf_scores\n        explain = explain + f\" + (\" + \" | \".join([f\"{field}:{q}\" for field in pf]) + \")\"\n\n    if pf2:\n        pf2_scores = np.zeros(len(frame))\n        for field in pf2:\n            post_arr = get_field(frame, field)\n            pf2_scores = np.maximum(pf2_scores, post_arr.score(q, similarity=similarity))\n        qf_scores = qf_scores + pf2_scores\n        explain = explain + f\" + (\" + \" | \".join([f\""}
{"namespace": "searcharray.solr.edismax", "completion": "    # Parse query terms\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    # Parse field boosts\n    query_fields = parse_field_boosts(qf)\n    phrase_fields = parse_field_boosts(pf)\n    bigram_fields = parse_field_boosts(pf2)\n    trigram_fields = parse_field_boosts(pf3)\n\n    # Parse minimum match\n    if mm is None:\n        mm = \"100%\"\n    if q_op == \"OR\":\n        mm = \"100%\"\n\n    # Perform search\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame,\n                                                   query_fields,\n                                                   num_search_terms,\n                                                   search_terms,\n                                                   mm,\n                                                   similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame,\n                                                    query_fields,\n                                                    num_search_terms,\n                                                    search_terms,\n                                                    mm,\n                                                    similarity)\n\n    # Add phrase and bigram matches\n    if phrase_fields:\n        for field, boost in phrase_fields.items():\n            post_arr = get_field(frame, field)\n            for phrase in search_terms[field]:\n                phrase_score = post_arr.score(phrase, similarity=similarity) * (1 if boost is None else boost)\n                qf_scores = qf_scores + phrase_score\n                explain += f\" | {field}:{phrase}^{boost}\"\n    if bigram_fields:\n        for field, boost in bigram_fields.items():\n            post_arr = get_field(frame, field)\n            for bigram in search_terms[field]:\n                bigram_score = post_arr.score(bigram, similarity=similarity) * (1 if"}
{"namespace": "searcharray.solr.edismax", "completion": "    if not q:\n        return np.zeros(len(frame)), \"Empty query\"\n\n    if not qf:\n        raise ValueError(\"No query fields specified\")\n\n    if q_op not in [\"OR\", \"AND\"]:\n        raise ValueError(\"q_op must be 'OR' or 'AND'\")\n\n    if pf is None:\n        pf = []\n    if pf2 is None:\n        pf2 = []\n    if pf3 is None:\n        pf3 = []\n\n    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, query_fields.keys())\n\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    if pf:\n        pf_scores = np.zeros(len(frame))\n        for field in pf:\n            post_arr = get_field(frame, field)\n            pf_scores += post_arr.phrase_score(q, similarity=similarity)\n        qf_scores += pf_scores\n        explain += f\" | {pf}:\" + \" \".join(q.split()) + f\"~{mm}\"\n\n    if pf2:\n        pf2_scores = np.zeros(len(frame))\n        for field in pf2:\n            post_arr = get_field(frame, field)\n            pf2_scores += post_arr.bigram_score(q, similarity=similarity)\n        qf_scores += pf2_scores\n        explain += f\" | {pf2}:\" + \" \".join(q.split()) + f\"~{mm}\""}
{"namespace": "searcharray.solr.edismax", "completion": "    # parse query\n    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    # parse phrase fields\n    phrase_fields = parse_field_boosts(pf)\n    phrase_fields.update(parse_field_boosts(pf2))\n    phrase_fields.update(parse_field_boosts(pf3))\n\n    # parse mm\n    if mm is None:\n        mm = \"100%\"\n\n    # compute scores\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame,\n                                                   query_fields,\n                                                   num_search_terms,\n                                                   search_terms,\n                                                   mm,\n                                                   similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame,\n                                                    query_fields,\n                                                    num_search_terms,\n                                                    search_terms,\n                                                    mm,\n                                                    similarity)\n\n    # compute phrase scores\n    phrase_scores = np.zeros(len(frame))\n    for field, boost in phrase_fields.items():\n        post_arr = get_field(frame, field)\n        for phrase in search_terms[field]:\n            phrase_scores += post_arr.score(phrase, similarity=similarity) * (1 if boost is None else boost)\n\n    # combine scores\n    qf_scores += phrase_scores\n\n    # combine scores\n    if q_op == \"AND\":\n        qf_scores = np.prod(qf_scores, axis=1)\n    else:\n        qf_scores = np.sum(qf_scores, axis=1)\n\n    return qf_scores, explain"}
{"namespace": "searcharray.solr.edismax", "completion": "    if q_op not in [\"OR\", \"AND\"]:\n        raise ValueError(\"Invalid q_op. Expecting 'OR' or 'AND'\")\n\n    # Parse the query\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    # Parse the field boosts\n    query_fields = parse_field_boosts(qf)\n    phrase_fields = parse_field_boosts(pf)\n    bigram_fields = parse_field_boosts(pf2)\n    trigram_fields = parse_field_boosts(pf3)\n\n    # Parse the minimum match specification\n    if mm is None:\n        mm = \"\"\n\n    # Perform the search\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    # Handle phrase and bigram matches\n    if phrase_fields:\n        for field, boost in phrase_fields.items():\n            post_arr = get_field(frame, field)\n            field_scores = np.array([post_arr.score(term, similarity=similarity)\n                                     for term in search_terms[field]])\n            matches_gt_mm = np.sum(field_scores > 0, axis=0) >= parse_min_should_match(len(search_terms[field]), mm)\n            sum_terms_bm25 = np.sum(field_scores, axis=0)\n            sum_terms_bm25[~matches_gt_mm] = 0\n            qf_scores = qf_scores + sum_terms_bm25 * (1 if boost is None else boost)\n            explain = explain + f\" +(\" + \" \".join([f\"{field}:{"}
{"namespace": "searcharray.solr.edismax", "completion": "    if q_op not in [\"OR\", \"AND\"]:\n        raise ValueError(\"Invalid q_op. Expecting 'OR' or 'AND'.\")\n\n    # Parse query terms\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    # Parse field boosts\n    query_fields = parse_field_boosts(pf)\n    query_fields.update(parse_field_boosts(pf2))\n    query_fields.update(parse_field_boosts(pf3))\n\n    # Parse phrase fields\n    phrase_fields = [field for field in pf if field in pf2]\n    if len(phrase_fields) > 1:\n        raise ValueError(f\"Invalid pf. Expecting only one field for pf2 and pf3.\")\n\n    # Perform search\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    # Apply q_op\n    if q_op == \"AND\":\n        qf_scores = np.prod(qf_scores, axis=0)\n    else:\n        qf_scores = np.sum(qf_scores, axis=0)\n\n    return qf_scores, explain\n\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        with self.lock:\n            connection = self.connections.get(message.connection_id)\n            if connection is None:\n                connection = Connection(\n                    process_id=process.id,\n                    connection_id=message.connection_id,\n                    multiple_connections=self.config['multipleConnections'],\n                    auto_close=self.config['autoCloseConnections'],\n                    logger=self.logger\n                )\n                self.connections[message.connection_id] = connection\n            if isinstance(message, SendMessage):\n                message.data = connection.c2s(message.data)\n            elif isinstance(message, RecvMessage):\n                message.data = connection.s2c(message.data)\n            elif isinstance(message, CloseMessage):\n                connection.close()\n                del self.connections[message.connection_id]\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        with self.lock:\n            if message.type == MessageType.SEND:\n                self.connections.setdefault(process.pid, Connection(self.server, DEFAULT_CONNECTION_ID))\n                self.connections[process.pid].send(message.data)\n                message.data = self.connections[process.pid].c2s(message.data)\n            elif message.type == MessageType.RECV:\n                self.connections.setdefault(process.pid, Connection(self.server, DEFAULT_CONNECTION_ID))\n                message.data = self.connections[process.pid].s2c(message.data)\n            elif message.type == MessageType.CLOSE:\n                if self.config['autoCloseConnections']:\n                    if process.pid in self.connections:\n                        self.connections[process.pid].close()\n                        del self.connections[process.pid]\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        with self.lock:\n            if isinstance(message, SendMessage):\n                if message.connection_id not in self.connections:\n                    if self.config['multipleConnections']:\n                        self.connections[message.connection_id] = Connection(\n                            process,\n                            message.connection_id,\n                            self.server,\n                            self.logger\n                        )\n                    else:\n                        self.connections[DEFAULT_CONNECTION_ID] = Connection(\n                            process,\n                            DEFAULT_CONNECTION_ID,\n                            self.server,\n                            self.logger\n                        )\n                self.connections[message.connection_id].send(message.data)\n                message.data = b''\n            elif isinstance(message, RecvMessage):\n                if message.connection_id not in self.connections:\n                    if self.config['multipleConnections']:\n                        self.connections[message.connection_id] = Connection(\n                            process,\n                            message.connection_id,\n                            self.server,\n                            self.logger\n                        )\n                    else:\n                        self.connections[DEFAULT_CONNECTION_ID] = Connection(\n                            process,\n                            DEFAULT_CONNECTION_ID,\n                            self.server,\n                            self.logger\n                        )\n                message.data = self.connections[message.connection_id].recv()\n            elif isinstance(message, CloseMessage):\n                if message.connection_id not in self.connections:\n                    if self.config['multipleConnections']:\n                        self.connections[message.connection_id] = Connection(\n                            process,\n                            message.connection_id,\n                            self.server,\n                            self.logger\n                        )\n                    else:\n                        self.connections[DEFAULT_CONNECTION_ID] = Connection(\n                            process,\n                            DEFAULT_CONNECTION_ID,\n                            self.server,\n                            self.logger\n                        )\n                self.connections[message.connection_id"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            self.handle_send_message(process, message)\n        elif isinstance(message, RecvMessage):\n            self.handle_recv_message(process, message)\n        elif isinstance(message, CloseMessage):\n            self.handle_close_message(process, message)\n\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        with self.lock:\n            connection = self.connections.get(process.pid, None)\n            if connection is None:\n                connection = Connection(\n                    process=process,\n                    server=self.server,\n                    multiple_connections=self.config['multipleConnections'],\n                    logger=self.logger\n                )\n                self.connections[process.pid] = connection\n\n            if isinstance(message, SendMessage):\n                connection.c2s(message.data)\n            elif isinstance(message, RecvMessage):\n                connection.s2c(message.data)\n            elif isinstance(message, CloseMessage):\n                connection.close()\n                if self.config['autoCloseConnections']:\n                    self.connections.pop(process.pid)\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if message.type == MessageType.SEND:\n            self._handle_send(process, message)\n        elif message.type == MessageType.RECV:\n            self._handle_recv(process, message)\n        elif message.type == MessageType.CLOSE:\n            self._handle_close(process, message)\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            self.intercept_send(process, message)\n        elif isinstance(message, RecvMessage):\n            self.intercept_recv(process, message)\n        elif isinstance(message, CloseMessage):\n            self.intercept_close(process, message)\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if message.type == MessageType.SEND:\n            self.lock.acquire()\n            connection = self.connections.get(message.connection_id, None)\n            if connection is None:\n                if not self.config['multipleConnections']:\n                    connection = self.connections.get(DEFAULT_CONNECTION_ID, None)\n                if connection is None:\n                    connection = Connection(self.server)\n                    self.connections[connection.id] = connection\n            connection.c2s(message.data)\n            self.lock.release()\n        elif message.type == MessageType.RECV:\n            self.lock.acquire()\n            connection = self.connections.get(message.connection_id, None)\n            if connection is None:\n                if not self.config['multipleConnections']:\n                    connection = self.connections.get(DEFAULT_CONNECTION_ID, None)\n                if connection is None:\n                    connection = Connection(self.server)\n                    self.connections[connection.id] = connection\n            message.data = connection.s2c()\n            self.lock.release()\n        elif message.type == MessageType.CLOSE:\n            self.lock.acquire()\n            connection = self.connections.get(message.connection_id, None)\n            if connection is None:\n                if not self.config['multipleConnections']:\n                    connection = self.connections.get(DEFAULT_CONNECTION_ID, None)\n                if connection is None:\n                    connection = Connection(self.server)\n                    self.connections[connection.id] = connection\n            connection.close()\n            if self.config['autoCloseConnections']:\n                del self.connections[connection.id]\n            self.lock.release()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        self.lock.acquire()\n        try:\n            if isinstance(message, SendMessage):\n                connection_id = message.connection_id if message.connection_id is not None else DEFAULT_CONNECTION_ID\n                if connection_id not in self.connections:\n                    if self.config['multipleConnections']:\n                        self.connections[connection_id] = self.server.create_connection(connection_id)\n                    else:\n                        self.connections[connection_id] = self.server.create_connection()\n                connection = self.connections[connection_id]\n                message.data = connection.c2s(message.data)\n            elif isinstance(message, RecvMessage):\n                connection_id = message.connection_id if message.connection_id is not None else DEFAULT_CONNECTION_ID\n                if connection_id not in self.connections:\n                    if self.config['multipleConnections']:\n                        self.connections[connection_id] = self.server.create_connection(connection_id)\n                    else:\n                        self.connections[connection_id] = self.server.create_connection()\n                connection = self.connections[connection_id]\n                message.data = connection.s2c(message.data)\n            elif isinstance(message, CloseMessage):\n                connection_id = message.connection_id if message.connection_id is not None else DEFAULT_CONNECTION_ID\n                if connection_id in self.connections:\n                    connection = self.connections[connection_id]\n                    connection.close()\n                    if self.config['autoCloseConnections']:\n                        del self.connections[connection_id]\n        finally:\n            self.lock.release()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if message.type == 'SendMessage':\n            with self.lock:\n                connection = self.connections.get(message.connection_id, None)\n                if connection is None:\n                    connection = Connection(\n                        process=process,\n                        connection_id=message.connection_id,\n                        multiple=self.config['multipleConnections']\n                    )\n                    self.connections[message.connection_id] = connection\n                message.data = connection.c2s(message.data)\n        elif message.type == 'RecvMessage':\n            with self.lock:\n                connection = self.connections.get(message.connection_id, None)\n                if connection is None:\n                    connection = Connection(\n                        process=process,\n                        connection_id=message.connection_id,\n                        multiple=self.config['multipleConnections']\n                    )\n                    self.connections[message.connection_id] = connection\n                message.data = connection.s2c(message.data)\n        elif message.type == 'CloseMessage':\n            with self.lock:\n                connection = self.connections.get(message.connection_id, None)\n                if connection is not None:\n                    if self.config['autoCloseConnections']:\n                        connection.close()\n                    del self.connections[message.connection_id]\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        with self.lock:\n            connection = self.connections.get(process.pid, None)\n            if not connection:\n                connection = Connection(\n                    process=process,\n                    server=self.server,\n                    multiple_connections=self.config['multipleConnections'],\n                    auto_close=self.config['autoCloseConnections'],\n                    logger=self.logger\n                )\n                self.connections[process.pid] = connection\n\n        if isinstance(message, SendMessage):\n            connection.c2s(message)\n        elif isinstance(message, RecvMessage):\n            connection.s2c(message)\n        elif isinstance(message, CloseMessage):\n            connection.close()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if message.type == 'SendMessage':\n            self.lock.acquire()\n            connection = self.connections.get(message.connection_id, Connection(DEFAULT_CONNECTION_ID))\n            self.connections[message.connection_id] = connection\n            self.lock.release()\n            message.data = connection.c2s(message.data)\n        elif message.type == 'RecvMessage':\n            self.lock.acquire()\n            connection = self.connections.get(message.connection_id, Connection(DEFAULT_CONNECTION_ID))\n            self.connections[message.connection_id] = connection\n            self.lock.release()\n            message.data = connection.s2c(message.data)\n        elif message.type == 'CloseMessage':\n            self.lock.acquire()\n            connection = self.connections.get(message.connection_id, Connection(DEFAULT_CONNECTION_ID))\n            self.connections[message.connection_id] = connection\n            self.lock.release()\n            connection.close()\n            if self.config['autoCloseConnections']:\n                self.lock.acquire()\n                if message.connection_id in self.connections:\n                    del self.connections[message.connection_id]\n                self.lock.release()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if message.type == MessageType.SEND:\n            self.handle_send_message(process, message)\n        elif message.type == MessageType.RECV:\n            self.handle_recv_message(process, message)\n        elif message.type == MessageType.CLOSE:\n            self.handle_close_message(process, message)\n        else:\n            raise ValueError(f'Unknown message type: {message.type}')\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if message.type == MessageType.SEND:\n            self.lock.acquire()\n            connection = self.connections.get(message.connection_id)\n            if not connection:\n                connection = self.server.create_connection(message.connection_id)\n                if self.config['multipleConnections']:\n                    self.connections[message.connection_id] = connection\n            self.lock.release()\n            message.data = connection.c2s(message.data)\n        elif message.type == MessageType.RECV:\n            self.lock.acquire()\n            connection = self.connections.get(message.connection_id)\n            if not connection:\n                connection = self.server.create_connection(message.connection_id)\n                if self.config['multipleConnections']:\n                    self.connections[message.connection_id] = connection\n            self.lock.release()\n            message.data = connection.s2c(message.data)\n        elif message.type == MessageType.CLOSE:\n            self.lock.acquire()\n            connection = self.connections.get(message.connection_id)\n            if connection:\n                if self.config['autoCloseConnections']:\n                    connection.close()\n                    del self.connections[message.connection_id]\n                else:\n                    connection.reset()\n            self.lock.release()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if message.type == MessageType.SEND:\n            self.handle_send_message(process, message)\n        elif message.type == MessageType.RECV:\n            self.handle_recv_message(process, message)\n        elif message.type == MessageType.CLOSE:\n            self.handle_close_message(process, message)\n        else:\n            raise NotImplementedError(f'Unknown message type {message.type}')\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if message.type == MessageType.SEND:\n            self.lock.acquire()\n            connection = self.connections.get(message.connection_id)\n            if not connection:\n                connection = self.server.get_connection(message.connection_id)\n                if connection:\n                    self.connections[message.connection_id] = connection\n            self.lock.release()\n            if connection:\n                message.data = connection.c2s(message.data)\n        elif message.type == MessageType.RECV:\n            self.lock.acquire()\n            connection = self.connections.get(message.connection_id)\n            if not connection:\n                connection = self.server.get_connection(message.connection_id)\n                if connection:\n                    self.connections[message.connection_id] = connection\n            self.lock.release()\n            if connection:\n                message.data = connection.s2c(message.data)\n        elif message.type == MessageType.CLOSE:\n            self.lock.acquire()\n            connection = self.connections.get(message.connection_id)\n            if connection:\n                connection.close()\n                del self.connections[message.connection_id]\n            self.lock.release()\n\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        with self.lock:\n            if message.type == MessageType.SEND:\n                if self.config['multipleConnections']:\n                    connection_id = message.data.connection_id\n                else:\n                    connection_id = DEFAULT_CONNECTION_ID\n                if connection_id not in self.connections:\n                    self.connections[connection_id] = Connection(connection_id, self.server, self.config['autoCloseConnections'], self.logger)\n                self.connections[connection_id].c2s(message.data.data)\n                message.data.data = self.connections[connection_id].id\n            elif message.type == MessageType.RECV:\n                if message.data.data in self.connections:\n                    self.connections[message.data.data].s2c(message.data.data)\n            elif message.type == MessageType.CLOSE:\n                if message.data.connection_id in self.connections:\n                    self.connections[message.data.connection_id].close()\n                    del self.connections[message.data.connection_id]\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        with self.lock:\n            if message.type == MessageType.SEND_MESSAGE:\n                connection = self.get_connection(process, message.connection_id)\n                message.data = connection.c2s(message.data)\n            elif message.type == MessageType.RECV_MESSAGE:\n                connection = self.get_connection(process, message.connection_id)\n                message.data = connection.s2c(message.data)\n            elif message.type == MessageType.CLOSE_MESSAGE:\n                connection = self.get_connection(process, message.connection_id)\n                connection.close()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        self.lock.acquire()\n        try:\n            if message.type == MessageType.SEND:\n                self.handle_send_message(process, message)\n            elif message.type == MessageType.RECV:\n                self.handle_recv_message(process, message)\n            elif message.type == MessageType.CLOSE:\n                self.handle_close_message(process, message)\n            else:\n                raise Exception('Unknown message type')\n        finally:\n            self.lock.release()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        with self.lock:\n            if message.type == MessageType.SEND:\n                self.connections[message.connection_id].c2s(message.data)\n            elif message.type == MessageType.RECV:\n                message.data = self.connections[message.connection_id].s2c(message.data)\n            elif message.type == MessageType.CLOSE:\n                if self.config['autoCloseConnections']:\n                    self.connections.pop(message.connection_id, None)\n            else:\n                raise Exception('Unknown message type: {}'.format(message.type))\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n            self.connections.clear()\n        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n            self.connections.clear()\n\n        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n            self.connections.clear()\n            self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n            self.connections = {}\n            self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection in self.connections.values():\n                connection.stop()\n            self.connections.clear()\n        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        # Stop all connections\n        with self.lock:\n            for connection in self.connections.values():\n                connection.stop()\n            self.connections.clear()\n\n        # Stop the server\n        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n            self.connections.clear()\n            self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.logger.info('Destroying proxifier')\n        with self.lock:\n            for connection in self.connections.values():\n                connection.stop()\n            self.connections.clear()\n        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.logger.info('Closing all connections')\n        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n            self.connections.clear()\n        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n            self.connections.clear()\n            self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.server.stop()\n        with self.lock:\n            for connection in self.connections.values():\n                connection.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.logger.info(\"Destroying ProxifierMessageInterceptor\")\n        with self.lock:\n            for connection in self.connections.values():\n                connection.stop()\n            self.connections = {}\n        self.server.stop()\n        self.server.join()\n        self.logger.info(\"ProxifierMessageInterceptor destroyed\")\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection in self.connections.values():\n                connection.stop()\n            self.connections.clear()\n        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.server.stop()\n        self.server.join()\n\n        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n            self.connections = {}\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.server.stop()\n        self.server.join()\n        with self.lock:\n            for connection in self.connections.values():\n                connection.stop()\n            self.connections.clear()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection in self.connections.values():\n                connection.stop()\n            self.connections.clear()\n\n        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.server.stop()\n        self.server.join()\n        for connection in self.connections.values():\n            connection.stop()\n            connection.join()\n        self.connections.clear()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection in self.connections.values():\n                connection.stop()\n\n        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection in self.connections.values():\n                connection.stop()\n            self.connections.clear()\n            self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        # Stop all connections\n        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n\n        # Stop the server\n        self.server.stop()\n"}
