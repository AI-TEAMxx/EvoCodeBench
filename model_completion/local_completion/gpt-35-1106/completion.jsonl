{"namespace": "iris.io.validators.are_shapes_equal", "completion": "\n    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shapes of field1 and field2 are equal.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shapes mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shapes of field1 and field2 are equal.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shapes mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "\n    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shapes of field1 and field2 are equal.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shapes mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "\n    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shapes of field1 and field2 are equal.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shapes mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1 and field2 have the same shape.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shapes mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "\n    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shapes of field1 and field2 are equal.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shapes mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "\n    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shapes of field1 and field2 are equal.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shapes mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shapes of field1 and field2 are equal.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shapes mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shapes of field1 and field2 are equal.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shapes mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    \n    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shapes of field1 and field2 are equal.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shapes mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "\n    def __validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shapes of field1 and field2 are equal.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shapes mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shapes of field1 and field2 are equal.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shapes mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "\n    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if shape of field1 equals shape of field2.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shapes mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "\n    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shapes of field1 and field2 are equal.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shapes mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "\n    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shapes of field1 and field2 are equal.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shapes mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shapes of field1 and field2 are equal.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shapes mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "\n    def __root_validator(cls: type, values: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Check if the shapes of field1 and field2 are equal.\"\"\"\n        if isinstance(values[field1], np.ndarray) and isinstance(values[field2], np.ndarray):\n            if values[field1].shape != values[field2].shape:\n                raise ValueError(\n                    f\"{cls.__name__}: {field1} and {field2} shapes mismatch, \"\n                    f\"resp. {values[field1].shape} and {values[field2].shape}\"\n                )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "\n    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shapes of field1 and field2 are equal.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shapes mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shapes of field1 and field2 are equal.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shapes mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "\n    def __root_validator(cls: type, values: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Check if the shapes of field1 and field2 are equal.\"\"\"\n        if isinstance(values[field1], np.ndarray) and isinstance(values[field2], np.ndarray):\n            if values[field1].shape != values[field2].shape:\n                raise ValueError(\n                    f\"{cls.__name__}: {field1} and {field2} shapes mismatch, \"\n                    f\"resp. {values[field1].shape} and {values[field2].shape}\"\n                )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(*args, **kwargs)\n\n        # Main algorithm run method\n        result = self.run(*args, **kwargs)\n\n        # Post-execution hooks\n        for callback in self._callbacks:\n            callback.post_execute(result, *args, **kwargs)\n\n        return result"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        # Add the main algorithm run method here\n        pass"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        # Add the main algorithm run method here\n        pass"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(*args, **kwargs)\n\n        # Main algorithm run method\n        result = self.run(*args, **kwargs)\n\n        # Post-execution hooks\n        for callback in self._callbacks:\n            callback.post_execute(result, *args, **kwargs)\n\n        return result"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        # Implement the main algorithm logic here\n        pass"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(*args, **kwargs)\n\n        # Main algorithm run method\n        result = self.run(*args, **kwargs)\n\n        # Post-execution hooks\n        for callback in self._callbacks:\n            callback.post_execute(result, *args, **kwargs)\n\n        return result"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(*args, **kwargs)\n\n        # Main algorithm run method\n        result = self.run(*args, **kwargs)\n\n        # Post-execution hooks\n        for callback in self._callbacks:\n            callback.post_execute(result, *args, **kwargs)\n\n        return result"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(*args, **kwargs)\n\n        # Run the main algorithm\n        result = self.run(*args, **kwargs)\n\n        # Run post-execution hooks\n        for callback in self._callbacks:\n            callback.post_execute(result, *args, **kwargs)\n\n        return result"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        # Add the main algorithm run method here\n        # Example: result = self.run_method(*args, **kwargs)\n        # Call pre-execution hooks\n        for callback in self._callbacks:\n            callback.pre_execute(*args, **kwargs)\n\n        # Run the main algorithm\n        result = self.run_method(*args, **kwargs)\n\n        # Call post-execution hooks\n        for callback in self._callbacks:\n            callback.post_execute(result, *args, **kwargs)\n\n        return result"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        # Add the main algorithm run method here\n        pass"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(*args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_execute(result)\n\n        return result"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        # Add the main algorithm run method here\n        pass"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(*args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_execute(result)\n\n        return result"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        # Pre-execution hooks\n        for callback in self._callbacks:\n            callback.pre_execute(*args, **kwargs)\n\n        # Main algorithm run method\n        result = self.run(*args, **kwargs)\n\n        # Post-execution hooks\n        for callback in self._callbacks:\n            callback.post_execute(result, *args, **kwargs)\n\n        return result"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        # Add the main algorithm logic here\n        pass"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(*args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_execute(result)\n\n        return result"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        # Add the main algorithm run method here\n        pass"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(*args, **kwargs)\n\n        # Main algorithm run method\n        result = self.run(*args, **kwargs)\n\n        # Post-execution hooks\n        for callback in self._callbacks:\n            callback.post_execute(result, *args, **kwargs)\n\n        return result"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(*args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_execute(result, *args, **kwargs)\n\n        return result"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(*args, **kwargs)\n        \n        result = self.run(*args, **kwargs)\n        \n        for callback in self._callbacks:\n            callback.post_execute(result, *args, **kwargs)\n        \n        return result"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "\n        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        if self.check_type(deserialized_output, type_definition):\n            return True\n        else:\n            return False"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "\n        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        if self.check_type(deserialized_output, type_definition):\n            return True\n        else:\n            return False"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "\n        try:\n            deserialized_output = json.loads(output)\n            return self.check_type(deserialized_output, type_definition)\n        except json.JSONDecodeError:\n            return False"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "\n        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        if self.check_type(deserialized_output, type_definition):\n            return True\n        else:\n            return False"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "\n        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        if self.check_type(deserialized_output, type_definition):\n            return True\n        else:\n            return False"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "\n        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "\n        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "\n        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "\n        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "\n        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "\n        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        if not self.check_type(deserialized_output, type_definition):\n            return False\n\n        return True"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "\n        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "\n        try:\n            deserialized_output = json.loads(output)\n            return self.check_type(deserialized_output, type_definition)\n        except (json.JSONDecodeError, TypeError):\n            return False"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)"}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + \"_\"\n\n    \"\"\"\n    Encodes an integer into a single character based on a predefined character set. The character set consists of lowercase letters, digits, and an underscore.\n\n    Input-Output Arguments\n    :param n: Integer. The integer to be encoded. It is used as an index to select a character from the character set.\n    :return: String. The encoded character corresponding to the input integer.\n    \"\"\""}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + \"_\"\n\n    \"\"\"\n    Encodes an integer into a single character based on a predefined character set. The character set consists of lowercase letters, digits, and an underscore.\n\n    Input-Output Arguments\n    :param n: Integer. The integer to be encoded. It is used as an index to select a character from the character set.\n    :return: String. The encoded character corresponding to the input integer.\n    \"\"\""}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + \"_\"\n\n    \"\"\"\n    Encodes an integer into a single character based on a predefined character set. The character set consists of lowercase letters, digits, and an underscore.\n\n    Input-Output Arguments\n    :param n: Integer. The integer to be encoded. It is used as an index to select a character from the character set.\n    :return: String. The encoded character corresponding to the input integer.\n    \"\"\""}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + \"_\"\n\n    \"\"\"\n    Encodes an integer into a single character based on a predefined character set. The character set consists of lowercase letters, digits, and an underscore.\n\n    Input-Output Arguments\n    :param n: Integer. The integer to be encoded. It is used as an index to select a character from the character set.\n    :return: String. The encoded character corresponding to the input integer.\n    \"\"\""}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + \"_\"\n\n    \"\"\"\n    Encodes an integer into a single character based on a predefined character set. The character set consists of lowercase letters, digits, and an underscore.\n\n    Input-Output Arguments\n    :param n: Integer. The integer to be encoded. It is used as an index to select a character from the character set.\n    :return: String. The encoded character corresponding to the input integer.\n    \"\"\""}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + \"_\"\n\n    \"\"\"\n    Encodes an integer into a single character based on a predefined character set. The character set consists of lowercase letters, digits, and an underscore.\n\n    Input-Output Arguments\n    :param n: Integer. The integer to be encoded. It is used as an index to select a character from the character set.\n    :return: String. The encoded character corresponding to the input integer.\n    \"\"\"\n\n    # Ensure that the input integer is within the range of the character set\n    if n < 0 or n >= len(character_set):\n        raise ValueError(\"Input integer is out of range for encoding\")\n\n    # Encode the integer by selecting the corresponding character from the character set\n    encoded_char = character_set[n]\n    return encoded_char"}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + \"_\"\n\n    \"\"\"\n    Encodes an integer into a single character based on a predefined character set. The character set consists of lowercase letters, digits, and an underscore.\n\n    Input-Output Arguments\n    :param n: Integer. The integer to be encoded. It is used as an index to select a character from the character set.\n    :return: String. The encoded character corresponding to the input integer.\n    \"\"\""}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + \"_\"\n\n    \"\"\"\n    Encodes an integer into a single character based on a predefined character set. The character set consists of lowercase letters, digits, and an underscore.\n\n    Input-Output Arguments\n    :param n: Integer. The integer to be encoded. It is used as an index to select a character from the character set.\n    :return: String. The encoded character corresponding to the input integer.\n    \"\"\"\n\n    # Ensure n is within the bounds of the character set\n    n = n % len(character_set)\n\n    # Return the character at index n in the character set\n    return character_set[n]"}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + \"_\"\n\n    \"\"\"\n    Encodes an integer into a single character based on a predefined character set. The character set consists of lowercase letters, digits, and an underscore.\n\n    Input-Output Arguments\n    :param n: Integer. The integer to be encoded. It is used as an index to select a character from the character set.\n    :return: String. The encoded character corresponding to the input integer.\n    \"\"\"\n\n    # Ensure that the input integer is within the bounds of the character set\n    if n < 0 or n >= len(character_set):\n        raise ValueError(\"Input integer out of bounds for encoding\")\n\n    # Return the encoded character corresponding to the input integer\n    return character_set[n]"}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + \"_\"\n\n    \"\"\"\n    Encodes an integer into a single character based on a predefined character set. The character set consists of lowercase letters, digits, and an underscore.\n\n    Input-Output Arguments\n    :param n: Integer. The integer to be encoded. It is used as an index to select a character from the character set.\n    :return: String. The encoded character corresponding to the input integer.\n    \"\"\"\n\n    # Ensure the input integer is within the range of the character set\n    if 0 <= n < len(character_set):\n        return character_set[n]\n    else:\n        raise ValueError(\"Input integer out of range for encoding\")"}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + \"_\"\n\n    \"\"\"\n    Encodes an integer into a single character based on a predefined character set. The character set consists of lowercase letters, digits, and an underscore.\n\n    Input-Output Arguments\n    :param n: Integer. The integer to be encoded. It is used as an index to select a character from the character set.\n    :return: String. The encoded character corresponding to the input integer.\n    \"\"\""}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + \"_\"\n\n    \"\"\"\n    Encodes an integer into a single character based on a predefined character set. The character set consists of lowercase letters, digits, and an underscore.\n\n    Input-Output Arguments\n    :param n: Integer. The integer to be encoded. It is used as an index to select a character from the character set.\n    :return: String. The encoded character corresponding to the input integer.\n    \"\"\"\n\n    return character_set[n % len(character_set)]"}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + \"_\"\n\n    \"\"\"\n    Encodes an integer into a single character based on a predefined character set. The character set consists of lowercase letters, digits, and an underscore.\n\n    Input-Output Arguments\n    :param n: Integer. The integer to be encoded. It is used as an index to select a character from the character set.\n    :return: String. The encoded character corresponding to the input integer.\n    \"\"\"\n\n    if n < len(character_set):\n        return character_set[n]\n    else:\n        raise ValueError(\"Integer n is out of range for the character set\")"}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + \"_\"\n\n    \"\"\"\n    Encodes an integer into a single character based on a predefined character set. The character set consists of lowercase letters, digits, and an underscore.\n\n    Input-Output Arguments\n    :param n: Integer. The integer to be encoded. It is used as an index to select a character from the character set.\n    :return: String. The encoded character corresponding to the input integer.\n    \"\"\""}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + \"_\"\n\n    \"\"\"\n    Encodes an integer into a single character based on a predefined character set. The character set consists of lowercase letters, digits, and an underscore.\n\n    Input-Output Arguments\n    :param n: Integer. The integer to be encoded. It is used as an index to select a character from the character set.\n    :return: String. The encoded character corresponding to the input integer.\n    \"\"\""}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + \"_\"\n\n    \"\"\"\n    Encodes an integer into a single character based on a predefined character set. The character set consists of lowercase letters, digits, and an underscore.\n\n    Input-Output Arguments\n    :param n: Integer. The integer to be encoded. It is used as an index to select a character from the character set.\n    :return: String. The encoded character corresponding to the input integer.\n    \"\"\""}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + \"_\"\n\n    \"\"\"\n    Encodes an integer into a single character based on a predefined character set. The character set consists of lowercase letters, digits, and an underscore.\n\n    Input-Output Arguments\n    :param n: Integer. The integer to be encoded. It is used as an index to select a character from the character set.\n    :return: String. The encoded character corresponding to the input integer.\n    \"\"\""}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + \"_\"\n\n    \"\"\"\n    Encodes an integer into a single character based on a predefined character set. The character set consists of lowercase letters, digits, and an underscore.\n\n    Input-Output Arguments\n    :param n: Integer. The integer to be encoded. It is used as an index to select a character from the character set.\n    :return: String. The encoded character corresponding to the input integer.\n    \"\"\""}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + \"_\"\n\n    \"\"\"\n    Encodes an integer into a single character based on a predefined character set. The character set consists of lowercase letters, digits, and an underscore.\n\n    Input-Output Arguments\n    :param n: Integer. The integer to be encoded. It is used as an index to select a character from the character set.\n    :return: String. The encoded character corresponding to the input integer.\n    \"\"\"\n\n    # Select the character from the character set based on the input integer\n    encoded_char = character_set[n % len(character_set)]\n    return encoded_char"}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + \"_\"\n\n    \"\"\"\n    Encodes an integer into a single character based on a predefined character set. The character set consists of lowercase letters, digits, and an underscore.\n\n    Input-Output Arguments\n    :param n: Integer. The integer to be encoded. It is used as an index to select a character from the character set.\n    :return: String. The encoded character corresponding to the input integer.\n    \"\"\"\n\n    return character_set[n % len(character_set)]"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        sig = inspect.signature(func_object)\n        hints = get_type_hints(func_object)\n\n        input_type_hints = []\n        output_type_hint = None\n\n        for param in sig.parameters.values():\n            if param.annotation != inspect.Parameter.empty:\n                input_type_hints.append(param.annotation)\n\n        if 'return' in hints:\n            output_type_hint = hints['return']\n\n        input_class_definitions = [get_class_definition(hint) for hint in input_type_hints]\n        output_class_definition = get_class_definition(output_type_hint)\n\n        if output_class_definition is not None:\n            if issubclass(output_class_definition, Embedding):\n                function_type = FunctionType.EMBEDDABLE\n            elif get_origin(output_type_hint) == Union:\n                for type_arg in get_type_hints(output_type_hint):\n                    if issubclass(get_class_definition(type_arg), Embedding):\n                        function_type = FunctionType.EMBEDDABLE\n                        break\n                else:\n                    function_type = FunctionType.SYMBOLIC\n            else:\n                function_type = FunctionType.SYMBOLIC\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=func_object.__doc__,\n            input_type_hints=input_type_hints,\n            output_type_hint=output_type_hint,\n            input_class_definitions=input_class_definitions,\n            output_class_definition=output_class_definition,\n            type=function_type\n        )"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "\n        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n\n        input_type_hints = []\n        output_type_hints = None\n\n        for param in signature.parameters.values():\n            if param.annotation != param.empty:\n                input_type_hints.append(get_class_definition(param.annotation))\n\n        if 'return' in type_hints:\n            output_type_hints = type_hints['return']\n            output_class_definition = get_class_definition(output_type_hints)\n            if get_origin(output_type_hints) == Union:\n                for type_hint in get_origin(output_type_hints).__args__:\n                    if type_hint == Embedding or (get_origin(type_hint) == Union and Embedding in get_origin(type_hint).__args__):\n                        output_type = FunctionType.EMBEDDABLE\n                        break\n                else:\n                    output_type = FunctionType.SYMBOLIC\n            elif output_type_hints == Embedding or (get_origin(output_type_hints) == Union and Embedding in get_origin(output_type_hints).__args__):\n                output_type = FunctionType.EMBEDDABLE\n            else:\n                output_type = FunctionType.SYMBOLIC\n        else:\n            output_type = FunctionType.SYMBOLIC\n            output_class_definition = None\n\n        function_description = FunctionDescription(\n            name=func_object.__name__,\n            docstring=func_object.__doc__,\n            input_type_hints=input_type_hints,\n            output_type_hints=output_type_hints,\n            input_class_definitions=[get_class_definition(param.annotation) for param in signature.parameters.values() if param.annotation != param.empty],\n            output_class_definition=output_class_definition,\n            type=output_type\n        )\n\n        return function_description"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "\n        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n\n        input_type_hints = [type_hints[param.name] for param in signature.parameters.values()]\n        output_type_hint = type_hints['return']\n\n        input_class_definitions = [get_class_definition(type_hint) for type_hint in input_type_hints]\n        output_class_definition = get_class_definition(output_type_hint)\n\n        function_type = FunctionType.SYMBOLIC if get_origin(output_type_hint) == Union or issubclass(output_type_hint, Embedding) else FunctionType.EMBEDDABLE\n\n        function_description = FunctionDescription(\n            name=func_object.__name__,\n            docstring=func_object.__doc__,\n            input_type_hints=input_type_hints,\n            input_class_definitions=input_class_definitions,\n            output_type_hint=output_type_hint,\n            output_class_definition=output_class_definition,\n            function_type=function_type\n        )\n\n        return function_description"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        docstring = func_object.__doc__\n\n        input_type_hints = [type_hints[param] for param in signature.parameters if param in type_hints]\n        output_type_hint = type_hints.get('return', None)\n\n        input_class_definitions = [get_class_definition(param) for param in input_type_hints]\n        output_class_definition = get_class_definition(output_type_hint)\n\n        function_type = FunctionType.SYMBOLIC if output_class_definition == Embedding else FunctionType.EMBEDDABLE\n\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=docstring,\n            input_type_hints=input_type_hints,\n            output_type_hint=output_type_hint,\n            input_class_definitions=input_class_definitions,\n            output_class_definition=output_class_definition,\n            function_type=function_type\n        )"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n\n        # Extract function name and docstring\n        func_name = func_object.__name__\n        docstring = inspect.getdoc(func_object)\n\n        # Extract input and output type hints\n        input_type_hints = [param.annotation for param in signature.parameters.values()]\n        output_type_hint = type_hints.get('return', None)\n\n        # Get class definitions for input and output types\n        input_class_definitions = [get_class_definition(hint) for hint in input_type_hints]\n        output_class_definition = get_class_definition(output_type_hint)\n\n        # Determine function type based on output type hint\n        function_type = FunctionType.SYMBOLIC if output_class_definition == Embedding else FunctionType.EMBEDDABLE\n\n        # Create FunctionDescription instance\n        function_description = FunctionDescription(func_name, docstring, input_type_hints, output_type_hint,\n                                                  input_class_definitions, output_class_definition, function_type)\n\n        return function_description"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "\n        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n\n        input_type_hints = [type_hints[param] for param in signature.parameters]\n        output_type_hint = type_hints['return']\n\n        input_class_definitions = [get_class_definition(param) for param in input_type_hints]\n        output_class_definition = get_class_definition(output_type_hint)\n\n        function_type = FunctionType.SYMBOLIC if get_origin(output_type_hint) != Embedding and not isinstance(output_type_hint, Union) else FunctionType.EMBEDDABLE\n\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=func_object.__doc__,\n            input_type_hints=input_type_hints,\n            output_type_hint=output_type_hint,\n            input_class_definitions=input_class_definitions,\n            output_class_definition=output_class_definition,\n            function_type=function_type\n        )"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "\n        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n\n        input_type_hints = [type_hints[param.name] for param in signature.parameters.values()]\n        output_type_hint = type_hints['return']\n\n        input_class_definitions = [get_class_definition(param) for param in input_type_hints]\n        output_class_definition = get_class_definition(output_type_hint)\n\n        if inspect.isclass(output_type_hint) or (isinstance(output_type_hint, type) and issubclass(output_type_hint, Union)):\n            function_type = FunctionType.EMBEDDABLE\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        function_description = FunctionDescription(\n            name=func_object.__name__,\n            docstring=func_object.__doc__,\n            input_type_hints=input_type_hints,\n            output_type_hint=output_type_hint,\n            input_class_definitions=input_class_definitions,\n            output_class_definition=output_class_definition,\n            function_type=function_type\n        )\n\n        return function_description"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n\n        # Extract function name and docstring\n        function_name = func_object.__name__\n        docstring = inspect.getdoc(func_object)\n\n        # Extract input and output type hints\n        input_type_hints = [param.annotation for param in signature.parameters.values()]\n        output_type_hint = signature.return_annotation\n\n        # Get class definitions for input and output types\n        input_class_definitions = [get_class_definition(type_hint) for type_hint in input_type_hints]\n        output_class_definition = get_class_definition(output_type_hint)\n\n        # Determine function type based on output type hint\n        function_type = FunctionType.SYMBOLIC if get_origin(output_type_hint) == Union else FunctionType.EMBEDDABLE\n\n        return FunctionDescription(\n            name=function_name,\n            docstring=docstring,\n            input_type_hints=input_type_hints,\n            input_class_definitions=input_class_definitions,\n            output_type_hint=output_type_hint,\n            output_class_definition=output_class_definition,\n            function_type=function_type\n        )"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        hints = get_type_hints(func_object)\n\n        input_type_hints = [hints[param.name] for param in signature.parameters.values()]\n        output_type_hint = hints.get('return', None)\n\n        input_class_definitions = [get_class_definition(hint) for hint in input_type_hints]\n        output_class_definition = get_class_definition(output_type_hint)\n\n        function_type = FunctionType.SYMBOLIC if output_type_hint and (\n                output_class_definition == Embedding or get_origin(output_type_hint) == Union) else FunctionType.EMBEDDABLE\n\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=func_object.__doc__,\n            input_type_hints=input_type_hints,\n            output_type_hint=output_type_hint,\n            input_class_definitions=input_class_definitions,\n            output_class_definition=output_class_definition,\n            function_type=function_type\n        )"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n\n        input_type_hints = [type_hints[param] for param in signature.parameters]\n        output_type_hint = type_hints.get('return', None)\n\n        input_class_definitions = [get_class_definition(hint) for hint in input_type_hints]\n        output_class_definition = get_class_definition(output_type_hint)\n\n        function_type = FunctionType.SYMBOLIC if output_class_definition == Embedding else FunctionType.EMBEDDABLE\n\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=func_object.__doc__,\n            input_type_hints=input_type_hints,\n            output_type_hint=output_type_hint,\n            input_class_definitions=input_class_definitions,\n            output_class_definition=output_class_definition,\n            function_type=function_type\n        )"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n\n        input_type_hints = [type_hints[param.name] for param in signature.parameters.values()]\n        output_type_hint = type_hints['return']\n\n        input_class_definitions = [get_class_definition(hint) for hint in input_type_hints]\n        output_class_definition = get_class_definition(output_type_hint)\n\n        function_type = FunctionType.SYMBOLIC if get_origin(output_type_hint) == Union and Embedding not in get_origin(output_type_hint).__args__ else FunctionType.EMBEDDABLE\n\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=func_object.__doc__,\n            input_type_hints=input_type_hints,\n            output_type_hint=output_type_hint,\n            input_class_definitions=input_class_definitions,\n            output_class_definition=output_class_definition,\n            function_type=function_type\n        )"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "\n        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n\n        input_type_hints = [param.annotation for param in signature.parameters.values() if param.annotation != inspect.Parameter.empty]\n        output_type_hint = type_hints.get('return')\n\n        input_class_definitions = [get_class_definition(type_hint) for type_hint in input_type_hints]\n        output_class_definition = get_class_definition(output_type_hint)\n\n        function_type = FunctionType.EMBEDDABLE if output_class_definition and issubclass(output_class_definition, Embedding) else FunctionType.SYMBOLIC\n\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=func_object.__doc__,\n            input_type_hints=input_type_hints,\n            input_class_definitions=input_class_definitions,\n            output_type_hint=output_type_hint,\n            output_class_definition=output_class_definition,\n            function_type=function_type\n        )"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n\n        input_type_hints = [type_hints[param.name] for param in signature.parameters.values()]\n        output_type_hint = type_hints.get('return')\n\n        input_class_definitions = [get_class_definition(input_type) for input_type in input_type_hints]\n        output_class_definition = get_class_definition(output_type_hint)\n\n        if output_type_hint and (isinstance(output_type_hint, type) or get_origin(output_type_hint) == Union):\n            if isinstance(output_type_hint, type) and issubclass(output_type_hint, Embedding):\n                function_type = FunctionType.EMBEDDABLE\n            elif get_origin(output_type_hint) == Union and any(issubclass(t, Embedding) for t in output_type_hint.__args__):\n                function_type = FunctionType.EMBEDDABLE\n            else:\n                function_type = FunctionType.SYMBOLIC\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=func_object.__doc__,\n            input_type_hints=input_type_hints,\n            input_class_definitions=input_class_definitions,\n            output_type_hint=output_type_hint,\n            output_class_definition=output_class_definition,\n            function_type=function_type\n        )"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        docstring = inspect.getdoc(func_object)\n\n        input_type_hints = {}\n        output_type_hint = None\n\n        for param in signature.parameters.values():\n            if param.annotation != inspect.Parameter.empty:\n                input_type_hints[param.name] = get_class_definition(param.annotation)\n\n        if 'return' in type_hints:\n            output_type_hint = type_hints['return']\n\n        output_class_definition = get_class_definition(output_type_hint)\n\n        function_type = FunctionType.SYMBOLIC if output_type_hint == Literal['Symbolic'] else FunctionType.EMBEDDABLE\n\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=docstring,\n            input_type_hints=input_type_hints,\n            output_type_hint=output_type_hint,\n            output_class_definition=output_class_definition,\n            function_type=function_type\n        )"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n\n        input_type_hints = [param.annotation for param in signature.parameters.values()]\n        output_type_hint = type_hints.get('return')\n\n        input_class_definitions = [get_class_definition(hint) for hint in input_type_hints]\n        output_class_definition = get_class_definition(output_type_hint)\n\n        if output_class_definition == Embedding or (isinstance(output_type_hint, type) and issubclass(output_type_hint, Embedding)):\n            function_type = FunctionType.EMBEDDABLE\n        elif get_origin(output_type_hint) == Union and any(get_origin(arg) == Embedding for arg in output_type_hint.__args__):\n            function_type = FunctionType.EMBEDDABLE\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=func_object.__doc__,\n            input_type_hints=input_type_hints,\n            output_type_hint=output_type_hint,\n            input_class_definitions=input_class_definitions,\n            output_class_definition=output_class_definition,\n            function_type=function_type\n        )"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        hints = get_type_hints(func_object)\n        name = func_object.__name__\n        docstring = func_object.__doc__\n        input_type_hints = [v for k, v in signature.parameters.items()]\n        output_type_hint = hints.get('return')\n\n        input_class_definitions = {}\n        output_class_definition = None\n\n        for input_type_hint in input_type_hints:\n            if isinstance(input_type_hint, inspect.Parameter):\n                input_class_definitions[input_type_hint.name] = get_class_definition(input_type_hint.annotation)\n\n        if output_type_hint:\n            if inspect.isclass(output_type_hint):\n                output_class_definition = get_class_definition(output_type_hint)\n            elif get_origin(output_type_hint) is Union:\n                for union_type in get_type_hints(output_type_hint):\n                    if union_type is not None and union_type != type(None):\n                        output_class_definition = get_class_definition(union_type)\n                        break\n\n        function_type = FunctionType.SYMBOLIC if output_class_definition is None or issubclass(output_class_definition, Embedding) else FunctionType.EMBEDDABLE\n\n        return FunctionDescription(name, docstring, input_class_definitions, output_class_definition, function_type)"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        docstring = func_object.__doc__\n\n        input_type_hints = [param.annotation for param in signature.parameters.values()]\n        output_type_hint = signature.return_annotation\n\n        input_class_definitions = [get_class_definition(type_hint) for type_hint in input_type_hints]\n        output_class_definition = get_class_definition(output_type_hint)\n\n        if inspect.isclass(output_type_hint) or (isinstance(output_type_hint, type) and issubclass(output_type_hint, Union)):\n            function_type = FunctionType.EMBEDDABLE\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=docstring,\n            input_type_hints=input_type_hints,\n            output_type_hint=output_type_hint,\n            input_class_definitions=input_class_definitions,\n            output_class_definition=output_class_definition,\n            function_type=function_type\n        )"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "\n        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n\n        input_type_hints = [type_hints[param.name] for param in signature.parameters.values()]\n        output_type_hint = type_hints['return']\n\n        input_class_definitions = [get_class_definition(type_hint) for type_hint in input_type_hints]\n        output_class_definition = get_class_definition(output_type_hint)\n\n        function_type = FunctionType.SYMBOLIC if get_origin(output_type_hint) == Union else FunctionType.EMBEDDABLE\n\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=func_object.__doc__,\n            input_type_hints=input_type_hints,\n            input_class_definitions=input_class_definitions,\n            output_type_hint=output_type_hint,\n            output_class_definition=output_class_definition,\n            function_type=function_type\n        )"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "\n        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        docstring = inspect.getdoc(func_object)\n\n        input_type_hints = [type_hints[param] for param in signature.parameters]\n        output_type_hint = type_hints['return']\n\n        input_class_definitions = [get_class_definition(param) for param in input_type_hints]\n        output_class_definition = get_class_definition(output_type_hint)\n\n        function_type = FunctionType.SYMBOLIC if get_origin(output_type_hint) == Union else FunctionType.EMBEDDABLE\n\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=docstring,\n            input_type_hints=input_type_hints,\n            output_type_hint=output_type_hint,\n            input_class_definitions=input_class_definitions,\n            output_class_definition=output_class_definition,\n            function_type=function_type\n        )"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "\n        sig = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        func_name = func_object.__name__\n        docstring = func_object.__doc__\n        parameters = sig.parameters\n\n        input_type_hints = {}\n        output_type_hint = None\n\n        for param_name, param in parameters.items():\n            if param.annotation != inspect.Parameter.empty:\n                input_type_hints[param_name] = get_class_definition(type_hints[param_name])\n\n        for param_name, param in parameters.items():\n            if param.default == inspect.Parameter.empty:\n                output_type_hint = type_hints[param_name]\n                break\n\n        output_class = get_class_definition(output_type_hint)\n\n        function_type = FunctionType.SYMBOLIC if isinstance(output_type_hint, type) and issubclass(output_type_hint, Embedding) else FunctionType.EMBEDDABLE\n\n        return FunctionDescription(func_name, docstring, input_type_hints, output_class, function_type)"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "\n        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "\n        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "\n        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "\n        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "\n        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "\n        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "\n        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "\n        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "\n        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Loaded bit array length does not match the expected length. Reinitializing bit array and indices.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Loaded bit array length does not match expected length. Reinitializing bit array.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Mismatch between loaded bit array length and expected length. Reinitializing bit array.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Loaded bit array length does not match expected length. Reinitializing and saving new state.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Loaded bit array length does not match expected length. Reinitializing and saving new state.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Loaded bit array length does not match expected length. Reinitializing and saving new state.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Loaded bit array length does not match the expected length. Reinitializing and saving new state.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Mismatch in the loaded bit array length. Reinitializing the bit array.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Mismatch between loaded bit array length and expected length. Reinitializing bit array.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Mismatch in the length of loaded bit array and expected length. Reinitializing bit array.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Loaded bit array length does not match expected length. Reinitializing bit array and saving new state.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Loaded bit array length does not match expected length. Reinitializing bit array and indices.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Mismatch in loaded bit array length. Reinitializing and saving new state.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Loaded bit array length does not match expected length. Reinitializing bit array.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Loaded bit array length does not match expected length. Reinitializing bit array.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Loaded bit array length does not match expected length. Reinitializing bit array.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Loaded bit array length does not match the expected length. Reinitializing bit array.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Mismatch in loaded bit array length. Reinitializing and saving new state.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Mismatch in loaded bit array length. Reinitializing and saving new state.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "\n        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"Mismatch in loaded bit array length. Reinitializing bit array and indices.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        indices = [(hash1 + i * hash2) % self.size for i in range(self.hash_count)]\n        for index in indices:\n            if not self.bit_array[index]:\n                return False\n        return True"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        indices = [hash1 % self.size, hash2 % self.size]\n\n        for index in indices:\n            if not self.bit_array[index]:\n                return False\n\n        return True"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "\n        hash1, hash2 = self.hash_functions(string)\n        indices = [(hash1 + i * hash2) % self.size for i in range(self.hash_count)]\n\n        for index in indices:\n            if not self.bit_array[index]:\n                return False\n\n        return True"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        indices = [(hash1 + i * hash2) % self.size for i in range(self.hash_count)]\n        for index in indices:\n            if not self.bit_array[index]:\n                return False\n        return True"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "\n        hash1, hash2 = self.hash_functions(string)\n        indices = [(hash1 + i * hash2) % self.size for i in range(self.hash_count)]\n        for index in indices:\n            if not self.bit_array[index]:\n                return False\n        return True"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "\n        hash1, hash2 = self.hash_functions(string)\n        indices = [(hash1 + i * hash2) % self.size for i in range(self.hash_count)]\n        for index in indices:\n            if not self.bit_array[index]:\n                return False\n        return True"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        indices = [(hash1 + i * hash2) % self.size for i in range(self.hash_count)]\n        for index in indices:\n            if not self.bit_array[index]:\n                return False\n        return True"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        indices = [(hash1 + i * hash2) % self.size for i in range(self.hash_count)]\n        for index in indices:\n            if not self.bit_array[index]:\n                return False\n        return True"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "\n        hash1, hash2 = self.hash_functions(string)\n        indices = [(hash1 + i * hash2) % self.size for i in range(self.hash_count)]\n\n        for index in indices:\n            if not self.bit_array[index]:\n                return False\n        return True"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        indices = [hash1 % self.size, hash2 % self.size]\n\n        for index in indices:\n            if not self.bit_array[index]:\n                return False\n\n        return True"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "\n        hash1, hash2 = self.hash_functions(string)\n        indices = [(hash1 + i * hash2) % self.size for i in range(self.hash_count)]\n\n        for index in indices:\n            if not self.bit_array[index]:\n                return False\n\n        return True"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        indices = [hash1 % self.size, hash2 % self.size]\n\n        for index in indices:\n            if not self.bit_array[index]:\n                return False\n        return True"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        indices = [hash1 % self.size, hash2 % self.size]\n\n        for index in indices:\n            if not self.bit_array[index]:\n                return False\n        return True"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        indices = [(hash1 + i * hash2) % self.size for i in range(self.hash_count)]\n        for index in indices:\n            if not self.bit_array[index]:\n                return False\n        return True"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        indices = [(hash1 + i * hash2) % self.size for i in range(self.hash_count)]\n        for index in indices:\n            if not self.bit_array[index]:\n                return False\n        return True"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        indices = [(hash1 + i * hash2) % self.size for i in range(self.hash_count)]\n        for index in indices:\n            if not self.bit_array[index]:\n                return False\n        return True"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        indices = []\n        for i in range(self.hash_count):\n            index = (hash1 + i * hash2) % self.size\n            indices.append(index)\n            if not self.bit_array[index]:\n                return False\n        return True"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "\n        hash1, hash2 = self.hash_functions(string)\n        indices = [(hash1 + i * hash2) % self.size for i in range(self.hash_count)]\n        for index in indices:\n            if not self.bit_array[index]:\n                return False\n        return True"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "\n        hash1, hash2 = self.hash_functions(string)\n        indices = [(hash1 + i * hash2) % self.size for i in range(self.hash_count)]\n        for index in indices:\n            if not self.bit_array[index]:\n                return False\n        return True"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        indices = [(hash1 + i * hash2) % self.size for i in range(self.hash_count)]\n        for index in indices:\n            if not self.bit_array[index]:\n                return False\n        return True"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = np.random.dirichlet(np.ones(n))\n    if zeros > 0:\n        zero_indices = np.random.choice(range(n), zeros, replace=False)\n        weights[zero_indices] = 0\n        weights /= np.sum(weights)  # Normalize the weights\n    return weights"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = np.random.dirichlet(np.ones(n))\n    if zeros > 0:\n        zero_indices = np.random.choice(range(n), zeros, replace=False)\n        weights[zero_indices] = 0\n        weights /= np.sum(weights)\n    return weights"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = rand_weights_dirichlet(n)\n    if zeros > 0:\n        idx = np.random.choice(range(n), zeros, replace=False)\n        weights[idx] = 0\n        weights /= np.sum(weights)\n    return weights"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = rand_weights_dirichlet(n)\n    if zeros > 0:\n        zero_indices = np.random.choice(range(n), zeros, replace=False)\n        weights[zero_indices] = 0\n        weights /= np.sum(weights)  # Normalize the weights to sum up to one\n    return weights"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"`zeros` must not exceed `n`\")\n    weights = rand_weights_dirichlet(n)\n    if zeros > 0:\n        zero_indices = np.random.choice(range(n), zeros, replace=False)\n        weights[zero_indices] = 0\n        weights /= np.sum(weights)\n    return weights"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = rand_weights_dirichlet(n)\n    if zeros > 0:\n        zero_indices = np.random.choice(range(n), zeros, replace=False)\n        weights[zero_indices] = 0\n        weights /= np.sum(weights)  # Normalize weights to sum up to one\n    return weights"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"`zeros` must not exceed `n`\")\n    weights = np.random.dirichlet(np.ones(n))\n    if zeros > 0:\n        zero_indices = np.random.choice(range(n), zeros, replace=False)\n        weights[zero_indices] = 0\n        weights /= np.sum(weights)  # Renormalize weights to sum up to one\n    return weights"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = rand_weights_dirichlet(n)\n    if zeros > 0:\n        zero_indices = np.random.choice(range(n), zeros, replace=False)\n        weights[zero_indices] = 0\n        weights = weights / np.sum(weights)  # Normalize weights to sum up to one\n    return weights"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = np.random.dirichlet(np.ones(n))\n    if zeros > 0:\n        zero_indices = np.random.choice(range(n), zeros, replace=False)\n        weights[zero_indices] = 0\n        weights /= np.sum(weights)  # Re-normalize after setting some weights to zero\n    return weights"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = rand_weights_dirichlet(n)\n    if zeros > 0:\n        idx = np.random.choice(range(n), zeros, replace=False)\n        weights[idx] = 0\n        weights /= np.sum(weights)  # Normalize the weights to sum up to one\n    return weights"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = np.random.dirichlet(np.ones(n))\n    if zeros > 0:\n        idx = np.random.choice(range(n), zeros, replace=False)\n        weights[idx] = 0\n        weights = weights / np.sum(weights)  # Normalize weights to sum up to one\n    return weights"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = np.random.dirichlet(np.ones(n))\n    if zeros > 0:\n        zero_indices = np.random.choice(range(n), size=zeros, replace=False)\n        weights[zero_indices] = 0\n        weights /= np.sum(weights)  # Re-normalize the weights\n    return weights"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"Number of zeros cannot exceed total number of weights\")\n\n    weights = rand_weights_dirichlet(n)\n\n    if zeros > 0:\n        idx = np.random.choice(range(n), zeros, replace=False)\n        weights[idx] = 0\n\n    return weights"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = np.random.dirichlet(np.ones(n))\n    if zeros > 0:\n        zero_indices = np.random.choice(range(n), zeros, replace=False)\n        weights[zero_indices] = 0\n        weights /= np.sum(weights)  # Normalize the weights to sum up to one\n    return weights"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = np.random.dirichlet(np.ones(n))\n    if zeros > 0:\n        zero_indices = np.random.choice(range(n), zeros, replace=False)\n        weights[zero_indices] = 0\n        weights /= np.sum(weights)  # Normalize the weights to ensure they sum up to one\n    return weights"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = np.random.dirichlet(np.ones(n))\n    if zeros > 0:\n        zero_indices = np.random.choice(range(n), zeros, replace=False)\n        weights[zero_indices] = 0\n        weights /= np.sum(weights)  # Normalize the weights to sum up to one\n    return weights"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = rand_weights_dirichlet(n)\n    if zeros > 0:\n        zero_indices = np.random.choice(np.arange(n), zeros, replace=False)\n        weights[zero_indices] = 0\n        weights /= np.sum(weights)\n    return weights"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = rand_weights_dirichlet(n)\n    if zeros > 0:\n        zero_indices = np.random.choice(range(n), zeros, replace=False)\n        weights[zero_indices] = 0\n        weights /= np.sum(weights)\n    return weights"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = rand_weights_dirichlet(n)\n    if zeros > 0:\n        idx = np.random.choice(range(n), zeros, replace=False)\n        weights[idx] = 0\n        weights = weights / np.sum(weights)\n    return weights"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = rand_weights_dirichlet(n)\n    if zeros > 0:\n        zero_indices = np.random.choice(range(n), zeros, replace=False)\n        weights[zero_indices] = 0\n        weights /= np.sum(weights)\n    return weights"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "\n        self.distilled_model = config_factory.create_model_config(json_dict.get('distilled_model', DEFAULT_STUDENT_MODELS[DEFAULT_DISTILLED_MODEL_NAME]))\n        self.current_model_stats = json_dict.get('current_model_stats', {\"trained_on_datapoints\": 0, \"running_faults\": []})\n        self.last_training_run = json_dict.get('last_training_run', {\"trained_on_datapoints\": 0})\n        self.current_training_run = json_dict.get('current_training_run', {})\n        self.nr_of_training_runs = json_dict.get('nr_of_training_runs', 0)\n        self.teacher_models = [config_factory.create_model_config(teacher_model) for teacher_model in json_dict.get('teacher_models', [DEFAULT_TEACHER_MODELS[teacher_model_name] for teacher_model_name in DEFAULT_TEACHER_MODEL_NAMES])]"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.create_model_config(json_dict.get('distilled_model', DEFAULT_STUDENT_MODELS[DEFAULT_DISTILLED_MODEL_NAME]))\n        self.current_model_stats = json_dict.get('current_model_stats', {\"trained_on_datapoints\": 0, \"running_faults\": []})\n        self.last_training_run = json_dict.get('last_training_run', {\"trained_on_datapoints\": 0})\n        self.current_training_run = json_dict.get('current_training_run', {})\n        self.nr_of_training_runs = json_dict.get('nr_of_training_runs', 0)\n        self.teacher_models = [config_factory.create_model_config(teacher_model) for teacher_model in json_dict.get('teacher_models', [DEFAULT_TEACHER_MODELS[teacher_model_name] for teacher_model_name in DEFAULT_TEACHER_MODEL_NAMES])]"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "\n        self.distilled_model = config_factory.create_model_config(json_dict.get('distilled_model', DEFAULT_STUDENT_MODELS[DEFAULT_DISTILLED_MODEL_NAME]))\n        self.current_model_stats = json_dict.get('current_model_stats', {\"trained_on_datapoints\": 0, \"running_faults\": []})\n        self.last_training_run = json_dict.get('last_training_run', {\"trained_on_datapoints\": 0})\n        self.current_training_run = json_dict.get('current_training_run', {})\n        self.teacher_models = [config_factory.create_model_config(teacher_model) for teacher_model in json_dict.get('teacher_models', [DEFAULT_TEACHER_MODELS[teacher_model_name] for teacher_model_name in DEFAULT_TEACHER_MODEL_NAMES])]\n        self.nr_of_training_runs = json_dict.get('nr_of_training_runs', 0)\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "\n        if 'distilled_model' in json_dict:\n            self.distilled_model = config_factory.create_model_config(json_dict['distilled_model'])\n\n        if 'current_model_stats' in json_dict:\n            self.current_model_stats = json_dict['current_model_stats']\n\n        if 'last_training_run' in json_dict:\n            self.last_training_run = json_dict['last_training_run']\n\n        if 'current_training_run' in json_dict:\n            self.current_training_run = json_dict['current_training_run']\n\n        if 'nr_of_training_runs' in json_dict:\n            self.nr_of_training_runs = json_dict['nr_of_training_runs']\n\n        if 'teacher_models' in json_dict:\n            self.teacher_models = [config_factory.create_model_config(teacher_model) for teacher_model in json_dict['teacher_models']]\n\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.create_model_config(json_dict.get('distilled_model', DEFAULT_STUDENT_MODELS[DEFAULT_DISTILLED_MODEL_NAME]))\n        self.current_model_stats = json_dict.get('current_model_stats', {\"trained_on_datapoints\": 0, \"running_faults\": []})\n        self.last_training_run = json_dict.get('last_training_run', {\"trained_on_datapoints\": 0})\n        self.current_training_run = json_dict.get('current_training_run', {})\n        self.nr_of_training_runs = json_dict.get('nr_of_training_runs', 0)\n        self.teacher_models = [config_factory.create_model_config(teacher_model) for teacher_model in json_dict.get('teacher_models', [DEFAULT_TEACHER_MODELS[teacher_model_name] for teacher_model_name in DEFAULT_TEACHER_MODEL_NAMES])]\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.create_model_config(json_dict.get(DISTILLED_MODEL, DEFAULT_DISTILLED_MODEL_NAME))\n        self.current_model_stats = json_dict.get(\"current_model_stats\", {\n            \"trained_on_datapoints\": 0,\n            \"running_faults\": []\n        })\n        self.last_training_run = json_dict.get(\"last_training_run\", {\"trained_on_datapoints\": 0})\n        self.current_training_run = json_dict.get(\"current_training_run\", {})\n        self.nr_of_training_runs = json_dict.get(\"nr_of_training_runs\", 0)\n        self.teacher_models = [config_factory.create_model_config(teacher_model) for teacher_model in json_dict.get(\"teacher_models\", DEFAULT_TEACHER_MODEL_NAMES)]\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.get_model_config(json_dict.get('distilled_model', DEFAULT_STUDENT_MODELS[DEFAULT_DISTILLED_MODEL_NAME]))\n        self.current_model_stats = json_dict.get('current_model_stats', {\"trained_on_datapoints\": 0, \"running_faults\": []})\n        self.last_training_run = json_dict.get('last_training_run', {\"trained_on_datapoints\": 0})\n        self.current_training_run = json_dict.get('current_training_run', {})\n        self.teacher_models = [config_factory.get_model_config(teacher_model) for teacher_model in json_dict.get('teacher_models', [DEFAULT_TEACHER_MODELS[teacher_model_name] for teacher_model_name in DEFAULT_TEACHER_MODEL_NAMES])]\n        self.nr_of_training_runs = json_dict.get('nr_of_training_runs', 0)"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "\n        if \"distilled_model\" in json_dict:\n            self.distilled_model = config_factory.get_model_config(json_dict[\"distilled_model\"])\n        if \"current_model_stats\" in json_dict:\n            self.current_model_stats = json_dict[\"current_model_stats\"]\n        if \"last_training_run\" in json_dict:\n            self.last_training_run = json_dict[\"last_training_run\"]\n        if \"current_training_run\" in json_dict:\n            self.current_training_run = json_dict[\"current_training_run\"]\n        if \"nr_of_training_runs\" in json_dict:\n            self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = [config_factory.get_model_config(teacher_model) for teacher_model in json_dict[\"teacher_models\"]]\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.get_model_config(json_dict.get(DISTILLED_MODEL, DEFAULT_DISTILLED_MODEL_NAME))\n        self.current_model_stats = json_dict.get(\"current_model_stats\", {\n            \"trained_on_datapoints\": 0,\n            \"running_faults\": []\n        })\n        self.last_training_run = json_dict.get(\"last_training_run\", {\"trained_on_datapoints\": 0})\n        self.current_training_run = json_dict.get(\"current_training_run\", {})\n        self.nr_of_training_runs = json_dict.get(\"nr_of_training_runs\", 0)\n        self.teacher_models = [config_factory.get_model_config(teacher_model) for teacher_model in json_dict.get(\"teacher_models\", DEFAULT_TEACHER_MODEL_NAMES)]\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.get_config(json_dict.get('distilled_model', DEFAULT_STUDENT_MODELS[DEFAULT_DISTILLED_MODEL_NAME]))\n        self.current_model_stats = json_dict.get('current_model_stats', {\"trained_on_datapoints\": 0, \"running_faults\": []})\n        self.last_training_run = json_dict.get('last_training_run', {\"trained_on_datapoints\": 0})\n        self.current_training_run = json_dict.get('current_training_run', {})\n        self.teacher_models = [config_factory.get_config(teacher_model) for teacher_model in json_dict.get('teacher_models', [DEFAULT_TEACHER_MODELS[teacher_model_name] for teacher_model_name in DEFAULT_TEACHER_MODEL_NAMES])]\n        self.nr_of_training_runs = json_dict.get('nr_of_training_runs', 0)\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.get_model_config(json_dict.get('distilled_model', DEFAULT_STUDENT_MODELS[DEFAULT_DISTILLED_MODEL_NAME]))\n        self.current_model_stats = json_dict.get('current_model_stats', {\"trained_on_datapoints\": 0, \"running_faults\": []})\n        self.last_training_run = json_dict.get('last_training_run', {\"trained_on_datapoints\": 0})\n        self.current_training_run = json_dict.get('current_training_run', {})\n        self.teacher_models = [config_factory.get_model_config(teacher_model) for teacher_model in json_dict.get('teacher_models', [DEFAULT_TEACHER_MODELS[teacher_model_name] for teacher_model_name in DEFAULT_TEACHER_MODEL_NAMES])]\n        self.nr_of_training_runs = json_dict.get('nr_of_training_runs', 0)"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "\n        if 'distilled_model' in json_dict:\n            self.distilled_model = config_factory.create_model_config(json_dict['distilled_model'])\n        if 'current_model_stats' in json_dict:\n            self.current_model_stats = json_dict['current_model_stats']\n        if 'last_training_run' in json_dict:\n            self.last_training_run = json_dict['last_training_run']\n        if 'current_training_run' in json_dict:\n            self.current_training_run = json_dict['current_training_run']\n        if 'nr_of_training_runs' in json_dict:\n            self.nr_of_training_runs = json_dict['nr_of_training_runs']\n        if 'teacher_models' in json_dict:\n            self.teacher_models = [config_factory.create_model_config(teacher_model) for teacher_model in json_dict['teacher_models']]\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        for key, value in json_dict.items():\n            if key == \"distilled_model\":\n                self.distilled_model = config_factory.create_model_config(value)\n            elif key == \"current_model_stats\":\n                self.current_model_stats = value\n            elif key == \"last_training_run\":\n                self.last_training_run = value\n            elif key == \"current_training_run\":\n                self.current_training_run = value\n            elif key == \"nr_of_training_runs\":\n                self.nr_of_training_runs = value\n            elif key == \"teacher_models\":\n                self.teacher_models = [config_factory.create_model_config(teacher_model) for teacher_model in value]\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "\n        if 'distilled_model' in json_dict:\n            self.distilled_model = config_factory.create_model_config(json_dict['distilled_model'])\n        if 'current_model_stats' in json_dict:\n            self.current_model_stats = json_dict['current_model_stats']\n        if 'last_training_run' in json_dict:\n            self.last_training_run = json_dict['last_training_run']\n        if 'current_training_run' in json_dict:\n            self.current_training_run = json_dict['current_training_run']\n        if 'nr_of_training_runs' in json_dict:\n            self.nr_of_training_runs = json_dict['nr_of_training_runs']\n        if 'teacher_models' in json_dict:\n            self.teacher_models = [config_factory.create_model_config(teacher_model) for teacher_model in json_dict['teacher_models']]"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        if 'distilled_model' in json_dict:\n            self.distilled_model = config_factory.create_config(json_dict['distilled_model'])\n        if 'current_model_stats' in json_dict:\n            self.current_model_stats = json_dict['current_model_stats']\n        if 'last_training_run' in json_dict:\n            self.last_training_run = json_dict['last_training_run']\n        if 'current_training_run' in json_dict:\n            self.current_training_run = json_dict['current_training_run']\n        if 'nr_of_training_runs' in json_dict:\n            self.nr_of_training_runs = json_dict['nr_of_training_runs']\n        if 'teacher_models' in json_dict:\n            self.teacher_models = [config_factory.create_config(teacher_model) for teacher_model in json_dict['teacher_models']]\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.get_model_config(json_dict.get('distilled_model', DEFAULT_STUDENT_MODELS[DEFAULT_DISTILLED_MODEL_NAME]))\n        self.current_model_stats = json_dict.get('current_model_stats', {\"trained_on_datapoints\": 0, \"running_faults\": []})\n        self.last_training_run = json_dict.get('last_training_run', {\"trained_on_datapoints\": 0})\n        self.current_training_run = json_dict.get('current_training_run', {})\n        self.teacher_models = [config_factory.get_model_config(teacher_model) for teacher_model in json_dict.get('teacher_models', DEFAULT_TEACHER_MODELS.values())]\n        self.nr_of_training_runs = json_dict.get('nr_of_training_runs', 0)"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        for key, value in json_dict.items():\n            if hasattr(self, key):\n                setattr(self, key, value)\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        for key, value in json_dict.items():\n            if hasattr(self, key):\n                setattr(self, key, value)\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        for key, value in json_dict.items():\n            if hasattr(self, key):\n                setattr(self, key, value)\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        for key, value in json_dict.items():\n            if key == \"distilled_model\":\n                self.distilled_model = config_factory.create_config(value)\n            elif key == \"current_model_stats\":\n                self.current_model_stats = value\n            elif key == \"last_training_run\":\n                self.last_training_run = value\n            elif key == \"current_training_run\":\n                self.current_training_run = value\n            elif key == \"nr_of_training_runs\":\n                self.nr_of_training_runs = value\n            elif key == \"teacher_models\":\n                self.teacher_models = [config_factory.create_config(teacher_model) for teacher_model in value]\n        return self"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "\n        self.check_api_key()\n\n        try:\n            response = requests.post(\n                OPENAI_URL,\n                headers={\"Authorization\": f\"Bearer {self.api_key}\"},\n                json={\n                    \"model\": model.model_name,\n                    \"messages\": [\n                        {\"role\": \"system\", \"content\": system_message},\n                        {\"role\": \"user\", \"content\": prompt}\n                    ],\n                    **kwargs\n                }\n            )\n            response.raise_for_status()\n            response_data = response.json()\n            generated_text = response_data[\"choices\"][0][\"message\"][\"content\"]\n            return generated_text\n        except requests.exceptions.RequestException as e:\n            logging.error(f\"An error occurred: {e}\")\n            return None"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        try:\n            response = requests.post(\n                OPENAI_URL,\n                headers={\"Authorization\": f\"Bearer {self.api_key}\"},\n                json={\n                    \"model\": model.model_name,\n                    \"prompt\": f\"{system_message}\\n{prompt}\",\n                    **kwargs\n                }\n            )\n            response.raise_for_status()\n            response_data = response.json()\n            generated_text = response_data[\"choices\"][0][\"text\"]\n            return generated_text\n        except requests.exceptions.RequestException as e:\n            print(f\"An error occurred: {e}\")\n            return None"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        try:\n            response = requests.post(\n                OPENAI_URL,\n                headers={\"Authorization\": f\"Bearer {self.api_key}\"},\n                json={\n                    \"model\": model.model_name,\n                    \"messages\": [\n                        {\"role\": \"system\", \"content\": system_message},\n                        {\"role\": \"user\", \"content\": prompt}\n                    ],\n                    **kwargs\n                }\n            )\n\n            response.raise_for_status()\n\n            data = response.json()\n            generated_text = data[\"choices\"][0][\"message\"][\"content\"]\n\n            return generated_text\n        except Exception as e:\n            print(f\"An error occurred: {e}\")\n            return None"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        try:\n            response = requests.post(\n                OPENAI_URL,\n                headers={\n                    \"Authorization\": f\"Bearer {self.api_key}\",\n                    \"Content-Type\": \"application/json\"\n                },\n                json={\n                    \"model\": model.model_name,\n                    \"messages\": [\n                        {\"role\": \"system\", \"content\": system_message},\n                        {\"role\": \"user\", \"content\": prompt}\n                    ],\n                    **kwargs\n                }\n            )\n            response.raise_for_status()\n            data = response.json()\n            generated_text = data[\"choices\"][0][\"message\"][\"content\"]\n            return generated_text\n        except Exception as e:\n            logging.error(f\"An error occurred: {e}\")\n            return None"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        try:\n            response = requests.post(\n                OPENAI_URL,\n                headers={\"Authorization\": f\"Bearer {self.api_key}\"},\n                json={\n                    \"model\": model.model_name,\n                    \"messages\": [\n                        {\"role\": \"system\", \"content\": system_message},\n                        {\"role\": \"user\", \"content\": prompt}\n                    ],\n                    **kwargs\n                }\n            )\n            response.raise_for_status()\n            data = response.json()\n            generated_text = data[\"choices\"][0][\"message\"][\"content\"]\n            return generated_text\n        except Exception as e:\n            print(f\"An error occurred: {e}\")\n            return None"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        try:\n            response = requests.post(\n                OPENAI_URL,\n                headers={\"Authorization\": f\"Bearer {self.api_key}\"},\n                json={\n                    \"model\": model.model_name,\n                    \"messages\": [\n                        {\"role\": \"system\", \"content\": system_message},\n                        {\"role\": \"user\", \"content\": prompt}\n                    ],\n                    **kwargs\n                }\n            )\n            response.raise_for_status()\n            data = response.json()\n            generated_text = data[\"choices\"][0][\"message\"][\"content\"]\n            return generated_text\n        except requests.exceptions.RequestException as e:\n            logging.error(f\"An error occurred: {e}\")\n            return None"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        try:\n            response = requests.post(\n                OPENAI_URL,\n                headers={\"Authorization\": f\"Bearer {self.api_key}\"},\n                json={\n                    \"model\": model.model_name,\n                    \"messages\": [\n                        {\"role\": \"system\", \"content\": system_message},\n                        {\"role\": \"user\", \"content\": prompt}\n                    ],\n                    **kwargs\n                }\n            )\n            response_data = response.json()\n            generated_text = response_data[\"choices\"][0][\"text\"].strip()\n            return generated_text\n        except Exception as e:\n            print(f\"An error occurred: {e}\")\n            return None"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n        \n        try:\n            response = requests.post(\n                OPENAI_URL,\n                headers={\"Authorization\": f\"Bearer {self.api_key}\"},\n                json={\n                    \"model\": model.model_name,\n                    \"messages\": [\n                        {\"role\": \"system\", \"content\": system_message},\n                        {\"role\": \"user\", \"content\": prompt}\n                    ],\n                    **kwargs\n                }\n            )\n            response.raise_for_status()\n            response_data = response.json()\n            generated_text = response_data[\"choices\"][0][\"message\"][\"content\"]\n            return generated_text\n        except requests.exceptions.RequestException as e:\n            logging.error(f\"An error occurred: {e}\")\n            return None"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        try:\n            response = requests.post(\n                OPENAI_URL,\n                headers={\"Authorization\": f\"Bearer {self.api_key}\"},\n                json={\n                    \"model\": model.model_name,\n                    \"messages\": [\n                        {\"role\": \"system\", \"content\": system_message},\n                        {\"role\": \"user\", \"content\": prompt}\n                    ],\n                    **kwargs\n                }\n            )\n            response.raise_for_status()\n            data = response.json()\n            generated_text = data[\"choices\"][0][\"message\"][\"content\"]\n            return generated_text\n        except Exception as e:\n            print(f\"An error occurred: {e}\")\n            return None"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "\n        self.check_api_key()\n\n        try:\n            response = requests.post(\n                OPENAI_URL,\n                headers={\"Authorization\": f\"Bearer {self.api_key}\"},\n                json={\n                    \"model\": model.model_name,\n                    \"messages\": [\n                        {\"role\": \"system\", \"content\": system_message},\n                        {\"role\": \"user\", \"content\": prompt}\n                    ],\n                    **kwargs\n                }\n            )\n            response.raise_for_status()\n            data = response.json()\n            generated_text = data[\"choices\"][0][\"message\"][\"content\"]\n            return generated_text\n        except Exception as e:\n            logging.error(f\"An error occurred: {e}\")\n            return None"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "\n        self.check_api_key()\n\n        try:\n            response = requests.post(\n                OPENAI_URL,\n                headers={\"Authorization\": f\"Bearer {self.api_key}\"},\n                json={\n                    \"model\": model.model_name,\n                    \"messages\": [\n                        {\"role\": \"system\", \"content\": system_message},\n                        {\"role\": \"user\", \"content\": prompt}\n                    ],\n                    **kwargs\n                }\n            )\n            response.raise_for_status()\n            data = response.json()\n            generated_text = data[\"choices\"][0][\"message\"][\"content\"]\n            return generated_text\n        except Exception as e:\n            logging.error(f\"An error occurred: {e}\")\n            return None"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "\n        self.check_api_key()\n\n        try:\n            response = requests.post(\n                OPENAI_URL,\n                headers={\"Authorization\": f\"Bearer {self.api_key}\"},\n                json={\n                    \"model\": model.model_name,\n                    \"messages\": [\n                        {\"role\": \"system\", \"content\": system_message},\n                        {\"role\": \"user\", \"content\": prompt}\n                    ],\n                    **kwargs\n                }\n            )\n            response.raise_for_status()\n            response_data = response.json()\n            generated_text = response_data[\"choices\"][0][\"message\"][\"content\"]\n            return generated_text\n        except Exception as e:\n            print(f\"An error occurred: {e}\")\n            return None"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        try:\n            response = requests.post(\n                OPENAI_URL,\n                headers={\"Authorization\": f\"Bearer {self.api_key}\"},\n                json={\n                    \"model\": model.model_name,\n                    \"messages\": [\n                        {\"role\": \"system\", \"content\": system_message},\n                        {\"role\": \"user\", \"content\": prompt}\n                    ],\n                    **kwargs\n                }\n            )\n            response.raise_for_status()\n            data = response.json()\n            generated_text = data[\"choices\"][0][\"message\"][\"content\"]\n            return generated_text\n        except requests.exceptions.RequestException as e:\n            logging.error(f\"An error occurred: {e}\")\n            return None"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        try:\n            response = requests.post(\n                OPENAI_URL,\n                headers={\"Authorization\": f\"Bearer {self.api_key}\"},\n                json={\n                    \"model\": model.model_name,\n                    \"system_message\": system_message,\n                    \"prompt\": prompt,\n                    **kwargs\n                }\n            )\n            response.raise_for_status()\n            data = response.json()\n            generated_text = data[\"choices\"][0][\"text\"].strip()\n            return generated_text\n        except Exception as e:\n            logging.error(f\"An error occurred: {e}\")\n            return None"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        try:\n            response = requests.post(\n                OPENAI_URL,\n                headers={\"Authorization\": f\"Bearer {self.api_key}\"},\n                json={\n                    \"model\": model.model_name,\n                    \"messages\": [\n                        {\"role\": \"system\", \"content\": system_message},\n                        {\"role\": \"user\", \"content\": prompt}\n                    ],\n                    **kwargs\n                }\n            )\n            response.raise_for_status()\n            data = response.json()\n            generated_text = data[\"choices\"][0][\"message\"][\"content\"]\n            return generated_text\n        except requests.exceptions.RequestException as e:\n            logging.error(f\"An error occurred: {e}\")\n            return None"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "\n        self.check_api_key()\n\n        try:\n            response = requests.post(\n                OPENAI_URL,\n                headers={\"Authorization\": f\"Bearer {self.api_key}\"},\n                json={\n                    \"model\": model.model_name,\n                    \"messages\": [\n                        {\"role\": \"system\", \"content\": system_message},\n                        {\"role\": \"user\", \"content\": prompt}\n                    ],\n                    **kwargs\n                }\n            )\n            response.raise_for_status()\n            data = response.json()\n            generated_text = data[\"choices\"][0][\"message\"][\"content\"]\n            return generated_text\n        except requests.exceptions.RequestException as e:\n            logging.error(f\"An error occurred: {e}\")\n            return None"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "\n        self.check_api_key()\n\n        try:\n            response = requests.post(\n                OPENAI_URL,\n                headers={\"Authorization\": f\"Bearer {self.api_key}\"},\n                json={\n                    \"model\": model.model_name,\n                    \"messages\": [\n                        {\"role\": \"system\", \"content\": system_message},\n                        {\"role\": \"user\", \"content\": prompt}\n                    ],\n                    **kwargs\n                }\n            )\n\n            if response.status_code == 200:\n                data = response.json()\n                generated_text = data[\"choices\"][0][\"message\"][\"content\"]\n                return generated_text\n            else:\n                logging.error(f\"Failed to generate response from OpenAI API. Status code: {response.status_code}, Message: {response.text}\")\n                return None\n\n        except Exception as e:\n            logging.error(f\"An error occurred: {e}\")\n            return None"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        try:\n            response = requests.post(\n                OPENAI_URL,\n                headers={\"Authorization\": f\"Bearer {self.api_key}\"},\n                json={\n                    \"model\": model.model_name,\n                    \"messages\": [\n                        {\"role\": \"system\", \"content\": system_message},\n                        {\"role\": \"user\", \"content\": prompt}\n                    ],\n                    **kwargs\n                }\n            )\n            response.raise_for_status()\n            response_data = response.json()\n            generated_text = response_data[\"choices\"][0][\"text\"]\n            # Remove any parsing helper tokens\n            # (e.g., special tokens like "}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "\n        self.check_api_key()\n\n        try:\n            response = requests.post(\n                OPENAI_URL,\n                headers={\"Authorization\": f\"Bearer {self.api_key}\"},\n                json={\n                    \"model\": model.model_name,\n                    \"messages\": [\n                        {\"role\": \"system\", \"content\": system_message},\n                        {\"role\": \"user\", \"content\": prompt}\n                    ],\n                    **kwargs\n                }\n            )\n            response.raise_for_status()\n            response_data = response.json()\n            generated_text = response_data[\"choices\"][0][\"text\"].strip()\n            return generated_text\n        except requests.exceptions.RequestException as e:\n            logging.error(f\"An error occurred: {e}\")\n            return None"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "\n        self.check_api_key()\n\n        try:\n            response = requests.post(\n                OPENAI_URL,\n                headers={\"Authorization\": f\"Bearer {self.api_key}\"},\n                json={\n                    \"model\": model.model_name,\n                    \"messages\": [\n                        {\"role\": \"system\", \"content\": system_message},\n                        {\"role\": \"user\", \"content\": prompt}\n                    ],\n                    **kwargs\n                }\n            )\n\n            response.raise_for_status()\n\n            data = response.json()\n\n            generated_text = data[\"choices\"][0][\"message\"][\"content\"]\n\n            # Remove parsing helper tokens\n            # Example: Remove "}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2:\n        raise ValueError(\"Input matrix must be two-dimensional\")\n    n, m = x.shape\n    if n != m:\n        raise ValueError(\"Input matrix must be square\")"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2:\n        raise ValueError(\"Input array must be a 2D matrix\")\n    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"Input matrix is not square\")"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2:\n        raise ValueError(\"Input array must be a 2D matrix\")\n    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"Input array must be a square matrix\")"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"Input matrix is not square\")"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"Input matrix is not square\")"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2:\n        raise ValueError(\"Input array must be a 2D array\")\n    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"Input array must be a square matrix\")"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2:\n        raise ValueError(\"Input matrix must be 2-dimensional\")\n    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"Input matrix must be square\")"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2:\n        raise ValueError(\"Input array must be a 2D matrix\")\n    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"Input matrix is not square\")"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2:\n        raise ValueError(\"Input matrix must be 2-dimensional\")\n    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"Input matrix must be square\")"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2:\n        raise ValueError(\"Input array must be a 2D array\")\n    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"Input array must be a square matrix\")"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2:\n        raise ValueError(\"Input array must be a 2D array\")\n    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"Input array must be a square matrix\")"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2:\n        raise ValueError(\"Input array must be a 2D matrix\")\n    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"Input matrix is not square\")"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2:\n        raise ValueError(\"Input matrix must be 2-dimensional\")\n    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"Input matrix must be square\")"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2:\n        raise ValueError(\"Input array must be a 2D matrix\")\n    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"Input matrix is not square\")"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2:\n        raise ValueError(\"Input array must be a 2D array\")\n    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"Input array must be a square matrix\")"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2:\n        raise ValueError(\"Input array must be a 2D matrix\")\n    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"Input matrix is not square\")"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"Input matrix is not square\")"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2:\n        raise ValueError(\"Input array must be a 2D matrix\")\n    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"Input matrix is not square\")"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"Input matrix is not a square matrix\")"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The input matrix is not square\")"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")"}
{"namespace": "ref_utils.l2_normalize", "completion": "  x_norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  x_norm = jnp.maximum(x_norm, grad_eps)\n  return x / x_norm"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Compute the squared L2 norm along the last axis\n  norm_squared = jnp.sum(x**2, axis=-1, keepdims=True)\n\n  # Clamp the squared norm to a minimum value to prevent exploding gradients\n  norm_squared = jnp.maximum(norm_squared, grad_eps)\n\n  # Compute the L2 norm\n  norm = jnp.sqrt(norm_squared)\n\n  # Normalize the array\n  return x / norm"}
{"namespace": "ref_utils.l2_normalize", "completion": "  return x / jnp.maximum(jnp.sqrt(jnp.sum(x**2, axis=-1, keepdims=True)), grad_eps)"}
{"namespace": "ref_utils.l2_normalize", "completion": "  x_norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  x_norm = jnp.maximum(x_norm, grad_eps)\n\n  return x / x_norm"}
{"namespace": "ref_utils.l2_normalize", "completion": "  x_norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  x_norm = jnp.maximum(x_norm, grad_eps)\n  return x / x_norm"}
{"namespace": "ref_utils.l2_normalize", "completion": "  norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  return x / jnp.maximum(norm, grad_eps)"}
{"namespace": "ref_utils.l2_normalize", "completion": "  norm_x = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  norm_x = jnp.maximum(norm_x, grad_eps)\n  return x / norm_x"}
{"namespace": "ref_utils.l2_normalize", "completion": "  x_norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  x_norm = jnp.maximum(x_norm, grad_eps)\n  return x / x_norm"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Compute the squared L2 norm along the last axis of the input array\n  norm_sq = jnp.sum(x**2, axis=-1, keepdims=True)\n\n  # Clamp the squared norm to a minimum value to prevent exploding gradients during the backward pass\n  norm_sq_clamped = jnp.maximum(norm_sq, grad_eps)\n\n  # Compute the L2 norm by taking the square root of the clamped squared norm\n  norm = jnp.sqrt(norm_sq_clamped)\n\n  # Normalize the input array by dividing it by the computed L2 norm\n  return x / norm"}
{"namespace": "ref_utils.l2_normalize", "completion": "  x = jnp.asarray(x)\n  x = x / (jnp.linalg.norm(x, axis=-1, keepdims=True) + grad_eps)\n  return x"}
{"namespace": "ref_utils.l2_normalize", "completion": "  norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  norm = jnp.maximum(norm, grad_eps)\n  return x / norm"}
{"namespace": "ref_utils.l2_normalize", "completion": "  norm_x = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  norm_x = jnp.maximum(norm_x, grad_eps)\n  return x / norm_x"}
{"namespace": "ref_utils.l2_normalize", "completion": "  norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  norm = jnp.maximum(norm, grad_eps)\n  return x / norm"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Compute the squared L2 norm along the last axis of the input array.\n  norm_sq = jnp.sum(x**2, axis=-1, keepdims=True)\n\n  # Compute the L2 norm by taking the square root of the squared norm.\n  norm = jnp.sqrt(jnp.maximum(norm_sq, grad_eps))\n\n  # Return the normalized array by dividing each element by its L2 norm.\n  return x / norm"}
{"namespace": "ref_utils.l2_normalize", "completion": "  x_norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  x_norm = jnp.maximum(x_norm, grad_eps)\n  return x / x_norm"}
{"namespace": "ref_utils.l2_normalize", "completion": "  norm_x = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  norm_x = jnp.maximum(norm_x, grad_eps)\n  return x / norm_x"}
{"namespace": "ref_utils.l2_normalize", "completion": "  norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  norm = jnp.maximum(norm, grad_eps)\n  return x / norm"}
{"namespace": "ref_utils.l2_normalize", "completion": "  return x / jnp.maximum(jnp.linalg.norm(x, axis=-1, keepdims=True), grad_eps)"}
{"namespace": "ref_utils.l2_normalize", "completion": "  norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  norm = jnp.maximum(norm, grad_eps)\n  return x / norm"}
{"namespace": "ref_utils.l2_normalize", "completion": "  norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  norm = jnp.maximum(norm, grad_eps)\n  return x / norm"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():  # if lower no uppers after\n        return word\n    elif word.isupper():  # if upper no lowers after\n        return word\n    elif word[0].isupper() and word[1].islower():  # if first letter is uppercase and second letter is lowercase\n        return word.capitalize()\n    else:  # if mixed case\n        return word.lower()  # convert to lowercase"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    elif word.isupper():\n        return word\n    elif word[0].isupper() and word[1:].islower():\n        return word\n    elif word[0].islower() and word[1:].isupper():\n        return word.capitalize()\n    else:\n        return word.lower()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    # if upper no lowers after\n    if word.isupper():\n        return word\n    # if mixed case\n    if word[0].isupper() and word[1].islower():\n        return word.capitalize()\n    else:\n        return word.lower()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    # if upper no lowers after\n    elif word.isupper():\n        return word\n    # if mixed case\n    else:\n        if word[0].isupper() and word[1].islower():\n            return word.capitalize()\n        else:\n            return word.lower()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    elif word.isupper():\n        return word\n    else:\n        if word[0].isupper() and word[1].islower():\n            return word.capitalize()\n        else:\n            return word.lower()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    elif word.isupper():\n        return word\n    elif word[0].isupper() and word[1:].islower():\n        return word\n    elif word[0].islower() and word[1:].isupper():\n        return word.upper()\n    else:\n        return word.capitalize()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    # if upper no lowers after\n    elif word.isupper():\n        return word\n    # if mixed case\n    else:\n        if word[0].isupper() and word[1].islower():\n            return word.capitalize()\n        else:\n            return word.lower()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    # if upper no lowers after\n    elif word.isupper():\n        return word\n    # if mixed case\n    else:\n        if word[0].isupper() and word[1].islower():\n            return word.capitalize()\n        else:\n            return word.lower()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():  # if lower no uppers after\n        return word\n    elif word.isupper():  # if upper no lowers after\n        return word\n    else:  # mixed case\n        if word[0].isupper() and word[1].islower():  # capitalize if first letter is uppercase and second is lowercase\n            return word.capitalize()\n        else:  # convert to lowercase if not already\n            return word.lower()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():  # if lower no uppers after\n        return word\n    elif word.isupper():  # if upper no lowers after\n        return word\n    elif word[0].isupper() and word[1].islower():  # if first letter is upper and second letter is lower\n        return word.capitalize()\n    else:  # if mixed case\n        return word.lower()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    elif word.isupper():\n        return word\n    elif word[0].isupper() and word[1:].islower():\n        return word.capitalize()\n    else:\n        return word.lower()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    elif word.isupper():\n        return word\n    elif word[0].isupper() and word[1:].islower():\n        return word\n    elif word[0].islower() and word[1:].isupper():\n        return word.upper()\n    else:\n        return word.capitalize()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():  # if lower no uppers after\n        return word\n    elif word.isupper():  # if upper no lowers after\n        return word\n    elif word[0].isupper() and word[1].islower():  # if first letter is upper and second letter is lower\n        return word.capitalize()\n    else:  # if mixed case\n        return word.lower()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    elif word.isupper():\n        return word\n    elif word[0].isupper() and word[1:].islower():\n        return word\n    elif word[0].islower() and word[1:].isupper():\n        return word.upper()\n    else:\n        return word.capitalize()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    elif word.isupper():\n        return word\n    else:\n        if word[0].isupper() and word[1].islower():\n            return word.capitalize()\n        else:\n            return word.lower()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    elif word.isupper():\n        return word\n    else:\n        if word[0].isupper() and word[1].islower():\n            return word.capitalize()\n        else:\n            return word.lower()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    # if upper no lowers after\n    if word.isupper():\n        return word\n    # if mixed case\n    if word[0].isupper() and word[1].islower():\n        return word.capitalize()\n    else:\n        return word.lower()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    # if upper no lowers after\n    if word.isupper():\n        return word\n    # if mixed case\n    return word.capitalize()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    elif word.isupper():\n        return word\n    elif word[0].isupper() and word[1:].islower():\n        return word\n    elif word[0].islower() and word[1:].isupper():\n        return word.upper()\n    else:\n        return word.capitalize()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    elif word.isupper():\n        return word\n    elif word[0].isupper() and word[1:].islower():\n        return word\n    elif word[0].islower() and word[1:].isupper():\n        return word.capitalize()\n    else:\n        return word.lower()"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = re.sub(r\"\\s+\", \"\", line_text)  # Remove all whitespace characters\n    tokens = [char for char in line_text]  # Segment the modified text into individual characters\n    return tokens"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = re.sub(r\"\\s+\", \"\", line_text)  # Remove all whitespace characters\n    tokens = [char for char in line_text]  # Segment the modified text into smaller parts or tokens\n    return tokens"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = re.sub(r\"\\s\", \"\", line_text)  # Remove all whitespace characters\n    tokens = re.findall(r\".{1,2}\", line_text)  # Segment the modified text into smaller parts or tokens\n    return tokens"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = re.sub(r'\\s+', '', line_text)  # Remove all whitespace characters\n    tokens = [char for char in line_text]  # Segment the modified text into smaller parts or tokens\n    return tokens"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = re.sub(r\"\\s+\", \"\", line_text)  # Remove all whitespace characters\n    tokens = re.findall(r\".{1,3}\", line_text)  # Segment the modified text into smaller parts or tokens\n    return tokens  # Return the segmented parts of the modified input text"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = re.sub(r\"\\s+\", \"\", line_text)  # Remove all whitespace characters\n    tokens = su.segment(line_text)  # Segment the modified text into smaller parts or tokens\n    return tokens  # Return the segmented parts of the modified input text"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = re.sub(r\"\\s\", \"\", line_text)  # Remove all whitespace characters\n    tokens = []\n    start = 0\n    for end, char in enumerate(line_text):\n        if char.isupper() and end > start + 1:  # Segment at uppercase letters\n            tokens.append(line_text[start:end])\n            start = end\n        elif char.isdigit() and end > start + 1:  # Segment at digits\n            tokens.append(line_text[start:end])\n            start = end\n    tokens.append(line_text[start:])  # Add the remaining part of the text as a token\n    return tokens"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = re.sub(r'\\s+', '', line_text)  # Remove all whitespace characters\n    tokens = [char for char in line_text]  # Segment the modified input text into smaller parts or tokens\n    return tokens"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = re.sub(r\"\\s\", \"\", line_text)  # Remove all whitespace characters\n    tokens = su.segment(line_text)  # Segment the modified text into smaller parts or tokens\n    return tokens  # Return the segmented parts of the modified input text"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = re.sub(r\"\\s+\", \"\", line_text)  # Remove all whitespace characters\n    tokens = [char for char in line_text]  # Segment the modified text into smaller parts or tokens\n    return tokens"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = re.sub(r\"\\s\", \"\", line_text)  # remove all whitespace characters\n    tokens = nlm_tokenize(line_text)  # segment the modified text into smaller parts or tokens\n    return tokens  # return the segmented parts of the modified input text"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = re.sub(r\"\\s+\", \"\", line_text)  # Remove all whitespace characters\n    tokens = su.segment(line_text)  # Segment the modified text into smaller parts or tokens\n    return tokens  # Return the segmented parts of the modified input text"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = re.sub(r\"\\s+\", \"\", line_text)  # Remove all whitespace characters\n    tokens = [line_text[i : i + 2] for i in range(0, len(line_text), 2)]  # Segment the text into smaller parts or tokens\n    return tokens"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = re.sub(r\"\\s\", \"\", line_text)  # remove all whitespace characters\n    tokens = nlm_tokenize(line_text)  # segment the modified text into smaller parts or tokens\n    return tokens"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\" \", \"\")  # Remove all whitespace characters\n    tokens = line_text.split()  # Segment the modified text into smaller parts or tokens\n    return tokens"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = re.sub(r\"\\s+\", \"\", line_text)  # Remove all whitespace characters\n    tokens = [char for char in line_text]  # Segment the modified text into individual characters\n    return tokens"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\" \", \"\")  # Remove all whitespace characters\n    tokens = [char for char in line_text]  # Segment the modified text into smaller parts or tokens\n    return tokens"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = re.sub(r\"\\s+\", \"\", line_text)  # Remove all whitespace characters\n    tokens = su.segment(line_text)  # Segment the modified text into smaller parts or tokens\n    return tokens  # Return the segmented parts of the modified input text"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\" \", \"\")  # remove all whitespace characters\n    tokens = line_text.split()  # segment the modified text into smaller parts or tokens\n    return tokens  # return the segmented parts of the modified input text"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "\n    line_text = re.sub(r\"\\s+\", \"\", line_text)  # Remove all whitespace characters\n    tokens = [char for char in line_text]  # Segment the modified text into smaller parts or tokens\n    return tokens"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  integrated_dir_enc_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Function for evaluating the directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    return integrated_dir_enc_fn(xyz, kappa_inv)\n\n  return dir_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  ml_array = get_ml_array(deg_view)\n  ide_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    return l2_normalize(ide_fn(xyz, kappa_inv))\n\n  return dir_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  ml_array = get_ml_array(deg_view)\n  ide_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    return ide_fn(xyz, kappa_inv)\n\n  return dir_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "\n  integrated_dir_enc_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Function for evaluating the directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    return integrated_dir_enc_fn(xyz, kappa_inv)\n\n  return dir_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  ml_array = get_ml_array(deg_view)\n  ide_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    return l2_normalize(ide_fn(xyz, kappa_inv))\n\n  return dir_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  ml_array = get_ml_array(deg_view)\n  ide_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    return l2_normalize(ide_fn(xyz, kappa_inv))\n\n  return dir_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  ide_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    return l2_normalize(ide_fn(xyz, kappa_inv))\n\n  return dir_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "\n  integrated_dir_enc_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Function for evaluating the directional encoding for given inputs.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    return integrated_dir_enc_fn(xyz, kappa_inv)\n\n  return dir_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  ide_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Evaluates the directional encoding for given inputs.\n\n    Input-Output Arguments\n    :param xyz: Array. An array of Cartesian coordinates of directions to evaluate at.\n    :param kappa_inv: Array. The reciprocal of the concentration parameter of the von Mises-Fisher distribution.\n    :return: Array. The resulting directional encoding.\n    \"\"\"\n    return l2_normalize(ide_fn(xyz, kappa_inv))\n\n  return dir_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "\n  # Create the integrated directional encoding function\n  integrated_dir_enc_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Function for evaluating the directional encoding for given inputs.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    return integrated_dir_enc_fn(xyz, kappa_inv)\n\n  return dir_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  ml_array = get_ml_array(deg_view)\n  ide_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    return l2_normalize(ide_fn(xyz, kappa_inv))\n\n  return dir_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  integrated_dir_enc_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Function for evaluating the directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    return integrated_dir_enc_fn(xyz, kappa_inv)\n\n  return dir_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  integrated_dir_enc_fn = generate_ide_fn(deg_view)\n\n  def directional_encoding_fn(xyz, kappa_inv):\n    \"\"\"\n    Function for evaluating the directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    return l2_normalize(integrated_dir_enc_fn(xyz, kappa_inv))\n\n  return directional_encoding_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  ml_array = get_ml_array(deg_view)\n  ide_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"Function for evaluating directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    return l2_normalize(ide_fn(xyz, kappa_inv))\n\n  return dir_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "\n  integrated_dir_enc_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Function for evaluating the directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    return integrated_dir_enc_fn(xyz, kappa_inv)\n\n  return dir_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "\n  integrated_dir_enc_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Function for evaluating the directional encoding of a 3D point.\n\n    Args:\n    :param xyz: Array. [..., 3] array of Cartesian coordinates of directions to evaluate at.\n    :param kappa_inv: Array. [..., 1] reciprocal of the concentration parameter of the von Mises-Fisher distribution.\n\n    Returns:\n    :return: Array. An array with the resulting directional encoding.\n    \"\"\"\n    return l2_normalize(integrated_dir_enc_fn(xyz, kappa_inv))\n\n  return dir_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  ml_array = get_ml_array(deg_view)\n  ide_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    return l2_normalize(ide_fn(xyz, kappa_inv))\n\n  return dir_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  ml_array = get_ml_array(deg_view)\n  ide_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Function for evaluating directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    return ide_fn(xyz, kappa_inv)\n\n  return dir_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  integrated_dir_enc_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Function for evaluating the directional encoding of a 3D point (or points).\n\n    Args:\n    :param xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n    :param kappa_inv: [..., 1] reciprocal of the concentration parameter of the von Mises-Fisher distribution.\n\n    Returns:\n    :return: An array with the resulting directional encoding.\n    \"\"\"\n    return l2_normalize(integrated_dir_enc_fn(xyz, kappa_inv))\n\n  return dir_enc_fn"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  integrated_dir_enc_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning directional encoding.\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting directional encoding.\n    \"\"\"\n    return l2_normalize(integrated_dir_enc_fn(xyz, kappa_inv))\n\n  return dir_enc_fn"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    clean_lines = []\n    line_blocks = []\n    line = \"\"\n    index = 0\n    for i, l in enumerate(lines):\n        if should_skip(l, xml):\n            continue\n        if not l.strip():\n            if line:\n                line_blocks.append((line, index))\n                line = \"\"\n                index = i\n            continue\n        line += \" \" + l.strip()\n    if line:\n        line_blocks.append((line, index))\n\n    for i, (l, start) in enumerate(line_blocks):\n        block = {\"index\": i, \"text\": l, \"type\": \"paragraph\", \"start\": start, \"blocks\": []}\n        if is_table_row(l):\n            block[\"type\"] = \"table-row\"\n        elif re.match(r\"^[A-Z\\s\\W]+\\.$\", l):\n            block[\"type\"] = \"header\"\n        elif re.match(r\"^\\d+[\\.\\)]\\s\", l):\n            block[\"type\"] = \"list-item\"\n        clean_lines.append(block)\n\n    return clean_lines"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    cleaned_lines = []\n    cleaned_line_index = 0\n    current_block = defaultdict(list)\n    current_block_type = None\n    current_block_start_index = 0\n    current_header_index = None\n    current_indentation_level = 0\n\n    for index, line in enumerate(lines):\n        line = line.strip()\n\n        if should_skip(line, xml):\n            continue\n\n        if is_table_row(line):\n            continue\n\n        if not check_parentheses(line):\n            continue\n\n        if find_floating_chars(line):\n            continue\n\n        tokens = nlm_tokenize(line)\n        cleaned_line = \" \".join(tokens)\n\n        if cleaned_line not in current_block.values():\n            if current_block:\n                current_block[\"text\"] = \"\\n\".join(current_block[\"text\"])\n                current_block[\"index\"] = cleaned_line_index\n                current_block[\"type\"] = current_block_type\n                current_block[\"start_index\"] = current_block_start_index\n                current_block[\"header_index\"] = current_header_index\n                current_block[\"indentation_level\"] = current_indentation_level\n                cleaned_lines.append(dict(current_block))\n\n            current_block = defaultdict(list)\n            current_block_type = None\n            current_header_index = None\n            current_indentation_level = 0\n            current_block_start_index = index\n            cleaned_line_index += 1\n\n        current_block[\"text\"].append(cleaned_line)\n\n        if line_parser.Line(line).is_header:\n            current_block_type = \"header\"\n            current_header_index = cleaned_line_index\n            current_indentation_level = 0\n        elif line_parser.Line(line).is_list_item:\n            current_block_type = \"list_item\"\n            current_indentation_level = line_parser.Line(line).indentation_level\n\n    if current_block:\n        current_block[\"text\"] = \"\\n\".join(current_block[\"text\"])\n        current_block[\"index\"] = cleaned_line_index\n        current_block[\"type\"] = current_block_type\n        current_block[\"start_index\"] = current_block_start_index\n        current_block[\"header_index\"] = current_header_index\n        current_block[\"indentation_level\"] = current_indentation_level\n        cleaned_lines.append(dict(current_block))\n\n    return cleaned_lines"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    cleaned_lines = []\n    line_blocks = []\n    current_block = defaultdict(list)\n    current_header = None\n    current_indent = 0\n\n    for i, line in enumerate(lines):\n        if should_skip(line, xml):\n            continue\n\n        line = line.strip()\n        if not line:\n            continue\n\n        if not check_parentheses(line):\n            continue\n\n        if is_table_row(line):\n            continue\n\n        if find_floating_chars(line):\n            continue\n\n        tokens = nlm_tokenize(line)\n        if not tokens:\n            continue\n\n        if current_block:\n            if tokens[0].isupper() and len(tokens) > 1 and tokens[1][0].islower():\n                if current_block['type'] == 'paragraph':\n                    cleaned_lines.append(current_block)\n                    current_block = defaultdict(list)\n\n        if tokens[0].isupper() and len(tokens) > 1 and tokens[1][0].islower():\n            if current_block:\n                cleaned_lines.append(current_block)\n                current_block = defaultdict(list)\n            current_block['type'] = 'header'\n            current_block['index'] = len(cleaned_lines)\n            current_block['text'] = line\n            current_header = current_block['index']\n            current_indent = 0\n            cleaned_lines.append(current_block)\n            current_block = defaultdict(list)\n        else:\n            if current_block and current_block['type'] == 'header':\n                current_block['blocks'].append(len(cleaned_lines))\n            current_block['type'] = 'paragraph'\n            current_block['index'] = len(cleaned_lines)\n            current_block['text'].append(line)\n            current_block['header'] = current_header\n            current_block['indent'] = current_indent\n            cleaned_lines.append(current_block)\n            current_block = defaultdict(list)\n\n    if current_block:\n        cleaned_lines.append(current_block)\n\n    return cleaned_lines"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    cleaned_lines = []\n    cleaned_line_index = 0\n    header_index = None\n    list_blocks = []\n    list_level = 0\n    current_block = defaultdict(str)\n\n    for index, line in enumerate(lines):\n        if should_skip(line, xml):\n            continue\n\n        line = line.strip()\n\n        if header_index is not None and not line:\n            header_index = None\n\n        if not line:\n            continue\n\n        if is_table_row(line):\n            current_block[\"type\"] = \"table\"\n            current_block[\"text\"] += line + \" \"\n            continue\n\n        if find_floating_chars(line):\n            continue\n\n        if check_parentheses(line):\n            line = re.sub(r\"\\s+\", \" \", line)\n\n        tokens = nlm_tokenize(line)\n        token_counter = Counter(tokens)\n\n        if token_counter.most_common(1)[0][1] > 1:\n            continue\n\n        if current_block[\"type\"] == \"list\" and line.startswith(\" \" * list_level):\n            current_block[\"text\"] += line + \" \"\n            continue\n\n        if current_block:\n            current_block[\"end_index\"] = index - 1\n            cleaned_lines.append(dict(current_block))\n            cleaned_line_index += 1\n            current_block.clear()\n\n        if line_parser.is_header(line):\n            header_index = cleaned_line_index\n            current_block[\"type\"] = \"header\"\n            current_block[\"text\"] = line\n            current_block[\"start_index\"] = index\n            current_block[\"header_index\"] = None\n            continue\n\n        if line_parser.is_list_item(line):\n            list_level = len(re.search(r\"^\\s*\", line).group(0))\n            current_block[\"type\"] = \"list\"\n            current_block[\"text\"] = line + \" \"\n            current_block[\"start_index\"] = index\n            continue\n\n        current_block[\"type\"] = \"paragraph\"\n        current_block[\"text\"] = line\n        current_block[\"start_index\"] = index\n\n    if current_block:\n        current_block[\"end_index\"] = len(lines) - 1\n        cleaned_lines.append(dict(current_block))\n\n    for block in cleaned_lines:\n        if block[\"type\"] == \"list\":\n            block[\"header_index\"] = header_index\n            list_blocks.append(block)\n\n    for block in list_blocks:\n        for sub_block in cleaned_lines[block[\"start_index\"] : block[\"end_index\"] + 1]:\n            if sub_block[\"type\"] != \"list\":\n                block[\"list\"].append(sub_block)\n\n    return cleaned_lines"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    cleaned_lines = []\n    cleaned_line_index = 0\n    header_stack = []\n    list_stack = []\n    list_level = 0\n\n    for i, line in enumerate(lines):\n        if should_skip(line, xml):\n            continue\n\n        line = line.strip()\n        if not check_parentheses(line):\n            continue\n\n        if is_table_row(line):\n            continue\n\n        if not find_floating_chars(line):\n            tokens = nlm_tokenize(line)\n            if len(tokens) == 1:\n                if tokens[0] in patterns.headers:\n                    header_stack.append(cleaned_line_index)\n                    cleaned_lines.append(\n                        {\n                            \"index\": cleaned_line_index,\n                            \"text\": line,\n                            \"type\": \"header\",\n                            \"start_index\": i,\n                            \"blocks\": [],\n                            \"header_index\": None,\n                            \"indentation\": 0,\n                        }\n                    )\n                    cleaned_line_index += 1\n                elif tokens[0] in patterns.lists:\n                    list_stack.append(cleaned_line_index)\n                    list_level += 1\n                    cleaned_lines.append(\n                        {\n                            \"index\": cleaned_line_index,\n                            \"text\": line,\n                            \"type\": \"list\",\n                            \"start_index\": i,\n                            \"blocks\": [],\n                            \"header_index\": None,\n                            \"indentation\": list_level,\n                        }\n                    )\n                    cleaned_line_index += 1\n                else:\n                    cleaned_lines.append(\n                        {\n                            \"index\": cleaned_line_index,\n                            \"text\": line,\n                            \"type\": \"paragraph\",\n                            \"start_index\": i,\n                            \"blocks\": [],\n                            \"header_index\": None,\n                            \"indentation\": 0,\n                        }\n                    )\n                    cleaned_line_index += 1\n            else:\n                cleaned_lines.append(\n                    {\n                        \"index\": cleaned_line_index,\n                        \"text\": line,\n                        \"type\": \"paragraph\",\n                        \"start_index\": i,\n                        \"blocks\": [],\n                        \"header_index\": None,\n                        \"indentation\": 0,\n                    }\n                )\n                cleaned_line_index += 1\n\n    return cleaned_lines"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    clean_lines = []\n    block = defaultdict(list)\n    block_index = 0\n    header_index = None\n    list_blocks = []\n    prev_line = \"\"\n    prev_indent = 0\n\n    for i, line in enumerate(lines):\n        if should_skip(line, xml):\n            continue\n\n        line = line.strip()\n        indent = len(line) - len(line.lstrip())\n\n        if indent > prev_indent:\n            if not block:\n                block[block_index].append(prev_line)\n            else:\n                block[block_index].append(line)\n        elif indent == prev_indent:\n            if block:\n                clean_line = \" \".join(block[block_index])\n                block_type = \"paragraph\" if len(clean_line) > 0 else \"header\"\n                clean_lines.append({\n                    \"index\": block_index,\n                    \"text\": clean_line,\n                    \"type\": block_type,\n                    \"start_index\": i - len(block[block_index]),\n                    \"blocks\": list_blocks,\n                    \"header_index\": header_index,\n                    \"indentation\": prev_indent\n                })\n                block_index += 1\n                list_blocks = []\n                block = defaultdict(list)\n            block[block_index].append(line)\n        else:\n            if block:\n                clean_line = \" \".join(block[block_index])\n                block_type = \"paragraph\" if len(clean_line) > 0 else \"header\"\n                clean_lines.append({\n                    \"index\": block_index,\n                    \"text\": clean_line,\n                    \"type\": block_type,\n                    \"start_index\": i - len(block[block_index]),\n                    \"blocks\": list_blocks,\n                    \"header_index\": header_index,\n                    \"indentation\": prev_indent\n                })\n                block_index += 1\n                list_blocks = []\n                block = defaultdict(list)\n            block[block_index].append(line)\n\n        prev_line = line\n        prev_indent = indent\n\n    if block:\n        clean_line = \" \".join(block[block_index])\n        block_type = \"paragraph\" if len(clean_line) > 0 else \"header\"\n        clean_lines.append({\n            \"index\": block_index,\n            \"text\": clean_line,\n            \"type\": block_type,\n            \"start_index\": len(lines) - len(block[block_index]),\n            \"blocks\": list_blocks,\n            \"header_index\": header_index,\n            \"indentation\": prev_indent\n        })\n\n    return clean_lines"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    clean_lines = []\n    block = defaultdict(list)\n    headers = []\n    header_index = -1\n    list_items = []\n    list_index = -1\n    prev_line = \"\"\n    prev_block = None\n    prev_indent = 0\n\n    for i, line in enumerate(lines):\n        line = line.strip()\n        if should_skip(line, xml):\n            continue\n\n        # Check if the line is a table row\n        if is_table_row(line):\n            continue\n\n        # Tokenize the line\n        tokens = nlm_tokenize(line)\n\n        # Check for floating characters\n        if find_floating_chars(line):\n            continue\n\n        # Check for parentheses balance\n        if not check_parentheses(line):\n            continue\n\n        # Check for indentation or list\n        indent = line_parser.get_indent_level(line)\n        list_level = line_parser.get_list_level(line)\n\n        if indent > prev_indent:\n            if prev_block:\n                block[i-1][\"blocks\"] = clean_lines(lines[i-1:list_index], xml)\n            prev_block = block\n            block = defaultdict(list)\n            prev_indent = indent\n            headers.append(prev_line)\n            header_index = i-1\n            list_items = []\n            list_index = -1\n        elif list_level > 0:\n            if list_level == 1:\n                list_items.append(line)\n                list_index = i\n            else:\n                block[i-1][\"blocks\"] = clean_lines(lines[i-1:list_index], xml)\n                prev_block = block\n                block = defaultdict(list)\n                prev_indent = indent\n                headers.append(prev_line)\n                header_index = i-1\n                list_items = []\n                list_index = -1\n        else:\n            if prev_block:\n                block[i-1][\"blocks\"] = clean_lines(lines[i-1:list_index], xml)\n            prev_block = block\n            block = defaultdict(list)\n            prev_indent = indent\n            headers.append(prev_line)\n            header_index = i-1\n            list_items = []\n            list_index = -1\n\n        block[i] = {\n            \"index\": i,\n            \"text\": line,\n            \"type\": \"paragraph\",\n            \"start_index\": i,\n            \"blocks\": [],\n            \"header_index\": header_index,\n            \"indentation\": indent,\n            \"list_level\": list_level\n        }\n\n    if block:\n        block[i] = {\n            \"index\": i,\n            \"text\": line,\n            \"type\": \"paragraph\",\n            \"start_index\": i,\n            \"blocks\": [],\n            \"header_index\": header_index,\n            \"indentation\": indent,\n            \"list_level\": list_level\n        }\n\n    clean_lines.append(block)\n\n    return clean_lines"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    cleaned_lines = []\n    cleaned_line_index = 0\n    block_index = 0\n    current_block = defaultdict(list)\n    previous_line = \"\"\n    previous_block_type = \"\"\n    previous_indentation = 0\n\n    for index, line in enumerate(lines):\n        line = line.strip()\n\n        # Skip empty lines\n        if should_skip(line, xml):\n            continue\n\n        # Clean and tokenize the line\n        tokens = nlm_tokenize(line)\n\n        # Check for floating characters\n        if find_floating_chars(line):\n            continue\n\n        # Check for parentheses balance\n        if not check_parentheses(line):\n            continue\n\n        # Check for table rows\n        if is_table_row(line):\n            continue\n\n        # Check for duplicate lines\n        if tokens == nlm_tokenize(previous_line):\n            continue\n\n        # Connect incomplete lines\n        if previous_line and not line[0].isupper():\n            current_block[cleaned_line_index - 1] += \" \" + line\n            previous_line = line\n            continue\n\n        # Determine block type\n        block_type = \"paragraph\"\n        if line.isupper() and not any(char.isdigit() for char in line):\n            block_type = \"header\"\n        elif re.match(r\"^[0-9]+\\.\", line):\n            block_type = \"list_item\"\n\n        # Determine indentation level\n        indentation = len(line) - len(line.lstrip())\n\n        # Append the current block to the result list\n        if previous_block_type and (block_type != previous_block_type or indentation > previous_indentation):\n            current_block[\"block_index\"] = block_index\n            cleaned_lines.append(dict(current_block))\n            block_index += 1\n            current_block = defaultdict(list)\n            cleaned_line_index = 0\n\n        # Update the current block with the new line\n        current_block[cleaned_line_index] = line\n        current_block[\"block_type\"] = block_type\n        current_block[\"block_start_index\"] = index\n        current_block[\"associated_header_index\"] = None\n        current_block[\"indentation_level\"] = indentation\n\n        # Update previous line and block type\n        previous_line = line\n        previous_block_type = block_type\n        previous_indentation = indentation\n        cleaned_line_index += 1\n\n    # Append the last block to the result list\n    if current_block:\n        current_block[\"block_index\"] = block_index\n        cleaned_lines.append(dict(current_block))\n\n    return cleaned_lines"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    cleaned_lines = []\n    cleaned_line_index = 0\n    current_block = {\"text\": \"\", \"type\": \"paragraph\", \"start_index\": 0, \"blocks\": []}\n    header_stack = []\n    list_stack = []\n    for i, line in enumerate(lines):\n        if should_skip(line, xml):\n            continue\n        if is_table_row(line):\n            continue\n        if check_parentheses(line):\n            continue\n        line = line.strip()\n        if not line:\n            continue\n        if find_floating_chars(line):\n            continue\n        tokens = nlm_tokenize(line)\n        cleaned_line = \" \".join(tokens)\n        if cleaned_line in current_block[\"text\"]:\n            continue\n        if len(cleaned_line) < 3:\n            continue\n        if cleaned_line in [x[\"text\"] for x in cleaned_lines]:\n            continue\n        if cleaned_line in [x[\"text\"] for x in current_block[\"blocks\"]]:\n            continue\n        if len(cleaned_line) > 3 and cleaned_line[-1] in [\":\", \".\"] and not cleaned_line[0].isupper():\n            continue\n        if len(cleaned_line) > 3 and cleaned_line[-1] == \":\" and not any(x.isalpha() for x in cleaned_line[:-1]):\n            continue\n        if len(cleaned_line) > 3 and not any(x.isalpha() for x in cleaned_line):\n            continue\n        if len(cleaned_line) > 3 and not any(x.isalpha() for x in cleaned_line[:-1]) and not cleaned_line[-1].isdigit():\n            continue\n        if len(cleaned_line) > 3 and cleaned_line[-1] in [\")\", \"]\"]:\n            if not any(x in cleaned_line for x in [\"(\", \"[\"]):\n                continue\n        if len(cleaned_line) > 3 and cleaned_line[-1] in [\")\", \"]\", \"}\"]:\n            if not any(x in cleaned_line for x in [\"(\", \"[\", \"{\"]):\n                continue\n        if len(cleaned_line) > 3 and cleaned_line[0] in [\")\", \"]\", \"}\"]:\n            if not any(x in cleaned_line for x in [\"(\", \"[\", \"{\"]):\n                continue\n        if len(cleaned_line) > 3 and cleaned_line[0] in [\"(\", \"[\", \"{\"]:\n            if not any(x in cleaned_line for x in [\")\", \"]\", \"}\"]):\n                continue\n        if len(cleaned_line) > 3 and cleaned_line[-1] in [\")\", \"]\", \"}\"]:\n            if not any(x in cleaned_line for x in [\"(\", \"[\", \"{\"]):\n                continue\n        if len(cleaned_line) > 3 and cleaned_line[0] in [\"(\", \"[\", \"{\"]:\n            if not any(x in cleaned_line for x in [\")\", \"]\", \"}\"]):\n                continue\n        if len(cleaned_line) > 3 and any(x.isalpha() for x in cleaned_line[:-1]) and cleaned_line[-1].isdigit():\n            continue\n        if len(cleaned_line) > 3 and any(x.isalpha() for x in cleaned_line[:-1]) and cleaned_line[-1] in [\")\", \"]\", \"}\"]:\n            continue\n        if len(cleaned_line) > 3 and any(x.isalpha() for x in cleaned_line[:-1]) and not any(x.isalpha() for x in cleaned_line[-1]):\n            continue\n        if len(cleaned_line) > 3 and any(x.isalpha() for x in cleaned_line[:-1]) and not any(x.isalpha() for x in cleaned_line[-1]) and cleaned_line[-1] in [\")\", \"]\", \"}\"]:\n            continue\n        if len(cleaned_line) > 3 and any(x.isalpha() for x in cleaned_line[:-1]) and not any(x.isalpha() for x in cleaned_line[-1]) and cleaned_line[-1] in [\")\", \"]\", \"}\"]:\n            continue\n        if len(cleaned_line) > 3 and any(x.isalpha() for x in cleaned_line[:-1]) and not any(x.isalpha() for x in cleaned_line[-1]) and cleaned_line[-1] in [\")\", \"]\", \"}\"]:\n            continue\n        if len(cleaned_line) > 3 and any(x.isalpha() for x in cleaned_line[:-1]) and not any(x.isalpha() for x in cleaned_line[-1]) and cleaned_line[-1] in [\")\", \"]\", \"}\"]:\n            continue\n        current_block[\"text\"] += cleaned_line + \" \"\n        if i == len(lines) - 1:\n            current_block[\"text\"] = current_block[\"text\"].strip()\n            cleaned_lines.append(\n                {\n                    \"text\": current_block[\"text\"],\n                    \"type\": current_block[\"type\"],\n                    \"start_index\": current_block[\"start_index\"],\n                    \"blocks\": current_block[\"blocks\"],\n                    \"header_index\": current_block.get(\"header_index\"),\n                    \"indentation\": current_block.get(\"indentation\"),\n                }\n            )\n        if current_block[\"type\"] == \"paragraph\":\n            current_block[\"type\"] = \"list\" if cleaned_line[-1] == \".\" else \"header\"\n        if current_block[\"type\"] == \"header\" and cleaned_line[-1] == \".\":\n            current_block[\"type\"] = \"list\"\n        if current_block[\"type\"] == \"list\" and cleaned_line[-1] != \".\":\n            current_block[\"type\"] = \"header\"\n        if current_block[\"type\"] == \"header\":\n            header_stack.append(cleaned_line)\n        if current_block[\"type\"] == \"list\":\n            list_stack.append(cleaned_line)\n        if cleaned_line[-1] == \".\":\n            if header_stack:\n                current_block[\"header_index\"] = cleaned_lines.index(\n                    next(\n                        (\n                            x\n                            for x in cleaned_lines\n                            if x[\"text\"] == header_stack[-1]\n                        ),\n                        None,\n                    )\n                )\n                header_stack.pop()\n            if list_stack:\n                current_block[\"indentation\"] = list_stack[-1].count(\".\") + 1\n                list_stack.pop()\n            current_block[\"text\"] = current_block[\"text\"].strip()\n            cleaned_lines.append(\n                {\n                    \"text\": current_block[\"text\"],\n                    \"type\": current_block[\"type\"],\n                    \"start_index\": current_block[\"start_index\"],\n                    \"blocks\": current_block[\"blocks\"],\n                    \"header_index\": current_block.get(\"header_index\"),\n                    \"indentation\": current_block.get(\"indentation\"),\n                }\n            )\n            current_block = {\"text\": \"\", \"type\": \"paragraph\", \"start_index\": i + 1, \"blocks\": []}\n    return cleaned_lines"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    cleaned_lines = []\n    cleaned_line_index = 0\n    header_index = -1\n    list_items = []\n    list_level = 0\n    in_table = False\n    table_rows = []\n    for i, line in enumerate(lines):\n        if should_skip(line, xml):\n            continue\n        line = line.strip()\n        if is_table_row(line):\n            table_rows.append(line)\n            in_table = True\n            continue\n        if in_table:\n            if line.strip() == \"\" or not is_table_row(line):\n                in_table = False\n                if table_rows:\n                    cleaned_lines.append({\n                        \"index\": cleaned_line_index,\n                        \"text\": table_rows,\n                        \"type\": \"table\",\n                        \"start_index\": i - len(table_rows),\n                    })\n                    cleaned_line_index += 1\n                    table_rows = []\n            else:\n                table_rows.append(line)\n                continue\n        if not check_parentheses(line):\n            continue\n        if find_floating_chars(line):\n            continue\n        tokens = nlm_tokenize(line)\n        if not tokens:\n            continue\n        if line_parser.Line(line).is_header:\n            if cleaned_lines:\n                cleaned_lines[-1][\"blocks\"] = list_items\n                list_items = []\n            header_index = cleaned_line_index\n            cleaned_lines.append({\n                \"index\": cleaned_line_index,\n                \"text\": line,\n                \"type\": \"header\",\n                \"start_index\": i,\n            })\n            cleaned_line_index += 1\n        elif line_parser.Line(line).is_list_item:\n            list_items.append({\n                \"index\": cleaned_line_index,\n                \"text\": line,\n                \"type\": \"list_item\",\n                \"start_index\": i,\n                \"level\": line_parser.Line(line).list_level,\n            })\n            cleaned_line_index += 1\n        else:\n            cleaned_lines.append({\n                \"index\": cleaned_line_index,\n                \"text\": line,\n                \"type\": \"paragraph\",\n                \"start_index\": i,\n                \"header_index\": header_index,\n            })\n            cleaned_line_index += 1\n    if cleaned_lines:\n        cleaned_lines[-1][\"blocks\"] = list_items\n    return cleaned_lines"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    cleaned_lines = []\n    cleaned_line_index = 0\n    header_blocks = []\n    list_blocks = []\n    current_list_block = defaultdict(list)\n    current_indentation = 0\n    current_list_level = 0\n    prev_line = \"\"\n\n    for i, line in enumerate(lines):\n        if should_skip(line, xml):\n            continue\n\n        line = line.strip()\n\n        if is_table_row(line):\n            continue\n\n        if not check_parentheses(line):\n            continue\n\n        if find_floating_chars(line):\n            continue\n\n        tokens = nlm_tokenize(line)\n        if not tokens:\n            continue\n\n        if tokens not in cleaned_lines:\n            cleaned_lines.append(tokens)\n            line_metadata = {\n                \"index\": cleaned_line_index,\n                \"text\": line,\n                \"type\": \"paragraph\",\n                \"start_index\": i,\n                \"blocks\": [],\n                \"header_index\": None,\n                \"indentation_level\": 0,\n                \"list_level\": 0,\n            }\n            cleaned_lines.append(line_metadata)\n            cleaned_line_index += 1\n\n    return cleaned_lines"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    clean_lines = []\n    current_block = defaultdict(list)\n    header_stack = []\n    list_stack = []\n    current_list_level = 0\n    current_indent = 0\n    current_paragraph = []\n    current_block_index = 0\n\n    for i, line in enumerate(lines):\n        if should_skip(line, xml):\n            continue\n\n        line = line.strip()\n        if check_parentheses(line):\n            if not find_floating_chars(line):\n                tokens = nlm_tokenize(line)\n                if len(tokens) > 0:\n                    if is_table_row(line):\n                        if current_paragraph:\n                            current_block_index += 1\n                            current_block[current_block_index] = {\n                                \"type\": \"paragraph\",\n                                \"text\": \" \".join(current_paragraph),\n                                \"start\": i - len(current_paragraph),\n                            }\n                            current_paragraph = []\n                        current_block_index += 1\n                        current_block[current_block_index] = {\"type\": \"table_row\", \"text\": line, \"start\": i}\n                    else:\n                        current_paragraph.append(line)\n                else:\n                    if current_paragraph:\n                        current_block_index += 1\n                        current_block[current_block_index] = {\n                            \"type\": \"paragraph\",\n                            \"text\": \" \".join(current_paragraph),\n                            \"start\": i - len(current_paragraph),\n                        }\n                        current_paragraph = []\n                    current_block_index += 1\n                    current_block[current_block_index] = {\"type\": \"unknown\", \"text\": line, \"start\": i}\n            else:\n                if current_paragraph:\n                    current_block_index += 1\n                    current_block[current_block_index] = {\n                        \"type\": \"paragraph\",\n                        \"text\": \" \".join(current_paragraph),\n                        \"start\": i - len(current_paragraph),\n                    }\n                    current_paragraph = []\n                current_block_index += 1\n                current_block[current_block_index] = {\"type\": \"unknown\", \"text\": line, \"start\": i}\n        else:\n            if current_paragraph:\n                current_block_index += 1\n                current_block[current_block_index] = {\n                    \"type\": \"paragraph\",\n                    \"text\": \" \".join(current_paragraph),\n                    \"start\": i - len(current_paragraph),\n                }\n                current_paragraph = []\n            current_block_index += 1\n            current_block[current_block_index] = {\"type\": \"unknown\", \"text\": line, \"start\": i}\n\n    if current_paragraph:\n        current_block_index += 1\n        current_block[current_block_index] = {\n            \"type\": \"paragraph\",\n            \"text\": \" \".join(current_paragraph),\n            \"start\": len(lines) - len(current_paragraph),\n        }\n\n    for block_index, block in current_block.items():\n        clean_lines.append(\n            {\n                \"index\": block_index,\n                \"text\": block[\"text\"],\n                \"type\": block[\"type\"],\n                \"start\": block[\"start\"],\n            }\n        )\n\n    return clean_lines"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    cleaned_lines = []\n    cleaned_line_index = 0\n    header_stack = []\n    list_stack = []\n    current_list_level = 0\n    current_paragraph = []\n\n    for i, line in enumerate(lines):\n        if should_skip(line, xml):\n            continue\n\n        line = line.strip()\n        if not line:\n            continue\n\n        if is_table_row(line):\n            continue\n\n        if not check_parentheses(line):\n            continue\n\n        if find_floating_chars(line):\n            continue\n\n        tokens = nlm_tokenize(line)\n\n        if tokens not in current_paragraph:\n            current_paragraph.append(tokens)\n\n        if line_parser.Line(line).is_header:\n            header_stack.append(cleaned_line_index)\n            cleaned_lines.append(\n                {\n                    \"index\": cleaned_line_index,\n                    \"text\": line,\n                    \"type\": \"header\",\n                    \"start_index\": i,\n                    \"blocks\": [],\n                    \"header_index\": None,\n                    \"indentation\": None,\n                }\n            )\n            cleaned_line_index += 1\n            continue\n\n        if line_parser.Line(line).is_list_item:\n            if current_list_level == 0:\n                list_stack.append(cleaned_line_index)\n            cleaned_lines.append(\n                {\n                    \"index\": cleaned_line_index,\n                    \"text\": line,\n                    \"type\": \"list_item\",\n                    \"start_index\": i,\n                    \"blocks\": [],\n                    \"header_index\": None,\n                    \"indentation\": current_list_level,\n                }\n            )\n            cleaned_line_index += 1\n            current_list_level += 1\n            continue\n\n        if current_paragraph:\n            cleaned_lines.append(\n                {\n                    \"index\": cleaned_line_index,\n                    \"text\": current_paragraph,\n                    \"type\": \"paragraph\",\n                    \"start_index\": i,\n                    \"blocks\": [],\n                    \"header_index\": header_stack[-1] if header_stack else None,\n                    \"indentation\": None,\n                }\n            )\n            cleaned_line_index += 1\n            current_paragraph = []\n\n    return cleaned_lines"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    cleaned_lines = []\n    cleaned_line_index = 0\n    line_index = 0\n    while line_index < len(lines):\n        line = lines[line_index].strip()\n        if should_skip(line, xml):\n            line_index += 1\n            continue\n        if is_table_row(line):\n            cleaned_lines.append(\n                {\n                    \"index\": cleaned_line_index,\n                    \"text\": line,\n                    \"type\": \"table_row\",\n                    \"start_index\": line_index,\n                }\n            )\n            cleaned_line_index += 1\n            line_index += 1\n            continue\n        if line_index < len(lines) - 1:\n            next_line = lines[line_index + 1].strip()\n            if not should_skip(next_line, xml) and not is_table_row(next_line):\n                line += \" \" + next_line\n                line_index += 1\n        tokens = nlm_tokenize(line)\n        if len(tokens) == 1 and find_floating_chars(tokens[0]):\n            line_index += 1\n            continue\n        cleaned_lines.append(\n            {\"index\": cleaned_line_index, \"text\": line, \"type\": \"paragraph\", \"start_index\": line_index}\n        )\n        cleaned_line_index += 1\n        line_index += 1\n    return cleaned_lines"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    cleaned_lines = []\n    cleaned_line_index = 0\n    header_blocks = []\n    current_header_block = None\n    current_list_block = None\n\n    for i, line in enumerate(lines):\n        if should_skip(line, xml):\n            continue\n\n        line = line.strip()\n        if not line:\n            continue\n\n        if is_table_row(line):\n            continue\n\n        if not check_parentheses(line):\n            continue\n\n        if find_floating_chars(line):\n            continue\n\n        tokens = nlm_tokenize(line)\n        if not tokens:\n            continue\n\n        cleaned_line = \" \".join(tokens)\n        if cleaned_line in cleaned_lines:\n            continue\n\n        cleaned_lines.append(cleaned_line)\n\n        if line_parser.is_header(line):\n            header_block = {\n                \"index\": cleaned_line_index,\n                \"text\": cleaned_line,\n                \"type\": \"header\",\n                \"start_index\": i,\n                \"blocks\": [],\n                \"header_index\": None,\n                \"indentation_level\": 0\n            }\n            header_blocks.append(header_block)\n            current_header_block = header_block\n            current_list_block = None\n        else:\n            if current_header_block:\n                block = {\n                    \"index\": cleaned_line_index,\n                    \"text\": cleaned_line,\n                    \"type\": \"paragraph\",\n                    \"start_index\": i,\n                    \"blocks\": [],\n                    \"header_index\": current_header_block[\"index\"],\n                    \"indentation_level\": 0\n                }\n                current_header_block[\"blocks\"].append(block)\n            else:\n                block = {\n                    \"index\": cleaned_line_index,\n                    \"text\": cleaned_line,\n                    \"type\": \"paragraph\",\n                    \"start_index\": i,\n                    \"blocks\": [],\n                    \"header_index\": None,\n                    \"indentation_level\": 0\n                }\n                cleaned_lines.append(block)\n\n        cleaned_line_index += 1\n\n    return cleaned_lines"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    cleaned_lines = []\n    line_blocks = defaultdict(list)\n    line_counter = Counter()\n    header_stack = []\n    list_stack = []\n\n    # Process each line\n    for i, line in enumerate(lines):\n        line = line.strip()\n\n        # Skip empty lines\n        if should_skip(line, xml):\n            continue\n\n        # Tokenize the line\n        tokens = nlm_tokenize(line)\n\n        # Check for parentheses balance\n        if not check_parentheses(line):\n            logger.warning(f\"Unbalanced parentheses in line {i}: {line}\")\n\n        # Check for floating characters\n        if find_floating_chars(line):\n            logger.warning(f\"Floating characters in line {i}: {line}\")\n\n        # Check if it's a table row\n        if is_table_row(line):\n            logger.info(f\"Table row detected in line {i}: {line}\")\n\n        # Clean the line and remove duplicates\n        cleaned_line = formatter.clean_text(line)\n        line_counter[cleaned_line] += 1\n\n        # Add the line to the appropriate block\n        if cleaned_line not in line_blocks:\n            block_index = len(cleaned_lines)\n            line_blocks[cleaned_line].append(block_index)\n            line_type = line_parser.get_line_type(line, header_stack, list_stack)\n            block = {\n                \"index\": block_index,\n                \"text\": line,\n                \"type\": line_type,\n                \"start_index\": i,\n                \"blocks\": [],\n                \"header_index\": None,\n                \"indentation_level\": line_parser.get_indentation_level(line),\n            }\n            cleaned_lines.append(block)\n        else:\n            block_index = line_blocks[cleaned_line][0]\n\n        # Update the block metadata\n        block = cleaned_lines[block_index]\n        block[\"blocks\"].append(i)\n        if block[\"type\"] == \"header\":\n            header_stack.append(block_index)\n        elif block[\"type\"] == \"list_item\":\n            list_stack.append(block_index)\n\n    # Update the header associations\n    for block in cleaned_lines:\n        if block[\"type\"] in [\"paragraph\", \"list_item\"]:\n            if header_stack:\n                block[\"header_index\"] = header_stack[-1]\n\n    return cleaned_lines"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    cleaned_lines = []\n    current_block = defaultdict(list)\n    current_block_index = 0\n    header_block_index = -1\n    last_line = None\n\n    for i, line in enumerate(lines):\n        line = line.strip()\n        if should_skip(line, xml):\n            continue\n\n        if line == last_line:\n            continue\n\n        if is_table_row(line):\n            continue\n\n        if find_floating_chars(line):\n            continue\n\n        if not check_parentheses(line):\n            continue\n\n        tokens = nlm_tokenize(line)\n        if len(tokens) == 1 and len(tokens[0]) <= 2:\n            continue\n\n        if current_block and current_block[\"type\"] == \"list\" and line.startswith(\"\u2022\"):\n            current_block[\"list\"].append(line)\n            continue\n\n        if current_block and current_block[\"type\"] == \"list\" and not line.startswith(\"\u2022\"):\n            cleaned_lines.append(current_block)\n            current_block = defaultdict(list)\n            current_block_index += 1\n            header_block_index = -1\n\n        if current_block and current_block[\"type\"] == \"paragraph\" and line.startswith(\" \") and not line.startswith(\"  \"):\n            cleaned_lines.append(current_block)\n            current_block = defaultdict(list)\n            current_block_index += 1\n            header_block_index = -1\n\n        if line.startswith(\" \") and not line.startswith(\"  \"):\n            continue\n\n        if line_parser.is_header(line):\n            if current_block:\n                cleaned_lines.append(current_block)\n                current_block = defaultdict(list)\n                current_block_index += 1\n\n            current_block = {\n                \"index\": current_block_index,\n                \"text\": line,\n                \"type\": \"header\",\n                \"start_index\": i,\n                \"list\": [],\n                \"header_index\": None,\n                \"indentation\": 0,\n            }\n            header_block_index = current_block_index\n        else:\n            if not current_block:\n                current_block = {\n                    \"index\": current_block_index,\n                    \"text\": line,\n                    \"type\": \"paragraph\",\n                    \"start_index\": i,\n                    \"list\": [],\n                    \"header_index\": header_block_index,\n                    \"indentation\": 0,\n                }\n            else:\n                current_block[\"text\"] += \" \" + line\n\n        last_line = line\n\n    if current_block:\n        cleaned_lines.append(current_block)\n\n    return cleaned_lines"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    cleaned_lines = []\n    cleaned_line_index = 0\n    block_index = 0\n    current_block = defaultdict(list)\n    previous_line = \"\"\n    previous_line_stripped = \"\"\n    previous_line_tokens = []\n    previous_line_is_table_row = False\n    in_table = False\n\n    for index, line in enumerate(lines):\n        if should_skip(line, xml):\n            continue\n\n        line = line.strip()\n        line_tokens = nlm_tokenize(line)\n\n        if is_table_row(line):\n            in_table = True\n            previous_line_is_table_row = True\n        else:\n            in_table = False\n            previous_line_is_table_row = False\n\n        if not in_table and previous_line_is_table_row:\n            block_index += 1\n\n        if previous_line_stripped and previous_line_stripped[-1] == \"-\":\n            previous_line_stripped = previous_line_stripped[:-1] + line\n            previous_line_tokens = nlm_tokenize(previous_line_stripped)\n        elif (\n            previous_line_tokens\n            and previous_line_tokens[-1] in formatter.list_markers\n            and not find_floating_chars(line)\n        ):\n            previous_line_stripped = \" \".join(previous_line_tokens) + \" \" + line\n            previous_line_tokens = nlm_tokenize(previous_line_stripped)\n        else:\n            if previous_line_stripped:\n                current_block[\"text\"].append(previous_line_stripped)\n                current_block[\"line_index\"].append(cleaned_line_index)\n                current_block[\"block_index\"] = block_index\n                current_block[\"type\"] = \"paragraph\"\n                cleaned_line_index += 1\n\n        previous_line = line\n        previous_line_stripped = line.strip()\n        previous_line_tokens = line_tokens\n\n    if previous_line_stripped:\n        current_block[\"text\"].append(previous_line_stripped)\n        current_block[\"line_index\"].append(cleaned_line_index)\n        current_block[\"block_index\"] = block_index\n        current_block[\"type\"] = \"paragraph\"\n        cleaned_line_index += 1\n\n    if current_block:\n        cleaned_lines.append(current_block)\n\n    return cleaned_lines"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    cleaned_lines = []\n    cleaned_line_index = 0\n    current_block = defaultdict(list)\n    previous_line = \"\"\n    for i, line in enumerate(lines):\n        if should_skip(line, xml):\n            continue\n        if not check_parentheses(line):\n            line = previous_line + \" \" + line\n        previous_line = line\n        line = line.strip()\n        if not line:\n            continue\n        tokens = nlm_tokenize(line)\n        if len(tokens) == 1 and find_floating_chars(line):\n            continue\n        if is_table_row(line):\n            continue\n        current_block[cleaned_line_index].append(line)\n        if i < len(lines) - 1:\n            next_line = lines[i + 1]\n            if not should_skip(next_line, xml) and not check_parentheses(next_line):\n                cleaned_line_index += 1\n                current_block[cleaned_line_index] = []\n        else:\n            cleaned_line_index += 1\n            current_block[cleaned_line_index] = []\n    for index, block in current_block.items():\n        if block:\n            cleaned_lines.append({\n                \"index\": index,\n                \"text\": \" \".join(block),\n                \"type\": \"paragraph\",\n                \"start_index\": index,\n                \"blocks\": [],\n                \"header_index\": None,\n                \"indentation_level\": 0\n            })\n    return cleaned_lines"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    cleaned_lines = []\n    cleaned_line_index = 0\n    header_index = -1\n    list_index = -1\n    list_level = 0\n    list_stack = []\n    prev_line = \"\"\n    prev_cleaned_line = \"\"\n    prev_line_index = -1\n    prev_line_type = \"\"\n    prev_line_list_index = -1\n    prev_line_level = 0\n\n    for i, line in enumerate(lines):\n        if should_skip(line, xml):\n            continue\n\n        # Clean the line\n        cleaned_line = \" \".join(nlm_tokenize(line))\n\n        # Check for floating characters\n        if find_floating_chars(cleaned_line):\n            continue\n\n        # Check for parentheses balance\n        if not check_parentheses(cleaned_line):\n            continue\n\n        # Check for table row\n        if is_table_row(cleaned_line):\n            continue\n\n        # Remove duplicate lines\n        if cleaned_line == prev_cleaned_line:\n            continue\n\n        # Connect incomplete lines\n        if prev_line and not prev_line.endswith((\"-\", \"/\", \"\u2013\")):\n            cleaned_line = prev_cleaned_line + \" \" + cleaned_line\n\n        # Determine the type of the line\n        line_type = \"paragraph\"\n        if re.match(patterns.header, line):\n            line_type = \"header\"\n            header_index = cleaned_line_index\n            list_index = -1\n            list_level = 0\n            list_stack = []\n        elif re.match(patterns.list_item, line):\n            line_type = \"list_item\"\n            list_index += 1\n            list_level = line_parser.get_list_level(line)\n            if list_level > prev_line_level:\n                list_stack.append(prev_line_list_index)\n            elif list_level < prev_line_level:\n                for _ in range(prev_line_level - list_level):\n                    list_stack.pop()\n            if list_level == prev_line_level:\n                list_stack[-1] = prev_line_list_index\n            prev_line_list_index = list_index\n\n        # Create a block of text with metadata\n        block = {\n            \"index\": cleaned_line_index,\n            \"text\": cleaned_line,\n            \"type\": line_type,\n            \"start_index\": i,\n            \"list_blocks\": list_stack.copy(),\n            \"header_index\": header_index if line_type != \"header\" else -1,\n            \"list_index\": list_index if line_type == \"list_item\" else -1,\n            \"level\": list_level,\n        }\n        cleaned_lines.append(block)\n\n        # Update previous line information\n        prev_line = line\n        prev_cleaned_line = cleaned_line\n        prev_line_index = i\n        prev_line_type = line_type\n        prev_line_level = list_level\n\n        cleaned_line_index += 1\n\n    return cleaned_lines"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if org_texts is None or len(org_texts) == 0:\n        return [org_texts]\n\n    # Apply the predefined rules and patterns\n    for rule, replacement in rules:\n        org_texts = rule.sub(replacement, org_texts)\n\n    org_texts = bracket_rule.sub(r\"\\1\", org_texts)  # Remove brackets and keep the content\n    org_texts = space_rule.sub(r\"\\1\", org_texts)  # Remove space between punctuations\n    org_texts = quotation_pattern.sub('\"', org_texts)  # Normalize quotation marks\n\n    # Use the NLTK tokenizer to tokenize the text into sentences\n    sentences = nltk_tokenzier.tokenize(org_texts)\n\n    return sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # Apply rules to normalize the text\n    for rule, replaced in rules:\n        org_texts = rule.sub(replaced, org_texts)\n\n    # Tokenize the text using the NLTK tokenizer\n    tokenized_texts = nltk_tokenzier.tokenize(org_texts)\n\n    # Normalize quotation marks\n    tokenized_texts = [quotation_pattern.sub('\"', text) for text in tokenized_texts]\n\n    # Remove any space between punctuations (.')\n    tokenized_texts = [space_rule.sub(r\"\\1\", text) for text in tokenized_texts]\n\n    # Ensure that sentences within brackets are not broken\n    tokenized_texts = [bracket_rule.sub(r\"(\\1)\", text) for text in tokenized_texts]\n\n    return tokenized_texts"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if org_texts is None or len(org_texts) == 0:\n        return org_texts\n\n    # Normalize quotation marks\n    org_texts = re.sub(quotation_pattern, '\"', org_texts)\n\n    # Apply predefined rules for special cases\n    for rule, replacement in rules:\n        org_texts = rule.sub(replacement, org_texts)\n\n    # Tokenize the text into sentences\n    sentences = nltk_tokenzier.tokenize(org_texts)\n\n    # Join sentences within brackets\n    sentences = [bracket_rule.sub(lambda m: m.group(0).replace('.', '_'), s) for s in sentences]\n\n    # Remove any space between punctuations (.')\n    sentences = [space_rule.sub(r\"\\1\", s) for s in sentences]\n\n    return sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if org_texts is None or org_texts == \"\":\n        return [org_texts]\n\n    # Apply rules to normalize the text\n    for rule, replaced in rules:\n        org_texts = rule.sub(replaced, org_texts)\n\n    # Tokenize the text into sentences\n    sentences = nltk_tokenzier.tokenize(org_texts)\n\n    # Normalize quotation marks within the text\n    sentences = [quotation_pattern.sub('\"', sent) for sent in sentences]\n\n    return sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if org_texts is None or org_texts == \"\":\n        return [org_texts]\n\n    # Normalize quotation marks\n    org_texts = re.sub(quotation_pattern, '\"', org_texts)\n\n    # Tokenize using NLTK tokenizer\n    sentences = nltk_tokenzier.tokenize(org_texts)\n\n    # Apply rules for handling abbreviations and special cases\n    for rule, replaced in rules:\n        sentences = [rule.sub(replaced, sentence) for sentence in sentences]\n\n    # Remove spaces between punctuation\n    sentences = [space_rule.sub(r\"\\1\", sentence) for sentence in sentences]\n\n    # Reconstruct sentences within brackets\n    sentences = [bracket_rule.sub(r\"(\\1)\", sentence) for sentence in sentences]\n\n    return sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # Replace special cases\n    org_texts = re.sub(bracket_rule, r\"(\\1)\", org_texts)\n    org_texts = re.sub(space_rule, r\"\\1\", org_texts)\n    org_texts = re.sub(quotation_pattern, '\"', org_texts)\n\n    # Tokenize the text into sentences\n    tokenized_sentences = nltk_tokenzier.tokenize(org_texts)\n\n    # Apply rules for abbreviation handling\n    for rule, replaced in rules:\n        tokenized_sentences = [rule.sub(replaced, sentence) for sentence in tokenized_sentences]\n\n    return tokenized_sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if org_texts is None or org_texts == \"\":\n        return [org_texts]\n\n    # Apply predefined rules and patterns to tokenize and normalize the text\n    for rule, replaced in rules:\n        org_texts = rule.sub(replaced, org_texts)\n\n    org_texts = bracket_rule.sub(r\" \\1 \", org_texts)\n    org_texts = space_rule.sub(r\"\\1\", org_texts)\n    org_texts = quotation_pattern.sub('\"', org_texts)\n\n    # Tokenize the normalized text using the NLTK tokenizer\n    tokenized_sentences = nltk_tokenzier.tokenize(org_texts)\n    \n    return tokenized_sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if org_texts is None or len(org_texts) == 0:\n        return [org_texts]\n\n    # Apply rules to normalize the text\n    for rule, replaced in rules:\n        org_texts = rule.sub(replaced, org_texts)\n\n    # Apply additional normalization for spaces, brackets, and quotation marks\n    org_texts = space_rule.sub(r\"\\1\", org_texts)\n    org_texts = bracket_rule.sub(r\" \\1 \", org_texts)\n    org_texts = quotation_pattern.sub('\"', org_texts)\n\n    # Use NLTK tokenizer to tokenize the normalized text into sentences\n    sentences = nltk_tokenzier.tokenize(org_texts)\n\n    return sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if org_texts is None or org_texts == \"\":\n        return [org_texts]\n\n    # Apply predefined rules and patterns to tokenize and normalize the text\n    tokenized_sentences = nltk_tokenzier.tokenize(org_texts)\n\n    # Apply additional rules and patterns to handle special cases\n    for rule, replaced in rules:\n        tokenized_sentences = [rule.sub(replaced, sent) for sent in tokenized_sentences]\n\n    tokenized_sentences = [bracket_rule.sub(r\"(\\1)\", sent) for sent in tokenized_sentences]\n    tokenized_sentences = [space_rule.sub(r\"\\1\", sent) for sent in tokenized_sentences]\n    tokenized_sentences = [quotation_pattern.sub('\"', sent) for sent in tokenized_sentences]\n\n    return tokenized_sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # Normalize quotation marks\n    org_texts = re.sub(quotation_pattern, '\"', org_texts)\n\n    # Tokenize the text using NLTK tokenizer\n    sentences = nltk_tokenzier.tokenize(org_texts)\n\n    # Apply rules for special cases\n    for rule, replaced in rules:\n        sentences = [rule.sub(replaced, sentence) for sentence in sentences]\n\n    # Remove spaces between punctuation\n    sentences = [space_rule.sub(r\"\\1\", sentence) for sentence in sentences]\n\n    # Join sentences separated by new lines\n    sentences = [re.sub(r\"\\n\", \" \", sentence) for sentence in sentences]\n\n    # Join sentences within brackets\n    sentences = [bracket_rule.sub(r\"\\1\", sentence) for sentence in sentences]\n\n    return sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # Normalize quotation marks\n    org_texts = re.sub(quotation_pattern, '\"', org_texts)\n\n    # Tokenize the text using the NLTK tokenizer\n    sentences = nltk_tokenzier.tokenize(org_texts)\n\n    # Apply rules for handling special cases\n    for rule, replacement in rules:\n        sentences = [rule.sub(replacement, sentence) for sentence in sentences]\n\n    # Join sentences separated by new lines\n    sentences = \" \".join(sentences).split(\"\\n\")\n\n    # Remove extra spaces between punctuations\n    sentences = [space_rule.sub(r\"\\1\", sentence) for sentence in sentences]\n\n    # Join sentences within brackets\n    sentences = [bracket_rule.sub(r\"\\1\", sentence) for sentence in sentences]\n\n    return sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if org_texts is None or org_texts == \"\":\n        return [org_texts]\n\n    # Apply predefined rules and patterns to normalize the text\n    org_texts = re.sub(bracket_rule, r\"(\\1)\", org_texts)\n    org_texts = re.sub(space_rule, r\"\\1\", org_texts)\n    org_texts = re.sub(quotation_pattern, '\"', org_texts)\n\n    # Use the NLTK tokenizer to tokenize the normalized text\n    tokenized_sentences = nltk_tokenzier.tokenize(org_texts)\n\n    # Apply additional rules to handle special cases\n    for rule, replaced in rules:\n        tokenized_sentences = [re.sub(rule, replaced, sentence) for sentence in tokenized_sentences]\n\n    return tokenized_sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if org_texts is None or org_texts == \"\":\n        return [org_texts]\n\n    # Apply rules to normalize the text\n    for rule, replacement in rules:\n        org_texts = rule.sub(replacement, org_texts)\n\n    org_texts = bracket_rule.sub(r\"\\1\", org_texts)  # Remove brackets and keep content\n    org_texts = space_rule.sub(r\"\\1\", org_texts)  # Remove space between punctuations\n    org_texts = quotation_pattern.sub('\"', org_texts)  # Normalize quotation marks\n\n    # Tokenize the normalized text into sentences\n    sentences = nltk_tokenzier.tokenize(org_texts)\n\n    return sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if org_texts is None or org_texts == \"\":\n        return [org_texts]\n\n    # Apply predefined rules and patterns for tokenization and normalization\n    for rule, replaced in rules:\n        org_texts = rule.sub(replaced, org_texts)\n\n    org_texts = bracket_rule.sub(r\" \\1 \", org_texts)  # Add space around content inside brackets\n    org_texts = space_rule.sub(r\"\\1\", org_texts)  # Remove any space between punctuations (.')\n    org_texts = quotation_pattern.sub('\"', org_texts)  # Normalize quotation marks\n\n    # Tokenize the text into sentences\n    tokenized_sentences = nltk_tokenzier.tokenize(org_texts)\n\n    return tokenized_sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if org_texts is None or org_texts == \"\":\n        return [org_texts]\n\n    # Apply rules to normalize and tokenize the text\n    for rule, replaced in rules:\n        org_texts = rule.sub(replaced, org_texts)\n\n    # Tokenize the text using the NLTK tokenizer\n    tokenized_sentences = nltk_tokenzier.tokenize(org_texts)\n\n    # Remove extra spaces between punctuation\n    tokenized_sentences = [space_rule.sub(r\"\\1\", sentence) for sentence in tokenized_sentences]\n\n    # Normalize quotation marks\n    tokenized_sentences = [quotation_pattern.sub('\"', sentence) for sentence in tokenized_sentences]\n\n    # Ensure sentences within brackets are not broken\n    tokenized_sentences = [bracket_rule.sub(r\"(\\1)\", sentence) for sentence in tokenized_sentences]\n\n    return tokenized_sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if org_texts is None or org_texts == \"\":\n        return [org_texts]\n\n    # Apply rules to normalize the text\n    for rule, replaced in rules:\n        org_texts = rule.sub(replaced, org_texts)\n\n    # Tokenize the text into sentences\n    sentences = nltk_tokenzier.tokenize(org_texts)\n\n    # Normalize quotation marks\n    sentences = [quotation_pattern.sub('\"', sentence) for sentence in sentences]\n\n    # Remove any space between punctuations (.')\n    sentences = [space_rule.sub(r\"\\1\", sentence) for sentence in sentences]\n\n    # Join sentences within brackets\n    sentences = [bracket_rule.sub(r\"\\1\", sentence) if sentence.startswith(\"(\") else sentence for sentence in sentences]\n\n    return sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if org_texts is None or org_texts == \"\":\n        return [org_texts]\n\n    # Apply rules to normalize the text\n    for rule, replaced in rules:\n        org_texts = rule.sub(replaced, org_texts)\n\n    # Tokenize the text into sentences\n    sentences = nltk_tokenzier.tokenize(org_texts)\n\n    # Remove extra spaces between punctuations\n    sentences = [space_rule.sub(r\"\\1\", sent) for sent in sentences]\n\n    # Normalize quotation marks\n    sentences = [quotation_pattern.sub('\"', sent) for sent in sentences]\n\n    # Join sentences within brackets\n    sentences = [bracket_rule.sub(lambda m: m.group(0).replace(\".\", \"_\"), sent) for sent in sentences]\n\n    return sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if org_texts is None or org_texts.strip() == \"\":\n        return [org_texts]\n\n    # Normalize quotation marks\n    org_texts = re.sub(quotation_pattern, '\"', org_texts)\n\n    # Tokenize the text using NLTK tokenizer\n    sentences = nltk_tokenzier.tokenize(org_texts)\n\n    # Apply rules for special cases\n    for rule, replaced in rules:\n        sentences = [rule.sub(replaced, sentence) for sentence in sentences]\n\n    # Remove space between punctuations\n    sentences = [space_rule.sub(r\"\\1\", sentence) for sentence in sentences]\n\n    # Join sentences within brackets\n    sentences = [bracket_rule.sub(r\"\\1\", sentence) if sentence.startswith(\"(\") else sentence for sentence in sentences]\n\n    return sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if org_texts is None or org_texts == \"\":\n        return [org_texts]\n\n    # Apply predefined rules and patterns to normalize the text\n    for rule, replaced in rules:\n        org_texts = rule.sub(replaced, org_texts)\n\n    org_texts = bracket_rule.sub(r\" \\1 \", org_texts)\n    org_texts = space_rule.sub(r\"\\1\", org_texts)\n    org_texts = quotation_pattern.sub('\"', org_texts)\n\n    # Use the NLTK tokenizer to tokenize the normalized text\n    tokenized_sentences = nltk_tokenzier.tokenize(org_texts)\n\n    return tokenized_sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if org_texts is None or org_texts == \"\":\n        return [org_texts]\n\n    # Apply predefined rules and patterns\n    for rule, replacement in rules:\n        org_texts = rule.sub(replacement, org_texts)\n\n    org_texts = bracket_rule.sub(r\" \\1 \", org_texts)\n    org_texts = space_rule.sub(r\"\\1\", org_texts)\n    org_texts = quotation_pattern.sub('\"', org_texts)\n\n    # Tokenize the text using the NLTK tokenizer\n    tokenized_sentences = nltk_tokenzier.tokenize(org_texts)\n\n    return tokenized_sentences"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            return self[key].positions(token)\n        else:\n            positions_list = []\n            for i in range(len(self)):\n                positions_list.append(self[i].positions(token))\n            return positions_list"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            return self[key].positions(token)\n        else:\n            return [doc.positions(token) for doc in self]"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "\n        if key is not None:\n            return self[key].positions(token)\n        else:\n            return [doc.positions(token) for doc in self]"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            return self[key].positions(token)\n        else:\n            return [doc.positions(token) for doc in self]"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "\n        if key is not None:\n            return [doc.positions(token) for doc in self[key].to_list()]\n        else:\n            return [doc.positions(token) for doc in self.to_list()]"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            return self[key].positions(token)\n        else:\n            return [doc.positions(token) for doc in self]"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            return self[key].positions(token)\n        else:\n            return [doc.positions(token) for doc in self]"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            return self[key].positions(token)\n        else:\n            return [doc.positions(token) for doc in self]"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            return self[key].positions(token)\n        else:\n            return [doc.positions(token) for doc in self]"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            return self[key].positions(token)\n        else:\n            return [doc.positions(token) for doc in self]"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "\n        if key is not None:\n            return self[key].positions(token)\n        else:\n            return [doc.positions(token) for doc in self]"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "\n        if key is not None:\n            return self[key].positions(token)\n        else:\n            return [doc.positions(token) for doc in self]"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "\n        if key is not None:\n            return self[key].positions(token)\n        else:\n            return [doc.positions(token) for doc in self]"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            return [doc.positions(token) for doc in self[key]]\n        else:\n            return [doc.positions(token) for doc in self]"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "\n        if key is not None:\n            return self[key].positions(token)\n        else:\n            return [doc.positions(token) for doc in self]"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "\n        if key is not None:\n            return self[key].positions(token)\n        else:\n            return [doc.positions(token) for doc in self]"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "\n        if key is not None:\n            return [doc.positions(token) for doc in self[key].to_numpy()]\n        else:\n            return [doc.positions(token) for doc in self.to_numpy()]"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            return self[key].positions(token)\n        else:\n            return [doc.positions(token) for doc in self]"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            return [doc.positions(token) for doc in self[key]]\n        else:\n            return [doc.positions(token) for doc in self]"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            return self[key].positions(token)\n        else:\n            positions_list = []\n            for doc in self:\n                positions_list.append(doc.positions(token))\n            return positions_list"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():\n        return int(spec)\n    elif '%' in spec:\n        percentage = int(re.search(r'\\d+', spec).group())\n        return int(num_clauses * (percentage / 100))\n    elif '<' in spec:\n        threshold = int(re.search(r'\\d+', spec).group())\n        return min(num_clauses, threshold)\n    else:\n        raise ValueError(\"Invalid 'min should match' specification\")"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():\n        return int(spec)\n    elif spec.endswith('%'):\n        return int(num_clauses * int(spec[:-1]) / 100)\n    elif '<' in spec:\n        threshold = int(re.findall(r'\\d+', spec)[0])\n        return min(num_clauses, threshold)\n    else:\n        raise ValueError(\"Invalid 'min should match' specification\")"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():\n        return int(spec)\n    elif '%' in spec:\n        percent = int(re.findall(r'\\d+', spec)[0])\n        return int(num_clauses * percent / 100)\n    elif '<' in spec:\n        threshold = int(re.findall(r'\\d+', spec)[0])\n        return min(num_clauses, threshold)\n    else:\n        raise ValueError(\"Invalid 'min should match' specification\")"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "\n    if spec.isdigit():\n        return int(spec)\n    elif '%' in spec:\n        percentage = int(re.findall(r'\\d+', spec)[0])\n        return int(num_clauses * (percentage / 100))\n    elif '<' in spec:\n        threshold = int(re.findall(r'\\d+', spec)[0])\n        return max(num_clauses - threshold, 0)\n    else:\n        raise ValueError(\"Invalid 'min should match' specification\")"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():\n        return int(spec)\n    elif spec.endswith(\"%\"):\n        percentage = int(spec[:-1])\n        return max(1, int(num_clauses * percentage / 100))\n    elif \"<\" in spec:\n        left, right = spec.split(\"<\")\n        left = int(left.strip())\n        right = int(right.strip())\n        return max(left, int(num_clauses * right / 100))\n    else:\n        raise ValueError(\"Invalid min should match specification\")"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():\n        return int(spec)\n    elif '%' in spec:\n        percentage = int(re.findall(r'\\d+', spec)[0])\n        return int(num_clauses * (percentage / 100))\n    elif '<' in spec:\n        threshold = int(re.findall(r'\\d+', spec)[0])\n        return min(num_clauses, threshold)\n    else:\n        raise ValueError(\"Invalid 'min should match' specification\")"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():\n        return int(spec)\n    elif '%' in spec:\n        percentage = int(re.findall(r'\\d+', spec)[0])\n        return int(num_clauses * (percentage / 100))\n    elif '<' in spec:\n        threshold = int(re.findall(r'\\d+', spec)[0])\n        return min(num_clauses, threshold)\n    else:\n        raise ValueError(\"Invalid 'min should match' specification\")"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():\n        return int(spec)\n    elif '%' in spec:\n        percentage = int(re.search(r'\\d+', spec).group())\n        return max(int(num_clauses * (percentage / 100)), 1)\n    elif '<' in spec:\n        threshold = int(re.search(r'\\d+', spec).group())\n        return max(num_clauses - threshold, 1)\n    else:\n        raise ValueError(\"Invalid 'min should match' specification\")"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():\n        return int(spec)\n    elif '%' in spec:\n        percentage = int(re.findall(r'\\d+', spec)[0])\n        return int(num_clauses * (percentage / 100))\n    elif '<' in spec:\n        threshold = int(re.findall(r'\\d+', spec)[0])\n        return min(num_clauses, threshold)\n    else:\n        raise ValueError(\"Invalid 'min should match' specification\")"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():\n        return int(spec)\n    elif spec.endswith('%'):\n        percentage = int(spec[:-1])\n        return int(num_clauses * percentage / 100)\n    elif '<' in spec:\n        left, right = map(int, spec.split('<'))\n        return min(num_clauses, right)\n    else:\n        raise ValueError(\"Invalid 'min should match' specification\")"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():\n        return int(spec)\n    elif '%' in spec:\n        percentage = int(re.search(r'\\d+', spec).group())\n        return int(num_clauses * (percentage / 100))\n    elif '<' in spec:\n        threshold = int(re.search(r'\\d+', spec).group())\n        return max(num_clauses - threshold, 1)\n    else:\n        raise ValueError(\"Invalid 'min should match' specification\")"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():\n        return int(spec)\n    elif '%' in spec:\n        percentage = int(re.findall(r'\\d+', spec)[0])\n        return int(num_clauses * (percentage / 100))\n    elif '<' in spec:\n        threshold = int(re.findall(r'\\d+', spec)[0])\n        return num_clauses - threshold\n    else:\n        raise ValueError(\"Invalid 'min should match' specification\")"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():  # absolute number\n        return int(spec)\n    elif '%' in spec:  # percentage\n        percent = int(re.findall(r'\\d+', spec)[0])\n        return int(num_clauses * percent / 100)\n    elif '<' in spec:  # conditional expression\n        threshold = int(re.findall(r'\\d+', spec)[0])\n        return min(num_clauses, threshold)\n    else:  # default to 1\n        return 1"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():\n        return int(spec)\n    elif '%' in spec:\n        percentage = int(re.findall(r'\\d+', spec)[0])\n        return int(num_clauses * (percentage / 100))\n    elif '<' in spec:\n        threshold = int(re.findall(r'\\d+', spec)[0])\n        return min(num_clauses, threshold)\n    else:\n        raise ValueError(\"Invalid 'min should match' specification\")"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():\n        return int(spec)\n    elif '%' in spec:\n        return int(num_clauses * (int(spec.strip('%')) / 100))\n    elif '<' in spec:\n        return int(num_clauses * (int(spec.strip('<')) / 100))\n    else:\n        raise ValueError(\"Invalid 'min should match' specification\")"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if not spec:\n        return 0\n\n    if spec.isdigit():\n        return int(spec)\n\n    if '%' in spec:\n        percent = int(re.search(r'\\d+', spec).group())\n        return int(num_clauses * (percent / 100))\n\n    if '<' in spec:\n        threshold = int(re.search(r'\\d+', spec).group())\n        return min(num_clauses, threshold)\n\n    raise ValueError(\"Invalid 'min should match' specification\")"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():\n        return int(spec)\n    elif '%' in spec:\n        percent = int(re.findall(r'\\d+', spec)[0])\n        return int(num_clauses * percent / 100)\n    elif '<' in spec:\n        threshold = int(re.findall(r'\\d+', spec)[0])\n        return min(num_clauses, threshold)\n    else:\n        raise ValueError(\"Invalid 'min should match' specification\")"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():\n        return int(spec)\n    elif spec.endswith(\"%\"):\n        percentage = int(re.search(r'\\d+', spec).group())\n        return int(num_clauses * (percentage / 100))\n    elif \"<\" in spec:\n        threshold = int(re.search(r'\\d+', spec).group())\n        return min(num_clauses, threshold)\n    else:\n        raise ValueError(\"Invalid 'min should match' specification\")"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():\n        return int(spec)\n    elif '%' in spec:\n        percentage = int(re.findall(r'\\d+', spec)[0])\n        return int(num_clauses * (percentage / 100))\n    elif '<' in spec:\n        threshold = int(re.findall(r'\\d+', spec)[0])\n        return min(num_clauses, threshold)\n    else:\n        raise ValueError(\"Invalid 'min should match' specification\")"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.isdigit():\n        return int(spec)\n    elif '%' in spec:\n        percentage = int(re.findall(r'\\d+', spec)[0])\n        return int(num_clauses * (percentage / 100))\n    elif '<' in spec:\n        threshold = int(re.findall(r'\\d+', spec)[0])\n        return min(num_clauses, threshold)\n    else:\n        raise ValueError(\"Invalid 'min should match' specification\")"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(set(tokens)) == len(tokens):\n            # Directly calculate phrase frequencies using positions of terms\n            return compute_phrase_freqs(self, tokens)\n        else:\n            # Delegate the calculation to another method that handles different slops or non-unique tokens\n            return scan_merge_ins(self, tokens, slop)"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "    if slop == 1 and len(set(tokens)) == len(tokens):\n        return compute_phrase_freqs(self.term_mat, self.posns, self.term_dict, tokens)\n    else:\n        return scan_merge_ins(self.term_mat, self.posns, self.term_dict, tokens, slop)"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "    if slop == 1 and len(tokens) == len(set(tokens)):\n        # Calculate phrase frequencies directly using positions of terms\n        return compute_phrase_freqs(self, tokens)\n    else:\n        # Delegate the calculation to another method for different slops or non-unique tokens\n        return scan_merge_ins(self, tokens, slop)"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if len(tokens) == 1:\n            return self.termfreqs(tokens[0])\n\n        if slop == 1 and len(set(tokens)) == len(tokens):\n            # Calculate phrase frequencies directly using positions of terms\n            return compute_phrase_freqs(self, tokens)\n\n        else:\n            # Delegate calculation to another method for different slops or non-unique tokens\n            return scan_merge_ins(self, tokens, slop)"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(set(tokens)) == len(tokens):\n            return compute_phrase_freqs(self.term_mat, self.posns, self.term_dict, tokens)\n        else:\n            return scan_merge_ins(self.term_mat, self.posns, self.term_dict, tokens, slop)"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "    if slop == 1 and len(set(tokens)) == len(tokens):\n        return compute_phrase_freqs(self, tokens)\n    else:\n        return scan_merge_ins(self, tokens, slop)"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(set(tokens)) == len(tokens):\n            return scan_merge_ins(self.term_mat, tokens, self.posns, self.term_dict)\n        else:\n            return compute_phrase_freqs(self.term_mat, tokens, self.posns, self.term_dict, slop)"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "    if slop == 1 and len(tokens) == len(set(tokens)):\n        return compute_phrase_freqs(self, tokens)\n    else:\n        return scan_merge_ins(self, tokens, slop)"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "    if slop == 1 and len(set(tokens)) == len(tokens):\n        return compute_phrase_freqs(self.term_mat, self.posns, self.term_dict, tokens)\n    else:\n        return scan_merge_ins(self.term_mat, self.posns, self.term_dict, tokens, slop)"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(set(tokens)) == len(tokens):\n            return compute_phrase_freqs(self, tokens)\n        else:\n            return scan_merge_ins(self, tokens, slop)"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if len(tokens) == 1:\n            return self.termfreqs(tokens[0])\n\n        if slop == 1 and len(set(tokens)) == len(tokens):\n            return compute_phrase_freqs(self, tokens)\n\n        return scan_merge_ins(self, tokens, slop)"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(set(tokens)) == len(tokens):\n            return compute_phrase_freqs(self.term_mat, self.posns, self.term_dict, tokens)\n        else:\n            return scan_merge_ins(self.term_mat, self.posns, self.term_dict, tokens, slop)"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(set(tokens)) == len(tokens):\n            return scan_merge_ins(self, tokens)\n        else:\n            return compute_phrase_freqs(self, tokens, slop)"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(set(tokens)) == len(tokens):\n            return compute_phrase_freqs(self, tokens)\n        else:\n            return scan_merge_ins(self, tokens, slop)"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(set(tokens)) == len(tokens):\n            return compute_phrase_freqs(self.posns, self.term_dict, tokens)\n        else:\n            return scan_merge_ins(self.posns, self.term_dict, tokens, slop)"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "    if len(tokens) == 1:\n        return self.termfreqs(tokens[0])\n    elif slop == 1 and len(set(tokens)) == len(tokens):\n        return scan_merge_ins(self, tokens)\n    else:\n        return compute_phrase_freqs(self, tokens, slop)"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "    if slop == 1 and len(set(tokens)) == len(tokens):\n        return compute_phrase_freqs(self, tokens)\n    else:\n        return scan_merge_ins(self, tokens, slop)"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(tokens) == len(set(tokens)):\n            return compute_phrase_freqs(self, tokens)\n        else:\n            return scan_merge_ins(self, tokens, slop)"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(set(tokens)) == len(tokens):\n            return compute_phrase_freqs(self, tokens)\n        else:\n            return scan_merge_ins(self, tokens, slop)"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if len(tokens) == 1:\n            return self.termfreqs(tokens[0])\n\n        if slop == 1 and len(set(tokens)) == len(tokens):\n            return scan_merge_ins(self, tokens)\n\n        return compute_phrase_freqs(self, tokens, slop)"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if not callable(tokenizer):\n            raise TypeError(\"The 'tokenizer' argument must be a callable function\")\n\n        if not isinstance(truncate, bool):\n            raise TypeError(\"The 'truncate' argument must be a boolean\")\n\n        if not isinstance(batch_size, numbers.Integral):\n            raise TypeError(\"The 'batch_size' argument must be an integer\")\n\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"The 'avoid_copies' argument must be a boolean\")\n\n        if not is_list_like(array):\n            raise TypeError(\"The 'array' argument must be a list-like object\")\n\n        postings = []\n        for batch_start in range(0, len(array), batch_size):\n            batch = array[batch_start:batch_start + batch_size]\n            tokens = [tokenizer(item) for item in batch]\n            postings.extend(tokens)\n\n        if truncate:\n            # Implement truncation logic here if needed\n            pass\n\n        return cls(postings, tokenizer, avoid_copies)"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "\n        if not callable(tokenizer):\n            raise TypeError(\"The 'tokenizer' argument must be a function\")\n\n        if not isinstance(truncate, bool):\n            raise TypeError(\"The 'truncate' argument must be a boolean\")\n\n        if not isinstance(batch_size, numbers.Integral) or batch_size <= 0:\n            raise ValueError(\"The 'batch_size' argument must be a positive integer\")\n\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"The 'avoid_copies' argument must be a boolean\")\n\n        if truncate:\n            warnings.warn(\"Data truncation is not currently supported. The entire dataset will be processed.\")\n\n        postings = []\n        for batch_start in range(0, len(array), batch_size):\n            batch_end = min(batch_start + batch_size, len(array))\n            batch = array[batch_start:batch_end]\n            tokens = [tokenizer(item) for item in batch]\n            postings.extend(tokens)\n\n        return cls(postings, tokenizer, avoid_copies)"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if not callable(tokenizer):\n            raise TypeError(\"The 'tokenizer' parameter must be a callable function\")\n\n        if not isinstance(truncate, bool):\n            raise TypeError(\"The 'truncate' parameter must be a boolean\")\n\n        if not isinstance(batch_size, numbers.Integral):\n            raise TypeError(\"The 'batch_size' parameter must be an integer\")\n\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"The 'avoid_copies' parameter must be a boolean\")\n\n        if not is_list_like(array):\n            raise TypeError(\"The 'array' parameter must be a list-like object\")\n\n        postings = []\n        for idx, string in enumerate(array):\n            tokens = tokenizer(string)\n            postings.append(tokens)\n\n            if (idx + 1) % batch_size == 0:\n                term_mat, posns, term_dict, avg_doc_length, doc_lens = build_index_from_terms_list(\n                    postings, Terms)\n                postings = []\n\n        if postings:\n            term_mat, posns, term_dict, avg_doc_length, doc_lens = build_index_from_terms_list(\n                postings, Terms)\n\n        return cls(postings, tokenizer, avoid_copies)"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if truncate:\n            warnings.warn(\"Truncation not supported, ignoring truncate parameter\", UserWarning)\n\n        postings = []\n        for i in range(0, len(array), batch_size):\n            batch = array[i:i + batch_size]\n            tokenized_batch = [tokenizer(item) for item in batch]\n            postings.extend(tokenized_batch)\n\n        return cls(postings, tokenizer, avoid_copies)"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        term_list = []\n        for batch_start in range(0, len(array), batch_size):\n            batch = array[batch_start:batch_start + batch_size]\n            term_list.extend(tokenizer(doc) for doc in batch)\n\n        term_list = [term for terms in term_list for term in terms]\n\n        if truncate:\n            warnings.warn(\"Truncation not yet implemented. Ignoring truncate.\")\n\n        return cls(term_list, tokenizer=tokenizer, avoid_copies=avoid_copies)"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if not callable(tokenizer):\n            raise ValueError(\"Tokenizer must be a callable function\")\n\n        if not isinstance(truncate, bool):\n            raise ValueError(\"Truncate must be a boolean\")\n\n        if not isinstance(batch_size, numbers.Integral) or batch_size <= 0:\n            raise ValueError(\"Batch size must be a positive integer\")\n\n        if not isinstance(avoid_copies, bool):\n            raise ValueError(\"Avoid copies must be a boolean\")\n\n        if not is_list_like(array):\n            raise ValueError(\"Array must be a list-like object\")\n\n        if truncate:\n            warnings.warn(\"Truncation is not implemented yet. The entire array will be indexed.\")\n\n        postings = []\n        for batch_start in range(0, len(array), batch_size):\n            batch = array[batch_start:batch_start + batch_size]\n            tokenized_batch = [tokenizer(item) for item in batch]\n            postings.extend(tokenized_batch)\n\n        return cls(postings, tokenizer, avoid_copies)"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if truncate:\n            warnings.warn(\"Truncation not yet implemented, ignoring.\")\n        if not callable(tokenizer):\n            raise ValueError(\"Tokenizer must be a callable function.\")\n\n        if not isinstance(batch_size, numbers.Integral) or batch_size <= 0:\n            raise ValueError(\"Batch size must be a positive integer.\")\n\n        postings = []\n        for i in range(0, len(array), batch_size):\n            batch = array[i:i + batch_size]\n            tokenized_batch = [tokenizer(item) for item in batch]\n            postings.extend(tokenized_batch)\n\n        return cls(postings, tokenizer, avoid_copies)"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        term_list = []\n        for batch_start in range(0, len(array), batch_size):\n            batch = array[batch_start:batch_start + batch_size]\n            term_list.extend(tokenizer(x) for x in batch)\n\n        term_mat, posns, term_dict, avg_doc_length, doc_lens = build_index_from_terms_list(term_list, Terms)\n\n        return cls(term_mat, tokenizer=tokenizer, avoid_copies=avoid_copies)"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if not callable(tokenizer):\n            raise TypeError(\"The 'tokenizer' parameter must be a callable function.\")\n\n        if not isinstance(truncate, bool):\n            raise TypeError(\"The 'truncate' parameter must be a boolean value.\")\n\n        if not isinstance(batch_size, numbers.Integral):\n            raise TypeError(\"The 'batch_size' parameter must be an integer value.\")\n\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"The 'avoid_copies' parameter must be a boolean value.\")\n\n        if not is_list_like(array):\n            raise TypeError(\"The 'array' parameter must be a list-like object.\")\n\n        if not array:\n            raise ValueError(\"The 'array' parameter cannot be empty.\")\n\n        postings = []\n        for i in range(0, len(array), batch_size):\n            batch = array[i:i + batch_size]\n            batch_postings = [tokenizer(doc) for doc in batch]\n            postings.extend(batch_postings)\n\n        return cls(postings, tokenizer, avoid_copies)"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if not callable(tokenizer):\n            raise TypeError(\"Expected a callable object for 'tokenizer'\")\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected a boolean value for 'truncate'\")\n        if not isinstance(batch_size, numbers.Integral):\n            raise TypeError(\"Expected an integer value for 'batch_size'\")\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected a boolean value for 'avoid_copies'\")\n\n        if truncate:\n            warnings.warn(\"Data truncation is not yet supported\", UserWarning)\n\n        indexed_data = build_index_from_tokenizer(array, tokenizer, batch_size=batch_size, avoid_copies=avoid_copies)\n\n        return cls(indexed_data, tokenizer, avoid_copies)"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check if array is list-like\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Initialize variables to hold the indexed data\n        term_mat = []\n        posns = PosnBitArray()\n        term_dict = {}\n        doc_lens = []\n        avg_doc_length = 0\n\n        # Process the array in batches\n        start = 0\n        end = batch_size\n        while start < len(array):\n            batch = array[start:end]\n\n            # Tokenize the batch using the specified tokenizer\n            tokenized_batch = [tokenizer(item) for item in batch]\n\n            # Build index from the tokenized batch\n            batch_term_mat, batch_posns, batch_term_dict, batch_avg_doc_length, batch_doc_lens = build_index_from_tokenizer(\n                tokenized_batch, Terms, truncate=truncate\n            )\n\n            # Append the indexed data from the batch to the overall indexed data\n            term_mat.append(batch_term_mat)\n            posns.merge(batch_posns)\n            term_dict.update(batch_term_dict)\n            doc_lens.extend(batch_doc_lens)\n\n            # Update average document length\n            avg_doc_length = (avg_doc_length * len(doc_lens) + batch_avg_doc_length * len(batch_doc_lens)) / (\n                    len(doc_lens) + len(batch_doc_lens))\n\n            # Move to the next batch\n            start = end\n            end += batch_size\n\n        # Create a new instance of SearchArray containing the indexed data\n        return cls(term_mat, posns, term_dict, avg_doc_length, doc_lens, avoid_copies=avoid_copies)"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "\n        if not callable(tokenizer):\n            raise ValueError(\"The 'tokenizer' parameter must be a callable function\")\n\n        if not isinstance(truncate, bool):\n            raise ValueError(\"The 'truncate' parameter must be a boolean\")\n\n        if not isinstance(batch_size, numbers.Integral) or batch_size <= 0:\n            raise ValueError(\"The 'batch_size' parameter must be a positive integer\")\n\n        if not isinstance(avoid_copies, bool):\n            raise ValueError(\"The 'avoid_copies' parameter must be a boolean\")\n\n        indexed_data = build_index_from_tokenizer(array, tokenizer, truncate, batch_size, avoid_copies)\n        return cls(indexed_data, tokenizer, avoid_copies)"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "\n        if not callable(tokenizer):\n            raise TypeError(\"The 'tokenizer' argument must be a callable function.\")\n\n        if not isinstance(truncate, bool):\n            raise TypeError(\"The 'truncate' argument must be a boolean value.\")\n\n        if not isinstance(batch_size, numbers.Integral):\n            raise TypeError(\"The 'batch_size' argument must be an integer.\")\n\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"The 'avoid_copies' argument must be a boolean value.\")\n\n        if not is_list_like(array):\n            raise TypeError(\"The 'array' argument must be a list-like object.\")\n\n        postings = []\n        for batch_start in range(0, len(array), batch_size):\n            batch = array[batch_start:batch_start + batch_size]\n            tokenized_batch = [tokenizer(item) for item in batch]\n            postings.extend(tokenized_batch)\n\n        return cls(postings, tokenizer, avoid_copies)"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        \n        if not callable(tokenizer):\n            raise TypeError(\"The 'tokenizer' parameter must be a callable function\")\n\n        if not isinstance(truncate, bool):\n            raise TypeError(\"The 'truncate' parameter must be a boolean\")\n\n        if not isinstance(batch_size, numbers.Integral):\n            raise TypeError(\"The 'batch_size' parameter must be an integer\")\n\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"The 'avoid_copies' parameter must be a boolean\")\n\n        if not is_list_like(array):\n            raise TypeError(\"The 'array' parameter must be iterable\")\n\n        postings = []\n        for i in range(0, len(array), batch_size):\n            batch = array[i:i + batch_size]\n            batch_postings = [tokenizer(item) for item in batch]\n            postings.extend(batch_postings)\n\n            if truncate and len(postings) > truncate:\n                break\n\n        return cls(postings, tokenizer, avoid_copies)"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if truncate:\n            warnings.warn(\"Truncation not currently implemented\")\n\n        postings = []\n        doc_lens = []\n        for batch_start in range(0, len(array), batch_size):\n            batch = array[batch_start:batch_start + batch_size]\n            tokenized_batch = [tokenizer(doc) for doc in batch]\n            postings.extend(tokenized_batch)\n            doc_lens.extend([len(tokens) for tokens in tokenized_batch])\n\n        return cls(postings, tokenizer=tokenizer, avoid_copies=avoid_copies)"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "\n        # Initialize variables\n        term_list = []\n        doc_lengths = []\n\n        # Process the array in batches\n        for i in range(0, len(array), batch_size):\n            batch = array[i:i + batch_size]\n\n            # Tokenize the batch\n            tokenized_batch = [tokenizer(item) for item in batch]\n\n            # Create a list of terms and document lengths\n            for tokens in tokenized_batch:\n                term_freqs = Counter(tokens)\n                term_list.append(term_freqs)\n                doc_lengths.append(len(tokens))\n\n        # Build the index from the term list\n        term_mat, posns, term_dict, avg_doc_length, doc_lens = build_index_from_terms_list(term_list, Terms)\n\n        # Create a new instance of SearchArray with the indexed data\n        return cls(term_list, tokenizer, avoid_copies)"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if truncate:\n            # Truncate the data to fit within memory constraints\n            array = array[:batch_size]\n\n        postings = []\n        for i in range(0, len(array), batch_size):\n            batch = array[i:i + batch_size]\n            tokens = [tokenizer(item) for item in batch]\n            postings.extend(tokens)\n\n        return cls(postings, tokenizer, avoid_copies)"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        if not callable(tokenizer):\n            raise TypeError(\"Expected a callable object for tokenizer\")\n\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Truncate parameter must be a boolean\")\n\n        if not isinstance(batch_size, numbers.Integral):\n            raise TypeError(\"Batch size must be an integer\")\n\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Avoid copies parameter must be a boolean\")\n\n        indexed_data = []\n        for i in range(0, len(array), batch_size):\n            batch = array[i:i + batch_size]\n            indexed_batch = [tokenizer(item) for item in batch]\n            indexed_data.extend(indexed_batch)\n\n        return cls(indexed_data, tokenizer, avoid_copies)"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if not callable(tokenizer):\n            raise ValueError(\"The 'tokenizer' parameter must be a callable function\")\n\n        if not isinstance(truncate, bool):\n            raise ValueError(\"The 'truncate' parameter must be a boolean\")\n\n        if not isinstance(batch_size, numbers.Integral) or batch_size < 1:\n            raise ValueError(\"The 'batch_size' parameter must be a positive integer\")\n\n        if not isinstance(avoid_copies, bool):\n            raise ValueError(\"The 'avoid_copies' parameter must be a boolean\")\n\n        if not is_list_like(array):\n            raise ValueError(\"The 'array' parameter must be a list-like object\")\n\n        if truncate:\n            warnings.warn(\"Truncation of data is not supported yet and will be ignored\", UserWarning)\n\n        postings = []\n        for i in range(0, len(array), batch_size):\n            batch = array[i:i + batch_size]\n            tokens = [tokenizer(item) for item in batch]\n            postings.extend(tokens)\n\n        return cls(postings, tokenizer, avoid_copies)"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if not callable(tokenizer):\n            raise TypeError(\"The 'tokenizer' parameter must be a callable function\")\n\n        if not isinstance(truncate, bool):\n            raise TypeError(\"The 'truncate' parameter must be a boolean\")\n\n        if not isinstance(batch_size, numbers.Integral) or batch_size <= 0:\n            raise ValueError(\"The 'batch_size' parameter must be a positive integer\")\n\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"The 'avoid_copies' parameter must be a boolean\")\n\n        if not is_list_like(array):\n            raise TypeError(\"The 'array' parameter must be a list-like object\")\n\n        if truncate:\n            array = array[:batch_size]\n\n        postings = []\n        for i in range(0, len(array), batch_size):\n            batch = array[i:i + batch_size]\n            tokens = [tokenizer(text) for text in batch]\n            postings.extend(tokens)\n\n        return cls(postings, tokenizer, avoid_copies)"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "class ProxifierMessageInterceptor(MessageInterceptor):\n    server: Server\n    connections: Dict[str, Connection]\n    lock: threading.Lock\n\n    @classmethod\n    def default_config(cls) -> dict:\n        return {\n            'proxyHost': '127.0.0.1',\n            'proxyPort': 8888,\n            'serverHost': '127.0.0.1',\n            'serverPort': 25500,\n            'strategy': 'length',\n            'strategies': {\n                'buffer': {\n                    'bufferSize': 65536,\n                },\n                'suffix': {\n                    'bufferSize': 65536,\n                    'value': '[D_END]',\n                },\n                'length': {\n                },\n            },\n            'autoCloseConnections': True,\n            'multipleConnections': True,\n        }\n\n    def __init__(self):\n        \"\"\"\n        Initializes an instance of the ProxifierMessageInterceptor class by setting up a server with specific configurations and starting it. It also initializes a dictionary to keep track of connections and a lock for thread safety.\n\n        Input-Output Arguments\n        :param self: ProxifierMessageInterceptor. An instance of the ProxifierMessageInterceptor class. It uses its configuration and logger attributes to set up the server and for logging purposes.\n        :return: No return values.\n        \"\"\"\n        self.server = Server(self.config['serverHost'], self.config['serverPort'])\n        self.connections = {}\n        self.lock = threading.Lock()\n        self.server.start()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "class ProxifierMessageInterceptor:\n    def __init__(self):\n        self.server = Server(self.config['serverHost'], self.config['serverPort'], self.logger)\n        self.connections = {}\n        self.lock = threading.Lock()\n        self.server.start()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "class ProxifierMessageInterceptor(MessageInterceptor):\n    def __init__(self):\n        super().__init__()\n        self.server = Server(self.config['serverHost'], self.config['serverPort'])\n        self.connections = {}\n        self.lock = threading.Lock()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "class ProxifierMessageInterceptor(MessageInterceptor):\n    def __init__(self):\n        \"\"\"\n        Initializes an instance of the ProxifierMessageInterceptor class by setting up a server with specific configurations and starting it. It also initializes a dictionary to keep track of connections and a lock for thread safety.\n\n        Input-Output Arguments\n        :param self: ProxifierMessageInterceptor. An instance of the ProxifierMessageInterceptor class. It uses its configuration and logger attributes to set up the server and for logging purposes.\n        :return: No return values.\n        \"\"\"\n        self.server = Server(self.config['serverHost'], self.config['serverPort'])\n        self.connections = {}\n        self.lock = threading.Lock()\n        self.server.start()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "class ProxifierMessageInterceptor:\n    def __init__(self):\n        self.server = Server(self.config['serverHost'], self.config['serverPort'])\n        self.connections = {}\n        self.lock = threading.Lock()\n        self.server.start()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "class ProxifierMessageInterceptor:\n    def __init__(self):\n        self.server = Server(\n            host=self.config['serverHost'],\n            port=self.config['serverPort'],\n            logger=self.logger,\n            interceptor=self\n        )\n        self.connections = {}\n        self.lock = threading.Lock()\n        self.server.start()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "class ProxifierMessageInterceptor:\n    def __init__(self):\n        self.server = Server((self.config['serverHost'], self.config['serverPort']), self.handle_message)\n        self.connections = {}\n        self.lock = threading.Lock()\n\n        self.server.start()\n\n    def handle_message(self, data, address):\n        \"\"\"\n        Handles incoming messages from the server\n        \"\"\"\n        # Implement message handling logic here"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server((self.config['serverHost'], self.config['serverPort']), self.logger)\n        self.connections = {}\n        self.lock = threading.Lock()\n        self.server.start()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "class ProxifierMessageInterceptor:\n    def __init__(self):\n        self.server = Server(\n            host=self.config['serverHost'],\n            port=self.config['serverPort'],\n            logger=self.logger\n        )\n        self.connections = {}\n        self.lock = threading.Lock()\n\n        \"\"\"\n        Initializes an instance of the ProxifierMessageInterceptor class by setting up a server with specific configurations and starting it. It also initializes a dictionary to keep track of connections and a lock for thread safety.\n\n        Input-Output Arguments\n        :param self: ProxifierMessageInterceptor. An instance of the ProxifierMessageInterceptor class. It uses its configuration and logger attributes to set up the server and for logging purposes.\n        :return: No return values.\n        \"\"\""}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "class ProxifierMessageInterceptor:\n    def __init__(self):\n        self.server = Server(self.config['serverHost'], self.config['serverPort'], self.logger)\n        self.connections = {}\n        self.lock = threading.Lock()\n        self.server.start()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "class ProxifierMessageInterceptor:\n    def __init__(self):\n        self.server = Server(host=self.config['serverHost'], port=self.config['serverPort'])\n        self.connections = {}\n        self.lock = threading.Lock()\n        self.logger.info(\"ProxifierMessageInterceptor initialized\")\n\n    def default_config(cls) -> dict:\n        return {\n            'proxyHost': '127.0.0.1',\n            'proxyPort': 8888,\n            'serverHost': '127.0.0.1',\n            'serverPort': 25500,\n            'strategy': 'length',\n            'strategies': {\n                'buffer': {\n                    'bufferSize': 65536,\n                },\n                'suffix': {\n                    'bufferSize': 65536,\n                    'value': '[D_END]',\n                },\n                'length': {\n                },\n            },\n            'autoCloseConnections': True,\n            'multipleConnections': True,\n        }"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "class ProxifierMessageInterceptor(MessageInterceptor):\n    def __init__(self):\n        \"\"\"\n        Initializes an instance of the ProxifierMessageInterceptor class by setting up a server with specific configurations and starting it. It also initializes a dictionary to keep track of connections and a lock for thread safety.\n\n        Input-Output Arguments\n        :param self: ProxifierMessageInterceptor. An instance of the ProxifierMessageInterceptor class. It uses its configuration and logger attributes to set up the server and for logging purposes.\n        :return: No return values.\n        \"\"\"\n        self.server = Server(self.config['serverHost'], self.config['serverPort'], self)\n        self.connections = {}\n        self.lock = threading.Lock()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "class ProxifierMessageInterceptor:\n    def __init__(self):\n        \"\"\"\n        Initializes an instance of the ProxifierMessageInterceptor class by setting up a server with specific configurations and starting it. It also initializes a dictionary to keep track of connections and a lock for thread safety.\n\n        Input-Output Arguments\n        :param self: ProxifierMessageInterceptor. An instance of the ProxifierMessageInterceptor class. It uses its configuration and logger attributes to set up the server and for logging purposes.\n        :return: No return values.\n        \"\"\"\n        self.server = Server(self.config['serverHost'], self.config['serverPort'], self)\n        self.connections = {}\n        self.lock = threading.Lock()\n        self.server.start()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "class ProxifierMessageInterceptor:\n    def __init__(self):\n        \"\"\"\n        Initializes an instance of the ProxifierMessageInterceptor class by setting up a server with specific configurations and starting it. It also initializes a dictionary to keep track of connections and a lock for thread safety.\n\n        Input-Output Arguments\n        :param self: ProxifierMessageInterceptor. An instance of the ProxifierMessageInterceptor class. It uses its configuration and logger attributes to set up the server and for logging purposes.\n        :return: No return values.\n        \"\"\"\n        self.server = Server(self.config['serverHost'], self.config['serverPort'], self)\n        self.connections = {}\n        self.lock = threading.Lock()\n        self.server.start()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "class ProxifierMessageInterceptor:\n    def __init__(self):\n        self.server = Server(self.config['serverHost'], self.config['serverPort'], self.logger)\n        self.connections = {}\n        self.lock = threading.Lock()\n        self.server.start()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "class ProxifierMessageInterceptor:\n    def __init__(self):\n        \"\"\"\n        Initializes an instance of the ProxifierMessageInterceptor class by setting up a server with specific configurations and starting it. It also initializes a dictionary to keep track of connections and a lock for thread safety.\n\n        Input-Output Arguments\n        :param self: ProxifierMessageInterceptor. An instance of the ProxifierMessageInterceptor class. It uses its configuration and logger attributes to set up the server and for logging purposes.\n        :return: No return values.\n        \"\"\"\n        self.server = Server(self.config['serverHost'], self.config['serverPort'], self.logger)\n        self.connections = {}\n        self.lock = threading.Lock()\n        self.server.start()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "class ProxifierMessageInterceptor(MessageInterceptor):\n    def __init__(self):\n        self.server = Server(\n            host=self.config['serverHost'],\n            port=self.config['serverPort'],\n            logger=self.logger,\n            strategy=get_strategy(self.config['strategy'], self.config['strategies'])\n        )\n        self.connections = {}\n        self.lock = threading.Lock()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "class ProxifierMessageInterceptor:\n    def __init__(self):\n        \"\"\"\n        Initializes an instance of the ProxifierMessageInterceptor class by setting up a server with specific configurations and starting it. It also initializes a dictionary to keep track of connections and a lock for thread safety.\n\n        Input-Output Arguments\n        :param self: ProxifierMessageInterceptor. An instance of the ProxifierMessageInterceptor class. It uses its configuration and logger attributes to set up the server and for logging purposes.\n        :return: No return values.\n        \"\"\"\n        self.server = Server((self.config['serverHost'], self.config['serverPort']), self.handle_connection)\n        self.connections = {}\n        self.lock = threading.Lock()\n        self.server.start()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "class ProxifierMessageInterceptor:\n    def __init__(self):\n        self.server = Server(self.config['serverHost'], self.config['serverPort'], self.logger)\n        self.connections = {}\n        self.lock = threading.Lock()\n        self.server.start()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "class ProxifierMessageInterceptor:\n    def __init__(self):\n        self.server = Server(\n            host=self.config['serverHost'],\n            port=self.config['serverPort'],\n            logger=self.logger\n        )\n        self.connections = {}\n        self.lock = threading.Lock()\n        self.server.start()"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & m1) + ((arr >> _2) & m1)\n    arr = (arr + (arr >> _4)) & s33\n    arr += arr >> _8\n    arr += arr >> _16\n    arr += arr >> _32\n    arr &= s0F\n    return arr"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & m1) + ((arr >> _2) & m1)\n    arr = (arr + (arr >> _4)) & s33\n    arr += arr >> _8\n    arr += arr >> _16\n    arr += arr >> _32\n    arr &= np.uint64(0x7F)\n    return arr"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & m1) + ((arr >> _2) & m1)\n    arr = (arr + (arr >> _4)) & s0F\n    arr += arr >> _8\n    arr += arr >> _16\n    arr += arr >> _32\n    arr &= s01\n    return arr"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & m1) + ((arr >> _2) & m1)\n    arr = (arr + (arr >> _4)) & s33\n    arr = (arr + (arr >> _8)) & s0F\n    arr = (arr * s01) >> all_but_one_bit\n    return arr"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & m1) + ((arr >> _2) & m1)\n    arr = (arr + (arr >> _4)) & s33\n    arr += arr >> _8\n    arr += arr >> _16\n    arr += arr >> _32\n    arr &= mask\n    return arr"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & s33) + ((arr >> _2) & s33)\n    arr = (arr + (arr >> _4)) & s0F\n    arr *= s01\n    arr >>= all_but_one_bit\n    return arr"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & m1) + ((arr >> _2) & m1)\n    arr = (arr + (arr >> _4)) & s0F\n    arr += arr >> _8\n    arr += arr >> _16\n    arr += arr >> _32\n    return arr & s01"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & m1) + ((arr >> _2) & m1)\n    arr = (arr + (arr >> _4)) & s0F\n    arr += arr >> _8\n    arr += arr >> _16\n    arr += arr >> _32\n    arr = arr & s01\n    return arr"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & m1) + ((arr >> _2) & m1)\n    arr = (arr + (arr >> _4)) & s33\n    arr += arr >> _8\n    arr += arr >> _16\n    arr += arr >> _32\n    return np.uint64(arr & mask)"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr = arr - ((arr >> _1) & s55)\n    arr = (arr & m1) + ((arr >> _2) & m1)\n    arr = (arr + (arr >> _4)) & s0F\n    arr = (arr * s01) >> all_but_one_bit\n    return arr"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & m1) + ((arr >> _2) & m1)\n    arr = (arr + (arr >> _4)) & s33\n    arr += arr >> _8\n    arr += arr >> _16\n    arr += arr >> _32\n    arr &= mask\n    return arr"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & s33) + ((arr >> _2) & s33)\n    arr = (arr + (arr >> _4)) & s0F\n    arr *= s01\n    arr >>= all_but_one_bit\n    return arr"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & m1) + ((arr >> _2) & m1)\n    arr = (arr + (arr >> _4)) & s33\n    arr += arr >> _8\n    arr += arr >> _16\n    arr += arr >> _32\n    arr &= mask\n    return arr"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & m1) + ((arr >> _2) & m1)\n    arr = (arr + (arr >> _4)) & s33\n    arr += arr >> _8\n    arr += arr >> _16\n    arr += arr >> _32\n    return arr & np.uint64(0x7F)"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr = arr - ((arr >> _1) & s55)\n    arr = (arr & m1) + ((arr >> _2) & m1)\n    arr = (arr + (arr >> _4)) & s33\n    arr = (arr + (arr >> _8)) & s0F\n    arr = (arr * s01) >> all_but_one_bit\n    return arr"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "\n    arr = arr - ((arr >> _1) & s55)\n    arr = (arr & s33) + ((arr >> _2) & s33)\n    arr = (arr + (arr >> _4)) & s0F\n    arr = (arr * s01) >> all_but_one_bit\n\n    return arr"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & m1) + ((arr >> _2) & m1)\n    arr = (arr + (arr >> _4)) & s33\n    arr += arr >> _8\n    arr &= s0F\n    arr *= s01\n    arr >>= all_but_one_bit\n    return arr"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "\n    arr -= (arr >> _1) & s55\n    arr = (arr & s33) + ((arr >> _2) & s33)\n    arr = (arr + (arr >> _4)) & s0F\n    arr *= s01\n    arr = (arr >> all_but_one_bit) + (arr & all_but_one_bit)\n    return arr"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "\n    arr = np.uint64(arr)\n\n    arr = arr - ((arr >> _1) & s55)\n    arr = (arr & s33) + ((arr >> _2) & s33)\n    arr = (arr + (arr >> _4)) & s0F\n    arr = (arr * s01) >> all_but_one_bit\n\n    return arr"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "\n    arr = np.uint64(arr)\n\n    arr = arr - ((arr >> _1) & s55)\n    arr = (arr & s33) + ((arr >> _2) & s33)\n    arr = (arr + (arr >> _4)) & s0F\n    arr = (arr * s01) >> all_but_one_bit\n\n    return arr"}
{"namespace": "searcharray.solr.edismax", "completion": "\n    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    if pf is None:\n        pf = []\n    if pf2 is None:\n        pf2 = []\n    if pf3 is None:\n        pf3 = []\n\n    query_fields = parse_field_boosts(qf)\n    phrase_fields = parse_field_boosts(pf)\n    bigram_fields = parse_field_boosts(pf2)\n    trigram_fields = parse_field_boosts(pf3)\n\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "\n    if pf is None:\n        pf = []\n    if pf2 is None:\n        pf2 = []\n    if pf3 is None:\n        pf3 = []\n\n    query_fields = parse_field_boosts(qf)\n    phrase_fields = parse_field_boosts(pf)\n    bigram_fields = parse_field_boosts(pf2)\n    trigram_fields = parse_field_boosts(pf3)\n\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    if phrase_fields:\n        # Process phrase fields\n        for field, boost in phrase_fields.items():\n            post_arr = get_field(frame, field)\n            phrase_score = post_arr.phrase_score(q, similarity=similarity) * (1 if boost is None else boost)\n            boost_exp = f\"{boost}\" if boost is not None else \"1\"\n            explain += f\" | {field}:\\\"{q}\\\"^{boost_exp}\"\n            qf_scores += phrase_score\n\n    if bigram_fields:\n        # Process bigram fields\n        for field, boost in bigram_fields.items():\n            post_arr = get_field(frame, field)\n            bigram_score = post_arr.bigram_score(q, similarity=similarity) * (1 if boost is None else boost)\n            boost_exp = f\"{boost}\" if boost is not None else \"1\"\n            explain += f\" | {field}:\\\"{q}\\\"^{boost_exp}\"\n            qf_scores += bigram_score\n\n    if trigram_fields:\n        # Process trigram fields\n        for field, boost in trigram_fields.items():\n            post_arr = get_field(frame, field)\n            trigram_score = post_arr.trigram_score(q, similarity=similarity) * (1 if boost is None else boost)\n            boost_exp = f\"{boost}\" if boost is not None else \"1\"\n            explain += f\" | {field}:\\\"{q}\\\"^{boost_exp}\"\n            qf_scores += trigram_score\n\n    return qf_scores, explain"}
{"namespace": "searcharray.solr.edismax", "completion": "    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "\n    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "\n    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    # Parse query terms\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    # If phrase, bigram, and trigram fields are provided, add them to the query fields\n    if pf:\n        qf.extend(pf)\n    if pf2:\n        qf.extend(pf2)\n    if pf3:\n        qf.extend(pf3)\n\n    query_fields = parse_field_boosts(qf)\n\n    # Perform term-centric or field-centric search based on the type of query\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "\n    if q_op not in [\"OR\", \"AND\"]:\n        raise ValueError(\"Invalid q_op value. It must be either 'OR' or 'AND'.\")\n\n    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)"}
{"namespace": "searcharray.solr.edismax", "completion": "    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        return _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        return _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            with self.lock:\n                connection = self.get_or_create_connection(process)\n                message.data = connection.c2s(message.data)\n        elif isinstance(message, RecvMessage):\n            with self.lock:\n                connection = self.get_or_create_connection(process)\n                message.data = connection.s2c(message.data)\n        elif isinstance(message, CloseMessage):\n            with self.lock:\n                self.close_connection(process)"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "\n        if isinstance(message, SendMessage):\n            with self.lock:\n                connection = self.connections.get(message.connection_id)\n                if connection:\n                    message.data = connection.c2s(message.data)\n\n        elif isinstance(message, RecvMessage):\n            with self.lock:\n                connection = self.connections.get(message.connection_id)\n                if connection:\n                    message.data = connection.s2c(message.data)\n\n        elif isinstance(message, CloseMessage):\n            with self.lock:\n                connection = self.connections.pop(message.connection_id, None)\n                if connection and self.config['autoCloseConnections']:\n                    connection.close()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            with self.lock:\n                connection = self.connections.get(process.id)\n                if connection:\n                    message.data = connection.c2s(message.data)\n\n        elif isinstance(message, RecvMessage):\n            with self.lock:\n                connection = self.connections.get(process.id)\n                if connection:\n                    message.data = connection.s2c(message.data)\n\n        elif isinstance(message, CloseMessage):\n            with self.lock:\n                connection = self.connections.get(process.id)\n                if connection:\n                    connection.close()\n                    if self.config['autoCloseConnections']:\n                        del self.connections[process.id]"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "\n        if isinstance(message, SendMessage):\n            with self.lock:\n                connection = self.get_connection(process)\n                if connection:\n                    message.data = connection.c2s(message.data)\n\n        elif isinstance(message, RecvMessage):\n            with self.lock:\n                connection = self.get_connection(process)\n                if connection:\n                    message.data = connection.s2c(message.data)\n\n        elif isinstance(message, CloseMessage):\n            with self.lock:\n                connection = self.get_connection(process)\n                if connection:\n                    connection.close()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "\n        if isinstance(message, SendMessage):\n            # Transform the message data using the connection's c2s method\n            with self.lock:\n                connection = self.connections.get(process.pid)\n                if connection:\n                    message.data = connection.c2s(message.data)\n\n        elif isinstance(message, RecvMessage):\n            # Use the s2c method of the connection\n            with self.lock:\n                connection = self.connections.get(process.pid)\n                if connection:\n                    message.data = connection.s2c(message.data)\n\n        elif isinstance(message, CloseMessage):\n            # Handle the connection closure without modifying the message data directly\n            with self.lock:\n                connection = self.connections.pop(process.pid, None)\n                if connection:\n                    connection.close()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "\n        if isinstance(message, SendMessage):\n            with self.lock:\n                connection = self._get_connection(process)\n                if connection:\n                    message.data = connection.c2s(message.data)\n\n        elif isinstance(message, RecvMessage):\n            with self.lock:\n                connection = self._get_connection(process)\n                if connection:\n                    message.data = connection.s2c(message.data)\n\n        elif isinstance(message, CloseMessage):\n            with self.lock:\n                self._close_connection(process)"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "\n        if message.type == MessageType.SEND:\n            self.lock.acquire()\n            connection = self.get_connection(process)\n            self.lock.release()\n\n            if connection:\n                connection.c2s(message.data)\n\n        elif message.type == MessageType.RECV:\n            self.lock.acquire()\n            connection = self.get_connection(process)\n            self.lock.release()\n\n            if connection:\n                connection.s2c(message.data)\n\n        elif message.type == MessageType.CLOSE:\n            self.lock.acquire()\n            connection = self.get_connection(process)\n            self.lock.release()\n\n            if connection:\n                connection.close()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            # Transform the message data using the connection's c2s method\n            with self.lock:\n                connection = self.connections.get(process.pid)\n                if connection:\n                    message.data = connection.c2s(message.data)\n        elif isinstance(message, RecvMessage):\n            # Use the s2c method of the connection to modify the message data\n            with self.lock:\n                connection = self.connections.get(process.pid)\n                if connection:\n                    message.data = connection.s2c(message.data)\n        elif isinstance(message, CloseMessage):\n            # Handle the connection closure without modifying the message data directly\n            with self.lock:\n                connection = self.connections.pop(process.pid, None)\n                if connection and self.config['autoCloseConnections']:\n                    connection.close()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            with self.lock:\n                connection = self.connections.get(process.id)\n                if connection:\n                    message.data = connection.c2s(message.data)\n\n        elif isinstance(message, RecvMessage):\n            with self.lock:\n                connection = self.connections.get(process.id)\n                if connection:\n                    message.data = connection.s2c(message.data)\n\n        elif isinstance(message, CloseMessage):\n            with self.lock:\n                connection = self.connections.pop(process.id, None)\n                if connection:\n                    connection.close()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "\n        if isinstance(message, SendMessage):\n            with self.lock:\n                connection = self.get_or_create_connection(process)\n                connection.c2s(message.data)\n        elif isinstance(message, RecvMessage):\n            with self.lock:\n                connection = self.get_or_create_connection(process)\n                connection.s2c(message.data)\n        elif isinstance(message, CloseMessage):\n            with self.lock:\n                connection = self.get_or_create_connection(process)\n                connection.close()\n                if self.config['autoCloseConnections']:\n                    self.remove_connection(process)"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            with self.lock:\n                connection = self.connections.get(process.pid)\n                if connection:\n                    message.data = connection.c2s(message.data)\n        elif isinstance(message, RecvMessage):\n            with self.lock:\n                connection = self.connections.get(process.pid)\n                if connection:\n                    message.data = connection.s2c(message.data)\n        elif isinstance(message, CloseMessage):\n            with self.lock:\n                connection = self.connections.get(process.pid)\n                if connection:\n                    connection.close()\n                    if self.config['autoCloseConnections']:\n                        del self.connections[process.pid]"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            with self.lock:\n                connection = self.connections.get(process.pid)\n                if connection:\n                    message.data = connection.c2s(message.data)\n        elif isinstance(message, RecvMessage):\n            with self.lock:\n                connection = self.connections.get(process.pid)\n                if connection:\n                    message.data = connection.s2c(message.data)\n        elif isinstance(message, CloseMessage):\n            with self.lock:\n                connection = self.connections.pop(process.pid, None)\n                if connection and self.config['autoCloseConnections']:\n                    connection.close()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "\n        if isinstance(message, SendMessage):\n            # Transform the message data using the connection's c2s method\n            with self.lock:\n                connection = self.connections.get(process.id)\n                if connection:\n                    connection.c2s(message.data)\n\n        elif isinstance(message, RecvMessage):\n            # Use the s2c method to modify the message data\n            with self.lock:\n                connection = self.connections.get(process.id)\n                if connection:\n                    message.data = connection.s2c(message.data)\n\n        elif isinstance(message, CloseMessage):\n            # Handle the connection closure without modifying the message data directly\n            with self.lock:\n                connection = self.connections.pop(process.id, None)\n                if connection and self.config['autoCloseConnections']:\n                    connection.close()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "\n        if isinstance(message, SendMessage):\n            with self.lock:\n                connection = self.connections.get(process.pid)\n                if connection:\n                    message.data = connection.c2s(message.data)\n\n        elif isinstance(message, RecvMessage):\n            with self.lock:\n                connection = self.connections.get(process.pid)\n                if connection:\n                    message.data = connection.s2c(message.data)\n\n        elif isinstance(message, CloseMessage):\n            with self.lock:\n                if self.config['autoCloseConnections']:\n                    connection = self.connections.pop(process.pid, None)\n                    if connection:\n                        connection.close()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            with self.lock:\n                connection = self.get_connection(process)\n                if connection:\n                    message.data = connection.c2s(message.data)\n\n        elif isinstance(message, RecvMessage):\n            with self.lock:\n                connection = self.get_connection(process)\n                if connection:\n                    message.data = connection.s2c(message.data)\n\n        elif isinstance(message, CloseMessage):\n            with self.lock:\n                connection = self.get_connection(process)\n                if connection:\n                    connection.close()\n                    if self.config['autoCloseConnections']:\n                        del self.connections[process.pid]"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            with self.lock:\n                connection = self.get_connection(process)\n                if connection:\n                    message.data = connection.c2s(message.data)\n        elif isinstance(message, RecvMessage):\n            with self.lock:\n                connection = self.get_connection(process)\n                if connection:\n                    message.data = connection.s2c(message.data)\n        elif isinstance(message, CloseMessage):\n            with self.lock:\n                connection = self.get_connection(process)\n                if connection:\n                    connection.close()\n                    if self.config['autoCloseConnections']:\n                        self.remove_connection(process)"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            with self.lock:\n                connection = self.connections.get(process.id)\n                if connection:\n                    message.data = connection.c2s(message.data)\n        elif isinstance(message, RecvMessage):\n            with self.lock:\n                connection = self.connections.get(process.id)\n                if connection:\n                    message.data = connection.s2c(message.data)\n        elif isinstance(message, CloseMessage):\n            with self.lock:\n                connection = self.connections.pop(process.id, None)\n                if connection and self.config['autoCloseConnections']:\n                    connection.close()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "\n        if isinstance(message, SendMessage):\n            # Transform the message data using the connection's c2s method\n            with self.lock:\n                connection = self.connections.get(process.id)\n                if connection:\n                    message.data = connection.c2s(message.data)\n\n        elif isinstance(message, RecvMessage):\n            # Use the s2c method of the connection to modify the message data\n            with self.lock:\n                connection = self.connections.get(process.id)\n                if connection:\n                    message.data = connection.s2c(message.data)\n\n        elif isinstance(message, CloseMessage):\n            # Handle the connection closure without modifying the message data directly\n            with self.lock:\n                connection = self.connections.pop(process.id, None)\n                if connection:\n                    connection.close()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            # Transform the message data using the connection's c2s method\n            with self.lock:\n                connection = self.connections.get(process.id)\n                if connection:\n                    message.data = connection.c2s(message.data)\n        elif isinstance(message, RecvMessage):\n            # Use the s2c method to modify the message data\n            with self.lock:\n                connection = self.connections.get(process.id)\n                if connection:\n                    message.data = connection.s2c(message.data)\n        elif isinstance(message, CloseMessage):\n            # Handle the connection closure without modifying the message data directly\n            with self.lock:\n                connection = self.connections.pop(process.id, None)\n                if connection and self.config['autoCloseConnections']:\n                    connection.close()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            with self.lock:\n                connection = self.get_connection(process)\n                if connection:\n                    message.data = connection.c2s(message.data)\n        elif isinstance(message, RecvMessage):\n            with self.lock:\n                connection = self.get_connection(process)\n                if connection:\n                    message.data = connection.s2c(message.data)\n        elif isinstance(message, CloseMessage):\n            with self.lock:\n                connection = self.get_connection(process)\n                if connection:\n                    connection.close()\n                    if self.config['autoCloseConnections']:\n                        self.connections.pop(connection.id, None)"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection_id, connection in self.connections.items():\n                connection.close()\n            self.connections.clear()\n        if self.server:\n            self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection_id, connection in self.connections.items():\n                connection.close()\n            self.connections.clear()\n\n        if self.server:\n            self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n            self.connections.clear()\n\n        if self.server:\n            self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n            self.connections.clear()\n        if self.server:\n            self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n            self.connections.clear()\n        if self.server:\n            self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n            self.connections.clear()\n        if self.server:\n            self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n            self.connections.clear()\n\n        if self.server:\n            self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n            self.connections.clear()\n\n        if self.server:\n            self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n            self.connections.clear()\n\n        if self.server:\n            self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n            self.connections.clear()\n\n        if self.server:\n            self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n            self.connections.clear()\n        if self.server:\n            self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n            self.connections.clear()\n        if self.server:\n            self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection_id, connection in list(self.connections.items()):\n                connection.close()\n                del self.connections[connection_id]\n            \n        if self.server:\n            self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection_id, connection in self.connections.items():\n                connection.close()\n            self.connections.clear()\n        if self.server:\n            self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for conn_id, conn in self.connections.items():\n                conn.close()\n            self.connections.clear()\n\n        if self.server:\n            self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n            self.connections.clear()\n        if self.server:\n            self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection_id, connection in self.connections.items():\n                connection.close()\n            self.connections.clear()\n        if self.server:\n            self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n            self.connections.clear()\n        if self.server:\n            self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n            self.connections.clear()\n        if self.server:\n            self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n            self.connections.clear()\n\n        if self.server:\n            self.server.stop()"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert_is_square(cov)\n    std_dev = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std_dev, std_dev)\n    return corr, std_dev"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "\n    # Calculate the standard deviations for each variable\n    std_dev = np.sqrt(np.diag(cov))\n\n    # Calculate the correlation matrix\n    corr = cov / np.outer(std_dev, std_dev)\n\n    return corr, std_dev"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "\n    assert_is_symmetric(cov)\n    std_dev = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std_dev, std_dev)\n    return corr, std_dev"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    std_dev = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std_dev, std_dev)\n    return corr, std_dev"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # Ensure input is a 2D array\n    assert_is_square(cov)\n    assert_is_symmetric(cov)\n\n    # Calculate standard deviations\n    std_dev = np.sqrt(np.diag(cov))\n\n    # Calculate correlation matrix\n    corr = np.divide(cov, np.outer(std_dev, std_dev))\n\n    return corr, std_dev"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    std_dev = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std_dev, std_dev)\n    return corr, std_dev"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    # Ensure the input is a 2D array\n    assert_is_square(cov)\n    assert_is_symmetric(cov)\n\n    # Calculate the standard deviation for each variable\n    std_dev = np.sqrt(np.diag(cov))\n\n    # Calculate the correlation matrix\n    corr = np.divide(cov, np.outer(std_dev, std_dev))\n\n    return corr, std_dev"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert_is_symmetric(cov)\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    return corr, std"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    std_dev = np.sqrt(np.diag(cov))  # Calculate the standard deviation for each variable\n    corr = cov / np.outer(std_dev, std_dev)  # Calculate the correlation matrix\n    return corr, std_dev"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert_is_square(cov)\n    std_dev = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std_dev, std_dev)\n    return corr, std_dev"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "\n    # Ensure input is a 2D array\n    assert_is_square(cov)\n    assert_is_symmetric(cov)\n\n    # Calculate standard deviations\n    std_dev = np.sqrt(np.diag(cov))\n\n    # Calculate correlation matrix\n    corr = np.divide(cov, np.outer(std_dev, std_dev))\n\n    return corr, std_dev"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert_is_square(cov)\n    std_devs = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std_devs, std_devs)\n    return corr, std_devs"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert_is_square(cov)\n    std_dev = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std_dev, std_dev)\n    return corr, std_dev"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert_is_square(cov)\n    std_dev = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std_dev, std_dev)\n    return corr, std_dev"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert_is_square(cov)\n    std_dev = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std_dev, std_dev)\n    return corr, std_dev"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    std_dev = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std_dev, std_dev)\n    return corr, std_dev"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert_is_symmetric(cov)\n    std_dev = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std_dev, std_dev)\n    return corr, std_dev"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    std_dev = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std_dev, std_dev)\n    return corr, std_dev"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    std_dev = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std_dev, std_dev)\n    return corr, std_dev"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert_is_symmetric(cov)\n    std_dev = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std_dev, std_dev)\n    return corr, std_dev"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_symmetric(x)\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The matrix must be a distance matrix\")"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.all(np.diagonal(x) == 0):\n        raise ValueError(\"The matrix diagonal elements must be close to zero\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.all(np.diagonal(x) == 0):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    assert_is_symmetric(x)\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The matrix must be a distance matrix\")"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.all(np.diagonal(x) == 0):\n        raise ValueError(\"The diagonal elements of the matrix must be zero for it to be a distance matrix\")\n    assert_is_symmetric(x)"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The matrix diagonal elements must be close to zero\")\n    assert_is_symmetric(x)"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.all(np.diagonal(x) == 0):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.all(np.diagonal(x) == 0):\n        raise ValueError(\"The diagonal elements of the matrix must be zero\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "\n    assert_is_square(x)\n\n    if not np.all(np.diagonal(x) == 0):\n        raise ValueError(\"The matrix must have zeros on its diagonal\")\n\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_symmetric(x)\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The matrix must be a distance matrix\")"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.all(np.isclose(np.diag(x), 0)):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n    assert_is_symmetric(x)"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.all(np.isclose(np.diag(x), 0)):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n    assert_is_symmetric(x)"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_symmetric(x)\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The matrix must be a distance matrix\")"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The matrix diagonal elements must be close to zero\")\n    assert_is_symmetric(x)"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_symmetric(x)\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The matrix must be a distance matrix\")"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_symmetric(x)\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The matrix must be a distance matrix\")"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.all(np.diagonal(x) == 0):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.all(np.diagonal(x) == 0):\n        raise ValueError(\"The matrix diagonal elements must be zero\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The matrix diagonal elements must be close to zero\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The matrix must have zero diagonal elements\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "    initialized = False\n    if func_hash in self.initialized_functions:\n        initialized = True\n\n    # Determine the token count for the prompt\n    token_count = approximate_token_count(args, kwargs)\n\n    # Check if the function is suitable for distillation\n    suitable_for_distillation = function_description.suitable_for_distillation\n\n    # Decide whether to use a distilled model or a teacher model based on suitability for distillation and token count requirements\n    if suitable_for_distillation and token_count <= self.default_generation_length:\n        model = self.function_modeler.get_distilled_model(function_description)\n        prompt = self.function_modeler.construct_zero_shot_prompt(args, kwargs, function_description)\n        is_distilled_model = True\n    else:\n        model = self.function_modeler.get_teacher_model(function_description)\n        prompt = self.function_modeler.construct_fine_tuning_prompt(args, kwargs, function_description)\n        is_distilled_model = False\n\n    return prompt, model, suitable_for_distillation, initialized"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Check if the function is already initialized and does not require saving examples for fine-tuning\n        if func_hash in self.initialized_functions:\n            initialized = True\n        else:\n            initialized = False\n\n        # Get the token count for the current function\n        token_count = approximate_token_count(args, kwargs, function_description, llm_parameters)\n        self.token_counts[func_hash] = token_count\n\n        # Determine if the model is suitable for distillation based on token count requirements\n        if token_count <= function_description.distillation_token_limit:\n            suitable_for_distillation = True\n        else:\n            suitable_for_distillation = False\n\n        # Get the appropriate language model based on suitability for distillation\n        if suitable_for_distillation:\n            model = self.function_modeler.get_distilled_model(function_description)\n        else:\n            model = self.function_modeler.get_teacher_model(function_description)\n\n        # Construct the prompt to be used for generation\n        prompt = self.function_modeler.construct_prompt(args, kwargs, function_description, token_count, llm_parameters)\n\n        return prompt, model, suitable_for_distillation, initialized"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        token_count = approximate_token_count(args, kwargs)\n        if func_hash not in self.initialized_functions:\n            self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": []}\n\n        if func_hash not in self.token_counts:\n            self.token_counts[func_hash] = token_count\n        else:\n            if token_count > self.token_counts[func_hash]:\n                self.token_counts[func_hash] = token_count\n\n        model, suitable_for_finetuning = self.function_modeler.get_model_for_function(function_description, token_count)\n\n        if suitable_for_finetuning:\n            prompt = self.function_modeler.construct_prompt(function_description, args, kwargs)\n            is_distilled_model = False\n        else:\n            prompt = function_description.name\n            is_distilled_model = True\n\n        return prompt, model, suitable_for_finetuning, is_distilled_model"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        initialized = func_hash in self.initialized_functions\n\n        # check if the function has examples for fine-tuning\n        has_examples = initialized and len(self.initialized_functions[func_hash][\"examples\"]) > 0\n\n        # check if the function is suitable for distillation\n        suitable_for_distillation = function_description.suitable_for_distillation\n\n        # check the token count for the prompt\n        token_count = approximate_token_count(function_description, args, kwargs)\n\n        # decide whether to use a distilled model or a teacher model\n        if suitable_for_distillation and token_count <= self.default_generation_length:\n            model = function_description.distilled_model\n            save_to_finetune = False\n        else:\n            model = function_description.teacher_model\n            save_to_finetune = True\n\n        # initialize function-specific data if not already done\n        if not initialized:\n            self.initialized_functions[func_hash] = {\"model\": model.model_name, \"examples\": []}\n\n        # update examples for fine-tuning if necessary\n        if not has_examples and save_to_finetune:\n            self.initialized_functions[func_hash][\"examples\"].append((args, kwargs))\n\n        # construct the prompt to be used for generation\n        prompt = self.function_modeler.construct_prompt(args, kwargs, function_description)\n\n        return prompt, model, suitable_for_distillation, initialized"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Check if the function is already initialized\n        if func_hash in self.initialized_functions:\n            initialized = True\n        else:\n            initialized = False\n\n        # Get the token count for the function arguments\n        token_count = approximate_token_count(args, kwargs)\n\n        # Check if the token count exceeds the limit for distillation\n        if token_count > BaseModelConfig.distillation_token_limit:\n            suitable_for_distillation = False\n            model = self.function_modeler.get_teacher_model(function_description)\n        else:\n            suitable_for_distillation = True\n            model = self.function_modeler.get_distilled_model(function_description)\n\n        # Construct the prompt for generation\n        prompt = self.function_modeler.construct_prompt(args, kwargs, function_description)\n\n        return prompt, model, suitable_for_distillation, initialized"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "\n        # Determine the appropriate language model and prompt based on the function description and its arguments\n        # ...\n        # Initialize function-specific data if not already done\n        # ...\n        # Update examples for fine-tuning if necessary\n        # ...\n        # Construct the prompt to be used for generation\n        # ...\n\n        # Return the constructed prompt, the selected model, a boolean indicating if the model is suitable for distillation,\n        # and a boolean indicating if the function is already initialized and does not require saving examples for fine-tuning\n        return prompt, model, is_distilled_model, is_initialized"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "\n    # Determine the appropriate language model and prompt based on function description, arguments, and llm parameters\n    # ...\n    # Initialize function-specific data if not already done\n    # ...\n    # Update examples for fine-tuning if necessary\n    # ...\n    # Construct the prompt to be used for generation\n    # ...\n\n    # Return the constructed prompt, the selected model, a boolean indicating if the model is suitable for distillation, and a boolean indicating if the function is already initialized and does not require saving examples for fine-tuning\n    return constructed_prompt, selected_model, is_suitable_for_distillation, is_function_initialized"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        if func_hash not in self.initialized_functions:\n            self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": []}\n\n        # Check if the function is already initialized\n        is_initialized = True if self.initialized_functions[func_hash][\"model\"] else False\n\n        # Get the token count for the arguments and kwargs\n        total_tokens = approximate_token_count(args) + approximate_token_count(kwargs)\n\n        # Determine if the model is suitable for distillation\n        is_distilled_model = function_description.suitable_for_distillation and total_tokens <= 1024\n\n        # Select the appropriate model based on distillation suitability\n        if is_distilled_model:\n            model = self.function_modeler.get_distilled_model(function_description)\n        else:\n            model = self.function_modeler.get_teacher_model(function_description)\n\n        # Construct the prompt based on the function description\n        prompt = function_description.construct_prompt(args, kwargs)\n\n        return prompt, model, is_initialized, is_distilled_model"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        token_count = approximate_token_count(args, kwargs)\n        # Check if the function is already initialized\n        if func_hash in self.initialized_functions:\n            model = self.function_modeler.get_model(function_description)\n            is_distilled_model = False\n            save_to_finetune = False\n        else:\n            model = self.function_modeler.get_model(function_description, token_count)\n            is_distilled_model = model.suitable_for_distillation\n            save_to_finetune = model.suitable_for_finetuning\n            self.initialized_functions[func_hash] = {\"model\": model.model_name, \"examples\": []}\n\n        prompt = self.function_modeler.construct_prompt(args, kwargs, function_description, model, is_distilled_model)\n        return prompt, model, save_to_finetune, is_distilled_model"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # check if the function is already initialized\n        if func_hash in self.initialized_functions:\n            initialized = True\n        else:\n            initialized = False\n\n        # get the function examples for fine-tuning\n        function_examples = self.function_modeler.get_function_examples(function_description.__hash__())\n\n        # check if the model is suitable for distillation\n        is_distilled_model = function_description.suitable_for_distillation\n\n        # calculate the token count for the prompt\n        prompt_token_count = approximate_token_count(function_description, args, kwargs)\n\n        # check if the token count exceeds the limit for distillation\n        if prompt_token_count > BaseModelConfig.distillation_token_limit:\n            is_distilled_model = False\n\n        # select the appropriate model based on distillation and initialization status\n        if is_distilled_model and not initialized:\n            model = function_description.distilled_model\n        else:\n            model = function_description.teacher_model\n\n        # construct the prompt\n        prompt = self.api_provider[model.provider].construct_prompt(model, function_description, args, kwargs, function_examples, prompt_token_count)\n\n        return prompt, model, is_distilled_model, initialized"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        token_count = approximate_token_count(args, kwargs)\n        if func_hash not in self.token_counts:\n            self.token_counts[func_hash] = token_count\n        else:\n            self.token_counts[func_hash] = max(self.token_counts[func_hash], token_count)\n\n        if self.token_counts[func_hash] > self.default_generation_length:\n            model = self.function_modeler.get_teacher_model(function_description)\n            is_distilled_model = False\n            save_to_finetune = True\n        else:\n            model = self.function_modeler.get_distilled_model(function_description)\n            is_distilled_model = True\n            save_to_finetune = False\n\n        if func_hash not in self.initialized_functions:\n            self.initialized_functions[func_hash] = {\n                \"model\": \"\",\n                \"examples\": [],\n            }\n\n        prompt = self.function_modeler.construct_prompt(args, kwargs, function_description)\n        return prompt, model, save_to_finetune, is_distilled_model"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        token_count = approximate_token_count(args, kwargs)\n        if func_hash not in self.initialized_functions:\n            self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": []}\n        if func_hash not in self.token_counts:\n            self.token_counts[func_hash] = 0\n        if token_count > self.default_generation_length:\n            model = self.function_modeler.get_teacher_model(function_description)\n            save_to_finetune = True\n            is_distilled_model = False\n        else:\n            model = self.function_modeler.get_distilled_model(function_description)\n            save_to_finetune = False\n            is_distilled_model = True\n        prompt = self.function_modeler.construct_prompt(args, kwargs, function_description)\n        return prompt, model, save_to_finetune, is_distilled_model"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        token_count = approximate_token_count(args, kwargs)\n        if token_count > function_description.max_tokens_for_distillation:\n            model = self.function_modeler.get_teacher_model(function_description)\n            prompt = self.function_modeler.get_teacher_prompt(args, kwargs, function_description)\n            save_to_finetune = True\n            is_distilled_model = False\n        else:\n            model = self.function_modeler.get_distilled_model(function_description)\n            prompt = self.function_modeler.get_distilled_prompt(args, kwargs, function_description)\n            save_to_finetune = False\n            is_distilled_model = True\n\n        if func_hash not in self.initialized_functions:\n            self.initialized_functions[func_hash] = {\"model\": model.model_name, \"examples\": []}\n\n        return prompt, model, save_to_finetune, is_distilled_model"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Check if the function is already initialized\n        if func_hash in self.initialized_functions:\n            initialized = True\n        else:\n            initialized = False\n\n        # Get the function token count\n        token_count = approximate_token_count(args, kwargs)\n        self.token_counts[func_hash] = token_count\n\n        # Determine the model based on token count and suitability for distillation\n        if token_count <= self.default_generation_length and function_description.suitable_for_distillation:\n            model = self.function_modeler.get_distilled_model(function_description)\n            suitable_for_distillation = True\n        else:\n            model = self.function_modeler.get_teacher_model(function_description)\n            suitable_for_distillation = False\n\n        # Construct the prompt\n        prompt = self.function_modeler.construct_prompt(function_description, args, kwargs)\n\n        return prompt, model, initialized, suitable_for_distillation"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Determine the appropriate language model based on function suitability for distillation and token count requirements\n        model, suitable_for_distillation = self.function_modeler.get_appropriate_model(function_description, llm_parameters)\n\n        # Initialize function-specific data if not already done\n        if func_hash not in self.initialized_functions:\n            self.initialized_functions[func_hash] = {\"model\": model.model_name, \"examples\": []}\n\n        # Update examples for fine-tuning if necessary\n        if model.model_name != self.initialized_functions[func_hash][\"model\"]:\n            self.initialized_functions[func_hash][\"model\"] = model.model_name\n            self.initialized_functions[func_hash][\"examples\"] = []\n\n        # Construct the prompt to be used for generation\n        prompt = self.function_modeler.construct_prompt(args, kwargs, function_description, model, llm_parameters)\n\n        return prompt, model, suitable_for_distillation, func_hash in self.initialized_functions"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Check if the function is already initialized\n        if func_hash in self.initialized_functions:\n            model = self.initialized_functions[func_hash][\"model\"]\n            is_distilled_model = False\n            save_to_finetune = False\n        else:\n            model = function_description.model\n            is_distilled_model = function_description.suitable_for_distillation\n            save_to_finetune = True\n\n        # Construct the prompt based on the function description and arguments\n        prompt = self._construct_prompt(args, kwargs, function_description)\n\n        return prompt, model, save_to_finetune, is_distilled_model"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Check if the function is already initialized and does not require saving examples for fine-tuning\n        initialized = func_hash in self.initialized_functions\n\n        # Check if the function is suitable for distillation based on the function description and llm_parameters\n        suitable_for_distillation = self.function_modeler.suitable_for_distillation(function_description, llm_parameters)\n\n        # Get the token count for the arguments and kwargs\n        token_count = approximate_token_count(args, kwargs)\n\n        # Determine the appropriate model based on the suitability for distillation and token count\n        model = self.function_modeler.get_appropriate_model(function_description, suitable_for_distillation, token_count)\n\n        # Construct the prompt to be used for generation\n        prompt = self.function_modeler.construct_prompt(function_description, args, kwargs)\n\n        return prompt, model, suitable_for_distillation, initialized"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Check if the function is already initialized\n        if func_hash in self.initialized_functions:\n            initialized = True\n        else:\n            initialized = False\n\n        # Get the token count for the function\n        token_count = approximate_token_count(args, kwargs)\n        self.token_counts[func_hash] = token_count\n\n        # Check if the token count exceeds the limit for distillation\n        if token_count <= BaseModelConfig.distillation_token_limit:\n            suitable_for_distillation = True\n            model = function_description.distilled_model\n        else:\n            suitable_for_distillation = False\n            model = function_description.teacher_model\n\n        # Construct the prompt based on the function description\n        prompt = function_description.construct_prompt(args, kwargs)\n\n        return prompt, model, suitable_for_distillation, initialized"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "\n        # Determine the appropriate language model and prompt for the given function description and its arguments\n        # ... (add your code here)\n\n        # Initialize function-specific data if not already done\n        # ... (add your code here)\n\n        # Update examples for fine-tuning if necessary\n        # ... (add your code here)\n\n        # Construct the prompt to be used for generation\n        # ... (add your code here)\n\n        # Return the constructed prompt, the selected model, a boolean indicating if the model is suitable for distillation,\n        # and a boolean indicating if the function is already initialized and does not require saving examples for fine-tuning\n        # ... (add your code here)"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        if func_hash in self.initialized_functions:\n            current_function_setup = self.initialized_functions[func_hash]\n            model = self.function_modeler.get_model(function_description, current_function_setup[\"model\"])\n            save_to_finetune = False\n            is_distilled_model = False\n        else:\n            # Initialize the function\n            model = self.function_modeler.get_model(function_description)\n            self.initialized_functions[func_hash] = {\"model\": model.model_name, \"examples\": []}\n            save_to_finetune = True\n            is_distilled_model = model.suitable_for_distillation\n\n        # Update token counts\n        token_count = approximate_token_count(args, kwargs, function_description)\n        self.token_counts[func_hash] = token_count\n\n        # Construct the prompt\n        prompt = self.function_modeler.construct_prompt(args, kwargs, function_description, model, token_count)\n\n        return prompt, model, save_to_finetune, is_distilled_model"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        return _nearest_corr_higham(cov, higham_max_iteration)\n    else:\n        return _nearest_corr_eigenvalues(cov)"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if not higham:\n        _, s, vh = np.linalg.svd(cov)\n        sclip = np.maximum(s, _CLIPPING_VALUE)\n        cov_nearest = vh.T @ np.diag(sclip) @ vh\n    else:\n        cov_nearest = cov\n        for _ in range(higham_max_iteration):\n            try:\n                np.linalg.cholesky(cov_nearest)\n                break\n            except np.linalg.linalg.LinAlgError:\n                w, v = np.linalg.eigh(cov_nearest)\n                wclip = np.maximum(w, _CLIPPING_VALUE)\n                cov_nearest = v @ np.diag(wclip) @ v.T\n    return cov_nearest"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        return nearest_corr_higham(cov, higham_max_iteration)\n    else:\n        return nearest_corr_eigen(cov)"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        return _nearest_corr_higham(cov, higham_max_iteration)\n    else:\n        return _nearest_corr_eigen(cov)"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        return _nearest_cov_higham(cov, higham_max_iteration)\n    else:\n        return _nearest_cov_eigenvalue(cov)"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        return nearest_corr_higham(cov, max_iteration=higham_max_iteration)\n    else:\n        return nearest_corr_eigen(cov)"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "\n    if not higham:\n        # Clip eigenvalues to ensure positive definiteness\n        eigval, eigvec = np.linalg.eigh(cov)\n        eigval[eigval < _CLIPPING_VALUE] = _CLIPPING_VALUE\n        cov = eigvec @ np.diag(eigval) @ eigvec.T\n    else:\n        # Use Higham & Nick (2002) algorithm\n        cov = sch.nearest_corr(cov, max_iteration=higham_max_iteration)\n\n    return cov"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        if not is_positive_definite(cov):\n            return sch.nearestPD(cov, max_iteration=higham_max_iteration)\n        else:\n            return cov\n    else:\n        corr, std = cov_to_corr(cov)\n        corr = np.clip(corr, -1, 1)\n        return corr_to_cov(corr, std)"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        return _nearest_corr_higham(cov, higham_max_iteration)\n    else:\n        return _nearest_corr_clipping(cov)"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        if not is_positive_definite(cov):\n            return sch.nearestPD(cov, max_iteration=higham_max_iteration)\n        return cov\n    else:\n        if not is_positive_definite(cov):\n            w, v = np.linalg.eigh(cov)\n            w = np.maximum(w, _CLIPPING_VALUE)\n            return (v * w) @ v.T\n        return cov"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    assert_is_symmetric(cov)\n    assert_is_square(cov)\n\n    if higham:\n        return _nearest_corr_higham(cov, higham_max_iteration)\n    else:\n        return _nearest_corr_eigen(cov)"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    assert_is_symmetric(cov)\n    assert_is_square(cov)\n\n    if higham:\n        if not is_positive_definite(cov):\n            n = cov.shape[0]\n            r = np.ones(n) / np.sqrt(n)\n            v = np.linalg.solve(cov, r)\n            p = np.sqrt(np.dot(r, v))\n            z = v / p\n            d = np.diag(cov)\n            d_inv = 1 / d\n            d_inv_sqrt = np.sqrt(d_inv)\n            s = d_inv_sqrt[:, None] * cov * d_inv_sqrt\n            s = (s + s.T) / 2\n            a = (s + _CLIPPING_VALUE * np.eye(n)) / 2\n            for _ in range(higham_max_iteration):\n                a_inv = np.linalg.inv(a)\n                a_inv_half = scs.sqrtm(a_inv)\n                b = np.dot(a_inv_half, np.dot(s, a_inv_half))\n                b_half = scs.sqrtm(b)\n                a_half = np.dot(a_inv_half, np.dot(b_half, a_inv_half))\n                a = (a_half + a_half.T) / 2\n            cov = np.dot(np.dot(d_inv_sqrt[:, None], a), d_inv_sqrt[None, :]) * p\n    else:\n        if not is_cholesky_dec(cov):\n            eig_vals, eig_vecs = np.linalg.eigh(cov)\n            eig_vals = np.maximum(eig_vals, _CLIPPING_VALUE)\n            cov = np.dot(eig_vecs, np.dot(np.diag(eig_vals), eig_vecs.T))\n\n    return cov"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "\n    if higham:\n        if not is_positive_definite(cov):\n            return scs.nearest_corr(cov)\n        else:\n            return cov\n    else:\n        if not is_positive_definite(cov):\n            d, v = np.linalg.eigh(cov)\n            d[d < _CLIPPING_VALUE] = _CLIPPING_VALUE\n            return (v * d) @ v.T\n        else:\n            return cov"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    assert_is_symmetric(cov)\n    assert_is_positive_definite(cov)\n\n    if higham:\n        return nearest_corr_higham(cov, higham_max_iteration)\n    else:\n        return nearest_corr_eigen(cov)"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        return _cov_nearest_higham(cov, higham_max_iteration)\n    else:\n        return _cov_nearest_clip(cov)"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        return _nearest_correlation_higham(cov, max_iter=higham_max_iteration)\n    else:\n        return _nearest_correlation_clipping(cov)"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "\n    if higham:\n        # Use Higham & Nick (2002) algorithm\n        return _nearest_corr_higham(cov, max_iteration=higham_max_iteration)\n    else:\n        # Clip eigenvalues to ensure positive definiteness\n        return _nearest_corr_eigenvalue_clip(cov)"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        return _nearest_higham(cov, higham_max_iteration)\n    else:\n        return _nearest_clipped(cov)"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "\n    if higham:\n        return _cov_nearest_higham(cov, max_iteration=higham_max_iteration)\n    else:\n        return _cov_nearest_eigen(cov)"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        return _nearest_corr_higham(cov, max_iteration=higham_max_iteration)\n    else:\n        return _nearest_corr_eigen(cov)"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for array in x:\n        if len(array) > 1:\n            midpoint = len(array) // 2\n            yield [array[:midpoint], array[midpoint:]]"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for arr in x:\n        if len(arr) > 1:\n            mid = len(arr) // 2\n            yield [arr[:mid], arr[mid:]]"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "\n    for arr in x:\n        if len(arr) > 1:\n            mid = len(arr) // 2\n            yield [arr[:mid], arr[mid:]]"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "\n    for arr in x:\n        if len(arr) > 1:\n            midpoint = len(arr) // 2\n            yield [arr[:midpoint], arr[midpoint:]]"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for arr in x:\n        if len(arr) > 1:\n            mid = len(arr) // 2\n            yield [arr[:mid], arr[mid:]]"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for arr in x:\n        if len(arr) > 1:\n            mid = len(arr) // 2\n            yield [arr[:mid], arr[mid:]]"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for arr in x:\n        if len(arr) > 1:\n            mid = len(arr) // 2\n            yield [arr[:mid], arr[mid:]]"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for arr in x:\n        if len(arr) > 1:\n            mid = len(arr) // 2\n            yield [arr[:mid], arr[mid:]]"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "\n    for arr in x:\n        if len(arr) > 1:\n            mid = len(arr) // 2\n            yield [arr[:mid], arr[mid:]]"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for arr in x:\n        if len(arr) > 1:\n            mid = len(arr) // 2\n            yield [arr[:mid], arr[mid:]]"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "\n    for arr in x:\n        if len(arr) > 1:\n            mid = len(arr) // 2\n            yield [arr[:mid], arr[mid:]]"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for arr in x:\n        if len(arr) > 1:\n            mid = len(arr) // 2\n            yield [arr[:mid], arr[mid:]]"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for arr in x:\n        if len(arr) > 1:\n            mid = len(arr) // 2\n            yield [arr[:mid], arr[mid:]]"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for arr in x:\n        if len(arr) > 1:\n            mid = len(arr) // 2\n            yield [arr[:mid], arr[mid:]]"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for arr in x:\n        if len(arr) > 1:\n            midpoint = len(arr) // 2\n            yield [arr[:midpoint], arr[midpoint:]]"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for arr in x:\n        if len(arr) > 1:\n            mid = len(arr) // 2\n            yield [arr[:mid], arr[mid:]]"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "\n    for arr in x:\n        if len(arr) > 1:\n            mid = len(arr) // 2\n            yield [arr[:mid], arr[mid:]]"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for arr in x:\n        if len(arr) > 1:\n            mid = len(arr) // 2\n            yield [arr[:mid], arr[mid:]]"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for arr in x:\n        if len(arr) > 1:\n            midpoint = len(arr) // 2\n            yield [arr[:midpoint], arr[midpoint:]]"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for arr in x:\n        if len(arr) > 1:\n            midpoint = len(arr) // 2\n            yield [arr[:midpoint], arr[midpoint:]]"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n    if abs(x) >= 1:\n        return f\"{x:.2f}\"\n    if abs(x) >= 0.1:\n        return f\"{x:.3f}\"\n    if abs(x) >= 0.01:\n        return f\"{x:.4f}\"\n    if abs(x) >= 0.001:\n        return f\"{x:.5f}\"\n    return f\"{x:.6f}\""}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n        if abs(x) < 1:\n            return f\"{x:.2f}%\"\n        elif abs(x) < 10:\n            return f\"{x:.1f}%\"\n        else:\n            return f\"{x:.0f}%\"\n    else:\n        if abs(x) < 1:\n            return f\"{x:.4f}\"\n        elif abs(x) < 10:\n            return f\"{x:.3f}\"\n        else:\n            return f\"{x:.2f}\""}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n    if abs(x) >= 1:\n        return f\"{x:.2f}\"\n    elif abs(x) >= 0.01:\n        return f\"{x:.4f}\"\n    else:\n        return f\"{x:.6f}\""}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n    if abs(x) >= 1:\n        return f\"{x:.2f}\"\n    elif abs(x) >= 0.1:\n        return f\"{x:.3f}\"\n    elif abs(x) >= 0.01:\n        return f\"{x:.4f}\"\n    else:\n        return f\"{x:.5f}\""}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n    if abs(x) < 1:\n        return f\"{x:.4f}\"\n    elif abs(x) < 10:\n        return f\"{x:.3f}\"\n    elif abs(x) < 100:\n        return f\"{x:.2f}\"\n    else:\n        return f\"{x:.1f}\""}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n    if abs(x) >= 10 or abs(x) < 0.01:\n        return f\"{x:.2f}\"\n    elif abs(x) >= 1 or abs(x) < 0.1:\n        return f\"{x:.3f}\"\n    else:\n        return f\"{x:.4f}\""}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n    if abs(x) >= 1 or x == 0:\n        return f\"{x:.2f}\"\n    elif abs(x) < 1e-3:\n        return f\"{x:.2e}\"\n    else:\n        return f\"{x:.4f}\""}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n    if abs(x) < 1:\n        return f\"{x:.4g}\"\n    if abs(x) < 10:\n        return f\"{x:.3g}\"\n    if abs(x) < 100:\n        return f\"{x:.2g}\"\n    if abs(x) < 1000:\n        return f\"{x:.1g}\"\n    return f\"{x:.0f}\""}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n    if abs(x) >= 1:\n        return f\"{x:.2f}\"\n    elif abs(x) >= 0.01:\n        return f\"{x:.4f}\"\n    elif abs(x) >= 0.0001:\n        return f\"{x:.6f}\"\n    else:\n        return f\"{x:.8f}\""}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n    if abs(x) >= 1:\n        return f\"{x:.2f}\"\n    if abs(x) >= 0.01:\n        return f\"{x:.4f}\"\n    if abs(x) >= 0.0001:\n        return f\"{x:.6f}\"\n    return f\"{x:.8f}\""}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n    if abs(x) >= 1:\n        return f\"{x:.2f}\"\n    if abs(x) >= 0.01:\n        return f\"{x:.4f}\"\n    if abs(x) >= 0.0001:\n        return f\"{x:.6f}\"\n    return f\"{x:.8f}\""}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "\n    if np.isnan(x):\n        return \"NaN\"\n    elif percent:\n        return f\"{x*100:.2f}%\"\n    else:\n        if abs(x) < 1:\n            return f\"{x:.4f}\"\n        elif abs(x) < 10:\n            return f\"{x:.3f}\"\n        elif abs(x) < 100:\n            return f\"{x:.2f}\"\n        elif abs(x) < 1000:\n            return f\"{x:.1f}\"\n        else:\n            return f\"{x:.0f}\""}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n        if abs(x) < 10:\n            return f\"{x:.2f}%\"\n        elif abs(x) < 100:\n            return f\"{x:.1f}%\"\n        else:\n            return f\"{x:.0f}%\"\n    else:\n        if abs(x) < 0.01:\n            return f\"{x:.4f}\"\n        elif abs(x) < 0.1:\n            return f\"{x:.3f}\"\n        elif abs(x) < 1:\n            return f\"{x:.2f}\"\n        elif abs(x) < 10:\n            return f\"{x:.1f}\"\n        else:\n            return f\"{x:.0f}\""}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n        if abs(x) < 1:\n            return f\"{x:.2f}%\"\n        elif abs(x) < 10:\n            return f\"{x:.1f}%\"\n        else:\n            return f\"{x:.0f}%\"\n    else:\n        if abs(x) < 1:\n            return f\"{x:.4f}\"\n        elif abs(x) < 10:\n            return f\"{x:.3f}\"\n        else:\n            return f\"{x:.2f}\""}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n    if abs(x) >= 1:\n        return f\"{x:.2f}\"\n    elif abs(x) >= 0.01:\n        return f\"{x:.4f}\"\n    elif abs(x) >= 0.0001:\n        return f\"{x:.6f}\"\n    else:\n        return f\"{x:.8f}\""}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n    if abs(x) >= 1 or x == 0:\n        return f\"{x:.2f}\"\n    if abs(x) < 0.001:\n        return f\"{x:.4e}\"\n    return f\"{x:.3f}\""}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n    if abs(x) >= 1 or x == 0:\n        return f\"{x:.2f}\"\n    elif abs(x) < 1:\n        power = -int(np.floor(np.log10(abs(x))))\n        return f\"{x:.{power + 2}f}\""}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "\n    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n        if abs(x) < 1:\n            return f\"{x:.2f}%\"\n        elif abs(x) < 10:\n            return f\"{x:.1f}%\"\n        else:\n            return f\"{x:.0f}%\"\n    else:\n        if abs(x) < 1:\n            return f\"{x:.4f}\"\n        elif abs(x) < 10:\n            return f\"{x:.3f}\"\n        else:\n            return f\"{x:.2f}\""}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n    if abs(x) >= 1:\n        return f\"{x:.2f}\"\n    if abs(x) >= 0.01:\n        return f\"{x:.4f}\"\n    return f\"{x:.6f}\""}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return \"NaN\"\n    if percent:\n        x *= 100\n    if abs(x) < 0.01:\n        return f\"{x:.4f}\"\n    elif abs(x) < 0.1:\n        return f\"{x:.3f}\"\n    elif abs(x) < 1:\n        return f\"{x:.2f}\"\n    elif abs(x) < 10:\n        return f\"{x:.1f}\"\n    else:\n        return f\"{x:.0f}\""}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\"assets_names must be provided when items is a dictionary\")\n        array = np.full((n_assets,), fill_value)\n        for i, asset_name in enumerate(assets_names):\n            if asset_name in items:\n                array[i] = items[asset_name]\n    else:\n        array = np.asarray(items)\n\n    if dim == 2:\n        if array.ndim == 1:\n            array = array[np.newaxis, :]\n        if array.shape[1] != n_assets:\n            raise ValueError(f\"The number of assets in {name} does not match the expected value\")\n    elif dim == 1:\n        if array.ndim != 1:\n            raise ValueError(f\"The dimension of {name} does not match the expected value\")\n\n    return array"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "\n    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\"assets_names must be provided when items is a dictionary\")\n\n        array = np.full(n_assets, fill_value)\n        for i, asset_name in enumerate(assets_names):\n            if asset_name in items:\n                array[i] = items[asset_name]\n    else:\n        array = np.asarray(items)\n\n    if dim == 1:\n        if array.shape != (n_assets,):\n            raise ValueError(f\"The shape of {name} must be ({n_assets},)\")\n    elif dim == 2:\n        if array.shape[1] != n_assets:\n            raise ValueError(f\"The number of assets in {name} must be {n_assets}\")\n    else:\n        raise ValueError(\"dim must be either 1 or 2\")\n\n    return array"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "\n    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\"assets_names must be provided when items is a dictionary\")\n        array = np.array([items.get(asset, fill_value) for asset in assets_names])\n    else:\n        array = np.asarray(items)\n\n    if dim == 1:\n        if array.shape != (n_assets,):\n            raise ValueError(f\"The shape of {name} is incorrect. Expected shape: {(n_assets,)}, actual shape: {array.shape}\")\n    elif dim == 2:\n        n_groups = len(array)\n        if n_groups != n_assets:\n            raise ValueError(f\"The number of groups in {name} does not match the expected number of assets. Expected: {n_assets}, actual: {n_groups}\")\n        for group in array:\n            if len(group) != n_assets:\n                raise ValueError(f\"The shape of {name} is incorrect. Expected shape: ({n_assets},), actual shape: {group.shape}\")\n    else:\n        raise ValueError(\"Invalid value for dim. It must be either 1 or 2.\")\n\n    return array"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\"assets_names must be provided when items is a dictionary\")\n\n        array = np.full((len(assets_names),), fill_value)\n        for i, asset_name in enumerate(assets_names):\n            if asset_name in items:\n                array[i] = items[asset_name]\n    else:\n        array = np.asarray(items)\n\n    if dim == 1:\n        if array.shape != (n_assets,):\n            raise ValueError(f\"{name} must have shape ({n_assets},) for dim=1\")\n    elif dim == 2:\n        if array.shape != (n_groups, n_assets):\n            raise ValueError(f\"{name} must have shape ({n_groups}, {n_assets}) for dim=2\")\n    else:\n        raise ValueError(\"dim must be either 1 or 2\")\n\n    return array"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\"assets_names must be provided when items is a dictionary\")\n        array = np.full((n_assets,), fill_value)\n        for i, name in enumerate(assets_names):\n            if name in items:\n                array[i] = items[name]\n    else:\n        array = np.asarray(items)\n\n    if dim == 1:\n        if array.ndim != 1 or array.shape[0] != n_assets:\n            raise ValueError(f\"{name} must have shape ({n_assets},) when dim=1\")\n    elif dim == 2:\n        if array.ndim != 2 or array.shape[1] != n_assets:\n            raise ValueError(f\"{name} must have shape (n_groups, {n_assets}) when dim=2\")\n\n    return array"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "\n    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\"assets_names must be provided when items is a dictionary\")\n\n        array = np.full((n_assets,), fill_value)\n        for i, asset_name in enumerate(assets_names):\n            if asset_name in items:\n                array[i] = items[asset_name]\n    else:\n        array = np.asarray(items)\n\n    if dim == 1:\n        if array.shape != (n_assets,):\n            raise ValueError(f\"{name} must be a 1D array with shape (n_assets,)\")\n    elif dim == 2:\n        if array.shape[1] != n_assets:\n            raise ValueError(f\"{name} must be a 2D array with shape (n_groups, n_assets)\")\n\n    return array"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if dim == 1:\n            array = np.array([items.get(asset, fill_value) for asset in assets_names])\n        elif dim == 2:\n            array = np.array([[items.get(asset, fill_value) for asset in assets_names]])\n        else:\n            raise ValueError(\"Invalid value for 'dim'. It should be either 1 or 2.\")\n    else:\n        array = np.array(items)\n\n    if dim == 1 and array.shape != (n_assets,):\n        raise ValueError(f\"The shape of the {name} array should be ({n_assets},)\")\n    elif dim == 2 and array.shape != (1, n_assets):\n        raise ValueError(f\"The shape of the {name} array should be (1, {n_assets})\")\n\n    return array"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\"assets_names must be provided when items is a dictionary\")\n        array = np.full((n_assets,), fill_value)\n        for i, asset_name in enumerate(assets_names):\n            if asset_name in items:\n                array[i] = items[asset_name]\n    else:\n        array = np.asarray(items)\n\n    if dim == 2 and array.ndim == 1:\n        array = array[np.newaxis, :]\n\n    if array.shape != (n_assets,) and array.shape != (1, n_assets):\n        raise ValueError(f\"The shape of {name} is not compatible with the expected shape\")\n\n    return array"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\"assets_names must be provided when items is a dictionary\")\n        array = np.full((n_assets,), fill_value)\n        for i, asset in enumerate(assets_names):\n            if asset in items:\n                array[i] = items[asset]\n    else:\n        array = np.asarray(items)\n\n    if dim == 2:\n        if array.shape[0] != n_assets:\n            raise ValueError(f\"The number of assets in {name} should be {n_assets}\")\n    elif dim == 1:\n        if array.shape != (n_assets,):\n            raise ValueError(f\"The shape of {name} should be ({n_assets},)\")\n    else:\n        raise ValueError(\"dim should be 1 or 2\")\n\n    return array"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "\n    if isinstance(items, dict):\n        # Fill in missing values in the dictionary\n        if assets_names is not None:\n            items = {asset: items.get(asset, fill_value) for asset in assets_names}\n        else:\n            raise ValueError(\"assets_names must be provided when items is a dictionary\")\n\n    # Convert items to numpy array\n    arr = np.array(items)\n\n    # Verify dimensions and shape\n    if dim == 1:\n        if arr.shape != (n_assets,):\n            raise ValueError(f\"The shape of {name} must be ({n_assets},)\")\n    elif dim == 2:\n        n_groups = len(items) if isinstance(items, dict) else 1\n        if arr.shape != (n_groups, n_assets):\n            raise ValueError(f\"The shape of {name} must be ({n_groups}, {n_assets})\")\n\n    return arr"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\"assets_names must be provided when items is a dictionary\")\n        array = np.full((n_assets,), fill_value)\n        for i, asset in enumerate(assets_names):\n            if asset in items:\n                array[i] = items[asset]\n    else:\n        array = np.asarray(items)\n\n    if dim == 2:\n        if array.ndim == 1:\n            array = array[np.newaxis, :]\n\n    if array.shape[-1] != n_assets:\n        raise ValueError(f\"The number of assets in {name} does not match the expected value\")\n\n    if dim == 1 and array.ndim != 1:\n        raise ValueError(f\"The shape of {name} does not match the expected dimension\")\n\n    if dim == 2 and array.ndim != 2:\n        raise ValueError(f\"The shape of {name} does not match the expected dimension\")\n\n    return array"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "\n    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\"assets_names must be provided when items is a dictionary\")\n\n        array = np.full((len(assets_names),), fill_value)\n        for i, asset in enumerate(assets_names):\n            if asset in items:\n                array[i] = items[asset]\n    else:\n        array = np.asarray(items)\n\n    if dim == 1:\n        if array.shape != (n_assets,):\n            raise ValueError(f\"The shape of {name} is {array.shape}, but it should be ({n_assets},)\")\n    elif dim == 2:\n        if array.shape != (n_groups, n_assets):\n            raise ValueError(f\"The shape of {name} is {array.shape}, but it should be ({n_groups}, {n_assets})\")\n\n    return array"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\"assets_names must be provided when items is a dictionary.\")\n        array = np.full((n_assets,), fill_value)\n        for i, asset_name in enumerate(assets_names):\n            if asset_name in items:\n                array[i] = items[asset_name]\n    else:\n        array = np.asarray(items)\n\n    if dim == 2:\n        if array.ndim == 1:\n            array = array[np.newaxis, :]\n        if array.shape[1] != n_assets:\n            raise ValueError(\n                f\"The number of assets in {name} does not match the expected value.\"\n            )\n\n    if dim == 1 and array.shape != (n_assets,):\n        raise ValueError(\n            f\"The shape of {name} does not match the expected shape (n_assets,).\"\n        )\n\n    return array"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "\n    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\"assets_names must be provided when items is a dictionary\")\n\n        array = np.full(n_assets, fill_value)\n        for i, asset_name in enumerate(assets_names):\n            if asset_name in items:\n                array[i] = items[asset_name]\n    else:\n        array = np.asarray(items)\n\n    if dim == 1:\n        if array.shape != (n_assets,):\n            raise ValueError(f\"The shape of {name} is not compatible with dim={dim}\")\n    elif dim == 2:\n        if array.shape[1] != n_assets:\n            raise ValueError(f\"The shape of {name} is not compatible with dim={dim}\")\n    else:\n        raise ValueError(\"dim must be 1 or 2\")\n\n    return array"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\"assets_names must be provided when items is a dictionary\")\n        array = np.full((n_assets,), fill_value)\n        for i, asset_name in enumerate(assets_names):\n            if asset_name in items:\n                array[i] = items[asset_name]\n    else:\n        array = np.asarray(items)\n\n    if dim == 2:\n        if array.ndim == 1:\n            array = array[np.newaxis, :]\n        if array.shape[1] != n_assets:\n            raise ValueError(f\"The number of assets in {name} does not match the expected value\")\n    elif dim == 1:\n        if array.ndim != 1:\n            raise ValueError(f\"The shape of {name} does not match the expected value\")\n\n    return array"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\"assets_names must be provided when items is a dictionary\")\n        array = np.full((len(assets_names),), fill_value)\n        for i, asset_name in enumerate(assets_names):\n            if asset_name in items:\n                array[i] = items[asset_name]\n    else:\n        array = np.asarray(items)\n\n    if dim == 1:\n        if array.shape != (n_assets,):\n            raise ValueError(f\"The shape of {name} is {array.shape}, but {n_assets} is expected\")\n    elif dim == 2:\n        if array.shape != (len(assets_names), n_assets):\n            raise ValueError(\n                f\"The shape of {name} is {array.shape}, but ({len(assets_names)}, {n_assets}) is expected\"\n            )\n    else:\n        raise ValueError(\"dim must be 1 or 2\")\n\n    return array"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is not None:\n            if set(items.keys()) != set(assets_names):\n                raise ValueError(\n                    f\"Keys of '{name}' do not match the asset names: \"\n                    f\"{set(items.keys())} != {set(assets_names)}\"\n                )\n        items = [items.get(asset, fill_value) for asset in assets_names]\n    array = np.asarray(items)\n    if dim == 1:\n        if array.ndim != 1:\n            raise ValueError(\n                f\"'{name}' must be 1-dimensional, got {array.ndim}-dimensional array\"\n            )\n        if array.shape[0] != n_assets:\n            raise ValueError(\n                f\"'{name}' must have {n_assets} elements, got {array.shape[0]}\"\n            )\n    elif dim == 2:\n        if array.ndim != 2:\n            raise ValueError(\n                f\"'{name}' must be 2-dimensional, got {array.ndim}-dimensional array\"\n            )\n        if array.shape[1] != n_assets:\n            raise ValueError(\n                f\"'{name}' must have {n_assets} columns, got {array.shape[1]}\"\n            )\n    else:\n        raise ValueError(f\"Invalid value for 'dim': {dim}. Must be 1 or 2.\")\n    return array"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\"assets_names must be provided when items is a dictionary\")\n\n        array = np.full((len(assets_names),), fill_value)\n        for i, asset_name in enumerate(assets_names):\n            if asset_name in items:\n                array[i] = items[asset_name]\n    else:\n        array = np.asarray(items)\n\n    if dim == 2:\n        if array.ndim == 1:\n            array = array[np.newaxis, :]\n\n    if array.shape[0] != n_assets:\n        raise ValueError(f\"The number of assets in {name} does not match n_assets\")\n\n    return array"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\"assets_names must be provided when items is a dictionary\")\n\n        result = np.full((n_assets,), fill_value)\n        for i, asset_name in enumerate(assets_names):\n            if asset_name in items:\n                result[i] = items[asset_name]\n    else:\n        result = np.asarray(items)\n\n    if dim == 1 and result.shape != (n_assets,):\n        raise ValueError(f\"{name} must have shape ({n_assets},) for dim=1\")\n    elif dim == 2 and result.shape[1] != n_assets:\n        raise ValueError(f\"{name} must have shape (n_groups, {n_assets}) for dim=2\")\n\n    return result"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if dim == 1:\n            array = np.array([items.get(asset, fill_value) for asset in assets_names])\n        elif dim == 2:\n            array = np.array([[items.get(asset, fill_value) for asset in assets_names]])\n        else:\n            raise ValueError(\"Invalid value for 'dim'. It must be 1 or 2.\")\n    else:\n        array = np.array(items)\n\n    if dim == 1 and array.shape != (n_assets,):\n        raise ValueError(f\"The shape of the array for {name} is incorrect. Expected: {(n_assets,)}, Got: {array.shape}\")\n    elif dim == 2 and array.shape != (1, n_assets):\n        raise ValueError(f\"The shape of the array for {name} is incorrect. Expected: {(1, n_assets)}, Got: {array.shape}\")\n\n    return array"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    elif isinstance(data_home, str):\n        data_home = Path(data_home)\n    if not data_home.exists():\n        data_home.mkdir(parents=True)\n    return str(data_home)"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    data_home = Path(data_home).expanduser()\n    if not data_home.exists():\n        data_home.mkdir(parents=True)\n    return str(data_home)"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    data_home = Path(data_home).expanduser()\n    if not data_home.exists():\n        data_home.mkdir(parents=True)\n    return str(data_home)"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get('SKFOLIO_DATA', Path.home() / 'skfolio_data')\n    else:\n        data_home = Path(data_home)\n\n    data_home = Path(data_home).expanduser()\n    if not data_home.exists():\n        data_home.mkdir(parents=True)\n\n    return str(data_home)"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    data_home = Path(data_home).expanduser()\n    \n    if not data_home.exists():\n        data_home.mkdir(parents=True)\n    \n    return str(data_home)"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    else:\n        data_home = Path(data_home)\n\n    if not isinstance(data_home, Path):\n        data_home = Path(data_home)\n\n    data_home = str(data_home.resolve())\n\n    if not os.path.exists(data_home):\n        os.makedirs(data_home)\n\n    return data_home"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    data_home = Path(data_home).expanduser()\n    if not data_home.exists():\n        data_home.mkdir(parents=True)\n    return str(data_home)"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    elif isinstance(data_home, str):\n        data_home = Path(data_home)\n    if not data_home.exists():\n        data_home.mkdir(parents=True, exist_ok=True)\n    return str(data_home)"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    elif isinstance(data_home, str):\n        data_home = Path(data_home)\n    if not data_home.exists():\n        data_home.mkdir(parents=True, exist_ok=True)\n    return str(data_home)"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    elif isinstance(data_home, str):\n        data_home = Path(data_home)\n    if not data_home.exists():\n        data_home.mkdir(parents=True, exist_ok=True)\n    return str(data_home)"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    data_home = Path(data_home).expanduser()\n    if not data_home.exists():\n        data_home.mkdir(parents=True)\n    return str(data_home)"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    else:\n        data_home = Path(data_home)\n\n    if not isinstance(data_home, Path):\n        data_home = Path(data_home)\n\n    data_home = data_home.expanduser()\n\n    if not data_home.exists():\n        data_home.mkdir(parents=True)\n\n    return str(data_home)"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    data_home = Path(data_home).expanduser()\n    if not data_home.exists():\n        data_home.mkdir(parents=True)\n    return str(data_home)"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    elif isinstance(data_home, str):\n        data_home = Path(data_home)\n    if not data_home.exists():\n        data_home.mkdir(parents=True, exist_ok=True)\n    return str(data_home)"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    elif isinstance(data_home, str):\n        data_home = Path(data_home)\n    if not data_home.exists():\n        data_home.mkdir(parents=True, exist_ok=True)\n    return str(data_home)"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    elif isinstance(data_home, str):\n        data_home = Path(data_home)\n    if not data_home.exists():\n        data_home.mkdir(parents=True, exist_ok=True)\n    return str(data_home)"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    data_home = Path(data_home).expanduser()\n    \n    if not data_home.exists():\n        data_home.mkdir(parents=True)\n\n    return str(data_home)"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    data_home = Path(data_home).expanduser()\n    if not data_home.exists():\n        data_home.mkdir(parents=True)\n    return str(data_home)"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get('SKFOLIO_DATA', Path.home() / 'skfolio_data')\n    data_home = Path(data_home).expanduser()\n    if not data_home.exists():\n        data_home.mkdir(parents=True)\n    return str(data_home)"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", Path.home() / \"skfolio_data\")\n    elif isinstance(data_home, str):\n        data_home = Path(data_home)\n    if not data_home.exists():\n        data_home.mkdir(parents=True, exist_ok=True)\n    return str(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    if os.path.exists(data_home):\n        shutil.rmtree(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    if os.path.exists(data_home):\n        shutil.rmtree(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n    os.makedirs(data_home, exist_ok=True)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    if data_home is None:\n        data_home = get_data_home()\n\n    if os.path.exists(data_home):\n        shutil.rmtree(data_home)\n        os.makedirs(data_home, exist_ok=True)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n    os.makedirs(data_home, exist_ok=True)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n    os.makedirs(data_home, exist_ok=True)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    for filename in os.listdir(data_home):\n        file_path = os.path.join(data_home, filename)\n        try:\n            if os.path.isfile(file_path) or os.path.islink(file_path):\n                os.unlink(file_path)\n            elif os.path.isdir(file_path):\n                shutil.rmtree(file_path)\n        except Exception as e:\n            print(f\"Failed to delete {file_path}. Reason: {e}\")"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    if os.path.exists(data_home):\n        shutil.rmtree(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n    os.makedirs(data_home, exist_ok=True)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n    os.makedirs(data_home, exist_ok=True)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home, ignore_errors=True)\n    os.makedirs(data_home, exist_ok=True)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n    os.makedirs(data_home, exist_ok=True)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    if os.path.exists(data_home):\n        shutil.rmtree(data_home)\n        os.makedirs(data_home, exist_ok=True)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n    os.makedirs(data_home, exist_ok=True)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    if os.path.exists(data_home):\n        shutil.rmtree(data_home)\n    os.makedirs(data_home, exist_ok=True)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n    os.makedirs(data_home, exist_ok=True)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    if data_home is None:\n        data_home = get_data_home()\n    else:\n        data_home = str(data_home)\n\n    if os.path.exists(data_home):\n        shutil.rmtree(data_home)\n    os.makedirs(data_home, exist_ok=True)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n    os.makedirs(data_home, exist_ok=True)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    if data_home is None:\n        data_home = get_data_home()\n    if os.path.exists(data_home):\n        shutil.rmtree(data_home)\n    os.makedirs(data_home, exist_ok=True)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)\n    os.makedirs(data_home, exist_ok=True)"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes, int, float, bool)):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    elif isinstance(obj, collections.abc.Mapping):\n        keys = sorted(obj.keys())\n        values = [obj[k] for k in keys]\n        ret, schema = ListSchema.flatten(values)\n        return ret, DictSchema(schema.schemas, schema.sizes, keys)\n    elif isinstance(obj, Instances):\n        ret, schema = InstancesSchema.flatten(obj)\n        return ret, schema\n    elif isinstance(obj, (Boxes, ROIMasks)):\n        ret, schema = TensorWrapSchema.flatten(obj)\n        return ret, schema\n    else:\n        raise ValueError(f\"Unsupported type {type(obj)} for flattening\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes)):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    elif isinstance(obj, collections.abc.Mapping):\n        keys = sorted(obj.keys())\n        values = [obj[k] for k in keys]\n        ret, schema = ListSchema.flatten(values)\n        return ret, DictSchema(schema.schemas, schema.sizes, keys)\n    elif isinstance(obj, Instances):\n        ret, schema = InstancesSchema.flatten(obj)\n        return ret, schema\n    elif isinstance(obj, Boxes):\n        ret, schema = TensorWrapSchema.flatten(obj)\n        return ret, schema\n    elif isinstance(obj, ROIMasks):\n        ret, schema = TensorWrapSchema.flatten(obj)\n        return ret, schema\n    else:\n        raise NotImplementedError(\"Flattening for this type is not implemented.\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes, int, float, bool)):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    elif isinstance(obj, collections.abc.Mapping):\n        keys = list(obj.keys())\n        values = [obj[k] for k in keys]\n        res, schema = ListSchema.flatten(values)\n        return res, DictSchema(schema.schemas, schema.sizes, keys)\n    elif isinstance(obj, Instances):\n        res, schema = InstancesSchema.flatten(obj)\n        return res, schema\n    elif isinstance(obj, (Boxes, ROIMasks)):\n        res, schema = TensorWrapSchema.flatten(obj)\n        return res, schema\n    else:\n        raise ValueError(f\"Unsupported type: {type(obj)}\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes, int, float, bool, type(None))):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    elif isinstance(obj, collections.abc.Mapping):\n        keys = list(obj.keys())\n        values = [obj[k] for k in keys]\n        res, schema = ListSchema.flatten(values)\n        return res, DictSchema(schema.schemas, schema.sizes, keys)\n    elif isinstance(obj, Instances):\n        ret, schema = InstancesSchema.flatten(obj)\n        return ret, schema\n    elif isinstance(obj, (Boxes, ROIMasks)):\n        ret, schema = TensorWrapSchema.flatten(obj)\n        return ret, schema\n    else:\n        raise TypeError(f\"Unsupported type: {type(obj)}\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes, int, float, bool)):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    elif isinstance(obj, collections.abc.Mapping):\n        keys = list(obj.keys())\n        values = [obj[k] for k in keys]\n        res, schema = ListSchema.flatten(values)\n        return res, DictSchema(schema.schemas, schema.sizes, keys)\n    elif isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    elif isinstance(obj, (Boxes, ROIMasks)):\n        return TensorWrapSchema.flatten(obj)\n    else:\n        raise NotImplementedError(f\"Flattening {type(obj)} is not supported.\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes, int, float)):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    elif isinstance(obj, collections.abc.Mapping):\n        keys = sorted(obj.keys())\n        values = [obj[k] for k in keys]\n        ret, schema = ListSchema.flatten(values)\n        return ret, DictSchema(schema.schemas, schema.sizes, keys)\n    elif isinstance(obj, Instances):\n        ret, schema = InstancesSchema.flatten(obj)\n        return ret, schema\n    elif isinstance(obj, (Boxes, ROIMasks)):\n        ret, schema = TensorWrapSchema.flatten(obj)\n        return ret, schema\n    else:\n        raise ValueError(f\"Unsupported type: {type(obj)}\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes, int, float, bool, type(None))):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    elif isinstance(obj, collections.abc.Mapping):\n        keys = list(obj.keys())\n        values = [obj[k] for k in keys]\n        res, schema = ListSchema.flatten(values)\n        return res, DictSchema(schema.schemas, schema.sizes, keys)\n    elif isinstance(obj, Instances):\n        res, schema = InstancesSchema.flatten(obj)\n        return res, schema\n    elif isinstance(obj, (Boxes, ROIMasks)):\n        return TensorWrapSchema.flatten(obj)\n    else:\n        raise ValueError(f\"Unsupported type: {type(obj)}\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes, int, float, bool, type(None))):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (tuple, list)):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    elif isinstance(obj, collections.abc.Mapping):\n        keys = sorted(obj.keys())\n        values = [obj[k] for k in keys]\n        ret, schema = ListSchema.flatten(values)\n        return ret, DictSchema(schema.schemas, schema.sizes, keys)\n    elif isinstance(obj, (Boxes, Instances, ROIMasks)):\n        return obj.flatten()\n    elif isinstance(obj, torch.Tensor):\n        return (obj,), TensorWrapSchema(_convert_target_to_string(type(obj)))\n    else:\n        raise NotImplementedError(f\"Unsupported type {type(obj)} for flattening\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes, int, float, bool)):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    elif isinstance(obj, collections.abc.Mapping):\n        keys = list(obj.keys())\n        values = [obj[k] for k in keys]\n        res, schema = ListSchema.flatten(values)\n        return res, DictSchema(schema.schemas, schema.sizes, keys)\n    elif isinstance(obj, Instances):\n        res, schema = InstancesSchema.flatten(obj)\n        return res, schema\n    elif isinstance(obj, (Boxes, ROIMasks)):\n        res, schema = TensorWrapSchema.flatten(obj)\n        return res, schema\n    else:\n        raise ValueError(\"Unsupported type for flattening: {}\".format(type(obj)))"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes, int, float, bool, type(None))):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    elif isinstance(obj, collections.abc.Mapping):\n        keys = sorted(obj.keys())\n        values = [obj[k] for k in keys]\n        ret, schema = ListSchema.flatten(values)\n        return ret, DictSchema(schema.schemas, schema.sizes, keys)\n    elif isinstance(obj, Instances):\n        ret, schema = InstancesSchema.flatten(obj)\n        return ret, schema\n    elif isinstance(obj, (Boxes, ROIMasks)):\n        ret, schema = TensorWrapSchema.flatten(obj)\n        return ret, schema\n    else:\n        raise NotImplementedError(f\"Flattening {type(obj)} is not supported.\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes, int, float, bool, type(None))):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    elif isinstance(obj, collections.abc.Mapping):\n        keys = sorted(obj.keys())\n        values = [obj[k] for k in keys]\n        ret, schema = ListSchema.flatten(values)\n        return ret, DictSchema(schema.schemas, schema.sizes, keys)\n    elif isinstance(obj, (Boxes, ROIMasks)):\n        return obj.tensor, TensorWrapSchema(_convert_target_to_string(type(obj)))\n    elif isinstance(obj, Instances):\n        ret, schema = InstancesSchema.flatten(obj)\n        return ret, schema\n    else:\n        raise NotImplementedError(f\"Type {type(obj)} is not supported for flattening.\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes, int, float, bool, type(None))):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, torch.Tensor):\n        return (obj,), TensorWrapSchema.flatten(obj)\n    elif isinstance(obj, list):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    elif isinstance(obj, tuple):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = TupleSchema._concat([k[0] for k in res])\n        return values, TupleSchema([k[1] for k in res], sizes)\n    elif isinstance(obj, collections.abc.Mapping):\n        keys = sorted(obj.keys())\n        values = [obj[k] for k in keys]\n        res, schema = ListSchema.flatten(values)\n        return res, DictSchema(schema.schemas, schema.sizes, keys)\n    elif isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    elif isinstance(obj, (Boxes, ROIMasks)):\n        return obj.flatten()\n    else:\n        raise ValueError(f\"Unsupported type: {type(obj)}\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes, int, float, bool, type(None))):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    elif isinstance(obj, collections.abc.Mapping):\n        keys = sorted(obj.keys())\n        values = [obj[k] for k in keys]\n        ret, schema = ListSchema.flatten(values)\n        return ret, DictSchema(schema.schemas, schema.sizes, keys)\n    elif isinstance(obj, (Boxes, ROIMasks)):\n        return obj.tensor, TensorWrapSchema(_convert_target_to_string(type(obj)))\n    elif isinstance(obj, Instances):\n        ret, schema = InstancesSchema.flatten(obj)\n        return ret, schema\n    else:\n        raise NotImplementedError(f\"Flattening {type(obj)} is not supported.\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    \n    if isinstance(obj, (str, bytes, int, float, bool, type(None))):\n        return (obj,), IdentitySchema()\n\n    elif isinstance(obj, (list, tuple)):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n\n    elif isinstance(obj, collections.abc.Mapping):\n        keys = sorted(obj.keys())\n        values = [obj[k] for k in keys]\n        ret, schema = ListSchema.flatten(values)\n        return ret, DictSchema(schema.schemas, schema.sizes, keys)\n\n    elif isinstance(obj, Instances):\n        ret, schema = InstancesSchema.flatten(obj)\n        return ret, schema\n\n    elif isinstance(obj, (Boxes, ROIMasks)):\n        ret, schema = TensorWrapSchema.flatten(obj)\n        return ret, schema\n\n    else:\n        raise ValueError(f\"Unsupported type for flattening: {type(obj)}\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "\n    if isinstance(obj, (str, bytes, int, float, bool, type(None))):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    elif isinstance(obj, collections.abc.Mapping):\n        keys = sorted(obj.keys())\n        values = [obj[k] for k in keys]\n        ret, schema = ListSchema.flatten(values)\n        return ret, DictSchema(schema.schemas, schema.sizes, keys)\n    elif isinstance(obj, (Boxes, Instances, ROIMasks)):\n        return obj.flatten()\n    else:\n        raise NotImplementedError(\"Flattening not supported for this type\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes, int, float, bool, type(None))):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    elif isinstance(obj, collections.abc.Mapping):\n        keys = sorted(obj.keys())\n        values = [obj[k] for k in keys]\n        ret, schema = ListSchema.flatten(values)\n        return ret, DictSchema(schema.schemas, schema.sizes, keys)\n    elif isinstance(obj, Instances):\n        ret, schema = InstancesSchema.flatten(obj)\n        return ret, schema\n    elif isinstance(obj, (Boxes, ROIMasks)):\n        ret, schema = TensorWrapSchema.flatten(obj)\n        return ret, schema\n    else:\n        raise NotImplementedError(f\"Flattening {type(obj)} is not supported.\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes)):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    elif isinstance(obj, collections.abc.Mapping):\n        keys = list(obj.keys())\n        values = [obj[k] for k in keys]\n        res, schema = ListSchema.flatten(values)\n        return res, DictSchema(schema.schemas, schema.sizes, keys)\n    elif isinstance(obj, Instances):\n        res, schema = InstancesSchema.flatten(obj)\n        return res, schema\n    elif isinstance(obj, (Boxes, ROIMasks)):\n        return TensorWrapSchema.flatten(obj)\n    else:\n        raise ValueError(f\"Unsupported type: {type(obj)}\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes, int, float, bool, type(None))):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    elif isinstance(obj, collections.abc.Mapping):\n        keys = sorted(obj.keys())\n        values = [obj[k] for k in keys]\n        ret, schema = ListSchema.flatten(values)\n        return ret, DictSchema(schema.schemas, schema.sizes, keys)\n    elif isinstance(obj, Instances):\n        ret, schema = InstancesSchema.flatten(obj)\n        return ret, schema\n    elif isinstance(obj, (Boxes, ROIMasks)):\n        ret, schema = TensorWrapSchema.flatten(obj)\n        return ret, schema\n    else:\n        raise ValueError(f\"Unsupported type for flattening: {type(obj)}\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes, int, float, bool)):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    elif isinstance(obj, collections.abc.Mapping):\n        keys = sorted(obj.keys())\n        values = [obj[k] for k in keys]\n        ret, schema = ListSchema.flatten(values)\n        return ret, DictSchema(schema.schemas, schema.sizes, keys)\n    elif isinstance(obj, Instances):\n        ret, schema = InstancesSchema.flatten(obj)\n        return ret, schema\n    elif isinstance(obj, Boxes):\n        ret, schema = TensorWrapSchema.flatten(obj)\n        return ret, schema\n    elif isinstance(obj, ROIMasks):\n        ret, schema = TensorWrapSchema.flatten(obj)\n        return ret, schema\n    else:\n        raise NotImplementedError(f\"Flattening object of type {type(obj)} is not supported.\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "\n    if isinstance(obj, (str, bytes, int, float, bool, type(None), torch.Tensor)):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, (list, tuple)):\n        res = [flatten_to_tuple(k) for k in obj]\n        values, sizes = ListSchema._concat([k[0] for k in res])\n        return values, ListSchema([k[1] for k in res], sizes)\n    elif isinstance(obj, collections.abc.Mapping):\n        keys = sorted(obj.keys())\n        values = [obj[k] for k in keys]\n        ret, schema = ListSchema.flatten(values)\n        return ret, DictSchema(schema.schemas, schema.sizes, keys)\n    elif isinstance(obj, Instances):\n        ret, schema = InstancesSchema.flatten(obj)\n        return ret, schema\n    elif isinstance(obj, Boxes):\n        ret, schema = TensorWrapSchema.flatten(obj)\n        return ret, schema\n    elif isinstance(obj, ROIMasks):\n        ret, schema = TensorWrapSchema.flatten(obj)\n        return ret, schema\n    else:\n        raise ValueError(f\"Unsupported type: {type(obj)}\")"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    n_groups, n_assets = groups.shape\n    n_equations = len(equations)\n\n    left = np.zeros((n_equations, n_assets))\n    right = np.zeros(n_equations)\n\n    for i, equation in enumerate(equations):\n        equation = equation.replace(\" \", \"\")\n        equation = re.sub(r\"([A-Za-z0-9_]+)\", r\"groups['\\1']\", equation)\n\n        try:\n            left[i, :] = eval(equation)\n        except NameError as e:\n            if raise_if_group_missing:\n                raise GroupNotFoundError(f\"Group '{e.args[0]}' not found in the provided groups array\") from e\n            else:\n                warnings.warn(f\"Group '{e.args[0]}' not found in the provided groups array. Skipping equation.\", UserWarning)\n                return None\n\n    if sum_to_one:\n        left = left - np.eye(n_assets)\n\n    return left, right"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    n_groups, n_assets = groups.shape\n    n_equations = len(equations)\n\n    left = np.zeros((n_equations, n_assets))\n    right = np.zeros(n_equations)\n\n    for i, equation in enumerate(equations):\n        # Parse the equation to extract group coefficients\n        equation = equation.replace(\" \", \"\")\n        equation = equation.replace(\"-\", \"+-\")\n        equation = equation.split(\"=\")\n\n        if len(equation) != 2:\n            raise EquationToMatrixError(f\"Equation {equation} is not properly formatted\")\n\n        equation = [e for e in equation if e]\n\n        if len(equation) != 2:\n            raise EquationToMatrixError(f\"Equation {equation} is not properly formatted\")\n\n        left_side, right_side = equation\n\n        if not re.match(r\"^[+-]?(\\d+(\\.\\d*)?|\\.\\d+)?\\*?[a-zA-Z_]+\", left_side):\n            raise EquationToMatrixError(f\"Invalid equation format: {left_side}\")\n\n        if not re.match(r\"^[+-]?(\\d+(\\.\\d*)?|\\.\\d+)?$\", right_side):\n            raise EquationToMatrixError(f\"Invalid equation format: {right_side}\")\n\n        for group in re.findall(r\"[+-]?(\\d+(\\.\\d*)?|\\.\\d+)?\\*?([a-zA-Z_]+)\", left_side):\n            coefficient, group_name = group\n            coefficient = float(coefficient) if coefficient else 1.0\n            try:\n                group_index = list(groups[:, 0]).index(group_name)\n            except ValueError:\n                if raise_if_group_missing:\n                    raise GroupNotFoundError(f\"Group {group_name} not found in the groups array\")\n                else:\n                    warnings.warn(f\"Group {group_name} not found in the groups array\", UserWarning)\n                    return None, None\n            left[i, group_index] = coefficient\n\n        right[i] = float(right_side)\n\n    if sum_to_one:\n        left = np.vstack([left, np.ones(n_assets)])\n        right = np.hstack([right, 1.0])\n\n    return left, right"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Convert groups and equations to matrices\n    left = []\n    right = []\n    for equation in equations:\n        equation = re.sub(r\"\\s+\", \"\", equation)  # Remove white spaces\n        equation = equation.replace(\"=\", \"-\")  # Replace \"=\" with \"-\"\n        equation = equation.split(\"-\")  # Split the equation into left and right sides\n        equation_left = equation[0]\n        equation_right = equation[1]\n\n        # Check if all groups in the equation are part of the input groups\n        if all(group in groups for group in re.findall(r\"[a-zA-Z_]+\", equation_left)):\n            left.append([equation_left.count(group) for group in groups])\n            right.append(equation_right)\n        else:\n            if raise_if_group_missing:\n                raise GroupNotFoundError(f\"At least one group in the equation '{equation}' is not found in the input groups.\")\n            else:\n                warnings.warn(f\"At least one group in the equation '{equation}' is not found in the input groups.\", UserWarning)\n                return None\n\n    return np.array(left), np.array(right)"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Initialize an empty list to store the left-hand side coefficients\n    left = []\n    \n    # Initialize an empty list to store the right-hand side coefficients\n    right = []\n    \n    # Loop through each equation\n    for eq in equations:\n        # Initialize a list to store the coefficients for the current equation\n        eq_coeffs = [0] * len(groups[0])\n        \n        # Split the equation into individual terms\n        terms = re.findall(r'(\\+|\\-)?(\\d*)\\s*([a-zA-Z_]+)', eq)\n        \n        # Loop through each term in the equation\n        for sign, coeff, group in terms:\n            # If the coefficient is empty, set it to 1\n            if coeff == \"\":\n                coeff = 1\n            else:\n                coeff = int(coeff)\n            \n            # Get the index of the group in the groups array\n            try:\n                group_index = list(groups).index(group)\n            except ValueError:\n                if raise_if_group_missing:\n                    raise GroupNotFoundError(f\"Group '{group}' not found in the {names[0]} array.\")\n                else:\n                    warnings.warn(f\"Group '{group}' not found in the {names[0]} array.\")\n                    return None, None\n            \n            # Update the coefficient in the equation coefficients list\n            if sign == \"-\":\n                eq_coeffs[group_index] = -coeff\n            else:\n                eq_coeffs[group_index] = coeff\n        \n        # Add the equation coefficients to the left-hand side list\n        left.append(eq_coeffs)\n        \n        # Extract the constant term from the equation\n        constant = re.findall(r'(\\+|\\-)?(\\d+)$', eq)\n        if constant:\n            sign, const = constant[0]\n            if sign == \"-\":\n                right.append(-int(const))\n            else:\n                right.append(int(const))\n        else:\n            right.append(0)\n    \n    # Convert the left and right lists to numpy arrays\n    left_matrix = np.array(left)\n    right_matrix = np.array(right)\n    \n    return left_matrix, right_matrix"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Initialize an empty list to store the left and right matrices\n    left_matrices = []\n    right_matrices = []\n\n    # Iterate through each equation\n    for equation in equations:\n        # Initialize a dictionary to store the coefficients of the equation\n        coefficients = {}\n        \n        # Split the equation into individual terms\n        terms = re.split(r\"([+-])\", equation)\n        \n        # Iterate through each term\n        for term in terms:\n            # Remove any whitespace\n            term = term.strip()\n            \n            # Check if the term is a coefficient\n            if re.match(r\"^[+-]?\\d+\\.?\\d*$\", term):\n                # Extract the coefficient and update the dictionary\n                coefficient = float(term)\n                coefficients[\"constant\"] = coefficient\n            else:\n                # Extract the group and coefficient\n                match = re.match(r\"([+-]?\\d+\\.?\\d*)\\s*\\*\\s*([A-Za-z0-9_]+)\", term)\n                if match:\n                    coefficient = float(match.group(1))\n                    group = match.group(2)\n                    coefficients[group] = coefficient\n                else:\n                    raise EquationToMatrixError(f\"Invalid term in equation: {equation}\")\n        \n        # Initialize the left matrix row for the equation\n        left_row = np.zeros(len(groups[0]))\n        \n        # Iterate through the groups to fill in the left matrix row\n        for i, group in enumerate(groups):\n            if group in coefficients:\n                left_row[i] = coefficients[group]\n            elif raise_if_group_missing:\n                raise GroupNotFoundError(f\"Group '{group}' not found in the input groups\")\n            else:\n                warnings.warn(f\"Group '{group}' not found in the input groups\", UserWarning)\n        \n        # Append the left matrix row to the left matrices list\n        left_matrices.append(left_row)\n        \n        # Append the constant coefficient to the right matrices list\n        right_matrices.append(-coefficients[\"constant\"])\n    \n    # Convert the left and right matrices to numpy arrays\n    left_matrix = np.array(left_matrices)\n    right_matrix = np.array(right_matrices)\n    \n    # Return the left and right matrices as a tuple\n    return left_matrix, right_matrix"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Check if all groups mentioned in the equations are present in the input groups\n    for eq in equations:\n        for group in re.findall(r\"\\b\\w+\\b\", eq):\n            if group not in groups:\n                if raise_if_group_missing:\n                    raise GroupNotFoundError(f\"Group '{group}' not found in the {names[0]} array\")\n                else:\n                    warnings.warn(f\"Group '{group}' not found in the {names[0]} array\", UserWarning)\n\n    # Create the left matrix\n    left = np.zeros((len(equations), len(groups)))\n    for i, eq in enumerate(equations):\n        for group in re.findall(r\"\\b\\w+\\b\", eq):\n            left[i, groups.index(group)] = eval(re.sub(r\"\\b\\w+\\b\", \"1\", eq))\n\n    # Create the right matrix\n    right = np.array([eval(eq) for eq in equations])\n\n    # If sum_to_one is True, normalize the left matrix\n    if sum_to_one:\n        left = left / left.sum(axis=1)[:, np.newaxis]\n\n    return left, right"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Convert groups and equations to matrices\n    group_dict = {group: i for i, group in enumerate(groups)}\n    n_equations = len(equations)\n    n_assets = len(groups)\n\n    left = np.zeros((n_equations, n_assets))\n    right = np.zeros(n_equations)\n\n    for i, equation in enumerate(equations):\n        # Parse equation\n        equation = equation.replace(\" \", \"\")\n        match = re.match(r\"([+\\-]?[0-9]*\\.?[0-9]*)\\*?([a-zA-Z_]+)\", equation)\n\n        if match is None:\n            raise EquationToMatrixError(f\"Invalid equation: {equation}\")\n\n        coefficient, group = match.groups()\n        coefficient = float(coefficient) if coefficient else 1.0\n\n        # Check if group is in groups\n        if group not in group_dict:\n            if raise_if_group_missing:\n                raise GroupNotFoundError(f\"Group '{group}' not found in {names[0]}\")\n            else:\n                warnings.warn(f\"Group '{group}' not found in {names[0]}\", UserWarning)\n                return None, None\n\n        # Assign coefficient to left matrix\n        left[i, group_dict[group]] = coefficient\n\n        # Assign 1 to right matrix if sum_to_one is True\n        if sum_to_one:\n            right[i] = 1.0\n\n    return left, right"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Initialize an empty list to store the left and right matrices\n    left_matrices = []\n    right_matrices = []\n\n    # Loop through each equation\n    for equation in equations:\n        # Initialize a list to store the coefficients of the equation\n        coefficients = []\n        \n        # Split the equation into individual terms\n        terms = re.split(r\"([+-])\", equation)\n        \n        # Loop through each term in the equation\n        for term in terms:\n            # Remove any whitespace\n            term = term.strip()\n            \n            # If the term is a group name\n            if term in groups:\n                # Find the index of the group in the groups array\n                group_index = np.where(groups == term)[0]\n                \n                # If the group is not found in the groups array\n                if len(group_index) == 0:\n                    # Raise an error or issue a warning based on the value of raise_if_group_missing\n                    if raise_if_group_missing:\n                        raise GroupNotFoundError(f\"Group '{term}' not found in the {names[0]} array\")\n                    else:\n                        warnings.warn(f\"Group '{term}' not found in the {names[0]} array\")\n                        # Set coefficients to None and break the loop\n                        coefficients = None\n                        break\n                else:\n                    # Add the coefficient for the group to the list of coefficients\n                    coefficients.append(1)\n            # If the term is a constant\n            elif re.match(r\"^-?\\d+\\.?\\d*$\", term):\n                # Add the constant to the list of coefficients\n                coefficients.append(float(term))\n            # If the term is a sum-to-one indicator\n            elif sum_to_one and term == \"sum_to_one\":\n                # Add a 1 to the list of coefficients\n                coefficients.append(1)\n            # If the term is a positive or negative sign\n            elif term in [\"+\", \"-\"]:\n                # Add the sign to the list of coefficients\n                coefficients.append(term)\n        \n        # If coefficients is not None, create the left and right matrices\n        if coefficients is not None:\n            # Convert the coefficients list to a numpy array\n            coefficients = np.array(coefficients)\n            \n            # Extract the constant term (if present) and remove it from the coefficients array\n            constant_term = coefficients[-1] if isinstance(coefficients[-1], float) else 0\n            coefficients = coefficients[:-1]\n            \n            # Add the coefficients to the left matrix\n            left_matrices.append(coefficients)\n            \n            # Add the constant term to the right matrix\n            right_matrices.append(-constant_term)\n    \n    # If left_matrices and right_matrices are not empty, convert them to numpy arrays and return them\n    if left_matrices and right_matrices:\n        return np.array(left_matrices), np.array(right_matrices)\n    else:\n        return None, None"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Check if all groups in equations are present in the input groups\n    if raise_if_group_missing:\n        for equation in equations:\n            groups_in_equation = re.findall(r\"\\b\\w+\\b\", equation)\n            for group in groups_in_equation:\n                if group not in groups:\n                    raise GroupNotFoundError(f\"Group '{group}' mentioned in the equations is not found in the groups array.\")\n    else:\n        for equation in equations:\n            groups_in_equation = re.findall(r\"\\b\\w+\\b\", equation)\n            for group in groups_in_equation:\n                if group not in groups:\n                    warnings.warn(f\"Group '{group}' mentioned in the equations is not found in the groups array.\", UserWarning)\n\n    # Initialize the left and right matrices\n    left = np.zeros((len(equations), len(groups)))\n    right = np.zeros(len(equations))\n\n    # Populate the left and right matrices based on the linear equations\n    for i, equation in enumerate(equations):\n        equation = equation.replace(\" \", \"\")\n        equation = equation.replace(\"-\", \"+-\")\n        equation = equation.split(\"=\")\n        right[i] = float(equation[1])\n\n        for term in equation[0].split(\"+\"):\n            coefficient = term.split(\"*\")[0]\n            group = term.split(\"*\")[1]\n\n            if sum_to_one:\n                left[i, np.where(groups == group)] = float(coefficient)\n            else:\n                left[i, np.where(groups == group)] = -float(coefficient)\n\n    return left, right"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Check if all groups in equations are part of the input groups\n    missing_groups = set(re.findall(r\"\\b\\w+\\b\", \" \".join(equations))) - set(groups.flatten())\n    if missing_groups:\n        if raise_if_group_missing:\n            raise GroupNotFoundError(f\"The following groups are missing in the input groups: {missing_groups}\")\n        else:\n            warnings.warn(f\"The following groups are missing in the input groups: {missing_groups}\")\n\n    # Create the left matrix\n    left = np.zeros((len(equations), len(groups)))\n    for i, equation in enumerate(equations):\n        equation = equation.replace(\" \", \"\")\n        for term in equation.split(\"+\"):\n            group, coef = term.split(\"*\")\n            left[i, np.where(groups == group)[1][0]] = float(coef)\n\n    # Create the right matrix\n    right = np.array([eval(re.sub(r\"\\b\\w+\\b\", lambda x: str(groups.flatten().tolist().index(x.group())), eq)) for eq in equations])\n\n    # Adjust the left matrix if sum_to_one is True\n    if sum_to_one:\n        left = np.hstack((left, -np.eye(len(groups))))\n\n    return left, right"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Convert groups and equations to matrices\n    group_matrix = np.array(groups)\n    equation_matrix = np.zeros((len(equations), group_matrix.shape[1]))\n\n    # Convert equations to matrix\n    for i, equation in enumerate(equations):\n        # Parse the equation string to extract coefficients and group names\n        equation = equation.replace(\" \", \"\")  # Remove white spaces\n        coefficients = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", equation)  # Extract coefficients\n        group_names = re.findall(r\"[a-zA-Z]+\", equation)  # Extract group names\n\n        # Check if all group names in the equation are present in the input groups\n        if raise_if_group_missing:\n            if not all(name in groups for name in group_names):\n                raise GroupNotFoundError(f\"One or more groups in the equation {equation} are not found in the input groups.\")\n        else:\n            missing_groups = [name for name in group_names if name not in groups]\n            if missing_groups:\n                warnings.warn(f\"The following groups in the equation {equation} are not found in the input groups: {missing_groups}\")\n\n        # Fill the equation matrix with coefficients\n        for j, group in enumerate(groups):\n            if group in group_names:\n                equation_matrix[i, j] = float(coefficients[group_names.index(group)])\n    \n    return equation_matrix, np.zeros(len(equations))"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Initialize the left and right matrices\n    left = []\n    right = []\n\n    # Loop through each equation\n    for eq in equations:\n        # Initialize the coefficients for the current equation\n        coefficients = np.zeros(len(groups[0]))\n\n        # Split the equation into individual terms\n        terms = re.split(r\"([+-])\", eq)\n\n        # Loop through each term in the equation\n        for term in terms:\n            # Remove whitespace\n            term = term.strip()\n\n            # Check if the term is a variable\n            if term in groups:\n                # Get the index of the group in the groups array\n                group_index = groups.index(term)\n\n                # Set the coefficient for the corresponding group\n                if \"+\" in term:\n                    coefficients[group_index] = 1\n                elif \"-\" in term:\n                    coefficients[group_index] = -1\n                else:\n                    coefficients[group_index] = 1\n\n            # Check if the term is a constant\n            if re.match(r\"^-?\\d+\\.?\\d*$\", term):\n                # Set the constant term\n                right.append(float(term))\n\n        # Add the coefficients to the left matrix\n        left.append(coefficients)\n\n    # Convert the left and right matrices to numpy arrays\n    left = np.array(left)\n    right = np.array(right)\n\n    # Check if any of the groups in the equations are missing from the input groups\n    missing_groups = [eq for eq in equations if eq not in groups]\n\n    # Raise an error or issue a warning if raise_if_group_missing is True or False, respectively\n    if missing_groups and raise_if_group_missing:\n        raise GroupNotFoundError(f\"The following groups in the equations are missing from the input groups: {missing_groups}\")\n    elif missing_groups:\n        warnings.warn(f\"The following groups in the equations are missing from the input groups: {missing_groups}\")\n\n    return left, right"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Convert groups to a dictionary for easy lookup\n    groups_dict = {group: i for i, group in enumerate(groups)}\n\n    # Initialize left and right matrices\n    left = np.zeros((len(equations), len(groups)))\n    right = np.zeros(len(equations))\n\n    # Loop through each equation\n    for i, equation in enumerate(equations):\n        # Split the equation into individual terms\n        terms = re.split(r\"([+-])\", equation)\n\n        # Initialize the coefficients and group index for the current equation\n        coefficients = []\n        group_indices = []\n\n        # Loop through each term in the equation\n        for term in terms:\n            # Remove whitespace and convert to lowercase\n            term = term.strip().lower()\n\n            # Check if the term is a coefficient or a group\n            if re.match(r\"^\\d+?(\\.\\d+)?$\", term):\n                # If the term is a coefficient, add it to the coefficients list\n                coefficients.append(float(term))\n            elif term in groups_dict:\n                # If the term is a group, add its index to the group_indices list\n                group_indices.append(groups_dict[term])\n            else:\n                # If the term is neither a coefficient nor a group, raise an error\n                raise EquationToMatrixError(f\"Invalid term '{term}' in equation '{equation}'\")\n\n        # If sum_to_one is True, add a constraint that all elements in a group should sum to one\n        if sum_to_one:\n            for index in group_indices:\n                coefficients.append(-1.0)\n            right[i] = 0.0\n\n        # Assign the coefficients to the left matrix\n        left[i, group_indices] = coefficients\n\n    # If raise_if_group_missing is True, check if any group mentioned in the equations is not found in the groups array\n    if raise_if_group_missing:\n        missing_groups = set(re.findall(r\"\\b\\w+\\b\", \" \".join(equations))) - set(groups_dict.keys())\n        if missing_groups:\n            raise GroupNotFoundError(f\"The following groups mentioned in the equations are missing: {missing_groups}\")\n\n    return left, right"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Convert groups and equations to a matrix representation\n    left = np.zeros((len(equations), len(groups[0])))\n    right = np.zeros(len(equations))\n\n    for i, equation in enumerate(equations):\n        # Parse the equation to extract coefficients and group names\n        coefficients = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", equation)\n        group_names = re.findall(r\"[a-zA-Z]+\", equation)\n\n        # Check if all group names in the equation are part of the input groups\n        if all(group in groups for group in group_names):\n            for coeff, group in zip(coefficients, group_names):\n                group_index = groups.index(group)\n                left[i, group_index] = float(coeff)\n\n            # If sum_to_one is True, add a constraint that the sum of all elements in a group should be 1\n            if sum_to_one:\n                left[i, groups.index(group_names[0])] = 1\n\n            # Extract the constant term from the equation\n            constant = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", equation)[-1]\n            right[i] = float(constant)\n        else:\n            if raise_if_group_missing:\n                raise GroupNotFoundError(f\"Group '{group}' not found in the input groups\")\n            else:\n                warnings.warn(f\"Group '{group}' not found in the input groups\", UserWarning)\n\n    return left, right"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Convert groups and equations to matrices\n    left = []\n    right = []\n    \n    for equation in equations:\n        equation = equation.replace(\" \", \"\")  # Remove spaces from equation\n        equation = re.sub(r'(\\d+)([A-Za-z])', r'\\1*\\2', equation)  # Add * between coefficient and variable\n        equation = re.sub(r'([A-Za-z])(\\d+)', r'\\1*\\2', equation)  # Add * between variable and coefficient\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])-(?=[A-Za-z\\(])', '-1*', equation)  # Add 1* for negative coefficient\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\(])', '+', equation)  # Add + between variables\n        \n        equation = re.sub(r'(?<=[A-Za-z\\d\\)])(?=[A-Za-z\\("}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Convert groups and equations to numpy arrays\n    groups = np.array(groups)\n    equations = np.array(equations)\n\n    # Initialize the left and right matrices\n    left = np.zeros((len(equations), len(groups[0])))\n    right = np.zeros(len(equations))\n\n    # Iterate through each equation\n    for i, equation in enumerate(equations):\n        # Parse the equation to extract group coefficients\n        coefficients = re.findall(r'(\\d+)', equation)\n        groups_in_equation = re.findall(r'[A-Za-z_]+', equation)\n\n        # Check if the groups in the equation are present in the input groups\n        missing_groups = [group for group in groups_in_equation if group not in groups]\n        if missing_groups:\n            if raise_if_group_missing:\n                raise GroupNotFoundError(f\"The following groups are missing: {missing_groups}\")\n            else:\n                warnings.warn(f\"The following groups are missing: {missing_groups}\", UserWarning)\n                return None, None\n\n        # Update the left and right matrices based on the equation coefficients\n        for group, coefficient in zip(groups_in_equation, coefficients):\n            group_index = np.where(groups == group)[0][0]\n            left[i, group_index] = float(coefficient)\n\n        # Extract the constant term from the equation\n        constant = re.findall(r'([-+]?\\d*\\.\\d+|\\d+)', equation)[-1]\n        right[i] = float(constant)\n\n    return left, right"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Initialize an empty list to store the left side of the inequality\n    left_side = []\n    \n    # Initialize an empty list to store the right side of the inequality\n    right_side = []\n    \n    # Iterate through each equation\n    for equation in equations:\n        # Initialize an empty list to store the coefficients of the equation\n        coefficients = []\n        \n        # Split the equation into individual terms\n        terms = re.findall(r'(\\+|\\-)?\\s*(\\d*\\.*\\d*)\\s*\\*\\s*(\\w+)', equation)\n        \n        # Iterate through each term in the equation\n        for term in terms:\n            # Extract the sign, coefficient, and group name from the term\n            sign, coefficient, group = term\n            \n            # Convert the coefficient to a float\n            coefficient = float(coefficient) if coefficient else 1.0\n            \n            # If the group is not found in the input groups\n            if group not in groups:\n                # Raise an error or issue a warning based on the `raise_if_group_missing` parameter\n                if raise_if_group_missing:\n                    raise GroupNotFoundError(f\"Group '{group}' mentioned in the equations not found in the input groups.\")\n                else:\n                    warnings.warn(f\"Group '{group}' mentioned in the equations not found in the input groups.\")\n                    return None, None\n            \n            # Find the index of the group in the input groups\n            group_index = np.where(groups == group)[0][0]\n            \n            # Append the coefficient to the list of coefficients\n            coefficients.append(coefficient)\n            \n            # If the sum_to_one parameter is True, add an additional constraint to the equation\n            if sum_to_one:\n                coefficients.append(-1.0)\n                \n            # Create a list of zeros with length equal to the number of groups\n            zeros = [0.0] * len(groups)\n            \n            # Replace the zero at the index of the group with the coefficient\n            zeros[group_index] = coefficient\n            \n            # If the sum_to_one parameter is True, replace the zero at the index of the group with -1\n            if sum_to_one:\n                zeros[group_index] = -1.0\n            \n            # Append the list of zeros to the left side of the inequality\n            left_side.append(zeros)\n        \n        # Append the list of coefficients to the right side of the inequality\n        right_side.append(coefficients)\n    \n    # Convert the left and right sides to numpy arrays\n    left_matrix = np.array(left_side)\n    right_matrix = np.array(right_side)\n    \n    # Return the left and right matrices\n    return left_matrix, right_matrix"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Initialize the left and right matrices\n    left = []\n    right = []\n\n    # Loop through each equation\n    for eq in equations:\n        # Split the equation into left and right side\n        sides = eq.split(\"=\")\n        if len(sides) != 2:\n            raise EquationToMatrixError(f\"Equation '{eq}' is not properly formatted\")\n\n        left_side = sides[0].strip()\n        right_side = sides[1].strip()\n\n        # Initialize the left side of the equation\n        left_eq = np.zeros(len(groups[0]))\n\n        # Loop through each group mentioned in the equation\n        for i, group in enumerate(groups):\n            if group in left_side:\n                # Extract the coefficient and group name\n                coefficient = re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", left_side)\n                if coefficient:\n                    coefficient = float(coefficient.group())\n                else:\n                    coefficient = 1.0\n\n                # Update the left side of the equation\n                left_eq[i] = coefficient\n\n        # Check if the group is not found in the input groups\n        if np.all(left_eq == 0) and raise_if_group_missing:\n            raise GroupNotFoundError(f\"Group in equation '{eq}' not found in the input groups\")\n\n        # Add the left side of the equation to the left matrix\n        left.append(left_eq)\n\n        # Add the right side of the equation to the right matrix\n        right.append(float(right_side))\n\n    # Convert the left and right matrices to numpy arrays\n    left = np.array(left)\n    right = np.array(right)\n\n    # If sum_to_one is True, add the constraint that all elements in a group should sum to one\n    if sum_to_one:\n        left = np.vstack([left, np.ones(len(groups[0]))])\n        right = np.append(right, 1.0)\n\n    return left, right"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Create an empty list to store the left and right matrices\n    left_matrices = []\n    right_matrices = []\n\n    # Iterate through each equation\n    for equation in equations:\n        # Split the equation into individual terms\n        terms = re.split(r\"([+-])\", equation)\n\n        # Initialize an array for the left matrix of the equation\n        left_matrix = np.zeros((1, len(groups[0])))\n\n        # Iterate through each term in the equation\n        for term in terms:\n            # Remove whitespace\n            term = term.strip()\n\n            # Extract the coefficient and group name from the term\n            match = re.match(r\"([-+]?[0-9]*\\.?[0-9]+)\\s*\\*\\s*(\\w+)\", term)\n\n            if match:\n                coefficient = float(match.group(1))\n                group_name = match.group(2)\n\n                # Find the index of the group in the groups array\n                try:\n                    group_index = groups.index(group_name)\n                except ValueError:\n                    if raise_if_group_missing:\n                        raise GroupNotFoundError(f\"Group '{group_name}' not found in the provided groups array.\")\n                    else:\n                        warnings.warn(f\"Group '{group_name}' not found in the provided groups array.\")\n\n                    # If the group is not found, set the left matrix to None and break the loop\n                    left_matrix = None\n                    break\n\n                # Set the coefficient in the left matrix\n                left_matrix[0, group_index] = coefficient\n\n            elif term:\n                raise EquationToMatrixError(f\"Invalid term '{term}' in equation '{equation}'\")\n\n        # If the left matrix is not None, append it to the list of left matrices\n        if left_matrix is not None:\n            left_matrices.append(left_matrix)\n\n            # Check if the equation should sum to one\n            if sum_to_one:\n                right_matrices.append(1.0)\n            else:\n                right_matrices.append(0.0)\n\n    # If there are no left matrices, return None\n    if not left_matrices:\n        return None, None\n\n    # Concatenate the left matrices into a single array\n    left = np.concatenate(left_matrices, axis=0)\n\n    # Convert the right matrices to a numpy array\n    right = np.array(right_matrices)\n\n    return left, right"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    n_groups, n_assets = groups.shape\n    n_equations = len(equations)\n\n    left = np.zeros((n_equations, n_assets))\n    right = np.zeros(n_equations)\n\n    for i, equation in enumerate(equations):\n        equation = re.sub(r\"(\\w+)\", r\"groups['\\1']\", equation)\n        try:\n            left[i, :] = eval(equation)\n        except KeyError as e:\n            if raise_if_group_missing:\n                raise GroupNotFoundError(f\"Group '{e.args[0]}' not found in {names[0]}\") from e\n            else:\n                warnings.warn(f\"Group '{e.args[0]}' not found in {names[0]}\", UserWarning)\n                return None\n\n    if sum_to_one:\n        left = left / left.sum(axis=1)[:, np.newaxis]\n\n    return left, right"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    @contextmanager\n    def _patched_instances():\n        global _counter\n        module_name = f\"_instances_patch_{_counter}\"\n        _counter += 1\n\n        # Create a new class dynamically\n        class_name = \"PatchedInstances\"\n        fields_str = \"\\n\".join([f\"    {field_name}: {field_type}\" for field_name, field_type in fields])\n        class_str = f\"class {class_name}:\\n{fields_str}\\n    pass\"\n\n        # Write the class to a temporary file and import it\n        with tempfile.TemporaryDirectory() as temp_dir:\n            file_path = os.path.join(temp_dir, f\"{module_name}.py\")\n            with open(file_path, \"w\") as f:\n                f.write(class_str)\n\n            # Import the new module\n            new_module = _import_file(file_path, module_name)\n\n            # Set up the environment for torchscript to recognize the new class\n            _add_instances_conversion_methods(new_module.__getattribute__(class_name))\n\n            # Yield the new class\n            yield new_module.__getattribute__(class_name)\n\n        # Clean up after exiting the context\n        _clear_jit_cache()\n\n    return _patched_instances()"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    @contextmanager\n    def _patched_instances():\n        global _counter\n\n        # Define the new class\n        class NewInstances(Instances):\n            pass\n\n        for field_name, field_type in fields:\n            setattr(NewInstances, field_name, field_type)\n\n        # Add from_instances methods to the new class\n        _add_instances_conversion_methods(NewInstances)\n\n        # Create a new module for the class\n        module_name = f\"NewInstancesModule_{_counter}\"\n        _counter += 1\n\n        # Write the new class to a temporary file\n        with tempfile.TemporaryDirectory() as temp_dir:\n            temp_file = os.path.join(temp_dir, f\"{module_name}.py\")\n            with open(temp_file, \"w\") as f:\n                f.write(f\"class {module_name}(Instances):\\n    pass\\n\")\n                for field_name, field_type in fields:\n                    f.write(f\"setattr({module_name}, '{field_name}', {field_type.__name__})\\n\")\n                f.write(f\"_add_instances_conversion_methods({module_name})\\n\")\n\n            # Import the new module\n            new_module = _import_file(temp_file, module_name)\n\n            # Set up the environment for torchscript\n            with ExitStack() as stack:\n                stack.enter_context(mock.patch.dict(sys.modules, {new_module.__name__: new_module}))\n                stack.enter_context(mock.patch(\"torch.jit._recursive.concrete_type_store.type_store\", clear=True))\n                stack.enter_context(mock.patch(\"torch.jit._state._jit_caching_layer\", clear=True))\n\n                yield new_module.NewInstances\n\n    return _patched_instances()"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    @contextmanager\n    def _patched_instances():\n        global _counter\n        _counter += 1\n        module_name = f\"instances_patched_{_counter}\"\n        code = f\"\"\"\nimport torch\nfrom detectron2.structures import Instances\nfrom typing import List, Tuple\n\nclass {module_name}(Instances):\n    def __init__(self, image_size: Tuple[int, int]):\n        super().__init__(image_size)\n\"\"\"\n        for field in fields:\n            field_name, field_type = field\n            code += f\"        self.{field_name}: {field_type}\\n\"\n\n        code += f\"\"\"\n_instances_patched = {module_name}\n\"\"\"\n\n        with tempfile.TemporaryDirectory(prefix=\"detectron2_patch\") as d:\n            file_path = os.path.join(d, f\"{module_name}.py\")\n            with open(file_path, \"w\") as f:\n                f.write(code)\n\n            sys.path.append(d)\n            try:\n                module = _import_file(module_name, file_path)\n                yield getattr(module, module_name)\n            finally:\n                sys.path.remove(d)\n\n    return _patched_instances()"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "\n    class_name = \"NewInstances\" + str(_counter)\n    _counter += 1\n\n    # Define the class dynamically\n    class_def = f\"class {class_name}(Instances):\\n\"\n    for field in fields:\n        class_def += f\"    {field[0]}: {field[1]} = {field[2]}\\n\"\n\n    # Create a temporary file and write the class definition\n    with tempfile.NamedTemporaryFile(mode=\"w\", delete=False) as temp_file:\n        temp_file.write(class_def)\n        temp_file_path = temp_file.name\n\n    # Import the temporary file as a module and get the new class\n    new_module = _import_file(temp_file_path, \"temp_module\")\n    new_instances = getattr(new_module, class_name)\n\n    # Add from_instances method to the new class\n    _add_instances_conversion_methods(new_instances)\n\n    # Clean up the temporary file\n    os.remove(temp_file_path)\n\n    # Yield the new class\n    yield new_instances"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "\n    class_name = \"ScriptedInstances\" + str(os.getpid()) + str(_counter)\n\n    # Create the class definition\n    class_definition = f\"class {class_name}(torch.jit.ScriptModule):\\n\"\n    class_definition += \"    def __init__(self, image_size):\\n\"\n    class_definition += \"        super().__init__()\\n\"\n    for field in fields:\n        field_name, field_type = field\n        class_definition += f\"        self._{field_name} = {field_type}()\\n\"\n\n    # Create the module definition\n    module_definition = f\"import torch\\n\"\n    module_definition += f\"from detectron2.structures import Instances\\n\"\n    module_definition += f\"class Instances:\\n\"\n    module_definition += f\"    def __init__(self, image_size):\\n\"\n    module_definition += f\"        self.image_size = image_size\\n\"\n    for field in fields:\n        field_name, field_type = field\n        module_definition += f\"        self.{field_name} = None\\n\"\n\n    # Write the class and module definitions to a temporary file\n    with tempfile.NamedTemporaryFile(mode='w', delete=False) as temp_file:\n        temp_file.write(class_definition)\n        temp_file.write(module_definition)\n        temp_file.write(\"\\n_add_instances_conversion_methods(\" + class_name + \")\\n\")\n\n    # Import the temporary file as a module\n    module = _import_file(temp_file.name, \"instances_patch\")\n\n    # Increment the counter\n    _counter += 1\n\n    # Yield the new class\n    yield getattr(module, class_name)\n\n    # Clean up by removing the temporary file and resetting the counter\n    os.remove(temp_file.name)\n    _counter -= 1"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "\n    class_name = \"NewInstances\" + str(id(fields))\n    class_str = f\"class {class_name}:\\n\"\n    for field in fields:\n        class_str += f\"    {field[0]}: {field[1]}\\n\"\n\n    class_str += f\"    def __init__(self, image_size):\\n        self.image_size = image_size\\n\"\n\n    exec_globals = {}\n    exec(class_str, exec_globals)\n\n    newInstances = exec_globals[class_name]\n    _add_instances_conversion_methods(newInstances)\n\n    with ExitStack() as stack:\n        # Create a new module for the class\n        module = sys.modules[__name__]\n        new_module = type(module)(module.__name__)\n        stack.enter_context(mock.patch.dict(\"sys.modules\", {module.__name__: new_module}))\n\n        # Write the class to a temporary file and import it\n        with tempfile.NamedTemporaryFile(\"w\", delete=False) as f:\n            f.write(class_str)\n            fpath = f.name\n            f.close()\n            stack.callback(os.remove, fpath)\n            new_module = _import_file(fpath, module.__name__)\n\n        # Set up the environment for torchscript to recognize and work with the new class\n        stack.enter_context(mock.patch(\"torch.jit._recursive.concrete_type_store.type_store\", clear=True))\n        stack.enter_context(mock.patch(\"torch.jit._state._jit_caching_layer\", clear=True))\n        _clear_jit_cache()\n\n        yield newInstances"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "\n    class_name = \"NewInstances\" + str(id(fields))\n    fields_str = \"\\n    \".join([f\"{field[0]}: {field[1]}\" for field in fields])\n    new_instances_code = f\"\"\"\nimport torch\nfrom detectron2.structures import Instances\n\nclass {class_name}(Instances):\n    def __init__(self, image_size):\n        super().__init__(image_size)\n        {fields_str}\n    \"\"\"\n\n    # Create a temporary file and write the new_instances_code to it\n    temp_file = tempfile.NamedTemporaryFile(mode=\"w\", delete=False)\n    temp_file.write(new_instances_code)\n    temp_file.close()\n\n    # Import the temporary file as a module\n    temp_module = _import_file(temp_file.name, \"temp_module\")\n\n    # Add from_instances method to the new class\n    _add_instances_conversion_methods(temp_module.__dict__[class_name])\n\n    # Yield the new class\n    yield temp_module.__dict__[class_name]\n\n    # Clean up\n    os.unlink(temp_file.name)\n    _clear_jit_cache()"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "\n    class_name = \"ScriptedInstances\" + str(_counter)\n    _counter += 1\n\n    # Define the class string\n    class_str = f\"\"\"\n    import torch\n    from detectron2.structures import Instances\n\n    class {class_name}(Instances):\n        def __init__(self, image_size):\n            super().__init__(image_size)\n    \"\"\"\n\n    for field in fields:\n        field_name, field_type = field\n        class_str += f\"        {field_name}: {field_type}\\n\"\n\n    class_str += f\"\"\"\n    _add_instances_conversion_methods({class_name})\n\n    return {class_name}\n    \"\"\"\n\n    # Create a temporary file and write the class string to it\n    with tempfile.NamedTemporaryFile(mode=\"w\", delete=False) as temp_file:\n        temp_file.write(class_str)\n        temp_file_path = temp_file.name\n\n    # Import the temporary file as a module\n    module = _import_file(temp_file_path, \"instances\")\n\n    # Set up the environment for torchscript to recognize the new class\n    with ExitStack() as stack:\n        stack.enter_context(mock.patch.dict(sys.modules, {module.__name__: module}))\n        stack.enter_context(mock.patch.dict(os.environ, {\"PYTORCH_JIT\": \"0\"}))\n        stack.enter_context(mock.patch(\"torch.jit._recursive.concrete_type_store.type_store\", clear=True))\n        stack.enter_context(mock.patch(\"torch.jit._state._jit_caching_layer\", clear=True))\n\n        # Yield the new class\n        yield getattr(module, class_name)\n\n    # Clean up by removing the temporary file\n    os.remove(temp_file_path)"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "\n    class_name = \"NewInstances\" + str(_counter)\n\n    # Define the new class\n    class NewInstances(Instances):\n        def __init__(self, image_size):\n            super().__init__(image_size)\n            for field_name, field_type in fields:\n                setattr(self, field_name, field_type)\n\n    # Add from_instances method to the new class\n    _add_instances_conversion_methods(NewInstances)\n\n    # Create a new module for the class\n    module_code = f\"\"\"\n    import torch\n    from detectron2.structures import Instances\n    class {class_name}(Instances):\n        def __init__(self, image_size):\n            super().__init__(image_size)\n    \"\"\"\n    for field_name, field_type in fields:\n        module_code += f\"        {field_name}: {field_type.__name__}\\n\"\n\n    # Write the module to a temporary file\n    with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as f:\n        f.write(module_code)\n        module_path = f.name\n\n    # Import the module\n    module = _import_file(module_path, class_name)\n\n    # Set up the environment for torchscript\n    with ExitStack() as stack:\n        stack.enter_context(mock.patch.dict(sys.modules, {module.__name__: module}))\n        stack.enter_context(mock.patch.dict(os.environ, {\"TORCH_JIT_DISABLE_NEWCONV\": \"1\"}))\n        stack.enter_context(torch.jit._disable_tracing())\n        yield module.NewInstances\n\n    # Clean up by removing modifications\n    os.remove(module_path)\n    _clear_jit_cache()\n    _counter += 1"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "\n    class_name = \"NewInstances\" + str(id(fields))\n    fields_str = \"\\n\".join([f\"    {name}: {type}\" for name, type in fields])\n    code = f\"\"\"\nimport torch\nfrom detectron2.structures import Instances\n\nclass {class_name}(Instances):\n    def __init__(self, image_size):\n        self.image_size = image_size\n{fields_str}\n\n_add_instances_conversion_methods({class_name})\n    \"\"\"\n    # Create a temporary file and write the new class code into it\n    with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as f:\n        f.write(code)\n        temp_file_path = f.name\n\n    # Import the temporary file as a module\n    module = _import_file(temp_file_path, \"new_instances_module\")\n\n    # Set up the environment so that torchscript can recognize and work with this new class\n    _add_instances_conversion_methods(getattr(module, class_name))\n    _clear_jit_cache()\n\n    # Yield the new class that replaces 'Instances' for the duration of the context\n    yield getattr(module, class_name)\n\n    # Clean up by removing modifications\n    delattr(module, class_name)\n    os.remove(temp_file_path)\n    _clear_jit_cache()"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "\n    def create_class(fields):\n        class NewInstances:\n            def __init__(self, image_size):\n                self.image_size = image_size\n                for field_name, field_type in fields:\n                    setattr(self, field_name, field_type)\n\n            def get_fields(self):\n                return {field_name: getattr(self, field_name) for field_name, _ in fields}\n\n        return NewInstances\n\n    new_instances_class = create_class(fields)\n\n    @contextmanager\n    def _patched_instances():\n        global _counter\n        _counter += 1\n        module_name = f\"patched_instances_{_counter}\"\n        code = f\"import torch\\nfrom detectron2.structures import Instances\\nInstances = _import_file('Instances', 'detectron2.structures.instances', True)\\n\"\n        code += f\"class Instances({new_instances_class.__name__}):\\n    pass\\n\"\n        with ExitStack() as stack:\n            temp_file = stack.enter_context(tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False))\n            temp_file.write(code)\n            temp_file.close()\n            module = stack.enter_context(mock.patch.dict(sys.modules, {module_name: _import_file(module_name, temp_file.name)}))\n            _clear_jit_cache()\n            _add_instances_conversion_methods(new_instances_class)\n            yield new_instances_class\n\n    return _patched_instances()"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "\n    class_name = f\"InstancesPatched{_counter}\"\n    _counter += 1\n\n    # Define the new class\n    class_def = f\"class {class_name}:\\n\"\n    for field in fields:\n        class_def += f\"    {field[0]}: {field[1]}\\n\"\n\n    # Write the class to a temporary file\n    with tempfile.NamedTemporaryFile(mode=\"w\", delete=False) as temp_file:\n        temp_file.write(class_def)\n        temp_file_path = temp_file.name\n\n    # Import the temporary file as a module\n    module_name = os.path.splitext(os.path.basename(temp_file_path))[0]\n    module = _import_file(module_name, temp_file_path)\n\n    # Set up the environment for torchscript to recognize the new class\n    _add_instances_conversion_methods(module.__dict__[class_name])\n    _clear_jit_cache()\n\n    # Yield the new class\n    yield module.__dict__[class_name]\n\n    # Clean up by removing the temporary file\n    os.remove(temp_file_path)"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "\n    class_name = \"NewInstances\" + str(_counter)\n    _counter += 1\n\n    # Define the new class dynamically\n    class_def = f\"class {class_name}(Instances):\\n\"\n    for field in fields:\n        class_def += f\"    {field[0]}: {field[1]}\\n\"\n\n    # Create a temporary file and write the class definition to it\n    with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as temp_file:\n        temp_file.write(class_def)\n        temp_filename = temp_file.name\n\n    # Import the temporary file as a module\n    spec = _import_file(temp_filename, \"detectron2_temp\")\n    new_instances_module = spec.loader.load_module()\n\n    # Add from_instances method to the new class\n    _add_instances_conversion_methods(new_instances_module)\n\n    # Replace the original Instances class with the new class\n    original_instances_class = Instances\n    Instances.__class__ = new_instances_module.NewInstances\n\n    try:\n        yield new_instances_module.NewInstances\n    finally:\n        # Clean up by removing modifications\n        Instances.__class__ = original_instances_class\n        os.remove(temp_filename)"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "\n    class_name = \"NewInstances\" + str(_counter)\n    _counter += 1\n\n    # Define the new class with the specified fields\n    class_def = f\"class {class_name}(torch.jit.ScriptModule):\\n\"\n    class_def += \"    def __init__(self, image_size):\\n\"\n    class_def += \"        self.image_size = image_size\\n\"\n    for field in fields:\n        field_name, field_type = field\n        class_def += f\"        self._{field_name} : {field_type} = None\\n\"\n\n    # Create a temporary file to write the new class definition\n    with tempfile.NamedTemporaryFile(mode=\"w\", delete=False) as temp_file:\n        temp_file.write(class_def)\n        temp_file_path = temp_file.name\n\n    # Import the temporary file as a module\n    module_name = \"temp_module_\" + str(_counter)\n    _counter += 1\n    spec = importlib.util.spec_from_file_location(module_name, temp_file_path)\n    module = importlib.util.module_from_spec(spec)\n    sys.modules[module_name] = module\n    spec.loader.exec_module(module)\n\n    # Set up the environment for torchscript to recognize and work with the new class\n    _add_instances_conversion_methods(module.NewInstances)\n    _clear_jit_cache()\n\n    # Yield the new class that replaces 'Instances' for the duration of the context\n    yield module.NewInstances\n\n    # Clean up by removing modifications\n    del sys.modules[module_name]\n    os.remove(temp_file_path)"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    @contextmanager\n    def _patched_instances_context(fields):\n        global _counter\n        _counter += 1\n        class_name = f\"PatchedInstances{_counter}\"\n        code = f\"class {class_name}:\\n\"\n        for field in fields:\n            code += f\"    {field[0]}: {field[1]}\\n\"\n        code += f\"    def __init__(self, image_size):\\n\"\n        code += f\"        self.image_size = image_size\\n\"\n        code += f\"    def get_fields(self):\\n\"\n        code += f\"        return {{field[0]: None for field in fields}}\\n\"\n        exec(code, globals())\n        new_instances = locals()[class_name]\n        _add_instances_conversion_methods(new_instances)\n        try:\n            yield new_instances\n        finally:\n            _clear_jit_cache()\n\n    return _patched_instances_context(fields)"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    class_name = f\"Instances{str(_counter)}\"\n    _counter += 1\n\n    class_def = f\"class {class_name}:\\n\"\n    class_def += \"    def __init__(self, image_size):\\n\"\n    class_def += \"        self.image_size = image_size\\n\"\n\n    for field in fields:\n        field_name, field_type = field\n        class_def += f\"        self.{field_name} = {field_type}()\\n\"\n\n    with tempfile.NamedTemporaryFile(mode=\"w\", delete=False) as f:\n        f.write(class_def)\n        temp_file_path = f.name\n\n    module_name = os.path.splitext(os.path.basename(temp_file_path))[0]\n    module = _import_file(module_name, temp_file_path)\n\n    _add_instances_conversion_methods(module)\n    _clear_jit_cache()\n\n    try:\n        yield module\n    finally:\n        os.remove(temp_file_path)\n        _clear_jit_cache()"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    class_name = f\"Instances_{_counter}\"\n    _counter += 1\n\n    # Define the class dynamically based on the input fields\n    class_def = f\"class {class_name}:\\n\"\n    for field in fields:\n        class_def += f\"    {field[0]}: {field[1]}\\n\"\n\n    # Write the class to a temporary file and import it\n    with tempfile.TemporaryDirectory() as temp_dir:\n        temp_file = os.path.join(temp_dir, \"temp_instances.py\")\n        with open(temp_file, \"w\") as f:\n            f.write(class_def)\n\n        module = _import_file(temp_file, \"temp_module\")\n\n    # Set up the environment for torchscript to recognize and work with the new class\n    _add_instances_conversion_methods(module.Instances)\n    _clear_jit_cache()\n\n    # Yield the new class that replaces 'Instances' for the duration of the context\n    yield module.Instances\n\n    # Clean up by removing modifications\n    del module\n    _clear_jit_cache()"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "\n    class_name = f\"InstancesPatched{_counter}\"\n    _counter += 1\n\n    class_str = f\"class {class_name}:\\n\"\n    for field in fields:\n        class_str += f\"    {field[0]}: {field[1]}\\n\"\n\n    with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as f:\n        f.write(class_str)\n\n    module_name = os.path.basename(f.name).replace(\".py\", \"\")\n    spec = _import_file(module_name, f.name)\n    new_instances = getattr(spec, class_name)\n\n    _add_instances_conversion_methods(new_instances)\n\n    return new_instances"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "\n    class NewInstances(Instances):\n        pass\n\n    for field in fields:\n        setattr(NewInstances, field[0], field[1])\n\n    _add_instances_conversion_methods(NewInstances)\n\n    with ExitStack() as stack:\n        # Create a temporary file to write the new module\n        temp_module_file = stack.enter_context(tempfile.NamedTemporaryFile(mode=\"w\", delete=False, suffix=\".py\"))\n\n        # Write the new module to the temporary file\n        temp_module_file.write(f\"import torch\\nfrom detectron2.structures import Instances\\n\\nclass NewInstances(Instances):\\n    pass\\n\\n\")\n\n        for field in fields:\n            temp_module_file.write(f\"NewInstances.{field[0]} = {field[1]}\\n\")\n\n        # Close the file\n        temp_module_file.close()\n\n        # Add the temporary directory to the Python path\n        temp_dir = os.path.dirname(temp_module_file.name)\n        stack.enter_context(sys.path_importer_cache)\n        sys.path.insert(0, temp_dir)\n\n        # Import the temporary module\n        new_module = _import_file(temp_module_file.name, \"new_module\")\n\n        # Replace the original 'Instances' class with the new class\n        original_instances = sys.modules[\"detectron2.structures\"].Instances\n        sys.modules[\"detectron2.structures\"].Instances = new_module.NewInstances\n\n        try:\n            yield new_module.NewInstances\n        finally:\n            # Clean up by removing modifications\n            sys.modules[\"detectron2.structures\"].Instances = original_instances\n            sys.path.remove(temp_dir)\n            os.unlink(temp_module_file.name)"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    class_name = f\"Instances{_counter}\"\n    _counter += 1\n\n    # Define the class dynamically\n    class_str = f\"class {class_name}:\\n\"\n    for field in fields:\n        class_str += f\"    {field[0]}: {field[1]}\\n\"\n\n    # Create a temporary file and write the class to it\n    tmp_file = tempfile.NamedTemporaryFile(mode=\"w\", delete=False)\n    with open(tmp_file.name, \"w\") as f:\n        f.write(class_str)\n\n    # Import the temporary file as a module\n    module_name = os.path.splitext(os.path.basename(tmp_file.name))[0]\n    module = _import_file(module_name, tmp_file.name)\n\n    # Add conversion methods to the new class\n    _add_instances_conversion_methods(module)\n\n    # Set up the environment for torchscript to recognize the new class\n    with ExitStack() as stack:\n        stack.enter_context(mock.patch.dict(sys.modules, {module_name: module}))\n        stack.enter_context(mock.patch(\"torch.jit._recursive.concrete_type_store.type_store\", clear=True))\n        stack.enter_context(mock.patch(\"torch.jit._state._jit_caching_layer\", clear=True))\n\n        # Yield the new class\n        yield getattr(module, class_name)\n\n    # Clean up by removing the temporary file\n    os.remove(tmp_file.name)"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "\n    with torch.no_grad():\n        for param in model.parameters():\n            param.requires_grad = False"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "\n    # Create a context manager to patch the \"training\" attribute of every submodule in the model\n    @contextmanager\n    def patch_training_mode(model):\n        \"\"\"\n        A context manager to temporarily set the \"training\" attribute of every submodule in a given model to a constant value.\n        \"\"\"\n        original_training_states = {}  # Store the original training states of submodules\n        try:\n            for name, module in model.named_modules():\n                if hasattr(module, \"training\"):\n                    original_training_states[name] = module.training  # Store the original training state\n                    module.training = False  # Set the \"training\" attribute to False\n            yield  # Yield to the code inside the context\n        finally:\n            # Revert the \"training\" attribute back to its original state after the context exits\n            for name, module in model.named_modules():\n                if hasattr(module, \"training\") and name in original_training_states:\n                    module.training = original_training_states[name]\n\n    # Apply the patch_training_mode context manager to the input model\n    with patch_training_mode(model):\n        yield  # Yield to the code inside the context"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "\n    with torch.no_grad():\n        for param in model.parameters():\n            param.requires_grad = False"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    class _FreezeTrainingMode:\n        def __init__(self, model):\n            self.model = model\n            self.training_states = {}\n\n        def __enter__(self):\n            for name, module in self.model.named_modules():\n                if hasattr(module, \"training\"):\n                    self.training_states[module] = module.training\n                    module.training = False\n\n        def __exit__(self, *args):\n            for module, training_state in self.training_states.items():\n                module.training = training_state\n\n    return _FreezeTrainingMode(model)"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    class _FreezeTrainingMode:\n        def __init__(self, model):\n            self.model = model\n            self.training_states = {}\n\n        def __enter__(self):\n            for name, module in self.model.named_modules():\n                if hasattr(module, \"training\"):\n                    self.training_states[name] = module.training\n                    module.training = False\n\n        def __exit__(self, *args):\n            for name, module in self.model.named_modules():\n                if hasattr(module, \"training\"):\n                    module.training = self.training_states[name]\n\n    return _FreezeTrainingMode(model)"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "\n    class FreezeTrainingModeContext:\n        def __init__(self, model):\n            self.model = model\n            self.training_states = {}\n\n        def __enter__(self):\n            for name, module in self.model.named_modules():\n                if hasattr(module, \"training\"):\n                    self.training_states[name] = module.training\n                    module.training = False\n\n        def __exit__(self, type, value, traceback):\n            for name, module in self.model.named_modules():\n                if hasattr(module, \"training\"):\n                    module.training = self.training_states[name]\n\n    return FreezeTrainingModeContext(model)"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "\n    class FreezeTrainingModeContext:\n        def __init__(self, model):\n            self.model = model\n            self.training_states = {}\n\n        def __enter__(self):\n            for name, module in self.model.named_modules():\n                if hasattr(module, \"training\"):\n                    self.training_states[name] = module.training\n                    module.training = False\n\n        def __exit__(self, *args):\n            for name, module in self.model.named_modules():\n                if hasattr(module, \"training\"):\n                    module.training = self.training_states[name]\n\n    with FreezeTrainingModeContext(model):\n        yield"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "\n    class FreezeTrainingModeContext:\n        def __init__(self, model):\n            self.model = model\n            self.training_states = {}\n\n        def __enter__(self):\n            for name, module in self.model.named_modules():\n                if hasattr(module, \"training\"):\n                    self.training_states[name] = module.training\n                    module.training = False\n\n        def __exit__(self, *args):\n            for name, module in self.model.named_modules():\n                if hasattr(module, \"training\"):\n                    module.training = self.training_states[name]\n\n    return FreezeTrainingModeContext(model)"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    class FreezeTrainingModeContext:\n        def __init__(self, model):\n            self.model = model\n            self.training_states = {}\n\n        def __enter__(self):\n            for module in self.model.modules():\n                if hasattr(module, \"training\"):\n                    self.training_states[module] = module.training\n                    module.training = False\n\n        def __exit__(self, type, value, traceback):\n            for module, training_state in self.training_states.items():\n                module.training = training_state\n\n    with FreezeTrainingModeContext(model):\n        yield"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "\n    class FreezeTrainingModeContext:\n        def __init__(self, model):\n            self.model = model\n            self.training_states = {}\n\n        def __enter__(self):\n            for name, module in self.model.named_modules():\n                self.training_states[name] = module.training\n                module.training = False\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            for name, module in self.model.named_modules():\n                module.training = self.training_states[name]\n\n    return FreezeTrainingModeContext(model)"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "\n    class FreezeTrainingModeContext:\n        def __enter__(self):\n            for module in model.modules():\n                if hasattr(module, \"training\"):\n                    module._original_training_mode = module.training  # Store the original training mode\n                    module.training = False  # Set the training mode to False\n\n        def __exit__(self, exc_type, exc_val, exc_tb):\n            for module in model.modules():\n                if hasattr(module, \"_original_training_mode\"):\n                    module.training = module._original_training_mode  # Restore the original training mode\n                    del module._original_training_mode  # Delete the stored original training mode\n\n    return FreezeTrainingModeContext()"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "\n    class FreezeTrainingModeContext:\n        def __enter__(self):\n            for module in model.modules():\n                if hasattr(module, \"training\"):\n                    module.__orig_training = module.training\n                    module.training = False\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            for module in model.modules():\n                if hasattr(module, \"training\"):\n                    module.training = module.__orig_training\n                    del module.__orig_training\n\n    return FreezeTrainingModeContext()"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "\n    class _FreezeTrainingModeContext:\n        def __init__(self, model):\n            self.model = model\n            self.prev_training_states = {}\n\n        def __enter__(self):\n            for module in self.model.modules():\n                if isinstance(module, (nn.Module, nn.ModuleList, nn.Sequential)):\n                    self.prev_training_states[module] = module.training\n                    module.train(False)\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            for module, training_state in self.prev_training_states.items():\n                module.train(training_state)\n\n    return _FreezeTrainingModeContext(model)"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    class FreezeTrainingModeContext:\n        def __init__(self, model):\n            self.model = model\n            self.training_states = {}\n\n        def __enter__(self):\n            for module in self.model.modules():\n                if isinstance(module, torch.nn.Module):\n                    self.training_states[module] = module.training\n                    module.training = False\n\n        def __exit__(self, exc_type, exc_val, exc_tb):\n            for module, training_state in self.training_states.items():\n                module.training = training_state\n\n    with FreezeTrainingModeContext(model):\n        yield"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "\n    class FreezeTrainingModeContext:\n        def __enter__(self):\n            for module in model.modules():\n                if hasattr(module, \"training\"):\n                    module.__orig_training_state = module.training\n                    module.training = False\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            for module in model.modules():\n                if hasattr(module, \"__orig_training_state\"):\n                    module.training = module.__orig_training_state\n                    del module.__orig_training_state\n\n    return FreezeTrainingModeContext()"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    class FreezeTrainingModeContext:\n        def __init__(self, model):\n            self.model = model\n            self.training_states = {}\n\n        def __enter__(self):\n            for module in self.model.modules():\n                if isinstance(module, torch.nn.Module):\n                    self.training_states[module] = module.training\n                    module.training = False\n\n        def __exit__(self, type, value, traceback):\n            for module, training_state in self.training_states.items():\n                module.training = training_state\n\n    return FreezeTrainingModeContext(model)"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    with torch.no_grad():\n        for param in model.parameters():\n            param.requires_grad = False"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "\n    @contextmanager\n    def set_training_mode_const(model, mode):\n        \"\"\"\n        A context manager to temporarily set the \"training\" attribute of a model to a constant value.\n        \"\"\"\n        old_training_states = {}\n        for module in model.modules():\n            if isinstance(module, torch.nn.Module):\n                old_training_states[module] = module.training\n                module.training = mode\n        try:\n            yield\n        finally:\n            for module, old_training in old_training_states.items():\n                module.training = old_training\n\n    with set_training_mode_const(model, False):\n        yield"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "\n    with torch.no_grad():\n        for param in model.parameters():\n            param.requires_grad = False"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "\n    class FreezeTrainingModeContext:\n        def __enter__(self):\n            for module in model.modules():\n                module.training = False\n\n        def __exit__(self, exc_type, exc_val, exc_tb):\n            for module in model.modules():\n                module.training = True\n\n    return FreezeTrainingModeContext()"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.where(x < eps, jnp.sqrt(value_at_zero), jnp.sqrt(x))"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.where(x < eps, jnp.sqrt(value_at_zero), jnp.sqrt(x))"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.where(x < eps, jnp.sqrt(value_at_zero), jnp.sqrt(x))"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.where(x < eps, jnp.sqrt(value_at_zero), jnp.sqrt(x))"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.where(x < eps, jnp.sqrt(value_at_zero), jnp.sqrt(x))"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.where(x < eps, jnp.sqrt(value_at_zero), jnp.sqrt(x))"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.where(x < eps, jnp.sqrt(value_at_zero), jnp.sqrt(x))"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.where(x < eps, jnp.sqrt(value_at_zero), jnp.sqrt(x))"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.where(x < eps, jnp.sqrt(value_at_zero), jnp.sqrt(x))"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.where(x < eps, jnp.sqrt(value_at_zero), jnp.sqrt(x))"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.where(x < eps, jnp.sqrt(value_at_zero), jnp.sqrt(x))"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.where(x < eps, jnp.sqrt(value_at_zero), jnp.sqrt(x))"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.where(x < eps, jnp.sqrt(value_at_zero), jnp.sqrt(x))"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.where(x < eps, jnp.sqrt(value_at_zero), jnp.sqrt(x))"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.where(x < eps, jnp.sqrt(value_at_zero), jnp.sqrt(x))"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.where(x < eps, jnp.sqrt(value_at_zero), jnp.sqrt(x))"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.where(x < eps, jnp.sqrt(value_at_zero), jnp.sqrt(x))"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.where(x < eps, jnp.sqrt(value_at_zero), jnp.sqrt(x))"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.where(x < eps, jnp.sqrt(value_at_zero), jnp.sqrt(x))"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.where(x < eps, jnp.sqrt(value_at_zero), jnp.sqrt(x))"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  homogeneous_vectors = to_homogeneous(vectors)\n  transformed_vectors = jnp.matmul(homogeneous_vectors, transform.T)\n  return from_homogeneous(transformed_vectors)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  homogeneous_vectors = to_homogeneous(vectors)\n  transformed_vectors = jnp.matmul(homogeneous_vectors, transform.T)\n  return from_homogeneous(transformed_vectors)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  homogeneous_vectors = to_homogeneous(vectors)\n  transformed_vectors = jnp.matmul(homogeneous_vectors, transform.T)\n  return from_homogeneous(transformed_vectors)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  homogeneous_vectors = to_homogeneous(vectors)\n  transformed_vectors = matmul(homogeneous_vectors, transform.T)\n  return from_homogeneous(transformed_vectors)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  homogeneous_vectors = to_homogeneous(vectors)\n  transformed_vectors = jnp.matmul(homogeneous_vectors, transform.T)\n  return from_homogeneous(transformed_vectors)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  homogeneous_vectors = to_homogeneous(vectors)\n  transformed_vectors = matmul(homogeneous_vectors, transform.T)\n  return from_homogeneous(transformed_vectors)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  homogeneous_vectors = to_homogeneous(vectors)\n  transformed_vectors = matmul(homogeneous_vectors, transform.T)\n  return from_homogeneous(transformed_vectors)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  homogeneous_vectors = to_homogeneous(vectors)\n  transformed_vectors = jnp.matmul(homogeneous_vectors, transform.T)\n  return from_homogeneous(transformed_vectors)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  homogeneous_vectors = to_homogeneous(vectors)\n  transformed_vectors = jnp.matmul(homogeneous_vectors, transform.T)\n  return from_homogeneous(transformed_vectors)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  homogeneous_vectors = to_homogeneous(vectors)\n  transformed_homogeneous_vectors = jnp.matmul(homogeneous_vectors, jnp.transpose(transform))\n  transformed_vectors = from_homogeneous(transformed_homogeneous_vectors)\n  return transformed_vectors"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  homogeneous_vectors = to_homogeneous(vectors)\n  transformed_vectors = matmul(homogeneous_vectors, transform.T)\n  return from_homogeneous(transformed_vectors)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  homogeneous_vectors = to_homogeneous(vectors)\n  transformed_vectors = matmul(homogeneous_vectors, transform.T)\n  return from_homogeneous(transformed_vectors)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return jnp.dot(vectors, transform.T)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  homogeneous_vectors = to_homogeneous(vectors)\n  transformed_vectors = jnp.matmul(homogeneous_vectors, transform.T)\n  return from_homogeneous(transformed_vectors)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  homogeneous_vectors = to_homogeneous(vectors)\n  transformed_vectors = matmul(homogeneous_vectors, transform.T)\n  return from_homogeneous(transformed_vectors)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  homogeneous_vectors = to_homogeneous(vectors)\n  transformed_vectors = matmul(homogeneous_vectors, transform.T)\n  return from_homogeneous(transformed_vectors)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Add an extra dimension to the vectors to make them homogeneous\n  homogeneous_vectors = to_homogeneous(vectors)\n\n  # Apply the homogeneous transformation to the vectors\n  transformed_vectors = jnp.matmul(homogeneous_vectors, transform.T)\n\n  # Convert the transformed vectors back to non-homogeneous representation\n  return from_homogeneous(transformed_vectors)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return jnp.dot(vectors, transform.T)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  homogeneous_vectors = to_homogeneous(vectors)\n  transformed_vectors = jnp.matmul(homogeneous_vectors, transform.T)\n  return from_homogeneous(transformed_vectors)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  homogeneous_vectors = to_homogeneous(vectors)\n  transformed_vectors = jnp.matmul(homogeneous_vectors, transform.T)\n  return from_homogeneous(transformed_vectors)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  utils.assert_valid_stepfun(t, jnp.zeros_like(t))\n\n  # Calculate the width of each interval in t\n  tp_diff = jnp.diff(tp)\n  t_diff = jnp.diff(t)\n\n  # Calculate the weights for resampling\n  weights = jnp.minimum(tp_diff[Ellipsis, None], t_diff[Ellipsis, :, None])\n\n  # Resample the values based on the method chosen\n  if use_avg:\n    resampled_values = jnp.sum(vp * weights, axis=-1) / t_diff\n  else:\n    resampled_values = jnp.sum(vp * weights, axis=-1)\n\n  return resampled_values"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  utils.assert_valid_stepfun(t, jnp.ones_like(t))\n\n  # Compute the width of each interval in t.\n  td = jnp.diff(t)\n\n  # Compute the width of each original interval in tp.\n  tpd = jnp.diff(tp)\n\n  # Compute the value of the resampled step function at the new intervals defined by t.\n  if use_avg:\n    # Compute the average value, weighted by the width of each interval in t.\n    v = jnp.zeros(t.shape[:-1] + (1,))\n    for i in range(len(t)):\n      mask = (tp >= t[i]) & (tp <= t[i + 1])\n      v = v.at[i].set(jnp.sum(vp[mask] * tpd[mask]) / td[i])\n  else:\n    # Sum the values of the step function for each interval in t.\n    v = jnp.zeros(t.shape[:-1] + (1,))\n    for i in range(len(t)):\n      mask = (tp >= t[i]) & (tp <= t[i + 1])\n      v = v.at[i].set(jnp.sum(vp[mask]))\n\n  return v"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(t, vp)\n\n  # Compute the widths of the original intervals.\n  dt = jnp.diff(tp)\n\n  # Compute the widths of the new intervals.\n  dt_new = jnp.diff(t)\n\n  # Compute the weights for averaging based on the new interval widths.\n  weights = dt_new / jnp.sum(dt_new)\n\n  # Initialize the resampled values.\n  resampled_values = jnp.zeros(t.shape[:-1])\n\n  # Loop over the new intervals and compute the resampled values.\n  for i in range(len(t) - 1):\n      # Find the original intervals that overlap with the new interval.\n      overlap_indices = jnp.where((tp >= t[i]) & (tp <= t[i + 1]))\n\n      # Compute the sum of values or the average based on the resampling method.\n      if use_avg:\n          resampled_values[i] = jnp.sum(vp[overlap_indices] * weights[i])\n      else:\n          resampled_values[i] = jnp.sum(vp[overlap_indices])\n\n  return resampled_values"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  \n  # Compute the width of the original intervals\n  dt = jnp.diff(tp)\n  \n  # Compute the width of the new intervals\n  dt_new = jnp.diff(t)\n  \n  # Compute the weights for resampling based on the method chosen\n  if use_avg:\n    weights = dt_new / dt\n  else:\n    weights = jnp.where(dt > 0, dt_new / dt, 0)\n  \n  # Compute the resampled values\n  vp_resampled = jnp.sum(weights * vp, axis=-1)\n  \n  return vp_resampled"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n\n  # Compute the widths of the original intervals.\n  dt = jnp.diff(tp)\n\n  # Compute the widths of the new intervals.\n  dt_new = jnp.diff(t)\n\n  # Compute the values of the resampled step function at the new intervals.\n  if use_avg:\n    # Compute the weighted average of the values, weighted by the width of each interval.\n    vp_resampled = jnp.sum(vp * jnp.interp(t[:-1], tp, vp) * dt_new / dt, axis=-1)\n  else:\n    # Sum the values of the original step function for each interval in t.\n    vp_resampled = jnp.sum(jnp.interp(t[:-1], tp, vp), axis=-1)\n\n  return vp_resampled"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n\n  # Compute the width of the original intervals.\n  dt = jnp.diff(tp)\n\n  # If use_avg is True, compute the weights for averaging.\n  if use_avg:\n      weights = dt / jnp.sum(dt)\n  else:\n      weights = dt\n\n  # Compute the resampled values by summing or averaging the original values.\n  resampled_values = jnp.sum(\n      jnp.where(\n          (t[..., None] >= tp[:-1]) & (t[..., None] < tp[1:]),\n          vp * weights,\n          0\n      ),\n      axis=-1\n  )\n\n  return resampled_values"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n\n  # Calculate the width of each interval\n  dt = jnp.diff(t)\n\n  # Calculate the width of each original interval\n  dt_p = jnp.diff(tp)\n\n  # Calculate the weights for each original interval based on the resampling method\n  if use_avg:\n    weights = vp * dt_p / dt\n  else:\n    weights = vp\n\n  # Interpolate the weights to the new intervals defined by t\n  resampled_values = math.sorted_interp(t, tp, weights, utils.device_is_tpu())\n\n  return resampled_values"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  # Compute the width of the original intervals\n  dt = jnp.diff(tp)\n  \n  # Compute the width of the new intervals\n  dt_new = jnp.diff(t)\n  \n  # Compute the weights for resampling based on the width of the new intervals\n  if use_avg:\n    weights = dt_new / dt\n  else:\n    weights = jnp.where(dt == 0, 0, dt_new / dt)\n  \n  # Resample the values of the step function at the new intervals\n  vp_resampled = jnp.sum(weights * vp, axis=-1)\n  \n  return vp_resampled"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n\n  # Calculate the width of the original intervals\n  dt = jnp.diff(tp)\n\n  # Calculate the width of the new intervals\n  dt_new = jnp.diff(t)\n\n  # Calculate the value for each new interval\n  if use_avg:\n    # Calculate the weighted average of the values for each new interval\n    new_values = jnp.zeros(t.shape[:-1])\n    for i in range(len(t) - 1):\n      # Find the original intervals that overlap with the new interval\n      overlap = jnp.logical_and(tp[:-1] < t[i + 1], tp[1:] > t[i])\n      # Calculate the fraction of the original interval that overlaps with the new interval\n      overlap_fraction = jnp.minimum(tp[1:], t[i + 1]) - jnp.maximum(tp[:-1], t[i])\n      # Calculate the weighted average of the values for the overlapping original intervals\n      weighted_values = vp[:-1] * overlap_fraction / dt\n      # Sum the weighted values for the overlapping original intervals\n      new_values[i] = jnp.sum(weighted_values)\n\n    # Adjust the values to account for the width of the new intervals\n    new_values /= dt_new\n\n  else:\n    # Calculate the sum of the values for each new interval\n    new_values = jnp.zeros(t.shape[:-1])\n    for i in range(len(t) - 1):\n      # Find the original intervals that overlap with the new interval\n      overlap = jnp.logical_and(tp[:-1] < t[i + 1], tp[1:] > t[i])\n      # Calculate the fraction of the original interval that overlaps with the new interval\n      overlap_fraction = jnp.minimum(tp[1:], t[i + 1]) - jnp.maximum(tp[:-1], t[i])\n      # Sum the values for the overlapping original intervals\n      new_values[i] = jnp.sum(vp[:-1] * overlap_fraction / dt)\n\n  return new_values"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(t, vp)\n\n  # Calculate the width of each interval in t\n  dt = jnp.diff(t)\n\n  # Initialize the resampled values\n  resampled_values = jnp.zeros(t.shape[:-1])\n\n  # Loop through each interval in t\n  for i in range(len(t) - 1):\n      # Find the original intervals that overlap with the current interval in t\n      overlap_indices = jnp.where((tp >= t[i]) & (tp <= t[i + 1]))[0]\n\n      # If there are overlapping intervals\n      if len(overlap_indices) > 0:\n          # Calculate the contribution of each original interval to the current interval in t\n          interval_contributions = jnp.minimum(tp[overlap_indices + 1], t[i + 1]) - jnp.maximum(tp[overlap_indices], t[i])\n\n          # Calculate the weighted sum of values if use_avg is False\n          if not use_avg:\n              resampled_values[i] = jnp.sum(vp[overlap_indices] * interval_contributions)\n          # Calculate the weighted average of values if use_avg is True\n          else:\n              resampled_values[i] = jnp.sum(vp[overlap_indices] * interval_contributions) / dt[i]\n\n  return resampled_values"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(t, vp)\n\n  # Compute the width of the original intervals.\n  dt = jnp.diff(tp)\n  \n  # Compute the width of the new intervals.\n  dt_new = jnp.diff(t)\n  \n  # Compute the weights for resampling based on the method chosen.\n  if use_avg:\n    weights = dt_new / dt\n  else:\n    weights = jnp.where(dt > 0, dt_new / dt, 0)\n\n  # Compute the resampled values by interpolating the original values at the new time points.\n  vp_resampled = linspline.eval(t, tp, vp, weights)\n\n  return vp_resampled"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n\n  # Calculate the width of the original intervals\n  dt = jnp.diff(tp)\n\n  # Calculate the width of the new intervals\n  dt_new = jnp.diff(t)\n\n  # Calculate the weights for resampling based on the width of the new intervals\n  if use_avg:\n    weights = dt_new / dt\n  else:\n    weights = jnp.where(dt > 0, dt_new / dt, 0)\n\n  # Resample the step function values based on the weights\n  resampled_values = jnp.dot(vp, weights)\n\n  return resampled_values"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n\n  # Compute the width of the original intervals.\n  dt = jnp.diff(tp)\n\n  # Compute the width of the new intervals.\n  dt_new = jnp.diff(t)\n\n  # Compute the weights for resampling.\n  weights = jnp.where(dt_new > 0, jnp.minimum(1, dt / dt_new), 0)\n\n  # Compute the resampled values.\n  if use_avg:\n    resampled_values = jnp.sum(vp * weights, axis=-1) / jnp.maximum(eps, dt_new)\n  else:\n    resampled_values = jnp.sum(vp * weights, axis=-1)\n\n  return resampled_values"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n\n  # Calculate the width of the original intervals\n  dt = jnp.diff(tp)\n\n  # If use_avg is False, sum the values of the step function for each interval in t\n  if not use_avg:\n    # Calculate the weights for each original interval based on the width of the new intervals\n    weights = jnp.minimum(1, jnp.minimum(\n        jnp.maximum(0, jnp.minimum(t[Ellipsis, 1:], tp[Ellipsis, 1:]) - t[Ellipsis, :-1]),\n        jnp.maximum(0, t[Ellipsis, :-1] - tp[Ellipsis, :-1])\n    ) / dt)\n\n    # Resample the values of the step function at the new intervals using the calculated weights\n    resampled_values = jnp.sum(weights * vp, axis=-1)\n\n  # If use_avg is True, return the average value, weighted by the width of each interval in t\n  else:\n    # Calculate the weights for each original interval based on the width of the new intervals\n    weights = jnp.minimum(1, jnp.minimum(\n        jnp.maximum(0, jnp.minimum(t[Ellipsis, 1:], tp[Ellipsis, 1:]) - t[Ellipsis, :-1]),\n        jnp.maximum(0, t[Ellipsis, :-1] - tp[Ellipsis, :-1])\n    ) / dt)\n\n    # Calculate the weighted sum of the values of the step function at the original intervals\n    weighted_sum = jnp.sum(weights * vp, axis=-1)\n\n    # Calculate the width of the new intervals\n    dt_new = jnp.diff(t)\n\n    # Calculate the average value, weighted by the width of each interval in t\n    resampled_values = weighted_sum / dt_new\n\n  return resampled_values"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n\n  # Compute the width of each interval in t.\n  td = jnp.diff(t)\n\n  # Compute the width of each original interval.\n  tpd = jnp.diff(tp)\n\n  # Compute the value of the step function at the new intervals defined by t.\n  resampled_values = jnp.zeros(t.shape[:-1] + (vp.shape[-1],))\n\n  for i in range(len(t)):\n    # Find the original intervals that overlap with the new interval.\n    overlap = (tp[:-1] < t[i]) & (t[i] <= tp[1:])\n    # Compute the contribution of each original interval to the new interval.\n    contribution = jnp.where(overlap, vp * (tpd / td[i]), 0)\n    # Sum or average the contributions based on the resampling method.\n    if use_avg:\n      resampled_values[i] = jnp.sum(contribution, axis=-1)\n    else:\n      resampled_values[i] = jnp.sum(contribution, axis=-1) / td[i]\n\n  return resampled_values"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n\n  # Compute the widths of the original intervals.\n  dt = jnp.diff(tp)\n\n  # Compute the widths of the new intervals.\n  dt_new = jnp.diff(t)\n\n  # Compute the weights for each original interval based on the resampling method.\n  if use_avg:\n    weights = vp * dt / dt_new\n  else:\n    weights = vp\n\n  # Interpolate the weights into the new intervals.\n  resampled_values = jnp.sum(math.sorted_interp(t, tp, weights, utils.device_is_tpu()), axis=-1)\n\n  return resampled_values"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  \n  # Calculate the width of the original intervals\n  dt = jnp.diff(tp)\n  \n  # Calculate the width of the new intervals\n  dt_new = jnp.diff(t)\n  \n  # Calculate the weights for resampling based on the width of the new intervals\n  weights = dt_new / dt[:, None]\n  \n  # Interpolate the values of the original step function at the new time points\n  vp_new = math.sorted_interp(t, tp, vp, utils.device_is_tpu())\n  \n  if use_avg:\n      # Calculate the average value, weighted by the width of each interval in t\n      vp_resampled = jnp.sum(vp_new * weights, axis=-1)\n  else:\n      # Sum the values of the step function for each interval in t\n      vp_resampled = jnp.sum(vp_new, axis=-1)\n\n  return vp_resampled"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(t, vp)\n\n  # Compute the width of the original intervals.\n  dt = jnp.diff(tp)\n\n  # Compute the width of the new intervals.\n  dt_new = jnp.diff(t)\n\n  # Compute the values of the resampled step function.\n  if use_avg:\n    # Compute the average value, weighted by the width of each interval in t.\n    vp_resampled = jnp.sum(vp * jnp.interp(t, tp, vp) * dt / dt_new, axis=-1)\n  else:\n    # Sum the values of the step function for each interval in t.\n    vp_resampled = jnp.interp(t, tp, vp)\n\n  return vp_resampled"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  # Compute the width of each original interval\n  dt = jnp.diff(tp)\n  \n  # Compute the width of each new interval\n  dt_new = jnp.diff(t)\n  \n  # Interpolate the original values onto the new intervals\n  vp_new = math.sorted_interp(t, tp, vp, utils.device_is_tpu())\n  \n  if use_avg:\n      # Compute the weighted average of the values in each new interval\n      vp_avg = vp_new / dt_new\n      return vp_avg\n  else:\n      # Compute the sum of the values in each new interval\n      vp_sum = vp_new * dt / dt_new\n      return vp_sum"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  \n  # Compute the widths of the original intervals\n  dt = jnp.diff(tp)\n  \n  # Compute the widths of the new intervals\n  dt_new = jnp.diff(t)\n  \n  # Compute the values of the resampled step function\n  if use_avg:\n    # Compute the weighted average of the values based on the interval widths\n    weights = dt_new / dt\n    vp_resampled = jnp.sum(vp[Ellipsis, :-1] * weights, axis=-1)\n  else:\n    # Sum the values of the original step function for each interval in t\n    vp_resampled = query(t, tp, vp)\n  \n  return vp_resampled"}
{"namespace": "coord.contract", "completion": "  # Calculate the magnitude squared of the points\n  mag_squared = jnp.sum(x**2, axis=-1, keepdims=True)\n\n  # Scale the points towards the origin based on the mathematical formula\n  contracted_x = x / (1 + mag_squared)\n\n  return contracted_x"}
{"namespace": "coord.contract", "completion": "  return x / (1 + jnp.sum(x**2, axis=-1, keepdims=True))"}
{"namespace": "coord.contract", "completion": "    magnitude_squared = jnp.sum(x**2, axis=-1, keepdims=True)\n    scale = 1.0 / jnp.maximum(1.0, magnitude_squared)\n    return x * scale"}
{"namespace": "coord.contract", "completion": "  return x * jnp.sqrt(1.0 / jnp.sum(x**2, axis=-1, keepdims=True))"}
{"namespace": "coord.contract", "completion": "  return x / (1 + jnp.sum(x**2))"}
{"namespace": "coord.contract", "completion": "\n  # Ensure input is a JAX array\n  x = jnp.array(x)\n\n  # Calculate the magnitude squared of the points\n  magnitude_squared = jnp.sum(x**2, axis=-1, keepdims=True)\n\n  # Scale the points based on the magnitude squared\n  scaled_points = x / (1 + magnitude_squared)\n\n  return scaled_points"}
{"namespace": "coord.contract", "completion": "  # Calculate the magnitude squared of the input points\n  magnitude_squared = jnp.sum(x**2, axis=-1, keepdims=True)\n  \n  # Define the contraction factor based on the magnitude squared\n  contraction_factor = 1 / (1 + magnitude_squared)\n  \n  # Scale the input points towards the origin\n  contracted_points = x * contraction_factor\n  \n  return contracted_points"}
{"namespace": "coord.contract", "completion": "  # Calculate the magnitude squared of the points\n  mag_sq = jnp.sum(x**2, axis=-1, keepdims=True)\n\n  # Calculate the scaling factor based on the mathematical formula (Equation 10 from the paper)\n  scale_factor = 1.0 / (1.0 + mag_sq)\n\n  # Scale the input array of points towards the origin\n  scaled_points = x * scale_factor\n\n  return scaled_points"}
{"namespace": "coord.contract", "completion": "    magnitude_squared = jnp.sum(jnp.square(x), axis=-1, keepdims=True)\n    scale = jnp.clip(1.0 - magnitude_squared, a_min=0.0, a_max=None)\n    return x * scale"}
{"namespace": "coord.contract", "completion": "  return x / (1 + jnp.sum(x**2))"}
{"namespace": "coord.contract", "completion": "  return x / (1 + jnp.sum(x**2))"}
{"namespace": "coord.contract", "completion": "  return x / (1 + jnp.sum(x**2))"}
{"namespace": "coord.contract", "completion": "  magnitude_squared = jnp.sum(x**2, axis=-1, keepdims=True)\n  scale = jnp.clip(1.0 - magnitude_squared, a_min=0.0, a_max=None)\n  return x * scale"}
{"namespace": "coord.contract", "completion": "  return x / (1 + jnp.sum(x**2))"}
{"namespace": "coord.contract", "completion": "  return x / (1 + jnp.sum(x**2))"}
{"namespace": "coord.contract", "completion": "  return x / (1 + jnp.sum(x**2))"}
{"namespace": "coord.contract", "completion": "  magnitude_squared = jnp.sum(x**2, axis=-1, keepdims=True)\n  scale_factor = 1.0 / (1.0 + magnitude_squared)\n  return x * scale_factor"}
{"namespace": "coord.contract", "completion": "  return x / (1 + jnp.sum(x**2))"}
{"namespace": "coord.contract", "completion": "  return x / (1 + jnp.sum(x**2))"}
{"namespace": "coord.contract", "completion": "  magnitude_squared = jnp.sum(x**2, axis=-1)\n  scale = 1 / (1 + magnitude_squared)\n  return x * jnp.expand_dims(scale, axis=-1)"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = (1 + jnp.sqrt(1 + 4 * x_mag_sq)) / 2\n  x = z / scale\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = 1 / (1 - jnp.sqrt(1 - 0.25 * x_mag_sq))\n  x = scale * z\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = 1 / (1 - jnp.sqrt(1 - x_mag_sq))\n  x = scale * z\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = 1 / (1 - jnp.sqrt(1 - 0.25 * x_mag_sq))\n  x = scale * z\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = 1 / (1 - jnp.sqrt(1 - x_mag_sq))\n  x = scale * z\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = 1 / (1 - jnp.sqrt(1 - 0.25 * x_mag_sq))\n  x = scale * z\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = (jnp.sqrt(1 + 4 * x_mag_sq) - 1) / (2 * x_mag_sq)\n  x = z / scale\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = 1 / (1 - jnp.sqrt(1 - x_mag_sq))\n  x = scale * z\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = 1 / (2 * (1 - jnp.sqrt(1 - 4 * x_mag_sq)))\n  x = scale * z\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = 1 / (1 - jnp.sqrt(1 - 0.25 * x_mag_sq))\n  x = scale * z\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = (1 + jnp.sqrt(1 + 4 * x_mag_sq)) / 2\n  x = z / scale\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = (1 + jnp.sqrt(1 + 4 * x_mag_sq)) / 2\n  x = z / scale\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = 1 / (1 - jnp.sqrt(1 - x_mag_sq))\n  x = scale * z\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = 1 / (2 * (1 - jnp.sqrt(1 - 4 * x_mag_sq)))\n  x = scale * z\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = 1 / (1 - jnp.sqrt(1 - x_mag_sq))\n  x = scale * z\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = 1 / (1 - jnp.sqrt(1 - x_mag_sq))\n  x = scale * z\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = 1 / (1 - jnp.sqrt(1 - x_mag_sq))\n  x = scale * z\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = (1 + jnp.sqrt(1 + 4 * x_mag_sq)) / 2\n  x = z / scale\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = 1 / (1 - jnp.sqrt(1 - 0.25 * x_mag_sq))\n  x = scale * z\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.sum(z**2, axis=-1, keepdims=True)\n  scale = 1 / (1 - jnp.sqrt(1 - x_mag_sq))\n  x = scale * z\n  return x"}
{"namespace": "grid_utils.trilerp", "completion": "\n  if datastructure == 'grid':\n      return resample.trilerp(values, coordinates)\n  elif datastructure == 'hash':\n      return hash_resample.trilerp(values, coordinates)\n  else:\n      raise ValueError(\"Invalid datastructure. Supported data structures are 'grid' or 'hash'.\")"}
{"namespace": "grid_utils.trilerp", "completion": "    if datastructure == 'grid':\n        return resample.trilerp(values, coordinates)\n    elif datastructure == 'hash':\n        return hash_resample.trilerp(values, coordinates)\n    else:\n        raise ValueError(\"Invalid datastructure. Only 'grid' or 'hash' are supported as valid data structures.\")"}
{"namespace": "grid_utils.trilerp", "completion": "\n    if datastructure == 'grid':\n        return resample.trilinear_interpolation(values, coordinates)\n    elif datastructure == 'hash':\n        return hash_resample.hash_trilinear_interpolation(values, coordinates)\n    else:\n        raise ValueError(\"Invalid datastructure. Supported data structures are 'grid' or 'hash'.\")"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return resample.trilinear_interpolation(values, coordinates)\n  elif datastructure == 'hash':\n    return hash_resample.trilinear_interpolation_hash(values, coordinates)\n  else:\n    raise ValueError(\"Invalid datastructure. Supported options are 'grid' or 'hash'.\")"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return resample.trilinear_interpolation(values, coordinates)\n  elif datastructure == 'hash':\n    return hash_resample.trilinear_interpolation(values, coordinates)\n  else:\n    raise ValueError(\"Invalid datastructure. Supported data structures are 'grid' or 'hash'.\")"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n      return resample.trilinear_interpolation(values, coordinates)\n  elif datastructure == 'hash':\n      return hash_resample.trilinear_interpolation(values, coordinates)\n  else:\n      raise ValueError(\"Invalid datastructure. Only 'grid' or 'hash' are supported as valid data structures.\")"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return resample.trilinear_interpolation(values, coordinates)\n  elif datastructure == 'hash':\n    return hash_resample.trilinear_interpolation(values, coordinates)\n  else:\n    raise ValueError(\"Invalid datastructure. Supported data structures are 'grid' or 'hash'.\")"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return resample.trilerp(values, coordinates)\n  elif datastructure == 'hash':\n    return hash_resample.trilerp(values, coordinates)\n  else:\n    raise ValueError(\"Invalid datastructure. Supported options are 'grid' or 'hash'.\")"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure not in ['grid', 'hash']:\n    raise ValueError(\"Invalid datastructure. Supported options are 'grid' or 'hash'.\")\n\n  if datastructure == 'grid':\n    return resample.trilinear_interpolation(values, coordinates)\n  elif datastructure == 'hash':\n    return hash_resample.trilinear_interpolation(values, coordinates)"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n      return resample.trilinear_interpolation(values, coordinates)\n  elif datastructure == 'hash':\n      return hash_resample.trilinear_interpolation(values, coordinates)\n  else:\n      raise ValueError(\"Invalid datastructure. Must be 'grid' or 'hash'.\")"}
{"namespace": "grid_utils.trilerp", "completion": "\n  if datastructure == 'grid':\n      return resample.trilinear_interpolation(values, coordinates)\n  elif datastructure == 'hash':\n      return hash_resample.trilinear_interpolation(values, coordinates)\n  else:\n      raise ValueError(\"Invalid datastructure. Only 'grid' or 'hash' are supported as valid data structures.\")"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n      return resample.trilinear_interpolation(values, coordinates)\n  elif datastructure == 'hash':\n      return hash_resample.trilinear_interpolation(values, coordinates)\n  else:\n      raise ValueError(\"Invalid datastructure. Supported data structures are 'grid' and 'hash'.\")"}
{"namespace": "grid_utils.trilerp", "completion": "\n  if datastructure == 'grid':\n    return resample.trilinear_interpolation(values, coordinates)\n  elif datastructure == 'hash':\n    return hash_resample.trilinear_interpolation(values, coordinates)\n  else:\n    raise ValueError(\"Invalid datastructure. Supported data structures are 'grid' and 'hash'.\")"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return resample.trilinear_interpolation(values, coordinates)\n  elif datastructure == 'hash':\n    return hash_resample.trilinear_interpolation(values, coordinates)\n  else:\n    raise ValueError(\"Invalid datastructure. Only 'grid' or 'hash' are supported as valid data structures.\")"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n      return resample.trilinear_interpolation(values, coordinates)\n  elif datastructure == 'hash':\n      return hash_resample.trilinear_interpolation(values, coordinates)\n  else:\n      raise ValueError(\"Invalid datastructure. Supported data structures are 'grid' and 'hash'.\")"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n      return resample.trilinear_interpolation(values, coordinates)\n  elif datastructure == 'hash':\n      return hash_resample.trilinear_interpolation(values, coordinates)\n  else:\n      raise ValueError(\"Invalid datastructure. Supported data structures are 'grid' or 'hash'.\")"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return resample.trilinear_interpolation(values, coordinates)\n  elif datastructure == 'hash':\n    return hash_resample.trilinear_interpolation(values, coordinates)\n  else:\n    raise ValueError(\"Invalid datastructure. Supported options are 'grid' or 'hash'.\")"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return resample.trilinear_interpolation(values, coordinates)\n  elif datastructure == 'hash':\n    return hash_resample.trilinear_interpolation(values, coordinates)\n  else:\n    raise ValueError(\"Invalid datastructure. Supported data structures are 'grid' and 'hash'.\")"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return resample.trilinear_interpolation(values, coordinates)\n  elif datastructure == 'hash':\n    return hash_resample.trilinear_interpolation(values, coordinates)\n  else:\n    raise ValueError(\"Invalid datastructure. Supported data structures are 'grid' and 'hash'.\")"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return resample.trilinear_interpolation(values, coordinates)\n  elif datastructure == 'hash':\n    return hash_resample.trilinear_interpolation(values, coordinates)\n  else:\n    raise ValueError(\"Invalid datastructure. Supported data structures are 'grid' and 'hash'.\")"}
{"namespace": "coord.track_linearize", "completion": "  # Linearize the function around the mean\n  fn_mean = fn(mean)\n\n  # Compute the Jacobian of the function at the mean\n  jacobian = jax.jacobian(fn)(mean)\n\n  # Transform the covariances using the Jacobian\n  fn_cov = jnp.einsum('...ij,...jk->...ik', jnp.einsum('...ij,...jk->...ik', jacobian, cov), jacobian)\n\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  # Linearize the function around the mean\n  fn_mean = fn(mean)\n\n  # Compute the Jacobian of the function at the mean\n  jacobian = jax.jacobian(fn)(mean)\n\n  # Transform the covariances using the Jacobian\n  fn_cov = jnp.einsum('...ij,...jk->...ik', jnp.einsum('...ji,...jk->...ik', jacobian, cov), jacobian)\n\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  # Apply the function to the mean\n  fn_mean = fn(mean)\n  \n  # Linearize the function around the mean\n  jacobian = jax.jacobian(fn)(mean)\n  \n  # Transform the covariances accordingly\n  fn_cov = jnp.einsum('...ij,...jk->...ik', jnp.einsum('...ij,...jk->...ik', jacobian, cov), jacobian)\n\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  # Linearize the function around the mean\n  fn_mean = fn(mean)\n\n  # Jacobian of the function at the mean\n  jacobian = jax.jacobian(fn)(mean)\n\n  # Transform the covariances using the linearized function\n  fn_cov = jnp.einsum('...ij,...jk->...ik', jnp.einsum('...ij,...jk->...ik', jacobian, cov), jacobian)\n\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  # Linearize the function around the mean\n  fn_mean = fn(mean)\n\n  # Compute the Jacobian of the function at the mean\n  jac_fn = jax.jacobian(fn)(mean)\n\n  # Transform the covariances using the Jacobian\n  fn_cov = jnp.einsum('...ij,...jk->...ik', jac_fn, jnp.einsum('...ik,...kj->...ij', cov, jac_fn))\n\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  # Linearize the function around the mean\n  fn_mean = fn(mean)\n\n  # Compute the Jacobian of the function at the mean\n  jacobian = jax.jacobian(fn)(mean)\n\n  # Transform the covariances using the linearized function and the Jacobian\n  fn_cov = jnp.einsum('...ij,...jk->...ik', jnp.einsum('...ij,...jk->...ik', jacobian, cov), jacobian)\n\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  # Linearize the function around the mean\n  fn_mean = fn(mean)\n\n  # Compute the Jacobian of the function at the mean\n  jacobian = jax.jacobian(fn)(mean)\n\n  # Transform the covariances using the linearized function\n  fn_cov = jnp.einsum('...ij,...jk->...ik', jnp.einsum('...ij,...jk->...ik', jacobian, cov), jacobian)\n\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  # Linearize the function around the mean\n  fn_mean = fn(mean)\n\n  # Compute the Jacobian of the function at the mean\n  jacobian = jax.jacobian(fn)(mean)\n\n  # Transform the covariances using the Jacobian\n  fn_cov = jnp.einsum('...ij,...jk->...ik', jnp.einsum('...ji,...jk->...ik', jacobian, cov), jacobian)\n\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  # Linearize the function around the mean\n  fn_mean = fn(mean)\n\n  # Calculate the Jacobian of the function at the mean\n  jacobian = jax.jacobian(fn)(mean)\n\n  # Transform the covariances using the Jacobian\n  fn_cov = jnp.einsum('...ij,...jk->...ik', jnp.einsum('...ij,...jk->...ik', jacobian, cov), jacobian)\n\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  # Linearize the function around the mean\n  fn_mean = fn(mean)\n\n  # Compute the Jacobian of the function at the mean\n  jacobian = jax.jacobian(fn)(mean)\n\n  # Transform the covariances using the linearized function\n  fn_cov = jnp.einsum('...ik,...kj->...ij', jnp.einsum('...ik,...kj->...ij', jacobian, cov), jacobian)\n\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  # Linearize the function around the mean\n  fn_mean = fn(mean)\n\n  # Calculate the Jacobian of the function at the mean\n  jacobian = jax.jacobian(fn)(mean)\n\n  # Transform the covariances using the Jacobian\n  fn_cov = jnp.einsum('...ij,...jk->...ik', jnp.einsum('...ij,...j->...i', jacobian, cov), jacobian)\n\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  # Linearize the function around the mean\n  fn_mean = fn(mean)\n\n  # Compute the Jacobian of the function at the mean\n  jacobian = jax.jacobian(fn)(mean)\n\n  # Transform the covariances using the Jacobian\n  fn_cov = jnp.einsum('...ij,...jk->...ik', jnp.einsum('...ij,...jk->...ik', jacobian, cov), jacobian)\n\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian of the function at the mean\n  jacobian = jax.jacobian(fn)(mean)\n\n  # Apply the function to the mean\n  fn_mean = fn(mean)\n\n  # Linearize the function to get the transformed covariances\n  fn_cov = jnp.einsum('...ij,...jk->...ik', jnp.einsum('...ij,...jk->...ik', jacobian, cov), jacobian.transpose())\n\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  # Linearize the function around the mean\n  fn_mean = fn(mean)\n\n  # Compute the Jacobian of the function at the mean\n  jacobian = jax.jacobian(fn)(mean)\n\n  # Transform the covariances using the Jacobian\n  fn_cov = jnp.einsum('...ij,...jk->...ik', jnp.einsum('...ij,...jk->...ik', jacobian, cov), jacobian)\n\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  # Linearize the function around the mean\n  fn_mean = fn(mean)\n\n  # Compute the Jacobian of the function at the mean\n  jacobian = jax.jacobian(fn)(mean)\n\n  # Transform the covariances using the Jacobian\n  fn_cov = jnp.einsum('...ij,...jk->...ik', jnp.einsum('...ij,...jk->...ik', jacobian, cov), jacobian)\n\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  # Apply the function to the mean\n  fn_mean = fn(mean)\n\n  # Compute the Jacobian of the function at the mean\n  jacobian_fn = jax.jacobian(fn)\n  jacobian = jacobian_fn(mean)\n\n  # Transform the covariances using the linearized function\n  fn_cov = jnp.einsum('...ij,...jk->...ik', jnp.einsum('...ji,...jk->...ik', jacobian, cov), jacobian)\n\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  # Linearize the function around the mean\n  fn_mean = fn(mean)\n\n  # Compute the Jacobian of the function at the mean\n  jacobian = jax.jacobian(fn)(mean)\n\n  # Transform the covariances using the linearized function\n  fn_cov = jnp.einsum('...ij,...jk->...ik', jnp.einsum('...ij,...jk->...ik', jacobian, cov), jacobian)\n\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  # Linearize the function around the mean\n  fn_mean = fn(mean)\n\n  # Compute the Jacobian of the function at the mean\n  jacobian = jax.jacobian(fn)(mean)\n\n  # Transform the covariances using the Jacobian\n  fn_cov = jnp.einsum('...ij,...jk->...ik', jnp.einsum('...ij,...jk->...ik', jacobian, cov), jacobian)\n\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  # Linearize the function around the mean\n  fn_mean = fn(mean)\n\n  # Compute the Jacobian of the function at the mean\n  jacobian = jax.jacobian(fn)(mean)\n\n  # Transform the covariances using the linearized function and its Jacobian\n  fn_cov = jnp.einsum('...ij,...jk->...ik', jnp.einsum('...ji,...jk->...ik', jacobian, cov), jacobian)\n\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  # Linearize the function around the mean\n  fn_mean = fn(mean)\n\n  # Compute the Jacobian of the function at the mean\n  jacobian = jax.jacobian(fn)(mean)\n\n  # Transform the covariances using the Jacobian\n  fn_cov = jnp.einsum('...ij,...jk->...ik', jnp.einsum('...ij,...jk->...ik', jacobian, cov), jacobian)\n\n  return fn_mean, fn_cov"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Compute the norm of the input array\n  x_norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  # Calculate the scaling factor based on the norm\n  scale = (2 * jnp.sqrt(x_norm) - 1) / x_norm\n  # Apply the scaling operation\n  z = scale * x\n  return z"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Calculate the norm of the input array\n  x_norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  \n  # Apply the isotropic scaling operation\n  scale = (2 * x_norm - 1) / x_norm\n  z = scale * x\n  \n  return z"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  scale = (2 * x_norm - 1) / x_norm\n  z = scale * x\n  return z"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded = expected_sin(\n      jnp.concatenate([scaled_x, scaled_x + 0.5 * jnp.pi], axis=-1),\n      jnp.concatenate([jnp.zeros_like(scaled_x)] * 2, axis=-1),\n  )\n  if append_identity:\n      return jnp.concatenate([x, encoded], axis=-1)\n  else:\n      return encoded"}
{"namespace": "coord.pos_enc", "completion": "  mean = x\n  var = jnp.ones_like(x)  # Assuming variance of 1 for simplicity\n\n  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = mean.shape[:-1] + (-1,)\n  scaled_mean = jnp.reshape(mean[Ellipsis, None, :] * scales[:, None], shape)\n  scaled_var = jnp.reshape(var[Ellipsis, None, :] * scales[:, None] ** 2, shape)\n\n  encoded = expected_sin(\n      jnp.concatenate([scaled_mean, scaled_mean + 0.5 * jnp.pi], axis=-1),\n      jnp.concatenate([scaled_var] * 2, axis=-1),\n  )\n\n  if append_identity:\n    return jnp.concatenate([x, encoded], axis=-1)\n  else:\n    return encoded"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded = expected_sin(\n      jnp.concatenate([scaled_x, scaled_x + 0.5 * jnp.pi], axis=-1),\n      jnp.concatenate([jnp.zeros_like(scaled_x)] * 2, axis=-1),\n  )\n  if append_identity:\n    encoded = jnp.concatenate([x, encoded], axis=-1)\n  return encoded"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded = expected_sin(\n      jnp.concatenate([scaled_x, scaled_x + 0.5 * jnp.pi], axis=-1),\n      jnp.concatenate([jnp.zeros_like(scaled_x)] * 2, axis=-1),\n  )\n  if append_identity:\n    encoded = jnp.concatenate([x, encoded], axis=-1)\n  return encoded"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded = expected_sin(\n      jnp.concatenate([scaled_x, scaled_x + 0.5 * jnp.pi], axis=-1),\n      jnp.concatenate([jnp.zeros_like(scaled_x)] * 2, axis=-1),\n  )\n  if append_identity:\n    encoded = jnp.concatenate([x, encoded], axis=-1)\n  return encoded"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded = expected_sin(\n      jnp.concatenate([scaled_x, scaled_x + 0.5 * jnp.pi], axis=-1),\n      jnp.concatenate([jnp.zeros_like(scaled_x)] * 2, axis=-1),\n  )\n  if append_identity:\n    encoded = jnp.concatenate([x, encoded], axis=-1)\n  return encoded"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[..., None, :] * scales[:, None], shape)\n  encoded = expected_sin(\n      jnp.concatenate([scaled_x, scaled_x + 0.5 * jnp.pi], axis=-1),\n      jnp.concatenate([jnp.zeros_like(scaled_x), jnp.zeros_like(scaled_x)], axis=-1),\n  )\n  if append_identity:\n    encoded = jnp.concatenate([x, encoded], axis=-1)\n  return encoded"}
{"namespace": "coord.pos_enc", "completion": "  scaled_mean = x * 2.0 ** jnp.arange(min_deg, max_deg)[:, None]\n  scaled_var = (2.0 ** jnp.arange(min_deg, max_deg)[:, None]) ** 2\n\n  encoded = expected_sin(\n      jnp.concatenate([scaled_mean, scaled_mean + 0.5 * jnp.pi], axis=-1),\n      jnp.concatenate([scaled_var] * 2, axis=-1),\n  )\n\n  if append_identity:\n    encoded = jnp.concatenate([x, encoded], axis=-1)\n\n  return encoded"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded = expected_sin(\n      jnp.concatenate([scaled_x, scaled_x + 0.5 * jnp.pi], axis=-1),\n      jnp.concatenate([jnp.zeros_like(scaled_x)] * 2, axis=-1),\n  )\n  if append_identity:\n    encoded = jnp.concatenate([x, encoded], axis=-1)\n  return encoded"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded = expected_sin(\n      jnp.concatenate([scaled_x, scaled_x + 0.5 * jnp.pi], axis=-1),\n      jnp.concatenate([jnp.zeros_like(scaled_x)] * 2, axis=-1),\n  )\n  if append_identity:\n    encoded = jnp.concatenate([x, encoded], axis=-1)\n  return encoded"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded = expected_sin(\n      jnp.concatenate([scaled_x, scaled_x + 0.5 * jnp.pi], axis=-1),\n      jnp.concatenate([jnp.zeros_like(scaled_x)] * 2, axis=-1),\n  )\n  if append_identity:\n    encoded = jnp.concatenate([x, encoded], axis=-1)\n  return encoded"}
{"namespace": "coord.pos_enc", "completion": "  scaled_mean = x * 2.0 ** jnp.arange(min_deg, max_deg)[:, None]\n  scaled_var = (2.0 ** jnp.arange(min_deg, max_deg)[:, None]) ** 2\n  encoded = expected_sin(\n      jnp.concatenate([scaled_mean, scaled_mean + 0.5 * jnp.pi], axis=-1),\n      jnp.concatenate([scaled_var] * 2, axis=-1),\n  )\n  if append_identity:\n    encoded = jnp.concatenate([x, encoded], axis=-1)\n  return encoded"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded = expected_sin(\n      jnp.concatenate([scaled_x, scaled_x + 0.5 * jnp.pi], axis=-1),\n      jnp.concatenate([jnp.zeros_like(scaled_x)] * 2, axis=-1),\n  )\n  if append_identity:\n    encoded = jnp.concatenate([x, encoded], axis=-1)\n  return encoded"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded = expected_sin(\n      jnp.concatenate([scaled_x, scaled_x + 0.5 * jnp.pi], axis=-1),\n      jnp.concatenate([scales[None, :] * 0.5, scales[None, :] * 0.5], axis=-1),\n  )\n  if append_identity:\n    encoded = jnp.concatenate([x, encoded], axis=-1)\n  return encoded"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded = expected_sin(\n      jnp.concatenate([scaled_x, scaled_x + 0.5 * jnp.pi], axis=-1),\n      jnp.concatenate([jnp.zeros_like(scaled_x)] * 2, axis=-1),\n  )\n  if append_identity:\n      encoded = jnp.concatenate([x, encoded], axis=-1)\n  return encoded"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded = expected_sin(\n      jnp.concatenate([scaled_x, scaled_x + 0.5 * jnp.pi], axis=-1),\n      jnp.concatenate([jnp.zeros_like(scaled_x)] * 2, axis=-1),\n  )\n  if append_identity:\n    encoded = jnp.concatenate([x, encoded], axis=-1)\n  return encoded"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded = expected_sin(\n      jnp.concatenate([scaled_x, scaled_x + 0.5 * jnp.pi], axis=-1),\n      jnp.concatenate([jnp.zeros_like(scaled_x)] * 2, axis=-1),\n  )\n  if append_identity:\n    encoded = jnp.concatenate([x, encoded], axis=-1)\n  return encoded"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded = expected_sin(\n      jnp.concatenate([scaled_x, scaled_x + 0.5 * jnp.pi], axis=-1),\n      jnp.concatenate([jnp.zeros_like(scaled_x)] * 2, axis=-1),\n  )\n  if append_identity:\n    encoded = jnp.concatenate([x, encoded], axis=-1)\n  return encoded"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded = expected_sin(\n      jnp.concatenate([scaled_x, scaled_x + 0.5 * jnp.pi], axis=-1),\n      jnp.concatenate([jnp.zeros_like(scaled_x)] * 2, axis=-1),\n  )\n  if append_identity:\n    encoded = jnp.concatenate([x, encoded], axis=-1)\n  return encoded"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  encoded = expected_sin(\n      jnp.concatenate([scaled_x, scaled_x + 0.5 * jnp.pi], axis=-1),\n      jnp.concatenate([scaled_x * 0, scaled_x * 0], axis=-1),\n  )\n  if append_identity:\n    encoded = jnp.concatenate([x, encoded], axis=-1)\n  return encoded"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance\n  scaled_mean = mean * (2 ** jnp.linspace(min_deg, max_deg - 1, mean.shape[-1]))\n  scaled_var = var * (2 ** (2 * jnp.linspace(min_deg, max_deg - 1, var.shape[-1])))\n\n  # Concatenate the scaled mean and variance\n  combined = jnp.concatenate((scaled_mean, scaled_var), axis=-1)\n\n  # Apply sinusoidal encoding\n  encoding = jnp.sin(combined)\n\n  return encoding"}
{"namespace": "coord.integrated_pos_enc", "completion": "  scaled_mean = mean * (2 ** jnp.linspace(min_deg, max_deg - 1, mean.shape[-1]))\n  scaled_var = var * (2 ** (2 * jnp.linspace(min_deg, max_deg - 1, var.shape[-1])))\n  encoded = jnp.concatenate([jnp.sin(scaled_mean), jnp.sin(scaled_var)], axis=-1)\n  return encoded"}
{"namespace": "coord.integrated_pos_enc", "completion": "    # Scale mean and variance\n    scaled_mean = mean / (2 ** min_deg)\n    scaled_var = var / (2 ** (2 * min_deg))\n\n    # Concatenate scaled mean and variance\n    concatenated = jnp.concatenate((scaled_mean, scaled_var), axis=-1)\n\n    # Apply sinusoidal encoding\n    encoding = jnp.concatenate((jnp.sin(concatenated), jnp.cos(concatenated)), axis=-1)\n\n    return encoding"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance\n  scaled_mean = mean * (2 ** jnp.arange(min_deg, max_deg))\n  scaled_var = var * (2 ** (2 * jnp.arange(min_deg, max_deg)))\n\n  # Concatenate the scaled mean and variance\n  concatenated = jnp.concatenate([scaled_mean, scaled_var])\n\n  # Apply sinusoidal encoding\n  encoded = jnp.sin(concatenated)\n\n  return encoded"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance\n  scaled_mean = mean * (2 ** jnp.arange(min_deg, max_deg))\n  scaled_var = var * (2 ** (2 * jnp.arange(min_deg, max_deg)))\n\n  # Concatenate the scaled mean and variance\n  concatenated = jnp.concatenate((scaled_mean, scaled_var), axis=-1)\n\n  # Apply sinusoidal encoding\n  encoding = jnp.sin(concatenated)\n\n  return encoding"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance\n  scaled_mean = mean * (2 ** jnp.arange(min_deg, max_deg))\n  scaled_var = var * (2 ** (2 * jnp.arange(min_deg, max_deg)))\n\n  # Concatenate the scaled mean and variance\n  concatenated = jnp.concatenate((scaled_mean, scaled_var), axis=-1)\n\n  # Apply sinusoidal encoding\n  encoded = jnp.sin(concatenated)\n\n  return encoded"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance\n  scaled_mean = mean * (2 ** jnp.linspace(min_deg, max_deg - 1, mean.shape[-1]))\n  scaled_var = var * (2 ** (2 * jnp.linspace(min_deg, max_deg - 1, var.shape[-1])))\n\n  # Concatenate the scaled mean and variance\n  concatenated_values = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n\n  # Apply sinusoidal encoding\n  encoded_values = jnp.sin(concatenated_values)\n\n  return encoded_values"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance\n  scaled_mean = mean * (2 ** jnp.arange(min_deg, max_deg))\n  scaled_var = var * (2 ** (2 * jnp.arange(min_deg, max_deg)))\n\n  # Concatenate the scaled mean and variance\n  concatenated = jnp.concatenate((scaled_mean, scaled_var), axis=-1)\n\n  # Apply sinusoidal encoding\n  encoded = jnp.sin(concatenated)\n\n  return encoded"}
{"namespace": "coord.integrated_pos_enc", "completion": "  scaled_mean = mean * (2 ** (min_deg - 1))\n  scaled_var = var * (2 ** (2 * min_deg - 2))\n\n  # Concatenate the scaled mean and variance\n  input_concat = jnp.concatenate((scaled_mean, scaled_var), axis=-1)\n\n  # Apply sinusoidal encoding\n  encoding = jnp.zeros((input_concat.shape[-1], max_deg - min_deg))\n  for i in range(max_deg - min_deg):\n    encoding[:, i] = jnp.sin(input_concat * (2 ** i))\n\n  return encoding"}
{"namespace": "coord.integrated_pos_enc", "completion": "    scaled_mean = mean * (2 ** jnp.linspace(min_deg, max_deg - 1, mean.shape[-1]))\n    scaled_var = var * (2 ** jnp.linspace(2 * min_deg, 2 * (max_deg - 1), mean.shape[-1]))\n\n    # Concatenate the scaled mean and variance\n    input_concat = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n\n    # Apply sinusoidal encoding\n    encoding = jnp.sin(input_concat)\n\n    return encoding"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance\n  scaled_mean = mean * (2 ** (min_deg - 1))\n  scaled_var = var * (2 ** (2 * (min_deg - 1)))\n\n  # Concatenate the scaled mean and variance\n  concatenated_values = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n\n  # Apply sinusoidal encoding\n  encoding = jnp.sin(concatenated_values)\n\n  return encoding"}
{"namespace": "coord.integrated_pos_enc", "completion": "    scaled_mean = mean * 2 ** jnp.linspace(min_deg, max_deg - 1, mean.shape[-1])\n    scaled_var = var * (2 ** jnp.linspace(min_deg, max_deg - 1, var.shape[-1])) ** 2\n    encoded = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n    encoded = jnp.sin(encoded)\n    return encoded"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance\n  scaled_mean = mean * (2 ** jnp.arange(min_deg, max_deg))\n  scaled_var = var * (2 ** (2 * jnp.arange(min_deg, max_deg)))\n\n  # Concatenate the scaled mean and variance\n  concatenated = jnp.concatenate((scaled_mean, scaled_var), axis=-1)\n\n  # Apply sinusoidal encoding\n  encoding = jnp.sin(concatenated)\n\n  return encoding"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale mean and variance\n  scaled_mean = mean * (2 ** jnp.arange(min_deg, max_deg))\n  scaled_var = var * (2 ** (2 * jnp.arange(min_deg, max_deg)))\n\n  # Concatenate scaled mean and variance\n  combined = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n\n  # Apply sinusoidal encoding\n  encoded = jnp.sin(combined)\n\n  return encoded"}
{"namespace": "coord.integrated_pos_enc", "completion": "  scaled_mean = mean * (2 ** jnp.linspace(min_deg, max_deg - 1, mean.shape[-1]))\n  scaled_var = var * (2 ** (2 * jnp.linspace(min_deg, max_deg - 1, var.shape[-1])))\n  encoded_values = jnp.concatenate([jnp.sin(scaled_mean), jnp.sin(scaled_var)], axis=-1)\n  return encoded_values"}
{"namespace": "coord.integrated_pos_enc", "completion": "  scaled_mean = mean * (2 ** (min_deg - 1))\n  scaled_var = var * (2 ** (2 * (min_deg - 1)))\n\n  # Concatenate the scaled mean and variance\n  input_concat = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n\n  # Apply sinusoidal encoding\n  encoding = jnp.concatenate([\n      jnp.sin(input_concat * (2 ** -i)) if i % 2 == 0\n      else jnp.cos(input_concat * (2 ** -i))\n      for i in range(min_deg, max_deg)\n  ], axis=-1)\n\n  return encoding"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance\n  scaled_mean = mean * (2 ** jnp.arange(min_deg, max_deg))\n  scaled_var = var * (2 ** (2 * jnp.arange(min_deg, max_deg)))\n\n  # Concatenate the scaled mean and variance\n  concatenated = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n\n  # Apply sinusoidal encoding\n  encoding = jnp.sin(concatenated)\n\n  return encoding"}
{"namespace": "coord.integrated_pos_enc", "completion": "  scaled_mean = mean * 2 ** jnp.linspace(min_deg, max_deg - 1, mean.shape[-1])\n  scaled_var = var * (2 ** (2 * jnp.linspace(min_deg, max_deg - 1, var.shape[-1])))\n  encoded = jnp.concatenate([jnp.sin(scaled_mean), jnp.sin(scaled_var)], axis=-1)\n  return encoded"}
{"namespace": "coord.integrated_pos_enc", "completion": "    scaled_mean = contract(mean)\n    scaled_var = contract(var)\n\n    # Concatenate the scaled mean and variance\n    scaled_concat = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n\n    # Apply sinusoidal encoding\n    degrees = jnp.arange(min_deg, max_deg, dtype=jnp.float32)\n    encoding = jnp.sin(scaled_concat[..., None] * (2 ** degrees[None]))\n\n    return encoding"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance\n  scaled_mean = mean * (2 ** jnp.linspace(min_deg, max_deg - 1, mean.shape[-1]))\n  scaled_var = var * (2 ** (2 * jnp.linspace(min_deg, max_deg - 1, var.shape[-1])))\n\n  # Concatenate the scaled mean and variance\n  concatenated_values = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n\n  # Apply sinusoidal encoding\n  encoded_values = jnp.sin(concatenated_values)\n\n  return encoded_values"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    det = jnp.linalg.det(cov)\n    isotropic_cov = det ** (1 / cov.shape[-1]) * jnp.eye(cov.shape[-1])\n  elif mode == 'accurate':\n    sign, logdet = jnp.linalg.slogdet(cov)\n    logdet /= cov.shape[-1]\n    isotropic_cov = jnp.exp(logdet) * jnp.eye(cov.shape[-1])\n  else:\n    raise ValueError(\"Invalid mode. Mode must be 'fast' or 'accurate'.\")\n  return isotropic_cov"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n      # Compute the determinant of the covariance matrix\n      det = jnp.linalg.det(cov)\n      \n      # Compute the isotropic scaling factor based on the determinant\n      isotropic_scale = jnp.abs(det) ** (-1 / cov.shape[-1])\n      \n      # Construct the isotropic covariance matrix with the same determinant\n      isotropic_cov = isotropic_scale * cov\n      \n  elif mode == 'accurate':\n      # Compute the logarithm of the determinant of the covariance matrix for stability\n      log_det = jnp.log(jnp.abs(jnp.linalg.det(cov)))\n      \n      # Compute the isotropic scaling factor based on the logarithm of the determinant\n      isotropic_scale = jnp.exp(-log_det / cov.shape[-1])\n      \n      # Construct the isotropic covariance matrix with the same determinant\n      isotropic_cov = isotropic_scale * cov\n      \n  else:\n      raise ValueError(\"Invalid mode. Please choose either 'fast' or 'accurate'.\")\n  \n  return isotropic_cov"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    # Compute the isotropic scaling factor using the determinant directly\n    det = jnp.linalg.det(cov)\n    isotropic_scale = jnp.abs(det) ** (-1 / cov.shape[-1])\n    # Apply the isotropic scaling factor to the covariance matrix\n    isotropic_cov = isotropic_scale * cov\n  elif mode == 'accurate':\n    # Compute the isotropic scaling factor using the logarithm of the determinant for stability\n    log_det = jnp.log(jnp.abs(jnp.linalg.det(cov)))\n    isotropic_scale = jnp.exp(-log_det / cov.shape[-1])\n    # Apply the isotropic scaling factor to the covariance matrix\n    isotropic_cov = isotropic_scale * cov\n  else:\n    raise ValueError(\"Invalid mode. Mode must be 'fast' or 'accurate'.\")\n\n  return isotropic_cov"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    # Compute the determinant of the covariance matrix\n    det = jnp.linalg.det(cov)\n    # Compute the isotropic scaling factor\n    isotropic_scale = jnp.abs(det) ** (-1 / cov.shape[-1])\n    # Construct the isotropic covariance matrix\n    isotropic_cov = isotropic_scale * jnp.eye(cov.shape[-1])\n    return isotropic_cov\n  elif mode == 'accurate':\n    # Compute the logarithm of the determinant of the covariance matrix\n    log_det = jnp.log(jnp.abs(jnp.linalg.det(cov)))\n    # Compute the isotropic scaling factor using the logarithm of the determinant\n    isotropic_scale = jnp.exp(-log_det / cov.shape[-1])\n    # Construct the isotropic covariance matrix\n    isotropic_cov = isotropic_scale * jnp.eye(cov.shape[-1])\n    return isotropic_cov\n  else:\n    raise ValueError(\"Invalid mode. Mode must be 'fast' or 'accurate'.\")"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    # Compute the determinant of the covariance matrix\n    det = jnp.linalg.det(cov)\n    # Compute the isotropic scaling factor\n    scale = jnp.abs(det) ** (1 / cov.shape[-1])\n    # Construct the isotropic covariance matrix\n    isotropic_cov = scale * jnp.eye(cov.shape[-1])\n  elif mode == 'accurate':\n    # Compute the logarithm of the determinant for stability\n    log_det = jnp.log(jnp.abs(jnp.linalg.det(cov)))\n    # Compute the isotropic scaling factor\n    scale = jnp.exp(log_det / cov.shape[-1])\n    # Construct the isotropic covariance matrix\n    isotropic_cov = scale * jnp.eye(cov.shape[-1])\n  else:\n    raise ValueError(\"Invalid mode. Mode must be 'fast' or 'accurate'.\")\n  return isotropic_cov"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    # Compute the determinant directly\n    det = jnp.linalg.det(cov)\n    isotropic_cov = det ** (1 / cov.shape[-1]) * jnp.eye(cov.shape[-1])\n  elif mode == 'accurate':\n    # Use the logarithm of the determinant for stability\n    sign, logdet = jnp.linalg.slogdet(cov)\n    det = jnp.exp(logdet)\n    isotropic_cov = det ** (1 / cov.shape[-1]) * jnp.eye(cov.shape[-1])\n  else:\n    raise ValueError(\"Invalid mode. Mode must be 'fast' or 'accurate'.\")\n  \n  return isotropic_cov"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    # Compute the determinant directly for isotropic scaling\n    det = jnp.linalg.det(cov)\n    isotropic_cov = det ** (1 / cov.shape[-1]) * jnp.eye(cov.shape[-1])\n  elif mode == 'accurate':\n    # Use the logarithm of the determinant for stability\n    log_det = jnp.log(jnp.abs(jnp.linalg.det(cov)))\n    isotropic_cov = jnp.exp(log_det / cov.shape[-1]) * jnp.eye(cov.shape[-1])\n  else:\n    raise ValueError(\"Invalid mode. Please choose 'fast' or 'accurate'.\")\n\n  return isotropic_cov"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    # Compute the determinant of the covariance matrix\n    det = jnp.linalg.det(cov)\n    # Compute the isotropic scaling factor\n    scale = jnp.abs(det) ** (1 / cov.shape[-1])\n    # Construct the isotropic covariance matrix\n    isotropic_cov = scale * jnp.eye(cov.shape[-1])\n    return isotropic_cov\n  elif mode == 'accurate':\n    # Compute the logarithm of the determinant of the covariance matrix for stability\n    log_det = jnp.log(jnp.abs(jnp.linalg.det(cov)))\n    # Compute the isotropic scaling factor\n    scale = jnp.exp(log_det / cov.shape[-1])\n    # Construct the isotropic covariance matrix\n    isotropic_cov = scale * jnp.eye(cov.shape[-1])\n    return isotropic_cov\n  else:\n    raise ValueError(\"Invalid mode. Mode must be 'fast' or 'accurate'.\")"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    det = jnp.linalg.det(cov)\n    isotropic_cov = jnp.cbrt(jnp.abs(det)) * jnp.eye(cov.shape[-1])\n  elif mode == 'accurate':\n    sqrt_cov, (eigvec, eigval) = sqrtm(cov, return_eigs=True)\n    log_det = jnp.sum(jnp.log(eigval), axis=-1)\n    log_det_mean = jnp.mean(log_det, axis=-1, keepdims=True)\n    isotropic_cov = jnp.exp((log_det_mean / cov.shape[-1])) * jnp.eye(cov.shape[-1])\n  else:\n    raise ValueError(\"Invalid mode. Please choose 'fast' or 'accurate'.\")\n\n  return isotropic_cov"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    # Compute the isotropic scaling factor using the determinant directly\n    det = jnp.linalg.det(cov)\n    isotropic_scale = jnp.abs(det) ** (-1 / cov.shape[-1])\n    # Apply the isotropic scaling to the covariance matrix\n    isotropic_cov = isotropic_scale * cov\n  elif mode == 'accurate':\n    # Compute the isotropic scaling factor using the logarithm of the determinant for stability\n    log_det = jnp.log(jnp.abs(jnp.linalg.det(cov)))\n    isotropic_scale = jnp.exp(-log_det / cov.shape[-1])\n    # Apply the isotropic scaling to the covariance matrix\n    isotropic_cov = isotropic_scale * cov\n  else:\n    raise ValueError(\"Invalid mode. Mode must be 'fast' or 'accurate'.\")\n  return isotropic_cov"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    # Compute the determinant of the covariance matrix\n    det = jnp.linalg.det(cov)\n    \n    # Compute the isotropic scaling factor\n    isotropic_scale = jnp.abs(det) ** (-1 / cov.shape[-1])\n    \n    # Construct the isotropic covariance matrix\n    isotropic_cov = isotropic_scale * jnp.eye(cov.shape[-1])\n    \n    return isotropic_cov\n  elif mode == 'accurate':\n    # Compute the logarithm of the determinant of the covariance matrix\n    log_det = jnp.log(jnp.abs(jnp.linalg.det(cov)))\n    \n    # Compute the isotropic scaling factor\n    isotropic_scale = jnp.exp(-log_det / cov.shape[-1])\n    \n    # Construct the isotropic covariance matrix\n    isotropic_cov = isotropic_scale * jnp.eye(cov.shape[-1])\n    \n    return isotropic_cov\n  else:\n    raise ValueError(\"Invalid mode. Mode must be 'fast' or 'accurate'.\")"}
{"namespace": "coord.isotropize", "completion": "  if mode not in ['fast', 'accurate']:\n    raise ValueError(\"Mode must be 'fast' or 'accurate'\")\n\n  if mode == 'fast':\n    det = jnp.linalg.det(cov)\n    isotropic_cov = jnp.cbrt(jnp.abs(det)) * jnp.eye(cov.shape[-1])\n  else:\n    sign, logdet = jnp.linalg.slogdet(cov)\n    logdet /= 3\n    isotropic_cov = jnp.exp(logdet) * jnp.eye(cov.shape[-1])\n\n  return isotropic_cov"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    # Compute the determinant directly for fast mode\n    det = jnp.linalg.det(cov)\n    isotropic_cov = jnp.power(det, 1/cov.shape[-1]) * jnp.eye(cov.shape[-1])\n  elif mode == 'accurate':\n    # Use the logarithm of the determinant for stability in accurate mode\n    sign, logdet = jnp.linalg.slogdet(cov)\n    logdet /= cov.shape[-1]\n    isotropic_cov = jnp.exp(logdet) * jnp.eye(cov.shape[-1])\n  else:\n    raise ValueError(\"Invalid mode. Mode must be 'fast' or 'accurate'.\")\n\n  return isotropic_cov"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    # Compute the determinant directly for fast mode\n    det = jnp.linalg.det(cov)\n    isotropic_cov = det ** (1 / cov.shape[-1]) * jnp.eye(cov.shape[-1])\n  elif mode == 'accurate':\n    # Use the logarithm of the determinant for stability in accurate mode\n    sign, logdet = jnp.linalg.slogdet(cov)\n    logdet /= cov.shape[-1]\n    isotropic_cov = jnp.exp(logdet) * jnp.eye(cov.shape[-1])\n  else:\n    raise ValueError(\"Invalid mode. Mode must be either 'fast' or 'accurate'.\")\n  \n  return isotropic_cov"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    d = cov.shape[-1]\n    det = jnp.linalg.det(cov)\n    isotropic_cov = jnp.power(det, 1/d) * jnp.eye(d)\n  elif mode == 'accurate':\n    sqrt_cov, (eigvec, eigval) = sqrtm(cov, return_eigs=True)\n    log_det = jnp.sum(jnp.log(eigval), axis=-1)\n    mean_log_det = jnp.mean(log_det, axis=-1, keepdims=True)\n    isotropic_cov = jnp.exp(mean_log_det) * jnp.eye(cov.shape[-1])\n  else:\n    raise ValueError(\"Invalid mode. Mode must be either 'fast' or 'accurate'.\")\n\n  return isotropic_cov"}
{"namespace": "coord.isotropize", "completion": "  if mode not in ['fast', 'accurate']:\n    raise ValueError(\"Invalid mode. Mode must be 'fast' or 'accurate'.\")\n\n  if mode == 'fast':\n    # Compute the determinant of the covariance matrix\n    det = jnp.linalg.det(cov)\n    # Compute the isotropic scaling factor\n    isotropic_scale = jnp.power(jnp.abs(det), -1.0 / cov.shape[-1])\n    # Construct the isotropic covariance matrix\n    isotropic_cov = isotropic_scale * cov\n  else:  # mode == 'accurate'\n    # Compute the logarithm of the determinant of the covariance matrix\n    log_det = jnp.log(jnp.abs(jnp.linalg.det(cov)))\n    # Compute the isotropic scaling factor using the logarithm of the determinant\n    isotropic_scale = jnp.exp(-log_det / cov.shape[-1])\n    # Construct the isotropic covariance matrix\n    isotropic_cov = isotropic_scale * cov\n\n  return isotropic_cov"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    # Compute the determinant of the covariance matrix\n    det = jnp.linalg.det(cov)\n    # Compute the isotropic scaling factor\n    scale = jnp.abs(det) ** (1 / cov.shape[-1])\n    # Construct the isotropic covariance matrix\n    isotropic_cov = scale * jnp.eye(cov.shape[-1])\n  elif mode == 'accurate':\n    # Compute the logarithm of the determinant for stability\n    log_det = jnp.log(jnp.abs(jnp.linalg.det(cov)))\n    # Compute the isotropic scaling factor\n    scale = jnp.exp(log_det / cov.shape[-1])\n    # Construct the isotropic covariance matrix\n    isotropic_cov = scale * jnp.eye(cov.shape[-1])\n  else:\n    raise ValueError(\"Invalid mode. Mode must be 'fast' or 'accurate'.\")\n\n  return isotropic_cov"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    # Compute the determinant directly\n    det = jnp.linalg.det(cov)\n    isotropic_cov = jnp.cbrt(jnp.abs(det)) * jnp.eye(cov.shape[-1])\n  elif mode == 'accurate':\n    # Use the logarithm of the determinant for stability\n    log_det = jnp.log(jnp.abs(jnp.linalg.det(cov)))\n    isotropic_cov = jnp.exp(log_det / cov.shape[-1]) * jnp.eye(cov.shape[-1])\n  else:\n    raise ValueError(\"Invalid mode. Please choose 'fast' or 'accurate'.\")\n\n  return isotropic_cov"}
{"namespace": "coord.isotropize", "completion": "\n  if mode == 'fast':\n    # Compute the determinant of the covariance matrix\n    det = jnp.linalg.det(cov)\n    # Compute the isotropic scaling factor based on the determinant\n    scale = jnp.abs(det) ** (-1 / cov.shape[-1])\n    # Construct the isotropic covariance matrix using the scaling factor\n    isotropic_cov = scale * jnp.eye(cov.shape[-1])\n    return isotropic_cov\n  elif mode == 'accurate':\n    # Compute the logarithm of the determinant for stability\n    log_det = jnp.log(jnp.abs(jnp.linalg.det(cov)))\n    # Compute the isotropic scaling factor based on the logarithm of the determinant\n    scale = jnp.exp(-log_det / cov.shape[-1])\n    # Construct the isotropic covariance matrix using the scaling factor\n    isotropic_cov = scale * jnp.eye(cov.shape[-1])\n    return isotropic_cov\n  else:\n    raise ValueError(\"Invalid mode. Please choose 'fast' or 'accurate'.\")"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n      # Compute the determinant of the covariance matrix\n      det = jnp.linalg.det(cov)\n      # Compute the isotropic scaling factor\n      scale = jnp.abs(det) ** (1 / cov.shape[-1])\n      # Create an isotropic covariance matrix with the same determinant\n      isotropic_cov = scale * jnp.eye(cov.shape[-1])\n  elif mode == 'accurate':\n      # Compute the logarithm of the determinant for stability\n      log_det = jnp.log(jnp.abs(jnp.linalg.det(cov)))\n      # Compute the isotropic scaling factor using the logarithm of the determinant\n      scale = jnp.exp(log_det / cov.shape[-1])\n      # Create an isotropic covariance matrix with the same determinant\n      isotropic_cov = scale * jnp.eye(cov.shape[-1])\n  else:\n      raise ValueError(\"Invalid mode. Please choose 'fast' or 'accurate'.\")\n\n  return isotropic_cov"}
{"namespace": "coord.construct_ray_warps", "completion": "    if fn_inv is None:\n      # Automatically determine the inverse based on a predefined mapping of functions to their inverses.\n      if fn == contract:\n        fn_inv = inv_contract\n      else:\n        raise ValueError('Inverse function not provided and could not be determined automatically.')\n\n    def t_to_s(t):\n      \"\"\"Maps metric distances to normalized distances in the range [0, 1].\"\"\"\n      return (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n    def s_to_t(s):\n      \"\"\"Maps normalized distances back to metric distances.\"\"\"\n      return fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t_near))\n\n    return t_to_s, s_to_t"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    if fn == contract:\n      fn_inv = inv_contract\n    else:\n      raise ValueError('fn_inv must be provided for custom fn functions.')\n\n  def t_to_s(t):\n    t_clipped = jnp.clip(t, t_near, t_far)\n    return (fn(t_clipped) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n  def s_to_t(s):\n    return fn_inv(fn(t_near) + s * (fn(t_far) - fn(t_near)))\n\n  return t_to_s, s_to_t"}
{"namespace": "coord.construct_ray_warps", "completion": "    if fn_inv is None:\n      if fn == contract:\n        fn_inv = inv_contract\n      else:\n        raise ValueError('fn_inv must be provided for the given fn')\n\n    def t_to_s(t):\n      t_clipped = jnp.clip(t, t_near, t_far)\n      return (fn(t_clipped) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n    def s_to_t(s):\n      return fn_inv(fn(t_near) + s * (fn(t_far) - fn(t_near)))\n\n    return t_to_s, s_to_t"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    if fn == contract:\n      fn_inv = inv_contract\n    else:\n      raise ValueError('fn_inv must be provided for non-contract functions.')\n\n  def t_to_s(t):\n    \"\"\"Maps metric distances to normalized distances.\"\"\"\n    return (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n  def s_to_t(s):\n    \"\"\"Maps normalized distances back to metric distances.\"\"\"\n    return fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t_near))\n\n  return t_to_s, s_to_t"}
{"namespace": "coord.construct_ray_warps", "completion": "  # If the inverse function is not provided, attempt to determine it automatically\n  if fn_inv is None:\n    if fn == contract:\n      fn_inv = inv_contract\n    else:\n      raise ValueError(\"Inverse function fn_inv must be provided for the given fn\")\n\n  def t_to_s(t):\n    \"\"\"Maps metric distances to normalized distances in the range [0, 1].\"\"\"\n    return (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n  def s_to_t(s):\n    \"\"\"Maps normalized distances back to metric distances.\"\"\"\n    return fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t_near))\n\n  return t_to_s, s_to_t"}
{"namespace": "coord.construct_ray_warps", "completion": "    def t_to_s(t):\n      return (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n    # If fn_inv is provided, use it as the inverse function\n    if fn_inv is not None:\n      def s_to_t(s):\n        return fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t_near))\n    else:\n      # If fn_inv is not provided, attempt to automatically determine the inverse\n      # based on a predefined mapping of functions to their inverses\n      if fn.__name__ == 'contract':\n        fn_inv = inv_contract\n      elif fn.__name__ == 'contract3_isoscale':\n        fn_inv = None  # No need to invert, as it's a fast version\n      else:\n        raise ValueError('Inverse function fn_inv must be provided for the given function fn')\n\n      def s_to_t(s):\n        return fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t_near))\n\n    return t_to_s, s_to_t"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    if fn == contract:\n      fn_inv = inv_contract\n    else:\n      raise ValueError(\"Inverse function fn_inv must be provided for custom fn\")\n\n  def t_to_s(t):\n    return (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n  def s_to_t(s):\n    return fn_inv(fn(t_near) + s * (fn(t_far) - fn(t_near)))\n\n  return t_to_s, s_to_t"}
{"namespace": "coord.construct_ray_warps", "completion": "  # Determine the inverse function if not provided\n  if fn_inv is None:\n    fn_inv = jax.scipy.optimize.root(fn, t_near, t_far)\n\n  # Define the forward mapping from metric to normalized distances\n  def t_to_s(t):\n    return (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n  # Define the backward mapping from normalized to metric distances\n  def s_to_t(s):\n    return fn_inv(fn(t_near) + s * (fn(t_far) - fn(t_near)))\n\n  return t_to_s, s_to_t"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    fn_inv = jax.scipy.optimize.root(fn - jax.numpy.array([0, 1]), 0.5).x\n  t_to_s = lambda t: (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n  s_to_t = lambda s: fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t_near))\n  return t_to_s, s_to_t"}
{"namespace": "coord.construct_ray_warps", "completion": "    if fn_inv is None:\n      fn_inv = inv_contract if fn == contract else None\n\n    def t_to_s(t):\n      # Clamp t to [t_near, t_far] to ensure it falls within a valid range.\n      t = jnp.clip(t, t_near, t_far)\n      # Map t to s using the provided function fn.\n      s = (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n      return s\n\n    def s_to_t(s):\n      # Map s to t using the inverse function fn_inv.\n      t = fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t_near))\n      return t\n\n    return t_to_s, s_to_t"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    if fn is contract:\n      fn_inv = inv_contract\n    else:\n      raise ValueError('No inverse function provided for fn')\n\n  def t_to_s(dist):\n    return (fn(dist) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n  def s_to_t(s_dist):\n    return fn_inv(fn(t_near) + s_dist * (fn(t_far) - fn(t_near)))\n\n  return t_to_s, s_to_t"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    if fn == contract:\n      fn_inv = inv_contract\n    else:\n      raise ValueError('fn_inv must be provided if fn is not contract.')\n\n  def t_to_s(t):\n    return (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n  def s_to_t(s):\n    return fn_inv(fn(t_near) + s * (fn(t_far) - fn(t_near)))\n\n  return t_to_s, s_to_t"}
{"namespace": "coord.construct_ray_warps", "completion": "    if fn_inv is None:\n        # Automatically determine the inverse of the fn function\n        fn_inv = inv_contract if fn == contract else None\n\n    def t_to_s(t):\n        # Map metric distances to normalized distances in the range [0, 1]\n        return (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n    def s_to_t(s):\n        # Map normalized distances back to metric distances\n        return fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t_near))\n\n    return t_to_s, s_to_t"}
{"namespace": "coord.construct_ray_warps", "completion": "\n    def t_to_s(t):\n      \"\"\"Maps metric distances to normalized distances in the range [0, 1].\"\"\"\n      return (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n    def s_to_t(s):\n      \"\"\"Maps normalized distances back to metric distances.\"\"\"\n      return fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t_near)) if fn_inv else None\n\n    return t_to_s, s_to_t"}
{"namespace": "coord.construct_ray_warps", "completion": "    if fn_inv is None:\n      fn_inv = jax.vmap(jax.scipy.optimize.root_scalar, in_axes=(None, None, None, None))(\n          lambda s: fn(s) - s, 0, 1, t_near, t_far\n      ).root\n\n    def t_to_s(t):\n      return (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n    def s_to_t(s):\n      return fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t_near))\n\n    return t_to_s, s_to_t"}
{"namespace": "coord.construct_ray_warps", "completion": "    if fn_inv is None:\n      fn_inv = inv_contract if fn == contract else None\n\n    def t_to_s(t):\n      t_clipped = jnp.clip(t, t_near, t_far)\n      s = (fn(t_clipped) - fn(t_near)) / (fn(t_far) - fn(t_near))\n      return jnp.clip(s, 0, 1)\n\n    def s_to_t(s):\n      s_clipped = jnp.clip(s, 0, 1)\n      t = t_near + (t_far - t_near) * fn_inv(s_clipped * (fn(t_far) - fn(t_near)) + fn(t_near))\n      return t\n\n    return t_to_s, s_to_t"}
{"namespace": "coord.construct_ray_warps", "completion": "    if fn_inv is None:\n      if fn == contract:\n        fn_inv = inv_contract\n      else:\n        raise ValueError('fn_inv must be provided for custom fn functions.')\n\n    def t_to_s(t):\n      \"\"\"Maps metric distances to normalized distances in the range [0, 1].\"\"\"\n      return (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n    def s_to_t(s):\n      \"\"\"Maps normalized distances back to metric distances.\"\"\"\n      return fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t_near))\n\n    return t_to_s, s_to_t"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    # Attempt to automatically determine the inverse based on a predefined mapping of functions to their inverses\n    if fn == contract:\n      fn_inv = inv_contract\n    else:\n      raise ValueError(\"Inverse function fn_inv must be provided for the given function fn\")\n\n  def t_to_s(t):\n    \"\"\"Maps metric distances to normalized distances in the range [0, 1].\"\"\"\n    return (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n  def s_to_t(s):\n    \"\"\"Maps normalized distances back to metric distances.\"\"\"\n    return fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t_near))\n\n  return t_to_s, s_to_t"}
{"namespace": "coord.construct_ray_warps", "completion": "    if fn_inv is None:\n      # Attempt to automatically determine the inverse based on a predefined mapping of functions to their inverses\n      if fn == contract:\n        fn_inv = inv_contract\n      else:\n        raise ValueError('Inverse function fn_inv must be provided.')\n\n    def t_to_s(t):\n      \"\"\"Maps metric distances to normalized distances in the range [0, 1].\"\"\"\n      s = (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n      return jnp.clip(s, 0, 1)\n\n    def s_to_t(s):\n      \"\"\"Maps normalized distances back to metric distances.\"\"\"\n      t = fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t_near))\n      return t\n\n    return t_to_s, s_to_t"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    if fn == contract:\n      fn_inv = inv_contract\n    else:\n      raise ValueError('fn_inv must be provided if fn is not contract')\n\n  def t_to_s(t):\n    t = jnp.clip(t, t_near, t_far)\n    return (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n  def s_to_t(s):\n    return fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t_near))\n\n  return t_to_s, s_to_t"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            if n_neurons <= 64:\n                return tinycudann.create_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)\n            else:\n                return torch.nn.Sequential(\n                    nn.Linear(n_input_dims, n_neurons),\n                    nn.ReLU() if activation == \"ReLU\" else nn.Identity(),\n                    *[nn.Sequential(\n                        nn.Linear(n_neurons, n_neurons),\n                        nn.ReLU() if activation == \"ReLU\" else nn.Identity()\n                    ) for _ in range(n_layers - 2)],\n                    nn.Linear(n_neurons, n_output_dims),\n                    nn.ReLU() if output_activation == \"ReLU\" else (nn.Sigmoid() if output_activation == \"Sigmoid\" else nn.Identity())\n                )\n        else:\n            return torch.nn.Sequential(\n                nn.Linear(n_input_dims, n_neurons),\n                nn.ReLU() if activation == \"ReLU\" else nn.Identity(),\n                *[nn.Sequential(\n                    nn.Linear(n_neurons, n_neurons),\n                    nn.ReLU() if activation == \"ReLU\" else nn.Identity()\n                ) for _ in range(n_layers - 1)],\n                nn.Linear(n_neurons, n_output_dims),\n                nn.ReLU() if output_activation == \"ReLU\" else (nn.Sigmoid() if output_activation == \"Sigmoid\" else nn.Identity())\n            )"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            if n_neurons <= 32:\n                # Create network using tinycudann\n                pass\n            else:\n                # Create network using PyTorch\n                layers = []\n                layers.append(nn.Linear(n_input_dims, n_neurons))\n                if activation == \"ReLU\":\n                    layers.append(nn.ReLU())\n                layers.extend([nn.Linear(n_neurons, n_neurons), nn.ReLU()] * (n_layers - 1))\n                layers.append(nn.Linear(n_neurons, n_output_dims))\n                if output_activation == \"ReLU\":\n                    layers.append(nn.ReLU())\n                elif output_activation == \"Sigmoid\":\n                    layers.append(nn.Sigmoid())\n                return nn.Sequential(*layers)\n        else:\n            # Create network using PyTorch\n            layers = []\n            layers.append(nn.Linear(n_input_dims, n_neurons))\n            if activation == \"ReLU\":\n                layers.append(nn.ReLU())\n            layers.extend([nn.Linear(n_neurons, n_neurons), nn.ReLU()] * (n_layers - 1))\n            layers.append(nn.Linear(n_neurons, n_output_dims))\n            if output_activation == \"ReLU\":\n                layers.append(nn.ReLU())\n            elif output_activation == \"Sigmoid\":\n                layers.append(nn.Sigmoid())\n            return nn.Sequential(*layers)"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"Number of layers must be greater than 0\"\n        assert n_neurons > 0, \"Number of neurons must be greater than 0\"\n\n        if self.tcnn:\n            # Create network using tinycudann\n            pass  # Placeholder for tinycudann implementation\n        else:\n            # Create network using PyTorch\n            layers = []\n            # Add input layer\n            layers.append(nn.Linear(n_input_dims, n_neurons))\n            if activation == \"ReLU\":\n                layers.append(nn.ReLU())\n            # Add hidden layers\n            for _ in range(n_layers - 1):\n                layers.append(nn.Linear(n_neurons, n_neurons))\n                if activation == \"ReLU\":\n                    layers.append(nn.ReLU())\n            # Add output layer\n            layers.append(nn.Linear(n_neurons, n_output_dims))\n            if output_activation == \"ReLU\":\n                layers.append(nn.ReLU())\n            elif output_activation == \"Sigmoid\":\n                layers.append(nn.Sigmoid())\n\n            return nn.Sequential(*layers)"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            if n_neurons <= 64:\n                network = tinycudann.Network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)\n            else:\n                network = tinycudann.DeepNetwork(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)\n        else:\n            layers = []\n            for i in range(n_layers):\n                if i == 0:\n                    layers.append(nn.Linear(n_input_dims, n_neurons))\n                elif i == n_layers - 1:\n                    layers.append(nn.Linear(n_neurons, n_output_dims))\n                else:\n                    layers.append(nn.Linear(n_neurons, n_neurons))\n                if i < n_layers - 1:\n                    if activation == \"ReLU\":\n                        layers.append(nn.ReLU())\n                    elif activation == \"None\":\n                        pass  # No activation function for hidden layers\n            network = nn.Sequential(*layers)\n\n        return network"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            # Use tinycudann\n            if n_neurons <= 64:\n                network_type = \"tiny\"\n            else:\n                network_type = \"cudann\"\n            # Generate network using tinycudann or PyTorch\n            # code for generating network using tinycudann\n            pass\n        else:\n            # Use PyTorch\n            layers = []\n            # Add input layer\n            layers.append(nn.Linear(n_input_dims, n_neurons))\n            if activation == \"ReLU\":\n                layers.append(nn.ReLU())\n            # Add hidden layers\n            for _ in range(n_layers - 2):\n                layers.append(nn.Linear(n_neurons, n_neurons))\n                if activation == \"ReLU\":\n                    layers.append(nn.ReLU())\n            # Add output layer\n            layers.append(nn.Linear(n_neurons, n_output_dims))\n            if output_activation == \"ReLU\":\n                layers.append(nn.ReLU())\n            elif output_activation == \"Sigmoid\":\n                layers.append(nn.Sigmoid())\n            # Create the network\n            network = nn.Sequential(*layers)\n            return network"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            if n_neurons <= 64:\n                # Create network using tinycudann\n                pass  # Placeholder for tinycudann network creation\n            else:\n                # Create network using PyTorch\n                layers = []\n                layers.append(nn.Linear(n_input_dims, n_neurons))\n                layers.append(nn.ReLU() if activation == \"ReLU\" else nn.Identity())\n                for _ in range(n_layers - 2):\n                    layers.append(nn.Linear(n_neurons, n_neurons))\n                    layers.append(nn.ReLU() if activation == \"ReLU\" else nn.Identity())\n                layers.append(nn.Linear(n_neurons, n_output_dims))\n                layers.append(nn.ReLU() if output_activation == \"ReLU\" else\n                              nn.Sigmoid() if output_activation == \"Sigmoid\" else nn.Identity())\n                return nn.Sequential(*layers)\n        else:\n            # Create network using tinycudann\n            pass  # Placeholder for tinycudann network creation"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"Number of layers must be greater than 0\"\n        assert n_neurons > 0, \"Number of neurons must be greater than 0\"\n\n        if self.tcnn:\n            # Create network using tinycudann\n            pass  # Placeholder for tinycudann network creation\n        else:\n            # Create network using PyTorch\n            layers = []\n            for _ in range(n_layers - 1):\n                layers.append(nn.Linear(n_input_dims, n_neurons))\n                if activation == \"ReLU\":\n                    layers.append(nn.ReLU())\n                n_input_dims = n_neurons\n            layers.append(nn.Linear(n_input_dims, n_output_dims))\n            if output_activation == \"ReLU\":\n                layers.append(nn.ReLU())\n            elif output_activation == \"Sigmoid\":\n                layers.append(nn.Sigmoid())\n            return nn.Sequential(*layers)"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            if n_neurons <= 64:\n                # Create network using tinycudann\n                # ...\n                pass\n            else:\n                # Create network using PyTorch\n                layers = []\n                layers.append(nn.Linear(n_input_dims, n_neurons))\n                layers.append(nn.ReLU() if activation == \"ReLU\" else nn.Identity())\n                for _ in range(n_layers - 2):\n                    layers.append(nn.Linear(n_neurons, n_neurons))\n                    layers.append(nn.ReLU() if activation == \"ReLU\" else nn.Identity())\n                layers.append(nn.Linear(n_neurons, n_output_dims))\n                if output_activation == \"ReLU\":\n                    layers.append(nn.ReLU())\n                elif output_activation == \"Sigmoid\":\n                    layers.append(nn.Sigmoid())\n                network = nn.Sequential(*layers)\n                return network\n        else:\n            # Create network using tinycudann\n            # ...\n            pass"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            if n_neurons <= 32:\n                # Use tinycudann for small networks\n                # Create and return the tinycudann network\n                pass\n            else:\n                # Use PyTorch for larger networks\n                # Create and return the PyTorch network\n                pass\n        else:\n            # Use PyTorch for all networks\n            # Create and return the PyTorch network\n            pass"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            # Use tinycudann for network creation\n            if n_neurons <= 64:\n                network_type = \"tiny\"\n            else:\n                network_type = \"cudann\"\n            # Create network using tinycudann or cudann based on the number of neurons\n            # code to create network using tinycudann or cudann\n            pass\n        else:\n            # Use PyTorch for network creation\n            layers = []\n            # Add input layer\n            layers.append(nn.Linear(n_input_dims, n_neurons))\n            layers.append(nn.ReLU() if activation == \"ReLU\" else nn.Identity())\n            # Add hidden layers\n            for _ in range(n_layers - 2):\n                layers.append(nn.Linear(n_neurons, n_neurons))\n                layers.append(nn.ReLU() if activation == \"ReLU\" else nn.Identity())\n            # Add output layer\n            layers.append(nn.Linear(n_neurons, n_output_dims))\n            if output_activation == \"ReLU\":\n                layers.append(nn.ReLU())\n            elif output_activation == \"Sigmoid\":\n                layers.append(nn.Sigmoid())\n            # Construct the network\n            network = nn.Sequential(*layers)\n            return network"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            # Use tinycudann for network creation\n            if n_neurons <= 32:\n                # Use a small network for low number of neurons\n                return tinycudann.create_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)\n            else:\n                # Use a large network for high number of neurons\n                return tinycudann.create_large_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)\n        else:\n            # Use PyTorch for network creation\n            layers = []\n            # Add input layer\n            layers.append(nn.Linear(n_input_dims, n_neurons))\n            layers.append(nn.ReLU() if activation == \"ReLU\" else nn.Identity())\n            # Add hidden layers\n            for _ in range(n_layers - 2):\n                layers.append(nn.Linear(n_neurons, n_neurons))\n                layers.append(nn.ReLU() if activation == \"ReLU\" else nn.Identity())\n            # Add output layer\n            layers.append(nn.Linear(n_neurons, n_output_dims))\n            if output_activation == \"ReLU\":\n                layers.append(nn.ReLU())\n            elif output_activation == \"Sigmoid\":\n                layers.append(nn.Sigmoid())\n            # Create and return the network\n            return nn.Sequential(*layers)"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            if n_neurons <= 64:\n                # Use tinycudann for small networks\n                network = tinycudann.Network(n_input_dims, n_output_dims)\n                for _ in range(n_layers - 1):\n                    network.add_layer(n_neurons, activation)\n                network.add_layer(n_output_dims, output_activation)\n            else:\n                # Use PyTorch for large networks\n                layers = []\n                layers.append(nn.Linear(n_input_dims, n_neurons))\n                layers.append(nn.ReLU() if activation == \"ReLU\" else nn.Identity())\n                for _ in range(n_layers - 2):\n                    layers.append(nn.Linear(n_neurons, n_neurons))\n                    layers.append(nn.ReLU() if activation == \"ReLU\" else nn.Identity())\n                layers.append(nn.Linear(n_neurons, n_output_dims))\n                if output_activation == \"ReLU\":\n                    layers.append(nn.ReLU())\n                elif output_activation == \"Sigmoid\":\n                    layers.append(nn.Sigmoid())\n                network = nn.Sequential(*layers)\n        else:\n            # Use PyTorch for all networks\n            layers = []\n            layers.append(nn.Linear(n_input_dims, n_neurons))\n            layers.append(nn.ReLU() if activation == \"ReLU\" else nn.Identity())\n            for _ in range(n_layers - 2):\n                layers.append(nn.Linear(n_neurons, n_neurons))\n                layers.append(nn.ReLU() if activation == \"ReLU\" else nn.Identity())\n            layers.append(nn.Linear(n_neurons, n_output_dims))\n            if output_activation == \"ReLU\":\n                layers.append(nn.ReLU())\n            elif output_activation == \"Sigmoid\":\n                layers.append(nn.Sigmoid())\n            network = nn.Sequential(*layers)\n\n        return network"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            if n_neurons <= 64:\n                # Use tinycudann for small networks\n                network = tinycudann.Network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)\n            else:\n                # Use PyTorch for larger networks\n                layers = []\n                layers.append(nn.Linear(n_input_dims, n_neurons))\n                if activation == \"ReLU\":\n                    layers.append(nn.ReLU())\n                if n_layers > 1:\n                    for _ in range(n_layers - 1):\n                        layers.append(nn.Linear(n_neurons, n_neurons))\n                        if activation == \"ReLU\":\n                            layers.append(nn.ReLU())\n                layers.append(nn.Linear(n_neurons, n_output_dims))\n                if output_activation == \"ReLU\":\n                    layers.append(nn.ReLU())\n                elif output_activation == \"Sigmoid\":\n                    layers.append(nn.Sigmoid())\n                network = nn.Sequential(*layers)\n        else:\n            # Use PyTorch for all networks\n            layers = []\n            layers.append(nn.Linear(n_input_dims, n_neurons))\n            if activation == \"ReLU\":\n                layers.append(nn.ReLU())\n            if n_layers > 1:\n                for _ in range(n_layers - 1):\n                    layers.append(nn.Linear(n_neurons, n_neurons))\n                    if activation == \"ReLU\":\n                        layers.append(nn.ReLU())\n            layers.append(nn.Linear(n_neurons, n_output_dims))\n            if output_activation == \"ReLU\":\n                layers.append(nn.ReLU())\n            elif output_activation == \"Sigmoid\":\n                layers.append(nn.Sigmoid())\n            network = nn.Sequential(*layers)\n\n        return network"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            if n_layers == 1:\n                return tinycudann.create_network(n_input_dims, n_output_dims, n_neurons)\n            else:\n                return tinycudann.create_deep_network(n_input_dims, n_output_dims, n_layers, n_neurons)\n        else:\n            layers = []\n            for _ in range(n_layers - 1):\n                layers.append(nn.Linear(n_input_dims, n_neurons))\n                if activation == \"ReLU\":\n                    layers.append(nn.ReLU())\n                n_input_dims = n_neurons\n            layers.append(nn.Linear(n_input_dims, n_output_dims))\n            if output_activation == \"ReLU\":\n                layers.append(nn.ReLU())\n            elif output_activation == \"Sigmoid\":\n                layers.append(nn.Sigmoid())\n            return nn.Sequential(*layers)"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            if n_neurons <= 64:\n                # Use tinycudann for small networks\n                network = tinycudann.Network(n_input_dims, n_output_dims)\n                for _ in range(n_layers - 1):\n                    network.add_layer(n_neurons, activation)\n                network.add_layer(n_output_dims, output_activation)\n            else:\n                # Use PyTorch for larger networks\n                layers = []\n                layers.append(nn.Linear(n_input_dims, n_neurons))\n                layers.append(nn.ReLU() if activation == \"ReLU\" else nn.Identity())\n                for _ in range(n_layers - 2):\n                    layers.append(nn.Linear(n_neurons, n_neurons))\n                    layers.append(nn.ReLU() if activation == \"ReLU\" else nn.Identity())\n                layers.append(nn.Linear(n_neurons, n_output_dims))\n                if output_activation == \"ReLU\":\n                    layers.append(nn.ReLU())\n                elif output_activation == \"Sigmoid\":\n                    layers.append(nn.Sigmoid())\n                network = nn.Sequential(*layers)\n        else:\n            # Use PyTorch for all networks\n            layers = []\n            layers.append(nn.Linear(n_input_dims, n_neurons))\n            layers.append(nn.ReLU() if activation == \"ReLU\" else nn.Identity())\n            for _ in range(n_layers - 2):\n                layers.append(nn.Linear(n_neurons, n_neurons))\n                layers.append(nn.ReLU() if activation == \"ReLU\" else nn.Identity())\n            layers.append(nn.Linear(n_neurons, n_output_dims))\n            if output_activation == \"ReLU\":\n                layers.append(nn.ReLU())\n            elif output_activation == \"Sigmoid\":\n                layers.append(nn.Sigmoid())\n            network = nn.Sequential(*layers)\n\n        return network"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            if n_neurons <= 64:\n                network_type = \"tiny\"\n            else:\n                network_type = \"cudann\"\n            # Create network using tinycudann or cudann\n            # ...\n            return network\n        else:\n            # Create network using PyTorch\n            layers = []\n            layers.append(nn.Linear(n_input_dims, n_neurons))\n            if activation == \"ReLU\":\n                layers.append(nn.ReLU())\n            for _ in range(n_layers - 2):\n                layers.append(nn.Linear(n_neurons, n_neurons))\n                if activation == \"ReLU\":\n                    layers.append(nn.ReLU())\n            layers.append(nn.Linear(n_neurons, n_output_dims))\n            if output_activation == \"ReLU\":\n                layers.append(nn.ReLU())\n            elif output_activation == \"Sigmoid\":\n                layers.append(nn.Sigmoid())\n            network = nn.Sequential(*layers)\n            return network"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"Number of layers must be greater than 0\"\n        assert n_neurons > 0, \"Number of neurons must be greater than 0\"\n\n        if self.tcnn:\n            # Create network using tinycudann\n            # ...\n            pass\n        else:\n            # Create network using PyTorch\n            layers = []\n            layers.append(nn.Linear(n_input_dims, n_neurons))\n            if activation == \"ReLU\":\n                layers.append(nn.ReLU())\n            if activation == \"None\":\n                pass  # No activation function\n            for _ in range(n_layers - 1):\n                layers.append(nn.Linear(n_neurons, n_neurons))\n                if activation == \"ReLU\":\n                    layers.append(nn.ReLU())\n                if activation == \"None\":\n                    pass  # No activation function\n            layers.append(nn.Linear(n_neurons, n_output_dims))\n            if output_activation == \"ReLU\":\n                layers.append(nn.ReLU())\n            if output_activation == \"Sigmoid\":\n                layers.append(nn.Sigmoid())\n            if output_activation == \"None\":\n                pass  # No activation function\n\n            return nn.Sequential(*layers)"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            if n_neurons <= 64:\n                # Create network using tinycudann\n                pass\n            else:\n                # Create network using PyTorch\n                layers = []\n                for _ in range(n_layers - 1):\n                    layers.append(nn.Linear(n_input_dims, n_neurons))\n                    if activation == \"ReLU\":\n                        layers.append(nn.ReLU())\n                    else:\n                        layers.append(nn.Identity())\n                    n_input_dims = n_neurons\n                layers.append(nn.Linear(n_input_dims, n_output_dims))\n                if output_activation == \"ReLU\":\n                    layers.append(nn.ReLU())\n                elif output_activation == \"Sigmoid\":\n                    layers.append(nn.Sigmoid())\n                else:\n                    layers.append(nn.Identity())\n                return nn.Sequential(*layers)\n        else:\n            # Create network using tinycudann\n            pass"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            if n_neurons <= 64:\n                # Create network using tinycudann\n                pass\n            else:\n                # Create network using PyTorch\n                layers = []\n                layers.append(nn.Linear(n_input_dims, n_neurons))\n                layers.append(nn.ReLU() if activation == \"ReLU\" else nn.Identity())\n                for _ in range(n_layers - 2):\n                    layers.append(nn.Linear(n_neurons, n_neurons))\n                    layers.append(nn.ReLU() if activation == \"ReLU\" else nn.Identity())\n                layers.append(nn.Linear(n_neurons, n_output_dims))\n                if output_activation == \"ReLU\":\n                    layers.append(nn.ReLU())\n                elif output_activation == \"Sigmoid\":\n                    layers.append(nn.Sigmoid())\n                else:\n                    layers.append(nn.Identity())\n                return nn.Sequential(*layers)\n        else:\n            # Create network using tinycudann\n            pass"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        if self.tcnn:\n            if n_neurons <= 64:\n                # Use tinycudann for small networks\n                return tinycudann.create_network(n_input_dims, n_output_dims, n_layers, n_neurons, activation, output_activation)\n            else:\n                # Use PyTorch for larger networks\n                layers = []\n                layers.append(nn.Linear(n_input_dims, n_neurons))\n                layers.append(nn.ReLU() if activation == \"ReLU\" else nn.Identity())\n                for _ in range(n_layers - 2):\n                    layers.append(nn.Linear(n_neurons, n_neurons))\n                    layers.append(nn.ReLU() if activation == \"ReLU\" else nn.Identity())\n                layers.append(nn.Linear(n_neurons, n_output_dims))\n                if output_activation == \"ReLU\":\n                    layers.append(nn.ReLU())\n                elif output_activation == \"Sigmoid\":\n                    layers.append(nn.Sigmoid())\n                return nn.Sequential(*layers)\n        else:\n            # Use PyTorch for all networks if self.tcnn is False\n            layers = []\n            layers.append(nn.Linear(n_input_dims, n_neurons))\n            layers.append(nn.ReLU() if activation == \"ReLU\" else nn.Identity())\n            for _ in range(n_layers - 2):\n                layers.append(nn.Linear(n_neurons, n_neurons))\n                layers.append(nn.ReLU() if activation == \"ReLU\" else nn.Identity())\n            layers.append(nn.Linear(n_neurons, n_output_dims))\n            if output_activation == \"ReLU\":\n                layers.append(nn.ReLU())\n            elif output_activation == \"Sigmoid\":\n                layers.append(nn.Sigmoid())\n            return nn.Sequential(*layers)"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if not polygons:\n        return []\n\n    areas = [area(polygon) for polygon in polygons]\n    max_area = max(areas)\n\n    filtered_polygons = []\n    for i, polygon in enumerate(polygons):\n        if areas[i] >= abs_tr and areas[i] >= rel_tr * max_area:\n            filtered_polygons.append(polygon)\n\n    return filtered_polygons"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if not polygons:\n        return []\n\n    areas = [area(polygon) for polygon in polygons]\n    max_area = max(areas)\n\n    filtered_polygons = [\n        polygon for polygon, polygon_area in zip(polygons, areas)\n        if polygon_area >= abs_tr and polygon_area >= rel_tr * max_area\n    ]\n\n    return filtered_polygons"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "\n    # Calculate the area of each polygon\n    polygon_areas = [area(poly) for poly in polygons]\n\n    # Find the index of the largest polygon\n    largest_polygon_index = np.argmax(polygon_areas)\n\n    # Calculate the relative threshold based on the area of the largest polygon\n    relative_threshold = rel_tr * polygon_areas[largest_polygon_index]\n\n    # Filter out polygons based on the area criteria\n    filtered_polygons = [poly for i, poly in enumerate(polygons) if polygon_areas[i] >= abs_tr and polygon_areas[i] >= relative_threshold]\n\n    return filtered_polygons"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    areas = [area(poly) for poly in polygons]\n    max_area = max(areas)\n    filtered_polygons = [poly for poly, poly_area in zip(polygons, areas) if poly_area >= max_area * rel_tr and poly_area >= abs_tr]\n    return filtered_polygons"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    areas = [area(polygon) for polygon in polygons]  # Calculate the area of each polygon\n    max_area = max(areas)  # Find the maximum area in the list of polygons\n\n    filtered_polygons = []  # Initialize an empty list to store the filtered polygons\n    for i, polygon in enumerate(polygons):\n        if areas[i] >= abs_tr and areas[i] >= rel_tr * max_area:  # Check if the area meets the criteria\n            filtered_polygons.append(polygon)  # Add the polygon to the filtered list if it meets the criteria\n\n    return filtered_polygons  # Return the list of polygons that meet the area criteria"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "\n    # Calculate the areas of all polygons\n    areas = [area(polygon) for polygon in polygons]\n\n    # Find the index of the largest polygon\n    largest_polygon_index = np.argmax(areas)\n\n    # Calculate the relative threshold based on the largest polygon's area\n    rel_threshold = rel_tr * areas[largest_polygon_index]\n\n    # Filter out polygons based on the area criteria\n    filtered_polygons = [\n        polygon for polygon, polygon_area in zip(polygons, areas)\n        if polygon_area >= abs_tr and polygon_area >= rel_threshold\n    ]\n\n    return filtered_polygons"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    areas = [area(p) for p in polygons]\n    max_area = max(areas)\n    filtered_polygons = [p for p, a in zip(polygons, areas) if a >= max_area * rel_tr and a >= abs_tr]\n    return filtered_polygons"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    areas = [area(poly) for poly in polygons]\n    max_area = max(areas)\n    filtered_polygons = [poly for poly, poly_area in zip(polygons, areas) if poly_area >= max_area * rel_tr and poly_area >= abs_tr]\n    return filtered_polygons"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    areas = [area(polygon) for polygon in polygons]\n    max_area = max(areas)\n    filtered_polygons = [polygon for polygon, area in zip(polygons, areas) if area >= abs_tr and area >= rel_tr * max_area]\n    return filtered_polygons"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "\n    areas = [area(polygon) for polygon in polygons]\n    max_area = max(areas)\n    filtered_polygons = [polygon for polygon, polygon_area in zip(polygons, areas) if polygon_area >= max_area * rel_tr and polygon_area >= abs_tr]\n    return filtered_polygons"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "\n    areas = [area(polygon) for polygon in polygons]\n    max_area = max(areas)\n\n    filtered_polygons = [polygon for polygon, area in zip(polygons, areas) if area >= max_area * rel_tr and area >= abs_tr]\n\n    return filtered_polygons"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    # Calculate the areas of all polygons\n    polygon_areas = [area(p) for p in polygons]\n\n    # Find the index of the largest polygon\n    max_area_index = np.argmax(polygon_areas)\n\n    # Filter out polygons that do not meet the area criteria\n    filtered_polygons = [p for i, p in enumerate(polygons) if (polygon_areas[i] >= abs_tr) and (polygon_areas[i] >= rel_tr * polygon_areas[max_area_index])]\n\n    return filtered_polygons"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    areas = [area(p) for p in polygons]\n    max_area = max(areas)\n    filtered_polygons = [p for p, a in zip(polygons, areas) if a >= abs_tr and a >= rel_tr * max_area]\n    return filtered_polygons"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    areas = [area(polygon) for polygon in polygons]\n    max_area = max(areas)\n    filtered_polygons = [polygon for polygon, area in zip(polygons, areas) if area >= max_area * rel_tr and area >= abs_tr]\n    return filtered_polygons"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    areas = [area(polygon) for polygon in polygons]\n    max_area = max(areas)\n    filtered_polygons = [polygon for polygon, polygon_area in zip(polygons, areas) if polygon_area >= max_area * rel_tr and polygon_area >= abs_tr]\n    return filtered_polygons"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    areas = [area(polygon) for polygon in polygons]\n    max_area = max(areas)\n    filtered_polygons = [polygon for polygon, area in zip(polygons, areas) if area >= max_area * rel_tr and area >= abs_tr]\n    return filtered_polygons"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "\n    # Calculate the area of each polygon\n    areas = [area(poly) for poly in polygons]\n\n    # Find the index of the largest polygon\n    max_area_index = np.argmax(areas)\n\n    # Calculate the relative threshold based on the largest polygon's area\n    rel_threshold = rel_tr * areas[max_area_index]\n\n    # Filter out polygons based on the area criteria\n    filtered_polygons = [poly for i, poly in enumerate(polygons) if areas[i] >= abs_tr and areas[i] >= rel_threshold]\n\n    return filtered_polygons"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "\n    areas = [area(p) for p in polygons]  # Calculate the area of each polygon\n    max_area = max(areas)  # Find the largest area\n\n    filtered_polygons = [\n        p for p, a in zip(polygons, areas) if a >= abs_tr or a >= rel_tr * max_area\n    ]  # Filter polygons based on area criteria\n\n    return filtered_polygons  # Return the filtered list of polygons"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    areas = [area(polygon) for polygon in polygons]\n    max_area = max(areas)\n    filtered_polygons = [polygon for polygon, polygon_area in zip(polygons, areas) if polygon_area >= max_area * rel_tr and polygon_area >= abs_tr]\n    return filtered_polygons"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "\n    areas = [area(polygon) for polygon in polygons]  # Calculate the areas of all polygons\n    max_area = max(areas)  # Find the largest area in the list\n\n    # Filter polygons based on the area criteria\n    filtered_polygons = [\n        polygon for polygon, polygon_area in zip(polygons, areas)\n        if polygon_area >= abs_tr and polygon_area >= rel_tr * max_area\n    ]\n\n    return filtered_polygons"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        return np.array([np.median(signal[i:i + 2 * kernel_offset + 1]) for i in range(len(signal) - 2 * kernel_offset)])"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        return np.array([np.median(signal[i - kernel_offset : i + kernel_offset + 1]) for i in range(kernel_offset, len(signal) - kernel_offset)])"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        rolling_medians = np.zeros(len(signal) - 2 * kernel_offset)\n        for i in range(kernel_offset, len(signal) - kernel_offset):\n            rolling_medians[i - kernel_offset] = np.median(signal[i - kernel_offset : i + kernel_offset + 1])\n        return rolling_medians"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        rolling_medians = np.zeros(len(signal) - 2 * kernel_offset)\n        for i in range(len(signal) - 2 * kernel_offset):\n            rolling_medians[i] = np.median(signal[i : i + 2 * kernel_offset + 1])\n        return rolling_medians"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        medians = np.zeros(len(signal) - 2 * kernel_offset)\n        for i in range(kernel_offset, len(signal) - kernel_offset):\n            medians[i - kernel_offset] = np.median(signal[i - kernel_offset : i + kernel_offset + 1])\n        return medians"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "    rolling_medians = np.zeros(len(signal) - 2 * kernel_offset)\n    for i in range(kernel_offset, len(signal) - kernel_offset):\n        window = signal[i - kernel_offset : i + kernel_offset + 1]\n        rolling_medians[i - kernel_offset] = np.median(window)\n    return rolling_medians"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        rolling_medians = []\n        for i in range(kernel_offset, len(signal) - kernel_offset + 1):\n            window = signal[i - kernel_offset : i + kernel_offset + 1]\n            median = np.median(window)\n            rolling_medians.append(median)\n        return np.array(rolling_medians)"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        rolling_medians = np.zeros(len(signal) - 2 * kernel_offset)\n        for i in range(len(signal) - 2 * kernel_offset):\n            rolling_medians[i] = np.median(signal[i : i + 2 * kernel_offset + 1])\n        return rolling_medians"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        rolling_medians = []\n        for i in range(kernel_offset, len(signal) - kernel_offset + 1):\n            window = signal[i - kernel_offset: i + kernel_offset + 1]\n            median = np.median(window)\n            rolling_medians.append(median)\n        return np.array(rolling_medians)"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        rolling_medians = []\n        for i in range(kernel_offset, len(signal) - kernel_offset + 1):\n            median = np.median(signal[i - kernel_offset : i + kernel_offset + 1])\n            rolling_medians.append(median)\n        return np.array(rolling_medians)"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        rolling_median = np.zeros(len(signal) - 2 * kernel_offset)\n        for i in range(len(signal) - 2 * kernel_offset):\n            rolling_median[i] = np.median(signal[i:i + 2 * kernel_offset + 1])\n        return rolling_median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        rolling_median = np.zeros(len(signal) - 2 * kernel_offset)\n        for i in range(len(signal) - 2 * kernel_offset):\n            rolling_median[i] = np.median(signal[i:i + 2 * kernel_offset + 1])\n        return rolling_median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        rolling_medians = []\n        for i in range(kernel_offset, len(signal) - kernel_offset):\n            window = signal[i - kernel_offset : i + kernel_offset + 1]\n            median = np.median(window)\n            rolling_medians.append(median)\n        return np.array(rolling_medians)"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        rolling_median = np.zeros(len(signal) - 2 * kernel_offset)\n        for i in range(len(signal) - 2 * kernel_offset):\n            rolling_median[i] = np.median(signal[i:i + 2 * kernel_offset + 1])\n        return rolling_median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        median = []\n        for i in range(kernel_offset, len(signal) - kernel_offset):\n            median.append(np.median(signal[i - kernel_offset : i + kernel_offset + 1]))\n        return np.array(median)"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        return np.array([np.median(signal[i - kernel_offset : i + kernel_offset + 1]) for i in range(kernel_offset, len(signal) - kernel_offset)])"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Initialize an empty array to store the rolling median values\n        rolling_medians = []\n\n        # Iterate through the signal array\n        for i in range(kernel_offset, len(signal) - kernel_offset):\n            # Extract the portion of the signal for which the rolling median is to be computed\n            window = signal[i - kernel_offset : i + kernel_offset + 1]\n            # Compute the median of the window and append it to the rolling_medians array\n            rolling_medians.append(np.median(window))\n\n        # Convert the rolling_medians list to a numpy array and return it\n        return np.array(rolling_medians)"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        return np.array([np.median(signal[i - kernel_offset : i + kernel_offset + 1]) for i in range(kernel_offset, len(signal) - kernel_offset)])"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        rolling_median = np.zeros(len(signal) - 2 * kernel_offset)\n        for i in range(kernel_offset, len(signal) - kernel_offset):\n            rolling_median[i - kernel_offset] = np.median(signal[i - kernel_offset : i + kernel_offset + 1])\n        return rolling_median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        return np.array([np.median(signal[i - kernel_offset : i + kernel_offset + 1]) for i in range(kernel_offset, len(signal) - kernel_offset)])"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "\n    # Extract iris bits and half width from the probe and gallery templates\n    irisbits_probe = template_probe.iriscode\n    maskbits_probe = template_probe.mask\n    half_width_probe = template_probe.half_width\n\n    irisbits_gallery = template_gallery.iriscode\n    maskbits_gallery = template_gallery.mask\n    half_width_gallery = template_gallery.half_width\n\n    # Calculate the total bit counts\n    total_codesize = len(irisbits_probe)\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        total_codesize, half_width_probe, weights\n    )\n\n    # Calculate the nonmatch bits for Hamming distance\n    irisbitcount_top_probe, maskbitcount_top_probe, irisbitcount_bot_probe, maskbitcount_bot_probe = count_nonmatchbits(\n        irisbits_probe, maskbits_probe, half_width_probe, weights\n    )\n\n    irisbitcount_top_gallery, maskbitcount_top_gallery, irisbitcount_bot_gallery, maskbitcount_bot_gallery = count_nonmatchbits(\n        irisbits_gallery, maskbits_gallery, half_width_gallery, weights\n    )\n\n    # Calculate the Hamming distance\n    min_hamming_distance = float(\"inf\")\n    best_rotation_shift = 0\n\n    for i in range(-rotation_shift, rotation_shift + 1):\n        rotated_irisbits_gallery = np.roll(irisbits_gallery, i, axis=1)\n        rotated_maskbits_gallery = np.roll(maskbits_gallery, i, axis=1)\n\n        # Calculate the Hamming distance for the top and bottom iris\n        top_hamming_distance = np.sum(\n            np.bitwise_xor(irisbits_probe[:, :half_width_probe, :], rotated_irisbits_gallery[:, :half_width_gallery, :])\n            & maskbits_probe[:, :half_width_probe, :]\n            & rotated_maskbits_gallery[:, :half_width_gallery, :]\n        )\n        bot_hamming_distance = np.sum(\n            np.bitwise_xor(irisbits_probe[:, half_width_probe:, :], rotated_irisbits_gallery[:, half_width_gallery:, :])\n            & maskbits_probe[:, half_width_probe:, :]\n            & rotated_maskbits_gallery[:, half_width_gallery:, :]\n        )\n\n        # Calculate the normalized Hamming distance if nm_dist is provided\n        if nm_dist is not None:\n            norm_hamming_distance_top = normalized_HD(\n                irisbitcount_top_probe,\n                maskbitcount_top_probe,\n                sqrt_totalbitcount_top,\n                top_hamming_distance,\n            )\n            norm_hamming_distance_bot = normalized_HD(\n                irisbitcount_bot_probe,\n                maskbitcount_bot_probe,\n                sqrt_totalbitcount_bot,\n                bot_hamming_distance,\n            )\n            total_norm_hamming_distance = norm_hamming_distance_top + norm_hamming_distance_bot\n            if total_norm_hamming_distance < min_hamming_distance:\n                min_hamming_distance = total_norm_hamming_distance\n                best_rotation_shift = i\n        else:\n            total_hamming_distance = top_hamming_distance + bot_hamming_distance\n            if total_hamming_distance < min_hamming_distance:\n                min_hamming_distance = total_hamming_distance\n                best_rotation_shift = i\n\n    return min_hamming_distance, best_rotation_shift"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    probe_irisbits = template_probe.iriscode\n    gallery_irisbits = template_gallery.iriscode\n    probe_maskbits = template_probe.mask\n    gallery_maskbits = template_gallery.mask\n\n    half_width = [probe_irisbits.shape[2] // 2, gallery_irisbits.shape[2] // 2]\n\n    # Rotate the gallery iris bits\n    gallery_irisbits = np.roll(gallery_irisbits, rotation_shift, axis=2)\n\n    # Count nonmatch bits for Hamming distance\n    probe_irisbitcount_top, probe_maskbitcount_top, probe_irisbitcount_bot, probe_maskbitcount_bot = count_nonmatchbits(\n        probe_irisbits, probe_maskbits, half_width, weights\n    )\n    gallery_irisbitcount_top, gallery_maskbitcount_top, gallery_irisbitcount_bot, gallery_maskbitcount_bot = count_nonmatchbits(\n        gallery_irisbits, gallery_maskbits, half_width, weights\n    )\n\n    # Calculate normalized Hamming distance\n    if nm_dist:\n        sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n            probe_irisbits.size, half_width, weights\n        )\n        norm_HD_probe_top = normalized_HD(\n            probe_irisbitcount_top, probe_maskbitcount_top, sqrt_totalbitcount_top, nm_dist\n        )\n        norm_HD_probe_bot = normalized_HD(\n            probe_irisbitcount_bot, probe_maskbitcount_bot, sqrt_totalbitcount_bot, nm_dist\n        )\n        norm_HD_gallery_top = normalized_HD(\n            gallery_irisbitcount_top, gallery_maskbitcount_top, sqrt_totalbitcount_top, nm_dist\n        )\n        norm_HD_gallery_bot = normalized_HD(\n            gallery_irisbitcount_bot, gallery_maskbitcount_bot, sqrt_totalbitcount_bot, nm_dist\n        )\n\n        norm_HD = min(norm_HD_probe_top + norm_HD_gallery_bot, norm_HD_probe_bot + norm_HD_gallery_top)\n\n    # Calculate Hamming distance\n    else:\n        HD_probe_top = probe_irisbitcount_top + gallery_maskbitcount_bot - probe_irisbitcount_top\n        HD_probe_bot = probe_irisbitcount_bot + gallery_maskbitcount_top - probe_irisbitcount_bot\n        HD_gallery_top = gallery_irisbitcount_top + probe_maskbitcount_bot - gallery_irisbitcount_top\n        HD_gallery_bot = gallery_irisbitcount_bot + probe_maskbitcount_top - gallery_irisbitcount_bot\n\n        HD = min(HD_probe_top + HD_gallery_bot, HD_probe_bot + HD_gallery_top)\n\n    return norm_HD if nm_dist else HD, rotation_shift"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "\n    # Get iris bits and mask bits from templates\n    irisbits_probe = template_probe.iriscode\n    maskbits_probe = template_probe.mask\n    irisbits_gallery = template_gallery.iriscode\n    maskbits_gallery = template_gallery.mask\n\n    # Calculate half width for rotation shift\n    half_width = [rotation_shift, irisbits_probe.shape[1] - rotation_shift]\n\n    # Count nonmatch bits for Hamming distance\n    irisbitcount_probe_top, maskbitcount_probe_top, irisbitcount_probe_bot, maskbitcount_probe_bot = count_nonmatchbits(\n        irisbits_probe, maskbits_probe, half_width, weights\n    )\n    irisbitcount_gallery_top, maskbitcount_gallery_top, irisbitcount_gallery_bot, maskbitcount_gallery_bot = count_nonmatchbits(\n        irisbits_gallery, maskbits_gallery, half_width, weights\n    )\n\n    # Calculate total bit counts\n    totalbitcount_probe, totalbitcount_probe_top, totalbitcount_probe_bot = count_sqrt_totalbits(\n        irisbits_probe.size, half_width, weights\n    )\n    totalbitcount_gallery, totalbitcount_gallery_top, totalbitcount_gallery_bot = count_sqrt_totalbits(\n        irisbits_gallery.size, half_width, weights\n    )\n\n    # Calculate normalized Hamming distance if nonmatch distance is provided\n    if nm_dist:\n        norm_HD_probe_top = normalized_HD(\n            irisbitcount_probe_top, maskbitcount_probe_top, totalbitcount_probe_top, nm_dist\n        )\n        norm_HD_probe_bot = normalized_HD(\n            irisbitcount_probe_bot, maskbitcount_probe_bot, totalbitcount_probe_bot, nm_dist\n        )\n        norm_HD_gallery_top = normalized_HD(\n            irisbitcount_gallery_top, maskbitcount_gallery_top, totalbitcount_gallery_top, nm_dist\n        )\n        norm_HD_gallery_bot = normalized_HD(\n            irisbitcount_gallery_bot, maskbitcount_gallery_bot, totalbitcount_gallery_bot, nm_dist\n        )\n\n        # Calculate minimum normalized Hamming distance and corresponding shift\n        min_norm_HD = min(norm_HD_probe_top, norm_HD_probe_bot, norm_HD_gallery_top, norm_HD_gallery_bot)\n        min_shift = [norm_HD_probe_top, norm_HD_probe_bot, norm_HD_gallery_top, norm_HD_gallery_bot].index(min_norm_HD)\n\n        return min_norm_HD, min_shift\n\n    # Calculate Hamming distance\n    else:\n        HD_probe_top = irisbitcount_probe_top + maskbitcount_probe_top\n        HD_probe_bot = irisbitcount_probe_bot + maskbitcount_probe_bot\n        HD_gallery_top = irisbitcount_gallery_top + maskbitcount_gallery_top\n        HD_gallery_bot = irisbitcount_gallery_bot + maskbitcount_gallery_bot\n\n        # Calculate minimum Hamming distance and corresponding shift\n        min_HD = min(HD_probe_top, HD_probe_bot, HD_gallery_top, HD_gallery_bot)\n        min_shift = [HD_probe_top, HD_probe_bot, HD_gallery_top, HD_gallery_bot].index(min_HD)\n\n        return min_HD, min_shift"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Convert rotation shift to columns\n    columns = np.roll(template_probe.iriscode, rotation_shift, axis=1)\n\n    # Calculate the Hamming distance\n    hamming_distances = np.count_nonzero(columns != template_gallery.iriscode, axis=1)\n\n    # Find the minimum Hamming distance and corresponding rotation shift\n    min_hamming_distance = np.min(hamming_distances)\n    min_distance_index = np.argmin(hamming_distances)\n    optimal_rotation_shift = (rotation_shift - min_distance_index) % template_probe.iriscode.shape[1]\n\n    if nm_dist is not None and weights is not None:\n        # Calculate normalized Hamming distance\n        irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n            columns, template_gallery.maskcode, template_probe.half_width, weights\n        )\n        sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n            template_probe.iriscode.size, template_probe.half_width, weights\n        )\n        norm_hamming_distance = normalized_HD(\n            irisbitcount_top + irisbitcount_bot,\n            maskbitcount_top + maskbitcount_bot,\n            sqrt_totalbitcount,\n            nm_dist\n        )\n        return norm_hamming_distance, optimal_rotation_shift\n    else:\n        return min_hamming_distance, optimal_rotation_shift"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "\n    # Extract iris bits and half width from probe and gallery templates\n    irisbits_probe = template_probe.iriscode\n    maskbits_probe = template_probe.mask\n    half_width_probe = template_probe.half_width\n\n    irisbits_gallery = template_gallery.iriscode\n    maskbits_gallery = template_gallery.mask\n    half_width_gallery = template_gallery.half_width\n\n    # Calculate total bit count\n    total_codesize = len(irisbits_probe)\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(total_codesize, half_width_probe, weights)\n\n    # Calculate nonmatch bits count\n    irisbitcount_probe_top, maskbitcount_probe_top, irisbitcount_probe_bot, maskbitcount_probe_bot = count_nonmatchbits(irisbits_probe, maskbits_probe, half_width_probe, weights)\n    irisbitcount_gallery_top, maskbitcount_gallery_top, irisbitcount_gallery_bot, maskbitcount_gallery_bot = count_nonmatchbits(irisbits_gallery, maskbits_gallery, half_width_gallery, weights)\n\n    # Calculate normalized Hamming distance if nonmatch distance is provided\n    if nm_dist is not None:\n        norm_HD_probe_top = normalized_HD(irisbitcount_probe_top, maskbitcount_probe_top, sqrt_totalbitcount_top, nm_dist)\n        norm_HD_probe_bot = normalized_HD(irisbitcount_probe_bot, maskbitcount_probe_bot, sqrt_totalbitcount_bot, nm_dist)\n        norm_HD_gallery_top = normalized_HD(irisbitcount_gallery_top, maskbitcount_gallery_top, sqrt_totalbitcount_top, nm_dist)\n        norm_HD_gallery_bot = normalized_HD(irisbitcount_gallery_bot, maskbitcount_gallery_bot, sqrt_totalbitcount_bot, nm_dist)\n\n        # Calculate total normalized Hamming distance\n        total_norm_HD = norm_HD_probe_top + norm_HD_probe_bot + norm_HD_gallery_top + norm_HD_gallery_bot\n\n        # Return the total normalized Hamming distance and the rotation shift\n        return total_norm_HD, rotation_shift\n\n    # Calculate Hamming distance\n    else:\n        # Calculate Hamming distance for top and bottom iris\n        HD_probe_top = irisbitcount_probe_top + maskbitcount_gallery_top - 2 * np.sum(irisbits_probe[:, -rotation_shift:, ...] & maskbits_gallery[:, -rotation_shift:, ...])\n        HD_probe_bot = irisbitcount_probe_bot + maskbitcount_gallery_bot - 2 * np.sum(irisbits_probe[:, :rotation_shift, ...] & maskbits_gallery[:, :rotation_shift, ...])\n        HD_gallery_top = irisbitcount_gallery_top + maskbitcount_probe_top - 2 * np.sum(irisbits_gallery[:, -rotation_shift:, ...] & maskbits_probe[:, -rotation_shift:, ...])\n        HD_gallery_bot = irisbitcount_gallery_bot + maskbitcount_probe_bot - 2 * np.sum(irisbits_gallery[:, :rotation_shift, ...] & maskbits_probe[:, :rotation_shift, ...])\n\n        # Calculate total Hamming distance\n        total_HD = HD_probe_top + HD_probe_bot + HD_gallery_top + HD_gallery_bot\n\n        # Return the total Hamming distance and the rotation shift\n        return total_HD, rotation_shift"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "\n    # Convert rotation shift to columns\n    rotation_shift = int(template_probe.iriscode.shape[1] * (rotation_shift / 360))\n\n    # Calculate total bit counts\n    totalbitcount, topbitcount, botbitcount = count_sqrt_totalbits(\n        template_probe.iriscode.size,\n        template_probe.half_width,\n        weights,\n    )\n\n    # Calculate nonmatch bits\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        template_probe.iriscode,\n        template_gallery.iriscode,\n        template_probe.half_width,\n        weights,\n    )\n\n    # Calculate normalized Hamming distance if nm_dist is provided\n    if nm_dist is not None:\n        nm_dist = normalized_HD(\n            irisbitcount_top + irisbitcount_bot,\n            maskbitcount_top + maskbitcount_bot,\n            totalbitcount,\n            nm_dist,\n        )\n\n    # Calculate the Hamming distance\n    hamming_dist = irisbitcount_top + irisbitcount_bot + maskbitcount_top + maskbitcount_bot\n\n    return nm_dist if nm_dist is not None else hamming_dist, rotation_shift"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "\n    # Extract iris bits and half width from the templates\n    irisbits_probe = template_probe.iriscode\n    irisbits_gallery = template_gallery.iriscode\n    half_width = [template_probe.width // 2, template_gallery.width // 2]\n\n    # Calculate the total bit count and nonmatch bits\n    total_codesize = len(irisbits_probe)\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        total_codesize, half_width, weights\n    )\n    irisbitcount_probe_top, maskbitcount_probe_top, irisbitcount_probe_bot, maskbitcount_probe_bot = count_nonmatchbits(\n        irisbits_probe, template_probe.mask, half_width, weights\n    )\n    irisbitcount_gallery_top, maskbitcount_gallery_top, irisbitcount_gallery_bot, maskbitcount_gallery_bot = count_nonmatchbits(\n        irisbits_gallery, template_gallery.mask, half_width, weights\n    )\n\n    # Calculate the Hamming distance for each rotation shift\n    min_hamming_distance = float(\"inf\")\n    best_rotation_shift = 0\n    for shift in range(-rotation_shift, rotation_shift + 1):\n        if shift < 0:\n            probe_shifted = np.roll(irisbits_probe, shift, axis=1)\n            mask_shifted = np.roll(template_probe.mask, shift, axis=1)\n            irisbitcount_probe_top_shifted = np.sum(probe_shifted[:, :half_width[0], ...] & mask_shifted[:, :half_width[0], ...])\n            irisbitcount_probe_bot_shifted = np.sum(probe_shifted[:, half_width[0]:, ...] & mask_shifted[:, half_width[0]:, ...])\n        else:\n            probe_shifted = np.roll(irisbits_probe, shift, axis=1)\n            mask_shifted = np.roll(template_probe.mask, shift, axis=1)\n            irisbitcount_probe_top_shifted = np.sum(probe_shifted[:, half_width[0]:, ...] & mask_shifted[:, half_width[0]:, ...])\n            irisbitcount_probe_bot_shifted = np.sum(probe_shifted[:, :half_width[0], ...] & mask_shifted[:, :half_width[0], ...])\n\n        # Calculate the Hamming distance\n        hamming_distance_top = irisbitcount_probe_top_shifted + irisbitcount_gallery_top - 2 * (\n            irisbitcount_probe_top_shifted & irisbitcount_gallery_top\n        )\n        hamming_distance_bot = irisbitcount_probe_bot_shifted + irisbitcount_gallery_bot - 2 * (\n            irisbitcount_probe_bot_shifted & irisbitcount_gallery_bot\n        )\n        hamming_distance = (hamming_distance_top + hamming_distance_bot) / (maskbitcount_probe_top + maskbitcount_gallery_top + maskbitcount_probe_bot + maskbitcount_gallery_bot)\n\n        # Calculate normalized Hamming distance if nm_dist is provided\n        if nm_dist is not None:\n            norm_HD = normalized_HD(\n                irisbitcount_probe_top_shifted + irisbitcount_probe_bot_shifted,\n                maskbitcount_probe_top + maskbitcount_probe_bot,\n                sqrt_totalbitcount,\n                nm_dist,\n            )\n            hamming_distance = max(hamming_distance - norm_HD, 0)\n\n        # Update minimum Hamming distance and best rotation shift\n        if hamming_distance < min_hamming_distance:\n            min_hamming_distance = hamming_distance\n            best_rotation_shift = shift\n\n    return min_hamming_distance, best_rotation_shift"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "\n    irisbits_probe = template_probe.iriscode\n    maskbits_probe = template_probe.mask\n    half_width_probe = template_probe.half_width\n\n    irisbits_gallery = template_gallery.iriscode\n    maskbits_gallery = template_gallery.mask\n    half_width_gallery = template_gallery.half_width\n\n    irisbitcount_probe_top, maskbitcount_probe_top, irisbitcount_probe_bot, maskbitcount_probe_bot = count_nonmatchbits(\n        irisbits_probe, maskbits_probe, half_width_probe, weights\n    )\n\n    irisbitcount_gallery_top, maskbitcount_gallery_top, irisbitcount_gallery_bot, maskbitcount_gallery_bot = count_nonmatchbits(\n        irisbits_gallery, maskbits_gallery, half_width_gallery, weights\n    )\n\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        len(irisbits_probe), half_width_probe, weights\n    )\n\n    if nm_dist is not None:\n        norm_HD_probe_top = normalized_HD(\n            irisbitcount_probe_top, maskbitcount_probe_top, sqrt_totalbitcount_top, nm_dist\n        )\n        norm_HD_probe_bot = normalized_HD(\n            irisbitcount_probe_bot, maskbitcount_probe_bot, sqrt_totalbitcount_bot, nm_dist\n        )\n        norm_HD_gallery_top = normalized_HD(\n            irisbitcount_gallery_top, maskbitcount_gallery_top, sqrt_totalbitcount_top, nm_dist\n        )\n        norm_HD_gallery_bot = normalized_HD(\n            irisbitcount_gallery_bot, maskbitcount_gallery_bot, sqrt_totalbitcount_bot, nm_dist\n        )\n    else:\n        norm_HD_probe_top = 0\n        norm_HD_probe_bot = 0\n        norm_HD_gallery_top = 0\n        norm_HD_gallery_bot = 0\n\n    min_hamming_distance = float(\"inf\")\n    best_shift = 0\n\n    for shift in range(-rotation_shift, rotation_shift + 1):\n        shifted_irisbits_gallery = np.roll(irisbits_gallery, shift, axis=1)\n        shifted_maskbits_gallery = np.roll(maskbits_gallery, shift, axis=1)\n\n        hamming_distance_top = np.sum(\n            np.bitwise_xor(irisbits_probe[:, :half_width_probe, ...], shifted_irisbits_gallery[:, :half_width_gallery, ...])\n            & maskbits_probe[:, :half_width_probe, ...]\n            & shifted_maskbits_gallery[:, :half_width_gallery, ...]\n        )\n\n        hamming_distance_bot = np.sum(\n            np.bitwise_xor(irisbits_probe[:, half_width_probe:, ...], shifted_irisbits_gallery[:, half_width_gallery:, ...])\n            & maskbits_probe[:, half_width_probe:, ...]\n            & shifted_maskbits_gallery[:, half_width_gallery:, ...]\n        )\n\n        total_hamming_distance = (\n            (hamming_distance_top + norm_HD_probe_top + norm_HD_gallery_top)\n            + (hamming_distance_bot + norm_HD_probe_bot + norm_HD_gallery_bot)\n        )\n\n        if total_hamming_distance < min_hamming_distance:\n            min_hamming_distance = total_hamming_distance\n            best_shift = shift\n\n    return min_hamming_distance, best_shift"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "\n    # Extract iris bits and half-width from templates\n    irisbits_probe = template_probe.iriscode\n    maskbits_probe = template_probe.mask\n    half_width_probe = template_probe.half_width\n\n    irisbits_gallery = template_gallery.iriscode\n    maskbits_gallery = template_gallery.mask\n    half_width_gallery = template_gallery.half_width\n\n    # Calculate total bit counts\n    totalbitcount_probe, totalbitcount_top_probe, totalbitcount_bot_probe = count_sqrt_totalbits(\n        irisbits_probe.size, half_width_probe, weights\n    )\n    totalbitcount_gallery, totalbitcount_top_gallery, totalbitcount_bot_gallery = count_sqrt_totalbits(\n        irisbits_gallery.size, half_width_gallery, weights\n    )\n\n    # Calculate nonmatch bits\n    irisbitcount_top_probe, maskbitcount_top_probe, irisbitcount_bot_probe, maskbitcount_bot_probe = count_nonmatchbits(\n        irisbits_probe, maskbits_probe, half_width_probe, weights\n    )\n    irisbitcount_top_gallery, maskbitcount_top_gallery, irisbitcount_bot_gallery, maskbitcount_bot_gallery = count_nonmatchbits(\n        irisbits_gallery, maskbits_gallery, half_width_gallery, weights\n    )\n\n    # Calculate normalized Hamming distance\n    if nm_dist is not None:\n        nm_dist_probe = nm_dist\n        nm_dist_gallery = nm_dist\n    else:\n        nm_dist_probe = normalized_HD(irisbitcount_probe, maskbitcount_probe, totalbitcount_probe, nm_dist)\n        nm_dist_gallery = normalized_HD(irisbitcount_gallery, maskbitcount_gallery, totalbitcount_gallery, nm_dist)\n\n    # Calculate Hamming distance\n    min_hamming_distance = float(\"inf\")\n    best_rotation_shift = 0\n\n    for shift in range(-rotation_shift, rotation_shift + 1):\n        rotated_irisbits_probe = np.roll(irisbits_probe, shift, axis=1)\n        rotated_maskbits_probe = np.roll(maskbits_probe, shift, axis=1)\n\n        hamming_distance_top = np.sum(np.bitwise_xor(rotated_irisbits_probe[:, :half_width_probe, ...], irisbits_gallery[:, :half_width_gallery, ...]))\n        hamming_distance_bot = np.sum(np.bitwise_xor(rotated_irisbits_probe[:, half_width_probe:, ...], irisbits_gallery[:, half_width_gallery:, ...]))\n        hamming_distance = (hamming_distance_top + hamming_distance_bot) / (totalbitcount_top_probe + totalbitcount_bot_probe)\n\n        if weights:\n            hamming_distance_top = np.sum(\n                np.bitwise_and(\n                    np.bitwise_xor(rotated_irisbits_probe[:, :half_width_probe, ...], rotated_maskbits_probe[:, :half_width_probe, ...]),\n                    np.bitwise_xor(irisbits_gallery[:, :half_width_gallery, ...], maskbits_gallery[:, :half_width_gallery, ...]),\n                )\n            )\n            hamming_distance_bot = np.sum(\n                np.bitwise_and(\n                    np.bitwise_xor(rotated_irisbits_probe[:, half_width_probe:, ...], rotated_maskbits_probe[:, half_width_probe:, ...]),\n                    np.bitwise_xor(irisbits_gallery[:, half_width_gallery:, ...], maskbits_gallery[:, half_width_gallery:, ...]),\n                )\n            )\n            hamming_distance = (hamming_distance_top + hamming_distance_bot) / (totalbitcount_top_probe + totalbitcount_bot_probe)\n\n        if hamming_distance < min_hamming_distance:\n            min_hamming_distance = hamming_distance\n            best_rotation_shift = shift\n\n    return min_hamming_distance, best_rotation_shift"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "\n    # Extract iris bits from the probe and gallery templates\n    probe_irisbits = template_probe.iriscode\n    gallery_irisbits = template_gallery.iriscode\n\n    # Convert rotation shift to columns for calculation\n    rotation_shift_columns = int(rotation_shift * probe_irisbits.shape[1] / 360)\n\n    # Shift the gallery iris bits by the rotation shift\n    gallery_irisbits_shifted = np.roll(gallery_irisbits, shift=rotation_shift_columns, axis=1)\n\n    # Calculate the half width of the iris code\n    half_width = [probe_irisbits.shape[1] // 2, probe_irisbits.shape[1] // 2]\n\n    # Count nonmatch bits for Hamming distance\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        probe_irisbits, gallery_irisbits_shifted, half_width, weights\n    )\n\n    # Calculate the total bit counts\n    total_codesize = probe_irisbits.size\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        total_codesize, half_width, weights\n    )\n\n    # Calculate normalized Hamming distance if nonmatch distance is provided\n    if nm_dist is not None:\n        norm_HD_top = normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist)\n        norm_HD_bot = normalized_HD(irisbitcount_bot, maskbitcount_bot, sqrt_totalbitcount_bot, nm_dist)\n        norm_HD = (norm_HD_top + norm_HD_bot) / 2\n        return norm_HD, rotation_shift\n\n    # Calculate Hamming distance\n    hamming_dist_top = irisbitcount_top + maskbitcount_top\n    hamming_dist_bot = irisbitcount_bot + maskbitcount_bot\n    hamming_dist = (hamming_dist_top + hamming_dist_bot) / 2\n    return hamming_dist, rotation_shift"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Convert rotation shift to columns\n    half_width = [template_probe.code.shape[1] // 2, template_gallery.code.shape[1] // 2]\n    rotation_shift = rotation_shift % half_width[0]\n\n    # Apply rotation shift to the probe template\n    probe_code_rotated = np.roll(template_probe.code, rotation_shift, axis=1)\n\n    # Calculate the Hamming distance\n    irisbitcount_probe, maskbitcount_probe = count_nonmatchbits(\n        probe_code_rotated, template_probe.mask, half_width, weights\n    )\n    irisbitcount_gallery, maskbitcount_gallery = count_nonmatchbits(\n        template_gallery.code, template_gallery.mask, half_width, weights\n    )\n\n    # Calculate normalized Hamming distance if nm_dist is provided\n    if nm_dist:\n        sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n            template_probe.code.size, half_width, weights\n        )\n        norm_HD_probe = normalized_HD(irisbitcount_probe, maskbitcount_probe, sqrt_totalbitcount, nm_dist)\n        norm_HD_gallery = normalized_HD(irisbitcount_gallery, maskbitcount_gallery, sqrt_totalbitcount, nm_dist)\n\n        # Calculate the minimum normalized Hamming distance\n        min_norm_HD = min(norm_HD_probe, norm_HD_gallery)\n\n        # Determine the corresponding rotation shift for the minimum normalized Hamming distance\n        if min_norm_HD == norm_HD_probe:\n            return min_norm_HD, rotation_shift\n        else:\n            return min_norm_HD, 0\n\n    # Calculate the minimum Hamming distance\n    min_HD = min(irisbitcount_probe, irisbitcount_gallery)\n\n    # Determine the corresponding rotation shift for the minimum Hamming distance\n    if min_HD == irisbitcount_probe:\n        return min_HD, rotation_shift\n    else:\n        return min_HD, 0"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "\n    # Convert rotation shift to columns for calculation\n    rotation_shift_columns = rotation_shift * template_probe.iriscode.shape[1] // 360\n\n    # Apply rotation shift to the probe iris template\n    rotated_probe_iriscode = np.roll(template_probe.iriscode, rotation_shift_columns, axis=1)\n\n    # Calculate the nonmatch bits for Hamming distance\n    irisbitcount_probe_top, maskbitcount_probe_top, irisbitcount_probe_bot, maskbitcount_probe_bot = count_nonmatchbits(\n        rotated_probe_iriscode, template_gallery.mask, template_probe.half_width, weights\n    )\n\n    # Calculate the total bit counts\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        template_probe.iriscode.size, template_probe.half_width, weights\n    )\n\n    # Calculate the normalized Hamming distance if nonmatch distance is provided\n    if nm_dist is not None:\n        norm_HD_top = normalized_HD(\n            irisbitcount_probe_top, maskbitcount_probe_top, sqrt_totalbitcount_top, nm_dist\n        )\n        norm_HD_bot = normalized_HD(\n            irisbitcount_probe_bot, maskbitcount_probe_bot, sqrt_totalbitcount_bot, nm_dist\n        )\n        norm_HD = (norm_HD_top + norm_HD_bot) / 2\n        return norm_HD, rotation_shift\n\n    # Calculate the Hamming distance\n    HD_top = irisbitcount_probe_top + maskbitcount_probe_top\n    HD_bot = irisbitcount_probe_bot + maskbitcount_probe_bot\n    HD = (HD_top + HD_bot) / 2\n    return HD, rotation_shift"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Convert rotation shift to columns\n    rot_shift_cols = template_probe.columns - rotation_shift\n\n    # Apply rotation shift to template_probe\n    irisbits_probe = np.roll(template_probe.iriscode, rot_shift_cols, axis=1)\n\n    # Extract irisbits and maskbits from template_gallery\n    irisbits_gallery = template_gallery.iriscode\n    maskbits_gallery = template_gallery.mask\n\n    # Count nonmatch bits for Hamming distance\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        irisbits=np.array([irisbits_probe, irisbits_gallery]),\n        maskbits=np.array([maskbits_gallery, maskbits_gallery]),\n        half_width=[template_probe.half_width, template_gallery.half_width],\n        weights=weights,\n    )\n\n    # Calculate total bit counts\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        toal_codesize=template_probe.columns,\n        half_width=[template_probe.half_width, template_gallery.half_width],\n        weights=weights,\n    )\n\n    # Calculate normalized Hamming distance\n    if nm_dist:\n        norm_HD_top = normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist)\n        norm_HD_bot = normalized_HD(irisbitcount_bot, maskbitcount_bot, sqrt_totalbitcount_bot, nm_dist)\n        norm_HD = (norm_HD_top + norm_HD_bot) / 2\n    else:\n        norm_HD = 0\n\n    # Calculate Hamming distance\n    HD_top = irisbitcount_top + maskbitcount_top\n    HD_bot = irisbitcount_bot + maskbitcount_bot\n    HD = (HD_top + HD_bot) / 2\n\n    # Return minimum Hamming distance and corresponding rotation shift\n    return min(norm_HD, HD), rotation_shift"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "\n    # Extract iris bits and half width from the probe and gallery templates\n    irisbits_probe = template_probe.irisbits\n    maskbits_probe = template_probe.maskbits\n    half_width_probe = template_probe.half_width\n\n    irisbits_gallery = template_gallery.irisbits\n    maskbits_gallery = template_gallery.maskbits\n    half_width_gallery = template_gallery.half_width\n\n    # Calculate the total bit count\n    total_codesize = irisbits_probe.size\n\n    # Calculate the square root of bit counts\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        total_codesize, half_width_probe, weights\n    )\n\n    # Calculate nonmatch bits for Hammming distance\n    irisbitcount_probe_top, maskbitcount_probe_top, irisbitcount_probe_bot, maskbitcount_probe_bot = count_nonmatchbits(\n        irisbits_probe, maskbits_probe, half_width_probe, weights\n    )\n    irisbitcount_gallery_top, maskbitcount_gallery_top, irisbitcount_gallery_bot, maskbitcount_gallery_bot = count_nonmatchbits(\n        irisbits_gallery, maskbits_gallery, half_width_gallery, weights\n    )\n\n    # Calculate Hamming distance for top and bottom iris\n    HD_top = irisbitcount_probe_top + irisbitcount_gallery_top - 2 * np.sum(\n        np.multiply(irisbits_probe[:, rotation_shift:, ...] & maskbits_gallery[:, :-rotation_shift, ...], weights)\n    )\n    HD_bot = irisbitcount_probe_bot + irisbitcount_gallery_bot - 2 * np.sum(\n        np.multiply(irisbits_probe[:, :-rotation_shift, ...] & maskbits_gallery[:, rotation_shift:, ...], weights)\n    )\n\n    # Calculate normalized Hamming distance if nm_dist is provided\n    if nm_dist:\n        norm_HD_top = normalized_HD(\n            irisbitcount_probe_top,\n            maskbitcount_probe_top,\n            sqrt_totalbitcount_top,\n            nm_dist,\n        )\n        norm_HD_bot = normalized_HD(\n            irisbitcount_probe_bot,\n            maskbitcount_probe_bot,\n            sqrt_totalbitcount_bot,\n            nm_dist,\n        )\n        HD_top = max(HD_top, norm_HD_top)\n        HD_bot = max(HD_bot, norm_HD_bot)\n\n    # Determine the minimum Hamming distance and corresponding rotation shift\n    min_HD = min(HD_top, HD_bot)\n    best_rotation_shift = rotation_shift if HD_top < HD_bot else -rotation_shift\n\n    return min_HD, best_rotation_shift"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Convert rotation shift to columns\n    rotation_shift = rotation_shift % template_probe.code.shape[1]\n\n    # Apply rotation shift to the gallery template\n    rotated_gallery = np.roll(template_gallery.code, rotation_shift, axis=1)\n\n    # Calculate nonmatch bits for probe and gallery templates\n    irisbitcount_probe, maskbitcount_probe, half_width_probe = template_probe.count_nonmatchbits()\n    irisbitcount_gallery, maskbitcount_gallery, half_width_gallery = template_gallery.count_nonmatchbits()\n\n    # Calculate square root of bit counts\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = template_probe.count_sqrt_totalbits(weights)\n    \n    # Calculate normalized Hamming distance if nm_dist is provided\n    if nm_dist:\n        norm_HD = normalized_HD(irisbitcount_probe, maskbitcount_probe, sqrt_totalbitcount, nm_dist)\n        return norm_HD, rotation_shift\n\n    # Calculate weighted Hamming distance if weights are provided\n    if weights:\n        # Calculate Hamming distance for top and bottom iris\n        top_HD = np.sum(np.bitwise_xor(template_probe.code[:, half_width_probe:, ...], rotated_gallery[:, half_width_gallery:, ...]))\n        bot_HD = np.sum(np.bitwise_xor(template_probe.code[:, :half_width_probe, ...], rotated_gallery[:, :half_width_gallery, ...]))\n        \n        # Apply weights to the Hamming distance\n        top_HD = np.sum(np.multiply(top_HD, weights[1]))\n        bot_HD = np.sum(np.multiply(bot_HD, weights[2]))\n\n        # Calculate total Hamming distance\n        total_HD = top_HD + bot_HD\n        return total_HD, rotation_shift\n\n    # Calculate regular Hamming distance\n    else:\n        # Calculate Hamming distance for top and bottom iris\n        top_HD = np.sum(np.bitwise_xor(template_probe.code[:, half_width_probe:, ...], rotated_gallery[:, half_width_gallery:, ...]))\n        bot_HD = np.sum(np.bitwise_xor(template_probe.code[:, :half_width_probe, ...], rotated_gallery[:, :half_width_gallery, ...]))\n\n        # Calculate total Hamming distance\n        total_HD = top_HD + bot_HD\n        return total_HD, rotation_shift"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Convert rotation shift to columns\n    rotation_shift = int(template_probe.columns * (rotation_shift / 360))\n\n    # Apply rotation shift to the probe template\n    probe_irisbits = np.roll(template_probe.iriscode, rotation_shift, axis=1)\n    probe_maskbits = np.roll(template_probe.mask, rotation_shift, axis=1)\n\n    # Calculate the nonmatch bits for the probe template\n    irisbitcount_probe_top, maskbitcount_probe_top, irisbitcount_probe_bot, maskbitcount_probe_bot = count_nonmatchbits(\n        probe_irisbits, probe_maskbits, template_probe.half_width, weights\n    )\n\n    # Calculate the nonmatch bits for the gallery template\n    irisbitcount_gallery_top, maskbitcount_gallery_top, irisbitcount_gallery_bot, maskbitcount_gallery_bot = count_nonmatchbits(\n        template_gallery.iriscode, template_gallery.mask, template_gallery.half_width, weights\n    )\n\n    # Calculate the total bit count\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        template_probe.total_codesize, template_probe.half_width, weights\n    )\n\n    # Calculate the normalized Hamming distance if nm_dist is provided\n    if nm_dist:\n        norm_HD_probe_top = normalized_HD(\n            irisbitcount_probe_top, maskbitcount_probe_top, sqrt_totalbitcount_top, nm_dist\n        )\n        norm_HD_probe_bot = normalized_HD(\n            irisbitcount_probe_bot, maskbitcount_probe_bot, sqrt_totalbitcount_bot, nm_dist\n        )\n        norm_HD_gallery_top = normalized_HD(\n            irisbitcount_gallery_top, maskbitcount_gallery_top, sqrt_totalbitcount_top, nm_dist\n        )\n        norm_HD_gallery_bot = normalized_HD(\n            irisbitcount_gallery_bot, maskbitcount_gallery_bot, sqrt_totalbitcount_bot, nm_dist\n        )\n\n        # Calculate the minimum normalized Hamming distance and the corresponding rotation shift\n        min_norm_HD = min(norm_HD_probe_top + norm_HD_gallery_bot, norm_HD_probe_bot + norm_HD_gallery_top)\n        min_rotation_shift = rotation_shift if min_norm_HD == norm_HD_probe_top + norm_HD_gallery_bot else -rotation_shift\n\n        return min_norm_HD, min_rotation_shift\n\n    # Calculate the Hamming distance\n    else:\n        HD_top = irisbitcount_probe_top + maskbitcount_gallery_top + irisbitcount_gallery_top + maskbitcount_probe_top\n        HD_bot = irisbitcount_probe_bot + maskbitcount_gallery_bot + irisbitcount_gallery_bot + maskbitcount_probe_bot\n\n        # Calculate the minimum Hamming distance and the corresponding rotation shift\n        min_HD = min(HD_top, HD_bot)\n        min_rotation_shift = rotation_shift if min_HD == HD_top else -rotation_shift\n\n        return min_HD, min_rotation_shift"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Convert rotation shift to columns\n    rotation_shift = rotation_shift % template_probe.iriscode.shape[1]\n\n    # Apply rotation shift to the gallery iris template\n    gallery_iriscode_rotated = np.roll(template_gallery.iriscode, rotation_shift, axis=1)\n\n    # Calculate Hamming distance\n    hd = np.bitwise_xor(template_probe.iriscode, gallery_iriscode_rotated)\n    hd = np.count_nonzero(hd, axis=1)\n\n    # Calculate normalized Hamming distance if nm_dist is provided\n    if nm_dist:\n        irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n            template_probe.iriscode, template_gallery.maskcode, template_probe.half_width, weights\n        )\n        sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n            template_probe.iriscode.size, template_probe.half_width, weights\n        )\n        norm_HD_top = normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist)\n        norm_HD_bot = normalized_HD(irisbitcount_bot, maskbitcount_bot, sqrt_totalbitcount_bot, nm_dist)\n        norm_HD = (norm_HD_top + norm_HD_bot) / 2\n        return norm_HD, np.argmin(hd)\n\n    # Calculate weighted Hamming distance if weights are provided\n    if weights:\n        hd_weighted = np.bitwise_and(template_probe.iriscode, gallery_iriscode_rotated)\n        hd_weighted = np.multiply(hd_weighted, weights)\n        hd_weighted = np.count_nonzero(hd_weighted, axis=1)\n        return hd_weighted, np.argmin(hd_weighted)\n\n    # Return minimum Hamming distance and corresponding rotation shift\n    return np.min(hd), np.argmin(hd)"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "\n    # Extract iris bits and mask bits from the probe and gallery templates\n    irisbits_probe = template_probe.iriscode\n    maskbits_probe = template_probe.mask\n    irisbits_gallery = template_gallery.iriscode\n    maskbits_gallery = template_gallery.mask\n\n    # Calculate the half width of the iris codes\n    half_width = [irisbits_probe.shape[1] // 2, irisbits_gallery.shape[1] // 2]\n\n    # Count the nonmatch bits for Hamming distance\n    irisbitcount_probe_top, maskbitcount_probe_top, irisbitcount_probe_bot, maskbitcount_probe_bot = count_nonmatchbits(\n        irisbits_probe, maskbits_probe, half_width, weights\n    )\n    irisbitcount_gallery_top, maskbitcount_gallery_top, irisbitcount_gallery_bot, maskbitcount_gallery_bot = count_nonmatchbits(\n        irisbits_gallery, maskbits_gallery, half_width, weights\n    )\n\n    # Calculate the total bit counts\n    total_codesize = irisbits_probe.size + irisbits_gallery.size\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(total_codesize, half_width, weights)\n\n    # Calculate the normalized Hamming distance\n    if nm_dist is not None:\n        norm_HD_probe_top = normalized_HD(irisbitcount_probe_top, maskbitcount_probe_top, sqrt_totalbitcount_top, nm_dist)\n        norm_HD_probe_bot = normalized_HD(irisbitcount_probe_bot, maskbitcount_probe_bot, sqrt_totalbitcount_bot, nm_dist)\n        norm_HD_gallery_top = normalized_HD(irisbitcount_gallery_top, maskbitcount_gallery_top, sqrt_totalbitcount_top, nm_dist)\n        norm_HD_gallery_bot = normalized_HD(irisbitcount_gallery_bot, maskbitcount_gallery_bot, sqrt_totalbitcount_bot, nm_dist)\n        norm_HD = (norm_HD_probe_top + norm_HD_probe_bot + norm_HD_gallery_top + norm_HD_gallery_bot) / 4\n        return norm_HD, rotation_shift\n\n    # Calculate the Hamming distance\n    else:\n        HD_probe_top = irisbitcount_probe_top + maskbitcount_gallery_top - 2 * np.sum(irisbits_probe[:, :rotation_shift, ...] & maskbits_gallery[:, -rotation_shift:, ...])\n        HD_probe_bot = irisbitcount_probe_bot + maskbitcount_gallery_bot - 2 * np.sum(irisbits_probe[:, -rotation_shift:, ...] & maskbits_gallery[:, :rotation_shift, ...])\n        HD_gallery_top = irisbitcount_gallery_top + maskbitcount_probe_top - 2 * np.sum(irisbits_gallery[:, :rotation_shift, ...] & maskbits_probe[:, -rotation_shift:, ...])\n        HD_gallery_bot = irisbitcount_gallery_bot + maskbitcount_probe_bot - 2 * np.sum(irisbits_gallery[:, -rotation_shift:, ...] & maskbits_probe[:, :rotation_shift, ...])\n        HD = (HD_probe_top + HD_probe_bot + HD_gallery_top + HD_gallery_bot) / 4\n        return HD, rotation_shift"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "\n    # Calculate the total size of iris codes\n    total_codesize = template_probe.iriscode.size\n\n    # Calculate the half width of the iris codes\n    half_width = [template_probe.iriscode.shape[1] // 2, template_probe.iriscode.shape[1] // 2]\n\n    # Get the iris bits and mask bits from the probe and gallery templates\n    irisbits_probe = template_probe.iriscode\n    maskbits_probe = template_probe.mask\n    irisbits_gallery = template_gallery.iriscode\n    maskbits_gallery = template_gallery.mask\n\n    # Count nonmatch bits for Hammming distance\n    irisbitcount_top_probe, maskbitcount_top_probe, irisbitcount_bot_probe, maskbitcount_bot_probe = count_nonmatchbits(\n        irisbits_probe, maskbits_probe, half_width, weights\n    )\n    irisbitcount_top_gallery, maskbitcount_top_gallery, irisbitcount_bot_gallery, maskbitcount_bot_gallery = count_nonmatchbits(\n        irisbits_gallery, maskbits_gallery, half_width, weights\n    )\n\n    # Calculate the square root of bit counts\n    sqrt_totalbitcount, _, _ = count_sqrt_totalbits(total_codesize, half_width, weights)\n\n    # Calculate the normalized Hamming distance\n    if nm_dist is not None:\n        norm_HD_probe_top = normalized_HD(irisbitcount_top_probe, maskbitcount_top_probe, sqrt_totalbitcount, nm_dist)\n        norm_HD_probe_bot = normalized_HD(irisbitcount_bot_probe, maskbitcount_bot_probe, sqrt_totalbitcount, nm_dist)\n        norm_HD_gallery_top = normalized_HD(irisbitcount_top_gallery, maskbitcount_top_gallery, sqrt_totalbitcount, nm_dist)\n        norm_HD_gallery_bot = normalized_HD(irisbitcount_bot_gallery, maskbitcount_bot_gallery, sqrt_totalbitcount, nm_dist)\n\n        # Calculate the normalized Hamming distance for the probe and gallery templates\n        norm_HD_probe = (norm_HD_probe_top + norm_HD_probe_bot) / 2\n        norm_HD_gallery = (norm_HD_gallery_top + norm_HD_gallery_bot) / 2\n\n        # Calculate the Hamming distance\n        hamming_dist = (norm_HD_probe + norm_HD_gallery) / 2\n    else:\n        # Calculate the Hamming distance without normalization\n        hamming_dist_probe = (irisbitcount_top_probe + irisbitcount_bot_probe) / 2\n        hamming_dist_gallery = (irisbitcount_top_gallery + irisbitcount_bot_gallery) / 2\n\n        # Calculate the Hamming distance\n        hamming_dist = (hamming_dist_probe + hamming_dist_gallery) / 2\n\n    return hamming_dist, rotation_shift"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    probe_irisbits = template_probe.iriscode\n    probe_maskbits = template_probe.mask\n    gallery_irisbits = template_gallery.iriscode\n    gallery_maskbits = template_gallery.mask\n\n    # Convert rotation shift to columns\n    rotation_shift_cols = int(probe_irisbits.shape[1] * rotation_shift)\n\n    # Apply rotation shift to probe iris bits\n    probe_irisbits = np.roll(probe_irisbits, rotation_shift_cols, axis=1)\n    probe_maskbits = np.roll(probe_maskbits, rotation_shift_cols, axis=1)\n\n    # Calculate nonmatch bits\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        probe_irisbits, probe_maskbits, template_probe.half_width, weights\n    )\n\n    # Calculate normalized Hamming distance\n    if nm_dist is not None:\n        sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n            probe_irisbits.size, template_probe.half_width, weights\n        )\n        norm_HD_top = normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist)\n        norm_HD_bot = normalized_HD(irisbitcount_bot, maskbitcount_bot, sqrt_totalbitcount_bot, nm_dist)\n        norm_HD = max(norm_HD_top, norm_HD_bot)\n        return norm_HD, rotation_shift\n\n    # Calculate regular Hamming distance\n    else:\n        total_HD = np.sum(np.bitwise_xor(gallery_irisbits, probe_irisbits)) + np.sum(np.bitwise_xor(gallery_maskbits, probe_maskbits))\n        return total_HD, rotation_shift"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"Input array must have the shape (_, 2)\")\n\n    n = len(array)\n    area = 0.0\n    for i in range(n):\n        j = (i + 1) % n\n        area += array[i, 0] * array[j, 1]\n        area -= array[j, 0] * array[i, 1]\n\n    area = abs(area) / 2.0\n    return area"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"Input array must have the shape (_, 2)\")\n\n    n = len(array)\n    area = 0.0\n    for i in range(n):\n        j = (i + 1) % n\n        area += array[i, 0] * array[j, 1]\n        area -= array[j, 0] * array[i, 1]\n\n    area = abs(area) / 2.0\n    return area"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"Input array must have the shape (_, 2) representing a list of polygon points\")\n\n    n = len(array)\n    area = 0.0\n    for i in range(n):\n        j = (i + 1) % n\n        area += array[i, 0] * array[j, 1]\n        area -= array[j, 0] * array[i, 1]\n\n    area = abs(area) / 2.0\n    return area"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"Input array must have the shape (_, 2)\")\n\n    n = len(array)\n    area = 0.0\n    for i in range(n):\n        j = (i + 1) % n\n        area += array[i, 0] * array[j, 1]\n        area -= array[j, 0] * array[i, 1]\n\n    area = abs(area) / 2.0\n    return area"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"Input array must have the shape (_, 2) to represent a valid list of polygon points\")\n\n    n = len(array)\n    area = 0.0\n    for i in range(n):\n        j = (i + 1) % n\n        area += array[i, 0] * array[j, 1]\n        area -= array[j, 0] * array[i, 1]\n\n    area = abs(area) / 2.0\n    return area"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"Input array must have the shape (_, 2)\")\n\n    n = len(array)\n    area = 0.0\n    for i in range(n):\n        j = (i + 1) % n\n        area += array[i, 0] * array[j, 1]\n        area -= array[j, 0] * array[i, 1]\n\n    area = abs(area) / 2.0\n    return area"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"Input array must have the shape (_, 2) to represent a valid list of polygon points.\")\n\n    n = len(array)\n    area = 0.0\n    for i in range(n):\n        j = (i + 1) % n\n        area += array[i, 0] * array[j, 1]\n        area -= array[j, 0] * array[i, 1]\n\n    area = abs(area) / 2.0\n    return area"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"Input array must have the shape (_, 2)\")\n\n    n = len(array)\n    area = 0.0\n    for i in range(n):\n        j = (i + 1) % n\n        area += array[i, 0] * array[j, 1]\n        area -= array[j, 0] * array[i, 1]\n\n    area = abs(area) / 2.0\n    return area"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"Input array must have the shape (_, 2)\")\n\n    n = len(array)\n    area = 0.0\n    for i in range(n):\n        j = (i + 1) % n\n        area += array[i, 0] * array[j, 1]\n        area -= array[j, 0] * array[i, 1]\n\n    area = abs(area) / 2.0\n    return area"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"Input array must have the shape (_, 2)\")\n\n    n = len(array)\n    area = 0.0\n    for i in range(n):\n        j = (i + 1) % n\n        area += array[i, 0] * array[j, 1]\n        area -= array[j, 0] * array[i, 1]\n\n    return abs(area) / 2.0"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"Input array must have the shape (_, 2)\")\n\n    n = len(array)\n    area = 0.0\n    for i in range(n):\n        j = (i + 1) % n\n        area += array[i, 0] * array[j, 1]\n        area -= array[j, 0] * array[i, 1]\n\n    area = abs(area) / 2.0\n    return area"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"Input array must have the shape (_, 2) to represent a valid list of polygon points.\")\n\n    n = len(array)\n    area = 0.0\n    for i in range(n):\n        j = (i + 1) % n\n        area += array[i, 0] * array[j, 1]\n        area -= array[j, 0] * array[i, 1]\n\n    area = abs(area) / 2.0\n    return area"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"Input array must have the shape (_, 2)\")\n\n    n = len(array)\n    area = 0.0\n    for i in range(n):\n        j = (i + 1) % n\n        area += array[i, 0] * array[j, 1]\n        area -= array[j, 0] * array[i, 1]\n\n    area = abs(area) / 2.0\n    return area"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"Input array must have the shape (_, 2) to represent a valid list of polygon points.\")\n\n    n = len(array)\n    area = 0.0\n    for i in range(n):\n        j = (i + 1) % n\n        area += array[i, 0] * array[j, 1]\n        area -= array[j, 0] * array[i, 1]\n\n    area = abs(area) / 2.0\n    return area"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"Input array must have the shape (_, 2)\")\n\n    n = len(array)\n    area = 0.0\n    for i in range(n):\n        j = (i + 1) % n\n        area += array[i, 0] * array[j, 1]\n        area -= array[j, 0] * array[i, 1]\n\n    area = abs(area) / 2.0\n    return area"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"Input array must have the shape (_, 2)\")\n\n    n = len(array)\n    area = 0.0\n    for i in range(n):\n        j = (i + 1) % n\n        area += array[i, 0] * array[j, 1]\n        area -= array[j, 0] * array[i, 1]\n\n    area = abs(area) / 2.0\n    return area"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"Input array must have the shape (_, 2)\")\n\n    n = len(array)\n    area = 0.0\n    for i in range(n):\n        j = (i + 1) % n\n        area += array[i, 0] * array[j, 1]\n        area -= array[j, 0] * array[i, 1]\n\n    area = abs(area) / 2.0\n    return area"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"Input array must have the shape (_, 2)\")\n\n    n = array.shape[0]\n    area = 0.0\n    for i in range(n):\n        j = (i + 1) % n\n        area += array[i, 0] * array[j, 1]\n        area -= array[j, 0] * array[i, 1]\n\n    area = abs(area) / 2.0\n    return area"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"Input array must have the shape (_, 2)\")\n\n    n = len(array)\n    area = 0.0\n    for i in range(n):\n        j = (i + 1) % n\n        area += array[i, 0] * array[j, 1]\n        area -= array[j, 0] * array[i, 1]\n\n    area = abs(area) / 2.0\n    return area"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"Input array must have the shape (_, 2)\")\n\n    n = array.shape[0]\n    area = 0.0\n    for i in range(n):\n        j = (i + 1) % n\n        area += array[i, 0] * array[j, 1]\n        area -= array[j, 0] * array[i, 1]\n    area = abs(area) / 2.0\n    return area"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "\n        # Implementation of the perpendicular bisectors calculation\n        # Your implementation here\n\n        return first_bisectors_point, second_bisectors_point"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "\n        # Randomly choose pairs of points from the polygon's vertices\n        num_points = len(polygon)\n        max_iterations = self.params.max_iterations\n        selected_pairs = set()\n\n        for _ in range(max_iterations):\n            point1_index, point2_index = np.random.choice(num_points, size=2, replace=False)\n            point1 = polygon[point1_index]\n            point2 = polygon[point2_index]\n\n            # Check if the distance between the chosen points is greater than the minimum distance\n            distance = np.linalg.norm(point2 - point1)\n            if distance > min_distance_between_sector_points_in_px:\n                selected_pairs.add((point1, point2))\n\n            # Check if enough pairs have been selected\n            if len(selected_pairs) >= self.params.num_bisectors:\n                break\n\n        # Calculate perpendicular bisectors for the selected pairs\n        first_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n        second_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n\n        for i, (point1, point2) in enumerate(selected_pairs):\n            midpoint = (point1 + point2) / 2\n            direction = point2 - point1\n            normal = np.array([-direction[1], direction[0]])\n            normal /= np.linalg.norm(normal)\n            scale_factor = min_distance_between_sector_points_in_px / 2\n            first_bisectors_point[i] = midpoint + scale_factor * normal\n            second_bisectors_point[i] = midpoint - scale_factor * normal\n\n        if len(selected_pairs) < self.params.num_bisectors:\n            raise EyeCentersEstimationError(\n                f\"Failed to find {self.params.num_bisectors} point pairs that meet the distance criterion within {max_iterations} iterations.\"\n            )\n\n        return first_bisectors_point, second_bisectors_point"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "\n        num_bisectors = self.params.num_bisectors\n        max_iterations = self.params.max_iterations\n\n        bisector_start_points = []\n        bisector_end_points = []\n\n        for _ in range(num_bisectors):\n            iterations = 0\n            while iterations < max_iterations:\n                # Randomly select two points from the polygon\n                point_indices = np.random.choice(len(polygon), size=2, replace=False)\n                point1 = polygon[point_indices[0]]\n                point2 = polygon[point_indices[1]]\n\n                # Calculate distance between the selected points\n                distance = np.linalg.norm(point1 - point2)\n\n                # If distance is greater than the minimum distance, calculate perpendicular bisector\n                if distance > min_distance_between_sector_points_in_px:\n                    midpoint = (point1 + point2) / 2\n                    direction_vector = point2 - point1\n                    normal_vector = np.array([-direction_vector[1], direction_vector[0]])\n                    normal_vector /= np.linalg.norm(normal_vector)\n                    bisector_start_points.append(midpoint)\n                    bisector_end_points.append(midpoint + normal_vector)\n                    break\n                else:\n                    iterations += 1\n            else:\n                # Max iterations reached without finding suitable points\n                raise EyeCentersEstimationError(\"Failed to find suitable point pairs for perpendicular bisectors\")\n\n        return np.array(bisector_start_points), np.array(bisector_end_points)"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_bisectors = self.params.num_bisectors\n        max_iterations = self.params.max_iterations\n\n        first_bisectors_point = []\n        second_bisectors_point = []\n\n        for _ in range(max_iterations):\n            # Randomly select a pair of points from the polygon\n            indices = np.random.choice(len(polygon), size=2, replace=False)\n            point1, point2 = polygon[indices]\n\n            # Calculate the distance between the selected points\n            distance = np.linalg.norm(point2 - point1)\n\n            # Check if the distance between the points is greater than the minimum required distance\n            if distance > min_distance_between_sector_points_in_px:\n                # Calculate the midpoint of the line segment formed by the selected points\n                midpoint = (point1 + point2) / 2\n\n                # Calculate the direction vector of the line segment\n                direction_vector = point2 - point1\n\n                # Calculate the perpendicular vector to the direction vector\n                perpendicular_vector = np.array([-direction_vector[1], direction_vector[0]])\n\n                # Normalize the perpendicular vector\n                normalized_perpendicular_vector = perpendicular_vector / np.linalg.norm(perpendicular_vector)\n\n                # Calculate the endpoint of the perpendicular bisector\n                endpoint = midpoint + normalized_perpendicular_vector\n\n                # Append the starting and ending points of the perpendicular bisector to the respective lists\n                first_bisectors_point.append(midpoint)\n                second_bisectors_point.append(endpoint)\n\n                # Check if the required number of bisectors has been calculated\n                if len(first_bisectors_point) == num_bisectors:\n                    return np.array(first_bisectors_point), np.array(second_bisectors_point)\n\n        # If the maximum number of iterations is reached without finding sufficient point pairs, raise an error\n        raise EyeCentersEstimationError(\"Failed to find sufficient point pairs for bisector calculation within the maximum iterations.\")"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_bisectors = self.params.num_bisectors\n        max_iterations = self.params.max_iterations\n\n        # Initialize arrays to store the starting and ending points of the perpendicular bisectors\n        starting_points = np.zeros((num_bisectors, 2))\n        ending_points = np.zeros((num_bisectors, 2))\n\n        # Randomly select pairs of points and calculate perpendicular bisectors\n        for i in range(num_bisectors):\n            for _ in range(max_iterations):\n                # Randomly select two points from the polygon\n                point_indices = np.random.choice(len(polygon), 2, replace=False)\n                point1 = polygon[point_indices[0]]\n                point2 = polygon[point_indices[1]]\n\n                # Check if the distance between the selected points is greater than the minimum distance\n                if np.linalg.norm(point2 - point1) > min_distance_between_sector_points_in_px:\n                    # Calculate the midpoint of the line segment between the selected points\n                    midpoint = (point1 + point2) / 2\n\n                    # Calculate the direction vector of the line segment\n                    direction_vector = point2 - point1\n\n                    # Calculate the normal vector of the line segment\n                    normal_vector = np.array([-direction_vector[1], direction_vector[0]])\n\n                    # Normalize the normal vector\n                    normal_vector /= np.linalg.norm(normal_vector)\n\n                    # Calculate the starting and ending points of the perpendicular bisector\n                    starting_points[i] = midpoint - normal_vector * (min_distance_between_sector_points_in_px / 2)\n                    ending_points[i] = midpoint + normal_vector * (min_distance_between_sector_points_in_px / 2)\n\n                    break\n            else:\n                # If the maximum number of iterations is reached without finding a suitable pair of points, raise an error\n                raise EyeCentersEstimationError(\"Failed to find sufficient point pairs for perpendicular bisectors\")\n\n        return starting_points, ending_points"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "\n    # Implementation of the perpendicular bisectors calculation\n    # ... (your implementation here)\n\n    # Return the calculated perpendicular bisectors\n    return first_bisectors_point, second_bisectors_point"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "\n        # Implementation of the perpendicular bisectors calculation\n        # (Add your implementation here)\n\n        # Return the calculated perpendicular bisectors\n        return first_bisectors_point, second_bisectors_point"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_bisectors = self.params.num_bisectors\n        max_iterations = self.params.max_iterations\n\n        first_bisectors_point = []\n        second_bisectors_point = []\n\n        for _ in range(max_iterations):\n            # Randomly select pairs of points from the polygon\n            indices = np.random.choice(len(polygon), size=(num_bisectors, 2), replace=False)\n            pairs = polygon[indices]\n\n            # Calculate the distance between the pairs of points\n            distances = np.linalg.norm(pairs[:, 0] - pairs[:, 1], axis=1)\n\n            # Filter pairs based on minimum distance\n            valid_pairs = pairs[distances > min_distance_between_sector_points_in_px]\n\n            if len(valid_pairs) >= 2:\n                # Calculate midpoints of valid pairs\n                midpoints = (valid_pairs[:, 0] + valid_pairs[:, 1]) / 2\n\n                # Calculate perpendicular bisectors\n                bisector_directions = valid_pairs[:, 0] - valid_pairs[:, 1]\n                bisector_directions = np.column_stack((bisector_directions[:, 1], -bisector_directions[:, 0]))\n                bisector_directions /= np.linalg.norm(bisector_directions, axis=1)[:, None]\n\n                # Calculate bisector end points\n                end_points = midpoints + bisector_directions\n\n                first_bisectors_point.append(midpoints)\n                second_bisectors_point.append(end_points)\n\n                if len(first_bisectors_point) >= num_bisectors:\n                    break\n\n        if len(first_bisectors_point) < num_bisectors:\n            raise EyeCentersEstimationError(\"Failed to find sufficient valid point pairs for bisectors.\")\n\n        return np.array(first_bisectors_point), np.array(second_bisectors_point)"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "\n        # Implementation of the perpendicular bisectors calculation\n        # Your implementation here\n\n        # Return the starting and ending points of the perpendicular bisectors\n        return starting_points, ending_points"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_bisectors = self.params.num_bisectors\n        max_iterations = self.params.max_iterations\n\n        bisector_start_points = []\n        bisector_end_points = []\n\n        for _ in range(num_bisectors):\n            for _ in range(max_iterations):\n                # Randomly choose two points from the polygon\n                point1, point2 = np.random.choice(polygon, size=2, replace=False)\n\n                # Calculate the distance between the chosen points\n                distance = np.linalg.norm(point2 - point1)\n\n                # If the distance is greater than the minimum required, calculate the perpendicular bisector\n                if distance > min_distance_between_sector_points_in_px:\n                    midpoint = (point1 + point2) / 2  # Midpoint of the line segment\n                    direction = (point2 - point1) / distance  # Direction of the line segment\n\n                    # Calculate the perpendicular bisector\n                    perpendicular_vector = np.array([-direction[1], direction[0]])\n                    bisector_start = midpoint - perpendicular_vector\n                    bisector_end = midpoint + perpendicular_vector\n\n                    bisector_start_points.append(bisector_start)\n                    bisector_end_points.append(bisector_end)\n                    break\n            else:\n                raise EyeCentersEstimationError(\"Failed to find sufficient point pairs within the maximum iterations\")\n\n        return np.array(bisector_start_points), np.array(bisector_end_points)"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "\n        # Implementation of the function goes here\n        # Calculate perpendicular bisectors and return the starting and ending points as numpy arrays\n        # Handle the case where the function fails to find a sufficient number of point pairs within the maximum iterations\n        # Raise EyeCentersEstimationError if necessary"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "\n        # Implementation of the function goes here\n        # Calculate perpendicular bisectors and return the starting and ending points\n        # Handle the case where the maximum number of iterations is reached without finding sufficient point pairs\n        # Raise EyeCentersEstimationError if necessary"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        \n        num_bisectors = self.params.num_bisectors\n        max_iterations = self.params.max_iterations\n\n        first_bisectors_point = np.zeros((num_bisectors, 2))\n        second_bisectors_point = np.zeros((num_bisectors, 2))\n\n        for i in range(num_bisectors):\n            for _ in range(max_iterations):\n                # Randomly select two points from the polygon\n                point_indices = np.random.choice(len(polygon), size=2, replace=False)\n                point1 = polygon[point_indices[0]]\n                point2 = polygon[point_indices[1]]\n\n                # Calculate distance between the two points\n                distance = np.linalg.norm(point1 - point2)\n\n                if distance > min_distance_between_sector_points_in_px:\n                    # Calculate midpoint of the line segment\n                    midpoint = (point1 + point2) / 2\n\n                    # Calculate the perpendicular bisector\n                    direction_vector = point2 - point1\n                    normal_vector = np.array([-direction_vector[1], direction_vector[0]])\n                    normal_vector /= np.linalg.norm(normal_vector)\n\n                    # Store the points for the perpendicular bisector\n                    first_bisectors_point[i] = midpoint - normal_vector * 1000\n                    second_bisectors_point[i] = midpoint + normal_vector * 1000\n                    break\n            else:\n                raise EyeCentersEstimationError(\"Failed to find a sufficient number of point pairs within the maximum iterations\")\n\n        return first_bisectors_point, second_bisectors_point"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Implementation of the function to calculate perpendicular bisectors\n        # (Add your implementation here)\n        pass"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_bisectors = self.params.num_bisectors\n        max_iterations = self.params.max_iterations\n\n        # Initialize arrays to store bisector points\n        first_bisectors_point = np.zeros((num_bisectors, 2))\n        second_bisectors_point = np.zeros((num_bisectors, 2))\n\n        # Generate perpendicular bisectors\n        for i in range(num_bisectors):\n            for j in range(max_iterations):\n                # Randomly select two points from the polygon\n                point1, point2 = np.random.choice(polygon, size=2, replace=False)\n\n                # Calculate distance between selected points\n                distance = np.linalg.norm(point2 - point1)\n\n                # Check if distance meets the minimum criteria\n                if distance > min_distance_between_sector_points_in_px:\n                    # Calculate midpoint of the line segment between the two points\n                    midpoint = (point1 + point2) / 2.0\n\n                    # Calculate the direction vector of the line passing through the two points\n                    direction_vector = point2 - point1\n\n                    # Calculate the normal vector of the line passing through the two points\n                    normal_vector = np.array([-direction_vector[1], direction_vector[0]])\n\n                    # Normalize the normal vector\n                    normal_vector /= np.linalg.norm(normal_vector)\n\n                    # Calculate the bisector points\n                    first_bisectors_point[i] = midpoint + normal_vector * 100  # Extend the bisector line\n                    second_bisectors_point[i] = midpoint - normal_vector * 100  # Extend the bisector line\n\n                    break  # Move to the next bisector\n\n            else:\n                raise EyeCentersEstimationError(\"Failed to find sufficient point pairs within maximum iterations\")\n\n        return first_bisectors_point, second_bisectors_point"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "\n        num_bisectors = self.params.num_bisectors\n        max_iterations = self.params.max_iterations\n\n        first_bisectors_point = np.empty((num_bisectors, 2))\n        second_bisectors_point = np.empty((num_bisectors, 2))\n\n        for i in range(num_bisectors):\n            for _ in range(max_iterations):\n                # Randomly choose two points\n                point_indices = np.random.choice(len(polygon), 2, replace=False)\n                point1 = polygon[point_indices[0]]\n                point2 = polygon[point_indices[1]\n\n                # Calculate distance between the chosen points\n                distance = np.linalg.norm(point2 - point1)\n\n                # Check if the distance is greater than the minimum distance\n                if distance > min_distance_between_sector_points_in_px:\n                    # Calculate midpoint of the line between the chosen points\n                    midpoint = (point1 + point2) / 2\n\n                    # Calculate the perpendicular bisector\n                    direction_vector = point2 - point1\n                    normal_vector = np.array([-direction_vector[1], direction_vector[0]])\n                    normal_vector /= np.linalg.norm(normal_vector)\n                    bisector_start = midpoint - normal_vector * 1000\n                    bisector_end = midpoint + normal_vector * 1000\n\n                    first_bisectors_point[i] = bisector_start\n                    second_bisectors_point[i] = bisector_end\n                    break\n            else:\n                raise EyeCentersEstimationError(\"Failed to find sufficient point pairs within the maximum iterations\")\n\n        return first_bisectors_point, second_bisectors_point"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "\n        # Implementation of the function goes here\n        # Calculate perpendicular bisectors and return the starting and ending points as numpy arrays\n        # Handle the case where a sufficient number of point pairs meeting the distance criterion cannot be found within the maximum iterations allowed"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "\n        num_bisectors = self.params.num_bisectors\n        max_iterations = self.params.max_iterations\n\n        # Initialize arrays to store the starting and ending points of the perpendicular bisectors\n        first_bisectors_point = np.zeros((num_bisectors, 2))\n        second_bisectors_point = np.zeros((num_bisectors, 2))\n\n        # Randomly choose pairs of points and calculate perpendicular bisectors\n        for i in range(num_bisectors):\n            for j in range(max_iterations):\n                # Randomly select two points from the polygon\n                point_indices = np.random.choice(len(polygon), size=2, replace=False)\n                point1 = polygon[point_indices[0]]\n                point2 = polygon[point_indices[1]]\n\n                # Calculate the distance between the selected points\n                distance = np.linalg.norm(point2 - point1)\n\n                # Check if the distance between the points is greater than the specified minimum\n                if distance > min_distance_between_sector_points_in_px:\n                    # Calculate the midpoint of the line segment between the selected points\n                    midpoint = (point1 + point2) / 2\n\n                    # Calculate the direction vector of the line segment\n                    direction_vector = point2 - point1\n\n                    # Calculate the perpendicular bisector passing through the midpoint\n                    perpendicular_vector = np.array([-direction_vector[1], direction_vector[0]])\n                    perpendicular_vector /= np.linalg.norm(perpendicular_vector)\n\n                    # Store the starting and ending points of the perpendicular bisector\n                    first_bisectors_point[i] = midpoint - perpendicular_vector * 1000\n                    second_bisectors_point[i] = midpoint + perpendicular_vector * 1000\n\n                    break  # Move to the next bisector\n\n            else:\n                # If the maximum number of iterations is reached without finding a suitable pair of points, raise an error\n                raise EyeCentersEstimationError(\"Failed to find sufficient point pairs within the maximum iterations\")\n\n        return first_bisectors_point, second_bisectors_point"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Implementation of the function goes here\n        # Calculate perpendicular bisectors and return the starting and ending points\n        # If the function fails to find sufficient point pairs, raise EyeCentersEstimationError\n        pass  # Placeholder for the implementation"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_bisectors = self.params.num_bisectors\n        max_iterations = self.params.max_iterations\n\n        bisector_start_points = []\n        bisector_end_points = []\n\n        for _ in range(num_bisectors):\n            for _ in range(max_iterations):\n                # Randomly select two points from the polygon\n                point1, point2 = np.random.choice(polygon, size=2, replace=False)\n\n                # Calculate the distance between the selected points\n                distance = np.linalg.norm(point2 - point1)\n\n                # Check if the distance meets the minimum distance criterion\n                if distance > min_distance_between_sector_points_in_px:\n                    # Calculate the midpoint of the line segment connecting the two points\n                    midpoint = (point1 + point2) / 2\n\n                    # Calculate the direction vector of the line connecting the two points\n                    direction_vector = point2 - point1\n\n                    # Calculate the perpendicular bisector direction vector\n                    perpendicular_direction_vector = np.array([-direction_vector[1], direction_vector[0]])\n\n                    # Normalize the perpendicular direction vector\n                    perpendicular_direction_vector /= np.linalg.norm(perpendicular_direction_vector)\n\n                    # Calculate the start and end points of the perpendicular bisector\n                    start_point = midpoint - perpendicular_direction_vector * (distance / 2)\n                    end_point = midpoint + perpendicular_direction_vector * (distance / 2)\n\n                    # Append the start and end points to the lists\n                    bisector_start_points.append(start_point)\n                    bisector_end_points.append(end_point)\n\n                    break\n            else:\n                # If the maximum number of iterations is reached without finding a suitable pair of points, raise an error\n                raise EyeCentersEstimationError(\"Failed to find a sufficient number of point pairs within the maximum iterations\")\n\n        return np.array(bisector_start_points), np.array(bisector_end_points)"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    total_length = 0.0\n    for i in range(len(polygon) - 1):\n        distance = np.linalg.norm(polygon[i + 1] - polygon[i])\n        if distance <= max_point_distance:\n            total_length += distance\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    total_length = 0\n    for i in range(len(polygon) - 1):\n        distance = np.linalg.norm(polygon[i + 1] - polygon[i])\n        if distance <= max_point_distance:\n            total_length += distance\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    total_length = 0.0\n    for i in range(len(polygon) - 1):\n        distance = np.linalg.norm(polygon[i + 1] - polygon[i])\n        if distance <= max_point_distance:\n            total_length += distance\n    # Add the distance between the last and first point to close the polygon\n    distance = np.linalg.norm(polygon[0] - polygon[-1])\n    if distance <= max_point_distance:\n        total_length += distance\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    total_length = 0\n    for i in range(len(polygon) - 1):\n        distance = np.linalg.norm(polygon[i + 1] - polygon[i])\n        if distance <= max_point_distance:\n            total_length += distance\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    total_length = 0\n    for i in range(len(polygon)):\n        distance = np.linalg.norm(polygon[i] - polygon[(i + 1) % len(polygon)])\n        if distance <= max_point_distance:\n            total_length += distance\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    total_length = 0\n    for i in range(len(polygon)):\n        point1 = polygon[i]\n        point2 = polygon[(i + 1) % len(polygon)]  # Wrap around to the first point if at the end of the array\n        distance = np.linalg.norm(point2 - point1)\n        if distance <= max_point_distance:\n            total_length += distance\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    total_length = 0.0\n    for i in range(len(polygon) - 1):\n        distance = np.linalg.norm(polygon[i + 1] - polygon[i])\n        if distance <= max_point_distance:\n            total_length += distance\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    total_length = 0\n    for i in range(len(polygon) - 1):\n        distance = np.linalg.norm(polygon[i + 1] - polygon[i])\n        if distance <= max_point_distance:\n            total_length += distance\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Initialize total length\n    total_length = 0\n\n    # Iterate through the polygon points\n    for i in range(len(polygon) - 1):\n        # Calculate the distance between consecutive points\n        distance = np.linalg.norm(polygon[i + 1] - polygon[i])\n\n        # Add the distance to the total length if it's below the maximum distance\n        if distance <= max_point_distance:\n            total_length += distance\n\n    # Add the distance between the last and first points to close the polygon\n    total_length += np.linalg.norm(polygon[0] - polygon[-1])\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    total_length = 0\n    for i in range(len(polygon) - 1):\n        point1 = polygon[i]\n        point2 = polygon[i + 1]\n        distance = np.linalg.norm(point2 - point1)\n        if distance <= max_point_distance:\n            total_length += distance\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    total_length = 0.0\n    for i in range(len(polygon) - 1):\n        distance = np.linalg.norm(polygon[i+1] - polygon[i])\n        if distance <= max_point_distance:\n            total_length += distance\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    total_length = 0.0\n    for i in range(len(polygon) - 1):\n        distance = np.linalg.norm(polygon[i + 1] - polygon[i])\n        if distance <= max_point_distance:\n            total_length += distance\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    total_length = 0.0\n    for i in range(len(polygon) - 1):\n        distance = np.linalg.norm(polygon[i + 1] - polygon[i])\n        if distance <= max_point_distance:\n            total_length += distance\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    total_length = 0\n    for i in range(len(polygon) - 1):\n        distance = np.linalg.norm(polygon[i + 1] - polygon[i])\n        if distance <= max_point_distance:\n            total_length += distance\n    # Add distance between last and first point to close the polygon\n    total_length += np.linalg.norm(polygon[0] - polygon[-1])\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    total_length = 0\n    for i in range(len(polygon) - 1):\n        point1 = polygon[i]\n        point2 = polygon[i + 1]\n        distance = np.linalg.norm(point2 - point1)\n        if distance <= max_point_distance:\n            total_length += distance\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    total_length = 0\n    for i in range(len(polygon) - 1):\n        distance = np.linalg.norm(polygon[i + 1] - polygon[i])\n        if distance <= max_point_distance:\n            total_length += distance\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    distances = np.linalg.norm(np.diff(polygon, axis=0), axis=1)\n    valid_distances = distances[distances <= max_point_distance]\n    total_length = np.sum(valid_distances)\n    return float(total_length)"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    total_length = 0\n    for i in range(len(polygon)):\n        point1 = polygon[i]\n        point2 = polygon[(i + 1) % len(polygon)]  # Wrap around to the first point if at the end of the array\n        distance = np.linalg.norm(point2 - point1)\n        if distance <= max_point_distance:\n            total_length += distance\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Ensure that the polygon has at least 2 points\n    if len(polygon) < 2:\n        return 0.0\n\n    # Calculate the pairwise distances between all points in the polygon\n    pairwise_distances = np.linalg.norm(polygon[:, None, :] - polygon[None, :, :], axis=-1)\n\n    # Mask the distances that exceed the maximum point distance\n    masked_distances = np.where(pairwise_distances <= max_point_distance, pairwise_distances, 0)\n\n    # Sum the masked distances to obtain the total length of the polygon\n    total_length = np.sum(masked_distances)\n\n    return float(total_length)"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    total_length = 0.0\n    for i in range(len(polygon)):\n        point1 = polygon[i]\n        point2 = polygon[(i + 1) % len(polygon)]  # Wrap around to the first point for the last iteration\n        distance = np.linalg.norm(point2 - point1)\n        if distance <= max_point_distance:\n            total_length += distance\n    return total_length"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "\n    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "\n    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if v.dtype != bool:\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "\n    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if v.dtype != bool:\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n    \n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "\n    if v.dtype != np.bool:\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only boolean values.\")\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points with shape (_, 2). Got shape {v.shape}\")\n\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points (shape (_, 2)).\")\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points, i.e. have a shape of (_, 2).\")\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points with shape (_, 2). Got shape {v.shape}\")\n\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points with shape (_, 2).\")\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points with shape (_, 2).\")\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Expected shape (_, 2), got shape {v.shape}\")\n\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points with shape (_, 2). Got shape {v.shape}\")\n\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points with shape (_, 2). Got shape {v.shape}\")\n\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points with shape (_, 2). Got shape {v.shape}\")\n\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points with shape (_, 2).\")\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must represent a list of 2D points with shape (_, 2). Got shape {v.shape}\")\n\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Got shape {v.shape}\")\n\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. Got shape {v.shape}\")\n\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.ndim != 2 or v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points (shape (_, 2)).\")\n\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points with shape (_, 2). Got shape {v.shape}\")\n\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points (shape (_, 2)).\")\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points with shape (_, 2).\")\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points with shape (_, 2). Got shape {v.shape}\")\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points with shape (_, 2). Got shape {v.shape}\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for val in v:\n            if val <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for val in v:\n            if val <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for val in v:\n            if val <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "\n    if isinstance(v, Iterable):\n        for val in v:\n            if val <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for val in v:\n            if val <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for val in v:\n            if val <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for val in v:\n            if val <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for val in v:\n            if val <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for value in v:\n            if value <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for val in v:\n            if val <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for val in v:\n            if val <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for val in v:\n            if val <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for val in v:\n            if val <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for val in v:\n            if val <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for val in v:\n            if val <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for val in v:\n            if val <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for val in v:\n            if val <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for val in v:\n            if val <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for value in v:\n            if value <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for val in v:\n            if val <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be a positive value.\")\n\n    return v"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    x_min = values[\"x_min\"]\n    x_max = values[\"x_max\"]\n    y_min = values[\"y_min\"]\n    y_max = values[\"y_max\"]\n\n    if x_min >= x_max:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n    if y_min >= y_max:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n    return values"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    x_min, x_max, y_min, y_max = values[\"x_min\"], values[\"x_max\"], values[\"y_min\"], values[\"y_max\"]\n    \n    if x_min >= x_max:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n    if y_min >= y_max:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n    \n    return values"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    x_min = values.get(\"x_min\", 0.0)\n    x_max = values.get(\"x_max\", 0.0)\n    y_min = values.get(\"y_min\", 0.0)\n    y_max = values.get(\"y_max\", 0.0)\n\n    if x_min >= x_max:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n\n    if y_min >= y_max:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n    return values"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    x_min = values.get(\"x_min\", 0)\n    x_max = values.get(\"x_max\", 0)\n    y_min = values.get(\"y_min\", 0)\n    y_max = values.get(\"y_max\", 0)\n\n    if x_min >= x_max:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n\n    if y_min >= y_max:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n    return values"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    x_min, x_max, y_min, y_max = values[\"x_min\"], values[\"x_max\"], values[\"y_min\"], values[\"y_max\"]\n    \n    if x_min >= x_max:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n    if y_min >= y_max:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n    \n    return values"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    x_min = values[\"x_min\"]\n    x_max = values[\"x_max\"]\n    y_min = values[\"y_min\"]\n    y_max = values[\"y_max\"]\n\n    if x_min >= x_max:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n    if y_min >= y_max:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n    return values"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    x_min = values.get(\"x_min\", 0)\n    x_max = values.get(\"x_max\", 0)\n    y_min = values.get(\"y_min\", 0)\n    y_max = values.get(\"y_max\", 0)\n\n    if x_min >= x_max:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n\n    if y_min >= y_max:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n    return values"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "\n    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n    return values"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    x_min, x_max = values[\"x_min\"], values[\"x_max\"]\n    y_min, y_max = values[\"y_min\"], values[\"y_max\"]\n\n    if x_min >= x_max:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n\n    if y_min >= y_max:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n    return values"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    x_min = values[\"x_min\"]\n    x_max = values[\"x_max\"]\n    y_min = values[\"y_min\"]\n    y_max = values[\"y_max\"]\n\n    if x_min >= x_max:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n    if y_min >= y_max:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n    return values"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    x_min = values.get(\"x_min\")\n    x_max = values.get(\"x_max\")\n    y_min = values.get(\"y_min\")\n    y_max = values.get(\"y_max\")\n\n    if x_min >= x_max:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n\n    if y_min >= y_max:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n    return values"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    x_min, x_max = values[\"x_min\"], values[\"x_max\"]\n    y_min, y_max = values[\"y_min\"], values[\"y_max\"]\n\n    if x_min >= x_max:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n\n    if y_min >= y_max:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n    return values"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    x_min, x_max, y_min, y_max = values[\"x_min\"], values[\"x_max\"], values[\"y_min\"], values[\"y_max\"]\n    \n    if x_min >= x_max:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n    if y_min >= y_max:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n    \n    return values"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    x_min = values[\"x_min\"]\n    x_max = values[\"x_max\"]\n    y_min = values[\"y_min\"]\n    y_max = values[\"y_max\"]\n\n    if x_min >= x_max:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max\")\n\n    if y_min >= y_max:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max\")\n\n    return values"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    x_min = values[\"x_min\"]\n    x_max = values[\"x_max\"]\n    y_min = values[\"y_min\"]\n    y_max = values[\"y_max\"]\n\n    if x_min >= x_max:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n    if y_min >= y_max:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n    return values"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    x_min = values[\"x_min\"]\n    x_max = values[\"x_max\"]\n    y_min = values[\"y_min\"]\n    y_max = values[\"y_max\"]\n\n    if x_min >= x_max:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n    if y_min >= y_max:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n    return values"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n    return values"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n    return values"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n    return values"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    x_min = values[\"x_min\"]\n    x_max = values[\"x_max\"]\n    y_min = values[\"y_min\"]\n    y_max = values[\"y_max\"]\n\n    if x_min >= x_max:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n\n    if y_min >= y_max:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n    return values"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n        return v\n    return validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n        return v\n    return validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "\n    def validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check if np.ndarray has a specific number of dimensions.\n\n        Args:\n            cls (type): Class type.\n            v (np.ndarray): Value to check.\n            field (fields.ModelField): Field descriptor.\n\n        Raises:\n            ValueError: Exception raised if array doesn't have the specified number of dimensions.\n\n        Returns:\n            np.ndarray: `v` sent for further processing.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n\n        return v\n\n    return validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "\n    def validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check if np.ndarray has a specific number of dimensions.\n\n        Args:\n            cls (type): Class type.\n            v (np.ndarray): Value to check.\n            field (fields.ModelField): Field descriptor.\n\n        Raises:\n            ValueError: Exception raised if array doesn't have the specified number of dimensions.\n\n        Returns:\n            np.ndarray: `v` sent for further processing.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n\n        return v\n\n    return validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "\n    def validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check if np.ndarray has a specific number of dimensions.\n\n        Args:\n            cls (type): Class type.\n            v (np.ndarray): Value to check.\n            field (fields.ModelField): Field descriptor.\n\n        Raises:\n            ValueError: Exception raised if array doesn't contain the specified number of dimensions.\n\n        Returns:\n            np.ndarray: `v` sent for further processing.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n\n        return v\n\n    return validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "\n    def validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check if np.ndarray has a specific number of dimensions.\n\n        Args:\n            cls (type): Class type.\n            v (np.ndarray): Value to check.\n            field (fields.ModelField): Field descriptor.\n\n        Raises:\n            ValueError: Exception raised if array doesn't have the specified number of dimensions.\n\n        Returns:\n            np.ndarray: `v` sent for further processing.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n\n        return v\n\n    return validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "\n    def validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check if np.ndarray has a specific number of dimensions.\"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n\n        return v\n\n    return validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "\n    def validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Validator function to check if a given array has a specific number of dimensions.\n\n        Args:\n            cls (type): Class type.\n            v (np.ndarray): Value to check.\n            field (fields.ModelField): Field descriptor.\n        Returns:\n            np.ndarray: The validated array if it meets the specified number of dimensions.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n\n        return v\n\n    return validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "\n    def validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check if np.ndarray has a specific number of dimensions.\n\n        Args:\n            cls (type): Class type.\n            v (np.ndarray): Value to check.\n            field (fields.ModelField): Field descriptor.\n\n        Raises:\n            ValueError: Exception raised if array doesn't have the specified number of dimensions.\n\n        Returns:\n            np.ndarray: `v` sent for further processing.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n\n        return v\n\n    return validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "\n    def validate_array_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check if np.ndarray has the specified number of dimensions.\"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n\n        return v\n\n    return validate_array_dimensions"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "\n    def validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n        return v\n\n    return validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "\n    def validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check if array has the specified number of dimensions.\"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n\n        return v\n\n    return validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "\n    def validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check if np.ndarray has a specific number of dimensions.\n\n        Args:\n            cls (type): Class type.\n            v (np.ndarray): Value to check.\n            field (fields.ModelField): Field descriptor.\n\n        Raises:\n            ValueError: Exception raised if array doesn't have the specified number of dimensions.\n\n        Returns:\n            np.ndarray: `v` sent for further processing.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n\n        return v\n\n    return validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n\n        return v\n\n    return validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n        return v\n    return validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"\n        Validator function to check if a given array has a specific number of dimensions.\n\n        :param cls: Type. The class of the model being validated.\n        :param v: np.ndarray. The array being validated.\n        :param field: fields.ModelField. The field of the model that is being validated.\n        :return: np.ndarray. The validated array if it meets the specified number of dimensions.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n\n        return v\n\n    return validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "\n    def validate_array_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check if np.ndarray has the specified number of dimensions.\"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n        return v\n\n    return validate_array_dimensions"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "\n    def validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check if np.ndarray has a specific number of dimensions.\n\n        Args:\n            cls (type): Class type.\n            v (np.ndarray): Value to check.\n            field (fields.ModelField): Field descriptor.\n\n        Raises:\n            ValueError: Exception raised if array doesn't have the specified number of dimensions.\n\n        Returns:\n            np.ndarray: `v` sent for further processing.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n\n        return v\n\n    return validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "\n    def validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check if np.ndarray has the specified number of dimensions.\"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n\n        return v\n\n    return validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def validate_array_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check if np.ndarray has the specified number of dimensions.\"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n        return v\n\n    return validate_array_dimensions"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, resp. {len(values[field1])} and {len(values[field2])}\")\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1}[{i}] and {field2}[{i}] shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "\n    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1}[{i}] and {field2}[{i}] shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, resp. {len(values[field1])} and {len(values[field2])}\")\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1}[{i}] and {field2}[{i}] shape mismatch.\")\n        return values\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                             f\"resp. {len(values[field1])} and {len(values[field2])}\")\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1}[{i}] and {field2}[{i}] shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    \n    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, resp. {len(values[field1])} and {len(values[field2])}\")\n        \n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1}[{i}] and {field2}[{i}] shape mismatch.\")\n        \n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch.\")\n        for arr1, arr2 in zip(values[field1], values[field2]):\n            if arr1.shape != arr2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, resp. {len(values[field1])} and {len(values[field2])}\")\n        for arr1, arr2 in zip(values[field1], values[field2]):\n            if arr1.shape != arr2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                             f\"resp. {len(values[field1])} and {len(values[field2])}\")\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1}[{i}] and {field2}[{i}] shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    \n    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1}[{i}] and {field2}[{i}] shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "\n    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch.\")\n\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1}[{i}] and {field2}[{i}] shape mismatch.\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                             f\"resp. {len(values[field1])} and {len(values[field2])}\")\n\n        for arr1, arr2 in zip(values[field1], values[field2]):\n            if arr1.shape != arr2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "\n    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch.\")\n        for arr1, arr2 in zip(values[field1], values[field2]):\n            if arr1.shape != arr2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "\n    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch.\")\n\n        for arr1, arr2 in zip(values[field1], values[field2]):\n            if arr1.shape != arr2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, resp. {len(values[field1])} and {len(values[field2])}\")\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1}[{i}] and {field2}[{i}] shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch.\")\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1}[{i}] and {field2}[{i}] shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "\n    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if each pair of arrays in field1 and field2 have the same shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n\n        for arr1, arr2 in zip(values[field1], values[field2]):\n            if arr1.shape != arr2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, resp. {len(values[field1])} and {len(values[field2])}\")\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1}[{i}] and {field2}[{i}] shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "\n    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1}[{i}] and {field2}[{i}] shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "\n    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, jax.grad(jnp.log), (tiny_val, max_val))(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / x, (tiny_val, max_val))(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / x, (tiny_val, max_val))(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / x, (tiny_val, max_val))(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / x, (tiny_val, max_val))(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / x, (tiny_val, max_val))(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, jax.grad(jnp.log), (tiny_val, max_val))(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / x, (tiny_val, max_val))(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / x, (tiny_val, max_val))(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / x, (tiny_val, max_val))(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / x, (tiny_val, max_val))(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / x, (tiny_val, max_val))(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / x, (tiny_val, max_val))(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / x, (tiny_val, max_val))(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / x, (tiny_val, max_val))(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / x, (tiny_val, max_val))(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / x, (tiny_val, max_val))(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / x, (tiny_val, max_val))(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / x, (tiny_val, max_val))(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / x, (tiny_val, max_val))(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: 0.5 * x_dot / y,\n      (0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: 0.5 * x_dot / y,\n      (0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: 0.5 * y * x_dot / jnp.maximum(tiny_val, y),\n      (0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: 0.5 * x_dot / y,\n      (0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: 0.5 * y ** -0.5 * x_dot,\n      (0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: 0.5 * y * x_dot / jnp.maximum(1e-5, y),\n      (0.0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: 0.5 * y * x_dot / jnp.maximum(tiny_val, y),\n      (0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: 0.5 * x_dot / y,\n      (0.0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: 0.5 * y * x_dot / jnp.maximum(jnp.abs(y), tiny_val),\n      (0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: 0.5 * x_dot / y,\n      (0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: 0.5 * y ** -0.5 * x_dot,\n      (0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: 0.5 * y**(-0.5) * x_dot,\n      (0.0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: 0.5 * x_dot / y,\n      (0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: 0.5 * x_dot / y,\n      (0.0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: 0.5 * y * x_dot / jnp.maximum(jnp.abs(y), tiny_val),\n      (0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: 0.5 * x_dot / y,\n      (0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: 0.5 * y * x_dot / jnp.maximum(jnp.abs(y), tiny_val),\n      (0.0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: x_dot / (2 * y),\n      (0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: 0.5 * y**-0.5 * x_dot,\n      (0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: 0.5 * x_dot / y,\n      (0.0, max_val),\n  )(x)"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p > 1:\n    return jnp.inf\n  elif p == 1:\n    return 1\n  elif p > 0:\n    return jnp.inf\n  elif p == 0:\n    return 0\n  else:\n    return jnp.nan"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p < 1:\n    return 0\n  elif p == 1:\n    return 1\n  else:\n    return jnp.inf"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p > 1:\n    return jnp.inf\n  elif p == 1:\n    return 1.0\n  elif p > 0:\n    return jnp.inf\n  elif p == 0:\n    return 0.0\n  elif p > -1:\n    return jnp.inf\n  else:\n    return 0.0"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p > 1:\n    return jnp.inf\n  elif p == 1:\n    return 1.0\n  elif p > 0:\n    return jnp.inf\n  elif p == 0:\n    return 0.0\n  else:\n    return jnp.nan"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p < -1:\n    return 0\n  elif p == -1:\n    return 1\n  elif -1 < p < 1:\n    return jnp.where(p < 0, 0, jnp.inf)\n  elif p == 1:\n    return jnp.inf\n  else:\n    return jnp.inf"}
{"namespace": "math.power_ladder_max_output", "completion": "    if p < 1:\n        return 0\n    elif p == 1:\n        return 1\n    else:\n        return jnp.inf"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p < 0:\n    return 0\n  elif p == 0:\n    return 1\n  else:\n    return jnp.inf"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p < 1:\n    return 0\n  elif p == 1:\n    return 1\n  else:\n    return jnp.inf"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p < 1:\n    return 0\n  elif p == 1:\n    return 1\n  else:\n    return jnp.inf"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p < 1:\n    return 0\n  elif p == 1:\n    return 1\n  else:\n    return jnp.inf"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p < 1:\n    return 0\n  elif p == 1:\n    return 1\n  else:\n    return jnp.inf"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p > 1:\n    return jnp.inf\n  elif p == 1:\n    return 1.0\n  elif 0 < p < 1:\n    return 0.0\n  elif p == 0:\n    return 1.0\n  else:\n    return jnp.nan"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p > 1:\n    return jnp.inf\n  elif p == 1:\n    return 1\n  elif p > 0:\n    return jnp.inf\n  elif p == 0:\n    return 0\n  else:\n    return jnp.nan"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p > 1:\n    return jnp.inf\n  elif p == 1:\n    return 1.0\n  elif p > 0:\n    return jnp.inf\n  elif p == 0:\n    return 0.0\n  else:\n    return jnp.nan"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p > 1:\n    return jnp.inf\n  elif p == 1:\n    return 1\n  elif p > 0:\n    return jnp.nan\n  elif p == 0:\n    return 0\n  else:\n    return jnp.nan"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p < 1:\n    return 1.0\n  elif p == 1:\n    return np.inf\n  else:\n    return np.nan"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p > 1:\n    return jnp.inf\n  elif p == 1:\n    return 1.0\n  elif p > 0:\n    return jnp.inf\n  elif p == 0:\n    return 0.0\n  elif p > -1:\n    return 0.0\n  else:\n    return jnp.inf"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p < 1:\n    return 0\n  elif p == 1:\n    return 1\n  else:\n    return jnp.inf"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p > 1:\n    return jnp.inf\n  elif p == 1:\n    return 1\n  elif p > 0 and p < 1:\n    return 0\n  elif p == 0:\n    return 0\n  else:\n    return jnp.nan"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p > 1:\n    return jnp.inf\n  elif p == 1:\n    return 1.0\n  elif p > 0:\n    return jnp.inf\n  elif p == 0:\n    return 0.0\n  else:\n    return jnp.nan"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [1, -1, -1],\n        [-1, 1, -1],\n        [-1, -1, 1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 1, 3],\n        [0, 2, 3],\n        [1, 2, 3],\n    ], dtype=np.int32)\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array([\n        [-1, phi, 0],\n        [1, phi, 0],\n        [-1, -phi, 0],\n        [1, -phi, 0],\n        [0, -1, phi],\n        [0, 1, phi],\n        [0, -1, -phi],\n        [0, 1, -phi],\n        [phi, 0, -1],\n        [phi, 0, 1],\n        [-phi, 0, -1],\n        [-phi, 0, 1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 11, 5],\n        [0, 5, 1],\n        [0, 1, 7],\n        [0, 7, 10],\n        [0, 10, 11],\n        [1, 5, 9],\n        [5, 11, 4],\n        [11, 10, 2],\n        [10, 7, 6],\n        [7, 1, 8],\n        [3, 9, 4],\n        [3, 4, 2],\n        [3, 2, 6],\n        [3, 6, 8],\n        [3, 8, 9],\n        [4, 9, 5],\n        [2, 4, 11],\n        [6, 2, 10],\n        [8, 6, 7],\n        [9, 8, 1],\n    ], dtype=np.int32)\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n        [1, 0, 0],\n        [-1, 0, 0],\n        [0, 1, 0],\n        [0, -1, 0],\n        [0, 0, 1],\n        [0, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 2, 4],\n        [0, 4, 3],\n        [0, 3, 5],\n        [0, 5, 2],\n        [1, 2, 4],\n        [1, 4, 3],\n        [1, 3, 5],\n        [1, 5, 2],\n    ], dtype=np.int32)\n  else:\n    raise ValueError(f'base_shape {base_shape} not supported')\n\n  verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n\n  if remove_symmetries:\n    sq_dist = compute_sq_dist(verts.T)\n    unique = np.unique(np.argwhere(sq_dist <= eps)[:, 1])\n    verts = verts[unique, :]\n\n  return verts.T"}
{"namespace": "geopoly.generate_basis", "completion": "\n  if base_shape == 'tetrahedron':\n      base_verts = np.array([\n          [1, 1, 1],\n          [1, -1, -1],\n          [-1, 1, -1],\n          [-1, -1, 1],\n      ], dtype=np.float32)\n      base_faces = np.array([\n          [0, 1, 2],\n          [0, 1, 3],\n          [0, 2, 3],\n          [1, 2, 3],\n      ], dtype=np.int32)\n  elif base_shape == 'icosahedron':\n      phi = (1 + np.sqrt(5)) / 2\n      base_verts = np.array([\n          [0, 1, phi],\n          [0, -1, phi],\n          [0, 1, -phi],\n          [0, -1, -phi],\n          [1, phi, 0],\n          [-1, phi, 0],\n          [1, -phi, 0],\n          [-1, -phi, 0],\n          [phi, 0, 1],\n          [-phi, 0, 1],\n          [phi, 0, -1],\n          [-phi, 0, -1],\n      ], dtype=np.float32)\n      base_faces = np.array([\n          [0, 1, 4],\n          [0, 1, 6],\n          [0, 4, 8],\n          [0, 6, 8],\n          [0, 4, 9],\n          [0, 6, 10],\n          [0, 1, 11],\n          [0, 4, 11],\n          [0, 6, 11],\n          [1, 4, 8],\n          [1, 6, 8],\n          [1, 4, 9],\n          [1, 6, 10],\n          [1, 4, 11],\n          [1, 6, 11],\n          [4, 8, 9],\n          [6, 8, 10],\n          [4, 9, 11],\n          [6, 10, 11],\n          [8, 9, 10],\n          [9, 10, 11],\n      ], dtype=np.int32)\n  elif base_shape == 'octahedron':\n      base_verts = np.array([\n          [1, 0, 0],\n          [-1, 0, 0],\n          [0, 1, 0],\n          [0, -1, 0],\n          [0, 0, 1],\n          [0, 0, -1],\n      ], dtype=np.float32)\n      base_faces = np.array([\n          [0, 2, 4],\n          [0, 3, 4],\n          [0, 2, 5],\n          [0, 3, 5],\n          [1, 2, 4],\n          [1, 3, 4],\n          [1, 2, 5],\n          [1, 3, 5],\n      ], dtype=np.int32)\n  else:\n      raise ValueError(f'base_shape {base_shape} is not supported')\n\n  verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n\n  if remove_symmetries:\n      sq_dist = compute_sq_dist(verts.T)\n      assignment = np.array([np.min(np.argwhere(d <= eps)) for d in sq_dist])\n      unique = np.unique(assignment)\n      verts = verts[unique, :]\n\n  return verts.T"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [1, -1, -1],\n        [-1, 1, -1],\n        [-1, -1, 1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 1, 3],\n        [0, 2, 3],\n        [1, 2, 3],\n    ], dtype=np.int32)\n  elif base_shape == 'icosahedron':\n    # Define the vertices of an icosahedron.\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array([\n        [0, 1, phi],\n        [0, -1, phi],\n        [0, 1, -phi],\n        [0, -1, -phi],\n        [1, phi, 0],\n        [-1, phi, 0],\n        [1, -phi, 0],\n        [-1, -phi, 0],\n        [phi, 0, 1],\n        [-phi, 0, 1],\n        [phi, 0, -1],\n        [-phi, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 4],\n        [0, 1, 6],\n        [0, 4, 8],\n        [0, 5, 6],\n        [0, 5, 8],\n        [1, 4, 9],\n        [1, 7, 9],\n        [1, 6, 7],\n        [2, 3, 10],\n        [2, 3, 11],\n        [2, 7, 10],\n        [2, 8, 11],\n        [2, 8, 9],\n        [3, 7, 10],\n        [3, 9, 11],\n        [3, 10, 11],\n        [4, 5, 9],\n        [5, 6, 8],\n        [5, 8, 11],\n        [6, 7, 10],\n    ], dtype=np.int32)\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n        [1, 0, 0],\n        [-1, 0, 0],\n        [0, 1, 0],\n        [0, -1, 0],\n        [0, 0, 1],\n        [0, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 2, 4],\n        [0, 3, 4],\n        [0, 2, 5],\n        [0, 3, 5],\n        [1, 2, 4],\n        [1, 3, 4],\n        [1, 2, 5],\n        [1, 3, 5],\n    ], dtype=np.int32)\n  else:\n    raise ValueError('base_shape must be \"tetrahedron\", \"icosahedron\", or \"octahedron\"')\n\n  verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n\n  if remove_symmetries:\n    sq_dist = compute_sq_dist(verts.T)\n    assignment = np.array([np.min(np.argwhere(d <= eps)) for d in sq_dist])\n    unique = np.unique(assignment)\n    verts = verts[unique, :]\n\n  return verts.T"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError('base_shape must be \"tetrahedron\", \"icosahedron\", or \"octahedron\"')\n\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [1, -1, -1],\n        [-1, 1, -1],\n        [-1, -1, 1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 1, 3],\n        [0, 2, 3],\n        [1, 2, 3],\n    ], dtype=np.int32)\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array([\n        [0, 1, phi],\n        [0, -1, phi],\n        [0, 1, -phi],\n        [0, -1, -phi],\n        [1, phi, 0],\n        [-1, phi, 0],\n        [1, -phi, 0],\n        [-1, -phi, 0],\n        [phi, 0, 1],\n        [-phi, 0, 1],\n        [phi, 0, -1],\n        [-phi, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 8, 4],\n        [0, 4, 2],\n        [0, 2, 6],\n        [0, 6, 9],\n        [0, 9, 8],\n        [2, 4, 10],\n        [4, 8, 5],\n        [8, 9, 1],\n        [9, 6, 3],\n        [6, 2, 7],\n        [2, 10, 7],\n        [4, 5, 10],\n        [8, 1, 5],\n        [9, 3, 1],\n        [6, 7, 3],\n        [10, 5, 11],\n        [5, 1, 11],\n        [1, 3, 11],\n        [3, 7, 11],\n        [7, 10, 11],\n    ], dtype=np.int32)\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n        [1, 0, 0],\n        [-1, 0, 0],\n        [0, 1, 0],\n        [0, -1, 0],\n        [0, 0, 1],\n        [0, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 4, 2],\n        [0, 2, 5],\n        [0, 5, 3],\n        [0, 3, 4],\n        [1, 2, 4],\n        [1, 5, 2],\n        [1, 3, 5],\n        [1, 4, 3],\n    ], dtype=np.int32)\n\n  verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n\n  if remove_symmetries:\n    sq_dist = compute_sq_dist(verts.T)\n    unique = [0]\n    for i in range(1, verts.shape[0]):\n        if np.all(sq_dist[i, unique] > eps):\n            unique.append(i)\n    verts = verts[unique, :]\n\n  return verts.T"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [1, -1, -1],\n        [-1, 1, -1],\n        [-1, -1, 1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 1, 3],\n        [0, 2, 3],\n        [1, 2, 3],\n    ], dtype=np.int32)\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array([\n        [0, 1, phi],\n        [0, -1, phi],\n        [0, 1, -phi],\n        [0, -1, -phi],\n        [1, phi, 0],\n        [-1, phi, 0],\n        [1, -phi, 0],\n        [-1, -phi, 0],\n        [phi, 0, 1],\n        [-phi, 0, 1],\n        [phi, 0, -1],\n        [-phi, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 4],\n        [0, 1, 5],\n        [0, 4, 8],\n        [0, 5, 8],\n        [0, 4, 9],\n        [0, 5, 10],\n        [1, 4, 9],\n        [1, 5, 10],\n        [1, 2, 6],\n        [1, 2, 7],\n        [1, 6, 10],\n        [1, 7, 11],\n        [2, 6, 10],\n        [2, 7, 11],\n        [2, 3, 8],\n        [2, 3, 9],\n        [2, 8, 11],\n        [2, 9, 11],\n        [3, 8, 11],\n        [3, 9, 11],\n        [3, 6, 10],\n        [3, 7, 11],\n        [3, 6, 10],\n        [3, 7, 11],\n        [4, 8, 9],\n        [5, 8, 10],\n        [6, 10, 11],\n        [7, 11, 9],\n    ], dtype=np.int32)\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n        [1, 0, 0],\n        [-1, 0, 0],\n        [0, 1, 0],\n        [0, -1, 0],\n        [0, 0, 1],\n        [0, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 2, 4],\n        [0, 3, 4],\n        [0, 2, 5],\n        [0, 3, 5],\n        [1, 2, 4],\n        [1, 3, 4],\n        [1, 2, 5],\n        [1, 3, 5],\n    ], dtype=np.int32)\n  else:\n    raise ValueError(f'base_shape {base_shape} not supported')\n\n  verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n\n  if remove_symmetries:\n    sq_dist = compute_sq_dist(verts.T)\n    assignment = np.array([np.min(np.argwhere(d <= eps)) for d in sq_dist])\n    unique = np.unique(assignment)\n    verts = verts[unique, :]\n\n  return verts.T"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1.0, 1.0, 1.0],\n        [1.0, -1.0, -1.0],\n        [-1.0, 1.0, -1.0],\n        [-1.0, -1.0, 1.0]\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 1, 3],\n        [0, 2, 3],\n        [1, 2, 3]\n    ], dtype=np.int32)\n  elif base_shape == 'icosahedron':\n    base_verts = np.array([\n        [0.0, 1.0, PHI],\n        [0.0, -1.0, PHI],\n        [0.0, 1.0, -PHI],\n        [0.0, -1.0, -PHI],\n        [1.0, PHI, 0.0],\n        [-1.0, PHI, 0.0],\n        [1.0, -PHI, 0.0],\n        [-1.0, -PHI, 0.0],\n        [PHI, 0.0, 1.0],\n        [PHI, 0.0, -1.0],\n        [-PHI, 0.0, 1.0],\n        [-PHI, 0.0, -1.0]\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 8, 4],\n        [0, 4, 9],\n        [0, 9, 6],\n        [0, 6, 1],\n        [0, 1, 8],\n        [8, 5, 4],\n        [4, 7, 9],\n        [9, 11, 6],\n        [6, 10, 1],\n        [1, 3, 8],\n        [2, 5, 7],\n        [2, 7, 11],\n        [2, 11, 10],\n        [2, 10, 3],\n        [2, 3, 5],\n        [5, 8, 7],\n        [7, 4, 11],\n        [11, 9, 10],\n        [10, 6, 3],\n        [3, 1, 5]\n    ], dtype=np.int32)\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n        [1.0, 0.0, 0.0],\n        [-1.0, 0.0, 0.0],\n        [0.0, 1.0, 0.0],\n        [0.0, -1.0, 0.0],\n        [0.0, 0.0, 1.0],\n        [0.0, 0.0, -1.0]\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 2, 4],\n        [0, 4, 3],\n        [0, 3, 5],\n        [0, 5, 2],\n        [1, 4, 2],\n        [1, 3, 4],\n        [1, 5, 3],\n        [1, 2, 5]\n    ], dtype=np.int32)\n  else:\n    raise ValueError(f'base_shape {base_shape} not supported')\n\n  base_verts /= np.linalg.norm(base_verts, axis=1, keepdims=True)\n  verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n\n  if remove_symmetries:\n    sq_dist = compute_sq_dist(verts.T)\n    unique = np.unique(np.argmin(sq_dist, axis=1))\n    verts = verts[unique]\n\n  return verts.T"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(f'base_shape {base_shape} must be \"tetrahedron\", \"icosahedron\", or \"octahedron\"')\n\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [1, -1, -1],\n        [-1, 1, -1],\n        [-1, -1, 1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 1, 3],\n        [0, 2, 3],\n        [1, 2, 3],\n    ], dtype=np.int32)\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array([\n        [0, 1, phi],\n        [0, -1, phi],\n        [0, 1, -phi],\n        [0, -1, -phi],\n        [1, phi, 0],\n        [-1, phi, 0],\n        [1, -phi, 0],\n        [-1, -phi, 0],\n        [phi, 0, 1],\n        [-phi, 0, 1],\n        [phi, 0, -1],\n        [-phi, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 8, 4],\n        [0, 4, 6],\n        [0, 6, 9],\n        [0, 9, 1],\n        [0, 1, 8],\n        [5, 10, 7],\n        [5, 7, 11],\n        [5, 11, 3],\n        [5, 3, 2],\n        [5, 2, 10],\n        [4, 8, 7],\n        [6, 4, 11],\n        [9, 6, 3],\n        [1, 9, 2],\n        [8, 1, 10],\n        [7, 8, 10],\n        [11, 7, 10],\n        [3, 11, 10],\n        [2, 3, 10],\n        [6, 4, 7],\n        [3, 6, 11],\n        [2, 9, 3],\n        [2, 1, 9],\n        [4, 8, 11],\n    ], dtype=np.int32)\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n        [1, 0, 0],\n        [-1, 0, 0],\n        [0, 1, 0],\n        [0, -1, 0],\n        [0, 0, 1],\n        [0, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 2, 4],\n        [0, 4, 3],\n        [0, 3, 5],\n        [0, 5, 2],\n        [1, 2, 4],\n        [1, 4, 3],\n        [1, 3, 5],\n        [1, 5, 2],\n    ], dtype=np.int32)\n\n  verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n\n  if remove_symmetries:\n    sq_dist = compute_sq_dist(verts.T)\n    assignment = np.array([np.min(np.argwhere(d <= eps)) for d in sq_dist])\n    unique = np.unique(assignment)\n    verts = verts[unique, :]\n\n  return verts.T"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(\"base_shape must be 'tetrahedron', 'icosahedron', or 'octahedron'\")\n\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [1, -1, -1],\n        [-1, 1, -1],\n        [-1, -1, 1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 1, 3],\n        [0, 2, 3],\n        [1, 2, 3],\n    ], dtype=np.int32)\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array([\n        [-1, phi, 0],\n        [1, phi, 0],\n        [-1, -phi, 0],\n        [1, -phi, 0],\n        [0, -1, phi],\n        [0, 1, phi],\n        [0, -1, -phi],\n        [0, 1, -phi],\n        [phi, 0, -1],\n        [phi, 0, 1],\n        [-phi, 0, -1],\n        [-phi, 0, 1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 11, 5],\n        [0, 5, 1],\n        [0, 1, 7],\n        [0, 7, 10],\n        [0, 10, 11],\n        [1, 5, 9],\n        [5, 11, 4],\n        [11, 10, 2],\n        [10, 7, 6],\n        [7, 1, 8],\n        [3, 9, 4],\n        [3, 4, 2],\n        [3, 2, 6],\n        [3, 6, 8],\n        [3, 8, 9],\n        [4, 9, 5],\n        [2, 4, 11],\n        [6, 2, 10],\n        [8, 6, 7],\n        [9, 8, 1],\n    ], dtype=np.int32)\n  else:  # base_shape == 'octahedron'\n    base_verts = np.array([\n        [1, 0, 0],\n        [-1, 0, 0],\n        [0, 1, 0],\n        [0, -1, 0],\n        [0, 0, 1],\n        [0, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 2, 4],\n        [0, 4, 3],\n        [0, 3, 5],\n        [0, 5, 2],\n        [1, 2, 4],\n        [1, 4, 3],\n        [1, 3, 5],\n        [1, 5, 2],\n    ], dtype=np.int32)\n\n  verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n\n  if remove_symmetries:\n    sq_dist = compute_sq_dist(verts.T)\n    symmetrical_pairs = np.argwhere(sq_dist < eps)\n    unique = np.unique(symmetrical_pairs)\n    verts = verts[unique, :]\n\n  return verts.T"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [1, -1, -1],\n        [-1, 1, -1],\n        [-1, -1, 1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 1, 3],\n        [0, 2, 3],\n        [1, 2, 3],\n    ], dtype=np.int32)\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array([\n        [+1, +phi, 0],\n        [-1, +phi, 0],\n        [+1, -phi, 0],\n        [-1, -phi, 0],\n        [0, +1, +phi],\n        [0, -1, +phi],\n        [0, +1, -phi],\n        [0, -1, -phi],\n        [+phi, 0, +1],\n        [-phi, 0, +1],\n        [+phi, 0, -1],\n        [-phi, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 8, 4],\n        [0, 5, 10],\n        [2, 4, 9],\n        [2, 11, 5],\n        [1, 6, 8],\n        [1, 10, 7],\n        [3, 9, 6],\n        [3, 7, 11],\n        [0, 10, 8],\n        [1, 8, 10],\n        [2, 9, 11],\n        [3, 11, 9],\n        [4, 2, 0],\n        [5, 0, 2],\n        [6, 1, 3],\n        [7, 3, 1],\n        [8, 6, 4],\n        [9, 4, 6],\n        [10, 5, 7],\n        [11, 7, 5],\n    ], dtype=np.int32)\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n        [+1, 0, 0],\n        [-1, 0, 0],\n        [0, +1, 0],\n        [0, -1, 0],\n        [0, 0, +1],\n        [0, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 2, 4],\n        [0, 4, 3],\n        [0, 3, 5],\n        [0, 5, 2],\n        [1, 4, 2],\n        [1, 3, 4],\n        [1, 5, 3],\n        [1, 2, 5],\n    ], dtype=np.int32)\n  else:\n    raise ValueError(f'base_shape {base_shape} is not supported')\n\n  verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n\n  if remove_symmetries:\n    sq_dist = compute_sq_dist(verts.T)\n    assignment = np.array([np.min(np.argwhere(d <= eps)) for d in sq_dist])\n    unique = np.unique(assignment)\n    verts = verts[unique, :]\n\n  return verts.T"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(f'base_shape {base_shape} must be one of \"tetrahedron\", \"icosahedron\", or \"octahedron\"')\n\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [1, -1, -1],\n        [-1, 1, -1],\n        [-1, -1, 1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 1, 3],\n        [0, 2, 3],\n        [1, 2, 3],\n    ], dtype=np.int32)\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array([\n        [-1, phi, 0],\n        [1, phi, 0],\n        [-1, -phi, 0],\n        [1, -phi, 0],\n        [0, -1, phi],\n        [0, 1, phi],\n        [0, -1, -phi],\n        [0, 1, -phi],\n        [phi, 0, -1],\n        [phi, 0, 1],\n        [-phi, 0, -1],\n        [-phi, 0, 1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 11, 5],\n        [0, 5, 1],\n        [0, 1, 7],\n        [0, 7, 10],\n        [0, 10, 11],\n        [1, 5, 9],\n        [5, 11, 4],\n        [11, 10, 2],\n        [10, 7, 6],\n        [7, 1, 8],\n        [3, 9, 4],\n        [3, 4, 2],\n        [3, 2, 6],\n        [3, 6, 8],\n        [3, 8, 9],\n        [4, 9, 5],\n        [2, 4, 11],\n        [6, 2, 10],\n        [8, 6, 7],\n        [9, 8, 1],\n    ], dtype=np.int32)\n  else:  # base_shape == 'octahedron'\n    base_verts = np.array([\n        [1, 0, 0],\n        [-1, 0, 0],\n        [0, 1, 0],\n        [0, -1, 0],\n        [0, 0, 1],\n        [0, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 2, 4],\n        [0, 4, 3],\n        [0, 3, 5],\n        [0, 5, 2],\n        [1, 2, 4],\n        [1, 4, 3],\n        [1, 3, 5],\n        [1, 5, 2],\n    ], dtype=np.int32)\n\n  verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n\n  if remove_symmetries:\n    sq_dist = compute_sq_dist(verts.T)\n    unique = np.unique(np.argwhere(sq_dist <= eps)[:, 1])\n    verts = verts[unique, :]\n\n  return verts.T"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(f'Invalid base_shape: {base_shape}. Must be \"tetrahedron\", \"icosahedron\", or \"octahedron\".')\n\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n      [1, 1, 1],\n      [1, -1, -1],\n      [-1, 1, -1],\n      [-1, -1, 1]\n    ], dtype=np.float32)\n    base_faces = np.array([\n      [0, 1, 2],\n      [0, 1, 3],\n      [0, 2, 3],\n      [1, 2, 3]\n    ], dtype=np.int32)\n  elif base_shape == 'icosahedron':\n    base_verts = np.array([\n      [0, 1, phi],\n      [0, -1, phi],\n      [0, 1, -phi],\n      [0, -1, -phi],\n      [1, phi, 0],\n      [-1, phi, 0],\n      [1, -phi, 0],\n      [-1, -phi, 0],\n      [phi, 0, 1],\n      [-phi, 0, 1],\n      [phi, 0, -1],\n      [-phi, 0, -1]\n    ], dtype=np.float32)\n    base_faces = np.array([\n      [0, 1, 4],\n      [0, 1, 5],\n      [0, 2, 6],\n      [0, 2, 7],\n      [1, 3, 8],\n      [1, 3, 9],\n      [2, 3, 10],\n      [2, 3, 11],\n      [4, 5, 8],\n      [4, 5, 9],\n      [6, 7, 10],\n      [6, 7, 11],\n      [4, 6, 8],\n      [4, 6, 10],\n      [5, 7, 9],\n      [5, 7, 11],\n      [0, 8, 10],\n      [1, 9, 11],\n      [0, 4, 8],\n      [1, 5, 9],\n      [2, 6, 10],\n      [3, 7, 11]\n    ], dtype=np.int32)\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n      [1, 0, 0],\n      [-1, 0, 0],\n      [0, 1, 0],\n      [0, -1, 0],\n      [0, 0, 1],\n      [0, 0, -1]\n    ], dtype=np.float32)\n    base_faces = np.array([\n      [0, 2, 4],\n      [0, 3, 4],\n      [0, 2, 5],\n      [0, 3, 5],\n      [1, 2, 4],\n      [1, 3, 4],\n      [1, 2, 5],\n      [1, 3, 5]\n    ], dtype=np.int32)\n\n  verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n\n  if remove_symmetries:\n    sq_dist = compute_sq_dist(verts.T)\n    unique = np.unique(np.argwhere(sq_dist <= eps)[:, 1])\n    verts = verts[unique, :]\n\n  return verts.T"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [1, -1, -1],\n        [-1, 1, -1],\n        [-1, -1, 1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 1, 3],\n        [0, 2, 3],\n        [1, 2, 3],\n    ], dtype=np.int32)\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array([\n        [0, 1, phi],\n        [0, -1, phi],\n        [0, 1, -phi],\n        [0, -1, -phi],\n        [1, phi, 0],\n        [-1, phi, 0],\n        [1, -phi, 0],\n        [-1, -phi, 0],\n        [phi, 0, 1],\n        [-phi, 0, 1],\n        [phi, 0, -1],\n        [-phi, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 8, 4],\n        [0, 4, 2],\n        [0, 2, 6],\n        [0, 6, 9],\n        [0, 9, 8],\n        [1, 5, 7],\n        [1, 7, 11],\n        [1, 11, 3],\n        [1, 3, 10],\n        [1, 10, 5],\n        [2, 4, 8],\n        [2, 8, 9],\n        [2, 9, 6],\n        [3, 7, 5],\n        [3, 5, 10],\n        [3, 10, 11],\n        [4, 5, 10],\n        [4, 10, 8],\n        [5, 7, 11],\n        [6, 9, 8],\n    ], dtype=np.int32)\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n        [1, 0, 0],\n        [-1, 0, 0],\n        [0, 1, 0],\n        [0, -1, 0],\n        [0, 0, 1],\n        [0, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 2, 4],\n        [0, 4, 3],\n        [0, 3, 5],\n        [0, 5, 2],\n        [1, 2, 4],\n        [1, 4, 3],\n        [1, 3, 5],\n        [1, 5, 2],\n    ], dtype=np.int32)\n  else:\n    raise ValueError(f'base_shape {base_shape} not recognized')\n\n  verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n\n  if remove_symmetries:\n    sq_dist = compute_sq_dist(verts.T)\n    assignment = np.array([np.min(np.argwhere(d <= eps)) for d in sq_dist])\n    unique = np.unique(assignment)\n    verts = verts[unique, :]\n\n  return verts.T"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [1, -1, -1],\n        [-1, 1, -1],\n        [-1, -1, 1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 1, 3],\n        [0, 2, 3],\n        [1, 2, 3],\n    ], dtype=np.int32)\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n        [1, 0, 0],\n        [-1, 0, 0],\n        [0, 1, 0],\n        [0, -1, 0],\n        [0, 0, 1],\n        [0, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 2, 4],\n        [0, 3, 4],\n        [0, 2, 5],\n        [0, 3, 5],\n        [1, 2, 4],\n        [1, 3, 4],\n        [1, 2, 5],\n        [1, 3, 5],\n    ], dtype=np.int32)\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array([\n        [-1, phi, 0],\n        [1, phi, 0],\n        [-1, -phi, 0],\n        [1, -phi, 0],\n        [0, -1, phi],\n        [0, 1, phi],\n        [0, -1, -phi],\n        [0, 1, -phi],\n        [phi, 0, -1],\n        [phi, 0, 1],\n        [-phi, 0, -1],\n        [-phi, 0, 1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 11, 5],\n        [0, 5, 1],\n        [0, 1, 7],\n        [0, 7, 10],\n        [0, 10, 11],\n        [1, 5, 9],\n        [5, 11, 4],\n        [11, 10, 2],\n        [10, 7, 6],\n        [7, 1, 8],\n        [3, 9, 4],\n        [3, 4, 2],\n        [3, 2, 6],\n        [3, 6, 8],\n        [3, 8, 9],\n        [4, 9, 5],\n        [2, 4, 11],\n        [6, 2, 10],\n        [8, 6, 7],\n        [9, 8, 1],\n    ], dtype=np.int32)\n  else:\n    raise ValueError(f'base_shape {base_shape} not supported')\n\n  verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n\n  if remove_symmetries:\n    sq_dist = compute_sq_dist(verts.T)\n    symmetric_pairs = np.argwhere(sq_dist <= eps)\n    unique_verts = np.unique(symmetric_pairs)\n    verts = verts[unique_verts]\n\n  return verts.T"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(f'base_shape {base_shape} must be one of \"tetrahedron\", \"icosahedron\", or \"octahedron\"')\n\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [1, -1, -1],\n        [-1, 1, -1],\n        [-1, -1, 1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 1, 3],\n        [0, 2, 3],\n        [1, 2, 3],\n    ], dtype=np.int32)\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array([\n        [0, 1, phi],\n        [0, -1, phi],\n        [0, 1, -phi],\n        [0, -1, -phi],\n        [1, phi, 0],\n        [-1, phi, 0],\n        [1, -phi, 0],\n        [-1, -phi, 0],\n        [phi, 0, 1],\n        [-phi, 0, 1],\n        [phi, 0, -1],\n        [-phi, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 4],\n        [0, 1, 5],\n        [0, 4, 8],\n        [0, 5, 8],\n        [0, 4, 9],\n        [0, 5, 10],\n        [0, 8, 9],\n        [0, 8, 10],\n        [1, 4, 6],\n        [1, 6, 11],\n        [1, 5, 7],\n        [1, 7, 11],\n        [1, 6, 9],\n        [1, 7, 10],\n        [2, 3, 8],\n        [2, 3, 9],\n        [2, 8, 10],\n        [2, 9, 10],\n        [2, 3, 11],\n        [2, 8, 11],\n        [2, 9, 11],\n        [2, 10, 11],\n        [3, 8, 10],\n        [3, 9, 10],\n    ], dtype=np.int32)\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n        [1, 0, 0],\n        [-1, 0, 0],\n        [0, 1, 0],\n        [0, -1, 0],\n        [0, 0, 1],\n        [0, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 2, 4],\n        [0, 3, 4],\n        [0, 2, 5],\n        [0, 3, 5],\n        [1, 2, 4],\n        [1, 3, 4],\n        [1, 2, 5],\n        [1, 3, 5],\n    ], dtype=np.int32)\n\n  verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n\n  if remove_symmetries:\n    sq_dist = compute_sq_dist(verts.T)\n    symmetric_pairs = np.argwhere(sq_dist <= eps)\n    unique_verts = np.unique(symmetric_pairs)\n    verts = verts[unique_verts]\n\n  return verts.T"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [-1, -1, 1],\n        [-1, 1, -1],\n        [1, -1, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 2, 3],\n        [0, 3, 1],\n        [1, 3, 2],\n    ], dtype=np.int32)\n  elif base_shape == 'icosahedron':\n    # Define the vertices of an icosahedron.\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array([\n        [0, 1, phi],\n        [0, -1, phi],\n        [0, 1, -phi],\n        [0, -1, -phi],\n        [1, phi, 0],\n        [-1, phi, 0],\n        [1, -phi, 0],\n        [-1, -phi, 0],\n        [phi, 0, 1],\n        [-phi, 0, 1],\n        [phi, 0, -1],\n        [-phi, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 4],\n        [0, 4, 8],\n        [0, 8, 9],\n        [0, 9, 6],\n        [0, 6, 1],\n        [1, 7, 4],\n        [1, 6, 10],\n        [1, 10, 7],\n        [2, 3, 5],\n        [2, 5, 11],\n        [2, 11, 7],\n        [2, 7, 10],\n        [2, 10, 3],\n        [3, 9, 8],\n        [3, 8, 11],\n        [3, 11, 5],\n        [4, 5, 8],\n        [4, 7, 5],\n        [6, 9, 3],\n        [6, 3, 10],\n        [11, 8, 5],\n        [11, 10, 7],\n        [9, 8, 5],\n    ], dtype=np.int32)\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n        [1, 0, 0],\n        [-1, 0, 0],\n        [0, 1, 0],\n        [0, -1, 0],\n        [0, 0, 1],\n        [0, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 2, 4],\n        [0, 4, 3],\n        [0, 3, 5],\n        [0, 5, 2],\n        [1, 2, 4],\n        [1, 4, 3],\n        [1, 3, 5],\n        [1, 5, 2],\n    ], dtype=np.int32)\n  else:\n    raise ValueError('base_shape must be \"tetrahedron\", \"icosahedron\", or \"octahedron\"')\n\n  verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n\n  if remove_symmetries:\n    sq_dist = compute_sq_dist(verts.T)\n    assignment = np.array([np.min(np.argwhere(d <= eps)) for d in sq_dist])\n    unique = np.unique(assignment)\n    verts = verts[unique, :]\n\n  return verts.T"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError('base_shape must be \"tetrahedron\", \"icosahedron\", or \"octahedron\"')\n  \n  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [1, -1, -1],\n        [-1, 1, -1],\n        [-1, -1, 1]\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 1, 3],\n        [0, 2, 3],\n        [1, 2, 3]\n    ], dtype=np.int32)\n  elif base_shape == 'icosahedron':\n    t = (1 + np.sqrt(5)) / 2\n    base_verts = np.array([\n        [-1, t, 0],\n        [1, t, 0],\n        [-1, -t, 0],\n        [1, -t, 0],\n        [0, -1, t],\n        [0, 1, t],\n        [0, -1, -t],\n        [0, 1, -t],\n        [t, 0, -1],\n        [t, 0, 1],\n        [-t, 0, -1],\n        [-t, 0, 1]\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 11, 5],\n        [0, 5, 1],\n        [0, 1, 7],\n        [0, 7, 10],\n        [0, 10, 11],\n        [1, 5, 9],\n        [5, 11, 4],\n        [11, 10, 2],\n        [10, 7, 6],\n        [7, 1, 8],\n        [3, 9, 4],\n        [3, 4, 2],\n        [3, 2, 6],\n        [3, 6, 8],\n        [3, 8, 9],\n        [4, 9, 5],\n        [2, 4, 11],\n        [6, 2, 10],\n        [8, 6, 7],\n        [9, 8, 1]\n    ], dtype=np.int32)\n  else:  # base_shape == 'octahedron'\n    base_verts = np.array([\n        [1, 0, 0],\n        [-1, 0, 0],\n        [0, 1, 0],\n        [0, -1, 0],\n        [0, 0, 1],\n        [0, 0, -1]\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 2, 4],\n        [0, 4, 3],\n        [0, 3, 5],\n        [0, 5, 2],\n        [1, 2, 5],\n        [1, 5, 3],\n        [1, 3, 4],\n        [1, 4, 2]\n    ], dtype=np.int32)\n\n  verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n\n  if remove_symmetries:\n    sq_dist = compute_sq_dist(verts.T)\n    unique = np.unique(np.argwhere(sq_dist <= eps)[:, 0])\n    verts = verts[unique, :]\n\n  return verts.T"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(\"base_shape must be either 'tetrahedron', 'icosahedron', or 'octahedron'\")\n\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [1, -1, -1],\n        [-1, 1, -1],\n        [-1, -1, 1]\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 1, 3],\n        [0, 2, 3],\n        [1, 2, 3]\n    ], dtype=np.int32)\n  elif base_shape == 'icosahedron':\n    t = (1 + np.sqrt(5)) / 2\n    base_verts = np.array([\n        [-1,  t, 0],\n        [ 1,  t, 0],\n        [-1, -t, 0],\n        [ 1, -t, 0],\n        [ 0, -1,  t],\n        [ 0,  1,  t],\n        [ 0, -1, -t],\n        [ 0,  1, -t],\n        [ t, 0, -1],\n        [ t, 0,  1],\n        [-t, 0, -1],\n        [-t, 0,  1]\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 11, 5],\n        [0, 5, 1],\n        [0, 1, 7],\n        [0, 7, 10],\n        [0, 10, 11],\n        [1, 5, 9],\n        [5, 11, 4],\n        [11, 10, 2],\n        [10, 7, 6],\n        [7, 1, 8],\n        [3, 9, 4],\n        [3, 4, 2],\n        [3, 2, 6],\n        [3, 6, 8],\n        [3, 8, 9],\n        [4, 9, 5],\n        [2, 4, 11],\n        [6, 2, 10],\n        [8, 6, 7],\n        [9, 8, 1]\n    ], dtype=np.int32)\n  else:  # base_shape == 'octahedron'\n    base_verts = np.array([\n        [1, 0, 0],\n        [-1, 0, 0],\n        [0, 1, 0],\n        [0, -1, 0],\n        [0, 0, 1],\n        [0, 0, -1]\n    ], dtype=np.float32)\n    base_faces = np.array([\n        [0, 2, 4],\n        [0, 4, 3],\n        [0, 3, 5],\n        [0, 5, 2],\n        [1, 2, 4],\n        [1, 4, 3],\n        [1, 3, 5],\n        [1, 5, 2]\n    ], dtype=np.int32)\n\n  verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n\n  if remove_symmetries:\n    sq_dist = compute_sq_dist(verts.T)\n    unique = np.unique(np.argwhere(sq_dist <= eps)[:, 0])\n    verts = verts[unique, :]\n\n  return verts.T"}
{"namespace": "geopoly.generate_basis", "completion": "\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n      [1, 1, 1],\n      [1, -1, -1],\n      [-1, 1, -1],\n      [-1, -1, 1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n      [0, 1, 2],\n      [0, 1, 3],\n      [0, 2, 3],\n      [1, 2, 3],\n    ], dtype=np.int32)\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array([\n      [0, 1, phi],\n      [0, -1, phi],\n      [0, 1, -phi],\n      [0, -1, -phi],\n      [1, phi, 0],\n      [-1, phi, 0],\n      [1, -phi, 0],\n      [-1, -phi, 0],\n      [phi, 0, 1],\n      [-phi, 0, 1],\n      [phi, 0, -1],\n      [-phi, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n      [0, 8, 4],\n      [0, 4, 2],\n      [0, 2, 6],\n      [0, 6, 9],\n      [0, 9, 8],\n      [1, 3, 5],\n      [1, 5, 7],\n      [1, 7, 10],\n      [1, 10, 3],\n      [1, 11, 3],\n      [2, 4, 8],\n      [2, 8, 5],\n      [2, 5, 3],\n      [2, 3, 6],\n      [3, 5, 8],\n      [3, 10, 6],\n      [4, 7, 5],\n      [4, 5, 8],\n      [4, 8, 7],\n      [6, 7, 9],\n      [6, 9, 10],\n      [7, 10, 11],\n      [7, 11, 9],\n      [9, 11, 10],\n    ], dtype=np.int32)\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n      [1, 0, 0],\n      [-1, 0, 0],\n      [0, 1, 0],\n      [0, -1, 0],\n      [0, 0, 1],\n      [0, 0, -1],\n    ], dtype=np.float32)\n    base_faces = np.array([\n      [0, 2, 4],\n      [0, 4, 3],\n      [0, 3, 5],\n      [0, 5, 2],\n      [1, 2, 4],\n      [1, 4, 3],\n      [1, 3, 5],\n      [1, 5, 2],\n    ], dtype=np.int32)\n  else:\n    raise ValueError(f'base_shape {base_shape} must be \"tetrahedron\", \"icosahedron\", or \"octahedron\"')\n\n  verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n\n  if remove_symmetries:\n    sq_dist = compute_sq_dist(verts.T)\n    assignment = np.array([np.min(np.argwhere(d <= eps)) for d in sq_dist])\n    unique = np.unique(assignment)\n    verts = verts[unique, :]\n\n  return verts.T"}
{"namespace": "geopoly.generate_basis", "completion": "\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([\n        [1, 1, 1],\n        [1, -1, -1],\n        [-1, 1, -1],\n        [-1, -1, 1]\n    ], dtype=float)\n    base_faces = np.array([\n        [0, 1, 2],\n        [0, 1, 3],\n        [0, 2, 3],\n        [1, 2, 3]\n    ], dtype=int)\n  elif base_shape == 'icosahedron':\n    t = (1.0 + np.sqrt(5.0)) / 2.0\n    base_verts = np.array([\n        [-1, t, 0],\n        [1, t, 0],\n        [-1, -t, 0],\n        [1, -t, 0],\n        [0, -1, t],\n        [0, 1, t],\n        [0, -1, -t],\n        [0, 1, -t],\n        [t, 0, -1],\n        [t, 0, 1],\n        [-t, 0, -1],\n        [-t, 0, 1]\n    ], dtype=float)\n    base_faces = np.array([\n        [0, 11, 5],\n        [0, 5, 1],\n        [0, 1, 7],\n        [0, 7, 10],\n        [0, 10, 11],\n        [1, 5, 9],\n        [5, 11, 4],\n        [11, 10, 2],\n        [10, 7, 6],\n        [7, 1, 8],\n        [3, 9, 4],\n        [3, 4, 2],\n        [3, 2, 6],\n        [3, 6, 8],\n        [3, 8, 9],\n        [4, 9, 5],\n        [2, 4, 11],\n        [6, 2, 10],\n        [8, 6, 7],\n        [9, 8, 1]\n    ], dtype=int)\n  elif base_shape == 'octahedron':\n    base_verts = np.array([\n        [1, 0, 0],\n        [-1, 0, 0],\n        [0, 1, 0],\n        [0, -1, 0],\n        [0, 0, 1],\n        [0, 0, -1]\n    ], dtype=float)\n    base_faces = np.array([\n        [0, 2, 4],\n        [0, 4, 3],\n        [0, 3, 5],\n        [0, 5, 2],\n        [1, 2, 5],\n        [1, 5, 3],\n        [1, 3, 4],\n        [1, 4, 2]\n    ], dtype=int)\n  else:\n    raise ValueError(f'base_shape {base_shape} must be \"tetrahedron\", \"icosahedron\", or \"octahedron\"')\n\n  verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n\n  if remove_symmetries:\n    sq_dist = compute_sq_dist(verts.T)\n    unique = np.unique(np.argwhere(sq_dist <= eps)[:, 0])\n    verts = verts[unique, :]\n\n  return verts.T"}
{"namespace": "geopoly.generate_basis", "completion": "\n    if base_shape == 'tetrahedron':\n        base_verts = np.array([\n            [1, 1, 1],\n            [1, -1, -1],\n            [-1, 1, -1],\n            [-1, -1, 1]\n        ], dtype=np.float32)\n        base_faces = np.array([\n            [0, 1, 2],\n            [0, 1, 3],\n            [0, 2, 3],\n            [1, 2, 3]\n        ], dtype=np.int32)\n    elif base_shape == 'icosahedron':\n        phi = (1 + np.sqrt(5)) / 2\n        base_verts = np.array([\n            [0, 1, phi],\n            [0, -1, phi],\n            [0, 1, -phi],\n            [0, -1, -phi],\n            [1, phi, 0],\n            [-1, phi, 0],\n            [1, -phi, 0],\n            [-1, -phi, 0],\n            [phi, 0, 1],\n            [-phi, 0, 1],\n            [phi, 0, -1],\n            [-phi, 0, -1]\n        ], dtype=np.float32)\n        base_faces = np.array([\n            [0, 8, 4],\n            [0, 4, 9],\n            [0, 9, 5],\n            [0, 5, 10],\n            [0, 10, 8],\n            [1, 7, 6],\n            [1, 6, 11],\n            [1, 11, 3],\n            [1, 3, 9],\n            [1, 9, 4],\n            [2, 5, 10],\n            [2, 10, 8],\n            [2, 8, 7],\n            [2, 7, 11],\n            [2, 11, 3],\n            [3, 11, 6],\n            [3, 6, 10],\n            [4, 8, 7],\n            [4, 7, 6],\n            [4, 6, 9],\n            [5, 9, 6],\n            [5, 6, 10]\n        ], dtype=np.int32)\n    elif base_shape == 'octahedron':\n        base_verts = np.array([\n            [1, 0, 0],\n            [-1, 0, 0],\n            [0, 1, 0],\n            [0, -1, 0],\n            [0, 0, 1],\n            [0, 0, -1]\n        ], dtype=np.float32)\n        base_faces = np.array([\n            [0, 2, 4],\n            [0, 4, 3],\n            [0, 3, 5],\n            [0, 5, 2],\n            [1, 2, 4],\n            [1, 4, 3],\n            [1, 3, 5],\n            [1, 5, 2]\n        ], dtype=np.int32)\n    else:\n        raise ValueError('Invalid base_shape. Must be \"tetrahedron\", \"icosahedron\", or \"octahedron\".')\n\n    verts = tesselate_geodesic(base_verts, base_faces, angular_tesselation, eps)\n\n    if remove_symmetries:\n        sq_dist = compute_sq_dist(verts.T)\n        assignment = np.array([np.min(np.argwhere(d <= eps)) for d in sq_dist])\n        unique = np.unique(assignment)\n        verts = verts[unique, :]\n\n    return verts.T"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1, max_val),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1.0, max_val),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1, max_val),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1, max_val),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1, max_val),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1.0, max_val),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1.0, max_val - 1),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1, max_val),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1, max_val),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1.0, max_val - 1.0),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1, max_val),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1, max_val),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1, max_val),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1, max_val),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1, max_val),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1.0, max_val - 1.0),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1.0, max_val - 1.0),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1.0, max_val - 1),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1.0, max_val),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (-1.0, max_val - 1.0),\n  )(x)"}
{"namespace": "math.power_ladder", "completion": "  # Apply optional pre-multiplication\n  if premult is not None:\n    x = x * premult\n\n  # Apply Tukey's power ladder transformation\n  if p == 1:\n    y = x\n  elif p == 0:\n    y = safe_log(x)\n  elif p == -jnp.inf:\n    y = safe_sign(x) * safe_log(safe_abs(x))\n  elif p == jnp.inf:\n    y = safe_sign(x) * safe_log1p(safe_abs(x))\n  else:\n    y = safe_sign(x) * safe_expm1(p * safe_log1p(safe_abs(x)))\n\n  # Apply optional post-multiplication\n  if postmult is not None:\n    y = y * postmult\n\n  return y"}
{"namespace": "math.power_ladder", "completion": "  # Apply pre-multiplication if specified\n  if premult is not None:\n    x = x * premult\n\n  # Apply Tukey's power ladder transformation\n  if p == 1:\n    y = x\n  elif p == 0:\n    y = safe_log1p(x)\n  elif p == -jnp.inf:\n    y = safe_sign(x) * safe_log1p(jnp.abs(x))\n  elif p == jnp.inf:\n    y = safe_sign(x) * safe_log1p(jnp.abs(x))\n  else:\n    y = safe_sign(x) * safe_expm1(p * safe_log1p(jnp.abs(x)))\n\n  # Apply post-multiplication if specified\n  if postmult is not None:\n    y = y * postmult\n\n  return y"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n\n  if p == 1:\n    y = x\n  elif p == 0:\n    y = safe_log(x)\n  elif p == -jnp.inf:\n    y = safe_sign(x) * safe_log(jnp.abs(x))\n  elif p == jnp.inf:\n    y = safe_sign(x) * safe_exp(safe_log(jnp.abs(x)))\n  else:\n    y = safe_sign(x) * safe_exp(safe_log1p((p - 1) * safe_log1p(jnp.abs(x))))\n\n  if postmult is not None:\n    y = y * postmult\n\n  return y"}
{"namespace": "math.power_ladder", "completion": "\n  if premult is not None:\n    x = x * premult\n\n  if p == 1:\n    y = x\n  elif p == 0:\n    y = safe_log1p(x)\n  elif p == -jnp.inf:\n    y = safe_sign(x) * safe_log1p(jnp.abs(x))\n  elif p == jnp.inf:\n    y = safe_sign(x) * safe_log1p(jnp.maximum(tiny_val, jnp.abs(x)))\n  else:\n    y = safe_sign(x) * safe_exp(safe_log1p(jnp.abs(x)) * p)\n\n  if postmult is not None:\n    y = y * postmult\n\n  return y"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n\n  if p == 1:\n    y = x\n  elif p == 0:\n    y = jnp.log(x)\n  elif p == -jnp.inf:\n    y = safe_sign(x) * jnp.log(jnp.abs(x))\n  elif p == jnp.inf:\n    y = safe_sign(x) * jnp.exp(x)\n  else:\n    y = safe_sign(x) * jnp.power(jnp.abs(x), p)\n\n  if postmult is not None:\n    y = y * postmult\n\n  return y"}
{"namespace": "math.power_ladder", "completion": "  x = jnp.asarray(x)\n  if premult is not None:\n    x = x * premult\n\n  if p == 1:\n    return safe_log1p(x) if postmult is None else postmult * safe_log1p(x)\n\n  if p == 0:\n    return safe_log(x) if postmult is None else postmult * safe_log(x)\n\n  if p == -jnp.inf:\n    return safe_sign(x) * jnp.log(jnp.abs(x)) if postmult is None else postmult * (safe_sign(x) * jnp.log(jnp.abs(x)))\n\n  if p == jnp.inf:\n    return safe_sign(x) * safe_exp(x) if postmult is None else postmult * (safe_sign(x) * safe_exp(x))\n\n  if p > 0:\n    return safe_sign(x) * safe_exp(scaled_softplus(jnp.abs(x), scale=p)) if postmult is None else postmult * (safe_sign(x) * safe_exp(scaled_softplus(jnp.abs(x), scale=p)))\n\n  if p < 0:\n    return safe_sign(x) * safe_exp(-scaled_softplus(jnp.abs(x), scale=-p)) if postmult is None else postmult * (safe_sign(x) * safe_exp(-scaled_softplus(jnp.abs(x), scale=-p)))"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n\n  if p == 1:\n    return x\n\n  if p == 0:\n    return jnp.log(x + 1)\n\n  if p == -jnp.inf:\n    return jnp.sign(x) * jnp.log(jnp.abs(x))\n\n  if p == jnp.inf:\n    return jnp.sign(x) * jnp.exp(x) - 1\n\n  result = safe_sign(x) * safe_exp(safe_log1p(jnp.abs(x) * (p - 1)))\n  \n  if postmult is not None:\n    result = result * postmult\n\n  return result"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n\n  if p == 1:\n    y = x\n  elif p == 0:\n    y = safe_log(x)\n  elif p == -jnp.inf:\n    y = safe_sign(x) * safe_log(jnp.abs(x))\n  elif p == jnp.inf:\n    y = safe_sign(x) * safe_exp(jnp.abs(x))\n  else:\n    y = safe_sign(x) * safe_exp(safe_log1p(jnp.abs(x) * (p - 1)))\n\n  if postmult is not None:\n    y = y * postmult\n\n  return y"}
{"namespace": "math.power_ladder", "completion": "  # Apply any pre-multiplication\n  if premult is not None:\n    x = x * premult\n\n  # Handle special cases for p\n  if p == 1:\n    y = x\n  elif p == 0:\n    y = safe_log(x)\n  elif p == -jnp.inf:\n    y = safe_sign(x) * safe_log(jnp.abs(x))\n  elif p == jnp.inf:\n    y = safe_sign(x) * safe_exp(safe_log(jnp.abs(x)))\n  else:\n    # Apply Tukey's power ladder transformation\n    y = safe_sign(x) * safe_exp(safe_log1p(p * safe_log(jnp.abs(x))))\n\n  # Apply any post-multiplication\n  if postmult is not None:\n    y = y * postmult\n\n  return y"}
{"namespace": "math.power_ladder", "completion": "  # Apply any pre-multiplication factor\n  if premult is not None:\n    x = x * premult\n\n  # Apply Tukey's power ladder transformation\n  if p == 1:\n    y = x\n  elif p == 0:\n    y = safe_log(x)\n  elif p == -jnp.inf:\n    y = safe_sign(x) * safe_log(safe_abs(x))\n  elif p == jnp.inf:\n    y = safe_sign(x) * safe_log1p(safe_abs(x))\n  else:\n    y = safe_sign(x) * safe_expm1(p * safe_log1p(safe_abs(x))) / p\n\n  # Apply any post-multiplication factor\n  if postmult is not None:\n    y = y * postmult\n\n  return y"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n\n  if p == 1:\n    y = x\n  elif p == 0:\n    y = jnp.log(x)\n  elif p == -jnp.inf:\n    y = jnp.sign(x) * jnp.log(jnp.abs(x))\n  elif p == jnp.inf:\n    y = jnp.sign(x) * jnp.exp(x)\n  else:\n    y = jnp.sign(x) * jnp.power(jnp.abs(x), p)\n\n  if postmult is not None:\n    y = y * postmult\n\n  return y"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n\n  if p == 1:\n    y = x\n  elif p == 0:\n    y = jnp.log(x)\n  elif p == -jnp.inf:\n    y = safe_sign(x) * jnp.log(jnp.abs(x))\n  elif p == jnp.inf:\n    y = safe_sign(x) * jnp.exp(x)\n  else:\n    y = safe_sign(x) * jnp.power(jnp.abs(x), p)\n\n  if postmult is not None:\n    y = y * postmult\n\n  return y"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n\n  if p == 1:\n    y = x\n  elif p == 0:\n    y = jnp.log1p(x)\n  elif p == -jnp.inf:\n    y = jnp.sign(x) * jnp.log(jnp.abs(x))\n  elif p == jnp.inf:\n    y = jnp.sign(x) * jnp.exp(x) - 1\n  else:\n    y = safe_sign(x) * safe_exp(safe_log1p(safe_sign(x) * x * (p - 1)))\n\n  if postmult is not None:\n    y = y * postmult\n\n  return y"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n\n  if p == 1:\n    y = x\n  elif p == 0:\n    y = safe_log(x)\n  elif p == -jnp.inf:\n    y = safe_sign(x) * safe_log(jnp.abs(x))\n  elif p == jnp.inf:\n    y = safe_sign(x) * safe_exp(jnp.abs(x))\n  else:\n    y = safe_sign(x) * safe_exp(safe_log1p(p * safe_log(jnp.abs(x))) / p)\n\n  if postmult is not None:\n    y = y * postmult\n\n  return y"}
{"namespace": "math.power_ladder", "completion": "  x = jnp.asarray(x)\n  if premult is not None:\n    x = x * premult\n\n  if p == 1:\n    y = x\n  elif p == 0:\n    y = safe_log(x)\n  elif p == -jnp.inf:\n    y = safe_sign(x) * safe_log(jnp.abs(x))\n  elif p == jnp.inf:\n    y = safe_sign(x) * safe_log1p(jnp.abs(x))\n  else:\n    y = safe_sign(x) * safe_exp(safe_log1p(jnp.abs(x) * (p - 1)))\n\n  if postmult is not None:\n    y = y * postmult\n\n  return y"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n\n  if p == 1:\n    y = x\n  elif p == 0:\n    y = jnp.log(x)\n  elif p == -jnp.inf:\n    y = safe_sign(x) * safe_log(jnp.abs(x))\n  elif p == jnp.inf:\n    y = safe_sign(x) * safe_exp(jnp.abs(x))\n  else:\n    y = safe_sign(x) * safe_pow(jnp.abs(x), p)\n\n  if postmult is not None:\n    y = y * postmult\n\n  return y"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n\n  if p == 1:\n    y = x\n  elif p == 0:\n    y = jnp.log(x)\n  elif p == -jnp.inf:\n    y = safe_sign(x) * jnp.log(jnp.abs(x))\n  elif p == jnp.inf:\n    y = safe_sign(x) * jnp.exp(x)\n  else:\n    y = safe_sign(x) * jnp.exp((1 / p) * safe_log(jnp.abs(x)))\n\n  if postmult is not None:\n    y = y * postmult\n\n  return y"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n\n  if p == 1:\n    x = safe_log1p(x)\n\n  elif p == 0:\n    x = safe_log(x)\n\n  elif p == -jnp.inf:\n    x = safe_sign(x) * jnp.exp(x)\n\n  elif p == jnp.inf:\n    x = safe_sign(x) * safe_exp(x)\n\n  else:\n    x = safe_sign(x) * safe_pow(jnp.abs(x), p)\n\n  if postmult is not None:\n    x = x * postmult\n\n  return x"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n\n  if p == 1:\n    y = x\n  elif p == 0:\n    y = jnp.log(x)\n  elif p == -jnp.inf:\n    y = safe_sign(x) * jnp.log(jnp.abs(x))\n  elif p == jnp.inf:\n    y = safe_sign(x) * jnp.exp(x)\n  else:\n    y = safe_sign(x) * jnp.power(jnp.abs(x), p)\n\n  if postmult is not None:\n    y = y * postmult\n\n  return y"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n\n  # Handle special cases for p\n  if p == 1:\n    y = x\n  elif p == 0:\n    y = jnp.log(x)\n  elif p == -jnp.inf:\n    y = safe_sign(x) * jnp.log(jnp.abs(x))\n  elif p == jnp.inf:\n    y = safe_sign(x) * jnp.exp(jnp.abs(x))\n  else:\n    y = safe_sign(x) * jnp.power(jnp.abs(x), p)\n\n  if postmult is not None:\n    y = y * postmult\n\n  return y"}
{"namespace": "math.inv_power_ladder", "completion": "    if postmult is not None:\n      y = y / postmult\n    \n    if p == 1:\n      return y\n    \n    if p == 0:\n      return jnp.expm1(y)\n    \n    if p == -jnp.inf:\n      return -jnp.log1p(-y)\n    \n    if p == jnp.inf:\n      return jnp.log1p(y)\n    \n    return jnp.sign(y) * jnp.power(jnp.abs(y) + 1, 1 / p) * jnp.abs(p - 1) / p"}
{"namespace": "math.inv_power_ladder", "completion": "    if postmult is not None:\n      y = y * postmult\n    yp = jnp.abs(y)\n    ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n    p_safe = clip_finite_nograd(remove_zero(p))\n    x = safe_sign(y) * select(\n        [\n            (p == 1, yp),\n            (p == 0, safe_exp(yp) - 1),\n            (p == -jnp.inf, -safe_log1p(-yp)),\n            (p == jnp.inf, safe_log1p(yp)),\n        ],\n        clip_finite_nograd(\n            safe_div(yp + 1, jnp.abs(p_safe - 1)) ** (1 / p_safe) - 1\n        ),\n    )\n    if premult is not None:\n      x = x * premult\n    return x"}
{"namespace": "math.inv_power_ladder", "completion": "    if postmult is not None:\n        y = y / postmult\n    yp = jnp.abs(y)\n    if p == 1:\n        x = y\n    elif p == 0:\n        x = jnp.exp(safe_exp(yp) - 1)\n    elif p == -jnp.inf:\n        x = -safe_log1p(-yp)\n    elif p == jnp.inf:\n        x = safe_log1p(yp)\n    else:\n        x = safe_sign(y) * (jnp.power(1 + yp * jnp.abs(p - 1) / jnp.abs(p), 1 / jnp.abs(p - 1)) - 1) * jnp.abs(p - 1) / jnp.abs(p)\n    if premult is not None:\n        x = x / premult\n    return x"}
{"namespace": "math.inv_power_ladder", "completion": "    if postmult is not None:\n      y = y / postmult\n    yp = jnp.abs(y)\n    ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n    p_safe = clip_finite_nograd(remove_zero(p))\n    x = safe_sign(y) * select(\n        [\n            (p == 1, yp),\n            (p == 0, safe_exp(yp) - 1),\n            (p == -jnp.inf, -safe_log1p(-yp)),\n            (p == jnp.inf, safe_log1p(yp)),\n        ],\n        (jnp.maximum(0, safe_div(yp + 1, jnp.abs(p_safe - 1))) ** safe_div(1, p_safe)) - 1\n    )\n    if premult is not None:\n      x = x / premult\n    return x"}
{"namespace": "math.inv_power_ladder", "completion": "    if postmult is not None:\n      y = y / postmult\n    yp = jnp.abs(y)\n    ps = jnp.abs(p - 1) / p\n    x = safe_sign(y) * select(\n        [\n            (p == 1, yp),\n            (p == 0, safe_exp(yp) - 1),\n            (p == -jnp.inf, -safe_log1p(-yp)),\n            (p == jnp.inf, safe_log1p(yp)),\n        ],\n        clip_finite_nograd((yp / ps + 1) ** (1 / ps) - 1),\n    )\n    if premult is not None:\n      x = x / premult\n    return x"}
{"namespace": "math.inv_power_ladder", "completion": "    if postmult is not None:\n      y = y * postmult\n    yp = jnp.abs(y)\n    if p == 1:\n      x = y\n    elif p == 0:\n      x = jnp.expm1(yp)\n    elif p == -jnp.inf:\n      x = -jnp.log1p(-yp)\n    elif p == jnp.inf:\n      x = jnp.log1p(yp)\n    else:\n      x = jnp.sign(y) * (yp ** (1 / p) - 1) * (p / (p - 1))\n    if premult is not None:\n      x = x * premult\n    return x"}
{"namespace": "math.inv_power_ladder", "completion": "    if postmult is not None:\n        y = y / postmult\n    yp = jnp.abs(y)\n    ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n    p_safe = clip_finite_nograd(remove_zero(p))\n    x = safe_sign(y) * select(\n        [\n            (p == 1, yp),\n            (p == 0, safe_exp(yp) - 1),\n            (p == -jnp.inf, -safe_log1p(-yp)),\n            (p == jnp.inf, safe_log1p(yp)),\n        ],\n        clip_finite_nograd(\n            (jnp.power(1 + yp * safe_sign(y), 1 / p_safe) - 1) * jnp.abs(p_safe - 1) / p_safe\n        ),\n    )\n    if premult is not None:\n        x = x / premult\n    return x"}
{"namespace": "math.inv_power_ladder", "completion": "      if postmult is not None:\n          y = y * postmult\n      yp = jnp.abs(y)\n      ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n      p_safe = clip_finite_nograd(remove_zero(p))\n      x = safe_sign(y) * select(\n          [\n              (p == 1, yp),\n              (p == 0, safe_exp(yp) - 1),\n              (p == -jnp.inf, -safe_log1p(-yp)),\n              (p == jnp.inf, safe_log1p(yp)),\n          ],\n          clip_finite_nograd(\n              jnp.power(1 + yp * safe_sign(p) * (p_safe / jnp.abs(p_safe - 1)), 1 / p_safe) - 1\n          ),\n      )\n      if premult is not None:\n          x = x * premult\n      return x"}
{"namespace": "math.inv_power_ladder", "completion": "    if postmult is not None:\n        y = y * postmult\n    yp = jnp.abs(y)\n    if p == 1:\n        x = y\n    elif p == 0:\n        x = jnp.exp(safe_log1p(yp)) - 1\n    elif p == -jnp.inf:\n        x = -safe_log1p(-yp)\n    elif p == jnp.inf:\n        x = safe_log1p(yp)\n    else:\n        x = jnp.sign(y) * ((yp + 1) ** (1 / p) - 1) * (jnp.abs(p - 1) / p)\n    if premult is not None:\n        x = x * premult\n    return x"}
{"namespace": "math.inv_power_ladder", "completion": "    if postmult is not None:\n        y = y / postmult\n    yp = jnp.abs(y)\n    if p == 1:\n        x = y\n    elif p == 0:\n        x = jnp.expm1(yp)\n    elif p == -jnp.inf:\n        x = -jnp.log1p(-yp)\n    elif p == jnp.inf:\n        x = jnp.log1p(yp)\n    else:\n        x = jnp.sign(y) * (jnp.power(1 + yp * jnp.abs(p - 1) / jnp.abs(p), 1 / jnp.abs(p - 1)) - 1) * jnp.abs(p - 1) / jnp.abs(p)\n    if premult is not None:\n        x = x / premult\n    return x"}
{"namespace": "math.inv_power_ladder", "completion": "\n    # Compute the sign of y\n    sign_y = safe_sign(y)\n\n    # Compute the absolute value of y\n    abs_y = jnp.abs(y)\n\n    # Compute the absolute value of p\n    abs_p = jnp.abs(p)\n\n    # Compute the inverse transformation based on the value of p\n    if p == 1:\n        result = abs_y\n    elif p == 0:\n        result = safe_exp(abs_y) - 1\n    elif p == -jnp.inf:\n        result = -safe_log1p(-abs_y)\n    elif p == jnp.inf:\n        result = safe_expm1(abs_y)\n    else:\n        result = (jnp.power(abs_y / (abs_p - 1) + 1, 1 / abs_p) - 1) * (abs_p / (abs_p - 1))\n\n    # Apply pre-multiplication and post-multiplication adjustments\n    if premult is not None:\n        result = result * premult\n    if postmult is not None:\n        result = result * postmult\n\n    # Apply the sign of y to the result\n    return sign_y * result"}
{"namespace": "math.inv_power_ladder", "completion": "    # Compute the inverse operation of the power ladder transformation\n    if postmult is not None:\n        y = y / postmult\n    yp = jnp.abs(y)\n    ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n    p_safe = clip_finite_nograd(remove_zero(p))\n    x = safe_sign(y) * select(\n        [\n            (p == 1, yp),\n            (p == 0, safe_exp(yp) - 1),\n            (p == -jnp.inf, -safe_log1p(-yp)),\n            (p == jnp.inf, safe_log1p(yp)),\n        ],\n        clip_finite_nograd(\n            (safe_div(p_safe, jnp.abs(p_safe - 1))) * (jnp.power(1 + ys, 1 / p_safe) - 1)\n        ),\n    )\n    if premult is not None:\n        x = x / premult\n    return x"}
{"namespace": "math.inv_power_ladder", "completion": "    # Apply various mathematical operations based on the value of `p` to compute the inverse transformation\n    if postmult is not None:\n        y = y / postmult\n    yp = jnp.abs(y)\n    p_safe = clip_finite_nograd(remove_zero(p))\n    x = safe_sign(y) * select(\n        [\n            (p == 1, yp),\n            (p == 0, safe_exp(yp) - 1),\n            (p == -jnp.inf, -safe_log1p(-yp)),\n            (p == jnp.inf, safe_log1p(yp)),\n        ],\n        safe_div(yp + 1, (jnp.abs(p_safe - 1) / p_safe) ** (1 / p_safe)) - 1\n    )\n    if premult is not None:\n        x = x / premult\n    return x"}
{"namespace": "math.inv_power_ladder", "completion": "    if premult is not None:\n        y = y / premult\n    yp = jnp.abs(y)\n    ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n    p_safe = clip_finite_nograd(remove_zero(p))\n    x = safe_sign(y) * select(\n        [\n            (p == 1, yp),\n            (p == 0, safe_exp(yp) - 1),\n            (p == -jnp.inf, -safe_log1p(-yp)),\n            (p == jnp.inf, safe_log1p(yp)),\n        ],\n        clip_finite_nograd(\n            (jnp.maximum(1 + yp, 1) ** (1 / p_safe)) * jnp.maximum(1 + yp, 1) - 1\n        ) / (jnp.abs(p_safe - 1) / p_safe),\n    )\n    if postmult is not None:\n        x = x / postmult\n    return x"}
{"namespace": "math.inv_power_ladder", "completion": "      if postmult is not None:\n          y = y / postmult\n      yp = jnp.abs(y)\n      ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n      p_safe = clip_finite_nograd(remove_zero(p))\n      # Compute the inverse transformation based on the value of p\n      x = safe_sign(y) * select(\n          [\n              (p == 1, yp),\n              (p == 0, safe_exp(yp) - 1),\n              (p == -jnp.inf, -safe_log1p(-yp)),\n              (p == jnp.inf, safe_log1p(yp)),\n          ],\n          clip_finite_nograd(\n              jnp.power(1 + yp * safe_div(p_safe, jnp.abs(p_safe - 1)), safe_div(1, p_safe)) - 1\n          ),\n      )\n      if premult is not None:\n          x = x / premult\n      return x"}
{"namespace": "math.inv_power_ladder", "completion": "    if postmult is not None:\n        y = y / postmult\n    yp = jnp.abs(y)\n    ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n    p_safe = clip_finite_nograd(remove_zero(p))\n    x = safe_sign(y) * select(\n        [\n            (p == 1, yp),\n            (p == 0, safe_exp(yp) - 1),\n            (p == -jnp.inf, -safe_log1p(-yp)),\n            (p == jnp.inf, safe_log1p(yp)),\n        ],\n        clip_finite_nograd(\n            jnp.power(1 + yp * safe_sign(p) * safe_div(1, p_safe), safe_div(1, p_safe)) - 1,\n        ),\n    )\n    if premult is not None:\n        x = x / premult\n    return x"}
{"namespace": "math.inv_power_ladder", "completion": "    # Apply various mathematical operations based on the value of `p` to compute the inverse transformation\n    if postmult is not None:\n      y = y / postmult\n    yp = jnp.abs(y)\n    y_sign = safe_sign(y)\n    p_safe = clip_finite_nograd(remove_zero(p))\n    x = y_sign * select(\n        [\n            (p == 1, yp),\n            (p == 0, safe_expm1(yp)),\n            (p == -jnp.inf, -safe_log1p(-yp)),\n            (p == jnp.inf, safe_log1p(yp)),\n        ],\n        clip_finite_nograd(\n            (jnp.power(yp / (jnp.abs(p - 1) / p_safe) + 1, 1 / p_safe) - 1) * (jnp.abs(p - 1) / p_safe)\n        ),\n    )\n    if premult is not None:\n      x = x / premult\n    return x"}
{"namespace": "math.inv_power_ladder", "completion": "    if postmult is not None:\n        y = y / postmult\n    yp = jnp.abs(y)\n    ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n    p_safe = clip_finite_nograd(remove_zero(p))\n    x = safe_sign(y) * select(\n        [\n            (p == 1, yp),\n            (p == 0, safe_exp(yp) - 1),\n            (p == -jnp.inf, -safe_log1p(-yp)),\n            (p == jnp.inf, safe_log1p(yp)),\n        ],\n        clip_finite_nograd(\n            (jnp.power(1 + yp * safe_sign(p) * (p - 1), 1 / p_safe) - 1) * jnp.maximum(tiny_val, jnp.abs(p - 1)) / p_safe\n        ),\n    )\n    if premult is not None:\n        x = x / premult\n    return x"}
{"namespace": "math.inv_power_ladder", "completion": "      # Compute the inverse operation based on the value of p\n      if postmult is not None:\n          y = y / postmult\n      yp = jnp.abs(y)\n      ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n      p_safe = clip_finite_nograd(remove_zero(p))\n      x = safe_sign(y) * select(\n          [\n              (p == 1, yp),\n              (p == 0, safe_exp(yp) - 1),\n              (p == -jnp.inf, -safe_log1p(-yp)),\n              (p == jnp.inf, safe_log1p(yp)),\n          ],\n          clip_finite_nograd(\n              jnp.power(1 + yp * safe_sign(p) * (p_safe / jnp.abs(p_safe - 1)), 1 / p_safe) - 1\n          ),\n      )\n      if premult is not None:\n          x = x / premult\n      return x"}
{"namespace": "math.inv_power_ladder", "completion": "    if postmult is not None:\n        y = y * postmult\n    yp = jnp.abs(y)\n    ps = jnp.abs(p - 1) / jnp.maximum(tiny_val, jnp.abs(p - 1))\n    x = safe_sign(y) * select(\n        [\n            (p == 1, yp),\n            (p == 0, safe_exp(yp) - 1),\n            (p == -jnp.inf, -safe_log1p(-yp)),\n            (p == jnp.inf, safe_log1p(yp)),\n        ],\n        clip_finite_nograd(safe_div(yp + 1, ps) ** (1 / ps)) - 1,\n    )\n    if premult is not None:\n        x = x * premult\n    return x"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Calculate the homogeneous coordinates of the origins\n  origins_homogeneous = xnp.concatenate([origins, xnp.ones((origins.shape[0], 1), dtype=xnp.float32)], axis=1)\n\n  # Apply the inverse intrinsic matrix to the origins\n  origins_homogeneous = xnp.dot(origins_homogeneous, pixtocam.T)\n\n  # Calculate the depth values for the origins\n  depths = xnp.dot(origins_homogeneous, xnp.array([0, 0, 1], dtype=xnp.float32))\n\n  # Adjust the origins to the near plane\n  origins_homogeneous = origins_homogeneous * (near / depths)[:, xnp.newaxis]\n\n  # Calculate the homogeneous coordinates of the directions\n  directions_homogeneous = xnp.concatenate([directions, xnp.zeros((directions.shape[0], 1), dtype=xnp.float32)], axis=1)\n\n  # Apply the inverse intrinsic matrix to the directions\n  directions_homogeneous = xnp.dot(directions_homogeneous, pixtocam.T)\n\n  # Calculate the normalized device coordinates for the origins and directions\n  origins_ndc = origins_homogeneous[:, :2] / depths[:, xnp.newaxis]\n  directions_ndc = directions_homogeneous[:, :2]\n\n  return origins_ndc, directions_ndc"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert origins and directions to homogeneous coordinates\n  origins_h = xnp.concatenate([origins, xnp.ones((origins.shape[0], 1))], axis=1)\n  directions_h = xnp.concatenate([directions, xnp.zeros((directions.shape[0], 1))], axis=1)\n\n  # Apply perspective projection\n  origins_ndc = xnp.dot(origins_h, pixtocam.T)\n  directions_ndc = xnp.dot(directions_h, pixtocam.T)\n\n  # Normalize by the z-coordinate and adjust for near plane\n  origins_ndc = origins_ndc / origins_ndc[:, -1][:, None] * near\n  directions_ndc = directions_ndc / directions_ndc[:, -1][:, None]\n\n  return origins_ndc[:, :3], directions_ndc[:, :3]"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert origins and directions to homogeneous coordinates\n  origins_homogeneous = xnp.concatenate([origins, xnp.ones((origins.shape[0], 1), dtype=origins.dtype)], axis=-1)\n  directions_homogeneous = xnp.concatenate([directions, xnp.zeros((directions.shape[0], 1), dtype=directions.dtype)], axis=-1)\n\n  # Apply perspective projection\n  origins_ndc = xnp.dot(origins_homogeneous, pixtocam.T)\n  directions_ndc = xnp.dot(directions_homogeneous, pixtocam.T)\n\n  # Normalize origins and directions by the near plane\n  origins_ndc /= -origins_ndc[:, -1, None] * near\n  directions_ndc /= -directions_ndc[:, -1, None]\n\n  return origins_ndc[:, :-1], directions_ndc[:, :-1]"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert origins and directions to homogeneous coordinates\n  origins_homogeneous = xnp.concatenate([origins, xnp.ones((origins.shape[0], 1), dtype=xnp.float32)], axis=1)\n  directions_homogeneous = xnp.concatenate([directions, xnp.zeros((directions.shape[0], 1), dtype=xnp.float32)], axis=1)\n\n  # Apply the inverse intrinsic matrix to convert to camera space\n  origins_cam = xnp.dot(origins_homogeneous, pixtocam.T)\n  directions_cam = xnp.dot(directions_homogeneous, pixtocam.T)\n\n  # Calculate the ray origins and directions in NDC\n  origins_ndc = origins_cam[:, :2] / xnp.expand_dims(-origins_cam[:, 2], axis=1)\n  directions_ndc = directions_cam[:, :2] / xnp.expand_dims(-directions_cam[:, 2], axis=1)\n\n  # Clip the origins and directions to the near plane\n  origins_ndc = xnp.clip(origins_ndc, -1, 1)\n  directions_ndc = xnp.clip(directions_ndc, -1, 1)\n\n  return origins_ndc, directions_ndc"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert origins to homogeneous coordinates\n  origins_h = xnp.concatenate([origins, xnp.ones((origins.shape[0], 1), dtype=xnp.float32)], axis=-1)\n\n  # Apply perspective projection\n  origins_h_proj = xnp.dot(origins_h, pixtocam.T)\n  origins_ndc = origins_h_proj[:, :2] / origins_h_proj[:, 2:]\n\n  # Calculate directions in NDC\n  directions_ndc = directions / xnp.linalg.norm(directions, axis=-1, keepdims=True)\n\n  return origins_ndc, directions_ndc"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert origins and directions to homogeneous coordinates\n  origins_homogeneous = xnp.concatenate([origins, xnp.ones((origins.shape[0], 1))], axis=1)\n  directions_homogeneous = xnp.concatenate([directions, xnp.zeros((directions.shape[0], 1))], axis=1)\n\n  # Apply inverse intrinsic matrix to origins and directions\n  origins_ndc = xnp.dot(origins_homogeneous, pixtocam.T)\n  directions_ndc = xnp.dot(directions_homogeneous, pixtocam.T)\n\n  # Normalize origins and directions by dividing by z-coordinate\n  origins_ndc /= origins_ndc[:, -1][:, None]\n  directions_ndc /= directions_ndc[:, -1][:, None]\n\n  # Adjust origins to the near plane\n  origins_ndc *= near\n\n  return origins_ndc[:, :3], directions_ndc[:, :3]"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert origins and directions to homogeneous coordinates\n  origins_homogeneous = xnp.concatenate([origins, xnp.ones((origins.shape[0], 1), dtype=xnp.float32)], axis=1)\n  directions_homogeneous = xnp.concatenate([directions, xnp.zeros((directions.shape[0], 1), dtype=xnp.float32)], axis=1)\n\n  # Apply the inverse intrinsic matrix to the origins and directions\n  origins_homogeneous_cam = xnp.dot(origins_homogeneous, pixtocam.T)\n  directions_homogeneous_cam = xnp.dot(directions_homogeneous, pixtocam.T)\n\n  # Normalize the directions\n  directions_normalized = directions_homogeneous_cam / xnp.linalg.norm(directions_homogeneous_cam, axis=1, keepdims=True)\n\n  # Calculate the intersection of the rays with the near plane\n  t = -origins_homogeneous_cam[:, 2] / directions_normalized[:, 2]\n  origins_ndc = origins_homogeneous_cam + t[:, xnp.newaxis] * directions_normalized\n\n  # Convert origins to NDC\n  origins_ndc = origins_ndc[:, :2] / origins_ndc[:, 2, xnp.newaxis]\n\n  # Convert directions to NDC\n  directions_ndc = directions_normalized[:, :2]\n\n  return origins_ndc, directions_ndc"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert origins to NDC\n  origins_h = xnp.concatenate([origins, xnp.ones((origins.shape[0], 1), dtype=xnp.float32)], axis=1)\n  origins_ndc = xnp.dot(origins_h, pixtocam.T)\n  origins_ndc = origins_ndc[:, :3] / origins_ndc[:, 3:]\n\n  # Convert directions to NDC\n  directions_ndc = xnp.dot(directions, pixtocam[:3, :3].T)\n\n  return origins_ndc, directions_ndc"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert origins and directions to homogeneous coordinates\n  origins_h = xnp.concatenate([origins, xnp.ones((origins.shape[0], 1), dtype=xnp.float32)], axis=1)\n  directions_h = xnp.concatenate([directions, xnp.zeros((directions.shape[0], 1), dtype=xnp.float32)], axis=1)\n\n  # Apply inverse intrinsic matrix to convert to camera space\n  origins_cam = xnp.dot(origins_h, pixtocam.T)\n  directions_cam = xnp.dot(directions_h, pixtocam.T)\n\n  # Normalize the directions\n  directions_cam_norm = xnp.linalg.norm(directions_cam, axis=1, keepdims=True)\n  directions_cam_normalized = directions_cam / directions_cam_norm\n\n  # Calculate the scale factor for adjusting the origins to the near plane\n  scale_factor = near / origins_cam[:, 2]\n\n  # Adjust origins to the near plane\n  origins_ndc = origins_cam * scale_factor[:, None]\n\n  return origins_ndc, directions_cam_normalized"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert origins and directions to homogeneous coordinates\n  origins_h = xnp.concatenate([origins, xnp.ones((origins.shape[0], 1))], axis=1)\n  directions_h = xnp.concatenate([directions, xnp.zeros((directions.shape[0], 1))], axis=1)\n\n  # Apply perspective projection\n  origins_ndc = xnp.dot(origins_h, pixtocam.T)\n  directions_ndc = xnp.dot(directions_h, pixtocam.T)\n\n  # Normalize by z-coordinate and adjust for near plane\n  origins_ndc /= origins_ndc[:, 2:3]\n  directions_ndc /= directions_ndc[:, 2:3]\n  origins_ndc[:, :2] = (origins_ndc[:, :2] + 1) / 2\n  directions_ndc[:, :2] = (directions_ndc[:, :2] + 1) / 2\n\n  # Adjust for near plane\n  origins_ndc[:, 2] = (2 * near * origins_ndc[:, 2] - near) / (near - origins_ndc[:, 2])\n  directions_ndc[:, 2] = (2 * near * directions_ndc[:, 2]) / (near - origins_ndc[:, 2])\n\n  return origins_ndc[:, :3], directions_ndc[:, :3]"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert origins and directions to homogeneous coordinates\n  origins_h = xnp.concatenate([origins, xnp.ones((origins.shape[0], 1), dtype=xnp.float32)], axis=1)\n  directions_h = xnp.concatenate([directions, xnp.zeros((directions.shape[0], 1), dtype=xnp.float32)], axis=1)\n\n  # Apply inverse intrinsic matrix to origins and directions\n  origins_cam = xnp.dot(pixtocam, origins_h.T).T\n  directions_cam = xnp.dot(pixtocam, directions_h.T).T\n\n  # Normalize origins and directions by the z-coordinate\n  origins_ndc = origins_cam / origins_cam[:, 2, None]\n  directions_ndc = directions_cam / directions_cam[:, 2, None]\n\n  # Scale origins and directions to the near plane\n  origins_ndc[:, :2] *= near\n  directions_ndc[:, :2] *= near\n\n  return origins_ndc, directions_ndc"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert origins and directions to homogeneous coordinates\n  origins_h = xnp.concatenate([origins, xnp.ones((origins.shape[0], 1), dtype=xnp.float32)], axis=1)\n  directions_h = xnp.concatenate([directions, xnp.zeros((directions.shape[0], 1), dtype=xnp.float32)], axis=1)\n\n  # Apply the inverse intrinsic matrix to the origins and directions\n  origins_h_ndc = xnp.dot(origins_h, pixtocam.T)\n  directions_h_ndc = xnp.dot(directions_h, pixtocam.T)\n\n  # Normalize the coordinates by dividing by the z-coordinate\n  origins_ndc = origins_h_ndc[:, :2] / origins_h_ndc[:, 2, None]\n  directions_ndc = directions_h_ndc[:, :2] / directions_h_ndc[:, 2, None]\n\n  # Scale the coordinates to the near plane\n  origins_ndc *= near\n  directions_ndc *= near\n\n  return origins_ndc, directions_ndc"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert origins and directions to homogeneous coordinates\n  origins_homo = xnp.concatenate([origins, xnp.ones((origins.shape[0], 1), dtype=xnp.float32)], axis=1)\n  directions_homo = xnp.concatenate([directions, xnp.zeros((directions.shape[0], 1), dtype=xnp.float32)], axis=1)\n\n  # Apply the inverse intrinsic matrix to the origins and directions\n  origins_ndc = xnp.dot(origins_homo, pixtocam.T)\n  directions_ndc = xnp.dot(directions_homo, pixtocam.T)\n\n  # Normalize the origins and directions by the z-coordinate and adjust for the near plane\n  origins_ndc = origins_ndc / origins_ndc[:, -1][:, None] * near\n  directions_ndc = directions_ndc / directions_ndc[:, -1][:, None]\n\n  # Remove the homogeneous coordinate\n  origins_ndc = origins_ndc[:, :3]\n  directions_ndc = directions_ndc[:, :3]\n\n  return origins_ndc, directions_ndc"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert origins and directions to homogeneous coordinates\n  origins_h = xnp.concatenate([origins, xnp.ones((origins.shape[0], 1))], axis=1)\n  directions_h = xnp.concatenate([directions, xnp.zeros((directions.shape[0], 1))], axis=1)\n\n  # Apply the inverse intrinsic matrix to the origins and directions\n  origins_cam = xnp.dot(origins_h, pixtocam.T)\n  directions_cam = xnp.dot(directions_h, pixtocam.T)\n\n  # Normalize the directions to have unit length\n  directions_cam /= xnp.linalg.norm(directions_cam, axis=1, keepdims=True)\n\n  # Calculate the intersection of the rays with the near plane\n  t = -origins_cam[:, 2] / directions_cam[:, 2]\n  origins_ndc = origins_cam + t[:, xnp.newaxis] * directions_cam\n\n  # Scale the origins and directions to the near plane\n  origins_ndc[:, :2] /= -origins_ndc[:, 2, xnp.newaxis]\n  directions_ndc = directions_cam / -directions_cam[:, 2, xnp.newaxis]\n\n  return origins_ndc[:, :2], directions_ndc[:, :2]"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert origins to homogeneous coordinates\n  origins_homogeneous = xnp.concatenate([origins, xnp.ones((origins.shape[0], 1))], axis=1)\n\n  # Apply perspective projection\n  origins_ndc = xnp.dot(origins_homogeneous, pixtocam.T)\n  origins_ndc = origins_ndc[:, :2] / origins_ndc[:, 2:]\n\n  # Calculate directions in NDC\n  directions_ndc = directions / xnp.linalg.norm(directions, axis=1, keepdims=True)\n\n  return origins_ndc, directions_ndc"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert origins and directions to homogeneous coordinates\n  origins_h = xnp.concatenate([origins, xnp.ones((origins.shape[0], 1), dtype=xnp.float32)], axis=1)\n  directions_h = xnp.concatenate([directions, xnp.zeros((directions.shape[0], 1), dtype=xnp.float32)], axis=1)\n\n  # Apply inverse intrinsic matrix to origins and directions\n  origins_cam = xnp.dot(origins_h, pixtocam.T)\n  directions_cam = xnp.dot(directions_h, pixtocam.T)\n\n  # Normalize origins and directions by z-coordinate\n  origins_ndc = origins_cam / origins_cam[:, -1][:, None]\n  directions_ndc = directions_cam / directions_cam[:, -1][:, None]\n\n  # Scale origins and directions to near plane\n  origins_ndc[:, :-1] *= near\n  directions_ndc[:, :-1] *= near\n\n  return origins_ndc, directions_ndc"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert origins to homogeneous coordinates\n  origins_h = xnp.concatenate([origins, xnp.ones((origins.shape[0], 1), dtype=xnp.float32)], axis=1)\n\n  # Apply the inverse intrinsic matrix to the origins\n  origins_cam = xnp.dot(origins_h, pixtocam.T)\n\n  # Calculate the depth of the origins in camera space\n  depths = origins_cam[:, 2]\n\n  # Normalize the origins to the near plane\n  origins_ndc = origins_cam / depths[:, xnp.newaxis] * near\n\n  # Apply the inverse intrinsic matrix to the directions\n  directions_ndc = xnp.dot(directions, pixtocam.T)\n\n  return origins_ndc, directions_ndc"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Validate input shapes\n  chex.assert_shape(origins, (..., 3))\n  chex.assert_shape(directions, (..., 3))\n  chex.assert_shape(pixtocam, (3, 3))\n\n  # Convert to homogeneous coordinates\n  origins_hom = xnp.concatenate([origins, xnp.ones_like(origins[..., :1])], axis=-1)\n\n  # Apply perspective projection\n  origins_ndc = xnp.einsum('...ij,...j->...i', pixtocam, origins_hom)\n  directions_ndc = xnp.einsum('...ij,...j->...i', pixtocam, directions)\n\n  # Normalize by homogeneous coordinate\n  origins_ndc = origins_ndc / origins_ndc[..., -1:]\n  directions_ndc = directions_ndc / origins_ndc[..., -1:]\n\n  # Clip to the near plane\n  origins_ndc[..., -1] = xnp.clip(origins_ndc[..., -1], near, xnp.inf)\n\n  return origins_ndc, directions_ndc"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert origins to homogeneous coordinates\n  origins_homogeneous = xnp.concatenate([origins, xnp.ones((origins.shape[0], 1), dtype=xnp.float32)], axis=1)\n\n  # Apply perspective projection\n  origins_ndc = xnp.dot(origins_homogeneous, pixtocam.T)\n  origins_ndc = origins_ndc[:, :2] / origins_ndc[:, 2:]\n\n  # Calculate directions in NDC\n  directions_ndc = directions / xnp.linalg.norm(directions, axis=1, keepdims=True)\n\n  return origins_ndc, directions_ndc"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Convert origins and directions to homogeneous coordinates\n  origins_h = xnp.concatenate([origins, xnp.ones((origins.shape[0], 1), dtype=xnp.float32)], axis=1)\n  directions_h = xnp.concatenate([directions, xnp.zeros((directions.shape[0], 1), dtype=xnp.float32)], axis=1)\n\n  # Apply the inverse intrinsic matrix to the origins and directions\n  origins_cam = xnp.dot(origins_h, pixtocam.T)\n  directions_cam = xnp.dot(directions_h, pixtocam.T)\n\n  # Calculate the intersection of rays with the near plane\n  t = -origins_cam[:, 2] / directions_cam[:, 2]\n  origins_near = origins_cam + t[:, xnp.newaxis] * directions_cam\n\n  # Normalize origins and directions to the near plane\n  origins_ndc = origins_near[:, :2] / origins_near[:, 2:xnp.newaxis]\n  directions_ndc = directions_cam[:, :2] / origins_near[:, 2:xnp.newaxis]\n\n  return origins_ndc, directions_ndc"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Ensure spline degree is at most one less than the number of points in x\n  spline_degree = min(spline_degree, len(x) - 1)\n  \n  # Perform spline interpolation\n  spline = scipy.interpolate.UnivariateSpline(t_input, x, k=spline_degree, s=smoothness)\n  \n  # Query the interpolated signal at t_output times\n  interpolated_values = spline(t_output)\n  \n  return interpolated_values"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Interpolate the 1-dimensional signal x at the specified output times t_output\n  interpolated_values = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n  return scipy.interpolate.splev(t_output, interpolated_values)"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Adjust spline degree\n  spline_degree = min(spline_degree, len(x) - 1)\n\n  # Perform spline interpolation\n  spline = scipy.interpolate.UnivariateSpline(t_input, x, k=spline_degree, s=smoothness)\n  interpolated_values = spline(t_output)\n\n  return interpolated_values"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  tck = scipy.interpolate.splrep(t_input, x, k=min(spline_degree, len(x)-1), s=smoothness)\n  return scipy.interpolate.splev(t_output, tck)"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "    tck = scipy.interpolate.splrep(t_input, x, k=min(spline_degree, len(x) - 1), s=smoothness)\n    interpolated_values = scipy.interpolate.splev(t_output, tck)\n    return interpolated_values"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "    tck = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n    interpolated_values = scipy.interpolate.splev(t_output, tck)\n    return interpolated_values"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Interpolate the 1-dimensional signal x at the specified output times t_output\n  interpolated_values = scipy.interpolate.splev(t_output, scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness))\n  \n  return interpolated_values"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  tck = scipy.interpolate.splrep(t_input, x, k=min(spline_degree, len(x)-1), s=smoothness)\n  return scipy.interpolate.splev(t_output, tck)"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  tck = scipy.interpolate.splrep(t_input, x, k=min(spline_degree, len(x) - 1), s=smoothness)\n  return scipy.interpolate.splev(t_output, tck)"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  tck = scipy.interpolate.splrep(t_input, x, k=min(spline_degree, len(x) - 1), s=smoothness)\n  return scipy.interpolate.splev(t_output, tck)"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  tck = scipy.interpolate.splrep(t_input, x, k=min(spline_degree, len(x)-1), s=smoothness)\n  return scipy.interpolate.splev(t_output, tck)"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Interpolate the 1-dimensional signal x at the specified output times t_output using spline interpolation\n  interpolated_values = scipy.interpolate.splev(t_output, scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness))\n  return interpolated_values"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  tck = scipy.interpolate.splrep(t_input, x, k=min(spline_degree, len(x) - 1), s=smoothness)\n  return scipy.interpolate.splev(t_output, tck)"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Interpolate the 1-dimensional signal using spline interpolation\n  interpolated_values = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n  return scipy.interpolate.splev(t_output, interpolated_values)"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Adjust spline degree\n  spline_degree = min(spline_degree, len(x) - 1)\n  \n  # Perform spline interpolation\n  spline = scipy.interpolate.UnivariateSpline(t_input, x, k=spline_degree, s=smoothness)\n  \n  # Query the interpolated values at t_output times\n  interpolated_values = spline(t_output)\n  \n  return interpolated_values"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Spline interpolation\n  tck = scipy.interpolate.splrep(t_input, x, k=min(spline_degree, len(x) - 1), s=smoothness)\n  interpolated_values = scipy.interpolate.splev(t_output, tck)\n  return interpolated_values"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Adjust spline degree to be at most one less than the number of points in x\n  spline_degree = min(spline_degree, len(x) - 1)\n  \n  # Perform spline interpolation\n  interpolated_values = scipy.interpolate.splev(t_output, scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness))\n  \n  return interpolated_values"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Adjust spline degree\n  spline_degree = min(spline_degree, len(x) - 1)\n  \n  # Perform spline interpolation\n  spline = scipy.interpolate.UnivariateSpline(t_input, x, k=spline_degree, s=smoothness)\n  \n  # Query the interpolated signal at t_output times\n  interpolated_values = spline(t_output)\n  \n  return interpolated_values"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Adjust spline degree\n  spline_degree = min(spline_degree, len(x) - 1)\n  \n  # Interpolate the 1-dimensional signal\n  interpolated_values = scipy.interpolate.splev(t_output, scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness))\n  \n  return interpolated_values"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Adjust spline degree to be at most one less than the number of points in x\n  spline_degree = min(spline_degree, len(x) - 1)\n  \n  # Perform spline interpolation\n  interpolated_values = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n  interpolated_x = scipy.interpolate.splev(t_output, interpolated_values)\n  \n  return interpolated_x"}
{"namespace": "math.learning_rate_decay", "completion": "  if step < lr_delay_steps:\n    # Apply delay to the initial learning rate\n    lr = lr_init * lr_delay_mult\n  else:\n    # Calculate the progression of steps\n    progress = min(step / max_steps, 1)\n    # Calculate the learning rate decay using log-linear interpolation\n    lr = log_lerp(progress, lr_init, lr_final)\n  return lr"}
{"namespace": "math.learning_rate_decay", "completion": "    if lr_delay_steps > 0 and step < lr_delay_steps:\n        return lr_init * lr_delay_mult * (1 - step / lr_delay_steps)\n    else:\n        alpha = step / max_steps\n        return log_lerp(alpha, lr_init, lr_final)"}
{"namespace": "math.learning_rate_decay", "completion": "  if step < lr_delay_steps:\n    lr = lr_init * lr_delay_mult\n  else:\n    t = (step - lr_delay_steps) / (max_steps - lr_delay_steps)\n    lr = log_lerp(t, lr_init, lr_final)\n  return lr"}
{"namespace": "math.learning_rate_decay", "completion": "  if step < lr_delay_steps:\n    lr = lr_init * lr_delay_mult\n  else:\n    progress = min(step / max_steps, 1.0)\n    lr = log_lerp(progress, lr_init, lr_final)\n  return lr"}
{"namespace": "math.learning_rate_decay", "completion": "  if step < lr_delay_steps:\n    lr = lr_init * lr_delay_mult\n  else:\n    progress = min(step / max_steps, 1)\n    lr = log_lerp(progress, lr_init, lr_final)\n  return lr"}
{"namespace": "math.learning_rate_decay", "completion": "    if lr_delay_steps > 0 and step < lr_delay_steps:\n        # Apply delay and scale down the initial learning rate\n        lr = lr_init * lr_delay_mult\n    else:\n        # Calculate the progression of steps\n        progress = step / max_steps\n        # Calculate the log-linear interpolation (exponential decay) between initial and final learning rate\n        lr = lr_init * (lr_final / lr_init) ** progress\n    return lr"}
{"namespace": "math.learning_rate_decay", "completion": "  if step < lr_delay_steps:\n    lr = lr_init * lr_delay_mult\n  else:\n    progress = min(step / max_steps, 1.0)\n    lr = log_lerp(progress, lr_init, lr_final)\n  return lr"}
{"namespace": "math.learning_rate_decay", "completion": "\n    if step < lr_delay_steps:\n        return lr_init * lr_delay_mult\n\n    t = step / max_steps\n    return log_lerp(t, lr_init, lr_final)"}
{"namespace": "math.learning_rate_decay", "completion": "  if step < lr_delay_steps:\n    lr = lr_init * lr_delay_mult\n  else:\n    progress = min(step / max_steps, 1)\n    lr = log_lerp(progress, lr_init, lr_final)\n  return lr"}
{"namespace": "math.learning_rate_decay", "completion": "  if step < lr_delay_steps:\n    lr = lr_init * lr_delay_mult\n  else:\n    progress = min(step / max_steps, 1.0)\n    lr = log_lerp(progress, lr_init, lr_final)\n  return lr"}
{"namespace": "math.learning_rate_decay", "completion": "  if step < lr_delay_steps:\n    lr = lr_init * lr_delay_mult\n  else:\n    progress = min(step / max_steps, 1)\n    lr = log_lerp(progress, lr_init, lr_final)\n  return lr"}
{"namespace": "math.learning_rate_decay", "completion": "    if step < lr_delay_steps:\n        return lr_init * lr_delay_mult\n    else:\n        t = (step - lr_delay_steps) / (max_steps - lr_delay_steps)\n        return log_lerp(t, lr_init, lr_final)"}
{"namespace": "math.learning_rate_decay", "completion": "    if step < lr_delay_steps:\n        # Apply delay to the initial learning rate\n        lr = lr_init * lr_delay_mult\n    else:\n        # Calculate the learning rate decay using log-linear interpolation\n        t = (step - lr_delay_steps) / (max_steps - lr_delay_steps)\n        lr = log_lerp(t, lr_init, lr_final)\n    \n    return lr"}
{"namespace": "math.learning_rate_decay", "completion": "    if step < lr_delay_steps:\n        return lr_init * lr_delay_mult\n    else:\n        progress = min(step / max_steps, 1)\n        return lr_init * (lr_final / lr_init) ** progress"}
{"namespace": "math.learning_rate_decay", "completion": "  if step < lr_delay_steps:\n    lr = lr_init * lr_delay_mult\n  else:\n    progress = min(1.0, step / max_steps)\n    lr = log_lerp(progress, lr_init, lr_final)\n  return lr"}
{"namespace": "math.learning_rate_decay", "completion": "    if step < lr_delay_steps:\n        return lr_init * lr_delay_mult\n    else:\n        t = (step - lr_delay_steps) / (max_steps - lr_delay_steps)\n        return log_lerp(t, lr_init, lr_final)"}
{"namespace": "math.learning_rate_decay", "completion": "  if step < lr_delay_steps:\n    lr = lr_init * lr_delay_mult\n  else:\n    progress = min(step / max_steps, 1)\n    lr = log_lerp(progress, lr_init, lr_final)\n  return lr"}
{"namespace": "math.learning_rate_decay", "completion": "    if step < lr_delay_steps:\n        return lr_init * lr_delay_mult\n    else:\n        t = (step - lr_delay_steps) / (max_steps - lr_delay_steps)\n        return log_lerp(t, lr_init, lr_final)"}
{"namespace": "math.learning_rate_decay", "completion": "    if lr_delay_steps > 0 and step < lr_delay_steps:\n        return lr_init * lr_delay_mult + (lr_init - lr_init * lr_delay_mult) * (step / lr_delay_steps)\n    else:\n        return lr_final + (lr_init - lr_final) * jnp.exp(-5 * step / max_steps)"}
{"namespace": "math.learning_rate_decay", "completion": "  if step < lr_delay_steps:\n    lr = lr_init * lr_delay_mult\n  else:\n    progress = min(1.0, step / max_steps)\n    lr = log_lerp(progress, lr_init, lr_final)\n  return lr"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "    return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([\n      [fx, 0, cx],\n      [0, fy, cy],\n      [0, 0, 1]\n  ])"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  intrinsic_matrix = xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n  return intrinsic_matrix"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  intrinsic_matrix = xnp.array([[fx, 0, cx],\n                                [0, fy, cy],\n                                [0, 0, 1]])\n  return intrinsic_matrix"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([\n      [fx, 0, cx],\n      [0, fy, cy],\n      [0, 0, 1]\n  ])"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  intrinsic_matrix = xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n  return intrinsic_matrix"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  intrinsic_matrix = xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n  return intrinsic_matrix"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "\n  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  K = xnp.array([\n      [fx, 0, cx],\n      [0, fy, cy],\n      [0, 0, 1]\n  ])\n  return K"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx],\n                    [0, fy, cy],\n                    [0, 0, 1]])"}
{"namespace": "utils.dummy_rays", "completion": "    rng = jax.random.PRNGKey(0)  # Initialize random number generator\n    n = 1000  # Number of rays to generate\n    origin_lo = -1.0  # Lower bound for ray origins\n    origin_hi = 1.0  # Upper bound for ray origins\n    radius_lo = 0.1  # Lower bound for ray radii\n    radius_hi = 0.5  # Upper bound for ray radii\n    near_lo = 0.1  # Lower bound for near plane\n    near_hi = 1.0  # Upper bound for near plane\n    far_lo = 3.0  # Lower bound for far plane\n    far_hi = 5.0  # Upper bound for far plane\n\n    # Generate random rays using the predefined function\n    random_rays = generate_random_rays(\n        rng,\n        n,\n        origin_lo,\n        origin_hi,\n        radius_lo,\n        radius_hi,\n        near_lo,\n        near_hi,\n        far_lo,\n        far_hi,\n        include_exposure_idx,\n        include_exposure_values,\n        include_device_idx,\n    )\n\n    return random_rays  # Return the generated random rays"}
{"namespace": "utils.dummy_rays", "completion": "    rng = jax.random.PRNGKey(0)  # Set a fixed random key for reproducibility\n    n = 1000  # Number of rays to generate\n    origin_lo = -1.0\n    origin_hi = 1.0\n    radius_lo = 0.1\n    radius_hi = 0.5\n    near_lo = 1.0\n    near_hi = 5.0\n    far_lo = 10.0\n    far_hi = 20.0\n\n    return generate_random_rays(\n        rng,\n        n,\n        origin_lo,\n        origin_hi,\n        radius_lo,\n        radius_hi,\n        near_lo,\n        near_hi,\n        far_lo,\n        far_hi,\n        include_exposure_idx,\n        include_exposure_values,\n        include_device_idx,\n    )"}
{"namespace": "utils.dummy_rays", "completion": "  # Set the parameters for generating random rays\n  rng = jax.random.PRNGKey(0)\n  n = 100  # Number of rays\n  origin_lo = -1.0\n  origin_hi = 1.0\n  radius_lo = 0.1\n  radius_hi = 0.5\n  near_lo = 0.1\n  near_hi = 1.0\n  far_lo = 3.0\n  far_hi = 5.0\n\n  # Generate random rays using the predefined function\n  random_rays = generate_random_rays(\n      rng,\n      n,\n      origin_lo,\n      origin_hi,\n      radius_lo,\n      radius_hi,\n      near_lo,\n      near_hi,\n      far_lo,\n      far_hi,\n      include_exposure_idx,\n      include_exposure_values,\n      include_device_idx,\n  )\n\n  return random_rays"}
{"namespace": "utils.dummy_rays", "completion": "  rng = jax.random.PRNGKey(0)  # Set a fixed random key for reproducibility\n  n = 1000  # Number of rays to generate\n  origin_lo, origin_hi = -1.0, 1.0  # Range for ray origins\n  radius_lo, radius_hi = 0.1, 0.5  # Range for ray radii\n  near_lo, near_hi = 0.1, 0.5  # Range for near plane\n  far_lo, far_hi = 3.0, 5.0  # Range for far plane\n\n  # Generate random rays using the specified parameters and options\n  random_rays = generate_random_rays(\n      rng,\n      n,\n      origin_lo,\n      origin_hi,\n      radius_lo,\n      radius_hi,\n      near_lo,\n      near_hi,\n      far_lo,\n      far_hi,\n      include_exposure_idx,\n      include_exposure_values,\n      include_device_idx,\n  )\n\n  return random_rays"}
{"namespace": "utils.dummy_rays", "completion": "    rng = jax.random.PRNGKey(0)\n    n = 100  # Number of rays to generate\n    origin_lo, origin_hi = 0, 1\n    radius_lo, radius_hi = 0.1, 0.5\n    near_lo, near_hi = 0.1, 0.5\n    far_lo, far_hi = 1.0, 5.0\n\n    return generate_random_rays(\n        rng,\n        n,\n        origin_lo,\n        origin_hi,\n        radius_lo,\n        radius_hi,\n        near_lo,\n        near_hi,\n        far_lo,\n        far_hi,\n        include_exposure_idx,\n        include_exposure_values,\n        include_device_idx,\n    )"}
{"namespace": "utils.dummy_rays", "completion": "  rng = jax.random.PRNGKey(0)\n  n = 100  # Number of rays to generate\n  origin_lo = -1.0\n  origin_hi = 1.0\n  radius_lo = 0.1\n  radius_hi = 0.5\n  near_lo = 0.1\n  near_hi = 1.0\n  far_lo = 3.0\n  far_hi = 5.0\n\n  return generate_random_rays(\n      rng,\n      n,\n      origin_lo,\n      origin_hi,\n      radius_lo,\n      radius_hi,\n      near_lo,\n      near_hi,\n      far_lo,\n      far_hi,\n      include_exposure_idx,\n      include_exposure_values,\n      include_device_idx,\n  )"}
{"namespace": "utils.dummy_rays", "completion": "  rng = jax.random.PRNGKey(0)\n  n = 100  # Number of rays to generate\n  origin_lo = -1.0\n  origin_hi = 1.0\n  radius_lo = 0.1\n  radius_hi = 0.5\n  near_lo = 0.1\n  near_hi = 0.5\n  far_lo = 2.0\n  far_hi = 3.0\n\n  return generate_random_rays(\n      rng,\n      n,\n      origin_lo,\n      origin_hi,\n      radius_lo,\n      radius_hi,\n      near_lo,\n      near_hi,\n      far_lo,\n      far_hi,\n      include_exposure_idx,\n      include_exposure_values,\n      include_device_idx,\n  )"}
{"namespace": "utils.dummy_rays", "completion": "    rng = jax.random.PRNGKey(0)  # Initialize random number generator\n    n = 100  # Number of rays to generate\n    origin_lo = 0.0\n    origin_hi = 1.0\n    radius_lo = 0.1\n    radius_hi = 0.5\n    near_lo = 0.1\n    near_hi = 1.0\n    far_lo = 5.0\n    far_hi = 10.0\n\n    return generate_random_rays(\n        rng,\n        n,\n        origin_lo,\n        origin_hi,\n        radius_lo,\n        radius_hi,\n        near_lo,\n        near_hi,\n        far_lo,\n        far_hi,\n        include_exposure_idx,\n        include_exposure_values,\n        include_device_idx,\n    )"}
{"namespace": "utils.dummy_rays", "completion": "    rng = jax.random.PRNGKey(0)\n    n = 100  # Number of rays to generate\n    origin_lo = -1.0\n    origin_hi = 1.0\n    radius_lo = 0.1\n    radius_hi = 0.5\n    near_lo = 0.1\n    near_hi = 0.5\n    far_lo = 1.0\n    far_hi = 2.0\n\n    return generate_random_rays(\n        rng,\n        n,\n        origin_lo,\n        origin_hi,\n        radius_lo,\n        radius_hi,\n        near_lo,\n        near_hi,\n        far_lo,\n        far_hi,\n        include_exposure_idx,\n        include_exposure_values,\n        include_device_idx,\n    )"}
{"namespace": "utils.dummy_rays", "completion": "  # Generate random rays using the specified parameters and options\n  rng = jax.random.PRNGKey(0)  # Initialize random number generator\n  n = 1000  # Number of rays to generate\n  origin_lo = -1.0\n  origin_hi = 1.0\n  radius_lo = 0.1\n  radius_hi = 0.5\n  near_lo = 1.0\n  near_hi = 5.0\n  far_lo = 10.0\n  far_hi = 20.0\n\n  # Call the generate_random_rays function to create random rays\n  random_rays = generate_random_rays(\n      rng,\n      n,\n      origin_lo,\n      origin_hi,\n      radius_lo,\n      radius_hi,\n      near_lo,\n      near_hi,\n      far_lo,\n      far_hi,\n      include_exposure_idx,\n      include_exposure_values,\n      include_device_idx,\n  )\n\n  return random_rays  # Return the generated random rays"}
{"namespace": "utils.dummy_rays", "completion": "  rng = jax.random.PRNGKey(0)\n  n = 100  # Number of rays\n  origin_lo = -1.0\n  origin_hi = 1.0\n  radius_lo = 0.1\n  radius_hi = 0.5\n  near_lo = 0.1\n  near_hi = 1.0\n  far_lo = 3.0\n  far_hi = 5.0\n\n  return generate_random_rays(\n      rng,\n      n,\n      origin_lo,\n      origin_hi,\n      radius_lo,\n      radius_hi,\n      near_lo,\n      near_hi,\n      far_lo,\n      far_hi,\n      include_exposure_idx,\n      include_exposure_values,\n      include_device_idx,\n  )"}
{"namespace": "utils.dummy_rays", "completion": "  # Generate random rays using the specified options\n  rng = jax.random.PRNGKey(0)  # Initialize random key\n  n = 1000  # Number of rays\n  origin_lo = -1.0  # Lower bound for ray origins\n  origin_hi = 1.0  # Upper bound for ray origins\n  radius_lo = 0.1  # Lower bound for ray radii\n  radius_hi = 0.5  # Upper bound for ray radii\n  near_lo = 1.0  # Lower bound for near plane\n  near_hi = 3.0  # Upper bound for near plane\n  far_lo = 4.0  # Lower bound for far plane\n  far_hi = 6.0  # Upper bound for far plane\n\n  # Generate random rays based on the input conditions\n  random_rays = generate_random_rays(\n      rng,\n      n,\n      origin_lo,\n      origin_hi,\n      radius_lo,\n      radius_hi,\n      near_lo,\n      near_hi,\n      far_lo,\n      far_hi,\n      include_exposure_idx,\n      include_exposure_values,\n      include_device_idx,\n  )\n\n  return random_rays"}
{"namespace": "utils.dummy_rays", "completion": "    # Define the parameters for generating random rays\n    rng = jax.random.PRNGKey(0)\n    n = 100  # Number of rays\n    origin_lo = -1.0\n    origin_hi = 1.0\n    radius_lo = 0.1\n    radius_hi = 0.5\n    near_lo = 0.1\n    near_hi = 1.0\n    far_lo = 3.0\n    far_hi = 5.0\n\n    # Generate random rays using the predefined function\n    random_rays = generate_random_rays(\n        rng,\n        n,\n        origin_lo,\n        origin_hi,\n        radius_lo,\n        radius_hi,\n        near_lo,\n        near_hi,\n        far_lo,\n        far_hi,\n        include_exposure_idx,\n        include_exposure_values,\n        include_device_idx,\n    )\n\n    return random_rays"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=random.PRNGKey(0),\n      n=100,  # Specify the number of rays to generate\n      origin_lo=-1.0,\n      origin_hi=1.0,\n      radius_lo=0.1,\n      radius_hi=0.5,\n      near_lo=0.1,\n      near_hi=0.5,\n      far_lo=2.0,\n      far_hi=5.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )"}
{"namespace": "utils.dummy_rays", "completion": "  # Set the parameters for generating random rays\n  rng = jax.random.PRNGKey(0)\n  n = 100  # Number of rays\n  origin_lo = -1.0\n  origin_hi = 1.0\n  radius_lo = 0.1\n  radius_hi = 0.5\n  near_lo = 0.1\n  near_hi = 1.0\n  far_lo = 3.0\n  far_hi = 5.0\n\n  # Generate random rays using the predefined function\n  random_rays = generate_random_rays(\n      rng,\n      n,\n      origin_lo,\n      origin_hi,\n      radius_lo,\n      radius_hi,\n      near_lo,\n      near_hi,\n      far_lo,\n      far_hi,\n      include_exposure_idx,\n      include_exposure_values,\n      include_device_idx,\n  )\n\n  return random_rays"}
{"namespace": "utils.dummy_rays", "completion": "  rng = jax.random.PRNGKey(0)  # Define a random key\n  n = 1000  # Number of rays to generate\n  origin_lo = -1.0  # Minimum value for ray origins\n  origin_hi = 1.0  # Maximum value for ray origins\n  radius_lo = 0.1  # Minimum value for ray radii\n  radius_hi = 0.5  # Maximum value for ray radii\n  near_lo = 0.1  # Minimum value for near plane\n  near_hi = 1.0  # Maximum value for near plane\n  far_lo = 3.0  # Minimum value for far plane\n  far_hi = 5.0  # Maximum value for far plane\n\n  # Generate random rays using the predefined function\n  random_rays = generate_random_rays(\n      rng,\n      n,\n      origin_lo,\n      origin_hi,\n      radius_lo,\n      radius_hi,\n      near_lo,\n      near_hi,\n      far_lo,\n      far_hi,\n      include_exposure_idx,\n      include_exposure_values,\n      include_device_idx,\n  )\n  return random_rays  # Return the generated random rays"}
{"namespace": "utils.dummy_rays", "completion": "  rng = jax.random.PRNGKey(0)  # Set a random key\n  n = 1000  # Number of rays to generate\n  origin_lo = 0  # Lower bound for ray origins\n  origin_hi = 1  # Upper bound for ray origins\n  radius_lo = 0.1  # Lower bound for ray radii\n  radius_hi = 0.5  # Upper bound for ray radii\n  near_lo = 0.1  # Lower bound for near plane\n  near_hi = 0.5  # Upper bound for near plane\n  far_lo = 0.5  # Lower bound for far plane\n  far_hi = 1.0  # Upper bound for far plane\n\n  # Generate random rays using the specified parameters and options\n  random_rays = generate_random_rays(\n      rng,\n      n,\n      origin_lo,\n      origin_hi,\n      radius_lo,\n      radius_hi,\n      near_lo,\n      near_hi,\n      far_lo,\n      far_hi,\n      include_exposure_idx,\n      include_exposure_values,\n      include_device_idx,\n  )\n\n  return random_rays  # Return the generated random rays"}
{"namespace": "utils.dummy_rays", "completion": "  rng = jax.random.PRNGKey(0)  # Set the random number generator key\n  n = 1000  # Number of random rays to generate\n  origin_lo = -1.0  # Lower bound for ray origins\n  origin_hi = 1.0  # Upper bound for ray origins\n  radius_lo = 0.1  # Lower bound for ray radii\n  radius_hi = 0.5  # Upper bound for ray radii\n  near_lo = 0.1  # Lower bound for near plane distance\n  near_hi = 1.0  # Upper bound for near plane distance\n  far_lo = 3.0  # Lower bound for far plane distance\n  far_hi = 5.0  # Upper bound for far plane distance\n\n  return generate_random_rays(\n      rng,\n      n,\n      origin_lo,\n      origin_hi,\n      radius_lo,\n      radius_hi,\n      near_lo,\n      near_hi,\n      far_lo,\n      far_hi,\n      include_exposure_idx,\n      include_exposure_values,\n      include_device_idx,\n  )"}
{"namespace": "utils.dummy_rays", "completion": "  rng = jax.random.PRNGKey(0)\n  n = 100  # Number of random rays to generate\n  origin_lo = -1.0\n  origin_hi = 1.0\n  radius_lo = 0.1\n  radius_hi = 0.5\n  near_lo = 0.1\n  near_hi = 1.0\n  far_lo = 3.0\n  far_hi = 5.0\n\n  return generate_random_rays(\n      rng,\n      n,\n      origin_lo,\n      origin_hi,\n      radius_lo,\n      radius_hi,\n      near_lo,\n      near_hi,\n      far_lo,\n      far_hi,\n      include_exposure_idx,\n      include_exposure_values,\n      include_device_idx,\n  )"}
{"namespace": "utils.dummy_rays", "completion": "  rng = jax.random.PRNGKey(0)  # Set the random number generator key\n  n = 1000  # Number of rays to generate\n  origin_lo = -1.0  # Lower bound for ray origins\n  origin_hi = 1.0  # Upper bound for ray origins\n  radius_lo = 0.1  # Lower bound for ray radii\n  radius_hi = 0.5  # Upper bound for ray radii\n  near_lo = 0.1  # Lower bound for near plane\n  near_hi = 1.0  # Upper bound for near plane\n  far_lo = 3.0  # Lower bound for far plane\n  far_hi = 5.0  # Upper bound for far plane\n\n  # Generate random rays using the specified parameters and options\n  random_rays = generate_random_rays(\n      rng,\n      n,\n      origin_lo,\n      origin_hi,\n      radius_lo,\n      radius_hi,\n      near_lo,\n      near_hi,\n      far_lo,\n      far_hi,\n      include_exposure_idx,\n      include_exposure_values,\n      include_device_idx,\n  )\n\n  return random_rays  # Return the generated random rays"}
{"namespace": "camera_utils.points_to_pixels", "completion": "\n  # Calculate the 2D pixel coordinates and depth values from the 3D point coordinates.\n  # ...\n\n  return coordinates, depth"}
{"namespace": "camera_utils.points_to_pixels", "completion": "\n  # Calculate the camera-space coordinates of the input points.\n  cam_points = camtoworlds @ points\n\n  # Project the camera-space coordinates onto the image plane.\n  pix_coords, depth = pixels_to_rays(\n      cam_points[Ellipsis, 0],\n      cam_points[Ellipsis, 1],\n      pixtocams,\n      camtoworlds,\n      distortion_params=distortion_params,\n      camtype=camtype,\n      xnp=xnp,\n  )\n\n  # Convert the pixel coordinates to image plane coordinates.\n  image_plane_coords = pix_coords[Ellipsis, :2]\n\n  return image_plane_coords, depth"}
{"namespace": "camera_utils.points_to_pixels", "completion": "\n  # Convert 3D points to homogeneous coordinates\n  points_homogeneous = xnp.concatenate([points, xnp.ones((points.shape[0], 1))], axis=1)\n\n  # Project 3D points to 2D pixel coordinates\n  projected_points = xnp.matmul(pixtocams, xnp.matmul(camtoworlds, points_homogeneous.T)).T\n  projected_points = projected_points / projected_points[:, 2][:, None]\n\n  # Apply distortion correction if distortion parameters are provided\n  if distortion_params is not None:\n    k1 = distortion_params.get('k1', 0)\n    k2 = distortion_params.get('k2', 0)\n    k3 = distortion_params.get('k3', 0)\n    k4 = distortion_params.get('k4', 0)\n    p1 = distortion_params.get('p1', 0)\n    p2 = distortion_params.get('p2', 0)\n\n    x = projected_points[:, 0]\n    y = projected_points[:, 1]\n\n    # Correct for radial and tangential distortion\n    r2 = x ** 2 + y ** 2\n    x_radial = x * (1 + k1 * r2 + k2 * r2 ** 2 + k3 * r2 ** 3 + k4 * r2 ** 4) + 2 * p1 * x * y + p2 * (r2 + 2 * x ** 2)\n    y_radial = y * (1 + k1 * r2 + k2 * r2 ** 2 + k3 * r2 ** 3 + k4 * r2 ** 4) + p1 * (r2 + 2 * y ** 2) + 2 * p2 * x * y\n\n    # Update the projected points with the distortion correction\n    projected_points[:, 0] = x_radial\n    projected_points[:, 1] = y_radial\n\n  # Extract the 2D pixel coordinates and depth values\n  coordinates = projected_points[:, :2]\n  depth = projected_points[:, 2]\n\n  return coordinates, depth"}
{"namespace": "camera_utils.points_to_pixels", "completion": "\n  # Convert points to homogeneous coordinates\n  points_homogeneous = xnp.concatenate([points, xnp.ones((points.shape[0], 1))], axis=1)\n\n  # Project points to camera coordinates\n  points_camera = xnp.einsum('...ij,...j->...i', pixtocams, points_homogeneous)\n\n  # Apply camera extrinsics to get points in world coordinates\n  points_world = xnp.einsum('...ij,...j->...i', camtoworlds[:, :3, :3], points_camera) + camtoworlds[:, :3, 3]\n\n  # Apply distortion correction if distortion parameters are provided\n  if distortion_params is not None:\n    # Apply radial and tangential distortion correction\n    x, y = _radial_and_tangential_distort(\n        points_world[..., 0],\n        points_world[..., 1],\n        **distortion_params,\n    )\n    points_world = xnp.stack([x, y, points_world[..., 2]], axis=-1)\n\n  # Project 3D points to 2D pixel coordinates\n  origins, directions, _, _, _ = pixels_to_rays(\n      xnp.zeros_like(points_world[..., 0]),\n      xnp.zeros_like(points_world[..., 1]),\n      pixtocams,\n      camtoworlds,\n      distortion_params,\n      camtype,\n      xnp,\n  )\n\n  # Calculate intersection of rays with the 3D points\n  t = (points_world[..., 2] - origins[..., 2]) / directions[..., 2]\n  coordinates = origins[..., :2] + t[..., None] * directions[..., :2]\n\n  return coordinates, t"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Calculate the camera space coordinates of the input points.\n  camera_coords = camtoworlds @ points\n\n  # Project the camera space coordinates onto the image plane.\n  if distortion_params is not None:\n    # Apply distortion correction.\n    x, y = _radial_and_tangential_distort(\n        camera_coords[0] / camera_coords[2],\n        camera_coords[1] / camera_coords[2],\n        **distortion_params,\n    )\n    projected_coords = np.stack([x, y], axis=-1)\n  else:\n    # Apply perspective projection.\n    projected_coords = pixtocams @ (camera_coords / camera_coords[2, None])\n\n  # Extract the x and y pixel coordinates.\n  pixel_x = projected_coords[0]\n  pixel_y = projected_coords[1]\n\n  # Calculate the depth values in the camera coordinate system.\n  depth = camera_coords[2]\n\n  return (pixel_x, pixel_y), depth"}
{"namespace": "camera_utils.points_to_pixels", "completion": "\n  # Calculate the camera ray origins and directions\n  origins, directions, _, _, _ = pixels_to_rays(\n      points[Ellipsis, 0],\n      points[Ellipsis, 1],\n      pixtocams,\n      camtoworlds,\n      distortion_params,\n      camtype,\n      xnp,\n  )\n\n  # Calculate the depth values\n  depth = -origins[..., 2] / directions[..., 2]\n\n  # Convert the ray origins to pixel coordinates\n  coordinates = origins[..., :2] / origins[..., 2, None]\n\n  return coordinates, depth"}
{"namespace": "camera_utils.points_to_pixels", "completion": "\n  # Calculate the camera space coordinates of the input points.\n  cam_points = camtoworlds @ points\n\n  # Project the camera space coordinates onto the image plane.\n  origins, directions, viewdirs, radii, imageplane = pixels_to_rays(\n      cam_points[Ellipsis, 0],\n      cam_points[Ellipsis, 1],\n      pixtocams,\n      camtoworlds,\n      distortion_params,\n      camtype,\n      xnp,\n  )\n\n  # Calculate the depth values of the points in the camera coordinate system.\n  depth = -cam_points[Ellipsis, 2]\n\n  # Convert the image plane coordinates to pixel coordinates.\n  pixel_x = (imageplane[Ellipsis, 0] * pixtocams[0, 0] + pixtocams[0, 2]).astype(int)\n  pixel_y = (imageplane[Ellipsis, 1] * pixtocams[1, 1] + pixtocams[1, 2]).astype(int)\n\n  # Return the pixel coordinates and depth values.\n  return (pixel_x, pixel_y), depth"}
{"namespace": "camera_utils.points_to_pixels", "completion": "\n  # Convert 3D points to homogeneous coordinates.\n  points_homogeneous = xnp.concatenate([points, xnp.ones((points.shape[0], 1))], axis=1)\n\n  # Project the 3D points to 2D pixel coordinates using the camera intrinsics and extrinsics.\n  projected_points = xnp.matmul(pixtocams, xnp.matmul(camtoworlds, points_homogeneous.T)).T\n\n  # Normalize the 2D pixel coordinates by dividing by the third coordinate (depth).\n  coordinates = projected_points[:, :2] / projected_points[:, 2][:, None]\n\n  # If distortion parameters are provided, correct for radial and tangential distortion.\n  if distortion_params is not None:\n    k1 = distortion_params.get('k1', 0)\n    k2 = distortion_params.get('k2', 0)\n    k3 = distortion_params.get('k3', 0)\n    k4 = distortion_params.get('k4', 0)\n    p1 = distortion_params.get('p1', 0)\n    p2 = distortion_params.get('p2', 0)\n\n    # Apply distortion correction to the 2D pixel coordinates.\n    coordinates = _radial_and_tangential_distort(\n        coordinates[:, 0],\n        coordinates[:, 1],\n        k1=k1,\n        k2=k2,\n        k3=k3,\n        k4=k4,\n        p1=p1,\n        p2=p2,\n    )\n\n  # Extract the depth values from the third coordinate of the projected points.\n  depth = projected_points[:, 2]\n\n  return coordinates, depth"}
{"namespace": "camera_utils.points_to_pixels", "completion": "\n  # Apply camera extrinsics to points.\n  cam_points = camtoworlds @ points[..., None]\n  cam_points = cam_points[..., :3, 0]\n\n  # Project 3D points to 2D pixel coordinates.\n  pixel_coords, _ = convert_to_ndc(cam_points, pixtocams, xnp=xnp)\n\n  # Apply distortion correction if distortion parameters are provided.\n  if distortion_params is not None:\n    # Apply radial and tangential distortion correction.\n    x, y = _radial_and_tangential_distort(\n        pixel_coords[..., 0],\n        pixel_coords[..., 1],\n        **distortion_params,\n    )\n    pixel_coords = xnp.stack([x, y], axis=-1)\n\n  # Extract depth values of the points in the camera coordinate system.\n  depth = cam_points[..., 2]\n\n  return pixel_coords, depth"}
{"namespace": "camera_utils.points_to_pixels", "completion": "\n  # Calculate the camera-space coordinates of the input points.\n  camera_points = camtoworlds @ points\n\n  # Project the camera-space coordinates onto the image plane.\n  origins, directions, _, _, _ = pixels_to_rays(\n      camera_points[Ellipsis, 0],\n      camera_points[Ellipsis, 1],\n      pixtocams,\n      camtoworlds,\n      distortion_params,\n      camtype,\n      xnp,\n  )\n\n  # Calculate the depth values of the points in the camera coordinate system.\n  depth = -camera_points[Ellipsis, 2]\n\n  # Convert the projected origins to pixel coordinates.\n  coordinates = origins @ pixtocams[Ellipsis, :2, :2] + pixtocams[Ellipsis, :2, 2]\n\n  return coordinates, depth"}
{"namespace": "camera_utils.points_to_pixels", "completion": "\n  # Calculate the camera space coordinates of the input points.\n  cam_points = camtoworlds @ points\n\n  # Project the camera space coordinates onto the image plane.\n  origins, directions, _, _, _ = pixels_to_rays(\n      cam_points[Ellipsis, 0],\n      cam_points[Ellipsis, 1],\n      pixtocams,\n      camtoworlds,\n      distortion_params,\n      camtype,\n      xnp,\n  )\n\n  # Calculate the intersection of the rays with the image plane to get the pixel coordinates.\n  t = -origins[Ellipsis, 2] / directions[Ellipsis, 2]\n  pixel_x = origins[Ellipsis, 0] + t * directions[Ellipsis, 0]\n  pixel_y = origins[Ellipsis, 1] + t * directions[Ellipsis, 1]\n\n  # Depth values are the negative of the z-coordinates of the camera space points.\n  depth = -cam_points[Ellipsis, 2]\n\n  return (xnp.stack([pixel_x, pixel_y], axis=-1), depth)"}
{"namespace": "camera_utils.points_to_pixels", "completion": "\n  # Calculate the homogeneous coordinates of the 3D points\n  points_hom = xnp.concatenate([points, xnp.ones((points.shape[0], 1))], axis=1)\n\n  # Project the 3D points to 2D pixel coordinates\n  projected_points = xnp.matmul(points_hom, camtoworlds.T)\n  pixel_coords_hom = xnp.matmul(projected_points, pixtocams.T)\n\n  # Normalize the pixel coordinates by the third component to obtain 2D pixel coordinates\n  pixel_coords = pixel_coords_hom[:, :2] / pixel_coords_hom[:, 2:3]\n\n  # Calculate the depth values of the points in the camera coordinate system\n  depth = xnp.linalg.norm(projected_points[:, :3], axis=1)\n\n  return pixel_coords, depth"}
{"namespace": "camera_utils.points_to_pixels", "completion": "\n  # Calculate the camera space coordinates of the 3D points.\n  camera_points = camtoworlds @ points[..., None]\n  camera_points = camera_points[..., :3, 0]\n\n  # Project the camera space coordinates to pixel coordinates.\n  pix_x, pix_y, depth = jaxcam.project(\n      camera_points, pixtocams, distortion_params, camtype, xnp\n  )\n\n  # Return the pixel coordinates and depth values.\n  return (pix_x, pix_y), depth"}
{"namespace": "camera_utils.points_to_pixels", "completion": "\n  # Project 3D points to 2D pixel coordinates\n  # using camera intrinsics and extrinsics\n  origins = camtoworlds @ points\n  directions = points - origins\n\n  # Apply inverse intrinsic matrices\n  pixel_coords = pixtocams @ (origins / directions[..., None])\n\n  # Correct for distortion if distortion parameters are provided\n  if distortion_params is not None:\n    # Extract x and y coordinates\n    x = pixel_coords[..., 0]\n    y = pixel_coords[..., 1]\n    # Apply radial and tangential distortion correction\n    x, y = _radial_and_tangential_distort(x, y, **distortion_params)\n    # Update the pixel coordinates\n    pixel_coords = xnp.stack([x, y], axis=-1)\n\n  # Extract the depth values\n  depth = xnp.linalg.norm(origins, axis=-1)\n\n  return pixel_coords, depth"}
{"namespace": "camera_utils.points_to_pixels", "completion": "\n  # Calculate the pixel coordinates and depth values using the provided parameters\n  # ... (add the implementation here)\n\n  return coordinates, depth  # Return the computed pixel coordinates and depth values"}
{"namespace": "camera_utils.points_to_pixels", "completion": "\n  # Project 3D points to 2D pixel coordinates and depth values\n  camera_points = camtoworlds @ points\n  pix_coords, _, _, _ = pixels_to_rays(\n      camera_points[0], camera_points[1], pixtocams, camtoworlds, distortion_params, camtype, xnp\n  )\n  depth = camera_points[2]\n\n  return pix_coords, depth"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Calculate the 2D pixel coordinates and depth values from the 3D point coordinates\n  camera_points = camtoworlds @ points\n  pix_coords = pixtocams @ camera_points\n  pix_coords /= pix_coords[..., 2:3]  # Normalize by the depth value\n  coordinates = pix_coords[..., :2]  # Extract the 2D pixel coordinates\n  depth = camera_points[..., 2]  # Extract the depth values\n  return coordinates, depth"}
{"namespace": "camera_utils.points_to_pixels", "completion": "\n  # Compute the 2D pixel coordinates and depth values\n  camera_points = camtoworlds @ points\n  camera_origins = camtoworlds[:, :3, 3]\n  ray_directions = camera_points - camera_origins\n  ray_directions = ray_directions / xnp.linalg.norm(ray_directions, axis=-1, keepdims=True)\n\n  if distortion_params is not None:\n    # Apply radial and tangential distortion\n    x, y = _radial_and_tangential_distort(\n        ray_directions[:, 0] / ray_directions[:, 2],\n        ray_directions[:, 1] / ray_directions[:, 2],\n        **distortion_params\n    )\n    ray_directions = xnp.stack([x, y, xnp.ones_like(x)], axis=-1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.arccos(ray_directions[:, 2])\n    phi = xnp.arctan2(ray_directions[:, 1], ray_directions[:, 0])\n    ray_directions = xnp.stack(\n        [\n            xnp.sin(theta) * xnp.cos(phi),\n            xnp.sin(theta) * xnp.sin(phi),\n            xnp.cos(theta),\n        ],\n        axis=-1,\n    )\n\n  elif camtype == ProjectionType.PANORAMIC:\n    theta = xnp.arctan2(ray_directions[:, 0], -ray_directions[:, 2])\n    phi = xnp.arcsin(ray_directions[:, 1])\n    ray_directions = xnp.stack(\n        [\n            theta / xnp.pi,\n            phi / (0.5 * xnp.pi),\n            xnp.ones_like(theta),\n        ],\n        axis=-1,\n    )\n\n  # Project the 3D points onto the image plane\n  projected_points = pixtocams @ ray_directions.T\n  projected_points = projected_points / projected_points[2]\n  coordinates = projected_points[:2].T\n\n  # Compute the depth values\n  depth = xnp.linalg.norm(points - camera_origins, axis=-1)\n\n  return coordinates, depth"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Calculate camera space coordinates.\n  camera_points = camtoworlds @ points[..., None]\n  camera_points = camera_points[..., :3, 0]\n\n  # Project camera space coordinates to pixel space.\n  pixel_coords = pixtocams @ camera_points.T\n  pixel_coords = pixel_coords[:2] / pixel_coords[2]\n\n  # Apply distortion correction if distortion parameters are provided.\n  if distortion_params is not None:\n    k1, k2, k3, k4, p1, p2 = distortion_params['k1'], distortion_params['k2'], distortion_params['k3'], distortion_params['k4'], distortion_params['p1'], distortion_params['p2']\n    x, y = pixel_coords\n    r2 = x**2 + y**2\n    x_distorted = x * (1 + k1 * r2 + k2 * r2**2 + k3 * r2**3 + k4 * r2**4) + 2 * p1 * x * y + p2 * (r2 + 2 * x**2)\n    y_distorted = y * (1 + k1 * r2 + k2 * r2**2 + k3 * r2**3 + k4 * r2**4) + p1 * (r2 + 2 * y**2) + 2 * p2 * x * y\n    pixel_coords = np.array([x_distorted, y_distorted])\n\n  # Calculate depth values in camera space.\n  depth = camera_points[..., 2]\n\n  return pixel_coords.T, depth"}
{"namespace": "camera_utils.points_to_pixels", "completion": "\n  # Calculate the pixel coordinates and depth values\n  pix_x, pix_y, depth = jaxcam.project_points(\n      points, pixtocams, camtoworlds, distortion_params=distortion_params, camtype=camtype, xnp=xnp\n  )\n\n  # Return the pixel coordinates and depth values\n  return (pix_x, pix_y, depth)"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    results = []\n\n    for module, params in zip(modules, module_params):\n        logger.info(f\"Running query expansion module: {module.__name__}\")\n        result = module(previous_result, **params)\n        results.append(result)\n\n    # Measure execution times\n    execution_times = measure_speed(results)\n\n    # Filter results by speed threshold\n    results = filter_by_threshold(results, execution_times, strategies['speed_threshold'])\n\n    # Evaluate and select the best result\n    best_result = select_best_average(results, strategies['evaluation_metrics'])\n\n    # Save results and summary to the specified directory\n    result_dir = os.path.join(node_line_dir, \"query_expansion_results\")\n    pathlib.Path(result_dir).mkdir(parents=True, exist_ok=True)\n\n    for idx, result in enumerate(results):\n        result.to_csv(os.path.join(result_dir, f\"result_{idx}.csv\"), index=False)\n\n    summary = pd.DataFrame({\n        \"Module\": [module.__name__ for module in modules],\n        \"Execution Time\": execution_times,\n        \"Evaluation Metrics\": [result['evaluation_metric'] for result in results]\n    })\n    summary.to_csv(os.path.join(node_line_dir, \"query_expansion_summary.csv\"), index=False)\n\n    # Save the best result\n    best_result.to_csv(os.path.join(node_line_dir, \"best_query_expansion_result.csv\"), index=False)\n\n    return best_result"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Initialize variables to store the results and execution times\n    results = []\n    execution_times = []\n\n    # Iterate through each module and its parameters\n    for module, params in zip(modules, module_params):\n        # Make a deep copy of the previous result to avoid modifying the original dataframe\n        expanded_result = deepcopy(previous_result)\n\n        # Execute the query expansion module with the specified parameters\n        expanded_result = module(expanded_result, **params)\n\n        # Measure the execution time of the module\n        time_taken = measure_speed(module, expanded_result, **params)\n\n        # Evaluate the performance of the expanded result based on the specified strategies\n        evaluated_result = evaluate_retrieval_node(expanded_result, strategies)\n\n        # Append the evaluated result and execution time to the respective lists\n        results.append(evaluated_result)\n        execution_times.append(time_taken)\n\n    # Select the best result based on the specified strategies\n    best_result = select_best_average(results, strategies)\n\n    # Save the results and summary to the specified directory\n    save_results_and_summary(results, execution_times, node_line_dir)\n\n    return best_result"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    support_modules = get_support_modules(modules, \"query_expansion\")\n\n    results = []\n    execution_times = []\n\n    for i, module in enumerate(support_modules):\n        params = module_params[i]\n        logger.info(f\"Running query expansion module: {module.__name__}\")\n        result, time = measure_speed(module, params, previous_result)\n        results.append(result)\n        execution_times.append((module.__name__, time))\n\n    results_df = pd.concat(results, axis=1)\n\n    summary = pd.DataFrame(execution_times, columns=[\"Module\", \"Execution Time\"])\n    summary.to_csv(os.path.join(node_line_dir, \"query_expansion_summary.csv\"), index=False)\n\n    filtered_results = filter_by_threshold(results_df, strategies[\"speed_threshold\"])\n    best_result = select_best_average(filtered_results, strategies[\"evaluation_metric\"])\n\n    best_result.to_csv(os.path.join(node_line_dir, \"best_query_expansion_result.csv\"), index=False)\n\n    return best_result"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Initialize variables to store results and execution times\n    results = []\n    execution_times = []\n\n    # Iterate through each module and its parameters\n    for module, params in zip(modules, module_params):\n        # Deep copy the previous result to avoid modifying the original dataframe\n        expanded_query = deepcopy(previous_result)\n\n        # Execute the query expansion module and measure execution time\n        with measure_speed() as speed:\n            expanded_query = module(expanded_query, **params)\n\n        # Append the execution time to the list\n        execution_times.append((module.__name__, speed()))\n\n        # Evaluate the query expansion module using the retrieval node\n        evaluated_result = evaluate_retrieval_node(expanded_query)\n\n        # Append the evaluated result to the list\n        results.append((module.__name__, evaluated_result))\n\n    # Save the execution times to a file in the specified directory\n    execution_times_df = pd.DataFrame(execution_times, columns=[\"Module\", \"Execution Time\"])\n    execution_times_df.to_csv(os.path.join(node_line_dir, \"execution_times.csv\"), index=False)\n\n    # Apply strategies to select the best query expansion module\n    selected_result = select_best_average(results, strategies)\n\n    # Save the selected result to a file in the specified directory\n    selected_result.to_csv(os.path.join(node_line_dir, \"selected_result.csv\"), index=False)\n\n    return selected_result"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    results = []\n    speed_results = []\n    \n    for i, module in enumerate(modules):\n        module_name = module.__name__\n        logger.info(f\"Running query expansion module: {module_name}\")\n        \n        # Run the module with specified parameters\n        expanded_results = module(previous_result, **module_params[i])\n        \n        # Measure the speed of the module\n        speed = measure_speed(module, previous_result, **module_params[i])\n        speed_results.append((module_name, speed))\n        \n        # Evaluate the module results based on specified strategies\n        evaluated_results = evaluate_retrieval_node(expanded_results, strategies)\n        \n        # Save the results to the directory\n        result_file = os.path.join(node_line_dir, f\"{module_name}_results.csv\")\n        evaluated_results.to_csv(result_file, index=False)\n        results.append((module_name, result_file))\n    \n    # Select the best module based on the evaluation metrics and speed\n    best_module = select_best_average(results, speed_results, strategies)\n    \n    # Load the best module results\n    best_result = pd.read_csv(best_module[1])\n    \n    # Save the summary of execution times and evaluation metrics\n    summary_file = os.path.join(node_line_dir, \"summary.csv\")\n    summary_data = pd.DataFrame(speed_results, columns=[\"Module\", \"Execution Time\"])\n    summary_data.to_csv(summary_file, index=False)\n    \n    logger.info(f\"Selected best query expansion module: {best_module[0]}\")\n    \n    return best_result"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    support_modules = get_support_modules(modules, module_params, previous_result)\n    results = evaluate_retrieval_node(support_modules, previous_result)\n\n    execution_times = measure_speed(support_modules, results)\n    filtered_results = filter_by_threshold(results, strategies)\n\n    best_result = select_best_average(filtered_results, strategies)\n\n    summary = {\n        \"execution_times\": execution_times,\n        \"filtered_results\": filtered_results,\n        \"best_result\": best_result\n    }\n\n    os.makedirs(node_line_dir, exist_ok=True)\n\n    summary_path = os.path.join(node_line_dir, \"query_expansion_summary.json\")\n    with open(summary_path, \"w\") as f:\n        json.dump(summary, f)\n\n    best_result_path = os.path.join(node_line_dir, \"best_query_expansion_result.csv\")\n    best_result.to_csv(best_result_path, index=False)\n\n    return best_result"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Initialize variables to store the results and execution times\n    results = []\n    execution_times = []\n\n    # Loop through each module and its parameters\n    for i, (module, params) in enumerate(zip(modules, module_params)):\n        logger.info(f\"Running query expansion module {i + 1}/{len(modules)}\")\n\n        # Make a deep copy of the previous result to avoid modifying the original dataframe\n        expanded_result = deepcopy(previous_result)\n\n        # Execute the query expansion module with the specified parameters\n        expanded_result = module(expanded_result, **params)\n\n        # Measure the execution time of the module\n        time_taken = measure_speed(module, expanded_result, **params)\n        execution_times.append((i, time_taken))\n\n        # Evaluate the performance of the expanded result using the specified strategies\n        evaluated_result = evaluate_retrieval_node(expanded_result, strategies)\n\n        # Store the evaluated result\n        results.append(evaluated_result)\n\n    # Combine the execution times into a dataframe\n    execution_times_df = pd.DataFrame(execution_times, columns=[\"module_index\", \"execution_time\"])\n\n    # Save the results and execution times to the specified directory\n    results_df = pd.concat(results, ignore_index=True)\n    results_df.to_csv(os.path.join(node_line_dir, \"query_expansion_results.csv\"), index=False)\n    execution_times_df.to_csv(os.path.join(node_line_dir, \"query_expansion_execution_times.csv\"), index=False)\n\n    # Select the best result based on the specified strategies\n    best_result = select_best_average(results, strategies)\n\n    # Save the best result to the specified directory\n    best_result.to_csv(os.path.join(node_line_dir, \"best_query_expansion_result.csv\"), index=False)\n\n    return best_result"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    results = []\n\n    for module, params in zip(modules, module_params):\n        logger.info(f\"Running query expansion module: {module.__name__}\")\n        result = module(previous_result, **params)\n        results.append(result)\n\n    # Measure execution times\n    execution_times = measure_speed(results)\n\n    # Apply strategies\n    filtered_results = filter_by_threshold(results, strategies['speed_threshold'])\n    best_result = select_best_average(filtered_results, strategies['evaluation_metric'])\n\n    # Save results and summary\n    result_summary = pd.DataFrame({'module': [module.__name__ for module in modules],\n                                   'execution_time': execution_times,\n                                   'evaluation_metric': [evaluate_retrieval_node(result) for result in results]})\n    result_summary.to_csv(os.path.join(node_line_dir, 'query_expansion_summary.csv'), index=False)\n\n    best_result.to_csv(os.path.join(node_line_dir, 'best_query_expansion_result.csv'), index=False)\n\n    return best_result"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Initialize variables to store the results and execution times\n    results = []\n    execution_times = []\n\n    # Iterate through each module and its parameters\n    for module, params in zip(modules, module_params):\n        # Make a deep copy of the previous result to avoid modifying it\n        expanded_result = deepcopy(previous_result)\n\n        # Execute the query expansion module with the specified parameters\n        expanded_result = module(expanded_result, **params)\n\n        # Measure the execution time of the module\n        time_taken = measure_speed(module, expanded_result, **params)\n        execution_times.append((module.__name__, time_taken))\n\n        # Evaluate the performance of the expanded result based on the specified strategies\n        evaluated_result = evaluate_retrieval_node(expanded_result, strategies)\n\n        # Add the evaluated result to the list of results\n        results.append((module.__name__, evaluated_result))\n\n    # Select the best result based on the evaluation strategies\n    best_result = select_best_average(results, strategies)\n\n    # Save the results and summaries to the specified directory\n    save_results_and_summaries(results, execution_times, node_line_dir)\n\n    return best_result"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Initialize variables to store the results and execution times\n    results = []\n    execution_times = []\n\n    # Loop through each module and its parameters\n    for module, params in zip(modules, module_params):\n        # Deep copy the previous result to avoid modifying the original dataframe\n        expanded_query = deepcopy(previous_result)\n\n        # Execute the query expansion module with the specified parameters\n        expanded_query = module(expanded_query, **params)\n\n        # Measure the execution time of the query expansion module\n        execution_time = measure_speed(module, expanded_query, **params)\n\n        # Evaluate the performance of the expanded query based on the specified strategies\n        evaluated_result = evaluate_retrieval_node(expanded_query, strategies)\n\n        # Append the evaluated result and execution time to the respective lists\n        results.append(evaluated_result)\n        execution_times.append(execution_time)\n\n    # Combine the results and execution times into a single dataframe\n    combined_results = pd.concat(results, ignore_index=True)\n    combined_execution_times = pd.DataFrame(execution_times, columns=[\"Execution Time\"])\n\n    # Save the combined results and execution times to the specified directory\n    results_file_path = os.path.join(node_line_dir, \"query_expansion_results.csv\")\n    execution_times_file_path = os.path.join(node_line_dir, \"query_expansion_execution_times.csv\")\n    combined_results.to_csv(results_file_path, index=False)\n    combined_execution_times.to_csv(execution_times_file_path, index=False)\n\n    # Select the best result based on the specified strategies\n    best_result = select_best_average(combined_results, strategies)\n\n    # Save the best result to the specified directory\n    best_result_file_path = os.path.join(node_line_dir, \"best_query_expansion_result.csv\")\n    best_result.to_csv(best_result_file_path, index=False)\n\n    return best_result"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    support_modules = get_support_modules(modules)\n\n    result_summary = []\n    for module, params in zip(modules, module_params):\n        logger.info(f\"Running query expansion module: {module.__name__}\")\n        result = module(previous_result, **params)\n        result_summary.append((module.__name__, result))\n\n    result_summary_df = pd.DataFrame(result_summary, columns=[\"module\", \"result\"])\n\n    execution_times = measure_speed(result_summary_df[\"result\"])\n    logger.info(f\"Execution times for query expansion modules: {execution_times}\")\n\n    filtered_results = filter_by_threshold(result_summary_df, execution_times, strategies[\"speed_threshold\"])\n    logger.info(f\"Filtered results based on speed threshold: {filtered_results}\")\n\n    best_result = select_best_average(filtered_results, strategies[\"evaluation_metrics\"])\n    logger.info(f\"Selected best result based on evaluation metrics: {best_result}\")\n\n    best_module = filtered_results.loc[filtered_results[\"result\"] == best_result, \"module\"].values[0]\n    best_result_df = result_summary_df.loc[result_summary_df[\"module\"] == best_module, \"result\"].values[0]\n\n    result_path = os.path.join(node_line_dir, \"best_query_expansion_result.csv\")\n    best_result_df.to_csv(result_path, index=False)\n    logger.info(f\"Saved best query expansion result to: {result_path}\")\n\n    summary_path = os.path.join(node_line_dir, \"query_expansion_summary.csv\")\n    result_summary_df.to_csv(summary_path, index=False)\n    logger.info(f\"Saved query expansion summary to: {summary_path}\")\n\n    return best_result_df"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Initialize variables to store the results and execution times\n    results = []\n    execution_times = []\n\n    # Loop through each module and its parameters\n    for module, params in zip(modules, module_params):\n        # Deep copy the previous result to avoid modifying the original dataframe\n        expanded_result = deepcopy(previous_result)\n\n        # Execute the query expansion module with the specified parameters\n        expanded_result = module(expanded_result, **params)\n\n        # Measure the execution time of the module\n        execution_time = measure_speed(module, expanded_result, **params)\n\n        # Evaluate the performance of the expanded result based on the specified strategies\n        evaluated_result = evaluate_retrieval_node(expanded_result, strategies)\n\n        # Append the evaluated result and execution time to the lists\n        results.append(evaluated_result)\n        execution_times.append(execution_time)\n\n    # Combine the results and execution times into a single dataframe\n    result_df = pd.concat(results, axis=1)\n    execution_times_df = pd.DataFrame(execution_times, columns=[\"Execution Time\"])\n\n    # Save the results and execution times to the specified directory\n    result_df.to_csv(os.path.join(node_line_dir, \"query_expansion_results.csv\"), index=False)\n    execution_times_df.to_csv(os.path.join(node_line_dir, \"query_expansion_execution_times.csv\"), index=False)\n\n    # Select the best result based on the specified strategies\n    best_result = select_best_average(result_df, strategies)\n\n    # Save the best result to the specified directory\n    best_result.to_csv(os.path.join(node_line_dir, \"best_query_expansion_result.csv\"), index=False)\n\n    return best_result"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Initialize variables to store the results and execution times\n    results = []\n    execution_times = []\n\n    # Iterate over each module and its parameters\n    for module, params in zip(modules, module_params):\n        # Make a deep copy of the previous result to avoid modifying the original dataframe\n        expanded_result = deepcopy(previous_result)\n\n        # Apply the query expansion module to the previous result using the specified parameters\n        expanded_result = module(expanded_result, **params)\n\n        # Measure the execution time of the query expansion module\n        execution_time = measure_speed(module, expanded_result, **params)\n\n        # Evaluate the performance of the expanded result based on the specified strategies\n        evaluated_result = evaluate_retrieval_node(expanded_result, strategies)\n\n        # Store the evaluated result and execution time\n        results.append(evaluated_result)\n        execution_times.append(execution_time)\n\n    # Combine the results and execution times into a single dataframe\n    result_df = pd.concat(results, axis=1)\n    execution_time_df = pd.DataFrame(execution_times, columns=[\"execution_time\"])\n\n    # Save the results and execution times to the specified directory\n    result_df.to_csv(os.path.join(node_line_dir, \"query_expansion_results.csv\"), index=False)\n    execution_time_df.to_csv(os.path.join(node_line_dir, \"query_expansion_execution_times.csv\"), index=False)\n\n    # Select the best result based on the specified strategies\n    best_result = select_best_average(result_df, strategies)\n\n    # Save the best result to the specified directory\n    best_result.to_csv(os.path.join(node_line_dir, \"best_query_expansion_result.csv\"), index=False)\n\n    return best_result"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Initialize variables to store the results and execution times\n    results = []\n    execution_times = []\n\n    # Iterate through each module and its parameters\n    for module, params in zip(modules, module_params):\n        # Deep copy the previous result to avoid modifying the original dataframe\n        expanded_result = deepcopy(previous_result)\n\n        # Apply the query expansion module with the specified parameters\n        expanded_result = module(expanded_result, **params)\n\n        # Measure the execution time of the query expansion module\n        time_taken = measure_speed(module, expanded_result, **params)\n\n        # Filter the expanded result based on speed threshold\n        expanded_result = filter_by_threshold(expanded_result, time_taken, strategies['speed_threshold'])\n\n        # Evaluate the performance of the expanded result using the retrieval node\n        evaluation_result = evaluate_retrieval_node(expanded_result, strategies['evaluation_metrics'])\n\n        # Append the evaluation result and execution time to the respective lists\n        results.append(evaluation_result)\n        execution_times.append(time_taken)\n\n    # Select the best result based on the specified strategies\n    best_result = select_best_average(results, strategies['evaluation_metrics'])\n\n    # Save the results and summary to the specified directory\n    save_results_and_summary(results, execution_times, node_line_dir)\n\n    return best_result"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Initialize variables to store results and performance metrics\n    results = []\n    performance_metrics = []\n\n    # Loop through each module and its parameters\n    for i, (module, params) in enumerate(zip(modules, module_params)):\n        logger.info(f\"Running query expansion module {i+1}/{len(modules)}\")\n\n        # Make a deep copy of the previous result to avoid modifying the original dataframe\n        expanded_result = deepcopy(previous_result)\n\n        # Execute the query expansion module with the specified parameters\n        expanded_result = module(expanded_result, **params)\n\n        # Measure the execution time of the query expansion module\n        execution_time = measure_speed(module, expanded_result, **params)\n\n        # Evaluate the performance of the expanded result based on the specified strategies\n        evaluated_result = evaluate_retrieval_node(expanded_result, strategies)\n\n        # Store the results and performance metrics\n        results.append(evaluated_result)\n        performance_metrics.append({\n            \"module\": module.__name__,\n            \"execution_time\": execution_time,\n            \"evaluation_metrics\": evaluated_result,\n        })\n\n    # Combine the results from all modules into a single dataframe\n    combined_results = pd.concat(results)\n\n    # Select the best result based on the specified strategies\n    best_result = select_best_average(combined_results, strategies)\n\n    # Save the results and performance metrics to the specified directory\n    results_path = os.path.join(node_line_dir, \"query_expansion_results.csv\")\n    performance_metrics_path = os.path.join(node_line_dir, \"query_expansion_performance_metrics.csv\")\n\n    combined_results.to_csv(results_path, index=False)\n    pd.DataFrame(performance_metrics).to_csv(performance_metrics_path, index=False)\n\n    logger.info(f\"Query expansion results saved to {results_path}\")\n    logger.info(f\"Query expansion performance metrics saved to {performance_metrics_path}\")\n\n    return best_result"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    support_modules = get_support_modules()\n\n    results = []\n    for i, module in enumerate(modules):\n        params = module_params[i]\n        logger.info(f\"Running query expansion module: {module.__name__}\")\n        result = module(previous_result, **params)\n        result.to_csv(os.path.join(node_line_dir, f\"{module.__name__}_result.csv\"), index=False)\n        results.append(result)\n\n    execution_times = measure_speed(results)\n    execution_times.to_csv(os.path.join(node_line_dir, \"execution_times.csv\"), index=False)\n\n    filtered_results = filter_by_threshold(results, strategies['speed_threshold'])\n    selected_result = select_best_average(filtered_results, strategies['evaluation_metric'])\n    selected_result.to_csv(os.path.join(node_line_dir, \"selected_result.csv\"), index=False)\n\n    return selected_result"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Initialize variables to store results and execution times\n    results = []\n    execution_times = []\n\n    # Loop through each module and its parameters\n    for module, params in zip(modules, module_params):\n        # Make a deep copy of the previous result to avoid modifying the original dataframe\n        expanded_result = deepcopy(previous_result)\n\n        # Execute the query expansion module with the specified parameters\n        expanded_result = module(expanded_result, **params)\n\n        # Measure the execution time of the module\n        execution_time = measure_speed(module, expanded_result, **params)\n\n        # Evaluate the performance of the expanded result based on the specified strategies\n        evaluated_result = evaluate_retrieval_node(expanded_result, strategies)\n\n        # Store the evaluated result and its execution time\n        results.append(evaluated_result)\n        execution_times.append(execution_time)\n\n    # Combine the results and execution times into a single dataframe\n    result_df = pd.concat(results, ignore_index=True)\n    execution_times_df = pd.DataFrame(execution_times, columns=[\"Execution Time\"])\n\n    # Save the results and execution times to the specified directory\n    result_df.to_csv(os.path.join(node_line_dir, \"query_expansion_results.csv\"), index=False)\n    execution_times_df.to_csv(os.path.join(node_line_dir, \"query_expansion_execution_times.csv\"), index=False)\n\n    # Select the best result based on the specified strategies\n    best_result = select_best_average(result_df, strategies)\n\n    # Save the best result to the specified directory\n    best_result.to_csv(os.path.join(node_line_dir, \"best_query_expansion_result.csv\"), index=False)\n\n    return best_result"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    logger.info(\"Running query expansion node...\")\n\n    # Initialize variables to store results and execution times\n    results = []\n    execution_times = []\n\n    # Iterate over each module and its parameters\n    for module, params in zip(modules, module_params):\n        # Deep copy the previous result to avoid modifying the original dataframe\n        expanded_query = deepcopy(previous_result)\n\n        # Execute the query expansion module with the given parameters\n        expanded_query = module(expanded_query, **params)\n\n        # Measure the execution time of the module\n        time_taken = measure_speed(module, params, expanded_query)\n\n        # Evaluate the performance of the expanded query using the retrieval node\n        evaluation_result = evaluate_retrieval_node(expanded_query)\n\n        # Store the results and execution times\n        results.append((module.__name__, expanded_query, evaluation_result))\n        execution_times.append((module.__name__, time_taken))\n\n    # Apply strategies to select the best query expansion module\n    filtered_results = filter_by_threshold(results, strategies)\n    best_result = select_best_average(filtered_results, strategies)\n\n    # Save the results and summaries to the specified directory\n    save_path = os.path.join(node_line_dir, \"query_expansion_results.csv\")\n    summary_path = os.path.join(node_line_dir, \"query_expansion_summary.csv\")\n\n    # Save the best result to the specified directory\n    best_result_df = pd.DataFrame(best_result[1])\n    best_result_df.to_csv(save_path, index=False)\n\n    # Save the summary of execution times and evaluation metrics\n    summary_df = pd.DataFrame({\"Module\": [r[0] for r in results],\n                               \"Execution Time (s)\": [t[1] for t in execution_times],\n                               \"Evaluation Metrics\": [r[2] for r in results]})\n    summary_df.to_csv(summary_path, index=False)\n\n    logger.info(\"Query expansion node completed.\")\n\n    return best_result_df"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Initialize variables to store results and execution times\n    results = []\n    execution_times = []\n\n    # Iterate over each module and its parameters\n    for module, params in zip(modules, module_params):\n        # Make a deep copy of the previous result to avoid modifying the original dataframe\n        expanded_result = deepcopy(previous_result)\n\n        # Execute the query expansion module with the specified parameters\n        expanded_result = module(expanded_result, **params)\n\n        # Measure the execution time of the module\n        execution_time = measure_speed(module, params)\n\n        # Evaluate the performance of the expanded result based on the specified strategies\n        evaluated_result = evaluate_retrieval_node(expanded_result, strategies)\n\n        # Append the evaluated result and execution time to the respective lists\n        results.append(evaluated_result)\n        execution_times.append(execution_time)\n\n    # Combine the results and execution times into a single dataframe\n    result_df = pd.concat(results, ignore_index=True)\n    execution_times_df = pd.DataFrame(execution_times, columns=[\"execution_time\"])\n\n    # Combine the results dataframe with the execution times dataframe\n    result_df = pd.concat([result_df, execution_times_df], axis=1)\n\n    # Select the best result based on the specified strategies\n    best_result = select_best_average(result_df, strategies)\n\n    # Save the results and summary to the specified directory\n    result_df.to_csv(os.path.join(node_line_dir, \"query_expansion_results.csv\"), index=False)\n    best_result.to_csv(os.path.join(node_line_dir, \"best_query_expansion_result.csv\"), index=False)\n\n    return best_result"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    results = []\n    execution_times = []\n\n    for i, module in enumerate(modules):\n        params = module_params[i]\n        result, exec_time = evaluate_retrieval_node(module, params, previous_result)\n        results.append(result)\n        execution_times.append(exec_time)\n\n    # Measure speed\n    speed_measurements = measure_speed(execution_times)\n\n    # Filter by speed threshold\n    filtered_results = filter_by_threshold(results, speed_measurements, strategies['speed_threshold'])\n\n    # Select best average\n    best_result = select_best_average(filtered_results, strategies['evaluation_metric'])\n\n    # Save results and summary\n    result_summary = pd.DataFrame({'Module': modules, 'Execution Time': execution_times, 'Evaluation Metric': filtered_results})\n    result_summary.to_csv(os.path.join(node_line_dir, 'query_expansion_summary.csv'), index=False)\n\n    best_result.to_csv(os.path.join(node_line_dir, 'best_query_expansion_result.csv'), index=False)\n\n    return best_result"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Validate the input dataset\n    validate_qa_dataset(previous_result)\n\n    # Create necessary directories\n    os.makedirs(node_line_dir, exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, 'prompt_maker_output'), exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, 'summary'), exist_ok=True)\n\n    # Initialize variables for best prompt maker and evaluation metrics\n    best_prompt_maker = None\n    best_metrics = None\n    best_execution_time = float('inf')\n\n    # Iterate over prompt maker modules and their parameters\n    for i, (module, params) in enumerate(zip(modules, module_params)):\n        # Execute the prompt maker module\n        output_dir = os.path.join(node_line_dir, 'prompt_maker_output', f'prompt_maker_{i}')\n        os.makedirs(output_dir, exist_ok=True)\n        start_time = measure_speed()\n        prompt_maker_output = module(**params)\n        execution_time = measure_speed(start_time)\n\n        # Evaluate the prompt maker output\n        evaluation_result = evaluate_generation(prompt_maker_output, strategies.get('generator', None))\n\n        # Select the best prompt maker based on evaluation metrics and speed\n        if evaluate_generation is not None:\n            metrics = cast_metrics(evaluation_result)\n            if best_metrics is None or select_best_average(metrics, strategies.get('metrics', None)) > select_best_average(best_metrics, strategies.get('metrics', None)):\n                best_prompt_maker = prompt_maker_output\n                best_metrics = metrics\n                best_execution_time = execution_time\n\n        # Save the prompt maker output and evaluation summary\n        prompt_maker_output.to_csv(os.path.join(output_dir, 'prompt_maker_output.csv'), index=False)\n        evaluation_result.to_csv(os.path.join(output_dir, 'evaluation_summary.csv'), index=False)\n\n    # Combine the best prompt maker's output with the previous result\n    combined_result = pd.concat([previous_result, best_prompt_maker], axis=1)\n\n    # Save the combined result\n    combined_result.to_csv(os.path.join(node_line_dir, 'combined_result.csv'), index=False)\n\n    # Save the summary\n    summary = pd.DataFrame({'best_prompt_maker': [best_prompt_maker.__name__],\n                            'best_metrics': [best_metrics],\n                            'best_execution_time': [best_execution_time]})\n    summary.to_csv(os.path.join(node_line_dir, 'summary', 'summary.csv'), index=False)\n\n    return combined_result"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create necessary directories\n    os.makedirs(node_line_dir, exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, 'prompt_maker'), exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, 'summary'), exist_ok=True)\n\n    # Initialize variables\n    best_module_result = None\n    best_module_evaluation = None\n    best_module_execution_time = float('inf')\n\n    # Iterate through prompt maker modules and their parameters\n    for module, params in zip(modules, module_params):\n        # Execute prompt maker module\n        result, execution_time = module(**params)\n\n        # Evaluate the prompt maker module\n        evaluation = evaluate_generation(result, previous_result, **strategies)\n\n        # Check if the current prompt maker module is the best based on the strategies\n        if select_best_average(evaluation, **strategies) and measure_speed(execution_time, best_module_execution_time, **strategies):\n            best_module_result = result\n            best_module_evaluation = evaluation\n            best_module_execution_time = execution_time\n\n    # Save the best prompt maker's output and evaluation summary to the specified directory\n    best_module_result.to_csv(os.path.join(node_line_dir, 'prompt_maker', 'best_prompt_maker_output.csv'), index=False)\n    best_module_evaluation.to_csv(os.path.join(node_line_dir, 'summary', 'best_prompt_maker_evaluation.csv'), index=False)\n\n    # Combine the best prompt maker's output with the previous result\n    combined_result = pd.concat([previous_result, best_module_result], axis=1)\n\n    return combined_result"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create necessary directories\n    os.makedirs(node_line_dir, exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, \"results\"), exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, \"summary\"), exist_ok=True)\n\n    # Initialize variables for best prompt maker and its evaluation metrics\n    best_module = None\n    best_metrics = None\n    best_time = float('inf')\n\n    # Iterate through prompt maker modules and their parameters\n    for i, module in enumerate(modules):\n        params = module_params[i]\n\n        # Execute prompt maker module and measure its speed\n        result, time_taken = measure_speed(module, params)\n\n        # Evaluate the prompt maker module based on specified strategies\n        evaluation_metrics = evaluate_generation(result, previous_result, strategies)\n\n        # Check if the prompt maker module meets the speed threshold\n        if filter_by_threshold(time_taken, strategies.get('speed_threshold')):\n            # Select the best prompt maker module based on evaluation metrics\n            if best_metrics is None or select_best_average(evaluation_metrics, best_metrics):\n                best_module = module\n                best_metrics = evaluation_metrics\n                best_time = time_taken\n\n        # Save the results and evaluation metrics to the specified directory\n        result.to_csv(os.path.join(node_line_dir, \"results\", f\"result_{i}.csv\"), index=False)\n        pd.DataFrame(cast_metrics(evaluation_metrics)).to_csv(os.path.join(node_line_dir, \"results\", f\"evaluation_metrics_{i}.csv\"), index=False)\n\n    # Combine the results of the best prompt maker module with the previous result\n    combined_result = best_module(previous_result, module_params[modules.index(best_module)])\n    return combined_result"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create necessary directories\n    os.makedirs(node_line_dir, exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, \"results\"), exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, \"summary\"), exist_ok=True)\n\n    # Initialize variables for best prompt maker and evaluation metrics\n    best_module = None\n    best_metrics = None\n    best_time = float('inf')\n\n    # Iterate through prompt maker modules and their parameters\n    for i, (module, params) in enumerate(zip(modules, module_params)):\n        # Execute prompt maker module and measure execution time\n        start_time = measure_speed(module, params)\n        result = module(**params)\n        end_time = measure_speed(module, params)\n\n        # Evaluate the performance of the prompt maker module\n        evaluation_metrics = evaluate_generation(result, previous_result, **strategies)\n\n        # Check if the current prompt maker module is the best based on evaluation metrics and execution time\n        if select_best_average(evaluation_metrics, **strategies) and end_time - start_time < best_time:\n            best_module = module\n            best_metrics = evaluation_metrics\n            best_time = end_time - start_time\n\n        # Save the results of the prompt maker module\n        result.to_csv(os.path.join(node_line_dir, \"results\", f\"result_{i}.csv\"), index=False)\n\n    # Combine the best prompt maker's result with the previous result\n    combined_result = pd.concat([previous_result, best_module(**module_params)], ignore_index=True)\n\n    # Save the summary of the best prompt maker's performance\n    summary = pd.DataFrame(cast_metrics(best_metrics))\n    summary.to_csv(os.path.join(node_line_dir, \"summary\", \"summary.csv\"), index=False)\n\n    return combined_result"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create necessary directories\n    os.makedirs(node_line_dir, exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, 'results'), exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, 'summary'), exist_ok=True)\n\n    # Initialize variables for best prompt maker and its evaluation metrics\n    best_prompt_maker = None\n    best_metrics = None\n    best_execution_time = float('inf')\n\n    # Iterate through prompt maker modules and their parameters\n    for i, (module, params) in enumerate(zip(modules, module_params)):\n        # Execute prompt maker module with specified parameters\n        result = module(**params)\n\n        # Evaluate the prompt maker module using the specified strategies\n        evaluation_result = evaluate_generation(result, previous_result, strategies)\n\n        # Measure the execution speed of the prompt maker module\n        execution_time = measure_speed(module, params)\n\n        # Filter prompt maker module based on speed threshold\n        if filter_by_threshold(execution_time, strategies.get('speed_threshold')):\n            # Select the best prompt maker module based on evaluation metrics\n            if best_prompt_maker is None or select_best_average(evaluation_result, best_metrics, strategies.get('evaluation_metrics')):\n                best_prompt_maker = result\n                best_metrics = cast_metrics(evaluation_result)\n                best_execution_time = execution_time\n\n    # Save the best prompt maker's output and summary to the specified directory\n    best_prompt_maker.to_csv(os.path.join(node_line_dir, 'results', 'best_prompt_maker_output.csv'), index=False)\n    summary = pd.DataFrame({'Best Prompt Maker': [best_prompt_maker.__name__],\n                            'Best Metrics': [best_metrics],\n                            'Execution Time': [best_execution_time]})\n    summary.to_csv(os.path.join(node_line_dir, 'summary', 'summary.csv'), index=False)\n\n    # Combine the results from previous operations with the best prompt maker's output\n    combined_result = pd.concat([previous_result, best_prompt_maker], axis=1)\n\n    return combined_result"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create necessary directories\n    os.makedirs(node_line_dir, exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, \"results\"), exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, \"summary\"), exist_ok=True)\n\n    # Initialize variables\n    best_module_result = None\n    best_module_evaluation = None\n    best_module_name = None\n    best_module_execution_time = float('inf')\n\n    # Iterate through prompt maker modules and their parameters\n    for i, (module, params) in enumerate(zip(modules, module_params)):\n        # Run prompt maker module\n        start_time = measure_speed()\n        result = module(**params)\n        execution_time = measure_speed(start_time)\n\n        # Evaluate prompt maker module\n        evaluation = evaluate_generation(result, previous_result, **strategies)\n\n        # Check if the current module is the best based on evaluation strategies\n        if select_best_average(evaluation, best_module_evaluation, **strategies):\n            best_module_result = deepcopy(result)\n            best_module_evaluation = deepcopy(evaluation)\n            best_module_name = module.__name__\n            best_module_execution_time = execution_time\n\n    # Save the best prompt maker's result and summary\n    best_module_result.to_csv(os.path.join(node_line_dir, \"results\", f\"{best_module_name}_result.csv\"), index=False)\n    summary = pd.DataFrame({\n        \"Module Name\": [best_module_name],\n        \"Execution Time (s)\": [best_module_execution_time],\n        **cast_metrics(best_module_evaluation)\n    })\n    summary.to_csv(os.path.join(node_line_dir, \"summary\", \"summary.csv\"), index=False)\n\n    # Combine the best prompt maker's output with the previous result\n    combined_result = pd.concat([previous_result, best_module_result], axis=1)\n\n    return combined_result"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create necessary directories\n    os.makedirs(node_line_dir, exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, 'results'), exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, 'summary'), exist_ok=True)\n\n    # Initialize variables\n    best_module_result = None\n    best_module_eval = None\n    best_module_params = None\n    best_module_name = None\n    best_module_time = float('inf')\n\n    # Iterate through prompt maker modules and evaluate their performance\n    for i, module in enumerate(modules):\n        params = module_params[i]\n        support_modules = get_support_modules()\n        combined_params = make_combinations(params, support_modules)\n        for param_set in combined_params:\n            start_time = measure_speed()\n            result = module(**param_set)\n            execution_time = measure_speed(start_time)\n            if execution_time < best_module_time:\n                best_module_result = result\n                best_module_time = execution_time\n                best_module_params = param_set\n                best_module_name = module.__name__\n\n    # Evaluate the performance of the best prompt maker module\n    if best_module_result is not None:\n        generator = strategies.get('generator', None)\n        evaluation_metrics = strategies.get('evaluation_metrics', None)\n        speed_threshold = strategies.get('speed_threshold', None)\n        if generator is not None and evaluation_metrics is not None:\n            eval_result = evaluate_generation(generator, best_module_result, previous_result, evaluation_metrics)\n            eval_result = cast_metrics(eval_result)\n            best_module_eval = eval_result\n            if speed_threshold is not None:\n                best_module_result = filter_by_threshold(best_module_result, eval_result, speed_threshold)\n            best_module_result = select_best_average(best_module_result)\n\n    # Save the results and summary to the specified directory\n    best_module_result.to_csv(os.path.join(node_line_dir, 'results', f'{best_module_name}_result.csv'), index=False)\n    if best_module_eval is not None:\n        best_module_eval.to_csv(os.path.join(node_line_dir, 'summary', f'{best_module_name}_summary.csv'), index=False)\n\n    # Combine the best prompt maker's output with the previous result\n    if best_module_result is not None:\n        combined_result = pd.concat([previous_result, best_module_result], axis=1)\n        return combined_result\n    else:\n        return previous_result"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Validate previous_result\n    validate_qa_dataset(previous_result)\n\n    # Create necessary directories\n    os.makedirs(node_line_dir, exist_ok=True)\n    prompt_maker_dir = os.path.join(node_line_dir, \"prompt_maker\")\n    os.makedirs(prompt_maker_dir, exist_ok=True)\n\n    # Initialize variables for best prompt maker and its evaluation metrics\n    best_prompt_maker = None\n    best_metrics = None\n\n    # Iterate through prompt maker modules and their parameters\n    for i, (module, params) in enumerate(zip(modules, module_params)):\n        # Execute prompt maker module\n        prompt_output = module(**params)\n\n        # Evaluate prompt maker performance\n        evaluation_result = evaluate_generation(prompt_output, previous_result, strategies)\n\n        # Extract evaluation metrics\n        metrics = cast_metrics(evaluation_result)\n\n        # Select the best prompt maker based on the specified strategies\n        if best_prompt_maker is None or select_best_average(metrics, best_metrics, strategies):\n            best_prompt_maker = prompt_output\n            best_metrics = deepcopy(metrics)\n\n        # Save prompt maker output and evaluation metrics to directory\n        prompt_output.to_csv(os.path.join(prompt_maker_dir, f\"prompt_output_{i}.csv\"), index=False)\n        metrics.to_csv(os.path.join(prompt_maker_dir, f\"evaluation_metrics_{i}.csv\"), index=False)\n\n    # Combine the best prompt maker's output with the previous result\n    combined_result = pd.concat([previous_result, best_prompt_maker], axis=1)\n\n    # Save the combined result to directory\n    combined_result.to_csv(os.path.join(node_line_dir, \"combined_result.csv\"), index=False)\n\n    return combined_result"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create necessary directories\n    os.makedirs(node_line_dir, exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, 'prompt_maker_results'), exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, 'summary'), exist_ok=True)\n\n    # Initialize variables\n    best_module = None\n    best_params = None\n    best_result = None\n    best_evaluation = None\n    best_speed = float('inf')\n\n    # Iterate through prompt maker modules and their parameters\n    for i, (module, params) in enumerate(zip(modules, module_params)):\n        # Execute prompt maker module\n        result = module(**params)\n\n        # Evaluate the performance of the prompt maker module\n        evaluation = evaluate_generation(result, previous_result, strategies.get('evaluation_metrics'))\n\n        # Measure the speed of the prompt maker module\n        speed = measure_speed(result)\n\n        # Filter prompt maker module based on speed threshold\n        if speed < strategies.get('speed_threshold', float('inf')):\n            # Select the best prompt maker module based on the specified strategy\n            if select_best_average(evaluation, strategies.get('evaluation_strategy')) and speed < best_speed:\n                best_module = module\n                best_params = params\n                best_result = result\n                best_evaluation = evaluation\n                best_speed = speed\n\n    # Save the best prompt maker's result and summary to the specified directory\n    best_result.to_csv(os.path.join(node_line_dir, 'prompt_maker_results', 'best_prompt_maker_result.csv'), index=False)\n    summary = pd.DataFrame({'best_module': [best_module.__name__], 'best_params': [best_params], 'best_speed': [best_speed]})\n    summary.to_csv(os.path.join(node_line_dir, 'summary', 'prompt_maker_summary.csv'), index=False)\n\n    # Combine the best prompt maker's result with the previous result\n    combined_result = pd.concat([previous_result, best_result], ignore_index=True)\n\n    return combined_result"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create necessary directories\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Initialize variables\n    best_module_result = None\n    best_module_evaluation = None\n    best_module_speed = float('inf')\n\n    # Iterate through prompt maker modules and their parameters\n    for i, module in enumerate(modules):\n        module_param = module_params[i]\n\n        # Execute prompt maker module\n        result = module(**module_param)\n\n        # Evaluate module performance\n        evaluation = evaluate_generation(result, previous_result, strategies.get('generator_module'))\n\n        # Measure module speed\n        speed = measure_speed(result)\n\n        # Apply strategies to select the best prompt maker module\n        if filter_by_threshold(evaluation, strategies.get('evaluation_metrics')) and speed < best_module_speed:\n            best_module_result = result\n            best_module_evaluation = evaluation\n            best_module_speed = speed\n\n    # Save the best prompt maker's result and evaluation summary to the specified directory\n    best_module_result.to_csv(os.path.join(node_line_dir, 'best_prompt_maker_result.csv'), index=False)\n    best_module_evaluation.to_csv(os.path.join(node_line_dir, 'best_prompt_maker_evaluation.csv'), index=False)\n\n    # Combine the best prompt maker's output with the previous result\n    combined_result = pd.concat([previous_result, best_module_result], ignore_index=True)\n\n    return combined_result"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create necessary directories\n    os.makedirs(node_line_dir, exist_ok=True)\n    prompt_maker_dir = os.path.join(node_line_dir, \"prompt_maker\")\n    os.makedirs(prompt_maker_dir, exist_ok=True)\n\n    # Initialize variables for tracking execution times and evaluation metrics\n    execution_times = []\n    evaluation_metrics = []\n\n    # Iterate through prompt maker modules and their parameters\n    for i, (module, params) in enumerate(zip(modules, module_params)):\n        # Execute the prompt maker module with specified parameters\n        result = module(**params)\n\n        # Evaluate the performance of the prompt maker module\n        evaluation_result = evaluate_generation(result, previous_result, strategies.get(\"generator\"))\n\n        # Track execution time\n        execution_time = measure_speed(module, params)\n        execution_times.append((i, execution_time))\n\n        # Track evaluation metrics\n        evaluation_metrics.append((i, cast_metrics(evaluation_result)))\n\n        # Save the prompt maker's output to a file\n        result.to_csv(os.path.join(prompt_maker_dir, f\"prompt_maker_{i}.csv\"), index=False)\n\n    # Filter prompt maker results based on specified strategies\n    filtered_results = filter_by_threshold(evaluation_metrics, strategies.get(\"thresholds\"))\n\n    # Select the best prompt maker based on specified strategies\n    best_prompt_maker_index = select_best_average(filtered_results, strategies.get(\"metrics\"))\n\n    # Combine the best prompt maker's output with the previous result\n    best_prompt_maker_output = pd.read_csv(os.path.join(prompt_maker_dir, f\"prompt_maker_{best_prompt_maker_index}.csv\"))\n    combined_result = pd.concat([previous_result, best_prompt_maker_output], ignore_index=True)\n\n    # Save the combined result to a file\n    combined_result.to_csv(os.path.join(node_line_dir, \"combined_result.csv\"), index=False)\n\n    return combined_result"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create necessary directories\n    os.makedirs(node_line_dir, exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, \"prompt_maker_output\"), exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, \"evaluation_metrics\"), exist_ok=True)\n\n    # Initialize variables for best prompt maker and evaluation metrics\n    best_prompt_maker = None\n    best_metrics = None\n\n    # Iterate through prompt maker modules and their parameters\n    for i, (module, params) in enumerate(zip(modules, module_params)):\n        # Execute the prompt maker module with specified parameters\n        prompt_maker_output = module(**params)\n\n        # Save the prompt maker output to a file\n        output_file = os.path.join(node_line_dir, \"prompt_maker_output\", f\"prompt_maker_output_{i}.csv\")\n        prompt_maker_output.to_csv(output_file, index=False)\n\n        # Evaluate the prompt maker output based on specified strategies\n        evaluation_result = evaluate_generation(prompt_maker_output, previous_result, strategies)\n\n        # Save the evaluation metrics to a file\n        metrics_file = os.path.join(node_line_dir, \"evaluation_metrics\", f\"evaluation_metrics_{i}.csv\")\n        evaluation_result.to_csv(metrics_file, index=False)\n\n        # Update the best prompt maker and evaluation metrics based on the evaluation result\n        if best_prompt_maker is None or select_best_average(evaluation_result, strategies) > select_best_average(best_metrics, strategies):\n            best_prompt_maker = prompt_maker_output\n            best_metrics = evaluation_result\n\n    # Combine the best prompt maker's output with the previous result\n    combined_result = pd.concat([previous_result, best_prompt_maker], axis=1)\n\n    return combined_result"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create necessary directories\n    os.makedirs(node_line_dir, exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, \"prompt_maker\"), exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, \"evaluation\"), exist_ok=True)\n\n    # Initialize variables\n    best_module_result = None\n    best_module_evaluation = None\n    best_module_name = None\n    best_module_params = None\n    best_module_execution_time = float('inf')\n\n    # Iterate through prompt maker modules and their parameters\n    for i, (module, params) in enumerate(zip(modules, module_params)):\n        # Execute the prompt maker module\n        start_time = measure_speed()\n        result = module(**params)\n        end_time = measure_speed(start_time)\n\n        # Save the prompt maker result\n        result.to_csv(os.path.join(node_line_dir, \"prompt_maker\", f\"prompt_maker_result_{i}.csv\"), index=False)\n\n        # Evaluate the prompt maker result\n        evaluation = evaluate_generation(result, previous_result, strategies.get(\"evaluation_metrics\", [\"accuracy\"]), strategies.get(\"generator_module\", None))\n        evaluation = cast_metrics(evaluation)\n\n        # Save the evaluation metrics\n        evaluation.to_csv(os.path.join(node_line_dir, \"evaluation\", f\"evaluation_metrics_{i}.csv\"), index=False)\n\n        # Update the best prompt maker module based on the specified strategies\n        if select_best_average(evaluation, strategies.get(\"evaluation_metrics\", [\"accuracy\"])) and end_time < best_module_execution_time:\n            best_module_result = result\n            best_module_evaluation = evaluation\n            best_module_name = module.__name__\n            best_module_params = params\n            best_module_execution_time = end_time\n\n    # Combine the best prompt maker's result with the previous result\n    combined_result = pd.concat([previous_result, best_module_result], axis=1)\n\n    # Save the combined result\n    combined_result.to_csv(os.path.join(node_line_dir, \"combined_result.csv\"), index=False)\n\n    return combined_result"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create necessary directories\n    os.makedirs(node_line_dir, exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, 'results'), exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, 'summary'), exist_ok=True)\n\n    # Initialize variables for best prompt maker and evaluation metrics\n    best_module = None\n    best_metrics = None\n    best_result = None\n    best_time = float('inf')\n\n    # Iterate through prompt maker modules and their parameters\n    for i, (module, params) in enumerate(zip(modules, module_params)):\n        # Create directory for the current prompt maker module\n        module_dir = os.path.join(node_line_dir, f'module_{i}')\n        os.makedirs(module_dir, exist_ok=True)\n\n        # Execute the prompt maker module\n        result, time_taken = module(**params)\n\n        # Evaluate the prompt maker module based on specified strategies\n        evaluation_metrics = evaluate_generation(result, previous_result, strategies)\n\n        # Check if the current prompt maker module is the best based on evaluation metrics and speed\n        if select_best_average(evaluation_metrics, strategies) and measure_speed(time_taken, strategies):\n            best_module = module\n            best_metrics = evaluation_metrics\n            best_result = result\n            best_time = time_taken\n\n        # Save the result and evaluation metrics to the module directory\n        result.to_csv(os.path.join(module_dir, 'result.csv'), index=False)\n        pd.DataFrame(cast_metrics(evaluation_metrics)).to_csv(os.path.join(module_dir, 'evaluation_metrics.csv'), index=False)\n\n    # Combine the best prompt maker's result with the previous result\n    combined_result = pd.concat([previous_result, best_result], axis=1)\n\n    # Save the combined result to the results directory\n    combined_result.to_csv(os.path.join(node_line_dir, 'results', 'combined_result.csv'), index=False)\n\n    # Save the best prompt maker's evaluation metrics and time taken to the summary directory\n    pd.DataFrame(cast_metrics(best_metrics)).to_csv(os.path.join(node_line_dir, 'summary', 'best_evaluation_metrics.csv'), index=False)\n    with open(os.path.join(node_line_dir, 'summary', 'best_time_taken.txt'), 'w') as f:\n        f.write(f'Time taken: {best_time}')\n\n    return combined_result"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create necessary directories\n    os.makedirs(node_line_dir, exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, 'results'), exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, 'summary'), exist_ok=True)\n\n    # Initialize variables\n    best_module_result = None\n    best_module_eval = None\n\n    # Iterate through prompt maker modules and their parameters\n    for module, params in zip(modules, module_params):\n        # Execute prompt maker module with specified parameters\n        result = module(**params)\n        \n        # Evaluate the performance of the prompt maker module\n        evaluation = evaluate_generation(result, previous_result, strategies.get('generator', None))\n        \n        # Update best module result and evaluation based on specified strategies\n        if best_module_result is None or select_best_average(evaluation, best_module_eval, strategies.get('metrics', None)):\n            best_module_result = result\n            best_module_eval = evaluation\n\n    # Save the best prompt maker's result and evaluation summary\n    best_module_result.to_csv(os.path.join(node_line_dir, 'results', 'best_prompt_maker_result.csv'), index=False)\n    best_module_eval.to_csv(os.path.join(node_line_dir, 'summary', 'best_prompt_maker_evaluation.csv'), index=False)\n\n    # Combine the best prompt maker's result with the previous result\n    combined_result = pd.concat([previous_result, best_module_result], ignore_index=True)\n\n    return combined_result"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create necessary directories\n    os.makedirs(node_line_dir, exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, \"results\"), exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, \"summary\"), exist_ok=True)\n\n    # Initialize variables\n    best_module_result = None\n    best_module_eval = None\n    best_module_name = None\n    best_module_params = None\n    best_module_execution_time = float('inf')\n\n    # Iterate through prompt maker modules and their parameters\n    for module, params in zip(modules, module_params):\n        # Execute the prompt maker module\n        start_time = time.time()\n        prompt_maker_result = module(**params)\n        execution_time = time.time() - start_time\n\n        # Evaluate the prompt maker module\n        evaluation_result = evaluate_generation(prompt_maker_result, previous_result, strategies)\n\n        # Update the best module if it performs better based on the specified strategies\n        if best_module_result is None or select_best_average(evaluation_result, best_module_eval, strategies):\n            best_module_result = prompt_maker_result\n            best_module_eval = evaluation_result\n            best_module_name = module.__name__\n            best_module_params = params\n            best_module_execution_time = execution_time\n\n    # Save the best prompt maker's result and evaluation summary to the specified directory\n    best_module_result.to_csv(os.path.join(node_line_dir, \"results\", f\"{best_module_name}_result.csv\"), index=False)\n    best_module_eval.to_csv(os.path.join(node_line_dir, \"summary\", f\"{best_module_name}_summary.csv\"), index=False)\n\n    # Combine the best prompt maker's result with the previous result\n    combined_result = pd.concat([previous_result, best_module_result], axis=1)\n\n    return combined_result"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create necessary directories\n    os.makedirs(node_line_dir, exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, \"prompt_maker_results\"), exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, \"summary\"), exist_ok=True)\n\n    # Initialize variables\n    best_module_result = None\n    best_module_metrics = None\n    best_module_execution_time = float('inf')\n\n    # Iterate through prompt maker modules and evaluate their performance\n    for i, module in enumerate(modules):\n        module_param = module_params[i]\n        support_modules = get_support_modules(module)\n\n        # Generate combinations of support modules\n        support_combinations = make_combinations(support_modules)\n\n        # Evaluate prompt maker module with each support combination\n        for support_combination in support_combinations:\n            # Deep copy the previous result to avoid modifying the original\n            temp_previous_result = deepcopy(previous_result)\n\n            # Execute prompt maker module with support combination\n            start_time = measure_speed()\n            prompt_result = module(temp_previous_result, **module_param, **support_combination)\n            execution_time = measure_speed(start_time)\n\n            # Evaluate prompt maker module's performance\n            evaluation_metrics = evaluate_generation(prompt_result, strategies.get('evaluation_metrics', ['accuracy']))\n            evaluation_metrics = cast_metrics(evaluation_metrics)\n\n            # Apply speed threshold if specified\n            if 'speed_threshold' in strategies:\n                if execution_time > strategies['speed_threshold']:\n                    continue\n\n            # Update best module result if it outperforms the current best\n            if select_best_average(evaluation_metrics, strategies.get('evaluation_metrics', ['accuracy'])) > best_module_metrics:\n                best_module_result = prompt_result\n                best_module_metrics = evaluation_metrics\n                best_module_execution_time = execution_time\n\n    # Save best module result and summary to specified directory\n    best_module_result.to_csv(os.path.join(node_line_dir, \"prompt_maker_results\", \"best_prompt_maker_result.csv\"), index=False)\n    summary = pd.DataFrame({'best_module_metrics': best_module_metrics, 'best_module_execution_time': best_module_execution_time}, index=[0])\n    summary.to_csv(os.path.join(node_line_dir, \"summary\", \"prompt_maker_summary.csv\"), index=False)\n\n    # Combine best module result with previous result\n    combined_result = pd.concat([previous_result, best_module_result], axis=0)\n\n    return combined_result"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create necessary directories\n    os.makedirs(node_line_dir, exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, 'prompt_maker_results'), exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, 'summary'), exist_ok=True)\n\n    # Initialize variables for storing results and execution times\n    prompt_maker_results = []\n    execution_times = []\n\n    # Loop through prompt maker modules and their parameters\n    for module, params in zip(modules, module_params):\n        # Execute the prompt maker module and measure its execution time\n        result, execution_time = measure_speed(module, params)\n        prompt_maker_results.append(result)\n        execution_times.append(execution_time)\n\n    # Convert the results to a DataFrame\n    prompt_maker_results_df = pd.concat(prompt_maker_results)\n\n    # Evaluate the prompt maker results based on specified strategies\n    evaluation_metrics = evaluate_generation(prompt_maker_results_df, previous_result, strategies)\n\n    # Select the best prompt maker based on the evaluation metrics and specified strategies\n    best_prompt_maker = select_best_average(prompt_maker_results_df, evaluation_metrics, strategies)\n\n    # Combine the best prompt maker's output with the previous result\n    combined_result = pd.concat([previous_result, best_prompt_maker])\n\n    # Save the prompt maker results and summary to the specified directory\n    prompt_maker_results_df.to_csv(os.path.join(node_line_dir, 'prompt_maker_results', 'prompt_maker_results.csv'), index=False)\n    evaluation_metrics.to_csv(os.path.join(node_line_dir, 'summary', 'evaluation_metrics.csv'), index=False)\n    pd.DataFrame({'execution_times': execution_times}).to_csv(os.path.join(node_line_dir, 'summary', 'execution_times.csv'), index=False)\n\n    return combined_result"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create necessary directories\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Initialize variables for best prompt maker and evaluation metrics\n    best_module = None\n    best_metrics = None\n    best_speed = float('inf')\n\n    # Loop through prompt maker modules and their parameters\n    for module, params in zip(modules, module_params):\n        # Execute prompt maker module with specified parameters\n        result = module(**params)\n\n        # Evaluate the performance of the prompt maker module\n        evaluation_result = evaluate_generation(result, previous_result, strategies)\n\n        # Get execution time and evaluation metrics\n        execution_time = evaluation_result['execution_time']\n        metrics = cast_metrics(evaluation_result['metrics'])\n\n        # Check if the prompt maker module meets the speed threshold\n        if measure_speed(execution_time, strategies.get('speed_threshold', float('inf'))):\n            # Check if the prompt maker module has better evaluation metrics\n            if select_best_average(metrics, strategies.get('evaluation_metrics', ['accuracy'])) < best_speed:\n                best_module = deepcopy(result)\n                best_metrics = metrics\n                best_speed = select_best_average(metrics, strategies.get('evaluation_metrics', ['accuracy']))\n\n    # Save the best prompt maker's output and summary to the specified directory\n    best_module.to_csv(os.path.join(node_line_dir, 'best_prompt_maker_output.csv'), index=False)\n    pd.DataFrame([best_metrics]).to_csv(os.path.join(node_line_dir, 'evaluation_summary.csv'), index=False)\n\n    # Combine the best prompt maker's output with the previous result\n    combined_result = pd.concat([previous_result, best_module], axis=0)\n\n    return combined_result"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create necessary directories\n    os.makedirs(node_line_dir, exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, \"results\"), exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, \"summary\"), exist_ok=True)\n\n    # Initialize variables for best prompt maker and evaluation metrics\n    best_module = None\n    best_metrics = None\n    best_execution_time = float('inf')\n\n    # Iterate through prompt maker modules and their parameters\n    for i, module in enumerate(modules):\n        params = module_params[i]\n\n        # Execute prompt maker module and measure execution time\n        start_time = measure_speed()\n        result = module(**params)\n        execution_time = measure_speed(start_time)\n\n        # Evaluate the prompt maker module based on specified strategies\n        evaluation_metrics = evaluate_generation(result, previous_result, strategies)\n\n        # Check if the prompt maker module is the best based on the evaluation metrics and execution time\n        if select_best_average(evaluation_metrics, strategies) and execution_time < best_execution_time:\n            best_module = module\n            best_metrics = evaluation_metrics\n            best_execution_time = execution_time\n\n        # Save the results and evaluation metrics to the specified directory\n        result.to_csv(os.path.join(node_line_dir, \"results\", f\"result_{i}.csv\"), index=False)\n        evaluation_metrics.to_csv(os.path.join(node_line_dir, \"summary\", f\"evaluation_metrics_{i}.csv\"), index=False)\n\n    # Combine the best prompt maker's output with the previous result\n    combined_result = best_module(**module_params[modules.index(best_module)])\n    combined_result = pd.concat([previous_result, combined_result], axis=1)\n\n    return combined_result"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "\n    values = set()\n    for node in nodes:\n        extracted_values = extract_values(node, key)\n        values.update(extracted_values)\n    return list(values)"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "\n    extracted_values = []\n    for node in nodes:\n        values = extract_values(node, key)\n        extracted_values.extend(values)\n\n    return list(set(extracted_values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "\n    extracted_values = []\n    for node in nodes:\n        values = extract_values(node, key)\n        extracted_values.extend(values)\n\n    return list(set(extracted_values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = []\n    for node in nodes:\n        values.extend(extract_values(node, key))\n    return list(set(values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = []\n    for node in nodes:\n        values.extend(extract_values(node, key))\n    return list(set(values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    extracted_values = []\n    for node in nodes:\n        values = extract_values(node, key)\n        extracted_values.extend(values)\n    return list(set(extracted_values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    extracted_values = []\n    for node in nodes:\n        values = extract_values(node, key)\n        extracted_values.extend(values)\n    return list(set(extracted_values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = []\n    for node in nodes:\n        extracted_values = extract_values(node, key)\n        values.extend(extracted_values)\n    unique_values = list(set(values))\n    return unique_values"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "\n    extracted_values = []\n    for node in nodes:\n        values = extract_values(node, key)\n        extracted_values.extend(values)\n\n    return list(set(extracted_values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "\n    extracted_values = []\n    for node in nodes:\n        extracted_values.extend(extract_values(node, key))\n    \n    return list(set(extracted_values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = []\n    for node in nodes:\n        values.extend(extract_values(node, key))\n    return list(set(values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "\n    values = []\n    for node in nodes:\n        values.extend(extract_values(node, key))\n    return list(set(values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    extracted_values = []\n    for node in nodes:\n        values = extract_values(node, key)\n        extracted_values.extend(values)\n    return list(set(extracted_values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "\n    extracted_values = []\n    for node in nodes:\n        values = extract_values(node, key)\n        extracted_values.extend(values)\n\n    return list(set(extracted_values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "\n    extracted_values = []\n    for node in nodes:\n        values = extract_values(node, key)\n        extracted_values.extend(values)\n\n    return list(set(extracted_values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(set(itertools.chain.from_iterable([extract_values(node, key) for node in nodes])))\n    return values"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = []\n    for node in nodes:\n        extracted_values = extract_values(node, key)\n        values.extend(extracted_values)\n    return list(set(values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "\n    extracted_values = []\n    for node in nodes:\n        extracted_values.extend(extract_values(node, key))\n\n    return list(set(extracted_values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "\n    extracted_values = []\n    for node in nodes:\n        values = extract_values(node, key)\n        extracted_values.extend(values)\n\n    return list(set(extracted_values))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = []\n    for node in nodes:\n        extracted_values = extract_values(node, key)\n        values.extend(extracted_values)\n    return list(set(values))"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "\n    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for col in dict_columns:\n        summary_df[col] = summary_df[col].apply(ast.literal_eval)\n\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "\n    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    df = pd.read_csv(summary_path)  # Load the summary file into a DataFrame\n\n    for column in dict_columns:\n        df[column] = df[column].apply(ast.literal_eval)  # Convert dictionary-like strings to actual dictionaries\n\n    return df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for col in dict_columns:\n        summary_df[col] = summary_df[col].apply(ast.literal_eval)\n\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n    \n    for col in dict_columns:\n        summary_df[col] = summary_df[col].apply(ast.literal_eval)\n\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "\n    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for col in dict_columns:\n        summary_df[col] = summary_df[col].apply(ast.literal_eval)\n\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for col in dict_columns:\n        summary_df[col] = summary_df[col].apply(ast.literal_eval)\n\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "\n    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for col in dict_columns:\n        summary_df[col] = summary_df[col].apply(ast.literal_eval)\n\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "\n    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for col in dict_columns:\n        summary_df[col] = summary_df[col].apply(ast.literal_eval)\n\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "\n    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    # Load the summary file into a DataFrame\n    summary_df = pd.read_csv(summary_path)\n\n    # Convert specified columns to dictionary objects\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(ast.literal_eval)\n\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "\n    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(ast.literal_eval)\n\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "\n    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)  # Load the summary file into a DataFrame\n\n    for col in dict_columns:  # Convert specified columns to dictionary objects\n        summary_df[col] = summary_df[col].apply(ast.literal_eval)\n\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "\n    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(ast.literal_eval)\n\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "\n    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(ast.literal_eval)\n\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "\n    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(ast.literal_eval)\n\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for col in dict_columns:\n        summary_df[col] = summary_df[col].apply(ast.literal_eval)\n\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "\n    # Load the summary file into a DataFrame\n    summary_df = pd.read_csv(summary_path)\n\n    # Convert specified columns to dictionary objects\n    if dict_columns is not None:\n        for column in dict_columns:\n            summary_df[column] = summary_df[column].apply(ast.literal_eval)\n\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for col in dict_columns:\n        summary_df[col] = summary_df[col].apply(ast.literal_eval)\n\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "\n    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(ast.literal_eval)\n\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "\n    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    # Load the summary file into a pandas DataFrame\n    summary_df = pd.read_csv(summary_path)\n\n    # Convert specified columns to dictionary objects\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(ast.literal_eval)\n\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "\n    # Read the summary file into a DataFrame\n    summary_df = pd.read_csv(summary_path)\n\n    # Convert specified columns to dictionary objects\n    if dict_columns is not None:\n        for column in dict_columns:\n            summary_df[column] = summary_df[column].apply(ast.literal_eval)\n\n    return summary_df"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.get('module_type')\n        module_param = deepcopy(module_dict)\n        module_param.pop('module_type', None)\n        return cls(module_type=module_type, module_param=module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict['module_type']\n        module_param = deepcopy(module_dict)\n        del module_param['module_type']\n        return cls(module_type=module_type, module_param=module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.get('module_type')\n        module_param = deepcopy(module_dict)\n        module_param.pop('module_type', None)\n        return cls(module_type=module_type, module_param=module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.get('module_type')\n        module_param = deepcopy(module_dict)\n        module_param.pop('module_type', None)\n        return cls(module_type=module_type, module_param=module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.get('module_type')\n        module_params = deepcopy(module_dict)\n        module_params.pop('module_type')\n\n        return cls(module_type=module_type, module_param=module_params)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.get('module_type')\n        module_param = deepcopy(module_dict)\n        module_param.pop('module_type', None)\n        return cls(module_type=module_type, module_param=module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.get('module_type')\n        module_params = {k: v for k, v in module_dict.items() if k != 'module_type'}\n        return cls(module_type=module_type, module_param=module_params)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        if 'module_type' not in module_dict:\n            raise ValueError(\"The 'module_type' key is missing in the module_dict.\")\n\n        module_type = module_dict['module_type']\n        module_param = deepcopy(module_dict)\n        del module_param['module_type']\n\n        return cls(module_type=module_type, module_param=module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.get('module_type')\n        module_param = deepcopy(module_dict)\n        module_param.pop('module_type', None)\n        return cls(module_type=module_type, module_param=module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.get('module_type')\n        module_param = deepcopy(module_dict)\n        module_param.pop('module_type', None)\n        return cls(module_type=module_type, module_param=module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.get('module_type')\n        module_param = deepcopy(module_dict)\n        del module_param['module_type']\n        return cls(module_type=module_type, module_param=module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.get('module_type')\n        module_param = deepcopy(module_dict)\n        module_param.pop('module_type', None)\n        return cls(module_type=module_type, module_param=module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.get('module_type')\n        module_param = deepcopy(module_dict)\n        module_param.pop('module_type')\n\n        return cls(module_type=module_type, module_param=module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.get('module_type')\n        module_param = deepcopy(module_dict)\n        module_param.pop('module_type', None)\n        return cls(module_type=module_type, module_param=module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict['module_type']\n        module_param = deepcopy(module_dict)\n        del module_param['module_type']\n        return cls(module_type=module_type, module_param=module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.get('module_type')\n        if module_type is None:\n            raise ValueError(\"Module dictionary must contain 'module_type' key.\")\n\n        module_param = deepcopy(module_dict)\n        del module_param['module_type']\n\n        return cls(module_type=module_type, module_param=module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.get('module_type')\n        module_param = deepcopy(module_dict)\n        module_param.pop('module_type', None)\n        return cls(module_type=module_type, module_param=module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "    module_type = module_dict.get('module_type')\n    module_param = deepcopy(module_dict)\n    module_param.pop('module_type')\n    return cls(module_type=module_type, module_param=module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.get('module_type')\n        module_param = deepcopy(module_dict)\n        del module_param['module_type']\n        return cls(module_type=module_type, module_param=module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.get('module_type')\n        module_param = deepcopy(module_dict)\n        module_param.pop('module_type', None)\n        return cls(module_type=module_type, module_param=module_param)"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "\n    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(metric['name'])\n            metric_params.append(deepcopy(metric))\n\n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(metric['name'])\n            metric_params.append(deepcopy(metric))\n\n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(metric['name'])\n            metric_params.append(deepcopy(metric))\n\n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "\n    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(metric['name'])\n            metric_params.append(deepcopy(metric))\n\n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(metric['name'])\n            metric_params.append(deepcopy(metric))\n\n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(metric.get('name'))\n            metric_params.append(deepcopy(metric))\n\n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(metric['name'])\n            metric_params.append(deepcopy(metric))\n\n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(metric['name'])\n            metric_params.append(deepcopy(metric))\n\n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(metric['name'])\n            metric_params.append(deepcopy(metric))\n\n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(list(metric.keys())[0])\n            metric_params.append(metric)\n\n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(metric['name'])\n            metric_params.append(deepcopy(metric))\n\n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "\n    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(metric['name'])\n            metric_params.append(deepcopy(metric))\n\n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(metric['name'])\n            metric_params.append(deepcopy(metric))\n        else:\n            raise ValueError(\"Invalid metric format. Metrics should be either strings or dictionaries.\")\n\n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "\n    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(metric['name'])\n            metric_params.append(deepcopy(metric))\n\n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "\n    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(metric['name'])\n            metric_params.append(deepcopy(metric))\n\n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(metric['name'])\n            metric_params.append(deepcopy(metric))\n        else:\n            raise ValueError(\"Invalid format for metric. Metric must be either a string or a dictionary.\")\n\n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "\n    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(metric['name'])\n            metric_params.append(deepcopy(metric))\n\n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(list(metric.keys())[0])\n            metric_params.append(metric)\n\n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "\n    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(list(metric.keys())[0])\n            metric_params.append(metric)\n\n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(metric['name'])\n            metric_params.append(deepcopy(metric))\n\n    return metric_names, metric_params"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "\n    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model('all-mpnet-base-v2')\n\n    pred_embedding = embedding_model.encode([pred])[0]\n    gt_embeddings = embedding_model.encode(generation_gt)\n\n    max_similarity = max([calculate_cosine_similarity(pred_embedding, gt_emb) for gt_emb in gt_embeddings])\n\n    return max_similarity"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model('all-mpnet-base-v2')\n\n    pred_embedding = embedding_model.encode(pred)\n    gt_embeddings = [embedding_model.encode(gt) for gt in generation_gt]\n\n    max_similarity = max([calculate_cosine_similarity(pred_embedding, gt_embedding) for gt_embedding in gt_embeddings])\n\n    return max_similarity"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model('all-mpnet-base-v2')\n\n    gt_embeddings = [embedding_model.encode(gt) for gt in generation_gt]\n    pred_embedding = embedding_model.encode(pred)\n\n    similarity_scores = [calculate_cosine_similarity(pred_embedding, gt_emb) for gt_emb in gt_embeddings]\n    return max(similarity_scores)"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model('all-mpnet-base-v2')\n\n    # Convert ground truth and prediction strings to embeddings\n    gt_embeddings = [embedding_model.encode(gt) for gt in generation_gt]\n    pred_embedding = embedding_model.encode(pred)\n\n    # Calculate cosine similarity between prediction and each ground truth string\n    similarities = [calculate_cosine_similarity(pred_embedding, gt) for gt in gt_embeddings]\n\n    # Return the maximum cosine similarity as the semantic similarity score\n    return max(similarities)"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model('all-mpnet-base-v2')\n\n    pred_embedding = embedding_model.encode(pred)\n    gt_embeddings = [embedding_model.encode(gt) for gt in generation_gt]\n\n    similarities = [calculate_cosine_similarity(pred_embedding, gt_emb) for gt_emb in gt_embeddings]\n    return max(similarities)"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "\n    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model('all-mpnet-base-v2')\n\n    similarity_scores = [calculate_cosine_similarity(embedding_model.encode(pred), embedding_model.encode(gt)) for gt in generation_gt]\n    return max(similarity_scores)"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model('all-mpnet-base-v2')\n\n    max_similarity = 0\n    for gt_string in generation_gt:\n        gt_embedding = embedding_model.encode(gt_string)\n        pred_embedding = embedding_model.encode(pred)\n        similarity = calculate_cosine_similarity(gt_embedding, pred_embedding)\n        max_similarity = max(max_similarity, similarity)\n\n    return max_similarity"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "\n    if embedding_model is None:\n        embedding_model = embedding_models.get_model(\"all-mpnet-base-v2\")\n\n    max_similarity = 0.0\n    for gt in generation_gt:\n        gt_embedding = embedding_model.encode(gt)\n        pred_embedding = embedding_model.encode(pred)\n        similarity = calculate_cosine_similarity(gt_embedding, pred_embedding)\n        max_similarity = max(max_similarity, similarity)\n\n    return max_similarity"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model('all-mpnet-base-v2')\n\n    similarities = [calculate_cosine_similarity(embedding_model.encode(pred), embedding_model.encode(gt)) for gt in generation_gt]\n    return max(similarities)"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model('all-mpnet-base-v2')\n\n    gt_embeddings = [embedding_model.encode(gt) for gt in generation_gt]\n    pred_embedding = embedding_model.encode(pred)\n\n    similarity_scores = [calculate_cosine_similarity(pred_embedding, gt_emb) for gt_emb in gt_embeddings]\n    max_similarity_score = max(similarity_scores)\n\n    return max_similarity_score"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model('all-mpnet-base-v2')\n\n    gt_embeddings = [embedding_model.encode(gt) for gt in generation_gt]\n    pred_embedding = embedding_model.encode(pred)\n\n    similarity_scores = [calculate_cosine_similarity(pred_embedding, gt_emb) for gt_emb in gt_embeddings]\n    return max(similarity_scores)"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model(\"all-mpnet-base-v2\")\n\n    # Convert ground truth and prediction strings to embeddings\n    gt_embeddings = [embedding_model.encode(gt) for gt in generation_gt]\n    pred_embedding = embedding_model.encode(pred)\n\n    # Calculate cosine similarity between prediction and each ground truth string\n    similarities = [calculate_cosine_similarity(pred_embedding, gt_emb) for gt_emb in gt_embeddings]\n\n    # Return the maximum cosine similarity as the semantic score\n    return max(similarities)"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model('all-mpnet-base-v2')\n\n    pred_embedding = embedding_model.encode(pred)\n    gt_embeddings = [embedding_model.encode(gt) for gt in generation_gt]\n\n    max_similarity = 0\n    for gt_embedding in gt_embeddings:\n        similarity = calculate_cosine_similarity(pred_embedding, gt_embedding)\n        if similarity > max_similarity:\n            max_similarity = similarity\n\n    return max_similarity"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "\n    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model('all-mpnet-base-v2')\n\n    max_similarity = 0\n    for gt in generation_gt:\n        similarity = calculate_cosine_similarity(embedding_model.encode([gt]), embedding_model.encode([pred]))\n        if similarity > max_similarity:\n            max_similarity = similarity\n\n    return max_similarity"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model('all-mpnet-base-v2')\n\n    gt_embeddings = [embedding_model.encode(sentence) for sentence in generation_gt]\n    pred_embedding = embedding_model.encode(pred)\n\n    similarities = [calculate_cosine_similarity(pred_embedding, gt_embedding) for gt_embedding in gt_embeddings]\n    return max(similarities)"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model('all-mpnet-base-v2')\n\n    pred_embedding = embedding_model.encode(pred)\n    gt_embeddings = [embedding_model.encode(gt) for gt in generation_gt]\n\n    similarities = [calculate_cosine_similarity(pred_embedding, gt_emb) for gt_emb in gt_embeddings]\n    return max(similarities)"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model('all-mpnet-base-v2')\n\n    pred_embedding = embedding_model.encode([pred])[0]\n    gt_embeddings = embedding_model.encode(generation_gt)\n\n    similarities = [calculate_cosine_similarity(pred_embedding, gt_emb) for gt_emb in gt_embeddings]\n\n    return max(similarities)"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "\n    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model('all-mpnet-base-v2')\n\n    pred_embedding = embedding_model.encode(pred)\n    gt_embeddings = [embedding_model.encode(gt) for gt in generation_gt]\n\n    similarity_scores = [calculate_cosine_similarity(pred_embedding, gt_emb) for gt_emb in gt_embeddings]\n\n    return max(similarity_scores)"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model(\"all-mpnet-base-v2\")\n\n    gt_embeddings = [embedding_model.encode(gt) for gt in generation_gt]\n    pred_embedding = embedding_model.encode(pred)\n\n    similarities = [calculate_cosine_similarity(pred_embedding, gt_emb) for gt_emb in gt_embeddings]\n    max_similarity = max(similarities)\n\n    return max_similarity"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "\n    if embedding_model is None:\n        embedding_model = embedding_models.get_embedding_model('all-mpnet-base-v2')\n\n    gt_embeddings = [embedding_model.encode(gt) for gt in generation_gt]\n    pred_embedding = embedding_model.encode(pred)\n\n    similarities = [calculate_cosine_similarity(pred_embedding, gt_embedding) for gt_embedding in gt_embeddings]\n\n    return max(similarities)"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "\n    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer is not set up. Returning the original image.\")\n        return np_image\n\n    try:\n        restored_image = gfpgan_face_restorer.restore(np_image)\n        return restored_image\n    except Exception as e:\n        logger.error(f\"Error occurred while using GFPGAN face restorer: {e}\")\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "\n    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer is not set up. Returning the original image.\")\n        return np_image\n\n    try:\n        restored_image = gfpgan_face_restorer.restore(np_image)\n        return restored_image\n    except Exception as e:\n        logger.error(f\"Error while using GFPGAN face restorer: {e}\")\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "\n    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer is not set up. Returning the original image.\")\n        return np_image\n\n    try:\n        restored_image = gfpgan_face_restorer.restore(np_image)\n        return restored_image\n    except Exception as e:\n        logger.error(f\"Error occurred while using GFPGAN face restorer: {e}\")\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "\n    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logging.warning(\"GFPGAN face restorer is not set up. Returning the original image.\")\n        return np_image\n\n    try:\n        restored_image = gfpgan_face_restorer.restore(np_image)\n        return restored_image\n    except Exception as e:\n        logging.warning(f\"Failed to restore faces using GFPGAN face restorer: {e}\")\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "\n    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer is not set up. Returning original image.\")\n        return np_image\n\n    try:\n        restored_image = gfpgan_face_restorer.restore(np_image)\n        return restored_image\n    except Exception as e:\n        logger.error(f\"Error while using GFPGAN face restorer: {e}\")\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "\n    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer is not set up. Returning the original image.\")\n        return np_image\n\n    try:\n        restored_image = gfpgan_face_restorer.restore(np_image)\n        return restored_image\n    except Exception as e:\n        logger.error(f\"Error occurred while restoring faces using GFPGAN: {e}\")\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "\n    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer is not set up. Returning original image.\")\n        return np_image\n\n    try:\n        restored_image = gfpgan_face_restorer.restore(np_image)\n        return restored_image\n    except Exception as e:\n        logger.error(f\"Failed to restore faces using GFPGAN: {e}\")\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "\n    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer is not set up. Returning original image.\")\n        return np_image\n    else:\n        try:\n            restored_image = gfpgan_face_restorer.restore(np_image)\n            return restored_image\n        except Exception as e:\n            logger.error(f\"Error in restoring faces using GFPGAN: {e}\")\n            return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "\n    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logging.warning(\"GFPGAN face restorer is not set up. Returning the original image.\")\n        return np_image\n\n    try:\n        restored_image = gfpgan_face_restorer.restore(np_image)\n        return restored_image\n    except Exception as e:\n        logging.warning(f\"Failed to restore faces using GFPGAN face restorer: {str(e)}\")\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "\n    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer is not set up. Returning the original image.\")\n        return np_image\n\n    try:\n        restored_image = gfpgan_face_restorer.restore(np_image)\n        return restored_image\n    except Exception as e:\n        logger.error(f\"Error occurred while using GFPGAN face restorer: {e}\")\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "\n    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer is not set up. Returning the original image.\")\n        return np_image\n    else:\n        try:\n            restored_image = gfpgan_face_restorer.restore(np_image)\n            return restored_image\n        except Exception as e:\n            logger.error(f\"Failed to restore faces using GFPGAN: {e}\")\n            return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "\n    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer is not set up. Unable to restore faces.\")\n        return np_image\n    else:\n        try:\n            restored_image = gfpgan_face_restorer.restore(np_image)\n            return restored_image\n        except Exception as e:\n            logger.error(f\"Error in restoring faces using GFPGAN: {e}\")\n            return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "\n    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logging.warning(\"GFPGAN face restorer is not set up. Returning original image.\")\n        return np_image\n    else:\n        try:\n            restored_image = gfpgan_face_restorer.restore(np_image)\n            return restored_image\n        except Exception as e:\n            logging.error(f\"Error in restoring faces using GFPGAN: {e}\")\n            return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "\n    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logging.warning(\"GFPGAN face restorer is not set up. Returning the original image.\")\n        return np_image\n    else:\n        try:\n            restored_image = gfpgan_face_restorer.restore(np_image)\n            return restored_image\n        except Exception as e:\n            logging.warning(f\"Failed to restore faces using GFPGAN face restorer: {e}\")\n            return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "\n    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer is not set up. Returning the original image.\")\n        return np_image\n\n    try:\n        restored_image = gfpgan_face_restorer.restore(np_image)\n        return restored_image\n    except Exception as e:\n        logger.error(f\"Failed to restore faces using GFPGAN face restorer: {e}\")\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "\n    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer is not set up. Returning the original image.\")\n        return np_image\n\n    try:\n        restored_image = gfpgan_face_restorer.restore(np_image)\n        return restored_image\n    except Exception as e:\n        logger.error(f\"Failed to restore faces using GFPGAN: {e}\")\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "\n    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer is not set up. Returning the original image.\")\n        return np_image\n    else:\n        try:\n            restored_image = gfpgan_face_restorer.restore(np_image)\n            return restored_image\n        except Exception as e:\n            logger.error(f\"Error in restoring faces using GFPGAN: {e}\")\n            return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "\n    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logging.warning(\"GFPGAN face restorer is not set up. Returning original image.\")\n        return np_image\n    else:\n        try:\n            restored_image = gfpgan_face_restorer.restore(np_image)\n            return restored_image\n        except Exception as e:\n            logging.error(f\"Error in restoring faces using GFPGAN: {e}\")\n            return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "\n    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer is not set up. Returning original image.\")\n        return np_image\n\n    try:\n        restored_image = gfpgan_face_restorer.restore(np_image)\n        return restored_image\n    except Exception as e:\n        logger.error(f\"Error in restoring faces using GFPGAN: {e}\")\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "\n    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer is not set up. Returning the original image.\")\n        return np_image\n\n    try:\n        restored_image = gfpgan_face_restorer.restore(np_image)\n        return restored_image\n    except Exception as e:\n        logger.error(f\"Error occurred while restoring faces using GFPGAN: {e}\")\n        return np_image"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(model_path=dirname)\n        face_restoration_utils.face_restorers.append(codeformer)\n    except Exception as e:\n        logger.error(f\"Error setting up CodeFormer model: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        global codeformer\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.ModelLoadingError as e:\n        logger.error(f\"Error setting up FaceRestorerCodeFormer: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        face_restorer = FaceRestorerCodeFormer(dirname)\n        face_restoration_utils.face_restorers.append(face_restorer)\n    except errors.ModelLoadError as e:\n        logger.error(f\"Error setting up model: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        global codeformer\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.ModelLoadingError as e:\n        logger.error(f\"Error setting up CodeFormer model: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.ModelLoadError as e:\n        logger.error(f\"Failed to load CodeFormer model: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.ModelLoadingError as e:\n        logger.error(f\"Error setting up model: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n\n    try:\n        codeformer = FaceRestorerCodeFormer(model_path=dirname)\n    except errors.ModelLoadingError as e:\n        logger.error(f\"Error setting up CodeFormer model: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        global codeformer\n        codeformer = FaceRestorerCodeFormer(model_path=dirname)\n    except errors.ModelLoadingError as e:\n        logger.error(f\"Error setting up model: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        global codeformer\n        codeformer = FaceRestorerCodeFormer(model_path=dirname)\n    except errors.ModelLoadError as e:\n        logger.error(f\"Error setting up CodeFormer model: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(model_path=dirname)\n    except errors.ModelNotFoundError as e:\n        logger.error(f\"Model not found at {dirname}: {e}\")\n    except errors.ModelLoadError as e:\n        logger.error(f\"Error loading model at {dirname}: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.ModelLoadError as e:\n        logger.error(f\"Error setting up model: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        global codeformer\n        codeformer = FaceRestorerCodeFormer(model_path=dirname)\n    except errors.ModelLoadError as e:\n        logger.error(f\"Error setting up CodeFormer model: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.ModelLoadError as e:\n        logger.error(f\"Failed to set up model for directory '{dirname}': {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        global codeformer\n        codeformer = FaceRestorerCodeFormer(model_path=dirname)\n    except errors.ModelLoadingError as e:\n        logger.error(f\"Failed to set up model from {dirname}: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(model_path=dirname)\n    except errors.ModelLoadError as e:\n        logger.error(f\"Error setting up CodeFormer model: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except Exception as e:\n        logger.error(f\"Error setting up model for FaceRestorerCodeFormer: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        global codeformer\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.ModelLoadingError as e:\n        logger.error(f\"Error setting up CodeFormer model: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        global codeformer\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.ModelLoadingError as e:\n        logger.error(f\"Error setting up CodeFormer model: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        global codeformer\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except errors.ModelLoadingError as e:\n        logger.error(f\"Failed to set up CodeFormer model: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(model_path=dirname)\n    except errors.ModelLoadingError as e:\n        logger.error(f\"Error setting up CodeFormer model: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(model_path=dirname)\n        shared.patch_facexlib()\n        logger.info(\"GFPGAN face restorer set up successfully\")\n    except Exception as e:\n        logger.error(f\"Error setting up GFPGAN face restorer: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(model_path=dirname)\n        shared.patch_facexlib(gfpgan_face_restorer)\n        logger.info(\"GFPGAN face restorer set up successfully\")\n    except Exception as e:\n        logger.error(f\"Error setting up GFPGAN face restorer: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n\n    try:\n        shared.patch_facexlib(dirname)\n        face_restorer_gfpgan = FaceRestorerGFPGAN()\n        face_restorer_gfpgan.set_model_path(dirname)\n        face_restorer_gfpgan.setup()\n        gfpgan_face_restorer = face_restorer_gfpgan\n    except errors.ModelLoadingError as e:\n        logger.error(f\"Error setting up GFPGAN face restorer: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN()\n        gfpgan_face_restorer.setup(dirname)\n    except Exception as e:\n        logger.error(f\"Error setting up GFPGAN model: {e}\")\n        raise errors.ModelSetupError(\"Error setting up GFPGAN model\") from e"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(model_path=dirname)\n        shared.patch_facexlib(gfpgan_face_restorer)\n        logger.info(\"GFPGAN face restorer set up\")\n    except Exception as e:\n        logger.error(f\"Error setting up GFPGAN face restorer: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n\n    try:\n        shared.patch_facexlib(dirname)\n        face_restorer = FaceRestorerGFPGAN()\n        face_restorer.set_model_path(dirname)\n        face_restorer.setup()\n        gfpgan_face_restorer = face_restorer\n    except Exception as e:\n        logger.error(f\"Failed to set up GFPGAN model: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        shared.patch_facexlib(dirname)\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n    except Exception as e:\n        logger.error(f\"Failed to set up GFPGAN model: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(model_path=dirname)\n        shared.patch_facexlib()\n        logger.info(\"GFPGAN face restorer set up successfully\")\n    except Exception as e:\n        logger.exception(\"Error setting up GFPGAN face restorer: %s\", e)"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(model_path=dirname)\n    except Exception as e:\n        logger.error(f\"Error setting up GFPGAN model: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(model_path=dirname)\n    except Exception as e:\n        logger.error(f\"Error setting up GFPGAN model: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n\n    try:\n        face_restorer = FaceRestorerGFPGAN()\n        face_restorer.set_model_path(dirname)\n        face_restorer.setup()\n        gfpgan_face_restorer = face_restorer\n    except errors.ModelLoadError as e:\n        logger.error(f\"Error setting up GFPGAN face restorer: {e}\")\n    except Exception as e:\n        logger.error(f\"An unexpected error occurred during GFPGAN face restorer setup: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n\n    try:\n        face_restoration_utils.patch_facexlib(dirname)\n        gfpgan_face_restorer = FaceRestorerGFPGAN(model_path=dirname)\n        logger.info(\"GFPGAN model setup completed\")\n    except errors.ModelSetupError as e:\n        logger.error(f\"Error setting up GFPGAN model: {e}\")\n    except Exception as e:\n        logger.error(f\"Unexpected error during GFPGAN model setup: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(model_path=dirname)\n        shared.patch_facexlib(gfpgan_face_restorer)\n        logger.info(\"GFPGAN face restorer set up successfully\")\n    except Exception as e:\n        logger.error(f\"Error setting up GFPGAN face restorer: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n        logger.info(\"GFPGAN face restorer set up successfully\")\n    except Exception as e:\n        logger.error(f\"Error setting up GFPGAN face restorer: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        face_restoration.patch_facexlib(dirname)\n        gfpgan_face_restorer = FaceRestorerGFPGAN(model_path=dirname)\n    except errors.PatchError as e:\n        logger.error(f\"Failed to patch facexlib with directory {dirname}: {e}\")\n    except errors.ModelLoadingError as e:\n        logger.error(f\"Failed to load GFPGAN model from directory {dirname}: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(model_path=dirname)\n        shared.patch_facexlib(gfpgan_face_restorer)\n        logger.info(\"GFPGAN face restorer set up successfully\")\n    except errors.SetupError as e:\n        logger.error(f\"Error setting up GFPGAN face restorer: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        face_restorer = FaceRestorerGFPGAN()\n        face_restorer.model_path = dirname\n        face_restorer.net = face_restorer.load_net()\n        gfpgan_face_restorer = face_restorer\n        logger.info(\"GFPGAN face restorer set up successfully\")\n    except Exception as e:\n        logger.error(f\"Error setting up GFPGAN face restorer: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(model_path=dirname)\n        logger.info(\"GFPGAN face restorer set up successfully\")\n    except Exception as e:\n        logger.error(f\"Error setting up GFPGAN face restorer: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n        shared.patch_facexlib(gfpgan_face_restorer)\n        logger.info(\"GFPGAN face restorer set up successfully\")\n    except Exception as e:\n        logger.error(f\"Error setting up GFPGAN face restorer: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        gfpgan_face_restorer = FaceRestorerGFPGAN(model_path=dirname)\n    except errors.ModelLoadingError as e:\n        logger.error(f\"Error setting up GFPGAN model: {e}\")"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format\n  v_quat = jnp.concatenate([v, jnp.array([0.0])])\n\n  # Perform the rotation\n  q_conj = conjugate(q)\n  rotated_v_quat = multiply(q, multiply(v_quat, q_conj))\n\n  # Convert the rotated vector back to 3D space\n  rotated_v = rotated_v_quat[:3]\n\n  return rotated_v"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format\n  v_quat = jnp.concatenate([v, jnp.array([0.0])])\n\n  # Apply the rotation using the quaternion multiplication\n  rotated_v_quat = multiply(multiply(q, v_quat), conjugate(q))\n\n  # Convert the rotated quaternion back to a vector format\n  rotated_v = rotated_v_quat[:3]\n\n  return rotated_v"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format\n  v_quat = jnp.concatenate([v, jnp.array([0.0])])\n\n  # Apply the quaternion rotation\n  result = multiply(multiply(q, v_quat), conjugate(q))\n\n  # Convert the result back to a vector format\n  rotated_v = result[:3]\n\n  return rotated_v"}
{"namespace": "quaternion.rotate", "completion": "\n  # Convert the vector to a quaternion format\n  v_quat = jnp.concatenate([v, jnp.array([0.0])])\n\n  # Apply the rotation\n  q_conj = conjugate(q)\n  v_rotated = multiply(multiply(q, v_quat), q_conj)\n\n  # Convert the rotated vector back to 3D space\n  return v_rotated[:3]"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format\n  v_quat = jnp.concatenate([v, jnp.array([0.0])])\n\n  # Apply the rotation\n  rotated_v_quat = multiply(multiply(q, v_quat), conjugate(q))\n\n  # Convert the rotated quaternion back to a vector format\n  rotated_v = rotated_v_quat[:3]\n\n  return rotated_v"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format\n  v_quat = jnp.concatenate([v, jnp.array([0.0])])\n\n  # Apply the rotation\n  rotated_v_quat = multiply(multiply(q, v_quat), conjugate(q))\n\n  # Convert the rotated quaternion back to a vector format\n  rotated_v = rotated_v_quat[:3]\n\n  return rotated_v"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector v into a quaternion format\n  v_quaternion = jnp.concatenate([v, jnp.array([0.0])])\n\n  # Compute the rotated quaternion by multiplying q with v_quaternion and its conjugate\n  rotated_quaternion = multiply(multiply(q, v_quaternion), conjugate(q))\n\n  # Extract the rotated vector from the rotated quaternion\n  rotated_vector = rotated_quaternion[:3]\n\n  return rotated_vector"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format\n  v_quat = jnp.concatenate([v, jnp.array([0.0])])\n\n  # Apply the quaternion rotation\n  q_conj = conjugate(q)\n  v_rotated = multiply(multiply(q, v_quat), q_conj)\n\n  # Convert the rotated vector back to 3D space\n  return v_rotated[:3]"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format\n  v_quaternion = jnp.concatenate([v, jnp.array([0.0])])\n\n  # Apply the quaternion rotation\n  rotated_v_quaternion = multiply(multiply(q, v_quaternion), conjugate(q))\n\n  # Convert the rotated quaternion back to a vector format\n  rotated_v = rotated_v_quaternion[:3]\n\n  return rotated_v"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format\n  v_quat = jnp.concatenate([v, jnp.array([0.0])])\n\n  # Apply the rotation\n  rotated_v_quat = multiply(multiply(q, v_quat), conjugate(q))\n\n  # Convert the rotated quaternion back to a vector format\n  rotated_v = rotated_v_quat[:3]\n\n  return rotated_v"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format\n  v_quat = jnp.concatenate([v, jnp.array([0.0])])\n  \n  # Apply the rotation using quaternion multiplication\n  rotated_v_quat = multiply(multiply(q, v_quat), conjugate(q))\n  \n  # Convert the rotated quaternion back to a vector format\n  rotated_v = rotated_v_quat[:3]\n  \n  return rotated_v"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format\n  v_quaternion = jnp.concatenate([v, jnp.array([0.0])])\n\n  # Apply the rotation using quaternion multiplication\n  rotated_v_quaternion = multiply(multiply(q, v_quaternion), conjugate(q))\n\n  # Convert the rotated quaternion back to a vector format\n  rotated_v = rotated_v_quaternion[:3]\n\n  return rotated_v"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format\n  v_quat = jnp.concatenate([v, jnp.array([0.0])])\n\n  # Apply the quaternion rotation\n  rotated_v_quat = multiply(multiply(q, v_quat), conjugate(q))\n\n  # Convert the rotated quaternion back to a vector format\n  rotated_v = rotated_v_quat[:3]\n\n  return rotated_v"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format\n  v_quaternion = jnp.concatenate([v, jnp.array([0.0])])\n\n  # Apply the rotation\n  q_conjugate = conjugate(q)\n  rotated_v_quaternion = multiply(multiply(q, v_quaternion), q_conjugate)\n\n  # Convert the rotated vector back to 3D space\n  rotated_v = rotated_v_quaternion[:3]\n\n  return rotated_v"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format\n  v_quat = jnp.concatenate([v, jnp.array([0.0])])\n\n  # Apply the rotation\n  rotated_v_quat = multiply(multiply(q, v_quat), conjugate(q))\n\n  # Convert the rotated quaternion back to a vector format\n  rotated_v = rotated_v_quat[..., :3]\n\n  return rotated_v"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector v into a quaternion format\n  v_quat = jnp.concatenate([v, jnp.array([0.0])])\n\n  # Apply the rotation using quaternion multiplication\n  q_rotated = multiply(multiply(q, v_quat), conjugate(q))\n\n  # Convert the rotated quaternion back to a vector format\n  v_rotated = q_rotated[:3]\n\n  return v_rotated"}
{"namespace": "quaternion.rotate", "completion": "  v_quat = jnp.concatenate([v, jnp.zeros_like(v[..., :1])], axis=-1)\n  q_conj = conjugate(q)\n  v_rotated_quat = multiply(multiply(q, v_quat), q_conj)\n  return v_rotated_quat[..., :3]"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector v to a quaternion format\n  v_quat = jnp.concatenate([v, jnp.array([0.0])])\n\n  # Apply the quaternion rotation\n  rotated_v_quat = multiply(multiply(q, v_quat), conjugate(q))\n\n  # Convert the rotated quaternion back to a vector format\n  rotated_v = rotated_v_quat[:3]\n\n  return rotated_v"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format\n  v_quat = jnp.concatenate([v, jnp.array([0.0])])\n\n  # Apply the quaternion rotation\n  q_conj = conjugate(q)\n  v_rotated = multiply(multiply(q, v_quat), q_conj)\n\n  # Convert the rotated vector back to 3D space\n  return v_rotated[:3]"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format\n  v_quat = jnp.concatenate([v, jnp.array([0.0])])\n\n  # Apply the rotation\n  q_conj = conjugate(q)\n  v_rotated = multiply(multiply(q, v_quat), q_conj)\n\n  # Convert the rotated quaternion back to a vector format\n  return v_rotated[:3]"}
{"namespace": "quaternion.from_axis_angle", "completion": "  norm_axis = linalg.norm(axis_angle)\n  half_angle = 0.5 * norm_axis\n  sin_half_angle = jnp.sin(half_angle)\n  w = jnp.cos(half_angle)\n  xyz = jnp.divide(axis_angle, norm_axis) * sin_half_angle\n  return jnp.concatenate((xyz, w), axis=-1)"}
{"namespace": "quaternion.from_axis_angle", "completion": "  angle = jnp.linalg.norm(axis_angle)\n  half_angle = 0.5 * angle\n  axis = axis_angle / (angle + eps)\n  return jnp.concatenate([jnp.sin(half_angle) * axis, jnp.cos(half_angle)])"}
{"namespace": "quaternion.from_axis_angle", "completion": "  norm_axis = linalg.norm(axis_angle)\n  half_angle = 0.5 * norm_axis\n  k = jnp.sin(half_angle) / jnp.maximum(norm_axis, eps * jnp.ones_like(norm_axis))\n  xyz = k * axis_angle\n  w = jnp.cos(half_angle)\n  return jnp.concatenate((xyz, w), axis=-1)"}
{"namespace": "quaternion.from_axis_angle", "completion": "  norm_axis = linalg.norm(axis_angle)\n  half_angle = 0.5 * norm_axis\n  axis = axis_angle / norm_axis\n  w = jnp.cos(half_angle)\n  xyz = jnp.sin(half_angle) * axis\n  return jnp.concatenate((xyz, w), axis=-1)"}
{"namespace": "quaternion.from_axis_angle", "completion": "  angle = jnp.linalg.norm(axis_angle)\n  half_angle = angle / 2.0\n  if angle < eps:\n    return jnp.array([0.0, 0.0, 0.0, 1.0])\n  else:\n    axis = axis_angle / angle\n    return jnp.concatenate([jnp.sin(half_angle) * axis, jnp.cos(half_angle)])"}
{"namespace": "quaternion.from_axis_angle", "completion": "  angle = jnp.linalg.norm(axis_angle)\n  half_angle = angle / 2.0\n  axis = axis_angle / (angle + eps)\n  w = jnp.cos(half_angle)\n  xyz = jnp.sin(half_angle) * axis\n  return jnp.concatenate((xyz, w), axis=-1)"}
{"namespace": "quaternion.from_axis_angle", "completion": "  angle = jnp.linalg.norm(axis_angle)\n  half_angle = angle / 2.0\n  axis = axis_angle / (angle + eps)\n  w = jnp.cos(half_angle)\n  xyz = jnp.sin(half_angle) * axis\n  return jnp.concatenate((xyz, w))"}
{"namespace": "quaternion.from_axis_angle", "completion": "  magnitude = linalg.norm(axis_angle)\n  half_angle = magnitude / 2\n  axis = axis_angle / magnitude if magnitude > eps else axis_angle\n  w = jnp.cos(half_angle)\n  xyz = jnp.sin(half_angle) * axis\n  return jnp.concatenate((xyz, w), axis=-1)"}
{"namespace": "quaternion.from_axis_angle", "completion": "  angle = jnp.linalg.norm(axis_angle)\n  half_angle = angle / 2.0\n  axis = axis_angle / (angle + eps)\n  return jnp.concatenate([jnp.sin(half_angle) * axis, jnp.cos(half_angle)])"}
{"namespace": "quaternion.from_axis_angle", "completion": "  angle = jnp.linalg.norm(axis_angle)\n  half_angle = angle / 2.0\n  axis = axis_angle / angle if angle > eps else axis_angle\n  w = jnp.cos(half_angle)\n  xyz = jnp.sin(half_angle) * axis\n  return jnp.concatenate((xyz, w))"}
{"namespace": "quaternion.from_axis_angle", "completion": "  angle = jnp.linalg.norm(axis_angle)\n  half_angle = angle / 2.0\n  axis = axis_angle / (angle + eps)\n  return jnp.concatenate([jnp.sin(half_angle) * axis, jnp.cos(half_angle)])"}
{"namespace": "quaternion.from_axis_angle", "completion": "  angle = jnp.linalg.norm(axis_angle)\n  half_angle = angle / 2.0\n  axis = axis_angle / (angle + eps)\n  w = jnp.cos(half_angle)\n  xyz = jnp.sin(half_angle) * axis\n  return jnp.concatenate((xyz, w))"}
{"namespace": "quaternion.from_axis_angle", "completion": "  angle = jnp.linalg.norm(axis_angle)\n  half_angle = angle / 2\n  axis = axis_angle / (angle + eps)\n  w = jnp.cos(half_angle)\n  xyz = jnp.sin(half_angle) * axis\n  return jnp.concatenate((xyz, w))"}
{"namespace": "quaternion.from_axis_angle", "completion": "  angle = jnp.linalg.norm(axis_angle)\n  half_angle = angle / 2.0\n  axis = axis_angle / angle if angle > eps else axis_angle\n  w = jnp.cos(half_angle)\n  xyz = jnp.sin(half_angle) * axis\n  return jnp.concatenate((xyz, w), axis=-1)"}
{"namespace": "quaternion.from_axis_angle", "completion": "  angle = linalg.norm(axis_angle)\n  half_angle = 0.5 * angle\n  axis = axis_angle / (angle + eps)\n  w = jnp.cos(half_angle)\n  xyz = jnp.sin(half_angle) * axis\n  return jnp.concatenate((xyz, w), axis=-1)"}
{"namespace": "quaternion.from_axis_angle", "completion": "  angle = jnp.linalg.norm(axis_angle)\n  half_angle = angle / 2\n  axis = axis_angle / (angle + eps)\n\n  w = jnp.cos(half_angle)\n  xyz = jnp.sin(half_angle) * axis\n\n  return jnp.concatenate((xyz, w), axis=-1)"}
{"namespace": "quaternion.from_axis_angle", "completion": "  angle = jnp.linalg.norm(axis_angle)\n  half_angle = 0.5 * angle\n  axis = jnp.divide(axis_angle, angle)\n  return jnp.concatenate([jnp.sin(half_angle) * axis, jnp.cos(half_angle)], axis=-1)"}
{"namespace": "quaternion.from_axis_angle", "completion": "  angle = jnp.linalg.norm(axis_angle)\n  half_angle = angle / 2\n  axis = axis_angle / (angle + eps)\n  w = jnp.cos(half_angle)\n  xyz = jnp.sin(half_angle) * axis\n  return jnp.concatenate((xyz, w), axis=-1)"}
{"namespace": "quaternion.from_axis_angle", "completion": "  angle = jnp.linalg.norm(axis_angle)\n  half_angle = angle / 2.0\n  axis = axis_angle / (angle + eps)\n  w = jnp.cos(half_angle)\n  xyz = jnp.sin(half_angle) * axis\n  return jnp.concatenate((xyz, w), axis=-1)"}
{"namespace": "quaternion.from_axis_angle", "completion": "  angle = jnp.linalg.norm(axis_angle)\n  half_angle = angle / 2.0\n  axis = axis_angle / (angle + eps)\n  return jnp.concatenate([jnp.sin(half_angle) * axis, jnp.cos(half_angle)])"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    low = 0\n    eps = 1e-8\n    num_calls = k\n\n    # check if idx is already in the top-k\n    topk_words = model.topk(prefix, {idx: high})\n    if idx in topk_words:\n        return topk_words[idx], num_calls\n\n    # bisection search\n    logprob, calls = bisection_search(model, prefix, idx, k, low, high, eps)\n    num_calls += calls\n\n    return logprob, num_calls"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # get raw topk, could be done outside and passed in\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n    high = logit_bias[idx]\n\n    # improve estimate\n    mid = high / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n\n    logit_bias[idx] = -mid\n    return exact_solve(model, prefix, [idx], logit_bias[idx], None)"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # define the bisection search function\n    log_prob, num_calls = bisection_search(model, prefix, idx, k, high=high)\n    return log_prob, num_calls"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # initialize low\n    low = 0\n\n    # perform bisection search\n    log_prob, num_calls = bisection_search(model, prefix, idx, k, low, high)\n\n    return log_prob, num_calls"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # perform bisection search\n    log_prob, num_calls = bisection_search(model, prefix, idx, k, high=high)\n    return log_prob, num_calls"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    with ThreadPoolExecutor() as executor:\n        futures = [\n            executor.submit(\n                bisection_search, model, prefix, idx, k, 0, high\n            )\n            for _ in range(5)\n        ]\n        results = [f.result() for f in tqdm.tqdm(futures, desc=\"bisection_search\")]\n\n    best_result = min(results, key=lambda x: x[0])\n    return best_result"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # get raw topk, could be done outside and passed in\n    topk_words = model.topk(prefix, {idx: high})\n\n    # check if idx is the argmax\n    num_calls = k\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    while model.argmax(prefix, {idx: high}) != idx:\n        high *= 2\n        num_calls += k\n\n    # improve estimate\n    low = 0\n    eps = 1e-8\n    mid = (high + low) / 2\n    while high >= low + eps:\n        if model.argmax(prefix, {idx: mid}) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n\n    return -mid, num_calls"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # get raw topk, could be done outside and passed in\n    num_calls = 0\n    logit_bias = {idx: high}\n    while True:\n        topk_words = model.topk(prefix, logit_bias)\n        num_calls += 1\n        if idx in topk_words:\n            break\n        logit_bias[idx] *= 2\n\n    # bisection search\n    low = 0\n    eps = 1e-8\n    while logit_bias[idx] >= low + eps:\n        mid = (logit_bias[idx] + low) / 2\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            logit_bias[idx] = mid\n        else:\n            low = mid\n        num_calls += 1\n\n    return logit_bias[idx], num_calls"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # get raw topk, could be done outside and passed in\n    num_calls = 0\n    logit_bias = {idx: high}\n    while True:\n        topk_words = model.topk(prefix, logit_bias)\n        num_calls += 1\n        if idx in topk_words:\n            break\n        logit_bias[idx] *= 2\n\n    # bisection search\n    low = 0\n    eps = 1e-8\n    while high >= low + eps:\n        mid = (high + low) / 2\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        num_calls += 1\n\n    logprob = model.get_logprob(prefix + \" \" + model.idx2word[idx], logit_bias)\n    return logprob, num_calls"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # get raw topk, could be done outside and passed in\n    num_calls = 0\n    low = 0\n    eps = 1e-8\n    logit_bias = {idx: high}\n\n    # check if idx is the argmax\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n\n    return -mid, num_calls"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # get raw topk, could be done outside and passed in\n    num_calls = 0\n    low = 0\n    eps = 1e-8\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n\n    return -mid, num_calls"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    num_calls = 0\n    low = 0\n    # perform bisection search to find the optimal bias\n    bias, calls = bisection_search(model, prefix, idx, k, low, high)\n    num_calls += calls\n\n    # get the log probability of the target index being the top result\n    log_prob, _, _ = exact_solve(model, prefix, [idx], bias)\n    num_calls += 1\n\n    return log_prob[idx], num_calls"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    num_calls = 0\n    low = 0\n    eps = 1e-8\n    \n    # check if idx is already in the top-k\n    topk_words = model.topk(prefix)\n    if idx in topk_words:\n        return topk_words[idx], 1\n    \n    # perform bisection search\n    log_prob, calls = bisection_search(model, prefix, idx, k, low, high, eps)\n    num_calls += calls\n    \n    return log_prob, num_calls"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # get raw topk, could be done outside and passed in\n    num_calls = 0\n    low = 0\n    eps = 1e-8\n    logit_bias = {idx: high}\n\n    # check if idx is the top result\n    if model.argmax(prefix) == idx:\n        return 0, 1\n\n    # initialize high\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n\n    return -mid, num_calls"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "        num_calls = 0\n        low = 0\n        eps = 1e-8\n\n        # check if idx is the argmax\n        num_calls += k\n        if model.argmax(prefix) == idx:\n            return 0, num_calls\n\n        # initialize high\n        logit_bias = {idx: high}\n        while model.argmax(prefix, logit_bias) != idx:\n            logit_bias[idx] *= 2\n            num_calls += k\n        high = logit_bias[idx]\n\n        # improve estimate\n        mid = (high + low) / 2\n        while high >= low + eps:\n            logit_bias[idx] = mid\n            if model.argmax(prefix, logit_bias) == idx:\n                high = mid\n            else:\n                low = mid\n            mid = (high + low) / 2\n            num_calls += k\n\n        return -mid, num_calls"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    num_calls = 0\n    low = 0\n    eps = 1e-8\n    logit_bias = {idx: high}\n\n    while model.argmax(prefix, logit_bias) != idx:\n        high *= 2\n        logit_bias[idx] = high\n        num_calls += k\n\n    # improve estimate\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n\n    return -mid, num_calls"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # get raw topk, could be done outside and passed in\n    topk_words = model.topk(prefix)\n\n    # check if idx is in the topk\n    if idx in topk_words:\n        return 0, 1\n\n    # perform bisection search\n    log_prob, num_calls = bisection_search(model, prefix, idx, k, high=high)\n    return log_prob, num_calls"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # calculate the log probability of the index being the top result under the adjusted conditions\n    log_prob, num_calls = bisection_search(model, prefix, idx, k, high=high)\n    return log_prob, num_calls"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # get raw topk, could be done outside and passed in\n    num_calls = 0\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate using bisection search\n    low = 0\n    eps = 1e-8\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n\n    return -mid, num_calls"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    num_calls = 0\n    logit_bias = {idx: high}\n    while True:\n        topk_words = model.topk(prefix, logit_bias)\n        num_calls += 1\n        if idx in topk_words:\n            return topk_words[idx], num_calls\n        else:\n            high *= 2\n            logit_bias[idx] = high"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The output_dir must be an instance of the Dir class.\")\n\n    if not output_dir.url or not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(\"The output_dir must be a valid S3 directory.\")\n\n    # Check if the directory is empty\n    # Implementation to check if the S3 directory is empty can be added here"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The output_dir must be an instance of the Dir class.\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(\"The output_dir must start with 's3://'.\")\n\n    # Check if append or overwrite is True, and raise an error since it is not implemented\n    if append or overwrite:\n        raise NotImplementedError(\"Appending and overwriting data is currently not supported.\")\n\n    # Check if the S3 bucket directory is empty\n    s3 = boto3.client(\"s3\")\n    response = s3.list_objects_v2(Bucket=output_dir.url.split(\"/\")[2], Prefix=\"/\".join(output_dir.url.split(\"/\")[3:]))\n    if \"Contents\" in response:\n        raise ValueError(f\"The directory {output_dir.url} is not empty.\")"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The output_dir must be an instance of the Dir class.\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(\"The output_dir must start with 's3://'.\")\n\n    if append:\n        raise NotImplementedError(\"Appending data to the directory is not currently supported.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting data in the directory is not currently supported.\")\n\n    # Check if the directory is empty\n    # Implementation to check if the directory is empty goes here\n\n    # If the directory is not empty, raise an error\n    if not is_empty:\n        raise ValueError(\"The directory is not empty.\")"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The output_dir must be an instance of the Dir class.\")\n\n    if not output_dir.url or not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(\"The output_dir URL must start with 's3://'.\")\n\n    # Check if the directory is empty\n    s3 = boto3.client(\"s3\")  # Assuming boto3 is available\n    bucket, prefix = output_dir.url.replace(\"s3://\", \"\").split(\"/\", 1)\n    objects = s3.list_objects_v2(Bucket=bucket, Prefix=prefix)\n\n    if objects.get(\"KeyCount\", 0) > 0:\n        raise ValueError(f\"The directory {output_dir.url} is not empty.\")\n\n    if append:\n        raise NotImplementedError(\"Appending data to the directory is not implemented.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting data in the directory is not implemented.\")"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"output_dir must be an instance of the Dir class\")\n\n    if not output_dir.url or not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(\"output_dir must be an S3 directory (start with 's3://')\")\n\n    # Check if the directory is empty\n    # Code to check if the directory is empty goes here\n    # If the directory is not empty, raise an error\n    # If the directory is empty, the function completes successfully"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"output_dir must be an instance of the Dir class.\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(\"The directory must be in an S3 bucket and start with 's3://'.\")\n\n    # Check if the directory is empty\n    # Implementation of checking if the directory is empty in an S3 bucket\n\n    if append:\n        raise NotImplementedError(\"Appending data to the directory is not yet supported.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting data in the directory is not yet supported.\")"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The output_dir must be an instance of the Dir class.\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(\"The output_dir URL must start with 's3://'.\")\n\n    if append:\n        raise NotImplementedError(\"Appending data to the directory is currently not implemented.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting data in the directory is currently not implemented.\")\n\n    # Check if the directory is empty\n    # Add code here to check if the directory in the S3 bucket is empty"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"output_dir must be an instance of the Dir class\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(\"The directory URL must start with 's3://'\")\n\n    # Check if the directory is empty\n    # Add code to check if the directory is empty\n    # If not empty, raise an error\n    # If append or overwrite is True, implement the logic to support it\n\n    if not append and not overwrite:\n        if not _BOTO3_AVAILABLE:\n            raise RuntimeError(\"Boto3 is not available. Please install boto3 to use this function.\")\n\n        s3 = boto3.client(\"s3\")\n        response = s3.list_objects_v2(Bucket=output_dir.url.split(\"/\")[2], Prefix=\"/\".join(output_dir.url.split(\"/\")[3:]))\n        if \"Contents\" in response:\n            raise ValueError(f\"The directory {output_dir.url} is not empty.\")"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The output directory must be an instance of the Dir class.\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(\"The output directory must be in an S3 bucket.\")\n\n    if append:\n        raise NotImplementedError(\"Appending data to the directory is not currently supported.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting data in the directory is not currently supported.\")\n\n    # Check if the directory is empty\n    s3 = boto3.client(\"s3\")  # Assuming boto3 is available\n\n    try:\n        response = s3.list_objects_v2(Bucket=output_dir.url.split(\"/\")[2], Prefix=\"/\".join(output_dir.url.split(\"/\")[3:]))\n        if response[\"KeyCount\"] > 0:\n            raise ValueError(f\"The directory {output_dir.url} is not empty.\")\n    except botocore.exceptions.ClientError as e:\n        if e.response[\"Error\"][\"Code\"] != \"NoSuchKey\":\n            raise e"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The output_dir must be an instance of the Dir class.\")\n\n    if not output_dir.url or not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(\"The output_dir must be an S3 directory specified with a URL starting with 's3://'.\")\n\n    # Check if the directory is empty\n    # Implementation of checking if the S3 directory is empty can be added here\n    # If the directory is not empty, raise an error\n    # If append or overwrite is True, additional logic for handling those cases can be added here\n    if not append and not overwrite:\n        raise NotImplementedError(\"Appending or overwriting data in the directory is not implemented.\")"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The output_dir must be an instance of the Dir class.\")\n\n    if not output_dir.url or not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(\"The output_dir must be an S3 directory (start with 's3://').\")\n\n    # Check if the directory is empty\n    # Add code here to check if the directory is empty in the S3 bucket\n    # If the directory is not empty, raise an error\n\n    if append:\n        raise NotImplementedError(\"Appending data to the directory is currently not implemented.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting data in the directory is currently not implemented.\")"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The output_dir must be an instance of the Dir class.\")\n\n    if not output_dir.url or not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(\"The output_dir must be an S3 directory specified with a URL starting with 's3://'.\")\n\n    # Check if the directory is empty\n    s3 = boto3.client(\"s3\")\n    response = s3.list_objects_v2(Bucket=output_dir.url.split(\"/\")[2], Prefix=\"/\".join(output_dir.url.split(\"/\")[3:]))\n    if response.get(\"Contents\") and not append and not overwrite:\n        raise ValueError(f\"The directory {output_dir.url} is not empty.\")"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The output_dir must be an instance of the Dir class.\")\n\n    if not output_dir.url or not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(\"The output_dir must be an S3 directory (start with 's3://').\")\n\n    # Check if the directory is empty\n    bucket, *path_parts = output_dir.url.replace(\"s3://\", \"\").split(\"/\")\n    s3 = boto3.client(\"s3\")\n\n    try:\n        response = s3.list_objects_v2(Bucket=bucket, Prefix=\"/\".join(path_parts))\n        if response.get(\"KeyCount\", 0) > 0:\n            raise ValueError(f\"The directory {output_dir.url} is not empty.\")\n    except botocore.exceptions.ClientError as e:\n        if e.response[\"Error\"][\"Code\"] != \"NoSuchKey\":\n            raise e"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The output_dir must be an instance of the Dir class.\")\n\n    if not output_dir.url or not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(\"The output_dir must be an S3 directory specified with a URL starting with 's3://'.\")\n\n    # Check if the directory is empty\n    # This part of the function is not implemented as it depends on the specific S3 bucket and its contents.\n    # You would need to use the boto3 library to interact with the S3 bucket and check if the directory is empty.\n    # The implementation would involve listing the objects in the directory and checking if the list is empty.\n\n    if append:\n        raise NotImplementedError(\"Appending data to the directory is currently not implemented.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting data in the directory is currently not implemented.\")"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"output_dir must be an instance of the Dir class.\")\n\n    if not output_dir.url or not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(\"The directory path must start with 's3://'.\")\n\n    # Check if the directory is empty\n    s3 = boto3.client('s3')\n    try:\n        response = s3.list_objects(Bucket=output_dir.url.split(\"/\")[2], Prefix=\"/\".join(output_dir.url.split(\"/\")[3:]))\n        if 'Contents' in response:\n            if not append and not overwrite:\n                raise ValueError(\"The directory is not empty and appending or overwriting is not allowed.\")\n            elif append or overwrite:\n                raise NotImplementedError(\"Appending or overwriting data in the directory is not implemented.\")\n    except botocore.exceptions.ClientError as e:\n        if e.response['Error']['Code'] != 'NoSuchKey':\n            raise"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The output_dir must be an instance of the Dir class.\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(\"The output_dir URL must start with 's3://'.\")\n\n    # Check if the directory is empty\n    # Add your code here to check if the directory is empty"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The output_dir must be an instance of the Dir class.\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(\"The output_dir must start with 's3://'.\")\n\n    if append:\n        raise NotImplementedError(\"Appending data to the directory is not currently supported.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting data in the directory is not currently supported.\")\n\n    client = boto3.client(\"s3\")  # Assuming that the boto3 library is available\n\n    try:\n        response = client.list_objects(Bucket=output_dir.url.split(\"/\")[2], Prefix=\"/\".join(output_dir.url.split(\"/\")[3:]))\n        if \"Contents\" in response:\n            raise ValueError(f\"The directory {output_dir.url} is not empty.\")\n    except botocore.exceptions.ClientError as e:\n        error_code = e.response[\"Error\"][\"Code\"]\n        if error_code != \"NoSuchKey\":\n            raise e"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The output_dir must be an instance of the Dir class.\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(\"The output_dir must start with 's3://'.\")\n\n    # Check if the directory is empty\n    client = boto3.client(\"s3\")\n    response = client.list_objects(Bucket=output_dir.url.split(\"/\")[2], Prefix=\"/\".join(output_dir.url.split(\"/\")[3:]))\n    if \"Contents\" in response and len(response[\"Contents\"]) > 0:\n        raise ValueError(f\"The directory {output_dir.url} is not empty.\")\n\n    if append:\n        raise NotImplementedError(\"Appending data to the directory is not yet supported.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting data in the directory is not yet supported.\")"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The output directory must be an instance of the Dir class.\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(\"The output directory must start with 's3://'.\")\n\n    if append:\n        raise NotImplementedError(\"Appending data to the directory is not currently supported.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting data in the directory is not currently supported.\")\n\n    # Check if the directory is empty in the S3 bucket\n    s3 = boto3.client(\"s3\") if _BOTO3_AVAILABLE else None\n    if s3:\n        bucket, prefix = parse_s3_url(output_dir.url)\n        try:\n            response = s3.list_objects_v2(Bucket=bucket, Prefix=prefix)\n            if \"Contents\" in response:\n                raise ValueError(f\"The directory {output_dir.url} is not empty.\")\n        except botocore.exceptions.ClientError as e:\n            error_code = e.response[\"Error\"][\"Code\"]\n            if error_code != \"NoSuchKey\":\n                raise ValueError(f\"An error occurred while checking the directory {output_dir.url}: {error_code}\")\n    else:\n        raise RuntimeError(\"Boto3 library is not available. Please install boto3 to use this function.\")"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The output_dir parameter must be an instance of the Dir class.\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(\"The output_dir must start with 's3://'.\")\n\n    # Check if appending or overwriting is allowed\n    if append:\n        raise NotImplementedError(\"Appending data to the directory is currently not implemented.\")\n    if overwrite:\n        raise NotImplementedError(\"Overwriting data in the directory is currently not implemented.\")\n\n    # Check if the directory is empty\n    client = boto3.client(\"s3\")  # Assuming boto3 is available\n    bucket, prefix = output_dir.url.replace(\"s3://\", \"\").split(\"/\", 1)\n    objects = client.list_objects_v2(Bucket=bucket, Prefix=prefix)\n\n    if \"Contents\" in objects:\n        if len(objects[\"Contents\"]) > 0:\n            raise ValueError(f\"The directory {output_dir.url} is not empty.\")\n    else:\n        raise ValueError(f\"The directory {output_dir.url} does not exist or is not accessible.\")"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "\n    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if \"Contents\" in objects:\n        for obj in objects[\"Contents\"]:\n            if obj[\"Key\"].endswith(\"index.json\"):\n                raise ValueError(f\"The directory {output_dir.path} already contains an index file.\")\n\n    # If no index file is found, delete all objects within the specified prefix in the bucket\n    if \"Contents\" in objects:\n        for obj in objects[\"Contents\"]:\n            s3.delete_object(Bucket=obj.netloc, Key=obj[\"Key\"])"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    index_file_exists = False\n\n    for content in objects.get(\"Contents\", []):\n        if content[\"Key\"].endswith(\"index.json\"):\n            index_file_exists = True\n            break\n\n    if index_file_exists:\n        raise RuntimeError(f\"The provided output_dir `{output_dir.path}` already contains an index file.\")\n\n    if objects[\"KeyCount\"] > 0:\n        # Delete all objects within the specified prefix in the bucket\n        s3.delete_objects(\n            Bucket=obj.netloc,\n            Delete={\n                \"Objects\": [{\"Key\": content[\"Key\"]} for content in objects.get(\"Contents\", [])],\n                \"Quiet\": True,\n            },\n        )"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if \"Contents\" in objects:\n        for content in objects[\"Contents\"]:\n            if content[\"Key\"].endswith(\"index.json\"):\n                raise RuntimeError(f\"The directory already contains an index file: {content['Key']}\")\n            else:\n                s3.delete_object(Bucket=obj.netloc, Key=content[\"Key\"])"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "\n    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if \"Contents\" in objects and any(obj[\"Key\"].endswith(\"/index.json\") for obj in objects[\"Contents\"]):\n        raise RuntimeError(f\"The provided output_dir `{output_dir.path}` already contains an index file.\")\n\n    if \"Contents\" in objects and not any(obj[\"Key\"].endswith(\"/index.json\") for obj in objects[\"Contents\"]):\n        for obj in objects[\"Contents\"]:\n            s3.delete_object(Bucket=obj[\"Bucket\"], Key=obj[\"Key\"])\n\n    if \"CommonPrefixes\" in objects:\n        for prefix in objects[\"CommonPrefixes\"]:\n            s3.delete_object(Bucket=obj.netloc, Key=prefix[\"Prefix\"])"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "\n    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if \"Contents\" in objects:\n        for obj in objects[\"Contents\"]:\n            if obj[\"Key\"].endswith(\"index.json\"):\n                raise ValueError(f\"The directory {output_dir.url} already contains an index file named 'index.json'.\")\n\n    # If index file is not found, delete all objects within the specified prefix in the bucket\n    if objects[\"KeyCount\"] > 0:\n        for obj in objects[\"Contents\"]:\n            s3.delete_object(Bucket=obj.netloc, Key=obj[\"Key\"])"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if objects[\"KeyCount\"] > 0:\n        for content in objects.get(\"Contents\", []):\n            if content[\"Key\"].endswith(\"index.json\"):\n                raise RuntimeError(f\"The provided output_dir `{output_dir.path}` already contains an index file.\")\n\n        # No index file found, delete all objects within the specified prefix in the bucket\n        for content in objects.get(\"Contents\", []):\n            s3.delete_object(Bucket=obj.netloc, Key=content[\"Key\"])"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if \"Contents\" in objects and any(obj[\"Key\"].endswith(\"index.json\") for obj in objects[\"Contents\"]):\n        raise RuntimeError(f\"The provided output_dir `{output_dir.path}` already contains an index file `index.json`.\")\n\n    # Delete all objects within the specified prefix in the bucket\n    for obj in objects.get(\"Contents\", []):\n        s3.delete_object(Bucket=obj.netloc, Key=obj[\"Key\"])"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        raise ValueError(\"The provided folder should start with s3://. Found None.\")\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if \"Contents\" in objects:\n        for obj in objects[\"Contents\"]:\n            if obj[\"Key\"].endswith(\"index.json\"):\n                raise RuntimeError(f\"The provided output_dir `{output_dir.path}` already contains an index file.\")\n\n    # Delete all objects within the specified prefix in the bucket\n    if \"Contents\" in objects:\n        for obj in objects[\"Contents\"]:\n            s3.delete_object(Bucket=obj.netloc, Key=obj[\"Key\"])"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if \"Contents\" in objects:\n        for obj in objects[\"Contents\"]:\n            if obj[\"Key\"].endswith(\"index.json\"):\n                raise ValueError(f\"The directory already contains an index file: {obj['Key']}\")\n    \n    # If index file not found, delete all objects within the specified prefix in the bucket\n    if \"Contents\" in objects:\n        for obj in objects[\"Contents\"]:\n            s3.delete_object(Bucket=obj.netloc, Key=obj[\"Key\"])"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if objects[\"KeyCount\"] > 0:\n        for content in objects.get(\"Contents\", []):\n            if os.path.basename(content[\"Key\"]) == \"index.json\":\n                raise RuntimeError(f\"The provided output_dir `{output_dir.path}` already contains an index file.\")\n            else:\n                s3.delete_object(Bucket=obj.netloc, Key=content[\"Key\"])"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "\n    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # Check if the index file exists\n    index_file_exists = False\n    for content in objects.get(\"Contents\", []):\n        if content[\"Key\"].endswith(\"index.json\"):\n            index_file_exists = True\n            break\n\n    if index_file_exists:\n        raise RuntimeError(f\"The directory {output_dir.path} already contains an index file named 'index.json'.\")\n\n    # If index file is not found, delete all objects within the specified prefix in the bucket\n    for content in objects.get(\"Contents\", []):\n        s3.delete_object(Bucket=obj.netloc, Key=content[\"Key\"])"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    \n    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # Check if the index file exists\n    index_file_exists = False\n    for content in objects.get(\"Contents\", []):\n        if content[\"Key\"].endswith(\"index.json\"):\n            index_file_exists = True\n            break\n\n    if index_file_exists:\n        raise RuntimeError(f\"The provided output_dir `{output_dir.path}` already contains an index file named 'index.json'.\")\n\n    # Delete all objects within the specified prefix in the bucket\n    for content in objects.get(\"Contents\", []):\n        s3.delete_object(Bucket=obj.netloc, Key=content[\"Key\"])"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        raise ValueError(\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if objects[\"KeyCount\"] > 0:\n        for content in objects.get(\"Contents\", []):\n            if content[\"Key\"].endswith(\"index.json\"):\n                raise ValueError(f\"The directory already contains an index file: {content['Key']}.\")\n\n        # If no index file is found, delete all objects within the specified prefix in the bucket\n        for content in objects.get(\"Contents\", []):\n            s3.delete_object(Bucket=obj.netloc, Key=content[\"Key\"])"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "\n    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if \"Contents\" in objects:\n        for obj in objects[\"Contents\"]:\n            if obj[\"Key\"] == \"index.json\":\n                raise ValueError(f\"The directory already contains an index file named 'index.json'.\")\n\n    if \"CommonPrefixes\" not in objects:\n        return\n\n    # Delete all objects within the specified prefix in the bucket\n    for prefix in objects[\"CommonPrefixes\"]:\n        s3.delete_objects(\n            Bucket=obj.netloc,\n            Delete={\n                \"Objects\": [\n                    {\n                        \"Key\": prefix[\"Prefix\"],\n                    }\n                ]\n            }\n        )"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    index_file_exists = False\n    for content in objects.get(\"Contents\", []):\n        if content[\"Key\"].endswith(\"index.json\"):\n            index_file_exists = True\n            break\n\n    if index_file_exists:\n        raise ValueError(f\"The directory {output_dir.url} already contains an index file named 'index.json'.\")\n\n    # Delete all objects within the specified prefix in the bucket\n    for content in objects.get(\"Contents\", []):\n        s3.delete_object(Bucket=obj.netloc, Key=content[\"Key\"])"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "\n    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        raise ValueError(\"The provided folder should start with s3://\")\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # Check if index.json already exists\n    for content in objects.get('Contents', []):\n        if content['Key'].endswith('index.json'):\n            raise ValueError(f\"The directory {output_dir.url} already contains an index file named 'index.json'.\")\n\n    # If index.json does not exist, delete all objects within the specified prefix\n    if objects[\"KeyCount\"] > 0:\n        s3.delete_objects(\n            Bucket=obj.netloc,\n            Delete={\n                'Objects': [{'Key': content['Key']} for content in objects.get('Contents', [])],\n                'Quiet': False\n            }\n        )"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "\n    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if \"Contents\" in objects:\n        for obj in objects[\"Contents\"]:\n            if obj[\"Key\"].endswith(\"index.json\"):\n                raise ValueError(f\"The directory {output_dir.url} already contains an index file named 'index.json'.\")\n\n    # If index file is not found, delete all objects within the specified prefix in the bucket\n    if \"Contents\" in objects:\n        for obj in objects[\"Contents\"]:\n            s3.delete_object(Bucket=obj.netloc, Key=obj[\"Key\"])"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        raise ValueError(\"The provided folder should start with s3://. Found None.\")\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if \"Contents\" in objects and any(obj[\"Key\"].endswith(\"index.json\") for obj in objects[\"Contents\"]):\n        raise RuntimeError(f\"The provided output_dir `{output_dir.path}` already contains an index file.\")\n\n    if \"Contents\" in objects:\n        for obj in objects[\"Contents\"]:\n            s3.delete_object(Bucket=obj[\"Bucket\"], Key=obj[\"Key\"])\n\n    if \"CommonPrefixes\" in objects:\n        for prefix in objects[\"CommonPrefixes\"]:\n            s3.delete_object(Bucket=obj[\"Bucket\"], Key=prefix[\"Prefix\"])"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if \"Contents\" in objects and any(obj[\"Key\"].endswith(\"index.json\") for obj in objects[\"Contents\"]):\n        raise RuntimeError(f\"The provided output_dir `{output_dir.path}` already contains an index file.\")\n\n    # Delete all objects within the specified prefix in the bucket\n    for obj in objects.get(\"Contents\", []):\n        s3.delete_object(Bucket=obj.netloc, Key=obj[\"Key\"])"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "\n    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # Check if \"index.json\" exists in the directory\n    index_file_exists = False\n    for content in objects.get('Contents', []):\n        if content['Key'].endswith(\"index.json\"):\n            index_file_exists = True\n            break\n\n    if index_file_exists:\n        raise RuntimeError(f\"The provided output_dir `{output_dir.path}` already contains an index file named 'index.json'.\")\n\n    # If \"index.json\" does not exist, delete all objects within the specified prefix in the bucket\n    for content in objects.get('Contents', []):\n        s3.delete_object(Bucket=obj.netloc, Key=content['Key'])"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            node_rank = 0  # Assume non-distributed environment or rank determination handled externally\n\n        if self.rank != node_rank:\n            # Wait until the merged index file is available\n            while not os.path.exists(os.path.join(self._cache_dir, f\"{node_rank}.{_INDEX_FILENAME}\")):\n                sleep(1)\n            return  # Non-master nodes (rank != 0) wait and then return\n\n        # Master node (rank 0) proceeds with the merge\n        while len(os.listdir(self._cache_dir)) < num_workers:\n            sleep(1)  # Wait for all parts to be available\n\n        # Perform the merge operation\n        # Combine individual index files into a single, unified index file\n        # Write the merged index file to the cache directory"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if self.rank != 0:\n            # Wait for the master node to perform the merge\n            while not self.filled:\n                sleep(1)\n            return\n\n        # Master node (rank 0) performs the merge\n        while not all(\n            os.path.exists(os.path.join(self._cache_dir, f\"{i}.{_INDEX_FILENAME}\")) for i in range(num_workers)\n        ):\n            sleep(1)\n\n        # Perform the merge operation\n        # ... (merge logic goes here)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None or node_rank == 0:\n            # Master node or non-distributed environment\n            while not self.filled:\n                sleep(1)\n            if node_rank == 0:\n                # Perform the merge operation\n                # Code for merging the index files goes here\n                pass\n        else:\n            # Non-master node in a distributed environment\n            while not self.filled:\n                sleep(1)\n            # Wait for the merged index file to be available\n            while not os.path.exists(os.path.join(self._cache_dir, f\"0.{_INDEX_FILENAME}\")):\n                sleep(1)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if self.rank != 0:\n            # Wait for the master node to perform the merge\n            while not os.path.exists(os.path.join(self._cache_dir, f\"0.{_INDEX_FILENAME}\")):\n                sleep(1)\n\n        # Master node proceeds with the merge\n        if self.rank == 0:\n            index_files = [f for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)]\n            while len(index_files) < num_workers:\n                # Wait for all index parts to be available\n                sleep(1)\n                index_files = [f for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)]\n\n            # Perform the merge\n            merged_index = {}\n            for file in index_files:\n                with open(os.path.join(self._cache_dir, file), \"r\") as f:\n                    data = json.load(f)\n                    merged_index.update(data[\"chunks\"])\n\n            # Write the merged index to a file\n            with open(os.path.join(self._cache_dir, f\"merged_index.{_INDEX_FILENAME}\"), \"w\") as out:\n                json.dump(merged_index, out, sort_keys=True)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            # Non-distributed environment or rank determination handled externally\n            return\n\n        if node_rank != 0:\n            # Wait until the merged index file is available\n            while not os.path.exists(os.path.join(self._cache_dir, f\"0.{_INDEX_FILENAME}\")):\n                sleep(1)\n\n        else:\n            # Master node (rank 0) responsible for merging\n            while True:\n                files = os.listdir(self._cache_dir)\n                index_files = [f for f in files if f.endswith(_INDEX_FILENAME)]\n                if len(index_files) == num_workers:\n                    # All parts of the index are available, proceed with the merge\n                    merged_index = {}\n                    for index_file in index_files:\n                        with open(os.path.join(self._cache_dir, index_file), \"r\") as f:\n                            data = json.load(f)\n                            merged_index.update(data[\"chunks\"])\n\n                    # Write the merged index to a single file\n                    with open(os.path.join(self._cache_dir, f\"merged_index.{_INDEX_FILENAME}\"), \"w\") as out:\n                        json.dump(merged_index, out, sort_keys=True)\n                    break\n                else:\n                    sleep(1)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if self.rank != 0:\n            # Wait for the master node to finish merging\n            while not self.filled:\n                sleep(1)\n            return\n\n        if num_workers > 1:\n            # Wait for all parts to be available\n            while len(os.listdir(self._cache_dir)) < num_workers:\n                sleep(1)\n\n        # Perform the merge operation\n        self._merge_index_files()"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if self.rank == 0:\n            while not self.filled:\n                sleep(1)\n            self.write_chunks_index()"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if self.rank != 0 and node_rank is None:\n            # If not the master node and node_rank is not specified, wait until the merged index file is available\n            while not os.path.exists(os.path.join(self._cache_dir, f\"0.{_INDEX_FILENAME}\")):\n                sleep(5)\n            return\n\n        # If the master node or node_rank is specified as 0, proceed with the merge process\n        while not self.filled:\n            # Wait until all parts of the index are available\n            sleep(5)\n\n        if self.rank == 0 or (node_rank is not None and node_rank == 0):\n            # Only the master node (rank 0) proceeds with the merge\n            index_files = [f for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME) and f != f\"0.{_INDEX_FILENAME}\"]\n            if len(index_files) == num_workers - 1:\n                # All parts of the index are available, proceed with the merge\n                chunks_info = []\n                for file in index_files:\n                    with open(os.path.join(self._cache_dir, file), \"r\") as f:\n                        data = json.load(f)\n                        chunks_info.extend(data[\"chunks\"])\n\n                # Write the merged index file\n                with open(os.path.join(self._cache_dir, f\"0.{_INDEX_FILENAME}\"), \"w\") as out:\n                    json.dump({\"chunks\": chunks_info, \"config\": self.get_config()}, out, sort_keys=True)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if self.rank != 0:\n            while not self.filled:\n                sleep(1)\n            return\n\n        # Wait for all workers to finish writing index files\n        while not self.filled:\n            sleep(1)\n\n        # Proceed with merging\n        index_files = [f for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)]\n        while len(index_files) < num_workers:\n            index_files = [f for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)]\n            sleep(1)\n\n        # Merge index files\n        merged_index = {}\n        for file in index_files:\n            with open(os.path.join(self._cache_dir, file), \"r\") as f:\n                data = json.load(f)\n                chunks = data[\"chunks\"]\n                for chunk in chunks:\n                    merged_index[chunk[\"filename\"]] = chunk\n\n        # Write the merged index to a file\n        merged_index_file = os.path.join(self._cache_dir, \"merged_index.json\")\n        with open(merged_index_file, \"w\") as f:\n            json.dump(merged_index, f, sort_keys=True)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            node_rank = 0\n\n        while True:\n            files = os.listdir(self._cache_dir)\n            index_files = [f for f in files if f.endswith(_INDEX_FILENAME)]\n            if len(index_files) == num_workers:\n                break\n            sleep(1)\n\n        if self.rank != node_rank:\n            while not os.path.exists(os.path.join(self._cache_dir, f\"{node_rank}.{_INDEX_FILENAME}\")):\n                sleep(1)\n            return\n\n        # Master node (rank 0) proceeds with the merge\n        index_data = []\n        for i in range(num_workers):\n            with open(os.path.join(self._cache_dir, f\"{i}.{_INDEX_FILENAME}\"), \"r\") as f:\n                data = json.load(f)\n                index_data.extend(data[\"chunks\"])\n\n        with open(os.path.join(self._cache_dir, f\"merged_index.{_INDEX_FILENAME}\"), \"w\") as out:\n            json.dump({\"chunks\": index_data, \"config\": self.get_config()}, out, sort_keys=True)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "\n        if self.rank == 0 and self.filled:\n            # Perform the merge operation only if it's the master node (rank 0) and all parts are available\n            index_files = [f for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)]\n            while len(index_files) < num_workers:\n                # Wait for all index parts to be available\n                sleep(1)\n                index_files = [f for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)]\n\n            # Perform the actual merge operation\n            merged_index = {}\n            for file in index_files:\n                with open(os.path.join(self._cache_dir, file), \"r\") as f:\n                    data = json.load(f)\n                    merged_index.update(data[\"chunks\"])\n\n            # Write the merged index to a new file\n            merged_file_path = os.path.join(self._cache_dir, f\"merged_index.{_INDEX_FILENAME}\")\n            with open(merged_file_path, \"w\") as f:\n                json.dump(merged_index, f, sort_keys=True)\n\n            # Notify other nodes that the merged index is available\n            if self._distributed_env.world_size > 1:\n                # Notify other nodes that the merged index is available\n                self._distributed_env.barrier()\n\n        elif self.rank != 0:\n            # Non-master nodes wait until the merged index file is available\n            while not os.path.exists(os.path.join(self._cache_dir, f\"merged_index.{_INDEX_FILENAME}\")):\n                sleep(1)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None or node_rank == 0:\n            while True:\n                if len(os.listdir(self._cache_dir)) >= num_workers:\n                    break\n                sleep(1)\n            if node_rank == 0:\n                # Perform the merge operation\n                pass\n        else:\n            while not os.path.exists(os.path.join(self._cache_dir, f\"0.{_INDEX_FILENAME}\")):\n                sleep(1)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            # Non-distributed environment or rank determination handled externally\n            return\n\n        if node_rank != 0:\n            # Wait until the merged index file is available\n            while not os.path.exists(os.path.join(self._cache_dir, f\"0.{_INDEX_FILENAME}\")):\n                sleep(1)\n            return\n\n        # Master node (rank 0) proceeds with the merge\n        while len(os.listdir(self._cache_dir)) < num_workers:\n            # Wait until all parts are available\n            sleep(1)\n\n        # Perform the merge operation\n        # Combine individual index files into a single, unified index file\n        # Write the merged index file to the cache directory"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "\n        if node_rank is None or node_rank == 0:\n            while True:\n                if len(os.listdir(self._cache_dir)) >= num_workers:\n                    break\n                sleep(1)\n\n            if node_rank == 0:\n                # Perform the merge operation\n                # Combine individual index files into a single, unified index file\n                # Write the merged index file to the cache directory\n                pass"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "\n        if self.rank != (node_rank or 0):\n            # Wait for the master node to perform the merge\n            while not self.filled:\n                sleep(1)\n            return\n\n        while not self.filled:\n            # Wait for all index parts to be available\n            sleep(1)\n\n        # Perform the merge operation\n        self.write_chunks_index()"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            # Non-distributed environment or rank determination handled externally\n            return\n        if node_rank != 0:\n            # Wait until the merged index file is available for non-master nodes\n            while not os.path.exists(os.path.join(self._cache_dir, f\"0.{_INDEX_FILENAME}\")):\n                sleep(1)\n            return\n\n        # Master node (rank 0) proceeds with the merge\n        while len(os.listdir(self._cache_dir)) < num_workers:\n            # Wait until all parts of the index are available\n            sleep(1)\n\n        # Merge the index files\n        merged_index = []\n        for i in range(num_workers):\n            with open(os.path.join(self._cache_dir, f\"{i}.{_INDEX_FILENAME}\"), \"r\") as f:\n                data = json.load(f)\n                merged_index.extend(data[\"chunks\"])\n\n        # Write the merged index to a single file\n        with open(os.path.join(self._cache_dir, f\"merged.{_INDEX_FILENAME}\"), \"w\") as out:\n            json.dump(merged_index, out, sort_keys=True)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # Determine if the current node is the master node\n        is_master_node = (node_rank is not None and node_rank == 0)\n\n        # If not the master node, wait for the merged index file to be available\n        if not is_master_node:\n            while not os.path.exists(os.path.join(self._cache_dir, f\"0.{_INDEX_FILENAME}\")):\n                sleep(1)\n            return\n\n        # If the master node, wait for all index parts to be available\n        while len([f for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)]) < num_workers:\n            sleep(1)\n\n        # Perform the merge operation\n        index_files = [f for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)]\n        merged_index = {\"chunks\": [], \"config\": self.get_config()}\n        for file in index_files:\n            with open(os.path.join(self._cache_dir, file), \"r\") as f:\n                data = json.load(f)\n                merged_index[\"chunks\"].extend(data[\"chunks\"])\n\n        # Write the merged index to a file\n        with open(os.path.join(self._cache_dir, f\"merged_index.{_INDEX_FILENAME}\"), \"w\") as out:\n            json.dump(merged_index, out, sort_keys=True)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if self.rank != 0:\n            # Wait for the master node to finish the merge\n            while not os.path.exists(os.path.join(self._cache_dir, f\"0.{_INDEX_FILENAME}\")):\n                sleep(1)\n            return\n\n        # Master node (rank 0) proceeds with the merge\n        while len(os.listdir(self._cache_dir)) < num_workers:\n            # Wait for all index parts to be available\n            sleep(1)\n\n        # Perform the merge operation\n        index_files = [f for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)]\n        chunks_info = []\n        for file in index_files:\n            with open(os.path.join(self._cache_dir, file), \"r\") as f:\n                data = json.load(f)\n                chunks_info.extend(data[\"chunks\"])\n\n        # Write the merged index file\n        with open(os.path.join(self._cache_dir, f\"0.{_INDEX_FILENAME}\"), \"w\") as out:\n            json.dump({\"chunks\": chunks_info, \"config\": self.get_config()}, out, sort_keys=True)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # Check if the environment is distributed\n        if self.rank != 0 and self._distributed_env.world_size > 1:\n            # If not the master node, wait until the merged index file is available\n            while not os.path.exists(os.path.join(self._cache_dir, f\"0.{_INDEX_FILENAME}\")):\n                sleep(1)\n            return\n\n        # Wait for all index parts to be available\n        while len(os.listdir(self._cache_dir)) < num_workers:\n            sleep(1)\n\n        # Proceed with the merge only if it's the master node (rank 0)\n        if self.rank == 0:\n            # Perform the merge operation\n            # Combine individual index files into a single, unified index file\n            # Write the merged index file to the cache directory\n            pass"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            # Non-distributed environment or rank determination handled externally\n            if self.rank != 0:\n                # Wait until the merged index file is available\n                while not os.path.exists(os.path.join(self._cache_dir, \"0.\" + _INDEX_FILENAME)):\n                    sleep(1)\n                return\n        else:\n            # Distributed environment, master node (rank 0) is responsible for merging\n            if node_rank != 0:\n                # Wait until the merged index file is available\n                while not os.path.exists(os.path.join(self._cache_dir, \"0.\" + _INDEX_FILENAME)):\n                    sleep(1)\n                return\n\n        # All parts of the index are ready for merging, proceed with the merge\n        if self.rank == 0:\n            index_files = [f for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)]\n            if len(index_files) == num_workers:\n                # Merge the index files into a single, unified index file\n                # Perform the merge operation here\n                pass"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install the required SDK to execute the job.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {sys.executable} -m lightning_cloud execute\"\n\n    studio = Studio()\n    job = studio.create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command\n    )\n\n    print(f\"Job created successfully. Job URL: {job.url}\")\n\n    while job.status != \"running\":\n        sleep(5)\n        job.refresh()\n\n    print(\"Job started successfully.\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "\n    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install the SDK to use this function.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('LIGHTNING_CLOUD_COMMAND', 'echo Hello, Lightning!')}\"\n\n    studio = Studio()\n    job = studio.create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command\n    )\n\n    job_url = _get_lightning_cloud_url() + f\"/jobs/{job.id}\"\n    print(f\"Job started! View the job at: {job_url}\")\n\n    while job.status != \"completed\" and job.status != \"failed\":\n        sleep(5)\n        job.refresh()\n\n    if job.status == \"failed\":\n        raise RuntimeError(f\"The job '{name}' has failed. View the job at: {job_url}\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "\n    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Unable to execute the job.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('LIGHTNING_EXECUTION_COMMAND', 'python -m lightning')}\"\n\n    studio = Studio()\n\n    job = studio.create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command\n    )\n\n    print(f\"Job URL: {job.url}\")\n\n    while job.status == \"PENDING\" or job.status == \"RUNNING\":\n        sleep(5)\n        job.refresh()\n\n    if job.status == \"FAILED\":\n        raise RuntimeError(\"Job execution failed.\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install the Lightning SDK to use this function.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {sys.executable} -m lightning_operators.entrypoint\"\n\n    studio = Studio()\n    job = studio.create_job(name=name, num_nodes=num_nodes, machine=machine, command=command)\n\n    print(f\"Job URL: {job.url}\")\n\n    while True:\n        job.refresh()\n        if job.status == \"failed\":\n            raise RuntimeError(f\"The job '{name}' has failed. Please check the job logs for more information.\")\n        elif job.status == \"succeeded\":\n            print(f\"The job '{name}' has succeeded.\")\n            break\n        else:\n            print(f\"Job status: {job.status}\")\n            sleep(10)"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise Exception(\"The Lightning SDK is not available.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('LIGHTNING_EXECUTION_COMMAND', 'echo Hello, Lightning!')}\"\n\n    studio = Studio()\n    job = studio.create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command\n    )\n\n    print(f\"Job created: {job.url}\")\n\n    while job.status != \"completed\":\n        sleep(10)\n        job.refresh()\n\n    if job.status == \"failed\":\n        raise Exception(\"Job execution failed.\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install the Lightning SDK to use this function.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {sys.executable} -m lightning_cloud.operator\"\n\n    studio = Studio(machine=machine)\n\n    job = studio.create_job(name=name, num_nodes=num_nodes, command=command)\n\n    print(f\"Job started successfully. Job URL: {job.url}\")\n\n    while not job.is_finished():\n        sleep(5)\n\n    if job.is_failed():\n        raise RuntimeError(f\"Job '{name}' failed. Please check the job logs for more details.\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "\n    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install the Lightning SDK to use this function.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('LIGHTNING_SDK_ENVIRONMENT')}\"\n\n    studio = Studio()\n    job = studio.create_job(name=name, num_nodes=num_nodes, machine=machine, command=command)\n\n    print(f\"Job URL: {job.url}\")\n\n    while job.status != \"running\":\n        sleep(10)\n        job.refresh()\n\n    if job.status == \"failed\":\n        raise RuntimeError(f\"The job '{name}' has failed. Please check the job logs for more information.\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "\n    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please make sure it is installed and configured properly.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('LIGHTNING_CLOUD_COMMAND', 'echo Hello, Lightning!')}\"\n\n    # Create the job\n    job = Studio().create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command\n    )\n\n    print(f\"Job created: {job.url}\")\n\n    # Check job status\n    while job.status != \"succeeded\" and job.status != \"failed\":\n        job.refresh()\n        sleep(5)\n\n    if job.status == \"failed\":\n        raise RuntimeError(f\"The job {job.name} failed. Please check the job logs for more details.\")\n\n    print(f\"The job {job.name} succeeded. You can access the job output at {job.url}.\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install the SDK to use this function.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('LIGHTNING_CLOUD_COMMAND', 'python')} operator.py\"\n\n    studio = Studio()\n\n    job = studio.create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command\n    )\n\n    job_url = f\"{_get_lightning_cloud_url()}/jobs/{job.id}\"\n\n    print(f\"Job started. Check job status at: {job_url}\")\n\n    while True:\n        job.refresh()\n        if job.status in (\"finished\", \"failed\"):\n            break\n        sleep(5)\n\n    if job.status == \"failed\":\n        raise RuntimeError(f\"Job {job.id} failed. Check job status at: {job_url}\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install the SDK to use this function.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('LIGHTNING_CLOUD_COMMAND', 'echo No command provided.')}\"\n\n    studio = Studio()\n\n    job = studio.create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command\n    )\n\n    print(f\"Job created. Job URL: {job.url}\")\n\n    while True:\n        job.refresh()\n        if job.status in [\"failed\", \"stopped\"]:\n            raise RuntimeError(f\"Job execution failed. Job status: {job.status}\")\n        elif job.status == \"succeeded\":\n            print(f\"Job succeeded. Job URL: {job.url}\")\n            break\n        else:\n            print(f\"Job status: {job.status}. Waiting for job to complete...\")\n            sleep(10)"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install the Lightning SDK to use this function.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {sys.executable} -m lightning_utilities.operator {name}\"\n\n    studio = Studio()\n    job = studio.jobs.create(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command\n    )\n\n    print(f\"Job started: {job.url}\")\n\n    while job.status != \"finished\":\n        sleep(10)\n        job.refresh()\n\n    if job.status == \"failed\":\n        raise RuntimeError(f\"The job '{name}' failed. Check the job logs for more details.\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install the Lightning SDK to use this function.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {sys.executable} -m lightning_operator\"\n\n    studio = Studio()\n    job = studio.create_job(name=name, num_nodes=num_nodes, machine=machine, command=command)\n\n    print(f\"Job {job.id} has been created and is starting.\")\n    print(f\"Job URL: {_get_lightning_cloud_url()}/jobs/{job.id}\")\n\n    while True:\n        job.refresh()\n        if job.status in [\"failed\", \"canceled\"]:\n            raise RuntimeError(f\"Job {job.id} failed or was canceled.\")\n        if job.status == \"succeeded\":\n            print(f\"Job {job.id} has succeeded.\")\n            break\n        sleep(10)"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "\n    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please make sure it is installed and configured.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('LIGHTNING_COMMAND', 'python')} operator.py\"\n\n    studio = Studio()\n    job = studio.create_job(name=name, num_nodes=num_nodes, machine=machine, command=command)\n\n    print(f\"Job '{name}' started. Job URL: {job.url}\")\n\n    while not job.is_finished():\n        sleep(10)\n\n    if job.status != \"succeeded\":\n        raise RuntimeError(f\"Job '{name}' failed with status: {job.status}\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "\n    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install the Lightning SDK to use this function.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('LIGHTNING_CLOUD_COMMAND', 'python')} operator.py\"\n\n    studio = Studio()\n\n    job = studio.create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command\n    )\n\n    print(f\"Job created: {job.url}\")\n\n    while job.status != \"completed\":\n        sleep(5)\n        job.refresh()\n\n    if job.status == \"failed\":\n        raise RuntimeError(f\"The job '{name}' failed. Please check the job logs for more information.\")\n\n    print(f\"Job '{name}' completed successfully.\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install the Lightning SDK to use this function.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('LIGHTNING_OPERATOR_CMD', 'python operator.py')}\"\n\n    studio = Studio()\n\n    job = studio.jobs.create(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command\n    )\n\n    print(f\"Job created: {job.url}\")\n\n    while job.status not in [\"completed\", \"failed\", \"killed\"]:\n        sleep(10)\n        job.refresh()\n\n    if job.status == \"failed\":\n        raise RuntimeError(f\"The job '{name}' failed. Please check the job logs for more details.\")\n\n    if job.status == \"killed\":\n        raise RuntimeError(f\"The job '{name}' was killed. Please check the job logs for more details.\")\n\n    print(f\"Job completed: {job.url}\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please make sure it is installed.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('LIGHTNING_COMMAND', 'echo No command provided')}\"\n\n    studio = Studio()\n    job = studio.jobs.create(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command\n    )\n\n    print(f\"Job URL: {job.url}\")\n\n    while job.status == \"PENDING\":\n        sleep(5)\n        job.refresh()\n\n    if job.status == \"FAILED\":\n        raise RuntimeError(f\"The job '{name}' failed. Please check the Studio for more details.\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "\n    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Unable to execute the job.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('LIGHTNING_EXECUTION_COMMAND', 'python')}\"\n\n    # Create the job\n    job = Studio().create_job(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command\n    )\n\n    print(f\"Job created: {job.url}\")\n\n    # Continuously check the job status\n    while True:\n        job.refresh()\n        if job.status in [\"failed\", \"stopped\"]:\n            raise RuntimeError(f\"Job failed: {job.url}\")\n        if job.status == \"running\":\n            print(f\"Job started: {job.url}\")\n            break\n        sleep(5)"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "\n    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please make sure it is installed.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('CMD') or 'echo No command specified'}\"\n\n    studio = Studio()\n\n    job = studio.job.create(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command\n    )\n\n    print(f\"Job {name} started. Job URL: {job.url}\")\n\n    while job.status() == \"running\":\n        sleep(10)\n\n    if job.status() == \"failed\":\n        raise RuntimeError(f\"Job {name} failed.\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "\n    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install the required SDK.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = \"python main.py\"  # Example default command\n\n    # Create the job using the Studio API\n    studio = Studio()\n    job = studio.create_job(name=name, num_nodes=num_nodes, machine=machine, command=command)\n\n    # Continuously check the job status\n    while job.status != \"completed\" and job.status != \"failed\":\n        sleep(10)  # Check every 10 seconds\n        job.refresh()\n\n    # Print the job URL when it starts\n    if job.status == \"completed\":\n        print(f\"Job {name} has completed. Job URL: {job.url}\")\n    elif job.status == \"failed\":\n        raise RuntimeError(f\"Job {name} has failed.\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install the SDK to use this function.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {os.getenv('LIGHTNING_EXECUTION_COMMAND', 'python -m lightning')}\"\n\n    studio = Studio()\n\n    job = studio.jobs.create(\n        name=name,\n        num_nodes=num_nodes,\n        machine=machine,\n        command=command\n    )\n\n    print(f\"Job started: {job.url}\")\n\n    while job.status not in [\"failed\", \"completed\"]:\n        sleep(5)\n        job.refresh()\n\n    if job.status == \"failed\":\n        raise RuntimeError(f\"The job {job.name} failed. Please check the job logs for details.\")\n\n    print(f\"Job completed: {job.url}\")"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        try:\n            # Load the configuration if the index files are available\n            config = ChunksConfig(\n                cache_dir=self._cache_dir,\n                remote_input_dir=self._remote_input_dir,\n                serializers=self._serializers,\n                item_loader=self._item_loader,\n            )\n            if config._has_index_files():\n                self._config = config\n                return config\n            else:\n                return None\n        except Exception as e:\n            logger.warning(f\"Failed to load chunks configuration: {e}\")\n            return None"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        try:\n            config = ChunksConfig.load(self._cache_dir, self._serializers, self._remote_input_dir, self._item_loader)\n            self._config = config\n            return config\n        except Exception as e:\n            logger.error(f\"Failed to load chunks configuration: {e}\")\n            return None"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "    config_file_path = os.path.join(self._cache_dir, \"config.json\")\n    if os.path.exists(config_file_path):\n        try:\n            config = ChunksConfig.load(config_file_path)\n            config.update_cache_dir(self._cache_dir)\n            config.update_remote_input_dir(self._remote_input_dir)\n            config.update_serializers(self._serializers)\n            config.update_item_loader(self._item_loader)\n            self._config = config\n            return config\n        except Exception as e:\n            logger.error(f\"Failed to load chunks config: {e}\")\n    return None"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        if not os.path.exists(self._cache_dir):\n            return None\n\n        # Check if the index file exists in the cache directory\n        index_file = os.path.join(self._cache_dir, \"index\")\n        if not os.path.exists(index_file):\n            return None\n\n        # Load the ChunksConfig object from the index file\n        try:\n            config = ChunksConfig.load(index_file)\n            return config\n        except Exception as e:\n            logger.warning(f\"Failed to load ChunksConfig from index file: {e}\")\n            return None"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Check if the cache directory exists\n        if not os.path.exists(self._cache_dir):\n            return None\n\n        # Check if the index files are available\n        index_files = [f for f in os.listdir(self._cache_dir) if f.endswith('.index')]\n        if not index_files:\n            return None\n\n        # Load the ChunksConfig object from the index files\n        try:\n            config = ChunksConfig.load(self._cache_dir, self._remote_input_dir, self._item_loader, self._serializers)\n            self._config = config\n            return config\n        except Exception as e:\n            logger.warning(f\"Failed to load ChunksConfig: {e}\")\n            return None"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        if not os.path.exists(self._cache_dir):\n            return None\n\n        # Try to load the configuration\n        try:\n            config = ChunksConfig.load(\n                self._cache_dir,\n                remote_input_dir=self._remote_input_dir,\n                compression=self._compression,\n                serializers=self._serializers,\n            )\n            self._config = config\n            return config\n        except Exception as e:\n            logger.warning(f\"Failed to load chunks configuration: {e}\")\n            return None"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        try:\n            # Load the chunks configuration from the cache directory\n            config = ChunksConfig.load(self._cache_dir, self._serializers, self._remote_input_dir, self._item_loader)\n\n            # Update the instance's configuration with the loaded ChunksConfig object\n            self._config = config\n            return config\n        except Exception as e:\n            # Handle the exception and return None if the configuration could not be loaded\n            logger.warning(f\"Failed to load chunks configuration: {e}\")\n            return None"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "    try:\n        # Check if the index files are available\n        index_files = [file for file in os.listdir(self._cache_dir) if file.endswith(\".index\")]\n        \n        if not index_files:\n            return None  # No index files available\n        \n        # Load the configuration using the index files\n        config = ChunksConfig(\n            cache_dir=self._cache_dir,\n            remote_input_dir=self._remote_input_dir,\n            serializers=self._serializers,\n            item_loader=self._item_loader,\n            rank=self._rank,\n            intervals=self._intervals\n        )\n        \n        # Update the instance's configuration with the loaded ChunksConfig object\n        self._config = config\n        return config\n    except Exception as e:\n        logger.warning(f\"Failed to load chunks configuration: {e}\")\n        return None"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        index_files = [f for f in os.listdir(self._cache_dir) if f.endswith(\".index\")]\n        if not index_files:\n            return None\n\n        try:\n            # Load the first index file found\n            index_file = index_files[0]\n            index_file_path = os.path.join(self._cache_dir, index_file)\n            config = ChunksConfig.load(index_file_path, self._cache_dir, self._remote_input_dir, self._item_loader, self._serializers)\n            self._config = config\n            return config\n        except Exception as e:\n            logger.warning(f\"Failed to load chunks configuration from {index_file}: {e}\")\n            return None"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        if not os.path.exists(self._cache_dir):\n            return None\n\n        # Check if the index file exists in the cache directory\n        index_file_path = os.path.join(self._cache_dir, \"index\")\n        if not os.path.exists(index_file_path):\n            return None\n\n        # Load the ChunksConfig object from the index file\n        try:\n            config = ChunksConfig.load(index_file_path)\n            self._config = config\n            return config\n        except Exception as e:\n            logger.warning(f\"Failed to load ChunksConfig from index file: {e}\")\n            return None"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "    config_path = os.path.join(self._cache_dir, \"config.json\")\n    if os.path.exists(config_path):\n        try:\n            config = ChunksConfig.load(config_path)\n            config.update(self._cache_dir, self._remote_input_dir, self._serializers, self._item_loader)\n            return config\n        except Exception as e:\n            logger.error(f\"Failed to load config from {config_path}: {e}\")\n    return None"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        index_files = [f for f in os.listdir(self._cache_dir) if f.endswith('.index')]\n        if not index_files:\n            return None\n\n        index_file = index_files[0]\n        config_path = os.path.join(self._cache_dir, index_file)\n\n        try:\n            config = ChunksConfig.load(\n                config_path,\n                remote_input_dir=self._remote_input_dir,\n                compression=self._compression,\n                item_loader=self._item_loader,\n                serializers=self._serializers,\n            )\n            self._config = config\n            return config\n        except Exception as e:\n            logger.warning(f\"Failed to load ChunksConfig from {config_path}: {e}\")\n            return None"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        try:\n            config = ChunksConfig(\n                cache_dir=self._cache_dir,\n                remote_input_dir=self._remote_input_dir,\n                serializers=self._serializers,\n                item_loader=self._item_loader,\n            )\n            config.load()\n            self._config = config\n            return config\n        except Exception as e:\n            logger.warning(f\"Failed to load chunks configuration: {e}\")\n            return None"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        index_files = [f for f in os.listdir(self._cache_dir) if f.endswith(\".index\")]\n        if not index_files:\n            return None\n\n        index_file = index_files[0]\n        index_file_path = os.path.join(self._cache_dir, index_file)\n\n        try:\n            config = ChunksConfig.load(\n                index_file_path,\n                remote_input_dir=self._remote_input_dir,\n                serializers=self._serializers,\n                item_loader=self._item_loader,\n            )\n            self._config = config\n            return config\n        except Exception as e:\n            logger.warning(f\"Failed to load ChunksConfig from {index_file_path}: {e}\")\n            return None"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        try:\n            config = ChunksConfig.load_from_cache_dir(\n                self._cache_dir,\n                serializers=self._serializers,\n                remote_input_dir=self._remote_input_dir,\n                item_loader=self._item_loader,\n            )\n            self._config = config\n            return config\n        except Exception as e:\n            logger.warning(f\"Failed to load chunks configuration: {e}\")\n            return None"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        index_files = [f for f in os.listdir(self._cache_dir) if f.endswith(\".index\")]\n        if len(index_files) == 0:\n            return None\n\n        index_file = index_files[0]\n        index_file_path = os.path.join(self._cache_dir, index_file)\n\n        try:\n            config = ChunksConfig.load(index_file_path, self._cache_dir, self._remote_input_dir, self._compression)\n            self._config = config\n            return config\n        except Exception as e:\n            logger.warning(f\"Failed to load ChunksConfig from {index_file_path}: {e}\")\n            return None"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        if not os.path.exists(self._cache_dir):\n            return None\n\n        # Check if the index file exists in the cache directory\n        index_file_path = os.path.join(self._cache_dir, \"index\")\n        if not os.path.exists(index_file_path):\n            return None\n\n        # Load the ChunksConfig object from the index file\n        try:\n            config = ChunksConfig.load(index_file_path)\n            self._config = config\n            return config\n        except Exception as e:\n            logger.warning(f\"Failed to load ChunksConfig from index file: {e}\")\n            return None"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        try:\n            config = ChunksConfig(\n                cache_dir=self._cache_dir,\n                remote_input_dir=self._remote_input_dir,\n                serializers=self._serializers,\n                item_loader=self._item_loader,\n            )\n            if config.is_valid():\n                self._config = config\n                return config\n        except Exception as e:\n            logger.warning(f\"Failed to load chunks configuration: {e}\")\n        return None"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        config_path = os.path.join(self._cache_dir, \"config.json\")\n        if os.path.exists(config_path):\n            try:\n                config = ChunksConfig.load(config_path)\n                config._cache_dir = self._cache_dir\n                config._remote_input_dir = self._remote_input_dir\n                config._serializers = self._serializers\n                config._item_loader = self._item_loader\n                self._config = config\n                return config\n            except Exception as e:\n                logger.warning(f\"Failed to load the chunks configuration: {e}\")\n        return None"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        config_path = os.path.join(self._cache_dir, \"config.json\")\n        if os.path.exists(config_path):\n            try:\n                config = ChunksConfig.load(config_path)\n                self._config = config\n                return config\n            except Exception as e:\n                logger.error(f\"Failed to load chunks config from {config_path}: {e}\")\n        return None"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for index in chunk_indexes:\n            self._to_download_queue.put(index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for index in chunk_indexes:\n            self._to_download_queue.put(index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for index in chunk_indexes:\n            self._to_download_queue.put(index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for index in chunk_indexes:\n            self._to_download_queue.put(index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for index in chunk_indexes:\n            self._to_download_queue.put(index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for index in chunk_indexes:\n            self._to_download_queue.put(index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for index in chunk_indexes:\n            self._to_download_queue.put(index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for index in chunk_indexes:\n            self._to_download_queue.put(index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for index in chunk_indexes:\n            self._to_download_queue.put(index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for index in chunk_indexes:\n            self._to_download_queue.put(index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for index in chunk_indexes:\n            self._to_download_queue.put(index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for index in chunk_indexes:\n            self._to_download_queue.put(index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for index in chunk_indexes:\n            self._to_download_queue.put(index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for index in chunk_indexes:\n            self._to_download_queue.put(index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for index in chunk_indexes:\n            self._to_download_queue.put(index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for index in chunk_indexes:\n            self._to_download_queue.put(index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for index in chunk_indexes:\n            self._to_download_queue.put(index)"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"Configuration should be defined before accessing it.\")\n        return self._config"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration should be defined before accessing it.\")\n        return self._config"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration should be defined before accessing it.\")\n        return self._config"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration should be defined before accessing it.\")\n        return self._config"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"Configuration should be defined before accessing it.\")\n        return self._config"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"Configuration should be defined before accessing it.\")\n        return self._config"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"Configuration should be defined before accessing it.\")\n        return self._config"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration should be defined before accessing it.\")\n        return self._config"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"Configuration should be defined before accessing it.\")\n        return self._config"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"Configuration should be defined before accessing it.\")\n        return self._config"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration should be defined before accessing it.\")\n        return self._config"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration should be defined before accessing it.\")\n        return self._config"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration should be defined before accessing it.\")\n        return self._config"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"Configuration should be defined before accessing it.\")\n        return self._config"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"Configuration should be defined before accessing it.\")\n        return self._config\n\n        \"\"\"\n        This function returns the configuration for a BinaryReader instance. If the configuration is not set (None), it raises a RuntimeError indicating that the configuration should be defined before accessing it.\n        Input-Output Arguments\n        :param self: BinaryReader. An instance of the BinaryReader class. It uses the _config attribute to determine if the configuration is set.\n        :return: ChunksConfig. The configuration of the BinaryReader instance.\n        \"\"\""}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"Configuration should be defined before accessing it\")\n        return self._config\n\n        \"\"\"\n        This function returns the configuration for a BinaryReader instance. If the configuration is not set (None), it raises a RuntimeError indicating that the configuration should be defined before accessing it.\n        Input-Output Arguments\n        :param self: BinaryReader. An instance of the BinaryReader class. It uses the _config attribute to determine if the configuration is set.\n        :return: ChunksConfig. The configuration of the BinaryReader instance.\n        \"\"\""}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"Configuration should be defined before accessing it.\")\n        return self._config\n\n        \"\"\"\n        This function returns the configuration for a BinaryReader instance. If the configuration is not set (None), it raises a RuntimeError indicating that the configuration should be defined before accessing it.\n        Input-Output Arguments\n        :param self: BinaryReader. An instance of the BinaryReader class. It uses the _config attribute to determine if the configuration is set.\n        :return: ChunksConfig. The configuration of the BinaryReader instance.\n        \"\"\""}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration should be defined before accessing it.\")\n        return self._config"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"Configuration should be defined before accessing it\")\n        return self._config"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"Configuration should be defined before accessing it.\")\n        return self._config"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index is not an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader's index configuration is not defined.\")\n\n        if self._prepare_thread is None:\n            raise AssertionError(\"The prepare thread is not available. Ensure it is correctly managing the chunks.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        self._prepare_thread.download([chunk_index])\n\n        return self._item_loader.load_item(index.index, chunk_index)"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index must be an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index configuration is not defined.\")\n\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread is not defined. Please ensure it is correctly managing the chunks.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        self._prepare_thread.download([chunk_index])\n\n        while True:\n            try:\n                item = self._item_loader.get_item(index, self._config)\n                return item\n            except Empty:\n                pass"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index must be an instance of ChunkedIndex.\")\n\n        if self._config is None:\n            raise Exception(\"The reader's index configuration is not defined.\")\n\n        if self._prepare_thread is None:\n            raise AssertionError(\"The prepare thread is not initialized. Please ensure it is correctly managing the chunks.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        self._prepare_thread.download([chunk_index])\n\n        while True:\n            try:\n                item = self._item_loader.load_item(index, self._config)\n                return item\n            except Empty:\n                continue"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index is not an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader's index configuration is not defined.\")\n\n        if self._prepare_thread is None:\n            raise AssertionError(\"The prepare thread is not defined. Make sure it is correctly managing the chunks.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        self._prepare_thread.download([chunk_index])\n\n        # Read the item from the specified chunk using the item loader\n        return self._item_loader.load(index, self._config)"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index is not an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader's index configuration is not defined.\")\n\n        if self._prepare_thread is None:\n            raise AssertionError(\"The prepare thread is not defined. Please ensure it is correctly managing the chunks.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        self._prepare_thread.download([chunk_index])\n\n        # Wait for the item to be loaded\n        while True:\n            try:\n                item = self._item_loader.load(index, self._config)\n                return item\n            except Empty:\n                pass"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index is not an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader's index configuration is not defined.\")\n\n        if self._prepare_thread is None:\n            raise AssertionError(\"The prepare thread is not present. Please ensure the thread is correctly managing the chunks.\")"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index must be an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader's index configuration is not defined.\")\n\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread is not defined. Unable to manage chunks.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        item = self._config.load_item(chunk_index, index.item_index)\n\n        return item"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index is not an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader's index configuration is not defined.\")\n\n        if self._prepare_thread is None:\n            raise AssertionError(\"The prepare thread is not available. Please ensure it is correctly managing the chunks.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        self._prepare_thread.download([chunk_index])\n\n        return self._item_loader.load(index)"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "\n        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index must be an instance of ChunkedIndex.\")\n\n        if self._config is None:\n            raise Exception(\"The reader's index configuration is not defined.\")\n\n        if self._prepare_thread is None:\n            raise AssertionError(\"The prepare thread is not available. Cannot read without preparing the chunks.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        self._prepare_thread.download([chunk_index])\n\n        while True:\n            try:\n                item = self._item_loader.load_item(chunk_index, index.item)\n                return item\n            except FileNotFoundError:\n                pass"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index must be an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index configuration is not defined.\")\n\n        if self._prepare_thread is None:\n            raise AssertionError(\"The prepare thread is not available. Ensure it is correctly managing the chunks.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        self._prepare_thread.download([chunk_index])\n\n        while True:\n            try:\n                item = self._item_loader.load(index)\n                return item\n            except Empty:\n                pass"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index must be an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index configuration is not defined.\")\n\n        if self._prepare_thread is None:\n            raise AssertionError(\"The prepare thread is not defined. Please ensure it is correctly managing the chunks.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        self._prepare_thread.download([chunk_index])\n\n        return self._item_loader.get_item(chunk_index, index.item)"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index is not an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader's index configuration is not defined.\")\n\n        if self._prepare_thread is None:\n            raise AssertionError(\"The prepare thread is not initialized. Please ensure it is correctly managing the chunks.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        self._prepare_thread.download([chunk_index])\n\n        return self._item_loader.load_item(index)"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index is not an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader's index configuration is not defined.\")\n\n        if self._prepare_thread is None:\n            raise AssertionError(\"The prepare thread is not defined. It is required for managing the chunks.\")\n\n        # Read the item from the specified chunk\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        item = self._item_loader.load(index.item, chunk_index)\n\n        return item"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index must be an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index configuration is not defined.\")\n\n        if self._prepare_thread is None:\n            raise AssertionError(\"The prepare thread is not available. Please ensure that the prepare thread is correctly managing the chunks.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        self._prepare_thread.download([chunk_index])\n\n        item = self._item_loader.load_item(index)\n        return item"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index must be an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index configuration is not defined.\")\n\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread is not initialized. Please ensure the prepare thread is correctly managing the chunks.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        self._prepare_thread.download([chunk_index])\n\n        item = self._item_loader.load(index.item, chunk_index)\n        return item"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index must be an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index configuration is not defined.\")\n\n        if self._prepare_thread is None:\n            raise AssertionError(\"The prepare thread is not defined. Please ensure it is correctly managing the chunks.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        self._prepare_thread.download([chunk_index])\n\n        while True:\n            if self._prepare_thread._has_exited:\n                break\n            if self._last_chunk_index != chunk_index:\n                self._last_chunk_index = chunk_index\n                break\n\n        return self._item_loader.load(index, self._config)"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index must be an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index configuration is not defined.\")\n\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread is not defined. Unable to manage chunks.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        self._prepare_thread.download([chunk_index])\n\n        while True:\n            if self._prepare_thread._has_exited:\n                raise Exception(\"The prepare thread has exited unexpectedly.\")\n\n            try:\n                item = self._item_loader.load(index)\n                return item\n            except Exception:\n                pass"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index must be an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index configuration is not defined.\")\n\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread is not defined. Unable to manage chunks.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        self._prepare_thread.download([chunk_index])\n\n        while True:\n            try:\n                item = self._item_loader.load_item(index, self._config)\n                return item\n            except Empty:\n                pass"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index must be an instance of ChunkedIndex.\")\n\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index configuration is not defined.\")\n\n        if self._prepare_thread is None:\n            raise AssertionError(\"The prepare thread is not defined. Please ensure it is correctly managing the chunks.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        self._prepare_thread.download([chunk_index])\n\n        return self._item_loader.load_item(index)"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index is not an instance of ChunkedIndex.\")\n\n        if self._config is None:\n            raise Exception(\"The reader's index configuration is not defined.\")\n\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread is not available for managing the chunks.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        self._prepare_thread.download([chunk_index])\n        self._prepare_thread.join()\n\n        return self._item_loader.load(index, self._config)"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                # if the file is a symbolic link, use the size of the link file\n                if os.path.islink(fp):\n                    total_size += os.lstat(fp).st_size\n                else:\n                    total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                # ignore FileNotFoundError exceptions\n                pass\n    return total_size"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                continue\n    return total_size"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for filename in filenames:\n            file_path = os.path.join(dirpath, filename)\n            try:\n                total_size += os.path.getsize(file_path)\n            except FileNotFoundError:\n                # Ignore FileNotFoundError exceptions if the file is deleted during the calculation\n                pass\n    return total_size"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                # Ignore FileNotFoundError exceptions\n                pass\n    return total_size"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                # if the file is a symbolic link, os.path.getsize will raise an OSError\n                total_size += os.path.getsize(fp)\n            except OSError:\n                pass\n    return total_size"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                if os.path.isfile(fp):\n                    total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                continue\n    return total_size"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                continue\n    return total_size"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                # if it is a symbolic link, os.path.getsize() will throw an exception, so we skip it\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for filename in filenames:\n            filepath = os.path.join(dirpath, filename)\n            try:\n                total_size += os.path.getsize(filepath)\n            except FileNotFoundError:\n                # Ignore FileNotFoundError exceptions if the file is deleted during the size calculation process\n                pass\n    return total_size"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                # Ignore the exception and continue calculating the total size\n                pass\n    return total_size"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    distributed_map = _ImmutableDistributedMap()\n    try:\n        return distributed_map.set_and_get(key, obj)\n    except RuntimeError:\n        return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    distributed_map = _ImmutableDistributedMap()\n    try:\n        return distributed_map.set_and_get(key, obj)\n    except RuntimeError:\n        return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "\n    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is not None:\n        distributed_map = _ImmutableDistributedMap()\n        return distributed_map.set_and_get(key, obj)\n    else:\n        return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    distributed_map = _ImmutableDistributedMap()\n    try:\n        return distributed_map.set_and_get(key, obj)\n    except RuntimeError:\n        return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    distributed_map = _ImmutableDistributedMap()\n    try:\n        return distributed_map.set_and_get(key, obj)\n    except RuntimeError:\n        return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    distributed_map = _ImmutableDistributedMap()\n    try:\n        return distributed_map.set_and_get(key, obj)\n    except RuntimeError:\n        return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "\n    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is not None:\n        distributed_map = _ImmutableDistributedMap()\n        return distributed_map.set_and_get(key, obj)\n    else:\n        return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    distributed_map = _ImmutableDistributedMap()\n    try:\n        return distributed_map.set_and_get(key, obj)\n    except RuntimeError:\n        return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "\n    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is not None:\n        distributed_map = _ImmutableDistributedMap()\n        return distributed_map.set_and_get(key, obj)\n    else:\n        return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") and os.getenv(\"LIGHTNING_APP_STATE_URL\"):\n        distributed_map = _ImmutableDistributedMap()\n        return distributed_map.set_and_get(key, obj)\n    else:\n        return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    distributed_map = _ImmutableDistributedMap()\n    try:\n        return distributed_map.set_and_get(key, obj)\n    except RuntimeError:\n        return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    distributed_map = _ImmutableDistributedMap()\n    try:\n        return distributed_map.set_and_get(key, obj)\n    except RuntimeError:\n        return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    distributed_map = _ImmutableDistributedMap()\n    try:\n        return distributed_map.set_and_get(key, obj)\n    except RuntimeError:\n        return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is not None:\n        distributed_map = _ImmutableDistributedMap()\n        return distributed_map.set_and_get(key, obj)\n    else:\n        return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "\n    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is not None:\n        distributed_map = _ImmutableDistributedMap()\n        return distributed_map.set_and_get(key, obj)\n    else:\n        return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") and os.getenv(\"LIGHTNING_APP_STATE_URL\"):\n        distributed_map = _ImmutableDistributedMap()\n        return distributed_map.set_and_get(key, obj)\n    else:\n        return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "\n    # Check if the application is running in a distributed environment\n    lightning_app_external_url = os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\")\n    if lightning_app_external_url:\n        # If in a distributed environment, use the immutable distributed map to broadcast the object\n        distributed_map = _ImmutableDistributedMap()\n        return distributed_map.set_and_get(key, obj)\n    else:\n        # If not in a distributed environment, simply return the object as is\n        return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") and os.getenv(\"LIGHTNING_APP_STATE_URL\"):\n        distributed_map = _ImmutableDistributedMap()\n        return distributed_map.set_and_get(key, obj)\n    else:\n        return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    distributed_map = _ImmutableDistributedMap()\n\n    try:\n        return distributed_map.set_and_get(key, obj)\n    except RuntimeError:\n        return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") and os.getenv(\"LIGHTNING_APP_STATE_URL\"):\n        distributed_map = _ImmutableDistributedMap()\n        return distributed_map.set_and_get(key, obj)\n    else:\n        return obj"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Create dictionaries to store the items in each bin and their total weight\n    bins = defaultdict(list)\n    bin_weights = defaultdict(int)\n\n    # Sort the items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Place each item into the bin with the current lowest total weight\n    for item, weight in sorted_items:\n        min_bin = min(bin_weights, key=bin_weights.get)\n        bins[min_bin].append(item)\n        bin_weights[min_bin] += weight\n\n    return bins, bin_weights"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Sort the items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Initialize the bins and their total weights\n    bins = defaultdict(list)\n    bin_weights = defaultdict(int)\n\n    # Place each item into the bin with the current lowest total weight\n    for item, weight in sorted_items:\n        min_bin = min(bin_weights, key=bin_weights.get)\n        bins[min_bin].append(item)\n        bin_weights[min_bin] += weight\n\n    return bins, bin_weights"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    bins = defaultdict(list)\n    bin_weights = defaultdict(int)\n\n    # Sort items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Place each item into the bin with the current lowest total weight\n    for item, weight in sorted_items:\n        min_bin = min(bin_weights, key=bin_weights.get)\n        bins[min_bin].append(item)\n        bin_weights[min_bin] += weight\n\n    return bins, bin_weights"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    bins = defaultdict(list)\n    bin_weights = defaultdict(int)\n\n    # Sort items and weights by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    for item, weight in sorted_items:\n        # Find the bin with the lowest total weight\n        min_bin = min(bin_weights, key=bin_weights.get)\n        # Add the item to the bin with the lowest total weight\n        bins[min_bin].append(item)\n        bin_weights[min_bin] += weight\n\n    return bins, bin_weights"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    bins = defaultdict(list)\n    bin_weights = defaultdict(int)\n    \n    # Sort items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n    \n    # Place each item into the bin with the current lowest total weight\n    for item, weight in sorted_items:\n        min_bin = min(bin_weights, key=bin_weights.get)\n        bins[min_bin].append(item)\n        bin_weights[min_bin] += weight\n        \n    return bins, bin_weights"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    bins = defaultdict(list)\n    bin_weights = defaultdict(int)\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    for item, weight in sorted_items:\n        min_bin = min(bin_weights, key=bin_weights.get)\n        bins[min_bin].append(item)\n        bin_weights[min_bin] += weight\n\n    return dict(bins), dict(bin_weights)"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    bins = defaultdict(list)\n    bin_weights = defaultdict(int)\n\n    # Sort items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Place each item into the bin with the current lowest total weight\n    for item, weight in sorted_items:\n        min_bin = min(bin_weights, key=bin_weights.get)\n        bins[min_bin].append(item)\n        bin_weights[min_bin] += weight\n\n    return bins, bin_weights"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    bins = defaultdict(list)\n    bin_weights = defaultdict(int)\n    \n    # Sort items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n    \n    # Place each item into the bin with the current lowest total weight\n    for item, weight in sorted_items:\n        min_bin = min(bin_weights, key=bin_weights.get)\n        bins[min_bin].append(item)\n        bin_weights[min_bin] += weight\n        \n    return bins, bin_weights"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Create a dictionary to store the items in each bin\n    bins = defaultdict(list)\n    # Create a dictionary to store the total weight of items in each bin\n    bin_weights = defaultdict(int)\n\n    # Sort the items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Iterate through the sorted items\n    for item, weight in sorted_items:\n        # Find the bin with the lowest total weight\n        min_bin = min(bin_weights, key=bin_weights.get)\n        # Add the item to the bin with the lowest total weight\n        bins[min_bin].append(item)\n        # Update the total weight of the bin\n        bin_weights[min_bin] += weight\n\n    return bins, bin_weights"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    bins = defaultdict(list)\n    bin_weights = defaultdict(int)\n\n    # Sort items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    for item, weight in sorted_items:\n        # Find the bin with the lowest total weight\n        min_weight_bin = min(bin_weights, key=bin_weights.get)\n        # Add the item to the bin with the lowest total weight\n        bins[min_weight_bin].append(item)\n        bin_weights[min_weight_bin] += weight\n\n    return bins, bin_weights"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Initialize the bins and their total weights\n    bins = defaultdict(list)\n    bin_weights = defaultdict(int)\n\n    # Sort the items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Place each item into the bin with the current lowest total weight\n    for item, weight in sorted_items:\n        min_bin = min(bin_weights, key=bin_weights.get)\n        bins[min_bin].append(item)\n        bin_weights[min_bin] += weight\n\n    return bins, bin_weights"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Create dictionaries to store the items in each bin and their total weights\n    bins = defaultdict(list)\n    bin_weights = defaultdict(int)\n\n    # Sort the items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Place each item into the bin with the current lowest total weight\n    for item, weight in sorted_items:\n        min_bin = min(bin_weights, key=bin_weights.get)\n        bins[min_bin].append(item)\n        bin_weights[min_bin] += weight\n\n    return bins, bin_weights"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    bin_items = defaultdict(list)\n    bin_weights = defaultdict(int)\n\n    # Sort items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Place each item into the bin with the current lowest total weight\n    for item, weight in sorted_items:\n        min_bin = min(bin_weights, key=bin_weights.get)\n        bin_items[min_bin].append(item)\n        bin_weights[min_bin] += weight\n\n    return dict(bin_items), dict(bin_weights)"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    bins = defaultdict(list)\n    bin_weights = defaultdict(int)\n\n    # Sort the items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Place each item into the bin with the current lowest total weight\n    for item, weight in sorted_items:\n        min_bin = min(bin_weights, key=bin_weights.get)\n        bins[min_bin].append(item)\n        bin_weights[min_bin] += weight\n\n    return bins, bin_weights"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Create a dictionary to store the items in each bin\n    bins: Dict[int, List[Any]] = defaultdict(list)\n    # Create a dictionary to store the total weight of items in each bin\n    bin_weights: Dict[int, int] = defaultdict(int)\n\n    # Sort the items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Place each item into the bin with the current lowest total weight\n    for item, weight in sorted_items:\n        # Find the bin with the lowest total weight\n        min_weight_bin = min(bin_weights, key=bin_weights.get)\n        # Add the item to the bin\n        bins[min_weight_bin].append(item)\n        # Update the total weight of the bin\n        bin_weights[min_weight_bin] += weight\n\n    return bins, bin_weights"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    bins = defaultdict(list)\n    bin_weights = defaultdict(int)\n    \n    # Sort items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n    \n    # Place each item into the bin with the current lowest total weight\n    for item, weight in sorted_items:\n        min_bin = min(bin_weights, key=bin_weights.get)\n        bins[min_bin].append(item)\n        bin_weights[min_bin] += weight\n        \n    return bins, bin_weights"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    bins = defaultdict(list)\n    bin_weights = defaultdict(int)\n\n    # Sort items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Place each item into the bin with the current lowest total weight\n    for item, weight in sorted_items:\n        min_bin = min(bin_weights, key=bin_weights.get)\n        bins[min_bin].append(item)\n        bin_weights[min_bin] += weight\n\n    return bins, bin_weights"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Create dictionaries to store the items in each bin and their total weights\n    bins = defaultdict(list)\n    bin_weights = defaultdict(int)\n\n    # Sort the items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Place each item into the bin with the current lowest total weight\n    for item, weight in sorted_items:\n        min_bin = min(bin_weights, key=bin_weights.get)\n        bins[min_bin].append(item)\n        bin_weights[min_bin] += weight\n\n    return bins, bin_weights"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Create dictionaries to store the items in each bin and their total weight\n    bins = defaultdict(list)\n    bin_weights = defaultdict(int)\n\n    # Sort the items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Place each item into the bin with the current lowest total weight\n    for item, weight in sorted_items:\n        min_bin = min(bin_weights, key=bin_weights.get)\n        bins[min_bin].append(item)\n        bin_weights[min_bin] += weight\n\n    return bins, bin_weights"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    bin_contents = defaultdict(list)\n    bin_weights = defaultdict(int)\n\n    # Sort items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    for item, weight in sorted_items:\n        # Find the bin with the lowest total weight\n        min_bin = min(bin_weights, key=bin_weights.get)\n        # Add the item to the bin with the lowest total weight\n        bin_contents[min_bin].append(item)\n        bin_weights[min_bin] += weight\n\n    return dict(bin_contents), dict(bin_weights)"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Flatten the chunks_per_ranks list\n    all_chunks = [chunk for rank_chunks in chunks_per_ranks for chunk in rank_chunks]\n    \n    # Set the random seed based on the current_epoch\n    np.random.seed(seed + current_epoch)\n    \n    # Shuffle the chunk indexes\n    np.random.shuffle(all_chunks)\n    \n    # Distribute the shuffled chunks evenly across nodes\n    chunks_per_node = len(all_chunks) // distributed_env.world_size\n    node_chunks = [all_chunks[i * chunks_per_node: (i + 1) * chunks_per_node] for i in range(distributed_env.world_size)]\n    \n    # Flatten the node_chunks list\n    flattened_node_chunks = [chunk for chunks in node_chunks for chunk in chunks]\n    \n    return flattened_node_chunks"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Flatten the list of chunk indexes\n    all_chunks = [chunk for chunks in chunks_per_ranks for chunk in chunks]\n\n    # Set the random seed based on the current epoch\n    np.random.seed(seed + current_epoch)\n\n    # Shuffle the chunk indexes\n    np.random.shuffle(all_chunks)\n\n    # Calculate the number of chunks per node\n    chunks_per_node = len(all_chunks) // distributed_env.world_size\n\n    # Distribute the shuffled chunk indexes to each node\n    distributed_chunks = [\n        all_chunks[i * chunks_per_node : (i + 1) * chunks_per_node]\n        for i in range(distributed_env.world_size)\n    ]\n\n    return distributed_chunks[distributed_env.rank]"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Flatten the list of chunk indexes\n    all_chunks = [chunk for chunks in chunks_per_ranks for chunk in chunks]\n\n    # Set the random seed based on the current epoch\n    np.random.seed(seed + current_epoch)\n\n    # Shuffle the chunk indexes\n    np.random.shuffle(all_chunks)\n\n    # Calculate the number of chunks per node\n    num_chunks_per_node = len(all_chunks) // distributed_env.world_size\n\n    # Distribute the shuffled chunk indexes to each node\n    distributed_chunks = [\n        all_chunks[i * num_chunks_per_node : (i + 1) * num_chunks_per_node]\n        for i in range(distributed_env.world_size)\n    ]\n\n    return distributed_chunks[distributed_env.rank]"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Flatten the list of chunks_per_ranks\n    all_chunks = [chunk for chunks in chunks_per_ranks for chunk in chunks]\n\n    # Set the random seed based on the current epoch\n    np.random.seed(seed + current_epoch)\n\n    # Shuffle the chunk indexes\n    np.random.shuffle(all_chunks)\n\n    # Calculate the number of chunks per node\n    chunks_per_node = len(all_chunks) // distributed_env.world_size\n\n    # Distribute the shuffled chunk indexes to each node\n    distributed_chunks = [all_chunks[i * chunks_per_node:(i + 1) * chunks_per_node] for i in range(distributed_env.world_size)]\n\n    # Flatten the distributed_chunks list\n    flattened_chunks = [chunk for chunks in distributed_chunks for chunk in chunks]\n\n    return flattened_chunks"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Flatten the list of chunk indexes assigned to each rank\n    flattened_chunks = [chunk for chunks in chunks_per_ranks for chunk in chunks]\n\n    # Set the random seed based on the provided seed and the current epoch\n    np.random.seed(seed + current_epoch)\n\n    # Shuffle the flattened list of chunk indexes\n    np.random.shuffle(flattened_chunks)\n\n    # Calculate the number of chunks per node\n    chunks_per_node = len(flattened_chunks) // distributed_env.world_size\n\n    # Distribute the shuffled chunk indexes to each node\n    distributed_chunks = [\n        flattened_chunks[i * chunks_per_node : (i + 1) * chunks_per_node]\n        for i in range(distributed_env.world_size)\n    ]\n\n    return distributed_chunks[distributed_env.rank]"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Flatten the list of chunk indexes\n    all_chunks = [chunk for chunks in chunks_per_ranks for chunk in chunks]\n\n    # Set the random seed based on the current epoch\n    np.random.seed(seed + current_epoch)\n\n    # Shuffle the chunk indexes\n    np.random.shuffle(all_chunks)\n\n    # Calculate the number of chunks per node\n    num_chunks_per_node = len(all_chunks) // distributed_env.world_size\n\n    # Distribute the shuffled chunk indexes to each node\n    distributed_chunks = [\n        all_chunks[i * num_chunks_per_node : (i + 1) * num_chunks_per_node]\n        for i in range(distributed_env.rank)\n    ]\n\n    # Add any remaining chunks to the last node\n    distributed_chunks[-1].extend(all_chunks[num_chunks_per_node * distributed_env.rank :])\n\n    # Flatten the list of distributed chunks\n    flattened_distributed_chunks = [chunk for chunks in distributed_chunks for chunk in chunks]\n\n    return flattened_distributed_chunks"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Flatten the chunks_per_ranks list\n    flat_chunks = [chunk for chunks in chunks_per_ranks for chunk in chunks]\n\n    # Set the random seed based on the input seed and current epoch\n    np.random.seed(seed + current_epoch)\n\n    # Shuffle the flattened list of chunk indexes\n    np.random.shuffle(flat_chunks)\n\n    # Calculate the number of chunks per node\n    num_chunks_per_node = len(flat_chunks) // distributed_env.world_size\n\n    # Distribute the shuffled chunk indexes to each node\n    distributed_chunks = []\n    for i in range(distributed_env.world_size):\n        start_index = i * num_chunks_per_node\n        end_index = (i + 1) * num_chunks_per_node\n        if i == distributed_env.world_size - 1:\n            distributed_chunks.append(flat_chunks[start_index:])\n        else:\n            distributed_chunks.append(flat_chunks[start_index:end_index])\n\n    # Flatten the distributed_chunks list and return the result\n    return [chunk for chunks in distributed_chunks for chunk in chunks]"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Flatten the list of chunk indexes\n    all_chunk_indexes = [chunk for rank_chunks in chunks_per_ranks for chunk in rank_chunks]\n\n    # Set the random seed based on the current epoch\n    np.random.seed(seed + current_epoch)\n\n    # Shuffle the chunk indexes\n    np.random.shuffle(all_chunk_indexes)\n\n    # Calculate the number of chunks per node\n    chunks_per_node = len(all_chunk_indexes) // distributed_env.world_size\n\n    # Distribute the shuffled chunk indexes to each node\n    distributed_chunks = [all_chunk_indexes[i * chunks_per_node: (i + 1) * chunks_per_node] for i in range(distributed_env.world_size)]\n\n    # Flatten the distributed chunks for the current node\n    my_chunks = distributed_chunks[distributed_env.rank]\n\n    return my_chunks"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Flatten the list of chunk indexes across all nodes\n    all_chunks = [chunk for chunks in chunks_per_ranks for chunk in chunks]\n\n    # Set the random seed based on the current epoch\n    np.random.seed(seed + current_epoch)\n\n    # Shuffle the chunk indexes\n    np.random.shuffle(all_chunks)\n\n    # Distribute the shuffled chunks evenly across nodes\n    node_chunk_count = len(all_chunks) // distributed_env.world_size\n    node_chunks = [all_chunks[i * node_chunk_count : (i + 1) * node_chunk_count] for i in range(distributed_env.world_size)]\n\n    # Return the shuffled chunk indexes for the current node\n    return node_chunks[distributed_env.rank]"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Flatten the list of chunk indexes\n    all_chunks = [chunk for rank_chunks in chunks_per_ranks for chunk in rank_chunks]\n    \n    # Set the random seed based on the current epoch\n    np.random.seed(seed + current_epoch)\n    \n    # Shuffle the chunk indexes\n    np.random.shuffle(all_chunks)\n    \n    # Calculate the number of chunks per node\n    chunks_per_node = len(all_chunks) // distributed_env.world_size\n    \n    # Distribute the shuffled chunk indexes across nodes\n    distributed_chunks = []\n    for i in range(distributed_env.world_size):\n        start_idx = i * chunks_per_node\n        end_idx = (i + 1) * chunks_per_node if i < distributed_env.world_size - 1 else None\n        distributed_chunks.append(all_chunks[start_idx:end_idx])\n    \n    return distributed_chunks"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    np.random.seed(seed + current_epoch)\n    flattened_chunks = [chunk for chunks in chunks_per_ranks for chunk in chunks]\n    np.random.shuffle(flattened_chunks)\n\n    # Distribute the shuffled chunks evenly across all nodes\n    num_nodes = distributed_env.world_size\n    node_chunks = [[] for _ in range(num_nodes)]\n    for i, chunk in enumerate(flattened_chunks):\n        node_chunks[i % num_nodes].append(chunk)\n\n    return [chunk for chunks in node_chunks for chunk in chunks]"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Flatten the list of chunk indexes assigned to each rank\n    all_chunks = [chunk for chunks in chunks_per_ranks for chunk in chunks]\n\n    # Set the random seed based on the current epoch\n    np.random.seed(seed + current_epoch)\n\n    # Shuffle the chunk indexes\n    np.random.shuffle(all_chunks)\n\n    # Distribute the shuffled chunk indexes across nodes\n    chunk_counts = [len(chunks) for chunks in chunks_per_ranks]\n    scattered_chunks = np.split(all_chunks, np.cumsum(chunk_counts)[:-1])\n\n    # Return the shuffled chunk indexes for the current node\n    return scattered_chunks[distributed_env.rank]"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Flatten the list of chunk indexes\n    flattened_chunks = [chunk for sublist in chunks_per_ranks for chunk in sublist]\n\n    # Set the random seed based on the current epoch\n    np.random.seed(seed + current_epoch)\n\n    # Shuffle the flattened list of chunk indexes\n    np.random.shuffle(flattened_chunks)\n\n    # Calculate the number of chunks per node\n    num_chunks_per_node = len(flattened_chunks) // distributed_env.world_size\n\n    # Distribute the shuffled chunk indexes to each node\n    distributed_chunks = []\n    for i in range(distributed_env.world_size):\n        start_index = i * num_chunks_per_node\n        end_index = (i + 1) * num_chunks_per_node if i < distributed_env.world_size - 1 else len(flattened_chunks)\n        distributed_chunks.extend(flattened_chunks[start_index:end_index])\n\n    return distributed_chunks"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Flatten the list of chunk indexes\n    flattened_chunks = [chunk for rank_chunks in chunks_per_ranks for chunk in rank_chunks]\n    \n    # Set the random seed based on the provided seed and current epoch\n    np.random.seed(seed + current_epoch)\n    \n    # Shuffle the flattened list of chunk indexes\n    np.random.shuffle(flattened_chunks)\n    \n    # Calculate the number of chunks per node\n    chunks_per_node = len(flattened_chunks) // distributed_env.world_size\n    \n    # Distribute the shuffled chunks evenly across nodes\n    distributed_chunks = [flattened_chunks[i * chunks_per_node:(i + 1) * chunks_per_node] for i in range(distributed_env.world_size)]\n    \n    # Flatten the distributed chunks list\n    shuffled_chunks = [chunk for node_chunks in distributed_chunks for chunk in node_chunks]\n    \n    return shuffled_chunks"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Flatten the chunks_per_ranks list\n    flattened_chunks = [chunk for sublist in chunks_per_ranks for chunk in sublist]\n    \n    # Set the random seed based on the provided seed and current epoch\n    np.random.seed(seed + current_epoch)\n    \n    # Shuffle the flattened list of chunk indexes\n    np.random.shuffle(flattened_chunks)\n    \n    # Calculate the number of chunks per node\n    chunks_per_node = len(flattened_chunks) // distributed_env.world_size\n    \n    # Distribute the shuffled chunk indexes to each node\n    distributed_chunks = [flattened_chunks[i * chunks_per_node:(i + 1) * chunks_per_node] for i in range(distributed_env.world_size)]\n    \n    # Flatten the distributed chunks list and return\n    return [chunk for sublist in distributed_chunks for chunk in sublist]"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Flatten the chunks_per_ranks list\n    flattened_chunks = [chunk for chunks in chunks_per_ranks for chunk in chunks]\n\n    # Set the random seed based on the current epoch\n    np.random.seed(seed + current_epoch)\n\n    # Shuffle the flattened list of chunk indexes\n    np.random.shuffle(flattened_chunks)\n\n    # Calculate the number of chunks per node\n    num_chunks_per_node = len(flattened_chunks) // distributed_env.world_size\n\n    # Distribute the shuffled chunks to each node\n    distributed_chunks = [\n        flattened_chunks[i * num_chunks_per_node : (i + 1) * num_chunks_per_node]\n        for i in range(distributed_env.rank)\n    ]\n\n    # Return the flattened list of shuffled chunk indexes for the current node\n    return distributed_chunks[distributed_env.rank]"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Flatten the list of chunk indexes assigned to each rank\n    all_chunks = [chunk for chunks in chunks_per_ranks for chunk in chunks]\n\n    # Set the seed based on the current epoch to ensure different shuffles for each epoch\n    np.random.seed(seed + current_epoch)\n\n    # Shuffle the chunk indexes\n    np.random.shuffle(all_chunks)\n\n    # Calculate the number of chunks per node\n    chunks_per_node = len(all_chunks) // distributed_env.world_size\n\n    # Distribute the shuffled chunk indexes to each node\n    shuffled_chunks = [all_chunks[i * chunks_per_node : (i + 1) * chunks_per_node] for i in range(distributed_env.world_size)]\n\n    return shuffled_chunks"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Flatten the chunks_per_ranks list\n    all_chunks = [chunk for chunks in chunks_per_ranks for chunk in chunks]\n    \n    # Set the random seed based on the current epoch\n    np.random.seed(seed + current_epoch)\n    \n    # Shuffle the chunk indexes\n    np.random.shuffle(all_chunks)\n    \n    # Determine the number of chunks per node\n    chunks_per_node = len(all_chunks) // distributed_env.world_size\n    \n    # Distribute the shuffled chunk indexes to each node\n    distributed_chunks = [all_chunks[i * chunks_per_node : (i + 1) * chunks_per_node] for i in range(distributed_env.world_size)]\n    \n    return distributed_chunks[distributed_env.rank]"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Flatten the list of chunk indexes assigned to each rank\n    all_chunks = [chunk for chunks in chunks_per_ranks for chunk in chunks]\n\n    # Set the random seed based on the input seed and current epoch\n    np.random.seed(seed + current_epoch)\n\n    # Shuffle the chunk indexes\n    np.random.shuffle(all_chunks)\n\n    # Distribute the shuffled chunk indexes across nodes\n    chunk_counts = [len(chunks) for chunks in chunks_per_ranks]\n    chunk_displacements = [0] + list(np.cumsum(chunk_counts))[:-1]\n    local_chunk_indexes = np.array_split(all_chunks, chunk_counts)\n\n    # Return the shuffled chunk indexes for the current node\n    return list(local_chunk_indexes[distributed_env.rank])"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Flatten the chunks_per_ranks list\n    all_chunks = [chunk for chunks in chunks_per_ranks for chunk in chunks]\n\n    # Set the random seed based on the current epoch\n    np.random.seed(seed + current_epoch)\n\n    # Shuffle the chunk indexes\n    np.random.shuffle(all_chunks)\n\n    # Calculate the number of chunks per node\n    num_chunks_per_node = len(all_chunks) // distributed_env.world_size\n\n    # Distribute the shuffled chunks to each node\n    distributed_chunks = [\n        all_chunks[i * num_chunks_per_node : (i + 1) * num_chunks_per_node]\n        for i in range(distributed_env.world_size)\n    ]\n\n    # Flatten the distributed_chunks list\n    flattened_distributed_chunks = [chunk for chunks in distributed_chunks for chunk in chunks]\n\n    return flattened_distributed_chunks"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if abs(num_bytes) < 1000.0:\n            return f\"{num_bytes:.1f} {unit}\"\n        num_bytes /= 1000.0\n    return f\"{num_bytes:.1f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if num_bytes < 1000:\n            return f\"{num_bytes:.2f} {suffix}\"\n        num_bytes /= 1000\n    return f\"{num_bytes:.2f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in [\"B\"] + list(_FORMAT_TO_RATIO.keys()):\n        if num_bytes < _FORMAT_TO_RATIO[suffix]:\n            return f\"{num_bytes:.2f} {suffix}\"\n        num_bytes /= _FORMAT_TO_RATIO[suffix]\n    return f\"{num_bytes:.2f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if num_bytes < 1000:\n            return f\"{num_bytes:.2f} {suffix}\"\n        num_bytes /= 1000\n    return f\"{num_bytes:.2f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if num_bytes < 1000:\n            return f\"{num_bytes:.2f} {suffix}\"\n        num_bytes /= 1000\n    return f\"{num_bytes:.2f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if num_bytes < 1000:\n            return f\"{num_bytes:.2f} {suffix}\"\n        num_bytes /= 1000\n    return f\"{num_bytes:.2f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if num_bytes < 1000:\n            return f\"{num_bytes:.2f} {suffix}\"\n        num_bytes /= 1000\n    return f\"{num_bytes:.2f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in [\"B\"] + list(_FORMAT_TO_RATIO.keys()):\n        if num_bytes < _FORMAT_TO_RATIO[suffix]:\n            return f\"{num_bytes:.2f} {suffix}\"\n        num_bytes /= _FORMAT_TO_RATIO[suffix]\n    return f\"{num_bytes:.2f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if num_bytes < 1000:\n            return f\"{num_bytes:.2f} {suffix}\"\n        num_bytes /= 1000\n    return f\"{num_bytes:.2f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if num_bytes < 1000:\n            return f\"{num_bytes:.2f} {suffix}\"\n        num_bytes /= 1000\n    return f\"{num_bytes:.2f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in [\"B\"] + list(_FORMAT_TO_RATIO.keys()):\n        if num_bytes < _FORMAT_TO_RATIO[suffix]:\n            return f\"{num_bytes:.2f} {suffix}\"\n        num_bytes /= _FORMAT_TO_RATIO[suffix]\n    return f\"{num_bytes:.2f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if num_bytes < 1000:\n            return f\"{num_bytes:.2f} {unit}\"\n        num_bytes /= 1000\n    return f\"{num_bytes:.2f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if num_bytes < 1000:\n            return f\"{num_bytes:.2f} {suffix}\"\n        num_bytes /= 1000\n    return f\"{num_bytes:.2f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if num_bytes < 1000:\n            return f\"{num_bytes:.2f} {suffix}\"\n        num_bytes /= 1000\n    return f\"{num_bytes:.2f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "\n    for suffix in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if num_bytes < 1000:\n            return f\"{num_bytes:.2f} {suffix}\"\n        num_bytes /= 1000\n    return f\"{num_bytes:.2f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in [\"B\"] + list(_FORMAT_TO_RATIO.keys()):\n        if abs(num_bytes) < _FORMAT_TO_RATIO[suffix]:\n            return f\"{num_bytes:.2f} {suffix}\"\n        num_bytes /= _FORMAT_TO_RATIO[suffix]\n    return f\"{num_bytes:.2f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if num_bytes < 1000:\n            return f\"{num_bytes:.2f} {suffix}\"\n        num_bytes /= 1000\n    return f\"{num_bytes:.2f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for suffix in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if num_bytes < 1000:\n            return f\"{num_bytes:.2f} {suffix}\"\n        num_bytes /= 1000\n    return f\"{num_bytes:.2f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if abs(num_bytes) < 1000.0:\n            return f\"{num_bytes:.1f} {unit}\"\n        num_bytes /= 1000.0\n    return f\"{num_bytes:.1f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if abs(num_bytes) < 1000:\n            return f\"{num_bytes:.2f} {unit}\"\n        num_bytes /= 1000\n    return f\"{num_bytes:.2f} PB\""}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if not indexed_paths:\n        return None\n\n    input_dir = os.path.dirname(list(indexed_paths.values())[0])\n    return input_dir"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if not indexed_paths:\n        return None\n\n    input_dir = os.path.dirname(indexed_paths[0])\n\n    if len(indexed_paths) > 1:\n        for index, path in indexed_paths.items():\n            if os.path.dirname(path) != input_dir:\n                raise ValueError(\"Inconsistent file paths found in the input sequence\")\n\n    return input_dir"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if not indexed_paths:\n        return None\n\n    input_dir = os.path.commonpath(indexed_paths.values())\n\n    return input_dir"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if not indexed_paths:\n        return None\n\n    input_dir = os.path.dirname(list(indexed_paths.values())[0])\n    return input_dir"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if indexed_paths:\n        first_path = list(indexed_paths.values())[0]\n        input_dir = os.path.dirname(first_path)\n        return os.path.abspath(input_dir)\n    else:\n        return None"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if not indexed_paths:\n        return None\n\n    input_dir = os.path.dirname(list(indexed_paths.values())[0])\n    return os.path.abspath(input_dir)"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if not indexed_paths:\n        return None\n\n    input_dir = os.path.dirname(list(indexed_paths.values())[0])\n    return input_dir"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if not indexed_paths:\n        return None\n\n    first_path = indexed_paths.get(0)\n    second_path = indexed_paths.get(1)\n\n    if first_path and second_path:\n        if os.path.dirname(first_path) != os.path.dirname(second_path):\n            raise ValueError(\"Inconsistent input directories\")\n\n    input_dir = os.path.dirname(first_path) if first_path else os.path.dirname(second_path)\n\n    return input_dir"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if not indexed_paths:\n        return None\n\n    input_dir = os.path.dirname(list(indexed_paths.values())[0])\n    return input_dir"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if not indexed_paths:\n        return None\n\n    input_dir = os.path.dirname(list(indexed_paths.values())[0])\n    return input_dir"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if not indexed_paths:\n        return None\n\n    input_dir = os.path.commonpath(indexed_paths.values())\n\n    return input_dir"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if not indexed_paths:\n        return None\n\n    input_dir = os.path.dirname(indexed_paths[0])\n\n    if len(indexed_paths) > 1:\n        for index, path in indexed_paths.items():\n            if os.path.dirname(path) != input_dir:\n                raise ValueError(\"Inconsistent file paths found in input sequence.\")\n\n    return input_dir"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if not indexed_paths:\n        return None\n\n    # Check if the first two elements of the input sequence are valid file paths\n    first_input_path = indexed_paths.get(0)\n    second_input_path = indexed_paths.get(1)\n\n    if first_input_path and second_input_path:\n        if os.path.dirname(first_input_path) != os.path.dirname(second_input_path):\n            raise ValueError(\"Inconsistent file paths found in the input sequence\")\n\n    # Format the path to include the project root or a specified depth in the file system\n    input_dir = os.path.commonpath([os.path.dirname(path) for path in indexed_paths.values()])\n\n    return input_dir"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n    if indexed_paths:\n        input_dir = os.path.dirname(list(indexed_paths.values())[0])\n        return input_dir\n    else:\n        return None"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if not indexed_paths:\n        return None\n\n    input_dir = os.path.commonpath(indexed_paths.values())\n\n    return input_dir"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if not indexed_paths:\n        return None\n\n    input_dir = os.path.dirname(indexed_paths[0])\n    for index, path in indexed_paths.items():\n        if os.path.dirname(path) != input_dir:\n            raise ValueError(\"Inconsistent file paths found in the input sequence.\")\n\n    return input_dir"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if not indexed_paths:\n        return None\n\n    input_dir = os.path.dirname(list(indexed_paths.values())[0])\n\n    return input_dir"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n    if not indexed_paths:\n        return None\n\n    input_dir = os.path.commonpath(indexed_paths.values())\n    return input_dir"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if not indexed_paths:\n        return None\n\n    input_dir = os.path.dirname(list(indexed_paths.values())[0])\n\n    if len(indexed_paths) > 1:\n        for path in indexed_paths.values():\n            if os.path.dirname(path) != input_dir:\n                raise ValueError(\"Inconsistent input directory paths found\")\n\n    return input_dir"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if not indexed_paths:\n        return None\n\n    input_dir = os.path.dirname(list(indexed_paths.values())[0])\n\n    for path in indexed_paths.values():\n        if os.path.dirname(path) != input_dir:\n            raise ValueError(\"Inconsistent input directory paths found\")\n\n    return input_dir"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # Dilation\n    dt = t * dilation\n\n    # Clipping\n    dt = torch.clamp(dt, min=domain[0], max=domain[1])\n\n    # Adjusting weights\n    dw = w / dilation\n\n    return dt, dw"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "\n    # Dilate the time steps\n    dilated_t = t * dilation\n\n    # Clip the dilated time steps within the specified domain\n    dilated_t = torch.clamp(dilated_t, min=domain[0], max=domain[1])\n\n    # Adjust the weights to match the dilated time steps\n    adjusted_w = w / dilation\n\n    return dilated_t, adjusted_w"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "\n    # Perform dilation by adjusting the time steps\n    dilated_t = t * dilation\n\n    # Clip the dilated time steps within the specified domain\n    dilated_t = torch.clamp(dilated_t, min=domain[0], max=domain[1])\n\n    # Adjust the weights to match the dilated time steps\n    adjusted_w = w / dilation\n\n    return dilated_t, adjusted_w"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "\n    # Dilate the time steps\n    dilated_t = t * dilation\n\n    # Clip the dilated time steps within the specified domain\n    dilated_t = torch.clamp(dilated_t, domain[0], domain[1])\n\n    # Adjust the weights to match the dilated time steps\n    dilated_w = w / dilation\n\n    return dilated_t, dilated_w"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # Calculate the dilated time steps\n    dilated_t = t * dilation\n\n    # Clip the dilated time steps within the specified domain\n    dilated_t = torch.clamp(dilated_t, min=domain[0], max=domain[1])\n\n    # Adjust the weights to match the dilated time steps\n    adjusted_w = w / dilation\n\n    return dilated_t, adjusted_w"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # Dilate the time steps\n    dilated_t = t * dilation\n\n    # Clip the dilated time steps within the specified domain\n    dilated_t = torch.clamp(dilated_t, min=domain[0], max=domain[1])\n\n    # Adjust the weights corresponding to the dilated time steps\n    adjusted_w = w / dilation\n\n    return dilated_t, adjusted_w"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "\n    # Dilate the time steps\n    dilated_t = t * dilation\n\n    # Clip the dilated time steps within the specified domain\n    dilated_t = torch.clamp(dilated_t, min=domain[0], max=domain[1])\n\n    # Adjust the weights to match the dilated time steps\n    adjusted_w = w / dilation\n\n    return dilated_t, adjusted_w"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "\n    # Compute the dilated time steps\n    dilated_t = t * dilation\n\n    # Clip the dilated time steps within the specified domain\n    dilated_t = torch.clamp(dilated_t, min=domain[0], max=domain[1])\n\n    # Adjust the weights to match the dilated time steps\n    adjusted_w = w / dilation\n\n    return dilated_t, adjusted_w"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "\n    # Dilate the time steps\n    dilated_t = t * dilation\n\n    # Clip the dilated time steps within the specified domain\n    dilated_t = torch.clamp(dilated_t, min=domain[0], max=domain[1])\n\n    # Adjust the weights to match the dilated time steps\n    # Compute the new weights based on the dilation factor\n    adjusted_w = w / dilation\n\n    return dilated_t, adjusted_w"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "\n    # Apply dilation to the time steps\n    dilated_t = t * dilation\n\n    # Clip the dilated time steps within the specified domain\n    dilated_t = torch.clamp(dilated_t, min=domain[0], max=domain[1])\n\n    # Adjust the weights based on the dilation factor\n    adjusted_w = w / dilation\n\n    return dilated_t, adjusted_w"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "\n    # Dilate the time steps\n    dilated_t = t * dilation\n\n    # Clip the dilated time steps within the specified domain\n    dilated_t = torch.clamp(dilated_t, min=domain[0], max=domain[1])\n\n    # Adjust the weights to match the dilated time steps\n    adjusted_w = w / dilation\n\n    return dilated_t, adjusted_w"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # Dilation\n    dilated_t = t * dilation\n\n    # Clipping the dilated time steps within the specified domain\n    dilated_t = torch.clamp(dilated_t, min=domain[0], max=domain[1])\n\n    # Adjusting the weights to match the dilated time steps\n    dt, dw = matchup_channels(dilated_t, w)\n\n    return dt, dw"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "\n    # Apply dilation to the time steps\n    dilated_t = t * dilation\n\n    # Clip the dilated time steps within the specified domain\n    dilated_t = torch.clamp(dilated_t, min=domain[0], max=domain[1])\n\n    # Adjust the weights to match the dilated time steps\n    # Compute the ratio of the original time step interval to the dilated time step interval\n    ratio = (t[..., 1:] - t[..., :-1]) / (dilated_t[..., 1:] - dilated_t[..., :-1]).clamp_min(1e-8)\n\n    # Adjust the weights based on the ratio\n    adjusted_w = w * ratio\n\n    return dilated_t, adjusted_w"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "\n    # Dilate the time steps\n    dilated_t = t * dilation\n\n    # Clip the dilated time steps within the specified domain\n    dilated_t = torch.clamp(dilated_t, min=domain[0], max=domain[1])\n\n    # Adjust the weights to match the dilated time steps\n    adjusted_w = w / dilation\n\n    return dilated_t, adjusted_w"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "\n    # Dilate the time steps\n    dilated_t = t * dilation\n\n    # Clip the dilated time steps within the specified domain\n    dilated_t = torch.clamp(dilated_t, min=domain[0], max=domain[1])\n\n    # Adjust the weights to match the dilated time steps\n    adjusted_w = w / dilation\n\n    return dilated_t, adjusted_w"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "\n    # Perform dilation\n    dilated_t = t * dilation\n\n    # Clip the dilated time steps within the specified domain\n    dilated_t = torch.clamp(dilated_t, min=domain[0], max=domain[1])\n\n    # Adjust the weights to match the dilated time steps\n    adjusted_w = w / dilation\n\n    return dilated_t, adjusted_w"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "\n    # Dilate the time steps\n    dilated_t = t * dilation\n\n    # Clip the dilated time steps within the specified domain\n    dilated_t = torch.clamp(dilated_t, min=domain[0], max=domain[1])\n\n    # Adjust the weights to match the dilated time steps\n    # The weights are adjusted based on the ratio of the original time step width to the dilated time step width\n    # This ensures that the total weight remains the same after dilation\n    width_ratio = t[..., 1:] - t[..., :-1] / (dilated_t[..., 1:] - dilated_t[..., :-1])\n    adjusted_w = w * width_ratio\n\n    return dilated_t, adjusted_w"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "\n    # Apply dilation to time steps\n    dilated_t = t * dilation\n\n    # Clip dilated time steps within the specified domain\n    dilated_t = torch.clamp(dilated_t, min=domain[0], max=domain[1])\n\n    # Adjust weights to match the dilated time steps\n    adjusted_w = w / dilation\n\n    return dilated_t, adjusted_w"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "\n    # Dilate the time steps\n    dilated_t = t * dilation\n\n    # Clip the dilated time steps within the specified domain\n    dilated_t = torch.clamp(dilated_t, min=domain[0], max=domain[1])\n\n    # Adjust the weights to match the dilated time steps\n    # Compute the new weights based on the dilation factor\n    dilated_w = w / dilation\n\n    return dilated_t, dilated_w"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "\n    # Dilate the time steps\n    dilated_t = t * dilation\n\n    # Clip the dilated time steps within the specified domain\n    dilated_t = torch.clamp(dilated_t, min=domain[0], max=domain[1])\n\n    # Adjust the weights to match the dilated time steps\n    adjusted_w = w / dilation\n\n    return dilated_t, adjusted_w"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    indices = torch.searchsorted(t, tq)\n    matches = (t[indices] == tq).float()\n    result = (1 - matches) * interpolate(tq, t, y) + matches * outside_value\n    return result"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Find the indices where tq should be inserted into t to maintain order\n    idx_lo, idx_hi = searchsorted(t, tq)\n\n    # Check if query times match a step change time\n    is_step_change = torch.where(tq == t[idx_lo], torch.ones_like(tq), torch.zeros_like(tq))\n\n    # Interpolate the values at the query times based on the step function\n    interpolated_values = (y[idx_lo] * (1 - is_step_change)) + (outside_value * is_step_change)\n\n    return interpolated_values"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Find the indices where tq should be inserted into t to maintain order\n    idx_lo, idx_hi = searchsorted(t, tq)\n\n    # Check if query times match a step change time\n    is_step_change = torch.logical_and(tq == t[idx_lo], tq == t[idx_hi])\n\n    # Interpolate the values at the query times based on the step function\n    interpolated_values = interpolate(tq, t, y)\n\n    # Return the outside value for query times that exactly match a step change time, otherwise return the interpolated values\n    result = torch.where(is_step_change, outside_value, interpolated_values)\n\n    return result"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "\n    # Find the indices where tq should be inserted into t to maintain order\n    idx_lo, idx_hi = searchsorted(t, tq)\n\n    # Check if query times exactly match a step change time\n    exact_match = (t[idx_lo] == tq) | (t[idx_hi] == tq)\n\n    # Interpolate the value at the query time based on the step function\n    interpolated_values = interpolate(tq, t, y)\n\n    # Return the outside value for query times that exactly match a step change time\n    result = torch.where(exact_match, outside_value, interpolated_values)\n\n    return result"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Find the indices where tq should be inserted into t to maintain order\n    idx_lo, idx_hi = searchsorted(t, tq)\n\n    # Check if query times exactly match a step change time\n    exact_match = tq == t[idx_lo]\n\n    # Interpolate the value at the query time based on the step function\n    interpolated_values = interpolate(tq, t, y)\n\n    # Return the outside value for query times that exactly match a step change time\n    result = torch.where(exact_match, outside_value, interpolated_values)\n\n    return result"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Find the indices where tq should be inserted into t to maintain order\n    idx_lo, idx_hi = searchsorted(t, tq)\n\n    # Check if query times exactly match a step change time\n    exact_match = torch.where(t[idx_lo] == tq, torch.ones_like(tq), torch.zeros_like(tq))\n\n    # Interpolate the values at the query times based on the step function\n    interpolated_values = (y[idx_lo] * (t[idx_hi] - tq) + y[idx_hi] * (tq - t[idx_lo])) / (t[idx_hi] - t[idx_lo])\n\n    # Return the outside value for exact matches, otherwise return the interpolated values\n    return torch.where(exact_match, outside_value, interpolated_values)"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Find the indices where tq should be inserted into t to maintain order\n    idx_lo, idx_hi = searchsorted(t, tq)\n\n    # Check if query times exactly match a step change time\n    exact_match = torch.where(tq == t[idx_lo], torch.full_like(tq, outside_value), torch.full_like(tq, 0))\n\n    # Interpolate the value at the query time based on the step function\n    interpolated_values = interpolate(tq, t, y)\n\n    # Return the interpolated values or outside values for exact matches\n    return exact_match + torch.where(tq == t[idx_lo], torch.full_like(tq, outside_value), interpolated_values)"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "\n    # Find the indices where tq should be inserted into t to maintain order\n    idx_lo, idx_hi = searchsorted(t, tq)\n\n    # If query time matches a step change time, return outside value\n    matched_step_change = (t[idx_lo] == tq) | (t[idx_hi] == tq)\n    result = torch.where(matched_step_change, outside_value, 0)\n\n    # Interpolate the value at the query time based on the step function\n    result += interpolate(tq, t, y)\n\n    return result"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Find the indices where tq should be inserted into t to maintain order\n    idx_lo, idx_hi = searchsorted(t, tq)\n\n    # Check if query times match a step change time\n    match = torch.where(t[idx_lo] == tq, outside_value, 0)\n\n    # Interpolate the value at the query time based on the step function\n    interpolated_values = interpolate(tq, t, y)\n\n    # Return the interpolated or outside values of the step function at the query times\n    return match + interpolated_values"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "\n    # Find the indices where tq should be inserted into t to maintain order\n    idx_lo, idx_hi = searchsorted(t, tq)\n\n    # Check if query times exactly match a step change time\n    exact_match = torch.logical_and(tq == t[idx_lo], idx_hi < len(t))\n\n    # Interpolate the values at the query times based on the step function\n    interpolated_values = interpolate(tq, t, y)\n\n    # Return the outside value for query times that exactly match a step change time\n    result = torch.where(exact_match, outside_value, interpolated_values)\n\n    return result"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Find the indices where tq should be inserted into t to maintain order\n    idx_lo, idx_hi = searchsorted(t, tq)\n\n    # Check if tq exactly matches a step change time\n    exact_match = tq == t[idx_lo]\n\n    # Interpolate the values at the query times based on the step function\n    interpolated_values = interpolate(tq, t, y)\n\n    # Return the outside value for query times that exactly match a step change time\n    result = torch.where(exact_match, outside_value, interpolated_values)\n\n    return result"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Find the indices where tq should be inserted into t to maintain order\n    idx_lo, idx_hi = searchsorted(t, tq)\n\n    # Check if query time exactly matches a step change time\n    exact_match = torch.where(t[idx_lo] == tq, outside_value, 0)\n\n    # Interpolate the value at the query time based on the step function\n    interpolated_value = interpolate(tq, t, y)\n\n    # Return the interpolated or outside values of the step function at the query times\n    return exact_match + interpolated_value"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Find the indices where tq should be inserted into t to maintain order\n    idx_lo, idx_hi = searchsorted(t, tq)\n\n    # Check if query times match a step change time\n    match_step_change = torch.where(t[idx_lo] == tq, 1, 0)\n\n    # Interpolate the value at the query time based on the step function\n    interpolated_values = (y[idx_lo] * (1 - match_step_change) + outside_value * match_step_change)\n\n    return interpolated_values"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Find the indices where tq should be inserted into t to maintain order\n    idx_lo, idx_hi = searchsorted(t, tq)\n\n    # Check if query time exactly matches a step change time\n    exact_match = torch.eq(tq, t[idx_lo])\n\n    # Interpolate the value at the query time based on the step function\n    interpolated_values = interpolate(tq, t, y)\n\n    # Return outside value for query times that exactly match a step change time\n    result = torch.where(exact_match, outside_value, interpolated_values)\n\n    return result"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "\n    # Find the indices where tq should be inserted into t to maintain order\n    idx_lo, idx_hi = searchsorted(t, tq)\n\n    # Check if query times match a step change time\n    is_step_change = tq == t[idx_lo]\n\n    # Interpolate the values at the query times based on the step function\n    interpolated_values = interpolate(tq, t, y)\n\n    # Return the outside value for query times that exactly match a step change time\n    result = torch.where(is_step_change, outside_value, interpolated_values)\n\n    return result"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Find the indices where tq should be inserted into t to maintain order\n    idx_lo, idx_hi = searchsorted(t, tq)\n\n    # Check if query times exactly match a step change time\n    exact_match = torch.eq(tq, t[idx_lo])\n\n    # Interpolate the value at the query time based on the step function\n    interpolated_values = interpolate(tq, t, y)\n\n    # Return the outside value for query times that exactly match a step change time\n    result = torch.where(exact_match, outside_value, interpolated_values)\n\n    return result"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Find the indices where tq should be inserted into t to maintain order\n    idx_lo, idx_hi = searchsorted(t, tq)\n\n    # Check if query times exactly match a step change time\n    exact_match = tq == t[idx_lo]\n\n    # Interpolate the values at the query times based on the step function\n    interpolated_values = interpolate(tq, t, y)\n\n    # Return outside value for query times that exactly match a step change time\n    result = torch.where(exact_match, outside_value, interpolated_values)\n\n    return result"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Find the indices where tq should be inserted into t to maintain order\n    idx_lo, idx_hi = searchsorted(t, tq)\n\n    # Check if the query times match a step change time\n    match = (t[idx_lo] == tq) | (t[idx_hi] == tq)\n\n    # Interpolate the values at the query times based on the step function\n    interpolated_values = interpolate(tq, t, y)\n\n    # Return the outside value for query times that exactly match a step change time\n    result = torch.where(match, outside_value, interpolated_values)\n\n    return result"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "\n    # Find the indices where tq should be inserted into t to maintain order\n    idx_lo, idx_hi = searchsorted(t, tq)\n\n    # Check if query time exactly matches a step change time\n    exact_match = tq == t[idx_lo]\n\n    # Interpolate the values at the query times based on the step function\n    interpolated_values = interpolate(tq, t, y)\n\n    # Return outside value for query times that exactly match a step change time\n    result = torch.where(exact_match, outside_value, interpolated_values)\n\n    return result"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "\n    # Find the indices where tq should be inserted into t to maintain order\n    idx_lo, idx_hi = searchsorted(t, tq)\n\n    # Check if query times exactly match a step change time\n    exact_match = torch.eq(tq, t[idx_lo])\n\n    # Interpolate the values at the query times based on the step function\n    interpolated_values = interpolate(tq, t, y)\n\n    # Return the outside value for query times that exactly match a step change time\n    result = torch.where(exact_match, outside_value, interpolated_values)\n\n    return result"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "\n    # Compute the bias function using Schlick's bias function\n    bias = (1 - train_frac) / (train_frac * anneal_slope + eps)\n\n    # Adjust the weights based on the bias function\n    w_adjusted = w * torch.exp(-bias * t[..., :-1])\n\n    # Handle cases where adjacent intervals have zero distance by setting their weight to zero\n    w_adjusted = torch.where(t[..., 1:] - t[..., :-1] <= 0, torch.zeros_like(w_adjusted), w_adjusted)\n\n    # Prevent NaN values by using a softmax operation on the adjusted weights\n    w_adjusted = torch.nn.functional.softmax(w_adjusted, dim=-1)\n\n    return w_adjusted"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # Calculate the annealing factor using Schlick's bias function\n    bias = (1 - train_frac) / (train_frac + eps)\n    annealing_factor = torch.exp(-anneal_slope * bias)\n\n    # Adjust the weights based on the annealing factor\n    adjusted_weights = w ** annealing_factor\n\n    # Handle cases where adjacent intervals have zero distance\n    adjusted_weights = torch.where(t[..., 1:] - t[..., :-1] <= 0, torch.tensor(0.0), adjusted_weights)\n\n    # Normalize the adjusted weights using softmax to prevent NaN values\n    normalized_weights = torch.nn.functional.softmax(adjusted_weights, dim=-1)\n\n    return normalized_weights"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "\n    # Compute the bias function based on the training fraction and anneal slope\n    bias = 1 / (1 + torch.exp(-anneal_slope * (train_frac - 0.5)))\n\n    # Adjust the weights using Schlick's bias function\n    adjusted_weights = (w ** bias) / torch.sum(w ** bias, dim=-1, keepdim=True).clip(eps)\n\n    return adjusted_weights"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "\n    # Compute the bias term using Schlick's bias function\n    bias = 1 - torch.exp(-anneal_slope * train_frac)\n\n    # Compute the adjusted weights\n    adjusted_w = w * (1 - bias)\n\n    # Handle cases where adjacent intervals have zero distance by setting their weight to zero\n    adjusted_w = torch.where((t[..., 1:] - t[..., :-1]) <= eps, torch.zeros_like(adjusted_w), adjusted_w)\n\n    # Apply softmax operation to prevent NaN values\n    adjusted_w = torch.nn.functional.softmax(adjusted_w, dim=-1)\n\n    return adjusted_w"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # Calculate the annealing factor using Schlick's bias function\n    bias = (1 - train_frac) / (train_frac * anneal_slope + eps)\n    annealed_w = w * torch.exp(bias * t[..., :-1])\n\n    # Handle cases where adjacent intervals have zero distance\n    interval_distance = t[..., 1:] - t[..., :-1]\n    zero_distance_mask = interval_distance < eps\n    annealed_w = torch.where(zero_distance_mask, torch.zeros_like(annealed_w), annealed_w)\n\n    # Prevent NaN values by using softmax operation on the adjusted weights\n    softmax_w = torch.nn.functional.softmax(annealed_w, dim=-1)\n\n    return softmax_w"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # Calculate the annealing factor using Schlick's bias function\n    bias = (1 - train_frac) / (train_frac * anneal_slope + 1e-8)\n\n    # Apply the annealing factor to the weights\n    annealed_w = w ** bias\n\n    # Ensure stability by handling cases where adjacent intervals have zero distance\n    # Set the weight to zero for such intervals\n    mask = t[..., 1:] - t[..., :-1] < eps\n    annealed_w = annealed_w * (~mask)\n\n    # Normalize the adjusted weights using softmax to prevent NaN values\n    normalized_w = torch.nn.functional.softmax(annealed_w, dim=-1)\n\n    return normalized_w"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n\n    # Calculate the annealing factor using Schlick's bias function\n    annealing_factor = 1 / (1 + (train_frac / (1 - train_frac)) ** anneal_slope)\n\n    # Adjust the weights using the annealing factor\n    adjusted_w = w ** annealing_factor\n\n    # Handle cases where adjacent intervals have zero distance by setting their weight to zero\n    adjusted_w = torch.where((t[..., 1:] - t[..., :-1]) < eps, torch.zeros_like(adjusted_w), adjusted_w)\n\n    # Prevent NaN values by using a softmax operation on the adjusted weights\n    adjusted_w = torch.nn.functional.softmax(adjusted_w, dim=-1)\n\n    return adjusted_w"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # Calculate the bias using Schlick's bias function\n    bias = 1 / (1 + torch.exp(-anneal_slope * (train_frac - 0.5)))\n\n    # Calculate the adjusted weights using the bias\n    adjusted_weights = w ** bias\n\n    # Handle cases where adjacent intervals have zero distance by setting their weight to zero\n    adjusted_weights = torch.where(t[..., 1:] - t[..., :-1] <= 0, torch.zeros_like(adjusted_weights), adjusted_weights)\n\n    # Prevent NaN values by using a softmax operation on the adjusted weights\n    adjusted_weights = torch.nn.functional.softmax(adjusted_weights, dim=-1)\n\n    return adjusted_weights"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "\n    # Calculate the annealing factor using Schlick's bias function\n    bias = (1 - train_frac) / (train_frac * anneal_slope + 1)\n\n    # Adjust the weights based on the annealing factor\n    w_adjusted = w ** bias\n\n    # Handle cases where adjacent intervals have zero distance by setting their weight to zero\n    w_adjusted = torch.where((t[..., 1:] - t[..., :-1]) < eps, torch.zeros_like(w_adjusted), w_adjusted)\n\n    # Prevent NaN values by using a softmax operation on the adjusted weights\n    w_adjusted = torch.nn.functional.softmax(w_adjusted, dim=-1)\n\n    return w_adjusted"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # Calculate the annealing factor using Schlick's bias function\n    bias = (1 - train_frac) / (train_frac * anneal_slope + eps)\n    annealed_w = w * torch.exp(bias * t[..., :-1])\n\n    # Handle cases where adjacent intervals have zero distance\n    mask = (t[..., 1:] - t[..., :-1]) < eps\n    annealed_w = torch.where(mask, torch.zeros_like(annealed_w), annealed_w)\n\n    # Normalize the adjusted weights using softmax to prevent NaN values\n    normalized_w = torch.nn.functional.softmax(annealed_w, dim=-1)\n\n    return normalized_w"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # Calculate the bias function using Schlick's bias function\n    bias = (1 - train_frac) ** anneal_slope\n\n    # Calculate the adjusted weights using the bias function\n    adjusted_weights = w ** bias\n\n    # Handle cases where adjacent intervals have zero distance, setting their weight to zero\n    adjusted_weights = torch.where((t[..., 1:] - t[..., :-1]) <= eps, torch.zeros_like(adjusted_weights), adjusted_weights)\n\n    # Normalize the adjusted weights using softmax to prevent NaN values\n    normalized_weights = torch.nn.functional.softmax(adjusted_weights, dim=-1)\n\n    return normalized_weights"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "\n    # Calculate the annealing factor using Schlick's bias function\n    bias = 1 / (1 + (anneal_slope * (1 - train_frac)))\n\n    # Apply the annealing factor to the weights\n    w_annealed = w ** bias\n\n    # Handle cases where adjacent intervals have zero distance\n    w_annealed = torch.where(t[..., 1:] - t[..., :-1] > 0, w_annealed, torch.zeros_like(w_annealed))\n\n    # Apply softmax operation to prevent NaN values\n    w_annealed = torch.nn.functional.softmax(w_annealed, dim=-1)\n\n    return w_annealed"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # Calculate the annealing factor using Schlick's bias function\n    bias = (1 - train_frac) / (train_frac + eps)\n    anneal_factor = bias ** anneal_slope\n\n    # Adjust the weights based on the annealing factor\n    adjusted_w = w ** anneal_factor\n\n    # Handle cases where adjacent intervals have zero distance\n    adjusted_w = torch.where(t[..., 1:] - t[..., :-1] <= eps, torch.zeros_like(adjusted_w), adjusted_w)\n\n    # Normalize the adjusted weights using softmax operation to prevent NaN values\n    normalized_w = torch.nn.functional.softmax(adjusted_w, dim=-1)\n\n    return normalized_w"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # Calculate the annealing factor using Schlick's bias function\n    anneal_factor = 1 / (1 + torch.exp(-anneal_slope * (train_frac - 0.5)))\n\n    # Adjust the weights based on the annealing factor\n    adjusted_w = w ** anneal_factor\n\n    # Handle cases where adjacent intervals have zero distance\n    adjusted_w = adjusted_w * (t[..., 1:] - t[..., :-1]).clip(eps)\n\n    # Normalize the adjusted weights using softmax operation to prevent NaN values\n    normalized_w = torch.nn.functional.softmax(adjusted_w, dim=-1)\n\n    return normalized_w"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    # Compute the width of each interval\n    widths = t[..., 1:] - t[..., :-1]\n    \n    # Compute the bias function using Schlick's bias function\n    bias = 1 / (1 + torch.exp(-anneal_slope * (train_frac - 0.5)))\n    \n    # Adjust the weights based on the bias function\n    adjusted_weights = w / (1 + bias * (widths / widths.mean()))\n    \n    # Handle cases where adjacent intervals have zero distance\n    adjusted_weights[widths < eps] = 0\n    \n    # Prevent NaN values by using softmax operation on the adjusted weights\n    adjusted_weights = torch.nn.functional.softmax(adjusted_weights, dim=-1)\n    \n    return adjusted_weights"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    # Compute the width of each interval\n    width = t[..., 1:] - t[..., :-1]\n    \n    # Compute the bias function based on the training fraction and annealing slope\n    bias = 1.0 - torch.exp(-anneal_slope * train_frac)\n    \n    # Compute the adjusted weights using Schlick's bias function\n    adjusted_weights = w * (1.0 - bias) / (width + eps)\n    \n    # Handle cases where adjacent intervals have zero distance\n    adjusted_weights = torch.where(width < eps, torch.zeros_like(adjusted_weights), adjusted_weights)\n    \n    # Apply softmax operation to prevent NaN values\n    adjusted_weights = torch.nn.functional.softmax(adjusted_weights, dim=-1)\n    \n    return adjusted_weights"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "\n    # Calculate the bias factor using Schlick's bias function\n    bias = 1.0 - (1.0 - train_frac) ** anneal_slope\n\n    # Compute the distance between adjacent intervals\n    interval_distances = t[..., 1:] - t[..., :-1]\n\n    # Handle cases where adjacent intervals have zero distance\n    interval_distances = interval_distances.clip(min=eps)\n\n    # Adjust the weights using the bias factor\n    adjusted_weights = w / interval_distances ** bias\n\n    # Prevent NaN values by using a softmax operation on the adjusted weights\n    adjusted_weights = torch.nn.functional.softmax(adjusted_weights, dim=-1)\n\n    return adjusted_weights"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "\n    # Calculate the annealing factor using Schlick's bias function\n    bias = (1 - train_frac) / (train_frac + eps)\n    annealing_factor = torch.exp(-anneal_slope * bias)\n\n    # Adjust the weights using the annealing factor\n    adjusted_weights = w ** annealing_factor\n\n    # Handle cases where adjacent intervals have zero distance by setting their weight to zero\n    adjusted_weights = torch.where(t[..., 1:] - t[..., :-1] < eps, torch.zeros_like(adjusted_weights), adjusted_weights)\n\n    # Prevent NaN values by using a softmax operation on the adjusted weights\n    normalized_weights = torch.nn.functional.softmax(adjusted_weights, dim=-1)\n\n    return normalized_weights"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "\n    # Calculate the annealing factor using Schlick's bias function\n    annealing_factor = 1 / (1 + (anneal_slope * (1 - train_frac)))\n\n    # Adjust the weights based on the annealing factor\n    adjusted_weights = w.pow(annealing_factor)\n\n    # Handle cases where adjacent intervals have zero distance by setting their weight to zero\n    adjusted_weights = torch.where(t[..., 1:] - t[..., :-1] <= 0, torch.zeros_like(adjusted_weights), adjusted_weights)\n\n    # Prevent NaN values by using a softmax operation on the adjusted weights\n    adjusted_weights = torch.nn.functional.softmax(adjusted_weights, dim=-1)\n\n    return adjusted_weights"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "\n    # Compute the annealing factor using Schlick's bias function\n    bias = (1 - train_frac) / (train_frac * anneal_slope + eps)\n\n    # Apply the annealing factor to the weights\n    w_annealed = w.pow(bias)\n\n    # Handle cases where adjacent intervals have zero distance\n    w_annealed = w_annealed * (t[..., 1:] - t[..., :-1]).clip(eps)\n\n    # Softmax operation to prevent NaN values\n    w_annealed = w_annealed.softmax(dim=-1)\n\n    return w_annealed"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, (tuple, list)):\n        return [to_cuda(x, device, ignore_list) for x in batch]\n    elif isinstance(batch, dict):\n        if \"meta\" in batch:\n            return batch\n        return {k: to_cuda(v, device, ignore_list) for k, v in batch.items()}\n    else:\n        return batch  # for non-tensor types, return as is"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, list):\n        return [to_cuda(item, device, ignore_list) for item in batch]\n    elif isinstance(batch, tuple):\n        return tuple(to_cuda(item, device, ignore_list) for item in batch)\n    elif isinstance(batch, dict):\n        return {key: to_cuda(val, device, ignore_list) if key != \"meta\" else val for key, val in batch.items()}\n    else:\n        return batch  # If the input is not a torch tensor, list, tuple, or dict, return it as is"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, (tuple, list)):\n        return [to_cuda(item, device, ignore_list) for item in batch]\n    elif isinstance(batch, dict):\n        return {key: to_cuda(val, device, ignore_list) if key != \"meta\" else val for key, val in batch.items()}\n    else:\n        return batch  # For non-tensor, non-iterable types, just return as is"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, (tuple, list)):\n        return [to_cuda(x, device, ignore_list) for x in batch]\n    elif isinstance(batch, dict):\n        return {k: to_cuda(v, device, ignore_list) if k != \"meta\" else v for k, v in batch.items()}\n    elif isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    else:\n        return batch"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, (tuple, list)):\n        return [to_cuda(b, device, ignore_list) for b in batch]\n    elif isinstance(batch, dict):\n        return {k: to_cuda(v, device, ignore_list) if k != \"meta\" else v for k, v in batch.items()}\n    else:\n        return batch  # Return unchanged for non-tensor data"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "\n    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, (list, tuple)):\n        return [to_cuda(b, device, ignore_list) for b in batch]\n    elif isinstance(batch, dict):\n        return {k: to_cuda(v, device, ignore_list) if k != 'meta' else v for k, v in batch.items()}\n    else:\n        return batch  # for non-tensor types, simply return as is"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "\n    if isinstance(batch, (list, tuple)):\n        return [to_cuda(item, device, ignore_list) for item in batch]\n    elif isinstance(batch, dict):\n        return {key: to_cuda(value, device, ignore_list) if key != \"meta\" else value for key, value in batch.items()}\n    elif isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    else:\n        return batch"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, (tuple, list)):\n        return [to_cuda(item, device, ignore_list) for item in batch]\n    elif isinstance(batch, dict):\n        return {k: to_cuda(v, device, ignore_list) if k != \"meta\" else v for k, v in batch.items()}\n    else:\n        return batch  # Return as is for non-tensor data"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "\n    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, (tuple, list)):\n        return [to_cuda(item, device, ignore_list) for item in batch]\n    elif isinstance(batch, dict):\n        return {key: to_cuda(value, device, ignore_list) if key != \"meta\" else value for key, value in batch.items()}\n    else:\n        return batch  # If the input is not a tensor, tuple, list, or dict, return it as is"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "\n    if isinstance(batch, (list, tuple)):\n        return [to_cuda(item, device, ignore_list) for item in batch]\n    elif isinstance(batch, dict):\n        return {key: to_cuda(value, device, ignore_list) for key, value in batch.items() if key != \"meta\"}\n    elif isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    else:\n        return batch  # if not a list, tuple, dict, or tensor, return as is"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, (tuple, list)):\n        return [to_cuda(item, device, ignore_list) for item in batch]\n    elif isinstance(batch, dict):\n        return {key: to_cuda(value, device, ignore_list) if key != \"meta\" else value for key, value in batch.items()}\n    else:\n        return batch  # Return unchanged for non-tensor types"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, (tuple, list)):\n        return [to_cuda(item, device, ignore_list) for item in batch]\n    elif isinstance(batch, dict):\n        return {key: to_cuda(value, device, ignore_list) if key != \"meta\" else value for key, value in batch.items()}\n    else:\n        return batch  # For non-tensor elements, no conversion is needed"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, (tuple, list)):\n        return [to_cuda(item, device, ignore_list) for item in batch]\n    elif isinstance(batch, dict):\n        return {key: to_cuda(value, device, ignore_list) if key != \"meta\" else value for key, value in batch.items()}\n    else:\n        return batch  # Return unchanged for non-tensor data"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, (tuple, list)):\n        return [to_cuda(x, device, ignore_list) for x in batch]\n    elif isinstance(batch, dict):\n        return {k: to_cuda(v, device, ignore_list) if k != \"meta\" else v for k, v in batch.items()}\n    elif isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    else:\n        return batch  # Return as is for non-tensor data"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "\n    if isinstance(batch, (tuple, list)):\n        return [to_cuda(item, device, ignore_list) for item in batch]\n    elif isinstance(batch, dict):\n        return {key: to_cuda(value, device, ignore_list) if key != \"meta\" else value for key, value in batch.items()}\n    elif isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    else:\n        return batch  # for non-tensor, non-iterable types, simply return the input"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "\n    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, (tuple, list)):\n        return [to_cuda(b, device, ignore_list) for b in batch]\n    elif isinstance(batch, dict):\n        if \"meta\" in batch:\n            return batch\n        return {k: to_cuda(v, device, ignore_list) for k, v in batch.items()}\n    else:\n        return batch  # for non-tensor types, just return as is"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, (tuple, list)):\n        return [to_cuda(item, device, ignore_list) for item in batch]\n    elif isinstance(batch, dict):\n        return {key: to_cuda(value, device, ignore_list) if key != \"meta\" else value for key, value in batch.items()}\n    else:\n        return batch  # If the input is not a tensor, tuple, list, or dict, return it as is"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, (tuple, list)):\n        return [to_cuda(item, device, ignore_list) for item in batch]\n    elif isinstance(batch, dict):\n        return {key: to_cuda(value, device, ignore_list) if key != \"meta\" else value for key, value in batch.items()}\n    else:\n        return batch  # Return as is if not a tensor, tuple, list, or dict"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, (list, tuple)):\n        return [to_cuda(item, device, ignore_list) for item in batch]\n    elif isinstance(batch, dict):\n        return {key: to_cuda(value, device, ignore_list) if key != \"meta\" else value for key, value in batch.items()}\n    else:\n        return batch  # Return as is if not a tensor, list, or dict"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, (tuple, list)):\n        return [to_cuda(b, device, ignore_list) for b in batch]\n    elif isinstance(batch, dict):\n        return {k: to_cuda(v, device, ignore_list) if k != 'meta' else v for k, v in batch.items()}\n    else:\n        return batch  # Return as is for non-tensor data"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "\n    # Gather the vertices for each face using the indices in the faces tensor\n    gathered_vertices = multi_gather(v, f, dim)\n\n    return gathered_vertices"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "\n    # Ensure that the faces tensor has the same batch dimension as the vertices tensor\n    f = multi_indexing(f, v.shape, dim)\n\n    # Gather the vertices using the adjusted faces tensor\n    gathered_vertices = multi_gather(v, f, dim)\n\n    return gathered_vertices"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "\n    # Gather vertices for each face\n    gathered_vertices = multi_gather(v, f, dim)\n\n    # Reshape the gathered vertices to maintain the original faces tensor structure with additional dimensions for batch processing\n    expanded_shape = list(f.shape)\n    expanded_shape.insert(dim, v.shape[dim])\n    gathered_vertices = gathered_vertices.view(*expanded_shape)\n\n    return gathered_vertices"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "\n    # Gather the vertices for each face using the face indices\n    gathered_vertices = multi_gather(v, f, dim)\n\n    return gathered_vertices"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "\n    # Gather the vertices for each face\n    gathered_vertices = multi_gather(v, f, dim)\n\n    # Compute the normals for each face\n    face_normals = torch.cross(gathered_vertices[:, :, 1, :] - gathered_vertices[:, :, 0, :],\n                               gathered_vertices[:, :, 2, :] - gathered_vertices[:, :, 0, :], dim=2)\n\n    return face_normals"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "\n    # Gather the vertices for each face\n    gathered_vertices = multi_gather(v, f, dim)\n\n    # Compute the normals of the faces using the gathered vertices\n    face_normals = compute_normals(gathered_vertices)\n\n    return face_normals"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "\n    # Gather the vertices for each face\n    gathered_vertices = multi_gather(v, f, dim)\n\n    # Reshape the gathered vertices to maintain the structure of the original faces tensor\n    # with additional dimensions for batch processing\n    expanded_shape = list(f.shape)\n    expanded_shape[dim] = -1\n    gathered_vertices = gathered_vertices.view(*expanded_shape)\n\n    return gathered_vertices"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "\n    # Gather the vertices for each face\n    gathered_vertices = multi_gather(v, f, dim)\n\n    # Compute the normals for each face\n    edge1 = gathered_vertices[:, :, 1, :] - gathered_vertices[:, :, 0, :]\n    edge2 = gathered_vertices[:, :, 2, :] - gathered_vertices[:, :, 0, :]\n    face_normals = torch.cross(edge1, edge2, dim=-1)\n\n    return face_normals"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "\n    # Gather the vertices for each face using the face indices\n    gathered_vertices = multi_gather(v, f, dim)\n\n    # Reshape the gathered vertices to maintain the structure of the original faces tensor\n    # with additional dimensions for batch processing\n    reshaped_gathered_vertices = gathered_vertices.view(*f.shape, -1)\n\n    return reshaped_gathered_vertices"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    return multi_gather(v, f, dim)"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "\n    # Gather the vertices based on the faces tensor\n    gathered_vertices = multi_gather(v, f, dim)\n\n    return gathered_vertices"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    return multi_gather(v, f, dim)"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "\n    # Gather the vertices for each face using the indices from the faces tensor\n    gathered_vertices = multi_gather(v, f, dim)\n\n    return gathered_vertices"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "\n    # Gather the vertices based on the faces indices\n    gathered_vertices = multi_gather(v, f, dim)\n\n    return gathered_vertices"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "\n    # Gather the vertices using the faces tensor to obtain the triangles\n    triangles = multi_gather(v, f, dim)\n\n    return triangles"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "\n    # expand faces tensor to match the batch dimension of the vertices tensor\n    expanded_f = multi_indexing(f, v.shape, dim)\n\n    # gather the vertices using the expanded faces tensor\n    gathered_triangles = multi_gather(v, expanded_f, dim)\n\n    return gathered_triangles"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "\n    # Gather the vertices using the faces tensor\n    gathered_vertices = multi_gather(v, f, dim)\n\n    return gathered_vertices"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    return multi_gather(v, f, dim)"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "\n    # Gather the vertices for each face using the indices from the faces tensor\n    gathered_vertices = multi_gather(v, f, dim)\n\n    return gathered_vertices"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "\n    # Gather the vertices based on the face indices\n    gathered_vertices = multi_gather(v, f, dim)\n\n    return gathered_vertices"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "\n    if isinstance(batch, (tuple, list)):\n        return [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        return {k: add_batch(v) for k, v in batch.items()}\n    elif isinstance(batch, torch.Tensor):\n        return batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):\n        return np.expand_dims(batch, axis=0)\n    else:\n        return batch  # for other data types, return as is"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    else:  # numpy and others\n        batch = np.expand_dims(batch, axis=0)\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        return [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        return {k: add_batch(v) for k, v in batch.items()}\n    elif isinstance(batch, torch.Tensor):\n        return batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):\n        return np.expand_dims(batch, axis=0)\n    else:\n        return batch  # for other types, return as is"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "\n    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):\n        batch = np.expand_dims(batch, axis=0)\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    else:  # numpy and others\n        batch = np.expand_dims(batch, axis=0)\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "\n    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    else:  # numpy and others\n        batch = np.expand_dims(batch, axis=0)\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "\n    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n        return np.stack(batch) if isinstance(batch[0], np.ndarray) else torch.stack(batch)\n    elif isinstance(batch, dict):\n        batch = {k: add_batch(v) for k, v in batch.items()}\n        return batch\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):\n        return np.expand_dims(batch, axis=0) if isinstance(batch, np.ndarray) else torch.unsqueeze(batch, 0)\n    else:\n        raise ValueError(\"Unsupported data type for batch\")"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    \n    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    else:  # numpy and others\n        batch = np.expand_dims(batch, axis=0)\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    else:  # numpy and others\n        batch = np.expand_dims(batch, axis=0)\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    else:  # numpy and others\n        batch = np.expand_dims(batch, axis=0)\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "\n    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    else:  # numpy and others\n        batch = np.expand_dims(batch, axis=0)\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "\n    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    else:  # numpy and others\n        batch = np.expand_dims(batch, axis=0)\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    else:  # numpy and others\n        batch = np.expand_dims(batch, axis=0)\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "\n    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):\n        batch = np.expand_dims(batch, axis=0)\n    else:\n        raise NotImplementedError(\"Unsupported data type for adding batch dimension\")\n\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "\n    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):\n        batch = np.expand_dims(batch, axis=0)\n    else:\n        raise ValueError(\"Unsupported data type for batch\")\n\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    else:  # numpy and others\n        batch = np.expand_dims(batch, axis=0)\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        return [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        return {k: add_batch(v) for k, v in batch.items()}\n    elif isinstance(batch, torch.Tensor):\n        return batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):\n        return np.expand_dims(batch, axis=0)\n    else:\n        return batch  # for other types, return as is"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "\n    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):\n        batch = np.expand_dims(batch, axis=0)\n    else:\n        raise ValueError(\"Unsupported data type for batch\")\n\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "\n    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    else:  # numpy and others\n        batch = np.expand_dims(batch, axis=0)\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "\n    if isinstance(batch, (tuple, list)):\n        return [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        return {k: add_batch(v) for k, v in batch.items()}\n    elif isinstance(batch, torch.Tensor):\n        return batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):\n        return np.expand_dims(batch, axis=0)\n    else:\n        return batch  # for other types of data, return as is"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = (\n            torch.tensor(self.H),\n            torch.tensor(self.W),\n            torch.tensor(self.K),\n            torch.tensor(self.R),\n            torch.tensor(self.T),\n            torch.tensor(self.n),\n            torch.tensor(self.f),\n            torch.tensor(self.t),\n            torch.tensor(self.v),\n            torch.tensor(self.bounds),\n        )\n\n        batch.meta = dotdict(\n            H=batch.H,\n            W=batch.W,\n            K=batch.K,\n            R=batch.R,\n            T=batch.T,\n            n=batch.n,\n            f=batch.f,\n            t=batch.t,\n            v=batch.v,\n            bounds=batch.bounds,\n        )\n\n        return batch"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = (\n            torch.tensor(self.H),\n            torch.tensor(self.W),\n            torch.tensor(self.K),\n            torch.tensor(self.R),\n            torch.tensor(self.T),\n            torch.tensor(self.n),\n            torch.tensor(self.f),\n            torch.tensor(self.t),\n            torch.tensor(self.v),\n            torch.tensor(self.bounds)\n        )\n\n        batch.meta = dotdict()\n        batch.meta.H, batch.meta.W, batch.meta.K, batch.meta.R, batch.meta.T, batch.meta.n, batch.meta.f, batch.meta.t, batch.meta.v, batch.meta.bounds = (\n            torch.tensor(self.H),\n            torch.tensor(self.W),\n            torch.tensor(self.K),\n            torch.tensor(self.R),\n            torch.tensor(self.T),\n            torch.tensor(self.n),\n            torch.tensor(self.f),\n            torch.tensor(self.t),\n            torch.tensor(self.v),\n            torch.tensor(self.bounds)\n        )\n\n        return batch"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, to_tensor(self.K), to_tensor(self.R), to_tensor(self.T), to_tensor(self.n), to_tensor(self.f), to_tensor(self.t), to_tensor(self.v), to_tensor(self.bounds)\n        \n        batch.meta = dotdict()\n        batch.meta.H, batch.meta.W, batch.meta.K, batch.meta.R, batch.meta.T, batch.meta.n, batch.meta.f, batch.meta.t, batch.meta.v, batch.meta.bounds = \"camera parameters and GUI related elements converted into tensors\"\n\n        return batch"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "\n        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, to_tensor(self.K), to_tensor(self.R), to_tensor(self.T), to_tensor(self.n), to_tensor(self.f), to_tensor(self.t), to_tensor(self.v), to_tensor(self.bounds)\n\n        meta = dotdict()\n        meta.H, meta.W, meta.K, meta.R, meta.T, meta.n, meta.f, meta.t, meta.v, meta.bounds = \"H, W, K, R, T, n, f, t, v, bounds\"\n        batch.meta = meta\n\n        return batch"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = (\n            torch.tensor(self.H),\n            torch.tensor(self.W),\n            torch.tensor(self.K),\n            torch.tensor(self.R),\n            torch.tensor(self.T),\n            torch.tensor(self.n),\n            torch.tensor(self.f),\n            torch.tensor(self.t),\n            torch.tensor(self.v),\n            torch.tensor(self.bounds),\n        )\n\n        batch.meta = dotdict(\n            H=batch.H,\n            W=batch.W,\n            K=batch.K,\n            R=batch.R,\n            T=batch.T,\n            n=batch.n,\n            f=batch.f,\n            t=batch.t,\n            v=batch.v,\n            bounds=batch.bounds,\n        )\n\n        return batch"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = (\n            torch.tensor(self.H),\n            torch.tensor(self.W),\n            torch.tensor(self.K),\n            torch.tensor(self.R),\n            torch.tensor(self.T),\n            torch.tensor(self.n),\n            torch.tensor(self.f),\n            torch.tensor(self.t),\n            torch.tensor(self.v),\n            torch.tensor(self.bounds),\n        )\n        batch.meta = dotdict(\n            {\n                \"origin\": torch.tensor(self.origin),\n                \"world_up\": torch.tensor(self.world_up),\n                \"movement_speed\": torch.tensor(self.movement_speed),\n            }\n        )\n        return batch"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = to_tensor(self.H), to_tensor(self.W), to_tensor(self.K), to_tensor(self.R), to_tensor(self.T), to_tensor(self.n), to_tensor(self.f), to_tensor(self.t), to_tensor(self.v), to_tensor(self.bounds)\n        batch.meta = dotdict()\n        batch.meta.H, batch.meta.W, batch.meta.K, batch.meta.R, batch.meta.T, batch.meta.n, batch.meta.f, batch.meta.t, batch.meta.v, batch.meta.bounds = to_tensor(self.H), to_tensor(self.W), to_tensor(self.K), to_tensor(self.R), to_tensor(self.T), to_tensor(self.n), to_tensor(self.f), to_tensor(self.t), to_tensor(self.v), to_tensor(self.bounds)\n        return batch"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = (\n            torch.as_tensor(self.H),\n            torch.as_tensor(self.W),\n            torch.as_tensor(self.K),\n            torch.as_tensor(self.R),\n            torch.as_tensor(self.T),\n            torch.as_tensor(self.n),\n            torch.as_tensor(self.f),\n            torch.as_tensor(self.t),\n            torch.as_tensor(self.v),\n            torch.as_tensor(self.bounds),\n        )\n        \n        batch.meta = dotdict()\n        batch.meta.H, batch.meta.W, batch.meta.K, batch.meta.R, batch.meta.T, batch.meta.n, batch.meta.f, batch.meta.t, batch.meta.v, batch.meta.bounds = (\n            torch.as_tensor(self.H),\n            torch.as_tensor(self.W),\n            torch.as_tensor(self.K),\n            torch.as_tensor(self.R),\n            torch.as_tensor(self.T),\n            torch.as_tensor(self.n),\n            torch.as_tensor(self.f),\n            torch.as_tensor(self.t),\n            torch.as_tensor(self.v),\n            torch.as_tensor(self.bounds),\n        )\n        \n        return batch"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, to_tensor(self.K), to_tensor(self.R), to_tensor(self.T), to_tensor(self.n), to_tensor(self.f), to_tensor(self.t), to_tensor(self.v), to_tensor(self.bounds)\n        batch.origin, batch.world_up, batch.movement_speed, batch.movement_force, batch.drag_coeff_mult, batch.constant_drag, batch.mass, batch.moment_of_inertia, batch.movement_torque, batch.angular_friction, batch.constant_torque, batch.min_interval, batch.pause_physics = to_tensor(self.origin), to_tensor(self.world_up), to_tensor(self.movement_speed), to_tensor(self.movement_force), to_tensor(self.drag_coeff_mult), to_tensor(self.constant_drag), to_tensor(self.mass), to_tensor(self.moment_of_inertia), to_tensor(self.movement_torque), to_tensor(self.angular_friction), to_tensor(self.constant_torque), to_tensor(self.min_interval), self.pause_physics\n        batch.meta = dotdict()\n        batch.meta.H, batch.meta.W, batch.meta.K, batch.meta.R, batch.meta.T, batch.meta.n, batch.meta.f, batch.meta.t, batch.meta.v, batch.meta.bounds = \"Camera Height\", \"Camera Width\", \"Intrinsics\", \"Extrinsics\", \"Translation\", \"Near\", \"Far\", \"Temporal Dimension\", \"View Dimension\", \"Bounds\"\n        batch.meta.origin, batch.meta.world_up, batch.meta.movement_speed, batch.meta.movement_force, batch.meta.drag_coeff_mult, batch.meta.constant_drag, batch.meta.mass, batch.meta.moment_of_inertia, batch.meta.movement_torque, batch.meta.angular_friction, batch.meta.constant_torque, batch.meta.min_interval, batch.meta.pause_physics = \"Origin\", \"World Up\", \"Movement Speed\", \"Movement Force\", \"Drag Coeff Mult\", \"Constant Drag\", \"Mass\", \"Moment of Inertia\", \"Movement Torque\", \"Angular Friction\", \"Constant Torque\", \"Min Interval\", \"Pause Physics\"\n        return batch"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = (\n            torch.tensor(self.H),\n            torch.tensor(self.W),\n            torch.tensor(self.K),\n            torch.tensor(self.R),\n            torch.tensor(self.T),\n            torch.tensor(self.n),\n            torch.tensor(self.f),\n            torch.tensor(self.t),\n            torch.tensor(self.v),\n            torch.tensor(self.bounds),\n        )\n\n        batch.meta = dotdict()\n        batch.meta.H, batch.meta.W, batch.meta.K, batch.meta.R, batch.meta.T, batch.meta.n, batch.meta.f, batch.meta.t, batch.meta.v, batch.meta.bounds = (\n            torch.tensor(self.H),\n            torch.tensor(self.W),\n            torch.tensor(self.K),\n            torch.tensor(self.R),\n            torch.tensor(self.T),\n            torch.tensor(self.n),\n            torch.tensor(self.f),\n            torch.tensor(self.t),\n            torch.tensor(self.v),\n            torch.tensor(self.bounds),\n        )\n\n        return batch"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = (\n            torch.tensor(self.H), \n            torch.tensor(self.W), \n            torch.tensor(self.K), \n            torch.tensor(self.R), \n            torch.tensor(self.T), \n            torch.tensor(self.n), \n            torch.tensor(self.f), \n            torch.tensor(self.t), \n            torch.tensor(self.v), \n            torch.tensor(self.bounds)\n        )\n\n        batch.meta = dotdict()\n        batch.meta.H, batch.meta.W, batch.meta.K, batch.meta.R, batch.meta.T, batch.meta.n, batch.meta.f, batch.meta.t, batch.meta.v, batch.meta.bounds = (\n            torch.tensor(self.H), \n            torch.tensor(self.W), \n            torch.tensor(self.K), \n            torch.tensor(self.R), \n            torch.tensor(self.T), \n            torch.tensor(self.n), \n            torch.tensor(self.f), \n            torch.tensor(self.t), \n            torch.tensor(self.v), \n            torch.tensor(self.bounds)\n        )\n\n        return batch"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "\n        # Convert camera parameters to tensors\n        H = torch.tensor(self.H)\n        W = torch.tensor(self.W)\n        K = torch.tensor(self.K)\n        R = torch.tensor(self.R)\n        T = torch.tensor(self.T)\n        n = torch.tensor(self.n)\n        f = torch.tensor(self.f)\n        t = torch.tensor(self.t)\n        v = torch.tensor(self.v)\n        bounds = torch.tensor(self.bounds)\n        origin = torch.tensor(self.origin)\n        world_up = torch.tensor(self.world_up)\n\n        # Create a structured dictionary with the converted parameters\n        batch = dotdict()\n        batch.H = H\n        batch.W = W\n        batch.K = K\n        batch.R = R\n        batch.T = T\n        batch.n = n\n        batch.f = f\n        batch.t = t\n        batch.v = v\n        batch.bounds = bounds\n        batch.origin = origin\n        batch.world_up = world_up\n\n        # Create a nested 'meta' dictionary with the same content\n        batch.meta = dotdict()\n        batch.meta.H = H\n        batch.meta.W = W\n        batch.meta.K = K\n        batch.meta.R = R\n        batch.meta.T = T\n        batch.meta.n = n\n        batch.meta.f = f\n        batch.meta.t = t\n        batch.meta.v = v\n        batch.meta.bounds = bounds\n        batch.meta.origin = origin\n        batch.meta.world_up = world_up\n\n        return batch"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, to_tensor(self.K), to_tensor(self.R), to_tensor(self.T), to_tensor(self.n), to_tensor(self.f), to_tensor(self.t), to_tensor(self.v), to_tensor(self.bounds)\n        batch.meta = dotdict()\n        batch.meta.H, batch.meta.W, batch.meta.K, batch.meta.R, batch.meta.T, batch.meta.n, batch.meta.f, batch.meta.t, batch.meta.v, batch.meta.bounds = batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds\n        return batch"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n\n        # Camera parameters\n        batch.H = torch.as_tensor(self.H)\n        batch.W = torch.as_tensor(self.W)\n        batch.K = torch.as_tensor(self.K)\n        batch.R = torch.as_tensor(self.R)\n        batch.T = torch.as_tensor(self.T)\n        batch.n = torch.as_tensor(self.n)\n        batch.f = torch.as_tensor(self.f)\n        batch.t = torch.as_tensor(self.t)\n        batch.v = torch.as_tensor(self.v)\n        batch.bounds = torch.as_tensor(self.bounds)\n\n        # GUI related elements\n        batch.origin = torch.as_tensor(self.origin)\n        batch.world_up = torch.as_tensor(self.world_up)\n        batch.movement_speed = torch.as_tensor(self.movement_speed)\n        batch.movement_force = torch.as_tensor(self.movement_force)\n        batch.drag_coeff_mult = torch.as_tensor(self.drag_coeff_mult)\n        batch.constant_drag = torch.as_tensor(self.constant_drag)\n        batch.mass = torch.as_tensor(self.mass)\n        batch.moment_of_inertia = torch.as_tensor(self.moment_of_inertia)\n        batch.movement_torque = torch.as_tensor(self.movement_torque)\n        batch.angular_friction = torch.as_tensor(self.angular_friction)\n        batch.constant_torque = torch.as_tensor(self.constant_torque)\n        batch.min_interval = torch.as_tensor(self.min_interval)\n        batch.pause_physics = torch.as_tensor(self.pause_physics)\n\n        # Nested 'meta' dictionary with the same content\n        batch.meta = dotdict({\n            'H': batch.H,\n            'W': batch.W,\n            'K': batch.K,\n            'R': batch.R,\n            'T': batch.T,\n            'n': batch.n,\n            'f': batch.f,\n            't': batch.t,\n            'v': batch.v,\n            'bounds': batch.bounds,\n            'origin': batch.origin,\n            'world_up': batch.world_up,\n            'movement_speed': batch.movement_speed,\n            'movement_force': batch.movement_force,\n            'drag_coeff_mult': batch.drag_coeff_mult,\n            'constant_drag': batch.constant_drag,\n            'mass': batch.mass,\n            'moment_of_inertia': batch.moment_of_inertia,\n            'movement_torque': batch.movement_torque,\n            'angular_friction': batch.angular_friction,\n            'constant_torque': batch.constant_torque,\n            'min_interval': batch.min_interval,\n            'pause_physics': batch.pause_physics\n        })\n\n        return batch"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = (\n            torch.tensor(self.H),\n            torch.tensor(self.W),\n            torch.tensor(self.K),\n            torch.tensor(self.R),\n            torch.tensor(self.T),\n            torch.tensor(self.n),\n            torch.tensor(self.f),\n            torch.tensor(self.t),\n            torch.tensor(self.v),\n            torch.tensor(self.bounds),\n        )\n\n        batch.meta = dotdict(\n            H=batch.H,\n            W=batch.W,\n            K=batch.K,\n            R=batch.R,\n            T=batch.T,\n            n=batch.n,\n            f=batch.f,\n            t=batch.t,\n            v=batch.v,\n            bounds=batch.bounds,\n        )\n\n        return batch"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = \\\n            torch.tensor(self.H), torch.tensor(self.W), torch.tensor(self.K), torch.tensor(self.R), torch.tensor(self.T), \\\n            torch.tensor(self.n), torch.tensor(self.f), torch.tensor(self.t), torch.tensor(self.v), torch.tensor(self.bounds)\n\n        batch.meta = dotdict()\n        batch.meta.H, batch.meta.W, batch.meta.K, batch.meta.R, batch.meta.T, batch.meta.n, batch.meta.f, batch.meta.t, batch.meta.v, batch.meta.bounds = \\\n            batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds\n\n        return batch"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "\n        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = (\n            torch.tensor(self.H),\n            torch.tensor(self.W),\n            torch.tensor(self.K),\n            torch.tensor(self.R),\n            torch.tensor(self.T),\n            torch.tensor(self.n),\n            torch.tensor(self.f),\n            torch.tensor(self.t),\n            torch.tensor(self.v),\n            torch.tensor(self.bounds)\n        )\n\n        meta = dotdict()\n        meta.H, meta.W, meta.K, meta.R, meta.T, meta.n, meta.f, meta.t, meta.v, meta.bounds = (\n            torch.tensor(self.H),\n            torch.tensor(self.W),\n            torch.tensor(self.K),\n            torch.tensor(self.R),\n            torch.tensor(self.T),\n            torch.tensor(self.n),\n            torch.tensor(self.f),\n            torch.tensor(self.t),\n            torch.tensor(self.v),\n            torch.tensor(self.bounds)\n        )\n\n        batch.meta = meta\n\n        return batch"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = (\n            torch.tensor(self.H),\n            torch.tensor(self.W),\n            torch.tensor(self.K),\n            torch.tensor(self.R),\n            torch.tensor(self.T),\n            torch.tensor(self.n),\n            torch.tensor(self.f),\n            torch.tensor(self.t),\n            torch.tensor(self.v),\n            torch.tensor(self.bounds),\n        )\n\n        batch.meta = dotdict()\n        batch.meta.H, batch.meta.W, batch.meta.K, batch.meta.R, batch.meta.T, batch.meta.n, batch.meta.f, batch.meta.t, batch.meta.v, batch.meta.bounds = (\n            torch.tensor(self.H),\n            torch.tensor(self.W),\n            torch.tensor(self.K),\n            torch.tensor(self.R),\n            torch.tensor(self.T),\n            torch.tensor(self.n),\n            torch.tensor(self.f),\n            torch.tensor(self.t),\n            torch.tensor(self.v),\n            torch.tensor(self.bounds),\n        )\n\n        return batch"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = (\n            torch.tensor(self.H),\n            torch.tensor(self.W),\n            torch.tensor(self.K),\n            torch.tensor(self.R),\n            torch.tensor(self.T),\n            torch.tensor(self.n),\n            torch.tensor(self.f),\n            torch.tensor(self.t),\n            torch.tensor(self.v),\n            torch.tensor(self.bounds)\n        )\n\n        # Nested 'meta' dictionary with the same content\n        batch.meta = dotdict()\n        batch.meta.H, batch.meta.W, batch.meta.K, batch.meta.R, batch.meta.T, batch.meta.n, batch.meta.f, batch.meta.t, batch.meta.v, batch.meta.bounds = (\n            torch.tensor(self.H),\n            torch.tensor(self.W),\n            torch.tensor(self.K),\n            torch.tensor(self.R),\n            torch.tensor(self.T),\n            torch.tensor(self.n),\n            torch.tensor(self.f),\n            torch.tensor(self.t),\n            torch.tensor(self.v),\n            torch.tensor(self.bounds)\n        )\n\n        return batch"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "\n        batch = dotdict()\n        batch.H = self.H\n        batch.W = self.W\n        batch.K = torch.tensor(self.K)\n        batch.R = torch.tensor(self.R)\n        batch.T = torch.tensor(self.T)\n        batch.n = torch.tensor(self.n)\n        batch.f = torch.tensor(self.f)\n        batch.t = torch.tensor(self.t)\n        batch.v = torch.tensor(self.v)\n        batch.bounds = torch.tensor(self.bounds)\n\n        batch.meta = dotdict()\n        batch.meta.origin = torch.tensor(self.origin)\n        batch.meta.world_up = torch.tensor(self.world_up)\n        batch.meta.movement_speed = torch.tensor(self.movement_speed)\n        batch.meta.movement_force = torch.tensor(self.movement_force)\n        batch.meta.drag_coeff_mult = torch.tensor(self.drag_coeff_mult)\n        batch.meta.constant_drag = torch.tensor(self.constant_drag)\n        batch.meta.mass = torch.tensor(self.mass)\n        batch.meta.moment_of_inertia = torch.tensor(self.moment_of_inertia)\n        batch.meta.movement_torque = torch.tensor(self.movement_torque)\n        batch.meta.angular_friction = torch.tensor(self.angular_friction)\n        batch.meta.constant_torque = torch.tensor(self.constant_torque)\n        batch.meta.min_interval = torch.tensor(self.min_interval)\n        batch.meta.pause_physics = torch.tensor(self.pause_physics)\n\n        return batch"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working() and not agent.is_prime():\n            serialized_agent = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working() and not agent.is_prime():\n            serialized_agent = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working() and not agent.is_prime():\n            serialized_agent = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working() and not agent.is_prime():\n            serialized_agent = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working() and not agent.is_prime():\n            serialized_agent = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working() and not agent.is_prime():\n            serialized_agent = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if not self.agents:\n                return None, float('-inf')\n\n            max_similarity = float('-inf')\n            closest_agent = None\n\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, float('-inf')"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if not self.agents:\n                return None, float('-inf')\n\n            max_similarity = float('-inf')\n            closest_agent = None\n\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, float('-inf')"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if not self.agents:\n                return None, float('-inf')\n\n            max_similarity = float('-inf')\n            closest_agent = None\n\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, float('-inf')"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            highest_similarity_score = -float('inf')\n            closest_agent = None\n\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity_score = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity_score > highest_similarity_score:\n                    highest_similarity_score = similarity_score\n                    closest_agent = agent\n\n            return closest_agent, highest_similarity_score\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -float('inf')"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if len(self.agents) == 0:\n                return None, float('-inf')\n\n            max_similarity = float('-inf')\n            closest_agent = None\n\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, float('-inf')"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if not self.agents:\n                return None, float('-inf')\n\n            max_similarity = float('-inf')\n            closest_agent = None\n\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity_score = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity_score > max_similarity:\n                    max_similarity = similarity_score\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, float('-inf')"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            max_similarity = -np.inf\n            closest_agent = None\n\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -np.inf"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if len(self.agents) == 0:\n                return None, -float('inf')\n\n            max_similarity = -float('inf')\n            closest_agent = None\n\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -float('inf')"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if len(self.agents) == 0:\n                return None, float('-inf')\n\n            max_similarity = float('-inf')\n            closest_agent = None\n\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, float('-inf')"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if not self.agents:\n                return None, float('-inf')\n\n            max_similarity = float('-inf')\n            closest_agent = None\n\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, float('-inf')"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if not self.agents:\n                return None, float('-inf')\n\n            max_similarity = float('-inf')\n            closest_agent = None\n\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, float('-inf')"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if not self.agents:\n                return None, float('-inf')\n\n            max_similarity = float('-inf')\n            closest_agent = None\n\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, float('-inf')"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if not self.agents:\n                return None, float('-inf')\n\n            max_similarity = float('-inf')\n            closest_agent = None\n\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, float('-inf')"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if not self.agents:\n                return None, float('-inf')\n\n            max_similarity = float('-inf')\n            closest_agent = None\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, float('-inf')"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if not self.agents:\n                return None, float('-inf')\n\n            max_similarity = float('-inf')\n            closest_agent = None\n\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, float('-inf')"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if len(self.agents) == 0:\n                return None, float('-inf')\n\n            max_similarity = float('-inf')\n            closest_agent = None\n\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n                \n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, float('-inf')"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if len(self.agents) == 0:\n                return None, float('-inf')\n\n            max_similarity = float('-inf')\n            closest_agent = None\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, float('-inf')"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if not self.agents:\n                return None, float('-inf')\n\n            similarities = [cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0] for agent in self.agents]\n            max_similarity = max(similarities)\n            closest_agent = self.agents[similarities.index(max_similarity)]\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, float('-inf')"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "    try:\n        if not self.agents:\n            return None, float('-inf')\n\n        max_similarity = float('-inf')\n        closest_agent = None\n\n        for agent in self.agents:\n            if agent.purpose_embedding is None:\n                agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n            similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n            if similarity > max_similarity:\n                max_similarity = similarity\n                closest_agent = agent\n\n        return closest_agent, max_similarity\n\n    except Exception as e:\n        logger.exception(f\"Error finding closest agent: {e}\")\n        return None, float('-inf')"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if not self.agents:\n                return None, float('-inf')\n\n            max_similarity = float('-inf')\n            closest_agent = None\n\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, float('-inf')"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(prompt=PRIME_PROMPT, name=PRIME_NAME, weight=PRIME_AGENT_WEIGHT, is_prime=True, unspecified_flag=False)\n        self.agents.append(prime_agent)"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "\n        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            is_prime=True,\n            unspecified_flag=True\n        )\n        self.agents.append(prime_agent)"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            is_prime=True,\n            unspecified_flag=False\n        )\n        self.agents.append(prime_agent)"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            flags={\"prime\": True, \"unspecified_flag\": False}\n        )\n        self.agents.append(prime_agent)"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "\n        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            is_prime=True,\n            unspecified_flag=False\n        )\n        self.agents.append(prime_agent)"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            is_prime=True,\n            unspecified_flag=False\n        )\n        self.agents.append(prime_agent)"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            is_prime=True,\n            unspecified_flag=False\n        )\n        self.agents.append(prime_agent)"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(prompt=PRIME_PROMPT, name=PRIME_NAME, weight=PRIME_AGENT_WEIGHT, is_prime=True, unspecified_flag=False)\n        self.agents.append(prime_agent)"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            is_prime=True,\n            unspecified_flag=False\n        )\n        self.agents.append(prime_agent)"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            flags={\n                \"prime\": True,\n                \"unspecified_flag\": True\n            }\n        )\n        self.agents.append(prime_agent)"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            is_prime=True,\n            unspecified_flag=False\n        )\n        self.agents.append(prime_agent)"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(prompt=PRIME_PROMPT, name=PRIME_NAME, weight=PRIME_AGENT_WEIGHT, is_prime=True, unspecified_flag=False)\n        self.agents.append(prime_agent)"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(prompt=PRIME_PROMPT, name=PRIME_NAME, weight=PRIME_AGENT_WEIGHT, prime=True, unspecified_flag=False)\n        self.agents.append(prime_agent)"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            is_prime=True,\n            unspecified_flag=False\n        )\n        self.agents.append(prime_agent)"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(prompt=PRIME_PROMPT, name=PRIME_NAME, weight=PRIME_AGENT_WEIGHT, is_prime=True, unspecified_flag=False)\n        self.agents.append(prime_agent)"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "\n        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            unspecified_flag=False\n        )\n        self.agents.append(prime_agent)"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            is_prime=True,\n            unspecified_flag=False\n        )\n        self.agents.append(prime_agent)"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        \n        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            unspecified_flag=True\n        )\n        self.agents.append(prime_agent)"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT\n        )\n        prime_agent.is_prime = True\n        prime_agent.unspecified_flag = False\n        self.agents.append(prime_agent)"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "\n        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            unspecified_flag=True\n        )\n        self.agents.append(prime_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "        agent_dict = self.persistence.load_agent(purpose)\n        if agent_dict:\n            agent = AgentSerializer.from_dict(agent_dict, agent_lifecycle, openai_wrapper)\n            return agent\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    agent_dict = self.persistence.load_agent(purpose)\n    if agent_dict:\n        return AgentSerializer.from_dict(agent_dict, agent_lifecycle, openai_wrapper)\n    else:\n        return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "        agent_dict = self.persistence.load_agent(purpose)\n        if agent_dict:\n            return AgentSerializer.from_dict(agent_dict, agent_lifecycle, openai_wrapper)\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "        agent_dict = self.persistence.load_agent(purpose)\n        if agent_dict:\n            return AgentSerializer.from_dict(agent_dict, agent_lifecycle, openai_wrapper)\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    agent_dict = self.persistence.load_agent(purpose)\n    if agent_dict:\n        return AgentSerializer.from_dict(agent_dict, agent_lifecycle, openai_wrapper)\n    else:\n        return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "        agent_dict = self.persistence.load_agent(purpose)\n        if agent_dict:\n            return AgentSerializer.from_dict(agent_dict, agent_lifecycle, openai_wrapper)\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    agent_dict = self.persistence.load_agent(purpose)\n    if agent_dict:\n        return AgentSerializer.from_dict(agent_dict, agent_lifecycle, openai_wrapper)\n    else:\n        return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "        agent_dict = self.persistence.load_agent(purpose)\n        if agent_dict:\n            return AgentSerializer.from_dict(agent_dict, agent_lifecycle, openai_wrapper)\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "        agent_dict = self.persistence.load_agent(purpose)\n        if agent_dict:\n            agent = AgentSerializer.from_dict(agent_dict, agent_lifecycle, openai_wrapper)\n            return agent\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "        agent_dict = self.persistence.load_agent(purpose)\n        if agent_dict:\n            return AgentSerializer.from_dict(agent_dict, agent_lifecycle, openai_wrapper)\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    agent_dict = self.persistence.load_agent(purpose)\n    if agent_dict:\n        return AgentSerializer.from_dict(agent_dict, agent_lifecycle, openai_wrapper)\n    else:\n        return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    agent_dict = self.persistence.load_agent(purpose)\n    if agent_dict:\n        return AgentSerializer.from_dict(agent_dict, agent_lifecycle, openai_wrapper)\n    else:\n        return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "        agent_dict = self.persistence.load_agent(purpose)\n        if agent_dict:\n            agent = AgentSerializer.from_dict(agent_dict, agent_lifecycle, openai_wrapper)\n            return agent\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "        agent_dict = self.persistence.load_agent(purpose)\n        if agent_dict:\n            return AgentSerializer.from_dict(agent_dict, agent_lifecycle, openai_wrapper)\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    agent_dict = self.persistence.load_agent(purpose)\n    if agent_dict:\n        return AgentSerializer.from_dict(agent_dict, agent_lifecycle, openai_wrapper)\n    else:\n        return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    agent_dict = self.persistence.load_agent(purpose)\n    if agent_dict:\n        return AgentSerializer.from_dict(agent_dict, agent_lifecycle, openai_wrapper)\n    else:\n        return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "        agent_data = self.persistence.load_agent(purpose)\n        if agent_data:\n            agent = AgentSerializer.from_dict(agent_data, agent_lifecycle, openai_wrapper)\n            return agent\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "        agent_dict = self.persistence.load_agent(purpose)\n        if agent_dict:\n            return AgentSerializer.from_dict(agent_dict, agent_lifecycle, openai_wrapper)\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "        agent_dict = self.persistence.load_agent(purpose)\n        if agent_dict:\n            return AgentSerializer.from_dict(agent_dict, agent_lifecycle, openai_wrapper)\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "        agent_dict = self.persistence.load_agent(purpose)\n        if agent_dict:\n            return AgentSerializer.from_dict(agent_dict, agent_lifecycle, openai_wrapper)\n        else:\n            return None"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response[response.find('Use Agent[') + len('Use Agent['):response.find(']')]\n        agent_name, input_text = agent_info.split(':') if ':' in agent_info else (agent_info, '')\n        return agent_name, input_text"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name, input_text = agent_info.split(\":\") if \":\" in agent_info else (agent_info, \"\")\n        return agent_name, input_text"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split('Use Agent[')[1].split(']')[0]\n        agent_name, input_text = agent_info.split(':') if ':' in agent_info else (agent_info, '')\n        return agent_name, input_text"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name, input_text = agent_info.split(\":\") if \":\" in agent_info else (agent_info, \"\")\n        return agent_name, input_text"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split('Use Agent[')[1].split(']')[0]\n        agent_name, input_text = agent_info.split(':') if ':' in agent_info else (agent_info, '')\n        return agent_name, input_text"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name, input_text = agent_info.split(\":\") if \":\" in agent_info else (agent_info, \"\")\n        return agent_name, input_text"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name, _, input_text = agent_info.partition(':')\n        return agent_name.strip(), input_text.strip()"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split('Use Agent[')[-1].split(']')[0]\n        agent_name, input_text = agent_info.split(':') if ':' in agent_info else (agent_info, '')\n        return agent_name, input_text"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\", 1)[1].split(\"]\")[0]\n        agent_name, input_text = agent_info.split(\":\") if \":\" in agent_info else (agent_info, \"\")\n        return agent_name, input_text"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split('Use Agent[')[1].split(']')[0]\n        agent_name, input_text = agent_info.split(':') if ':' in agent_info else (agent_info, '')\n        return agent_name, input_text"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name, input_text = agent_info.split(\":\") if \":\" in agent_info else (agent_info, \"\")\n        return agent_name, input_text"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name, input_text = agent_info.split(\":\") if \":\" in agent_info else (agent_info, \"\")\n        return agent_name, input_text"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response[response.find('Use Agent[') + len('Use Agent['): response.find(']')]\n        agent_name, input_text = agent_info.split(':') if ':' in agent_info else (agent_info, '')\n        return agent_name, input_text"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split('Use Agent[')[1].split(']')[0]\n        agent_name, input_text = agent_info.split(':') if ':' in agent_info else (agent_info, '')\n        return agent_name, input_text"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\", 1)[-1].split(\"]\")[0]\n        agent_name, input_text = agent_info.split(\":\") if \":\" in agent_info else (agent_info, \"\")\n        return agent_name, input_text"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name, input_text = agent_info.split(\":\") if \":\" in agent_info else (agent_info, \"\")\n        return agent_name, input_text"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name, input_text = agent_info.split(\":\") if \":\" in agent_info else (agent_info, \"\")\n        return agent_name, input_text"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name, input_text = agent_info.split(\":\") if \":\" in agent_info else (agent_info, \"\")\n        return agent_name, input_text"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split('Use Agent[')[1].split(']')[0]\n        agent_name, input_text = agent_info.split(':') if ':' in agent_info else (agent_info, '')\n        return agent_name, input_text"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name, input_text = agent_info.split(\":\") if \":\" in agent_info else (agent_info, \"\")\n        return agent_name, input_text"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        agents = []\n        # Fetch all agents from the database\n        all_agents = self.persistence.fetch_all_agents()\n        # Load each agent and add it to the list if successfully loaded\n        for serialized_agent in all_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if agent:\n                agents.append(agent)\n        return agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        loaded_agents = []\n        purposes = self.persistence.fetch_all_agent_purposes()\n        for purpose in purposes:\n            serialized_agent = self.persistence.fetch_agent(purpose)\n            if serialized_agent:\n                agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n                loaded_agents.append(agent)\n        return loaded_agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        loaded_agents = []\n        purposes = self.persistence.get_all_agent_purposes()\n        \n        for purpose in purposes:\n            serialized_agent = self.persistence.fetch_agent(purpose)\n            if serialized_agent:\n                agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n                loaded_agents.append(agent)\n        \n        return loaded_agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        agents = []\n        purposes = self.persistence.fetch_all_agent_purposes()\n        for purpose in purposes:\n            serialized_agent = self.persistence.fetch_agent(purpose)\n            if serialized_agent:\n                agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n                agents.append(agent)\n        return agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        loaded_agents = []\n        # Fetch all serialized agents from the database\n        all_serialized_agents = self.persistence.fetch_all_agents()\n        \n        # Deserialize and load each agent\n        for serialized_agent in all_serialized_agents:\n            loaded_agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if loaded_agent:\n                loaded_agents.append(loaded_agent)\n        \n        return loaded_agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        agents = []\n        # Fetch all agents from the database\n        all_agents = self.persistence.fetch_all_agents()\n        \n        # Load each agent and add it to the list if successfully loaded\n        for serialized_agent in all_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if agent:\n                agents.append(agent)\n        \n        return agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        all_agents = []\n        # Fetch all agents from the database\n        all_serialized_agents = self.persistence.fetch_all_agents()\n        \n        # Deserialize and load each agent\n        for serialized_agent in all_serialized_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if agent:\n                all_agents.append(agent)\n        \n        return all_agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        loaded_agents = []\n        # Fetch all agents from the database\n        all_agents = self.persistence.fetch_all_agents()\n        \n        # Load each agent and add it to the list of loaded agents\n        for serialized_agent in all_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if agent:\n                loaded_agents.append(agent)\n        \n        return loaded_agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        loaded_agents = []\n        # Fetch all agents from the database\n        all_agents = self.persistence.fetch_all_agents()\n        # Load each agent and add it to the list of loaded agents\n        for agent_data in all_agents:\n            agent = AgentSerializer.from_dict(agent_data, agent_lifecycle, openai_wrapper)\n            if agent:\n                loaded_agents.append(agent)\n        return loaded_agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        loaded_agents = []\n        purposes = self.persistence.get_all_agent_purposes()\n        for purpose in purposes:\n            serialized_agent = self.persistence.fetch_agent(purpose)\n            if serialized_agent:\n                loaded_agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n                loaded_agents.append(loaded_agent)\n        return loaded_agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        loaded_agents = []\n        purposes = self.persistence.get_all_agent_purposes()\n        for purpose in purposes:\n            serialized_agent = self.persistence.fetch_agent(purpose)\n            if serialized_agent:\n                agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n                loaded_agents.append(agent)\n        return loaded_agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        all_agents = []\n        # Fetch all agents from the database\n        all_serialized_agents = self.persistence.fetch_all_agents()\n        \n        # Deserialize and load each agent\n        for serialized_agent in all_serialized_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if agent:\n                all_agents.append(agent)\n        \n        return all_agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        loaded_agents = []\n        # Fetch all agents from the database\n        all_agents = self.persistence.fetch_all_agents()\n        \n        # Load each agent and add it to the list of loaded agents\n        for serialized_agent in all_agents:\n            loaded_agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if loaded_agent:\n                loaded_agents.append(loaded_agent)\n        \n        return loaded_agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        serialized_agents = self.persistence.fetch_all_agents()\n        loaded_agents = []\n        for serialized_agent in serialized_agents:\n            loaded_agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if loaded_agent:\n                loaded_agents.append(loaded_agent)\n        return loaded_agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        loaded_agents = []\n        purposes = self.persistence.get_all_agent_purposes()\n        for purpose in purposes:\n            serialized_agent = self.persistence.fetch_agent(purpose)\n            if serialized_agent:\n                agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n                loaded_agents.append(agent)\n        return loaded_agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        loaded_agents = []\n        purposes = self.persistence.fetch_all_agent_purposes()\n        for purpose in purposes:\n            serialized_agent = self.persistence.fetch_agent(purpose)\n            if serialized_agent:\n                agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n                loaded_agents.append(agent)\n        return loaded_agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        loaded_agents = []\n        # Fetch all agents from the database\n        all_agents = self.persistence.fetch_all_agents()\n        \n        # Load each agent and add it to the list of loaded agents\n        for serialized_agent in all_agents:\n            loaded_agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if loaded_agent:\n                loaded_agents.append(loaded_agent)\n        \n        return loaded_agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        loaded_agents = []\n        # Fetch all agents from the database\n        all_agents = self.persistence.fetch_all_agents()\n        \n        # Load each agent and add it to the list of loaded agents\n        for serialized_agent in all_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if agent:\n                loaded_agents.append(agent)\n        \n        return loaded_agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        loaded_agents = []\n        purposes = self.persistence.get_all_agent_purposes()\n        for purpose in purposes:\n            serialized_agent = self.persistence.fetch_agent(purpose)\n            if serialized_agent:\n                agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n                loaded_agents.append(agent)\n        return loaded_agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        agents = []\n        # Fetch all agents from the database\n        all_agents = self.persistence.fetch_all_agents()\n        \n        # Load each agent and append to the list if successfully loaded\n        for serialized_agent in all_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if agent:\n                agents.append(agent)\n        \n        return agents"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error occurred while saving agent: {e}\")\n            raise"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error occurred while saving agent: {e}\")\n            raise e"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error occurred while saving agent: {e}\")\n            raise e"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error occurred while saving agent: {e}\")\n            raise e"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error occurred while saving agent {agent.id}: {e}\")\n            raise"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error occurred while saving agent: {e}\")\n            raise e"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error occurred while saving agent: {e}\")\n            raise e"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(\"Error occurred while saving the agent:\")\n            raise e"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error occurred while saving agent: {e}\")\n            raise"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error occurred while saving agent: {e}\")\n            raise e"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error occurred while saving agent {agent.id}: {e}\")\n            raise"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error occurred while saving agent: {e}\")\n            raise e"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error occurred while saving agent {agent.id}: {e}\")\n            raise e"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error occurred while saving agent: {e}\")\n            raise e"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error occurred while saving agent: {e}\")\n            raise e"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error occurred while saving agent: {e}\")\n            raise e"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error occurred while saving agent: {e}\")\n            raise e"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error occurred while saving agent: {e}\")\n            raise e"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error occurred while saving agent: {e}\")\n            raise e"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error occurred while saving agent: {e}\")\n            raise"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # Calculate the center of the instance's bounding box\n    center_x = (instance[\"bbox\"][0] + instance[\"bbox\"][2]) / 2\n    center_y = (instance[\"bbox\"][1] + instance[\"bbox\"][3]) / 2\n\n    # Calculate the top-left corner of the crop\n    crop_x1 = max(0, int(center_x - crop_size[1] / 2))\n    crop_y1 = max(0, int(center_y - crop_size[0] / 2))\n\n    # Calculate the bottom-right corner of the crop\n    crop_x2 = min(image_size[1], crop_x1 + crop_size[1])\n    crop_y2 = min(image_size[0], crop_y1 + crop_size[0])\n\n    # Create a CropTransform object\n    crop_transform = T.CropTransform(crop_y1, crop_x1, crop_y2, crop_x2)\n\n    return crop_transform"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "\n    # Calculate the center of the instance's bounding box\n    center_x = (instance[\"bbox\"][0] + instance[\"bbox\"][2]) / 2\n    center_y = (instance[\"bbox\"][1] + instance[\"bbox\"][3]) / 2\n\n    # Calculate the top-left corner of the crop\n    crop_x1 = max(0, center_x - crop_size[1] // 2)\n    crop_y1 = max(0, center_y - crop_size[0] // 2)\n\n    # Adjust the top-left corner if the crop goes out of the image boundaries\n    crop_x1 = min(crop_x1, image_size[1] - crop_size[1])\n    crop_y1 = min(crop_y1, image_size[0] - crop_size[0])\n\n    return T.CropTransform(crop_x1, crop_y1, crop_size[1], crop_size[0])"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # Get the bounding box of the instance\n    bbox = instance[\"bbox\"]\n\n    # Calculate the center of the bounding box\n    center_x = bbox[0] + (bbox[2] - bbox[0]) / 2\n    center_y = bbox[1] + (bbox[3] - bbox[1]) / 2\n\n    # Calculate the top-left corner of the crop region\n    crop_x1 = max(0, center_x - crop_size[1] // 2)\n    crop_y1 = max(0, center_y - crop_size[0] // 2)\n\n    # Calculate the bottom-right corner of the crop region\n    crop_x2 = min(image_size[1], center_x + crop_size[1] // 2)\n    crop_y2 = min(image_size[0], center_y + crop_size[0] // 2)\n\n    # Create the CropTransform object\n    crop_transform = T.CropTransform(crop_y1, crop_x1, crop_y2, crop_x2)\n\n    return crop_transform"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "\n    # Calculate the center of the instance's bounding box\n    x_center = (instance[\"bbox\"][0] + instance[\"bbox\"][2]) / 2\n    y_center = (instance[\"bbox\"][1] + instance[\"bbox\"][3]) / 2\n\n    # Calculate the top-left corner of the crop region\n    crop_x1 = max(0, int(x_center - crop_size[1] / 2))\n    crop_y1 = max(0, int(y_center - crop_size[0] / 2))\n\n    # Adjust the crop region if it exceeds the image boundaries\n    crop_x2 = min(crop_x1 + crop_size[1], image_size[1])\n    crop_y2 = min(crop_y1 + crop_size[0], image_size[0])\n\n    # Calculate the new dimensions of the crop region\n    crop_width = crop_x2 - crop_x1\n    crop_height = crop_y2 - crop_y1\n\n    return T.CropTransform(crop_x1, crop_y1, crop_width, crop_height)"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "\n    # Calculate the center of the instance's bounding box\n    bbox = instance[\"bbox\"]\n    center_x = (bbox[0] + bbox[2]) / 2\n    center_y = (bbox[1] + bbox[3]) / 2\n\n    # Calculate the top-left corner of the crop region\n    crop_x1 = max(0, int(center_x - crop_size[1] / 2))\n    crop_y1 = max(0, int(center_y - crop_size[0] / 2))\n\n    # Adjust the crop region to fit within the image boundaries\n    crop_x2 = min(image_size[1], crop_x1 + crop_size[1])\n    crop_y2 = min(image_size[0], crop_y1 + crop_size[0])\n\n    # Calculate the dimensions of the crop region\n    crop_width = crop_x2 - crop_x1\n    crop_height = crop_y2 - crop_y1\n\n    return T.CropTransform(crop_x1, crop_y1, crop_width, crop_height)"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "\n    # Calculate the center of the instance's bounding box\n    center_x = (instance[\"bbox\"][0] + instance[\"bbox\"][2]) / 2\n    center_y = (instance[\"bbox\"][1] + instance[\"bbox\"][3]) / 2\n\n    # Calculate the top-left corner of the crop region\n    crop_x1 = max(0, center_x - crop_size[1] // 2)\n    crop_y1 = max(0, center_y - crop_size[0] // 2)\n\n    # Calculate the bottom-right corner of the crop region\n    crop_x2 = min(image_size[1], crop_x1 + crop_size[1])\n    crop_y2 = min(image_size[0], crop_y1 + crop_size[0])\n\n    # Adjust the top-left corner if the crop region is not fully contained within the image\n    crop_x1 = max(0, crop_x2 - crop_size[1]) if crop_x2 > image_size[1] else crop_x1\n    crop_y1 = max(0, crop_y2 - crop_size[0]) if crop_y2 > image_size[0] else crop_y1\n\n    return T.CropTransform(crop_x1, crop_y1, crop_x2, crop_y2)"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "\n    # Calculate the center of the instance's bounding box\n    bbox = instance[\"bbox\"]\n    x_center = (bbox[0] + bbox[2]) / 2\n    y_center = (bbox[1] + bbox[3]) / 2\n\n    # Calculate the top-left corner of the crop region\n    crop_x1 = max(0, int(x_center - crop_size[1] / 2))\n    crop_y1 = max(0, int(y_center - crop_size[0] / 2))\n\n    # Adjust the crop region if it extends beyond the image boundaries\n    crop_x2 = min(image_size[1], crop_x1 + crop_size[1])\n    crop_y2 = min(image_size[0], crop_y1 + crop_size[0])\n    crop_x1 = crop_x2 - crop_size[1]  # Adjust x1 if x2 was clipped\n    crop_y1 = crop_y2 - crop_size[0]  # Adjust y1 if y2 was clipped\n\n    # Create a CropTransform object with the calculated crop region\n    return T.CropTransform(crop_x1, crop_y1, crop_x2, crop_y2)"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # Calculate the center of the instance's bounding box\n    center_x = (instance[\"bbox\"][0] + instance[\"bbox\"][2]) / 2\n    center_y = (instance[\"bbox\"][1] + instance[\"bbox\"][3]) / 2\n\n    # Calculate the top-left corner of the crop to ensure the instance is in the center\n    crop_x1 = max(0, int(center_x - crop_size[1] / 2))\n    crop_y1 = max(0, int(center_y - crop_size[0] / 2))\n\n    # Adjust the crop dimensions if it exceeds the image boundaries\n    crop_x2 = min(crop_x1 + crop_size[1], image_size[1])\n    crop_y2 = min(crop_y1 + crop_size[0], image_size[0])\n\n    # Adjust the top-left corner if the crop dimensions were adjusted\n    crop_x1 = max(0, crop_x2 - crop_size[1])\n    crop_y1 = max(0, crop_y2 - crop_size[0])\n\n    # Create and return the CropTransform object\n    return T.CropTransform(crop_x1, crop_y1, crop_x2, crop_y2)"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "\n    # Get the bounding box of the instance\n    bbox = instance[\"bbox\"]\n    bbox_mode = instance[\"bbox_mode\"]\n\n    # Calculate the center of the bounding box\n    center_x = (bbox[0] + bbox[2]) / 2\n    center_y = (bbox[1] + bbox[3]) / 2\n\n    # Calculate the top-left corner of the crop\n    crop_x1 = max(0, int(center_x - crop_size[1] / 2))\n    crop_y1 = max(0, int(center_y - crop_size[0] / 2))\n\n    # Calculate the bottom-right corner of the crop\n    crop_x2 = min(image_size[1], crop_x1 + crop_size[1])\n    crop_y2 = min(image_size[0], crop_y1 + crop_size[0])\n\n    # Adjust the top-left corner if the crop exceeds image boundaries\n    crop_x1 = max(0, crop_x2 - crop_size[1])\n    crop_y1 = max(0, crop_y2 - crop_size[0])\n\n    # Create a CropTransform object\n    crop_transform = T.CropTransform(crop_x1, crop_y1, crop_x2, crop_y2)\n\n    return crop_transform"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # Calculate the center of the instance's bounding box\n    center_x = (instance[\"bbox\"][0] + instance[\"bbox\"][2]) / 2\n    center_y = (instance[\"bbox\"][1] + instance[\"bbox\"][3]) / 2\n\n    # Calculate the top-left corner of the crop\n    crop_x1 = max(0, center_x - crop_size[1] // 2)\n    crop_y1 = max(0, center_y - crop_size[0] // 2)\n\n    # Calculate the bottom-right corner of the crop\n    crop_x2 = min(image_size[1], center_x + crop_size[1] // 2)\n    crop_y2 = min(image_size[0], center_y + crop_size[0] // 2)\n\n    # Create a CropTransform object\n    crop_transform = T.CropTransform(crop_y1, crop_x1, crop_y2, crop_x2)\n\n    return crop_transform"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # Get the bounding box of the instance\n    bbox = instance[\"bbox\"]\n\n    # Calculate the center of the bounding box\n    center_x = (bbox[0] + bbox[2]) / 2\n    center_y = (bbox[1] + bbox[3]) / 2\n\n    # Calculate the top-left corner of the crop region\n    crop_x1 = max(0, int(center_x - crop_size[1] / 2))\n    crop_y1 = max(0, int(center_y - crop_size[0] / 2))\n\n    # Calculate the bottom-right corner of the crop region\n    crop_x2 = min(image_size[1], crop_x1 + crop_size[1])\n    crop_y2 = min(image_size[0], crop_y1 + crop_size[0])\n\n    # Create a CropTransform object\n    crop_transform = T.CropTransform(crop_y1, crop_x1, crop_y2, crop_x2)\n\n    return crop_transform"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "\n    # Calculate the center of the instance's bounding box\n    bbox = instance[\"bbox\"]\n    x_center = (bbox[0] + bbox[2]) / 2\n    y_center = (bbox[1] + bbox[3]) / 2\n\n    # Calculate the top-left corner of the crop region\n    crop_x1 = max(0, int(x_center - crop_size[1] / 2))\n    crop_y1 = max(0, int(y_center - crop_size[0] / 2))\n\n    # Adjust the crop region if it exceeds the image boundaries\n    crop_x2 = min(image_size[1], crop_x1 + crop_size[1])\n    crop_y2 = min(image_size[0], crop_y1 + crop_size[0])\n\n    # Create the CropTransform object\n    return T.CropTransform(crop_x1, crop_y1, crop_x2, crop_y2)"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "\n    # Calculate the center of the instance's bounding box\n    bbox = instance[\"bbox\"]\n    x_center = (bbox[0] + bbox[2]) / 2\n    y_center = (bbox[1] + bbox[3]) / 2\n\n    # Calculate the top-left corner of the crop region\n    crop_x1 = max(0, int(x_center - crop_size[1] / 2))\n    crop_y1 = max(0, int(y_center - crop_size[0] / 2))\n\n    # Adjust the crop region to fit within the image boundaries\n    crop_x2 = min(image_size[1], crop_x1 + crop_size[1])\n    crop_y2 = min(image_size[0], crop_y1 + crop_size[0])\n\n    # Create a CropTransform object with the calculated crop region\n    return T.CropTransform(crop_x1, crop_y1, crop_x2, crop_y2)"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "\n    # Get the bounding box of the instance\n    bbox = instance[\"bbox\"]\n    bbox_mode = instance[\"bbox_mode\"]\n\n    # Calculate the center of the bounding box\n    center_x = (bbox[0] + bbox[2]) / 2\n    center_y = (bbox[1] + bbox[3]) / 2\n\n    # Calculate the top-left corner of the crop\n    crop_x1 = max(0, center_x - crop_size[1] // 2)\n    crop_y1 = max(0, center_y - crop_size[0] // 2)\n\n    # Calculate the bottom-right corner of the crop\n    crop_x2 = min(image_size[1], crop_x1 + crop_size[1])\n    crop_y2 = min(image_size[0], crop_y1 + crop_size[0])\n\n    # Adjust the top-left corner if the crop exceeds image boundaries\n    crop_x1 = max(0, crop_x2 - crop_size[1])\n    crop_y1 = max(0, crop_y2 - crop_size[0])\n\n    # Create and return the CropTransform object\n    return T.CropTransform(crop_x1, crop_y1, crop_x2, crop_y2)"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # Calculate the center of the instance's bounding box\n    x_center = (instance[\"bbox\"][0] + instance[\"bbox\"][2]) / 2\n    y_center = (instance[\"bbox\"][1] + instance[\"bbox\"][3]) / 2\n\n    # Calculate the top-left corner of the crop region\n    crop_x1 = max(0, int(x_center - crop_size[1] / 2))\n    crop_y1 = max(0, int(y_center - crop_size[0] / 2))\n\n    # Calculate the bottom-right corner of the crop region\n    crop_x2 = min(image_size[1], crop_x1 + crop_size[1])\n    crop_y2 = min(image_size[0], crop_y1 + crop_size[0])\n\n    # Create a CropTransform object with the calculated crop region\n    crop_transform = T.CropTransform(crop_x1, crop_y1, crop_x2, crop_y2)\n\n    return crop_transform"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # Compute the center of the instance's bounding box\n    center_x = (instance[\"bbox\"][0] + instance[\"bbox\"][2]) / 2\n    center_y = (instance[\"bbox\"][1] + instance[\"bbox\"][3]) / 2\n\n    # Calculate the top-left corner of the crop\n    crop_x1 = max(0, int(center_x - crop_size[1] / 2))\n    crop_y1 = max(0, int(center_y - crop_size[0] / 2))\n\n    # Adjust the crop dimensions if it exceeds the image boundaries\n    crop_x2 = min(image_size[1], crop_x1 + crop_size[1])\n    crop_y2 = min(image_size[0], crop_y1 + crop_size[0])\n\n    # Create the CropTransform object\n    crop_transform = T.CropTransform(crop_x1, crop_y1, crop_x2, crop_y2)\n\n    return crop_transform"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "\n    # Get the bounding box of the instance\n    bbox = instance[\"bbox\"]\n\n    # Calculate the center of the bounding box\n    center_x = (bbox[0] + bbox[2]) / 2\n    center_y = (bbox[1] + bbox[3]) / 2\n\n    # Calculate the top-left corner of the crop\n    crop_x1 = max(0, int(center_x - crop_size[1] / 2))\n    crop_y1 = max(0, int(center_y - crop_size[0] / 2))\n\n    # Calculate the bottom-right corner of the crop\n    crop_x2 = min(image_size[1], crop_x1 + crop_size[1])\n    crop_y2 = min(image_size[0], crop_y1 + crop_size[0])\n\n    # Create a CropTransform object with the calculated crop parameters\n    crop_transform = T.CropTransform(crop_x1, crop_y1, crop_x2, crop_y2)\n\n    return crop_transform"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    x1, y1, x2, y2 = instance[\"bbox\"]\n    center_x = (x1 + x2) / 2\n    center_y = (y1 + y2) / 2\n    crop_height, crop_width = crop_size\n\n    # Adjust crop region to fit within image boundaries\n    crop_x1 = max(center_x - crop_width // 2, 0)\n    crop_y1 = max(center_y - crop_height // 2, 0)\n    crop_x2 = min(center_x + crop_width // 2, image_size[1])\n    crop_y2 = min(center_y + crop_height // 2, image_size[0])\n\n    return T.CropTransform(crop_x1, crop_y1, crop_x2, crop_y2)"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    crop_h, crop_w = crop_size\n    image_h, image_w = image_size\n\n    # Get the bounding box coordinates of the instance\n    bbox = instance[\"bbox\"]\n    x1, y1, x2, y2 = bbox\n\n    # Calculate the center of the bounding box\n    center_x = (x1 + x2) / 2\n    center_y = (y1 + y2) / 2\n\n    # Calculate the top-left corner of the crop region\n    crop_x1 = max(0, int(center_x - crop_w / 2))\n    crop_y1 = max(0, int(center_y - crop_h / 2))\n\n    # Adjust the crop region if it exceeds the image boundaries\n    crop_x2 = min(image_w, crop_x1 + crop_w)\n    crop_y2 = min(image_h, crop_y1 + crop_h)\n\n    # Calculate the new dimensions of the crop region\n    crop_w = crop_x2 - crop_x1\n    crop_h = crop_y2 - crop_y1\n\n    return T.CropTransform(crop_x1, crop_y1, crop_w, crop_h)"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "\n    # Determine the center of the instance's bounding box\n    bbox = instance[\"bbox\"]\n    x_center = (bbox[0] + bbox[2]) / 2\n    y_center = (bbox[1] + bbox[3]) / 2\n\n    # Calculate the top-left corner of the crop region\n    crop_x1 = max(0, int(x_center - crop_size[1] / 2))\n    crop_y1 = max(0, int(y_center - crop_size[0] / 2))\n\n    # Calculate the dimensions of the crop region\n    crop_x2 = min(image_size[1], crop_x1 + crop_size[1])\n    crop_y2 = min(image_size[0], crop_y1 + crop_size[0])\n\n    # Create the CropTransform object\n    crop_transform = T.CropTransform(crop_x1, crop_y1, crop_x2, crop_y2)\n\n    return crop_transform"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "\n    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "\n    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n    return image"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    for i, xform in enumerate(transforms):\n        if \"bbox\" in annotation:\n            bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n            bbox = xform.apply_box([bbox])[0]\n            annotation[\"bbox\"] = BoxMode.convert(bbox, BoxMode.XYXY_ABS, annotation[\"bbox_mode\"])\n\n        if \"segmentation\" in annotation:\n            # Create a dummy instance to use the masks function\n            dummy_instance = Instances(image_size)\n            mask_format = annotation.get(\"segmentation_mode\", \"polygon\")\n            if mask_format == \"polygon\":\n                polygons = [xform.apply_polygons([poly])[0] for poly in annotation[\"segmentation\"]]\n                annotation[\"segmentation\"] = polygons\n            elif mask_format == \"bitmask\":\n                rle = mask_util.frPyObjects(annotation[\"segmentation\"], image_size[0], image_size[1])\n                rle = xform.apply_segmentation(rle)\n                annotation[\"segmentation\"] = mask_util.merge(rle) if rle else []\n            else:\n                raise ValueError(\"Unknown segmentation mode: {}\".format(mask_format))\n\n        if \"keypoints\" in annotation and keypoint_hflip_indices is not None and xform.__class__.__name__ == \"HFlipTransform\":\n            keypoints = annotation[\"keypoints\"]\n            keypoints = [keypoints[i] if i in keypoint_hflip_indices else (image_size[0] - 1 - keypoints[i]) for i in range(len(keypoints))]\n            annotation[\"keypoints\"] = keypoints\n\n    return annotation"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Apply transformation to bounding box\n    annotation[\"bbox\"] = transforms.apply_box(\n        BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    )\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Apply transformation to segmentation\n    if \"segmentation\" in annotation:\n        if isinstance(annotation[\"segmentation\"], PolygonMasks):\n            annotation[\"segmentation\"] = annotation[\"segmentation\"].crop_and_resize(\n                transforms, image_size\n            )\n        else:\n            raise ValueError(\n                \"Cannot transform segmentation of type '{}'!\".format(\n                    type(annotation[\"segmentation\"])\n                )\n            )\n\n    # Apply transformation to keypoints\n    if \"keypoints\" in annotation:\n        keypoints = annotation[\"keypoints\"]\n        keypoints = transforms.apply_coords(keypoints)\n        # Flip the keypoints if horizontal flip transformation is applied\n        if keypoint_hflip_indices is not None:\n            keypoints = keypoints[:, keypoint_hflip_indices]\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "\n    # Transform the bounding box\n    if \"bbox\" in annotation:\n        bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n        bbox = transforms.apply_box([bbox])[0]\n        annotation[\"bbox\"] = bbox\n        annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Transform the segmentation\n    if \"segmentation\" in annotation:\n        if isinstance(annotation[\"segmentation\"], list):\n            # Polygon format\n            annotation[\"segmentation\"] = [\n                mask_util.frPyObjects(poly, image_size[0], image_size[1]) for poly in annotation[\"segmentation\"]\n            ]\n            annotation[\"segmentation\"] = mask_util.merge(annotation[\"segmentation\"])\n            annotation[\"segmentation\"] = mask_util.decode(annotation[\"segmentation\"])\n        else:\n            # RLE format\n            annotation[\"segmentation\"] = mask_util.frPyObjects(\n                annotation[\"segmentation\"], image_size[0], image_size[1]\n            )\n            annotation[\"segmentation\"] = mask_util.decode(annotation[\"segmentation\"])\n\n        # Apply the transformations\n        annotation[\"segmentation\"] = [transforms.apply_segmentation(segmentation) for segmentation in annotation[\"segmentation\"]]\n\n    # Transform the keypoints\n    if \"keypoints\" in annotation and keypoint_hflip_indices is not None:\n        keypoints = Keypoints(annotation[\"keypoints\"], annotation[\"bbox\"], image_size, annotation[\"bbox_mode\"])\n        keypoints = keypoints.keypoints\n        keypoints = keypoints[keypoint_hflip_indices]\n        keypoints = torch.as_tensor(keypoints)\n        keypoints = transforms.apply_coords(keypoints)\n        keypoints = keypoints.numpy()\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Apply transformation to bounding box\n    if \"bbox\" in annotation:\n        bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n        bbox = transforms.apply_box([bbox])[0]\n        annotation[\"bbox\"] = bbox\n        annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Apply transformation to segmentation\n    if \"segmentation\" in annotation:\n        segmentation = annotation[\"segmentation\"]\n        if isinstance(segmentation, np.ndarray) and len(segmentation.shape) == 2:\n            # RLE encoded binary masks\n            mask = mask_util.decode(segmentation)\n            mask = transforms.apply_segmentation(mask)\n            rle = mask_util.encode(np.array(mask[:, :, None], order=\"F\"))[0]\n            annotation[\"segmentation\"] = rle\n        elif isinstance(segmentation, list):\n            # Polygon format\n            for i, poly in enumerate(segmentation):\n                segmentation[i] = transforms.apply_polygons([poly])[0]\n        else:\n            raise ValueError(\"Cannot transform segmentation of type '{}'!\".format(type(segmentation)))\n\n    # Apply transformation to keypoints\n    if \"keypoints\" in annotation:\n        keypoints = annotation[\"keypoints\"]\n        keypoints = transforms.apply_keypoints(keypoints)\n        if keypoint_hflip_indices is not None and transforms.hflip:\n            keypoints = keypoints[:, keypoint_hflip_indices]\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "\n    # Apply transformation to bounding box\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    bbox = transforms.apply_box([bbox])[0]\n    annotation[\"bbox\"] = bbox\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Apply transformation to segmentation\n    if \"segmentation\" in annotation:\n        if annotation[\"segmentation\"] is None:\n            return annotation\n        segmentation = annotation[\"segmentation\"]\n        if isinstance(segmentation, np.ndarray):\n            if segmentation.dtype.kind == \"i\":\n                # RLE\n                mask = mask_util.decode(segmentation).astype(\"uint8\")\n            else:\n                # polygon\n                mask = polygons_to_bitmask([segmentation], *image_size)\n        else:\n            # mask object\n            mask = segmentation.crop_and_resize(\n                np.zeros((1,) + image_size, dtype=\"uint8\"), 1, (0, 0, image_size[1], image_size[0])\n            )[0]\n        mask = mask[0] if isinstance(mask, torch.Tensor) else mask\n        mask = mask_util.encode(np.array(mask, order=\"F\", dtype=\"uint8\"))[0]\n        mask[\"counts\"] = mask[\"counts\"].decode(\"utf-8\")\n        annotation[\"segmentation\"] = mask\n\n    # Apply transformation to keypoints\n    if \"keypoints\" in annotation and keypoint_hflip_indices is not None:\n        keypoints = annotation[\"keypoints\"]\n        keypoints = transforms.apply_coords(keypoints)\n        if \"horizontal_flip\" in transforms:\n            keypoints = keypoints.copy()\n            flipped = keypoints[keypoint_hflip_indices]\n            keypoints[keypoint_hflip_indices] = keypoints[flipped]\n            keypoints[flipped] = keypoints[keypoint_hflip_indices]\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "\n    # Transform the bounding box\n    if \"bbox\" in annotation:\n        bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n        bbox = transforms.apply_box([bbox])[0]\n        annotation[\"bbox\"] = bbox\n        annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Transform the segmentation\n    if \"segmentation\" in annotation:\n        if annotation[\"segmentation\"] is None:\n            # This is a dummy annotation for some datasets, e.g., COCO.\n            return annotation\n        # Create a dummy mask object to use the `apply_segmentation` function\n        mask = PolygonMasks([annotation[\"segmentation\"]])\n        mask = mask_util.decode(mask.polygons)[0]  # Convert to RLE\n        mask = mask_util.encode(np.asarray(mask_util.decode(mask))[:, :, np.newaxis])[0]\n        mask = torch.as_tensor(mask)\n        mask = mask.reshape((mask.shape[0], mask.shape[1], 1))\n        mask = transforms.apply_segmentation([mask])[0]\n        mask = mask.squeeze(2)\n        mask = mask_util.encode(np.asarray(mask.numpy(), order=\"F\", dtype=\"uint8\"))\n        mask = mask_util.decode(mask)\n        # Only keep the largest connected component\n        mask = mask_util.encode(mask_util.decode(mask_util.encode(np.asarray(mask)))[0])\n        mask = mask_util.encode(np.asarray(mask_util.decode(mask))[:, :, np.newaxis])\n        mask = mask_util.decode(mask)\n        annotation[\"segmentation\"] = mask\n\n    # Transform the keypoints\n    if \"keypoints\" in annotation:\n        keypoints = Keypoints(annotation[\"keypoints\"], annotation[\"keypoints_mode\"], image_size)\n        keypoints = keypoints.keypoints\n        keypoints = keypoints.reshape(-1, 3)  # Reshape to Nx3\n        keypoints = transforms.apply_coords(keypoints)\n        keypoints = keypoints.reshape(-1, 17, 3)  # Reshape back to 17x3\n        annotation[\"keypoints\"] = keypoints\n        annotation[\"keypoints_mode\"] = \"xy\"\n        if keypoint_hflip_indices is not None and transforms.hflip:\n            keypoints = keypoints[keypoint_hflip_indices]\n            keypoints[..., 0] = image_size[1] - keypoints[..., 0] - 1\n            annotation[\"keypoints\"] = keypoints\n\n    return annotation"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Transform the bounding box\n    if \"bbox\" in annotation:\n        bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n        bbox = transforms.apply_box([bbox])[0]\n        annotation[\"bbox\"] = bbox\n        annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Transform the segmentation\n    if \"segmentation\" in annotation:\n        segmentation = annotation[\"segmentation\"]\n        if isinstance(segmentation, np.ndarray):\n            # Polygon format\n            if len(segmentation) == 0:\n                # empty mask\n                return annotation\n            segmentation = [np.asarray(seg).reshape(-1, 2) for seg in segmentation]\n            segmentation = [transforms.apply_polygons([seg])[0] for seg in segmentation]\n            annotation[\"segmentation\"] = segmentation\n        else:\n            # RLE format\n            mask = mask_util.decode(segmentation).astype(\"uint8\")\n            mask = transforms.apply_segmentation(mask)\n            rle = mask_util.encode(np.array(mask[:, :, None], order=\"F\"))[0]\n            annotation[\"segmentation\"] = rle\n\n    # Transform the keypoints\n    if \"keypoints\" in annotation and transforms:\n        keypoints = annotation[\"keypoints\"]\n        keypoints = transforms.apply_keypoints(keypoints)\n        if keypoint_hflip_indices is not None and transforms.proposal_hflip is not None:\n            keypoints = keypoints[:, :3]  # remove the scores\n            keypoints[keypoint_hflip_indices] = keypoints[keypoint_hflip_indices, ::-1]\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "\n    # Apply transformation to bounding box\n    if \"bbox\" in annotation:\n        bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n        bbox = transforms.apply_box([bbox])[0]\n        annotation[\"bbox\"] = bbox\n        annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Apply transformation to segmentation\n    if \"segmentation\" in annotation:\n        if isinstance(annotation[\"segmentation\"], list):\n            # Polygon format\n            segmentation = annotation[\"segmentation\"]\n            for i, polygon in enumerate(segmentation):\n                segmentation[i] = transforms.apply_polygons([polygon])[0]\n        elif isinstance(annotation[\"segmentation\"], dict):\n            # RLE format\n            mask = mask_util.decode(annotation[\"segmentation\"])\n            mask = Image.fromarray(mask)\n            mask = transforms.apply_segmentation(mask)\n            rle = mask_util.encode(np.array(mask)[:, :, np.newaxis])[0]\n            annotation[\"segmentation\"] = rle\n\n    # Apply transformation to keypoints\n    if \"keypoints\" in annotation and keypoint_hflip_indices is not None:\n        keypoints = annotation[\"keypoints\"]\n        keypoints = transforms.apply_keypoints([keypoints])[0]\n        # Handle horizontal flipping of keypoints\n        if \"horizontal_flip\" in transforms:\n            keypoints = keypoints.numpy()\n            keypoints[keypoint_hflip_indices, 0] = image_size[1] - keypoints[keypoint_hflip_indices, 0]\n            annotation[\"keypoints\"] = torch.as_tensor(keypoints)\n\n    return annotation"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if \"bbox\" in annotation:\n        bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n        bbox = transforms.apply_box([bbox])[0]\n        annotation[\"bbox\"] = bbox\n\n    if \"segmentation\" in annotation:\n        segmentation = annotation[\"segmentation\"]\n        if isinstance(segmentation, list):\n            # Polygons\n            segmentation = [transforms.apply_polygons(s, image_size) for s in segmentation]\n        elif isinstance(segmentation, dict) and \"counts\" in segmentation and \"size\" in segmentation:\n            # RLE\n            mask = mask_util.decode(segmentation)\n            mask = transforms.apply_segmentation(mask, image_size)\n            rle = mask_util.encode(np.array(mask[:, :, None], order=\"F\"))[0]\n            annotation[\"segmentation\"] = {\"counts\": rle[\"counts\"].decode(\"utf-8\"), \"size\": segmentation[\"size\"]}\n        else:\n            raise ValueError(\"Cannot transform segmentation of type '{}'!\".format(type(segmentation)))\n        annotation[\"segmentation\"] = segmentation\n\n    if \"keypoints\" in annotation and transforms:\n        keypoints = annotation[\"keypoints\"]\n        keypoints = transforms.apply_keypoints(keypoints)\n        annotation[\"keypoints\"] = keypoints\n\n        if keypoint_hflip_indices is not None and \"horizontal_flip\" in transforms:\n            keypoints = np.asarray(keypoints)\n            keypoints = T.apply_horizontal_flip_keypoints(keypoints, image_size, keypoint_hflip_indices)\n            annotation[\"keypoints\"] = keypoints\n\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n    return annotation"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Transform the bounding box\n    if \"bbox\" in annotation:\n        bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n        bbox = transforms.apply_box([bbox])[0]\n        annotation[\"bbox\"] = bbox\n        annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Transform the segmentation\n    if \"segmentation\" in annotation:\n        if isinstance(annotation[\"segmentation\"], list):\n            # polygon format\n            segmentation = [transforms.apply_polygons(s) for s in annotation[\"segmentation\"]]\n        else:\n            # RLE format\n            segmentation = annotation[\"segmentation\"]\n            mask = mask_util.decode(segmentation)\n            mask = transforms.apply_segmentation(mask)\n            segmentation = mask_util.encode(np.array(mask, order=\"F\"))\n        annotation[\"segmentation\"] = segmentation\n\n    # Transform the keypoints\n    if \"keypoints\" in annotation:\n        keypoints = annotation[\"keypoints\"]\n        keypoints = transforms.apply_keypoints(keypoints)\n        if keypoint_hflip_indices is not None and transforms.hflip:\n            keypoints = keypoints.copy()\n            keypoints[..., 0] = image_size[1] - keypoints[..., 0] - 1\n            for l, r in keypoint_hflip_indices:\n                keypoints[l], keypoints[r] = keypoints[r], keypoints[l]\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # transform the bounding box\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    bbox = transforms.apply_box([bbox])[0]\n    annotation[\"bbox\"] = bbox\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # transform the segmentation\n    if \"segmentation\" in annotation:\n        polygons = annotation[\"segmentation\"]\n        if isinstance(polygons, list):\n            # list[list[float]]: open-ended polygons\n            segmentation = [transforms.apply_polygons(polygons)]\n        else:\n            # RLE\n            segmentation = mask_util.decode(polygons)\n            segmentation = [transforms.apply_segmentation([segmentation])[0]]\n        annotation[\"segmentation\"] = segmentation[0]\n\n    # transform the keypoints\n    if \"keypoints\" in annotation and len(annotation[\"keypoints\"]):\n        keypoints = Keypoints(annotation[\"keypoints\"], annotation[\"keypoints_mode\"], image_size)\n        keypoints = keypoints.keypoints\n        if keypoint_hflip_indices is not None:\n            keypoints = keypoints[keypoint_hflip_indices]\n            keypoints[..., 0] = image_size[1] - keypoints[..., 0] - 1\n        keypoints, _ = transforms.apply_keypoint(keypoints, image_size)\n        keypoints = Keypoints(keypoints, keypoints_mode=KeypointsMode.POINT, image_size=image_size)\n        annotation[\"keypoints\"] = keypoints.tensor"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Transform the bounding box\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    bbox = transforms.apply_box([bbox])[0]\n    annotation[\"bbox\"] = bbox\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Transform the segmentation\n    if \"segmentation\" in annotation:\n        polygons = [PolygonMasks([s[\"polygon\"]]) for s in annotation[\"segmentation\"]]\n        segmentations = mask_util.frPyObjects([p.polygons[0] for p in polygons], image_size[0], image_size[1])\n        segmentations = mask_util.merge(segmentations)\n        segmentations = mask_util.decode(segmentations)\n        segmentations = mask_util.encode(np.asarray(transforms.apply_segmentation(segmentations)))\n        polygons = mask_util.toBbox(segmentations)\n        annotation[\"segmentation\"] = [dict(polygon=polygons[i], category_id=1) for i in range(len(polygons))]\n\n    # Transform the keypoints\n    if \"keypoints\" in annotation:\n        keypoints = annotation[\"keypoints\"]\n        keypoints = transforms.apply_keypoint(keypoints)\n        if keypoint_hflip_indices is not None and transforms.hflip:\n            keypoints = keypoints.copy()\n            keypoints = keypoints[:, keypoint_hflip_indices, :]\n            # Maintain COCO convention that if visibility == 0, then x, y = 0\n            # This allows test-dev to ignore these points\n            keypoints[keypoints[:, 2] == 0] = 0\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Transform the bounding box\n    if \"bbox\" in annotation:\n        bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n        bbox = transforms.apply_box([bbox])[0]\n        annotation[\"bbox\"] = bbox\n        annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Transform the segmentation\n    if \"segmentation\" in annotation:\n        if isinstance(annotation[\"segmentation\"], list):\n            # Polygon format\n            segmentation = annotation[\"segmentation\"]\n            for i, s in enumerate(segmentation):\n                if len(s) % 2 != 0:\n                    raise ValueError(\"Segmentation should have an even number of coordinates.\")\n                segmentation[i] = transforms.apply_polygons([s])[0]\n            annotation[\"segmentation\"] = segmentation\n        elif isinstance(annotation[\"segmentation\"], dict):\n            # RLE format\n            mask = mask_util.decode(annotation[\"segmentation\"])\n            mask = Image.fromarray(mask)\n            mask = transforms.apply_segmentation(mask)\n            rle = mask_util.encode(np.array(mask)[:, :, np.newaxis])[0]\n            annotation[\"segmentation\"] = rle\n\n    # Transform the keypoints\n    if \"keypoints\" in annotation and keypoint_hflip_indices is not None:\n        keypoints = annotation[\"keypoints\"]\n        keypoints = torch.as_tensor(keypoints).reshape(-1, 3)\n        keypoints = transforms.apply_keypoints(keypoints)\n        keypoints = keypoints.reshape(-1, 3).tolist()\n        annotation[\"keypoints\"] = keypoints\n    return annotation"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "\n    # Apply transformation to bounding box\n    if \"bbox\" in annotation:\n        bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n        bbox = transforms.apply_box([bbox])[0]\n        annotation[\"bbox\"] = bbox\n        annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Apply transformation to segmentation\n    if \"segmentation\" in annotation:\n        if isinstance(annotation[\"segmentation\"], list):\n            # Polygon format\n            segmentations = annotation[\"segmentation\"]\n            for i, segm in enumerate(segmentations):\n                segmentations[i] = transforms.apply_segmentation(segm)\n        elif isinstance(annotation[\"segmentation\"], dict):\n            # RLE format\n            rle = mask_util.frPyObjects([annotation[\"segmentation\"]], image_size[0], image_size[1])\n            rle = mask_util.merge(rle)\n            rle = transforms.apply_segmentation(rle)\n            annotation[\"segmentation\"] = mask_util.decode(rle)\n\n    # Apply transformation to keypoints\n    if \"keypoints\" in annotation and keypoint_hflip_indices is not None:\n        keypoints = annotation[\"keypoints\"]\n        keypoints = transforms.apply_keypoint(keypoints)\n        if \"keypoints_hflip_indices\" in annotation:\n            keypoints = keypoints[:, keypoint_hflip_indices]\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Transform the bounding box\n    if \"bbox\" in annotation:\n        bbox = BoxMode.convert(annotation[\"bbox\"], annotation.get(\"bbox_mode\", BoxMode.XYXY), BoxMode.XYXY_ABS)\n        bbox = transforms.apply_box([bbox])[0]\n        annotation[\"bbox\"] = bbox\n        annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Transform the segmentation\n    if \"segmentation\" in annotation:\n        segmentation = annotation[\"segmentation\"]\n        if isinstance(segmentation, list):\n            # Polygons\n            transformed_segmentation = [\n                transforms.apply_polygons([poly])[0] for poly in segmentation\n            ]\n            annotation[\"segmentation\"] = transformed_segmentation\n        elif isinstance(segmentation, dict):\n            # RLE\n            mask = mask_util.decode(segmentation)\n            mask = transforms.apply_segmentation(mask)\n            rle = mask_util.encode(np.array(mask, order=\"F\", dtype=\"uint8\"))\n            annotation[\"segmentation\"] = rle\n        else:\n            raise ValueError(f\"Cannot transform segmentation of type '{type(segmentation)}'\")\n\n    # Transform the keypoints\n    if \"keypoints\" in annotation:\n        keypoints = Keypoints(annotation[\"keypoints\"], annotation[\"keypoints_categories\"])\n        keypoints = keypoints.apply_transform(transforms)\n        annotation[\"keypoints\"] = keypoints.tensor\n        if keypoint_hflip_indices is not None:\n            annotation[\"keypoints\"] = KeypointsList.flip(annotation[\"keypoints\"], image_size, keypoint_hflip_indices)\n\n    return annotation"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # transform the bounding box\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    bbox = transforms.apply_box([bbox])[0]\n    bbox = BoxMode.convert(bbox, BoxMode.XYXY_ABS, annotation[\"bbox_mode\"])\n    annotation[\"bbox\"] = bbox\n\n    # transform the segmentation\n    if \"segmentation\" in annotation:\n        if annotation[\"segmentation\"] is None:\n            # fill in \"segmentation\" if the annotation is missing it\n            annotation[\"segmentation\"] = [[\n                annotation[\"bbox\"][0], annotation[\"bbox\"][1],\n                annotation[\"bbox\"][0], annotation[\"bbox\"][3],\n                annotation[\"bbox\"][2], annotation[\"bbox\"][3],\n                annotation[\"bbox\"][2], annotation[\"bbox\"][1],\n            ]]\n        # RLE or Polygon\n        if isinstance(annotation[\"segmentation\"], dict):\n            # RLE\n            mask = mask_util.decode(annotation[\"segmentation\"])\n            mask = Image.fromarray(mask, \"I\")\n            mask = transforms.apply_segmentation(mask)\n            rle = mask_util.encode(np.asarray(mask)[:, :, None])[0]\n            annotation[\"segmentation\"] = rle\n        else:\n            # Polygon\n            segmentation = PolygonMasks([annotation[\"segmentation\"]])\n            segmentation = transforms.apply_polygons(segmentation)\n            annotation[\"segmentation\"] = segmentation.polygons[0]\n\n    # transform keypoints\n    if \"keypoints\" in annotation:\n        keypoints = Keypoints(annotation[\"keypoints\"], annotation[\"keypoint_flip_map\"])\n        keypoints = transforms.apply_keypoints(keypoints)\n        annotation[\"keypoints\"] = keypoints.tensor\n\n    return annotation"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Transform the bounding box\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    bbox = transforms.apply_box([bbox])[0]\n    annotation[\"bbox\"] = bbox\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Transform the segmentation\n    if \"segmentation\" in annotation:\n        if annotation[\"segmentation\"] is None:\n            # fill in \"segmentation\" if it is empty\n            annotation[\"segmentation\"] = []\n        else:\n            # transform the segmentation polygons\n            segmentation = annotation[\"segmentation\"]\n            if isinstance(segmentation, np.ndarray) and (segmentation.ndim == 3):\n                # RLE encoded\n                if segmentation.shape[0] != image_size[0] or segmentation.shape[1] != image_size[1]:\n                    raise SizeMismatchError(\n                        \"Segmentation shape {} does not match image size {}\".format(\n                            segmentation.shape[:2], image_size\n                        )\n                    )\n                segmentation = mask_util.encode(np.array(segmentation, order=\"F\"))\n                segmentation = mask_util.decode(segmentation)\n            else:\n                # list[list[float]]: a list of polygons\n                segmentation = [np.asarray(seg, dtype=np.float64) for seg in segmentation]\n                segmentation = [transforms.apply_polygons([seg])[0] for seg in segmentation]\n            annotation[\"segmentation\"] = segmentation\n\n    # Transform the keypoints\n    if \"keypoints\" in annotation:\n        keypoints = Keypoints(annotation[\"keypoints\"], annotation[\"keypoint_flip_map\"])\n        keypoints = keypoints.keypoints\n        keypoints = keypoints[:, :2]  # N,4 (x,y,v,o) -> N,2 (x,y)\n        keypoints = transforms.apply_coords(keypoints)\n        if keypoint_hflip_indices is not None:\n            keypoints = keypoints[keypoint_hflip_indices]\n        annotation[\"keypoints\"] = keypoints"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Transform the bounding box\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    bbox = transforms.apply_box([bbox])[0]\n    annotation[\"bbox\"] = bbox\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Transform the segmentation\n    if \"segmentation\" in annotation:\n        if isinstance(annotation[\"segmentation\"], list):\n            # Polygon format\n            segmentation = annotation[\"segmentation\"]\n            for i in range(len(segmentation)):\n                segmentation[i] = transforms.apply_polygons([segmentation[i]])[0]\n            annotation[\"segmentation\"] = segmentation\n        else:\n            # RLE format\n            mask = mask_util.decode(annotation[\"segmentation\"])\n            mask = Image.fromarray(mask)\n            mask = transforms.apply_segmentation([np.array(mask)])[0]\n            rle = mask_util.encode(np.array(mask, order=\"F\"))\n            annotation[\"segmentation\"] = rle\n\n    # Transform the keypoints\n    if \"keypoints\" in annotation and len(annotation[\"keypoints\"]):\n        keypoints = Keypoints(annotation[\"keypoints\"], annotation[\"keypoints_mode\"], image_size)\n        keypoints = keypoints.keypoints\n        if keypoint_hflip_indices is not None:\n            keypoints = keypoints[keypoint_hflip_indices]\n            keypoints[..., 0] = image_size[1] - keypoints[..., 0] - 1\n        keypoints, _ = transforms.apply_keypoint(keypoints, image_size)\n        keypoints = Keypoints(keypoints, KeypointsMode.XY)\n        annotation[\"keypoints\"] = keypoints.tensor\n        annotation[\"keypoints_mode\"] = KeypointsMode.XY\n    return annotation"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "\n    # Apply transformation to bounding box\n    if \"bbox\" in annotation:\n        bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n        bbox = transforms.apply_box([bbox])[0]\n        annotation[\"bbox\"] = bbox\n        annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Apply transformation to segmentation\n    if \"segmentation\" in annotation:\n        if annotation[\"segmentation\"] is None:\n            annotation[\"segmentation\"] = []\n        if annotation[\"segmentation_mode\"] == \"poly\":\n            # Transform segmentation polygons\n            polygons = annotation[\"segmentation\"]\n            segmentations = [transforms.apply_polygons(polygons).polygons]\n            annotation[\"segmentation\"] = segmentations\n        elif annotation[\"segmentation_mode\"] == \"compressed\":\n            # Transform RLE (Run-Length Encoding) masks\n            rle = mask_util.frPyObjects(annotation[\"segmentation\"], image_size[0], image_size[1])\n            rle = transforms.apply_segmentation(rle)\n            rle = mask_util.merge(rle)\n            rle = mask_util.frPyObjects(rle, image_size[0], image_size[1])\n            annotation[\"segmentation\"] = rle\n\n    # Apply transformation to keypoints\n    if \"keypoints\" in annotation:\n        keypoints = annotation[\"keypoints\"]\n        keypoints = transforms.apply_keypoints([keypoints])[0]\n        annotation[\"keypoints\"] = keypoints\n\n        # Handle horizontal flip of keypoints\n        if keypoint_hflip_indices is not None:\n            keypoints = np.asarray(keypoints)\n            keypoints = keypoints.reshape(-1, 3)\n            keypoints[keypoint_hflip_indices, 0] = image_size[1] - keypoints[keypoint_hflip_indices, 0]\n            annotation[\"keypoints\"] = keypoints.flatten()\n\n    return annotation"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    # Transform the bounding box\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    bbox = transforms.apply_box([bbox])[0]\n    annotation[\"bbox\"] = bbox\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Transform the segmentation\n    if \"segmentation\" in annotation:\n        polygons = annotation[\"segmentation\"]\n        if isinstance(polygons, list):\n            # list[list[float]]: open polygons\n            polygons = [np.asarray(p, dtype=np.float64) for p in polygons]\n        else:\n            # a compressed RLE\n            polygons = mask_util.decode(polygons)\n        for i, p in enumerate(polygons):\n            if len(p) == 0:\n                continue\n            polygons[i] = transforms.apply_polygons([p])[0]\n        annotation[\"segmentation\"] = polygons\n\n    # Transform the keypoints\n    if \"keypoints\" in annotation and keypoint_hflip_indices is not None:\n        keypoints = annotation[\"keypoints\"]\n        keypoints = transforms.apply_keypoints([keypoints])[0]\n        if \"horizontal_flip\" in transforms:\n            keypoints = keypoints[:, keypoint_hflip_indices]\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n\n        # Apply the rotation matrix to each coordinate\n        rotated_coords = np.dot(coords - self.center, self.rm_coords.T) + self.center\n        return rotated_coords"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n\n        # Apply the rotation matrix to each coordinate\n        rotated_coords = np.dot(coords - self.center, self.rm_coords.T) + self.center\n        return rotated_coords"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        new_coords = np.dot(coords - self.center, self.rm_coords.T) + self.center\n        return new_coords"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n\n        # Apply the rotation matrix to each coordinate\n        new_coords = np.dot(coords, self.rm_coords.T)\n        return new_coords"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        # Apply the rotation matrix to the coordinates\n        rotated_coords = np.dot(coords - self.center, self.rm_coords.T) + self.center\n        return rotated_coords"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n\n        # Convert coordinates to homogeneous coordinates\n        coords = np.hstack((coords, np.ones((len(coords), 1))))\n\n        # Apply rotation matrix to coordinates\n        transformed_coords = np.dot(coords, self.rm_coords.T)\n\n        return transformed_coords[:, :2]"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        # Apply rotation transformation to each coordinate\n        new_coords = np.dot(coords - self.center, self.rm_coords.T) + self.center\n        return new_coords"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        new_coords = np.dot(coords - self.center, self.rm_coords.T) + self.center\n        return new_coords"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        new_coords = np.dot(coords - self.center, self.rm_coords.T) + self.center\n        return new_coords"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        new_coords = np.dot(coords - self.center, self.rm_coords.T) + self.center\n        return new_coords"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n\n        # Apply the rotation matrix to each coordinate\n        new_coords = np.dot(coords - self.center, self.rm_coords.T) + self.center\n        return new_coords"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        # Apply rotation transformation to each coordinate\n        new_coords = np.dot(coords - self.center, self.rm_coords.T) + self.center\n        return new_coords"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        new_coords = np.column_stack((coords, np.ones(len(coords))))\n        new_coords = np.dot(new_coords, self.rm_coords.T)\n        return new_coords[:, :2]"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n\n        # Apply the rotation matrix to each coordinate\n        new_coords = np.dot(coords - self.center, self.rm_coords.T) + self.center\n        return new_coords"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords  # Return original coordinates if input is empty or rotation angle is a multiple of 360 degrees\n\n        # Apply the rotation matrix to each coordinate\n        rotated_coords = np.dot(coords - self.center, self.rm_coords.T) + self.center\n        return rotated_coords"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        # Apply rotation transformation to each coordinate\n        new_coords = np.dot(coords - self.center, self.rm_coords.T) + self.center\n        return new_coords"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        new_coords = np.column_stack((coords, np.ones(coords.shape[0])))\n        new_coords = np.dot(new_coords, self.rm_coords.T)\n        return new_coords[:, :2]"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n\n        # Apply the rotation matrix to each coordinate\n        rotated_coords = np.dot(coords - self.center, self.rm_coords.T) + self.center\n        return rotated_coords"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n\n        # Apply the rotation matrix to each coordinate\n        rotated_coords = np.dot(coords - self.center, self.rm_coords.T) + self.center\n        return rotated_coords"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        # Apply the rotation matrix to the coordinates\n        new_coords = np.dot(coords - self.center, self.rm_coords.T) + self.center\n        return new_coords"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [x[\"bbox\"] for x in annos]\n    boxes = BoxMode.convert(boxes, BoxMode.XYWH_ABS, BoxMode.XYXY_ABS)\n\n    if mask_format == \"polygon\":\n        masks = [x[\"segmentation\"] for x in annos]\n        masks = [\n            polygons_to_bitmask([np.asarray(p).reshape(-1, 2) for p in x], *image_size)\n            for x in masks\n        ]\n        masks = BitMasks(masks)\n    elif mask_format == \"bitmask\":\n        masks = [mask_util.decode(x[\"segmentation\"]) for x in annos]\n        masks = torch.as_tensor(masks)\n\n    classes = [x[\"category_id\"] for x in annos]\n    classes = torch.tensor(classes)\n\n    keypoints = None\n    if \"keypoints\" in annos[0]:\n        keypoints = [x[\"keypoints\"] for x in annos]\n        keypoints = Keypoints(keypoints)\n\n    return Instances(\n        image_size,\n        gt_boxes=Boxes(boxes),\n        gt_classes=classes,\n        gt_masks=masks,\n        gt_keypoints=keypoints,\n    )"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    # Create empty lists to store annotations\n    boxes = []\n    classes = []\n    masks = []\n    keypoints = []\n\n    # Loop through each annotation\n    for anno in annos:\n        # Extract bounding box coordinates and class label\n        bbox = anno[\"bbox\"]\n        x0, y0, x1, y1 = bbox\n        boxes.append([x0, y0, x1, y1])\n        classes.append(anno[\"category_id\"])\n\n        # Process segmentation masks based on the specified format\n        if mask_format == \"polygon\":\n            # Convert polygon segmentation to bitmask\n            if \"segmentation\" in anno:\n                poly = anno[\"segmentation\"]\n                rles = mask_util.frPyObjects(poly, image_size[0], image_size[1])\n                mask = mask_util.merge(rles)\n                masks.append(mask)\n            else:\n                masks.append(None)\n        elif mask_format == \"bitmask\":\n            # Convert bitmask segmentation to polygon\n            if \"segmentation\" in anno:\n                bitmask = anno[\"segmentation\"]\n                mask = BitMasks(bitmask, image_size[0], image_size[1])\n                masks.append(mask)\n            else:\n                masks.append(None)\n\n        # Process keypoints\n        if \"keypoints\" in anno:\n            keypoints.append(anno[\"keypoints\"])\n        else:\n            keypoints.append(None)\n\n    # Create an Instances object to store the annotations\n    instances = Instances(image_size)\n    instances.gt_boxes = Boxes(boxes)\n    instances.gt_classes = torch.tensor(classes)\n    instances.gt_masks = masks\n    instances.gt_keypoints = keypoints\n\n    return instances"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    # Convert annotations to instances\n    instances = Instances(image_size)\n    if not annos:\n        return instances\n\n    # Process bounding boxes and classes\n    boxes = [x[\"bbox\"] for x in annos]\n    boxes = BoxMode.convert(boxes, BoxMode.XYWH_ABS, BoxMode.XYXY_ABS)\n    boxes = torch.as_tensor(boxes).reshape(-1, 4)\n    instances.gt_boxes = Boxes(boxes)\n\n    classes = [x[\"category_id\"] for x in annos]\n    instances.gt_classes = torch.tensor(classes)\n\n    # Process segmentation masks\n    if \"segmentation\" in annos[0] and mask_format == \"polygon\":\n        masks = [x[\"segmentation\"] for x in annos]\n        masks = [polygons_to_bitmask(x, *image_size) for x in masks]\n        masks = torch.as_tensor(masks)\n        instances.gt_masks = BitMasks(masks)\n\n    elif \"segmentation\" in annos[0] and mask_format == \"bitmask\":\n        masks = [x[\"segmentation\"] for x in annos]\n        masks = [mask_util.decode(x) for x in masks]\n        masks = torch.as_tensor(masks)\n        instances.gt_masks = BitMasks(masks)\n\n    # Process keypoints\n    if \"keypoints\" in annos[0]:\n        keypoints = [x[\"keypoints\"] for x in annos]\n        keypoints = [x for x in keypoints if len(x) > 0]  # remove empty keypoints\n        if len(keypoints) > 0:\n            keypoints = torch.as_tensor(keypoints)\n            num_keypoints = keypoints.shape[1] // 3\n            keypoints = keypoints.view(len(annos), num_keypoints, 3)\n            instances.gt_keypoints = Keypoints(keypoints)\n\n    return instances"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    # Create empty lists to store the processed annotations\n    boxes = []\n    classes = []\n    masks = []\n    keypoints = []\n\n    # Iterate over each annotation in the input list\n    for anno in annos:\n        # Extract bounding box coordinates and class label\n        bbox = anno[\"bbox\"]\n        bbox = [bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]]  # Convert to (x1, y1, x2, y2) format\n        boxes.append(bbox)\n        classes.append(anno[\"category_id\"])\n\n        # Process segmentation masks based on the specified format\n        if mask_format == \"polygon\":\n            # Convert polygon format to bitmask\n            if \"segmentation\" in anno:\n                mask = polygons_to_bitmask(anno[\"segmentation\"], image_size[0], image_size[1])\n                masks.append(mask)\n            else:\n                masks.append(None)  # Append None for instances without segmentation masks\n        elif mask_format == \"bitmask\":\n            # Convert bitmask format to bitmask\n            if \"segmentation\" in anno:\n                mask = mask_util.decode(anno[\"segmentation\"])\n                mask = mask_util.encode(np.asfortranarray(mask))\n                masks.append(mask)\n            else:\n                masks.append(None)  # Append None for instances without segmentation masks\n\n        # Process keypoints\n        if \"keypoints\" in anno:\n            keypoints.append(anno[\"keypoints\"])\n        else:\n            keypoints.append(None)  # Append None for instances without keypoints\n\n    # Create an Instances object and populate it with the processed annotations\n    instances = Instances(image_size)\n    instances.gt_boxes = Boxes(boxes)\n    instances.gt_classes = torch.tensor(classes)\n    if len(masks) > 0:\n        instances.gt_masks = PolygonMasks(masks) if mask_format == \"polygon\" else BitMasks(masks)\n    if len(keypoints) > 0:\n        instances.gt_keypoints = Keypoints(keypoints)\n\n    return instances"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [x[\"bbox\"] for x in annos]\n    boxes = BoxMode.convert(boxes, BoxMode.XYWH_ABS, BoxMode.XYXY_ABS)\n    boxes = np.asarray(boxes, dtype=\"float32\")\n\n    # remove empty boxes\n    valid = (boxes[:, 2] > 0) & (boxes[:, 3] > 0)\n    boxes = boxes[valid]\n\n    classes = [x[\"category_id\"] for x in annos]\n    classes = np.asarray(classes, dtype=\"int64\")\n\n    gt_classes = torch.as_tensor(classes, dtype=torch.int64)\n    gt_boxes = torch.as_tensor(boxes)\n\n    if \"segmentation\" in annos[0] and mask_format == \"polygon\":\n        masks = [x[\"segmentation\"] for x in annos]\n        masks = [np.asarray(x, dtype=np.float32) for x in masks]\n        masks = polygons_to_bitmask(masks, image_size[0], image_size[1])\n        masks = torch.as_tensor(masks)\n    elif \"segmentation\" in annos[0] and mask_format == \"bitmask\":\n        masks = [x[\"segmentation\"] for x in annos]\n        masks = [mask_util.decode(x) for x in masks]\n        masks = torch.as_tensor(masks)\n    else:\n        masks = None\n\n    if \"keypoints\" in annos[0]:\n        keypoints = [x[\"keypoints\"] for x in annos]\n        keypoints = torch.as_tensor(keypoints)\n    else:\n        keypoints = None\n\n    instances = Instances(image_size)\n    instances.gt_boxes = gt_boxes\n    instances.gt_classes = gt_classes\n    instances.gt_masks = masks\n    instances.gt_keypoints = keypoints\n\n    return instances"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [x[\"bbox\"] for x in annos]\n    boxes = [BoxMode.convert(x, x[\"bbox_mode\"], BoxMode.XYXY_ABS) for x in boxes]\n    boxes = np.asarray(boxes, dtype=\"float64\")\n\n    if len(boxes):\n        boxes = boxes.clip(min=0)\n        # remove invalid boxes (with non-positive area)\n        valid_mask = (boxes[:, 2] > boxes[:, 0]) & (boxes[:, 3] > boxes[:, 1])\n        boxes = boxes[valid_mask]\n\n    if mask_format == \"polygon\":\n        # This will apply a polygon-to-bitmask transform, which is lossy\n        # and the loss will be consistent across images. Therefore, we consider\n        # the polygon as the ground truth during training, not the lossy bitmask.\n        # This is not applicable when mask_format is \"bitmask\".\n        segm = [x[\"segmentation\"] for x in annos]\n        masks = [np.asarray(x, dtype=\"float64\") for x in segm]\n        masks = [x.reshape(-1, 2) for x in masks]\n        masks = [PolygonMasks([x], *image_size) for x in masks]\n    elif mask_format == \"bitmask\":\n        # This process is lossless because it is based on the exact\n        # rasterization of the polygons. Therefore, it is applicable\n        # when mask_format is \"bitmask\".\n        segm = [x[\"segmentation\"] for x in annos]\n        masks = [mask_util.decode(x) for x in segm]\n        masks = [torch.as_tensor(x, dtype=torch.uint8) for x in masks]\n        masks = [BitMasks(x) for x in masks]\n    else:\n        raise ValueError(\"Unknown value for mask_format: \" + mask_format)\n\n    keypoints = None\n    if \"keypoints\" in annos[0]:\n        keypoints = [x[\"keypoints\"] for x in annos]\n        keypoints = [x.reshape(-1, 3) for x in keypoints]\n        keypoints = [Keypoints(x, *image_size) for x in keypoints]\n\n    classes = [x[\"category_id\"] for x in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n\n    instances = Instances(image_size)\n    instances.gt_boxes = Boxes(boxes)\n    instances.gt_classes = classes\n    instances.gt_masks = masks\n    if keypoints:\n        instances.gt_keypoints = keypoints\n\n    return instances"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    # Create empty lists to store the annotations\n    boxes = []\n    classes = []\n    masks = []\n    keypoints = []\n\n    # Iterate over each annotation\n    for anno in annos:\n        # Extract bounding box coordinates\n        bbox = anno[\"bbox\"]\n        x0, y0, x1, y1 = bbox\n        # Convert to (x, y, width, height) format\n        bbox = [x0, y0, x1, y1]\n        boxes.append(bbox)\n\n        # Extract class label\n        classes.append(anno[\"category_id\"])\n\n        # Extract segmentation mask\n        if \"segmentation\" in anno:\n            if mask_format == \"polygon\":\n                # Convert polygon to bitmask\n                mask = polygons_to_bitmask(anno[\"segmentation\"], image_size[0], image_size[1])\n                masks.append(mask)\n            elif mask_format == \"bitmask\":\n                # Directly append the bitmask\n                masks.append(anno[\"segmentation\"])\n\n        # Extract keypoints\n        if \"keypoints\" in anno:\n            keypoints.append(anno[\"keypoints\"])\n\n    # Create Instances object\n    instances = Instances(image_size)\n    instances.gt_boxes = Boxes(boxes)\n    instances.gt_classes = torch.tensor(classes)\n    if masks:\n        instances.gt_masks = PolygonMasks(masks)\n    if keypoints:\n        instances.gt_keypoints = Keypoints(keypoints)\n\n    return instances"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    # Create empty lists to store the annotations\n    boxes = []\n    classes = []\n    masks = []\n    keypoints = []\n\n    # Iterate through each annotation in the input list\n    for anno in annos:\n        # Extract the bounding box coordinates and class label\n        bbox = anno[\"bbox\"]\n        box = [bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]]  # Convert to (x1, y1, x2, y2) format\n        boxes.append(box)\n        classes.append(anno[\"category_id\"])\n\n        # Process segmentation masks based on the specified mask format\n        if mask_format == \"polygon\":\n            # Convert polygon format masks to bitmask format\n            if \"segmentation\" in anno:\n                mask = polygons_to_bitmask(anno[\"segmentation\"], image_size[0], image_size[1])\n                masks.append(mask)\n        elif mask_format == \"bitmask\":\n            # Directly append bitmask format masks\n            if \"segmentation\" in anno:\n                masks.append(anno[\"segmentation\"])\n        \n        # Process keypoints\n        if \"keypoints\" in anno:\n            keypoints.append(anno[\"keypoints\"])\n\n    # Convert the lists to appropriate data types\n    boxes = Boxes(torch.tensor(boxes, dtype=torch.float32))\n    classes = torch.tensor(classes)\n    masks = BitMasks(torch.tensor(masks))\n    keypoints = Keypoints(torch.tensor(keypoints, dtype=torch.float32))\n\n    # Create an Instances object and populate it with the annotations\n    instances = Instances(image_size)\n    instances.gt_boxes = boxes\n    instances.gt_classes = classes\n    instances.gt_masks = masks\n    instances.gt_keypoints = keypoints\n\n    return instances"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    # Create empty lists to store the annotations\n    boxes = []\n    classes = []\n    masks = []\n    keypoints = []\n\n    # Iterate through each annotation in the input list\n    for anno in annos:\n        # Extract bounding box coordinates and class label\n        bbox = anno[\"bbox\"]\n        box = [bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]]  # Convert to (x1, y1, x2, y2) format\n        boxes.append(box)\n        classes.append(anno[\"category_id\"])\n\n        # Process segmentation masks based on the specified format\n        if mask_format == \"polygon\":\n            polygons = anno[\"segmentation\"]\n            masks.append(polygons_to_bitmask(polygons, image_size[0], image_size[1]))  # Convert polygons to bitmasks\n        elif mask_format == \"bitmask\":\n            masks.append(mask_util.decode(anno[\"segmentation\"]))\n\n        # Extract and process keypoints if available\n        if \"keypoints\" in anno:\n            keypoints.append(anno[\"keypoints\"])\n\n    # Create an Instances object and populate it with the processed annotations\n    instances = Instances(image_size)\n    instances.gt_boxes = Boxes(torch.tensor(boxes))\n    instances.gt_classes = torch.tensor(classes)\n    instances.gt_masks = PolygonMasks(masks)\n    if keypoints:\n        instances.gt_keypoints = Keypoints(keypoints)\n\n    return instances"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    # Create empty lists to store the annotations\n    boxes = []\n    classes = []\n    masks = []\n    keypoints = []\n\n    # Iterate over each annotation in the input list\n    for anno in annos:\n        # Extract bounding box coordinates and append to the boxes list\n        bbox = anno[\"bbox\"]\n        bbox = [bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]]  # Convert from xywh to xyxy\n        boxes.append(bbox)\n\n        # Extract class label and append to the classes list\n        classes.append(anno[\"category_id\"])\n\n        # Process segmentation masks based on the specified mask format\n        if mask_format == \"polygon\":\n            # Convert polygon segmentation to bitmask and append to the masks list\n            if \"segmentation\" in anno:\n                mask = polygons_to_bitmask(anno[\"segmentation\"], *image_size)\n                masks.append(mask)\n        elif mask_format == \"bitmask\":\n            # Directly append the bitmask segmentation to the masks list\n            if \"segmentation\" in anno:\n                masks.append(anno[\"segmentation\"])\n\n        # Process keypoints and append to the keypoints list\n        if \"keypoints\" in anno:\n            keypoints.append(anno[\"keypoints\"])\n\n    # Create an Instances object and populate it with the processed annotations\n    instances = Instances(image_size)\n    instances.gt_boxes = Boxes(boxes)\n    instances.gt_classes = torch.tensor(classes)\n    if len(masks) > 0:\n        instances.gt_masks = PolygonMasks(masks)\n    if len(keypoints) > 0:\n        instances.gt_keypoints = Keypoints(keypoints)\n\n    return instances"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    # Convert annotations to instances\n    instances = Instances(image_size)\n    if not annos:\n        return instances\n\n    # Process bounding boxes and classes\n    boxes = [obj[\"bbox\"] for obj in annos]\n    boxes = BoxMode.convert(boxes, BoxMode.XYWH_ABS, BoxMode.XYXY_ABS)\n    boxes = torch.as_tensor(boxes).reshape(-1, 4)\n    instances.gt_boxes = Boxes(boxes)\n\n    if \"category_id\" in annos[0]:\n        category_ids = [obj[\"category_id\"] for obj in annos]\n        instances.gt_classes = torch.tensor(category_ids)\n\n    # Process segmentation masks\n    if \"segmentation\" in annos[0]:\n        if mask_format == \"polygon\":\n            masks = [obj[\"segmentation\"] for obj in annos]\n            masks = [polygon_to_bitmask(p, image_size[0], image_size[1]) for p in masks]\n            instances.gt_masks = BitMasks(masks)\n        elif mask_format == \"bitmask\":\n            masks = [obj[\"segmentation\"] for obj in annos]\n            masks = [mask_util.decode(p) for p in masks]\n            masks = torch.as_tensor(masks, dtype=torch.uint8)\n            instances.gt_masks = masks\n\n    # Process keypoints\n    if \"keypoints\" in annos[0]:\n        keypoints = [obj[\"keypoints\"] for obj in annos]\n        keypoints = torch.as_tensor(keypoints)\n        num_keypoints = keypoints.shape[1] // 3\n        keypoints = keypoints.view(-1, num_keypoints, 3)\n        instances.gt_keypoints = Keypoints(keypoints)\n\n    return instances"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    # Create empty lists to store the annotations\n    gt_boxes = []\n    gt_classes = []\n    gt_masks = []\n    gt_keypoints = []\n\n    # Iterate over each annotation in the input list\n    for anno in annos:\n        # Extract bounding box, class, mask, and keypoint information from the annotation dictionary\n        bbox = anno[\"bbox\"]\n        class_id = anno[\"category_id\"]\n        mask = anno.get(\"segmentation\", None)\n        keypoints = anno.get(\"keypoints\", None)\n\n        # Convert the bounding box to BoxMode.XYXY_ABS format\n        bbox = BoxMode.convert(bbox, BoxMode.XYWH_ABS, BoxMode.XYXY_ABS)\n\n        # Append the extracted information to the corresponding lists\n        gt_boxes.append(bbox)\n        gt_classes.append(class_id)\n\n        # Process segmentation masks based on the specified mask_format\n        if mask is not None:\n            if mask_format == \"polygon\":\n                # Convert polygon masks to bitmask\n                bitmask = polygons_to_bitmask(mask, *image_size)\n                gt_masks.append(mask_util.encode(np.asarray(bitmask, order=\"F\")))\n            elif mask_format == \"bitmask\":\n                # Directly encode bitmask if the format is already in bitmask\n                gt_masks.append(mask)\n            else:\n                raise ValueError(\"Unsupported mask format: {}\".format(mask_format))\n\n        # Append keypoints to the list\n        if keypoints is not None:\n            gt_keypoints.append(keypoints)\n\n    # Create an Instances object and populate it with the processed annotations\n    instances = Instances(image_size)\n    instances.gt_boxes = Boxes(torch.tensor(gt_boxes))\n    instances.gt_classes = torch.tensor(gt_classes)\n    if gt_masks:\n        instances.gt_masks = PolygonMasks(gt_masks)\n    if gt_keypoints:\n        instances.gt_keypoints = Keypoints(gt_keypoints)\n\n    return instances"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    # Create empty lists to store the annotations\n    boxes = []\n    classes = []\n    masks = []\n    keypoints = []\n\n    # Loop through each annotation in the input list\n    for anno in annos:\n        # Extract bounding box coordinates and convert to XYXY_ABS format\n        bbox = anno[\"bbox\"]\n        bbox = [bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]]\n        boxes.append(bbox)\n\n        # Extract class label\n        classes.append(anno[\"category_id\"])\n\n        # Process segmentation masks based on the specified format\n        if mask_format == \"polygon\":\n            # Convert segmentation polygons to bitmask\n            mask = polygons_to_bitmask(anno[\"segmentation\"], image_size[0], image_size[1])\n            masks.append(mask)\n        elif mask_format == \"bitmask\":\n            # Use the provided bitmask directly\n            masks.append(anno[\"segmentation\"])\n\n        # Extract keypoints if available\n        if \"keypoints\" in anno:\n            keypoints.append(anno[\"keypoints\"])\n\n    # Create an Instances object and populate it with the processed annotations\n    instances = Instances(image_size)\n    instances.gt_boxes = Boxes(torch.tensor(boxes))\n    instances.gt_classes = torch.tensor(classes)\n    instances.gt_masks = PolygonMasks(masks)\n    if len(keypoints) > 0:\n        instances.gt_keypoints = Keypoints(keypoints)\n\n    return instances"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    # Convert annotations to instances\n    instances = Instances(image_size)\n    if len(annos) == 0:\n        return instances\n\n    # Process bounding boxes and classes\n    boxes = [obj[\"bbox\"] for obj in annos]\n    boxes = BoxMode.convert(boxes, BoxMode.XYWH_ABS, BoxMode.XYXY_ABS)\n    boxes = np.clip(boxes, 0, image_size[0])\n    instances.gt_boxes = Boxes(boxes)\n    instances.gt_classes = torch.tensor([obj[\"category_id\"] for obj in annos])\n\n    # Process segmentation masks\n    if \"segmentation\" in annos[0] and mask_format == \"polygon\":\n        masks = [obj[\"segmentation\"] for obj in annos]\n        masks = [np.asarray(mask, dtype=np.float32).reshape(-1, 2) for mask in masks]\n        masks = [PolygonMasks([mask]) for mask in masks]\n        instances.gt_masks = masks\n    elif \"segmentation\" in annos[0] and mask_format == \"bitmask\":\n        masks = [obj[\"segmentation\"] for obj in annos]\n        masks = [mask_util.decode(mask) for mask in masks]\n        masks = [torch.as_tensor(mask, dtype=torch.uint8) for mask in masks]\n        instances.gt_masks = BitMasks(masks)\n\n    # Process keypoints\n    if \"keypoints\" in annos[0]:\n        keypoints = [obj[\"keypoints\"] for obj in annos]\n        keypoints = [np.asarray(keypoint, dtype=np.float32).reshape(-1, 3) for keypoint in keypoints]\n        instances.gt_keypoints = Keypoints(keypoints)\n\n    return instances"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    # Convert annotations to instances\n    instances = Instances(image_size)\n    if not annos:\n        return instances\n\n    # Process bounding boxes and classes\n    boxes = [x[\"bbox\"] for x in annos]\n    boxes = BoxMode.convert(boxes, BoxMode.XYWH_ABS, BoxMode.XYXY_ABS)\n    boxes = torch.tensor(boxes, dtype=torch.float32)\n    instances.gt_boxes = boxes\n\n    if \"category_id\" in annos[0]:\n        category_ids = [x[\"category_id\"] for x in annos]\n        instances.gt_classes = torch.tensor(category_ids, dtype=torch.int64)\n\n    # Process segmentation masks\n    if \"segmentation\" in annos[0]:\n        if mask_format == \"polygon\":\n            masks = [x[\"segmentation\"] for x in annos]\n            masks = [polygons_to_bitmask(p, *image_size) for p in masks]\n            masks = torch.as_tensor(masks, dtype=torch.uint8)\n        elif mask_format == \"bitmask\":\n            masks = [mask_util.decode(x[\"segmentation\"]) for x in annos]\n            masks = torch.as_tensor(masks, dtype=torch.uint8)\n        instances.gt_masks = BitMasks(masks)\n\n    # Process keypoints\n    if \"keypoints\" in annos[0]:\n        keypoints = [x[\"keypoints\"] for x in annos]\n        keypoints = torch.as_tensor(keypoints, dtype=torch.float32)\n        num_keypoints = keypoints.shape[1] // 3\n        keypoints = keypoints.view(len(annos), num_keypoints, 3)\n        instances.gt_keypoints = Keypoints(keypoints, instances.image_size)\n\n    return instances"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    # Convert annotations to instances\n    instances = Instances(image_size)\n    if len(annos) == 0:\n        return instances\n\n    gt_boxes = [obj[\"bbox\"] for obj in annos]\n    gt_boxes = BoxMode.convert(gt_boxes, BoxMode.XYWH_ABS, BoxMode.XYXY_ABS)\n    gt_boxes = torch.as_tensor(gt_boxes).reshape(-1, 4)\n    instances.gt_boxes = Boxes(gt_boxes)\n\n    if \"bbox_mode\" in annos[0]:\n        gt_box_mode = [obj[\"bbox_mode\"] for obj in annos]\n        instances.gt_box_mode = gt_box_mode\n\n    if \"category_id\" in annos[0]:\n        category_ids = [obj[\"category_id\"] for obj in annos]\n        instances.gt_classes = torch.tensor(category_ids)\n\n    if \"segmentation\" in annos[0]:\n        if mask_format == \"polygon\":\n            polygons = [obj[\"segmentation\"] for obj in annos]\n            instances.gt_masks = PolygonMasks(polygons, *image_size)\n        elif mask_format == \"bitmask\":\n            rles = [mask_util.frPyObjects(obj[\"segmentation\"], *image_size) for obj in annos]\n            rle = mask_util.merge(rles)\n            bitmask = mask_util.decode(rle)\n            instances.gt_masks = BitMasks(bitmask)\n\n    if \"keypoints\" in annos[0]:\n        keypoints = [obj[\"keypoints\"] for obj in annos]\n        instances.gt_keypoints = Keypoints(keypoints, *image_size)\n\n    return instances"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    # Create empty lists to store the annotations\n    boxes = []\n    classes = []\n    masks = []\n    keypoints = []\n\n    # Iterate through each annotation\n    for anno in annos:\n        # Extract bounding box coordinates\n        x0, y0, x1, y1 = anno[\"bbox\"]\n        boxes.append([x0, y0, x1, y1])\n\n        # Extract class label\n        classes.append(anno[\"category_id\"])\n\n        # Process segmentation masks based on the specified format\n        if mask_format == \"polygon\":\n            # Convert polygon segmentation to bitmask\n            polygons = anno[\"segmentation\"]\n            mask = polygons_to_bitmask(polygons, image_size[0], image_size[1])\n            masks.append(mask)\n        elif mask_format == \"bitmask\":\n            # Directly append the bitmask segmentation\n            masks.append(anno[\"segmentation\"])\n\n        # Extract keypoints if available\n        if \"keypoints\" in anno:\n            keypoints.append(anno[\"keypoints\"])\n\n    # Create Instances object and populate with the processed annotations\n    instances = Instances(image_size)\n    instances.gt_boxes = Boxes(torch.tensor(boxes))\n    instances.gt_classes = torch.tensor(classes)\n    instances.gt_masks = PolygonMasks(masks)\n    instances.gt_keypoints = Keypoints(keypoints)\n\n    return instances"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    instances = Instances(image_size)\n    if len(annos) == 0:\n        return instances\n\n    gt_boxes = [obj[\"bbox\"] for obj in annos]\n    gt_boxes = BoxMode.convert(gt_boxes, BoxMode.XYWH_ABS, BoxMode.XYXY_ABS)\n    instances.gt_boxes = Boxes(torch.tensor(gt_boxes))\n\n    gt_classes = [obj[\"category_id\"] for obj in annos]\n    instances.gt_classes = torch.tensor(gt_classes)\n\n    if \"segmentation\" in annos[0] and mask_format == \"polygon\":\n        polygons = [obj[\"segmentation\"] for obj in annos]\n        masks = [polygons_to_bitmask(p, image_size[0], image_size[1]) for p in polygons]\n        instances.gt_masks = BitMasks(torch.tensor(masks))\n    elif \"segmentation\" in annos[0] and mask_format == \"bitmask\":\n        masks = [mask_util.decode(obj[\"segmentation\"]) for obj in annos]\n        instances.gt_masks = BitMasks(torch.tensor(masks))\n\n    if \"keypoints\" in annos[0]:\n        keypoints = [obj[\"keypoints\"] for obj in annos]\n        instances.gt_keypoints = Keypoints(torch.tensor(keypoints))\n\n    return instances"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    # Convert annotations to instances\n    instances = Instances(image_size)\n    if not annos:\n        return instances\n\n    # Process each annotation\n    fields = instances.get_fields()\n    if \"bbox\" in annos[0]:\n        boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n        instances.set(\"gt_boxes\", boxes)\n\n    if \"category_id\" in annos[0]:\n        category_ids = [obj[\"category_id\"] for obj in annos]\n        instances.set(\"gt_classes\", torch.tensor(category_ids))\n\n    if \"segmentation\" in annos[0]:\n        if mask_format == \"polygon\":\n            polygons = [obj[\"segmentation\"] for obj in annos]\n            masks = [polygon_to_bitmask(p, image_size[0], image_size[1]) for p in polygons]\n            masks = torch.as_tensor(masks)\n            instances.set(\"gt_masks\", masks)\n        elif mask_format == \"bitmask\":\n            masks = [mask_util.decode(obj[\"segmentation\"]) for obj in annos]\n            masks = torch.as_tensor(masks)\n            instances.set(\"gt_masks\", masks)\n\n    if \"keypoints\" in annos[0]:\n        keypoints = [obj[\"keypoints\"] for obj in annos]\n        keypoints = torch.as_tensor(keypoints, dtype=torch.float32)\n        instances.set(\"gt_keypoints\", keypoints)\n\n    return instances"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    # Convert annotations to instances\n    instances = Instances(image_size)\n    if len(annos) == 0:\n        return instances\n\n    # Process bounding boxes and classes\n    boxes = [obj[\"bbox\"] for obj in annos]\n    boxes = [BoxMode.convert(obj, BoxMode.XYWH_ABS, BoxMode.XYXY_ABS) for obj in boxes]\n    boxes = np.asarray(boxes, dtype=\"float32\")\n    instances.gt_boxes = Boxes(boxes)\n    instances.gt_classes = torch.tensor([obj[\"category_id\"] for obj in annos], dtype=torch.int64)\n\n    # Process segmentation masks\n    if \"segmentation\" in annos[0] and mask_format == \"polygon\":\n        masks = [obj[\"segmentation\"] for obj in annos]\n        masks = [polygon_to_bitmask(p, *image_size) for p in masks]\n        instances.gt_masks = BitMasks(masks)\n    elif \"segmentation\" in annos[0] and mask_format == \"bitmask\":\n        masks = [obj[\"segmentation\"] for obj in annos]\n        masks = [mask_util.decode(p) for p in masks]\n        instances.gt_masks = BitMasks(masks)\n\n    # Process keypoints\n    if \"keypoints\" in annos[0]:\n        keypoints = [obj[\"keypoints\"] for obj in annos]\n        instances.gt_keypoints = Keypoints(keypoints, *image_size)\n\n    return instances"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    analysis = FlopCountAnalysis(model, inputs)\n    return analysis.by_operator()"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    analysis = FlopCountAnalysis(model, inputs)\n    return analysis.by_operator()"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # Create a FlopCountAnalysis object for the model and inputs\n    flop_analysis = FlopCountAnalysis(model, inputs)\n    \n    # Get the flop counts for each operator\n    flop_counts = flop_analysis.get_per_operator_flop_count()\n    \n    return flop_counts"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    wrapper = TracingAdapter(model, inputs, allow_non_tensor=True)\n    flop_analysis = FlopCountAnalysis(wrapper, wrapper.flattened_inputs)\n    flop_analysis.set_op_handle(**{k: None for k in _IGNORED_OPS})\n    return flop_analysis.by_operator()"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    analysis = FlopCountAnalysis(model, inputs)\n    return analysis.by_operator()"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    wrapper = TracingAdapter(model, inputs, allow_non_tensor=True)\n    flop_analysis = FlopCountAnalysis(wrapper, wrapper.flattened_inputs)\n    flop_analysis.set_op_handle(**{k: None for k in _IGNORED_OPS})\n    return flop_analysis.by_operator()"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "\n    analysis = FlopCountAnalysis(model, inputs)\n    return analysis.by_operator()"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    wrapper = TracingAdapter(model, inputs, allow_non_tensor=True)\n    flop_analysis = FlopCountAnalysis(wrapper, wrapper.flattened_inputs)\n    flop_analysis.set_op_handle(**{k: None for k in _IGNORED_OPS})\n    return flop_analysis.by_operator()"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "\n    # Wrap the model and inputs using TracingAdapter\n    wrapper = TracingAdapter(model, inputs, allow_non_tensor=True)\n\n    # Initialize FlopCountAnalysis with the wrapped model and inputs\n    flop_analysis = FlopCountAnalysis(wrapper, wrapper.flattened_inputs)\n\n    # Set the op handle for ignored ops\n    flop_analysis.set_op_handle(**{k: None for k in _IGNORED_OPS})\n\n    # Return the Gflop counts for each operator\n    return flop_analysis.by_operator()"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    wrapper = TracingAdapter(model, inputs, allow_non_tensor=True)\n    flop_analysis = FlopCountAnalysis(wrapper, wrapper.flattened_inputs)\n    flop_analysis.set_op_handle(**{k: None for k in _IGNORED_OPS})\n    return flop_analysis.by_operator()"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    analysis = FlopCountAnalysis(model, inputs)\n    return analysis.by_operator()"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "\n    # Create a FlopCountAnalysis object\n    flop_analysis = FlopCountAnalysis(model, inputs)\n\n    # Get the flop count for each operator\n    flop_counts = flop_analysis.by_operator()\n\n    return flop_counts"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    analysis = FlopCountAnalysis(model, inputs)\n    return analysis.total()"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    analysis = FlopCountAnalysis(model, inputs)\n    return analysis.by_operator()"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    analysis = FlopCountAnalysis(model, inputs)\n    return analysis.by_operator()"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    analysis = FlopCountAnalysis(model, inputs)\n    return analysis.by_operator()"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "\n    # Create an instance of FlopCountAnalysis\n    flop_analysis = FlopCountAnalysis(model, inputs)\n\n    # Get the flop count for each operator\n    flop_counts = flop_analysis.by_operator()\n\n    return flop_counts"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    analysis = FlopCountAnalysis(model, inputs)\n    return analysis.by_operator()"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "\n    # Create a FlopCountAnalysis object with the model and inputs\n    flop_analysis = FlopCountAnalysis(model, inputs)\n\n    # Get the flop count for each operator\n    flop_counts = flop_analysis.get_per_operator_resources()\n\n    return flop_counts"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    analysis = FlopCountAnalysis(model, inputs)\n    return analysis.by_operator()"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.angle % 360 == 0:\n            return img\n        if img.size == 0:\n            return img\n        if interp is None:\n            interp = self.interp\n        center = (self.w / 2, self.h / 2)\n        M = cv2.getRotationMatrix2D(center, -self.angle, 1)\n        if self.expand:\n            rotated_img = cv2.warpAffine(img, M, (self.bound_w, self.bound_h), flags=interp)\n        else:\n            rotated_img = cv2.warpAffine(img, M, (self.w, self.h), flags=interp)\n        return rotated_img"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.angle % 360 == 0:\n            return img\n        if len(img.shape) == 3 and img.shape[2] == 1:\n            img = img[:, :, 0]\n        if interp is None:\n            interp = self.interp\n        if self.expand:\n            # Rotate the image and expand the canvas to fit the whole rotated image\n            M = cv2.getRotationMatrix2D((self.center[0], self.center[1]), -self.angle, 1)\n            img = cv2.warpAffine(img, M, (self.bound_w, self.bound_h), flags=interp)\n        else:\n            # Rotate the image and crop to the original dimensions\n            M = cv2.getRotationMatrix2D((self.center[0], self.center[1]), -self.angle, 1)\n            img = cv2.warpAffine(img, M, (self.w, self.h), flags=interp)\n        if len(img.shape) == 2:\n            img = img[:, :, np.newaxis]\n        return img"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.angle % 360 == 0:\n            return img\n\n        if len(img.shape) > 2 and img.shape[2] == 1:\n            img = img[:, :, 0]\n\n        if interp is None:\n            interp = self.interp\n\n        if self.expand:\n            img = cv2.warpAffine(\n                img,\n                self.rm_image,\n                (self.bound_w, self.bound_h),\n                flags=interp,\n                borderMode=cv2.BORDER_CONSTANT,\n                borderValue=0,\n            )\n        else:\n            img = cv2.warpAffine(\n                img,\n                self.rm_image,\n                (self.w, self.h),\n                flags=interp,\n                borderMode=cv2.BORDER_CONSTANT,\n                borderValue=0,\n            )\n\n        if len(img.shape) == 2:\n            img = np.expand_dims(img, axis=2)\n\n        return img"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.angle % 360 == 0:\n            return img\n        if len(img.shape) == 3 and img.shape[2] == 1:\n            img = img[:, :, 0]\n        if interp is None:\n            interp = self.interp\n        if self.expand:\n            # rotate the image while keeping the whole image\n            image = cv2.warpAffine(\n                img,\n                self.rm_image,\n                (self.bound_w, self.bound_h),\n                flags=interp,\n                borderMode=cv2.BORDER_CONSTANT,\n                borderValue=0,\n            )\n        else:\n            # rotate the image and crop to fit the whole image\n            image = cv2.warpAffine(\n                img,\n                self.rm_image,\n                (self.bound_w, self.bound_h),\n                flags=interp,\n                borderMode=cv2.BORDER_CONSTANT,\n                borderValue=0,\n            )\n            image = image[\n                (self.bound_h - self.h) // 2 : (self.bound_h + self.h) // 2,\n                (self.bound_w - self.w) // 2 : (self.bound_w + self.w) // 2,\n            ]\n        if len(img.shape) == 3 and img.shape[2] == 1:\n            image = np.expand_dims(image, -1)\n        return image"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.angle % 360 == 0:\n            return img\n\n        if len(img.shape) == 3:\n            img = cv2.warpAffine(\n                img, self.rm_image, (self.bound_w, self.bound_h), flags=self.interp\n            )\n        else:\n            img = cv2.warpAffine(\n                img,\n                self.rm_image,\n                (self.bound_w, self.bound_h),\n                flags=self.interp,\n                borderMode=cv2.BORDER_CONSTANT,\n                borderValue=0,\n            )\n\n        return img"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.angle % 360 == 0:\n            return img\n        if len(img.shape) > 2 and img.shape[2] == 1:\n            img = img[:, :, 0]\n        img = cv2.warpAffine(img, self.rm_image, (self.bound_w, self.bound_h), flags=self.interp)\n        if len(img.shape) == 2:\n            img = np.expand_dims(img, axis=-1)\n        return img"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.angle % 360 == 0:\n            return img\n        if len(img.shape) > 2 and img.shape[2] == 1:\n            pil_image = Image.fromarray(img[:, :, 0], mode=\"L\")\n        else:\n            pil_image = Image.fromarray(img)\n        pil_image = pil_image.rotate(\n            -self.angle,\n            resample=interp if interp else self.interp,\n            expand=self.expand,\n            center=self.center,\n        )\n        ret = np.asarray(pil_image)\n        if len(img.shape) > 2 and img.shape[2] == 1:\n            ret = np.expand_dims(ret, -1)\n        return ret"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.angle % 360 == 0:\n            return img\n        return cv2.warpAffine(\n            img,\n            self.rm_image,\n            (self.bound_w, self.bound_h),\n            flags=cv2.INTER_LINEAR if interp is None else interp,\n        )"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.angle % 360 == 0:\n            return img\n        if len(img.shape) == 3:\n            img = cv2.warpAffine(\n                img,\n                self.rm_image,\n                (self.bound_w, self.bound_h),\n                flags=self.interp,\n                borderMode=cv2.BORDER_CONSTANT,\n                borderValue=0,\n            )\n        else:\n            img = cv2.warpAffine(\n                img,\n                self.rm_image,\n                (self.bound_w, self.bound_h),\n                flags=self.interp,\n                borderMode=cv2.BORDER_CONSTANT,\n                borderValue=0,\n            )\n        return img"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.angle % 360 == 0:\n            return img\n        if len(img.shape) == 3:\n            img = cv2.warpAffine(\n                img,\n                self.rm_image,\n                (self.bound_w, self.bound_h),\n                flags=self.interp,\n                borderMode=cv2.BORDER_CONSTANT,\n                borderValue=0,\n            )\n        else:\n            img = cv2.warpAffine(\n                img,\n                self.rm_image,\n                (self.bound_w, self.bound_h),\n                flags=self.interp,\n                borderMode=cv2.BORDER_CONSTANT,\n                borderValue=0,\n            )\n        return img"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.angle % 360 == 0:\n            return img\n        if len(img.shape) == 2:\n            img = img[:, :, None]\n        return cv2.warpAffine(\n            img,\n            self.rm_image,\n            (self.bound_w, self.bound_h),\n            flags=cv2.INTER_LINEAR if interp is None else interp,\n        )"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.angle % 360 == 0:\n            return img\n        if len(img.shape) > 2 and img.shape[2] == 1:\n            pil_image = Image.fromarray(img[:, :, 0], mode=\"L\")\n        else:\n            pil_image = Image.fromarray(img)\n        pil_image = pil_image.rotate(\n            -self.angle,\n            resample=interp if interp else self.interp,\n            expand=self.expand,\n            center=self.center,\n        )\n        ret = np.asarray(pil_image)\n        if len(img.shape) > 2 and img.shape[2] == 1:\n            ret = np.expand_dims(ret, -1)\n        return ret"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.angle % 360 == 0:\n            return img\n        if len(img.shape) == 2:\n            img = img[..., None]\n        if interp is None:\n            interp = self.interp\n        if self.expand:\n            # find the new width and height bounds\n            bound_w, bound_h = np.rint(\n                [self.h * abs(np.sin(np.deg2rad(self.angle))) + self.w * abs(np.cos(np.deg2rad(self.angle))),\n                 self.h * abs(np.cos(np.deg2rad(self.angle))) + self.w * abs(np.sin(np.deg2rad(self.angle)))]\n            ).astype(int)\n        else:\n            bound_w, bound_h = self.w, self.h\n        rm_image = self.create_rotation_matrix(offset=-0.5)\n        img = cv2.warpAffine(img, rm_image, (bound_w, bound_h), flags=self.interp)\n        return img"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.angle % 360 == 0:\n            return img\n        if len(img.shape) == 0:\n            return img\n        if interp is None:\n            interp = self.interp\n        if img.dtype == np.uint8:\n            if len(img.shape) > 2 and img.shape[2] == 1:\n                pil_image = Image.fromarray(img[:, :, 0], mode=\"L\")\n            else:\n                pil_image = Image.fromarray(img)\n            pil_image = pil_image.rotate(\n                -self.angle,\n                resample=interp,\n                expand=self.expand,\n                center=self.center,\n            )\n            ret = np.asarray(pil_image)\n            if len(img.shape) > 2 and img.shape[2] == 1:\n                ret = np.expand_dims(ret, -1)\n        else:\n            # PIL only supports uint8\n            if any(x < 0 for x in img.strides):\n                img = np.ascontiguousarray(img)\n            img = torch.from_numpy(img)\n            shape = list(img.shape)\n            shape_4d = shape[:2] + [1] * (4 - len(shape)) + shape[2:]\n            img = img.view(shape_4d).permute(2, 3, 0, 1)  # hw(c) -> nchw\n            angle_rad = np.deg2rad(self.angle)\n            M = cv2.getRotationMatrix2D(self.center, self.angle, 1.0)\n            img = cv2.warpAffine(\n                img.numpy(), M, (self.bound_w, self.bound_h), flags=cv2.INTER_LINEAR\n            )\n            shape[:2] = (self.bound_h, self.bound_w)\n            ret = img.permute(2, 3, 0, 1).view(shape).numpy()  # nchw -> hw(c)\n        return ret"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.angle % 360 == 0:\n            return img\n        if len(img.shape) == 3 and img.shape[2] == 1:\n            img = img[:, :, 0]\n        if interp is None:\n            interp = self.interp\n        if img.dtype == np.uint8:\n            pil_image = Image.fromarray(img, mode=\"L\" if img.ndim == 2 else \"RGB\")\n            pil_image = pil_image.rotate(\n                -self.angle,\n                resample=interp,\n                expand=self.expand,\n                center=self.center,\n            )\n            ret = np.asarray(pil_image)\n            if img.ndim == 2:\n                ret = np.expand_dims(ret, -1)\n        else:\n            if any(x < 0 for x in img.strides):\n                img = np.ascontiguousarray(img)\n            img = torch.from_numpy(img)\n            shape = list(img.shape)\n            shape_4d = shape[:2] + [1] * (4 - len(shape)) + shape[2:]\n            img = img.view(shape_4d).permute(2, 3, 0, 1)  # hw(c) -> nchw\n            angle_rad = -np.deg2rad(self.angle)\n            matrix = torch.tensor(\n                [\n                    [np.cos(angle_rad), -np.sin(angle_rad), 0],\n                    [np.sin(angle_rad), np.cos(angle_rad), 0],\n                ],\n                dtype=img.dtype,\n            )\n            matrix = matrix.to(img.device)\n            img = F.grid_sample(\n                img[None, ...],  # add batch dim\n                F.affine_grid(\n                    matrix[None, :2, :], img.shape, align_corners=False\n                ),\n                mode=\"bilinear\",\n                padding_mode=\"zeros\",\n            )[0]  # remove batch dim\n            shape[:2] = (self.bound_h, self.bound_w)\n            ret = img.permute(2, 3, 0, 1).view(shape).numpy()  # nchw -> hw(c)\n        return ret"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.angle % 360 == 0:\n            return img\n\n        if len(img.shape) > 2 and img.shape[2] == 1:\n            pil_image = Image.fromarray(img[:, :, 0], mode=\"L\")\n        else:\n            pil_image = Image.fromarray(img)\n\n        if interp is None:\n            interp = self.interp\n\n        pil_image = pil_image.rotate(\n            -self.angle,\n            resample=interp,\n            expand=self.expand,\n            center=self.center,\n        )\n\n        ret = np.asarray(pil_image)\n\n        if len(img.shape) > 2 and img.shape[2] == 1:\n            ret = np.expand_dims(ret, -1)\n\n        return ret"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.angle % 360 == 0:\n            return img\n        elif img.size == 0:\n            return img\n        else:\n            return cv2.warpAffine(img, self.rm_image, (self.bound_w, self.bound_h), flags=self.interp)"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.angle % 360 == 0:\n            return img\n        else:\n            if interp is None:\n                interp = self.interp\n            return cv2.warpAffine(\n                img,\n                self.rm_image,\n                (self.bound_w, self.bound_h),\n                flags=interp,\n                borderMode=cv2.BORDER_CONSTANT,\n                borderValue=0,\n            )"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.angle % 360 == 0:  # No change\n            return img\n        if img.size == 0:  # Empty image\n            return img\n\n        if interp is None:\n            interp = self.interp\n\n        if len(img.shape) > 2 and img.shape[2] == 1:\n            img = img[:, :, 0]\n\n        # Rotate the image using OpenCV's warpAffine function\n        rotated_img = cv2.warpAffine(\n            img,\n            self.rm_image,\n            (self.bound_w, self.bound_h),\n            flags=cv2.INTER_LINEAR,\n            borderMode=cv2.BORDER_CONSTANT,\n            borderValue=0,\n        )\n\n        if len(img.shape) > 2 and img.shape[2] == 1:\n            rotated_img = np.expand_dims(rotated_img, -1)\n\n        return rotated_img"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.angle % 360 == 0:\n            return img\n        else:\n            if interp is None:\n                interp = self.interp\n            return cv2.warpAffine(img, self.rm_image, (self.bound_w, self.bound_h), flags=interp)"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.thing_classes)\n        masks = predictions.pred_masks if predictions.has(\"pred_masks\") else None\n        masks_rle = predictions.pred_masks_rle if predictions.has(\"pred_masks_rle\") else None\n\n        if self._instance_mode == ColorMode.SEGMENTATION:\n            color_list = self.metadata.thing_colors\n        else:\n            color_list = [random_color(rgb=True) for _ in range(len(labels))]\n\n        for i in range(len(labels)):\n            color = color_list[i]\n            area = (masks[i] > 0).sum() if masks is not None else None\n            mask = GenericMask(masks[i], self.output.height, self.output.width) if masks is not None else None\n            mask_rle = masks_rle[i] if masks_rle is not None else None\n            keypoints = Keypoints(keypoints[i]) if keypoints is not None else None\n            self.draw_instance(\n                boxes[i],\n                labels[i],\n                color,\n                area,\n                mask,\n                mask_rle,\n                keypoints,\n            )\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n        masks = predictions.pred_masks if predictions.has(\"pred_masks\") else None\n\n        if self._instance_mode == ColorMode.SEGMENTATION:\n            colors = None\n            if predictions.has(\"pred_classes\"):\n                colors = [\n                    self.metadata.thing_colors[c] for c in predictions.pred_classes.to(\"cpu\")\n                ]\n            if self.metadata.stuff_classes:\n                stuff_colors = [\n                    self.metadata.stuff_colors[c] for c in predictions.pred_classes.to(\"cpu\")\n                ]\n            else:\n                stuff_colors = None\n        else:\n            colors = None\n            stuff_colors = None\n\n        labels = _create_text_labels(\n            classes, scores, self.metadata.thing_classes, is_crowd=None\n        )\n\n        panoptic_seg = predictions.panoptic_seg if predictions.has(\"panoptic_seg\") else None\n        if panoptic_seg is not None:\n            panoptic_info = predictions.panoptic_seg_info\n            if panoptic_info is None:\n                panoptic_info = [\n                    {\"id\": id, \"isthing\": id in self.metadata.thing_dataset_id_to_contiguous_id}\n                    for id in np.unique(panoptic_seg)\n                ]\n            panoptic = _PanopticPrediction(panoptic_seg, panoptic_info, self.metadata)\n            panoptic_seg = panoptic_seg.to(self.cpu_device)\n            segments_info = panoptic_info\n        else:\n            panoptic = None\n            segments_info = None\n\n        if masks is not None:\n            masks = BitMasks(masks, masks.shape[-1], masks.shape[-2])\n\n        self.overlay_instances(\n            labels=labels,\n            boxes=boxes,\n            masks=masks,\n            keypoints=keypoints,\n            assigned_colors=colors,\n            stuff_colors=stuff_colors,\n            alpha=0.5,\n            area_threshold=_SMALL_OBJECT_AREA_THRESH,\n            keypoint_threshold=self.keypoint_threshold,\n            panoptic=panoptic,\n            segments_info=segments_info,\n        )\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n        masks = predictions.pred_masks if predictions.has(\"pred_masks\") else None\n        masks_rle = predictions.pred_masks_rle if predictions.has(\"pred_masks_rle\") else None\n\n        num_instances = len(boxes) if boxes is not None else len(masks_rle)\n        if num_instances == 0:\n            return self.output\n\n        if self._instance_mode == ColorMode.SEGMENTATION and masks_rle:\n            masks = [\n                mask_util.decode(rle)\n                for rle in masks_rle\n            ]\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            # Convert all areas without masks to grayscale\n            if masks is None:\n                masks = [np.zeros((self.output.height, self.output.width), dtype=np.uint8)]\n            else:\n                masks = [\n                    (mask > 0).astype(\"uint8\") * 255\n                    for mask in masks\n                ]\n\n        # Draw masks\n        if masks is not None:\n            color = random_color(rgb=True, maximum=1)\n            for mask in masks:\n                mask = np.asarray(mask, dtype=np.uint8, order=\"F\")\n                thresh = mask[0, :, :, None]\n                contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n                cv2.drawContours(self.output.img, contours, -1, color, 2, cv2.LINE_AA)\n\n        # Draw boxes\n        if boxes is not None:\n            for box in boxes:\n                box = BoxMode.convert(box, BoxMode.XYXY_ABS, BoxMode.XYWH_ABS)\n                x, y, w, h = box\n                cv2.rectangle(\n                    self.output.img,\n                    (int(x), int(y)),\n                    (int(x + w), int(y + h)),\n                    color,\n                    2,\n                    cv2.LINE_AA,\n                )\n\n        # Draw keypoints\n        if keypoints is not None:\n            for keypoint in keypoints:\n                for kp in keypoint:\n                    x, y, v = kp\n                    if v > self.keypoint_threshold:\n                        cv2.circle(\n                            self.output.img,\n                            (int(x), int(y)),\n                            radius=3,\n                            color=color,\n                            thickness=-1,\n                            lineType=cv2.LINE_AA,\n                        )\n\n        # Draw class labels and scores\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\"))\n        for label, score, box in zip(labels, scores, boxes):\n            x, y = box[:2]\n            self.output.ax.text(\n                x,\n                y,\n                f\"{label}: {score:.2f}\",\n                color=\"white\",\n                fontsize=self._default_font_size,\n                ha=\"left\",\n                va=\"top\",\n                bbox=dict(facecolor=color, alpha=0.5, pad=0, edgecolor=\"none\"),\n            )\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n        masks = predictions.pred_masks if predictions.has(\"pred_masks\") else None\n        if predictions.has(\"pred_masks_rle\"):\n            masks_rle = predictions.pred_masks_rle\n            if isinstance(masks_rle, PolygonMasks):\n                masks = masks_rle.polygons\n            elif isinstance(masks_rle, BitMasks):\n                masks = masks_rle.tensor\n            else:\n                raise ValueError(\"Unknown mask type\")\n        labels = _create_text_labels(classes, scores, self.metadata.thing_classes)\n        return self.overlay_instances(\n            labels=labels, boxes=boxes, masks=masks, keypoints=keypoints\n        )"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.thing_classes)\n        masks = predictions.pred_masks if predictions.has(\"pred_masks\") else None\n        if masks is not None:\n            masks = mask_util.decode(masks)[:, :, None]\n        if self._instance_mode == ColorMode.SEGMENTATION:\n            colors = [self.metadata.thing_colors[c] for c in classes]\n            alpha = 0.8\n            vis_masks = []\n            for mask, color in zip(masks, colors):\n                color_mask = np.ones_like(mask) * color\n                vis_masks.append((color_mask * alpha + self.img * (1 - alpha)).astype(\"uint8\"))\n            masks = np.array(vis_masks)\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            # Any value below the threshold will be replaced by 0\n            threshold = 0.5\n            masks = (masks > threshold).astype(\"uint8\") * 255\n            masks = np.concatenate([masks, masks, masks], axis=2)\n        if boxes is not None:\n            for box, score, label in zip(boxes, scores, labels):\n                box = BoxMode.convert(box, BoxMode.XYXY_ABS, BoxMode.XYWH_ABS)\n                x, y, w, h = box\n                self.draw_box((x, y, x + w, y + h), edge_color=self.metadata.thing_colors[classes], label=label)\n        if masks is not None:\n            for mask, label in zip(masks, labels):\n                self.draw_binary_mask(mask, _OFF_WHITE, label=label)\n        if keypoints is not None:\n            for keypoints, label in zip(keypoints, labels):\n                self.draw_keypoints(keypoints, _RED, _KEYPOINT_THRESHOLD, label=label)\n        return self.output.get_image()"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n        masks = predictions.pred_masks if predictions.has(\"pred_masks\") else None\n\n        if self._instance_mode == ColorMode.SEGMENTATION:\n            colors = self._read_instance_colors(predictions)\n        else:\n            colors = None\n\n        labels = _create_text_labels(classes, scores, self.metadata.thing_classes)\n        alpha = 0.5 if self._instance_mode == ColorMode.SEGMENTATION else 0.3\n\n        if masks is not None:\n            masks = masks if isinstance(masks, BitMasks) else PolygonMasks(masks)\n            for i in range(len(predictions)):\n                color = colors[i] if colors is not None else None\n                mask = GenericMask(masks.polygons[i], self.output.height, self.output.width)\n                self.draw_binary_mask(\n                    mask.mask, color=mask_util.decode(mask.mask) if color is None else color, alpha=alpha\n                )\n\n        if boxes is not None:\n            for i in range(len(predictions)):\n                color = colors[i] if colors is not None else None\n                self.draw_box(boxes.tensor[i], edge_color=color)\n\n        if labels is not None:\n            for i in range(len(predictions)):\n                self.draw_text(labels[i], boxes.tensor[i][:2], color=colors[i] if colors is not None else None)\n\n        if keypoints is not None:\n            for keypoints_per_instance in keypoints:\n                self.draw_and_connect_keypoints(keypoints_per_instance)\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n        masks = predictions.pred_masks if predictions.has(\"pred_masks\") else None\n        masks_rle = predictions.pred_masks_rle if predictions.has(\"pred_masks_rle\") else None\n\n        num_instances = len(boxes) if boxes is not None else len(masks_rle)\n\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n\n        if self._instance_mode == ColorMode.SEGMENTATION:\n            colors = [self.metadata.thing_colors[c] for c in classes] if classes is not None else None\n        else:\n            colors = None\n\n        for i in range(num_instances):\n            if boxes is not None:\n                box = boxes[i].tensor.cpu().numpy()\n                self.draw_box(box, edge_color=colors[i] if colors is not None else None)\n                if labels is not None:\n                    label = labels[i]\n                    self.draw_text(label, (box[0], box[1]), color=colors[i] if colors is not None else None)\n            if masks is not None:\n                mask = masks[i].cpu().numpy()\n                self.draw_binary_mask(mask, color=colors[i] if colors is not None else None)\n            if masks_rle is not None:\n                mask_rle = masks_rle[i]\n                mask = mask_util.decode(mask_rle)\n                self.draw_binary_mask(mask, color=colors[i] if colors is not None else None)\n            if keypoints is not None:\n                kps = keypoints[i]\n                self.draw_and_connect_keypoints(kps)\n\n        return self.output.get_image()"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n        elif predictions.has(\"pred_masks_rle\"):\n            masks = [\n                mask_util.decode(rle) for rle in predictions.pred_masks_rle\n            ]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION:\n            colors = None\n        else:\n            num_instances = len(boxes) if boxes is not None else (\n                masks.shape[0] if masks is not None else 0\n            )\n            colors = _COCO_INSTANCE_CATEGORY_NAMES if self.metadata is None else self.metadata.thing_colors\n\n        labels = _create_text_labels(classes, scores, self.metadata.thing_classes, is_crowd=None)\n\n        return self.overlay_instances(\n            labels=labels,\n            boxes=boxes,\n            masks=masks,\n            keypoints=keypoints,\n            assigned_colors=colors,\n        )"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.thing_classes)\n        masks = predictions.pred_masks if predictions.has(\"pred_masks\") else None\n        if self._instance_mode == ColorMode.SEGMENTATION:\n            colors = None\n        else:\n            colors = [random_color(rgb=True, maximum=1) for _ in range(len(labels))]\n        panoptic_seg = predictions.panoptic_seg if predictions.has(\"panoptic_seg\") else None\n        if panoptic_seg is not None:\n            panoptic_seg = _PanopticPrediction(panoptic_seg, None, self.metadata)\n        if masks is not None:\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        keypoints = [k.to(self.cpu_device) for k in keypoints] if keypoints is not None else None\n\n        if self._instance_mode == ColorMode.SEGMENTATION:\n            for mask, label in zip(masks, labels):\n                color = random_color(rgb=True, maximum=1)\n                self.draw_binary_mask(mask.mask, color=color, text=label)\n        else:\n            for box, score, label, mask, keypoints, color in zip(boxes, scores, labels, masks, keypoints, colors):\n                color = mplc.rgb2hex(color)\n                self.draw_box(box, edge_color=color)\n                if self._instance_mode == ColorMode.IMAGE_BW:\n                    mask = mask.mask[..., None] * np.array([colorsys.rgb_to_hsv(mplc.to_rgb(color))])\n                    mask = (mask * 255).astype(np.uint8)\n                self.draw_binary_mask(mask.mask, color=color, text=label)\n                if keypoints is not None:\n                    self.draw_and_connect_keypoints(keypoints, color=color)\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n        masks = predictions.pred_masks if predictions.has(\"pred_masks\") else None\n        if predictions.has(\"pred_masks_rle\"):\n            masks_rle = predictions.pred_masks_rle\n            masks = [mask_util.decode(rle) for rle in masks_rle]\n\n        num_instances = len(boxes) if boxes is not None else len(masks)\n        if num_instances == 0:\n            return self.output\n\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n\n        if self._instance_mode == ColorMode.SEGMENTATION:\n            colors = [self.metadata.thing_colors[c] for c in classes]\n        else:\n            colors = [random_color(rgb=True) for _ in range(num_instances)]\n\n        if masks is not None:\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n\n        for i in range(num_instances):\n            color = colors[i]\n            if boxes is not None:\n                self.draw_box(boxes[i], edge_color=color)\n            if labels is not None:\n                self.draw_text(labels[i], boxes[i][:2], color=color)\n            if masks is not None and masks[i].mask.size > 0:\n                self.draw_binary_mask(masks[i].mask, color=color)\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n        masks = predictions.pred_masks if predictions.has(\"pred_masks\") else None\n        if self._instance_mode == ColorMode.SEGMENTATION:\n            color = random_color(rgb=True, maximum=1)\n        else:\n            color = None\n        num_instances = len(boxes) if boxes is not None else len(masks)\n        labels = _create_text_labels(\n            classes, scores, self.metadata.get(\"thing_classes\", None), is_crowd=None\n        )\n        masks_rles = predictions.pred_masks_rle if predictions.has(\"pred_masks_rle\") else None\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            # Convert the image to grayscale\n            img_gray = cv2.cvtColor(self.img, cv2.COLOR_RGB2GRAY)\n            img_gray = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2RGB)\n            vis_output = VisImage(img_gray, scale=self.output.scale)\n        else:\n            vis_output = self.output\n\n        for i in range(num_instances):\n            color_to_use = color\n            if masks is not None:\n                mask = GenericMask(masks[i], self.output.height, self.output.width)\n            elif masks_rles is not None:\n                mask = GenericMask(masks_rles[i], self.output.height, self.output.width)\n            else:\n                mask = None\n\n            if self._instance_mode == ColorMode.SEGMENTATION:\n                color_to_use = color if color is not None else self.metadata.thing_colors[classes[i].item()]\n                color_to_use = mplc.rgb2hex(color_to_use)\n            if boxes is not None:\n                vis_output.draw_box(boxes[i], edge_color=color_to_use)\n            if labels is not None:\n                vis_output.draw_text(\n                    labels[i],\n                    (boxes[i, 0] + 5, boxes[i, 1] + 5),\n                    color=color_to_use\n                )\n            if masks is not None or masks_rles is not None:\n                vis_output.draw_binary_mask(mask.mask, color=color_to_use, text=labels[i])\n\n            if keypoints is not None:\n                vis_output.draw_and_connect_keypoints(keypoints[i])\n\n        return vis_output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.thing_classes)\n        masks = None\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n        elif predictions.has(\"pred_masks_rle\"):\n            masks = [\n                mask_util.decode(rle) for rle in predictions.pred_masks_rle\n            ]\n        vis_output = self._create_instances(\n            boxes=boxes, labels=labels, masks=masks, keypoints=keypoints\n        )\n        return vis_output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.thing_classes)\n        masks = None\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n        elif predictions.has(\"pred_masks_rle\"):\n            masks = [mask_util.decode(rle) for rle in predictions.pred_masks_rle]\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            masks = (masks > 0).astype(\"uint8\") * 255\n        if self._instance_mode == ColorMode.SEGMENTATION:\n            colors = self.metadata.thing_colors\n            alpha = 0.8\n        else:\n            colors = None\n            alpha = 0.5\n        vis_output = self._create_keypoint_and_mask_visualizations(\n            self.img, boxes, labels, masks, keypoints, colors, alpha\n        )\n        return vis_output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n        masks = predictions.pred_masks if predictions.has(\"pred_masks\") else None\n        if predictions.has(\"pred_masks_rle\"):\n            masks_rle = predictions.pred_masks_rle\n            masks = [\n                mask_util.decode(rle) for rle in masks_rle\n            ]  # Convert RLE to binary masks\n        if self._instance_mode == ColorMode.SEGMENTATION:\n            color = random_color(rgb=True, maximum=1)\n        else:\n            color = None\n\n        labels = _create_text_labels(\n            classes, scores, self.metadata.get(\"thing_classes\", None), None\n        )\n        return self.overlay_instances(\n            labels=labels,\n            boxes=boxes,\n            masks=masks,\n            keypoints=keypoints,\n            assigned_colors=color,\n        )"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n        if predictions.has(\"pred_masks\"):\n            masks = predictions.pred_masks\n        elif predictions.has(\"pred_masks_rle\"):\n            masks = [mask_util.decode(rle) for rle in predictions.pred_masks_rle]\n        else:\n            masks = None\n\n        num_instances = len(boxes) if boxes is not None else len(masks)\n        if num_instances == 0:\n            return self.output\n\n        if self._instance_mode == ColorMode.SEGMENTATION:\n            colors = [self.metadata.thing_colors[c] for c in classes]\n        else:\n            colors = [random_color() for _ in range(num_instances)]\n\n        if masks is not None:\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n\n        labels = _create_text_labels(\n            classes, scores, self.metadata.get(\"thing_classes\", None), is_crowd=None\n        )\n\n        for i in range(num_instances):\n            color = colors[i]\n            if boxes is not None:\n                self.draw_box(boxes[i], edge_color=color)\n            if masks is not None:\n                mask = masks[i]\n                if self._instance_mode == ColorMode.IMAGE_BW:\n                    mask = np.uint8(mask.mask * 255)\n                    self.draw_binary_mask(mask, color=color, text=labels[i])\n                else:\n                    self.draw_binary_mask(mask.mask, color=color, text=labels[i])\n            if keypoints is not None:\n                self.draw_and_connect_keypoints(keypoints[i])\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n        masks = predictions.pred_masks if predictions.has(\"pred_masks\") else None\n\n        num_instances = len(boxes) if boxes is not None else len(masks)\n\n        if num_instances == 0:\n            return self.output\n\n        if self._instance_mode == ColorMode.SEGMENTATION:\n            colors = [\n                metadata.thing_colors[classes[i]] for i in range(num_instances)\n            ] if predictions.has(\"pred_classes\") else None\n        else:\n            colors = None\n\n        labels = _create_text_labels(\n            classes, scores, self.metadata.get(\"thing_classes\", None), is_crowd=None\n        )\n\n        masks_rles = [\n            mask_util.encode(np.array(mask[0, :, :, np.newaxis], order=\"F\"))[0]\n            for mask in masks\n        ] if masks is not None else None\n\n        for i in range(num_instances):\n            color = random_color(rgb=True) if colors is None else colors[i]\n            color = np.array(color) * 255\n\n            if boxes is not None:\n                box = boxes.tensor[i]\n                self.draw_box(box, edge_color=color)\n\n            if labels is not None:\n                label = labels[i]\n                if self._instance_mode == ColorMode.SEGMENTATION:\n                    area = masks[i].sum() if masks is not None else None\n                    self.draw_text(\n                        label, (boxes.tensor[i, :2] + boxes.tensor[i, 2:]) / 2, color=color\n                    )\n                    self.draw_text(\n                        f\"{label} {area}\", (boxes.tensor[i, :2] + boxes.tensor[i, 2:]) / 2, color=color\n                    )\n                else:\n                    self.draw_text(label, boxes.tensor[i, :2], color=color)\n\n            if keypoints is not None:\n                self.draw_and_connect_keypoints(keypoints[i], color=color)\n\n            if masks_rles is not None:\n                mask_rle = masks_rles[i]\n                mask = mask_util.decode(mask_rle)[:, :]\n                self.draw_binary_mask(mask, color=color)\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n        masks = predictions.pred_masks if predictions.has(\"pred_masks\") else None\n        masks_rle = predictions.pred_masks_rle if predictions.has(\"pred_masks_rle\") else None\n\n        num_instances = len(boxes) if boxes is not None else len(masks) if masks is not None else 0\n\n        if num_instances == 0:\n            return self.output\n\n        if self._instance_mode == ColorMode.SEGMENTATION:\n            colors = [self.metadata.thing_colors[c] for c in classes] if classes is not None else None\n        else:\n            colors = None\n\n        if masks is not None:\n            masks = masks if isinstance(masks, BitMasks) else BitMasks(masks, masks.shape[1], masks.shape[2])\n        if masks_rle is not None:\n            masks_rle = [\n                mask_util.decode(rle) if isinstance(rle, dict) else mask_util.decode(rle)\n                for rle in masks_rle\n            ]\n\n        for i in range(num_instances):\n            color = random_color(rgb=True) if colors is None else colors[i]\n            color = mplc.rgb2hex(color)\n\n            if boxes is not None:\n                box = boxes[i].tensor.numpy()\n                self.draw_box(box, edge_color=color)\n\n            if masks is not None:\n                mask = masks[i].mask\n                self.draw_binary_mask(mask, color=color)\n\n            if masks_rle is not None:\n                mask_rle = masks_rle[i]\n                mask = mask_util.decode(mask_rle)\n                self.draw_binary_mask(mask, color=color)\n\n            if keypoints is not None:\n                keypoints_i = keypoints[i].numpy()\n                self.draw_and_connect_keypoints(keypoints_i, color=color)\n\n            if classes is not None and scores is not None:\n                label = \"{}: {:.0f}%\".format(self.metadata.thing_classes[classes[i]], scores[i] * 100)\n                self.draw_text(label, (box[0], box[1]), color=color)\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n        if predictions.has(\"pred_masks\"):\n            masks = predictions.pred_masks\n        elif predictions.has(\"pred_masks_rle\"):\n            masks = [mask_util.decode(rle) for rle in predictions.pred_masks_rle]\n        else:\n            masks = None\n\n        num_instances = len(boxes) if boxes is not None else len(masks)\n        colors = None\n        if self._instance_mode == ColorMode.SEGMENTATION:\n            try:\n                colors = [metadata.thing_colors[c] for c in classes]\n            except AttributeError:\n                logger.warning(\n                    \"Using default color (green) for instance visualizations. \"\n                    \"Pass metadata to Visualizer to set the colors of classes.\"\n                )\n                colors = [random_color(rgb=True, maximum=1) for _ in range(num_instances)]\n\n        if boxes is not None:\n            # boxes = boxes.tensor.numpy()\n            for i in range(num_instances):\n                color = colors[i] if colors is not None else None\n                self.draw_box(boxes[i], edge_color=color)\n\n        if masks is not None:\n            for i in range(num_instances):\n                color = colors[i] if colors is not None else None\n                mask = masks[i]\n                self.draw_binary_mask(mask, color=color)\n\n        if classes is not None and scores is not None:\n            labels = _create_text_labels(classes, scores, self.metadata.thing_classes)\n            for label, (x, y), color in zip(labels, boxes.get_centers(), colors):\n                self.draw_text(label, (x, y), color=color)\n\n        if keypoints is not None:\n            for keypoints_per_instance, color in zip(keypoints, colors):\n                self.draw_and_connect_keypoints(keypoints_per_instance, keypoint_threshold=self.keypoint_threshold, color=color)\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n        masks = predictions.pred_masks if predictions.has(\"pred_masks\") else None\n\n        num_instances = len(predictions)\n\n        if num_instances == 0:\n            return self.output\n\n        if self._instance_mode == ColorMode.SEGMENTATION:\n            colors = [self.metadata.thing_colors[c] for c in classes]\n        else:\n            colors = [random_color() for _ in range(num_instances)]\n\n        if masks is not None:\n            masks = masks.cpu().numpy()\n\n        for i in range(num_instances):\n            color = colors[i]\n            if boxes is not None:\n                box = boxes[i].cpu().numpy()\n                self.draw_box(box, edge_color=color)\n\n            if masks is not None:\n                mask = (masks[i, 0] * 255).astype(np.uint8)\n                self.draw_binary_mask(mask, color=color)\n\n            if classes is not None and self.metadata.thing_classes is not None:\n                class_name = self.metadata.thing_classes[classes[i]]\n                if scores is not None:\n                    score = scores[i]\n                    label = \"{} {:.0f}%\".format(class_name, score * 100)\n                else:\n                    label = class_name\n                self.draw_text(label, (box[0], box[1]), color=color)\n\n            if keypoints is not None:\n                keypoints_i = keypoints[i].cpu().numpy()\n                self.draw_and_connect_keypoints(keypoints_i, keypoint_names=None, color=color)\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n        masks = predictions.pred_masks if predictions.has(\"pred_masks\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.thing_classes)\n        colors = None\n        if self._instance_mode == ColorMode.SEGMENTATION:\n            colors = [self.metadata.thing_colors[c] for c in classes] if classes is not None else None\n        if masks is not None:\n            masks = masks if isinstance(masks, PolygonMasks) else PolygonMasks(masks)\n        return self.overlay_instances(\n            labels=labels, boxes=boxes, masks=masks, keypoints=keypoints, assigned_colors=colors\n        )"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        self.canvas.draw()  # draw the canvas\n        buf = self.canvas.buffer_rgba()  # get the buffer in RGBA format\n        buf = np.asarray(buf)  # convert buffer to numpy array\n        return buf[:, :, :3]  # return only RGB channels"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        self.canvas.draw()  # Draw the canvas to generate the visualized image\n        buf = self.canvas.buffer_rgba()  # Get the RGBA buffer from the canvas\n        buf = np.asarray(buf)  # Convert the buffer to a numpy array\n        return buf[:, :, :3]  # Return the RGB portion of the buffer"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        self.canvas.draw()  # Draw the canvas to update the image\n        buf = self.canvas.buffer_rgba()  # Get the buffer in RGBA format\n        w, h = self.fig.canvas.get_width_height()  # Get the width and height of the image\n        img = np.frombuffer(buf, np.uint8).reshape(h, w, 4)  # Convert the buffer to a numpy array\n        img = img[:, :, :3]  # Remove the alpha channel to convert from RGBA to RGB\n        return img  # Return the visualized image in RGB format as a numpy ndarray"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        self.canvas.draw()\n        buf = self.canvas.buffer_rgba()\n        w, h = self.canvas.get_width_height()\n        img = np.frombuffer(buf, np.uint8).reshape(h, w, 4)\n        return img[..., :3]"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        self.fig.tight_layout(pad=0)\n        self.canvas.draw()\n        buf = self.canvas.buffer_rgba()\n        w, h = self.fig.canvas.get_width_height()\n        img = np.frombuffer(buf, np.uint8).reshape(h, w, 4)\n        img = img[:, :, :3]  # Remove the alpha channel\n        return img"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        self.canvas.draw()  # draw the canvas\n        buf = self.canvas.buffer_rgba()  # get the buffer in RGBA format\n        buf = np.asarray(buf)  # convert buffer to numpy array\n        img = buf[:, :, :3]  # extract RGB channels\n        return img.astype(np.uint8)  # return the image as uint8 type"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        self.canvas.draw()  # draw the canvas\n        buf = self.canvas.buffer_rgba()  # get the buffer in RGBA format\n        buf = np.asarray(buf)  # convert buffer to numpy array\n        # Convert RGBA to RGB\n        rgb_image = buf[:, :, :3]  # take only the RGB channels\n        return rgb_image.astype(np.uint8)  # return as uint8 type"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        self.canvas.draw()\n        buf = self.canvas.buffer_rgba()\n        buf = np.asarray(buf, dtype=np.uint8)\n        buf = buf[:, :, :3]  # Drop the alpha channel\n        return buf"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        self.canvas.draw()  # Draw the canvas to render the image\n        buf = self.canvas.buffer_rgba()  # Get the buffer in RGBA format\n        buf = np.asarray(buf)  # Convert buffer to numpy array\n        img = buf[:, :, :3]  # Extract RGB channels\n        return img.astype(np.uint8)  # Return the visualized image as a numpy array of uint8 type"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # Convert the RGBA image to RGB format\n        img_rgba = self.canvas.buffer_rgba()\n        img_rgb = np.array(img_rgba)[:, :, :3]  # Extract RGB channels\n\n        return img_rgb"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        self.canvas.draw()  # Draw the canvas to render the image\n        buf = self.canvas.buffer_rgba()  # Get the buffer in RGBA format\n        img = np.asarray(buf)  # Convert the buffer to a numpy array\n        img = img[:, :, :3]  # Keep only the RGB channels, discarding the alpha channel\n        return img  # Return the visualized image as a numpy ndarray in RGB format"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        self.canvas.draw()  # draw the canvas\n        buf = self.canvas.buffer_rgba()  # get the buffer in RGBA format\n        buf = np.asarray(buf)  # convert buffer to numpy array\n        # Convert from RGBA to RGB\n        rgb_image = buf[:, :, :3]\n        return rgb_image.astype(np.uint8)  # return as uint8 numpy array"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        self.canvas.draw()  # draw the canvas\n        buf = self.canvas.buffer_rgba()  # get the buffer in RGBA format\n        buf = np.asarray(buf)  # convert buffer to numpy array\n        return buf[:, :, :3]  # return the RGB format of the image"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        self.canvas.draw()\n        buf = self.canvas.buffer_rgba()\n        w, h = self.canvas.get_width_height()\n        img = np.frombuffer(buf, np.uint8).reshape(h, w, 4)\n        return img[:, :, :3]"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        self.canvas.draw()\n        buf = self.canvas.buffer_rgba()\n        w, h = self.canvas.get_width_height()\n        img = np.frombuffer(buf, np.uint8).reshape(h, w, 4)\n        return img[:, :, :3]"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        self.canvas.draw()  # draw the canvas\n        buf = self.canvas.buffer_rgba()  # get the RGBA buffer\n        buf = np.asarray(buf)  # convert buffer to numpy array\n        return buf[:, :, :3]  # return only the RGB channels"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        self.canvas.draw()  # draw the canvas\n        buf = self.canvas.buffer_rgba()  # get the buffer in RGBA format\n        buf = np.asarray(buf)  # convert buffer to numpy array\n        return buf[:, :, :3]  # return the RGB part of the buffer"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        self.canvas.draw()  # draw the canvas\n        buf = self.canvas.buffer_rgba()  # get the buffer in RGBA format\n        buf = np.asarray(buf)  # convert buffer to numpy array\n        # Convert from RGBA to RGB\n        rgb_image = buf[:, :, :3]\n        return rgb_image"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        self.canvas.draw()  # draw the canvas\n        buf = self.canvas.buffer_rgba()  # get the buffer in RGBA format\n        buf = np.asarray(buf)  # convert buffer to numpy array\n        return buf[:, :, :3]  # return only the RGB channels"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        self.canvas.draw()  # Draw the canvas to update the image\n        buf = self.canvas.buffer_rgba()  # Get the RGBA buffer from the canvas\n        img = np.asarray(buf)  # Convert the buffer to a numpy array\n        img = img[:, :, :3]  # Keep only the RGB channels, discarding the alpha channel\n        return img.astype(np.uint8)  # Convert the image to uint8 type and return it"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "\n        if \"annotations\" in dic:\n            return self.draw_instance_predictions(dic[\"annotations\"])\n        elif \"sem_seg\" in dic:\n            return self.draw_sem_seg(dic[\"sem_seg\"])\n        elif \"panoptic_seg\" in dic:\n            return self.draw_panoptic_seg(dic[\"panoptic_seg\"], dic.get(\"segments_info\"))\n        else:\n            raise ValueError(\"Unsupported format in the input dictionary\")"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        if \"annotations\" in dic:\n            # Draw instance-level prediction results\n            instances = Instances(dic[\"image\"].shape[:2])\n            instances.set(\"pred_boxes\", dic[\"annotations\"][\"boxes\"])\n            instances.set(\"scores\", dic[\"annotations\"][\"scores\"])\n            instances.set(\"pred_classes\", dic[\"annotations\"][\"classes\"])\n            if \"masks\" in dic[\"annotations\"]:\n                instances.set(\"pred_masks\", dic[\"annotations\"][\"masks\"])\n            if \"keypoints\" in dic[\"annotations\"]:\n                instances.set(\"pred_keypoints\", dic[\"annotations\"][\"keypoints\"])\n            return self.draw_instance_predictions(instances)\n\n        if \"sem_seg\" in dic:\n            # Draw semantic segmentation predictions/labels\n            return self.draw_sem_seg(dic[\"sem_seg\"])\n\n        if \"panoptic_seg\" in dic and \"segments_info\" in dic:\n            # Draw panoptic prediction annotations or results\n            return self.draw_panoptic_seg(dic[\"panoptic_seg\"], dic[\"segments_info\"])\n\n        # If none of the above, return the original image\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        if \"annotations\" in dic:\n            # Draw instance-level prediction results\n            instances = Instances(\n                image_size=(dic[\"height\"], dic[\"width\"]),\n                pred_boxes=Boxes(dic[\"annotations\"][\"bbox\"]),\n                scores=dic[\"annotations\"][\"score\"],\n                pred_classes=dic[\"annotations\"][\"category_id\"],\n                pred_masks=dic[\"annotations\"][\"segmentation\"],\n            )\n            return self.draw_instance_predictions(instances)\n        elif \"sem_seg\" in dic:\n            # Draw semantic segmentation predictions/labels\n            return self.draw_sem_seg(dic[\"sem_seg\"])\n        elif \"panoptic_seg\" in dic and \"segments_info\" in dic:\n            # Draw panoptic prediction annotations or results\n            return self.draw_panoptic_seg(dic[\"panoptic_seg\"], dic[\"segments_info\"])\n        else:\n            raise ValueError(\"Unsupported format of dataset dictionary\")"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        if \"annotations\" in dic:\n            # Draw instance-level predictions\n            instances = dic[\"annotations\"]\n            return self.draw_instance_predictions(instances)\n        elif \"sem_seg\" in dic:\n            # Draw semantic segmentation\n            sem_seg = dic[\"sem_seg\"]\n            return self.draw_sem_seg(sem_seg)\n        elif \"panoptic_seg\" in dic and \"segments_info\" in dic:\n            # Draw panoptic segmentation\n            panoptic_seg = dic[\"panoptic_seg\"]\n            segments_info = dic[\"segments_info\"]\n            return self.draw_panoptic_seg(panoptic_seg, segments_info)\n        else:\n            raise ValueError(\"Unsupported dataset format. The input dictionary should contain annotations, sem_seg, or panoptic_seg keys.\")"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        if \"annotations\" in dic:\n            annotations = dic[\"annotations\"]\n            instances = Annotations(annotations)\n            return self.draw_instance_predictions(instances)\n        elif \"sem_seg\" in dic:\n            sem_seg = dic[\"sem_seg\"]\n            return self.draw_sem_seg(sem_seg)\n        elif \"panoptic_seg\" in dic and \"segments_info\" in dic:\n            panoptic_seg = dic[\"panoptic_seg\"]\n            segments_info = dic[\"segments_info\"]\n            return self.draw_panoptic_seg(panoptic_seg, segments_info)\n        else:\n            raise ValueError(\"Unsupported dataset format. The input dictionary should contain annotations, sem_seg, or panoptic_seg.\")"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        if \"annotations\" in dic:\n            annotations = dic[\"annotations\"]\n            instances = Instances((dic[\"height\"], dic[\"width\"]))\n            instances.set(\"pred_boxes\", torch.tensor([x[\"bbox\"] for x in annotations]))\n            instances.set(\"scores\", torch.tensor([x[\"score\"] for x in annotations]))\n            instances.set(\"pred_classes\", torch.tensor([x[\"category_id\"] for x in annotations]))\n            if \"segmentation\" in annotations[0]:\n                masks = [x[\"segmentation\"] for x in annotations]\n                instances.set(\"pred_masks\", mask_util.frPyObjects(masks, dic[\"height\"], dic[\"width\"]))\n            if \"keypoints\" in annotations[0]:\n                keypoints = [x[\"keypoints\"] for x in annotations]\n                instances.set(\"pred_keypoints\", torch.tensor(keypoints))\n            self.draw_instance_predictions(instances)\n\n        if \"sem_seg\" in dic:\n            sem_seg = dic[\"sem_seg\"]\n            self.draw_sem_seg(sem_seg)\n\n        if \"panoptic_seg\" in dic and \"segments_info\" in dic:\n            panoptic_seg = dic[\"panoptic_seg\"]\n            segments_info = dic[\"segments_info\"]\n            self.draw_panoptic_seg(panoptic_seg, segments_info)\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        if \"annotations\" in dic:\n            # Draw annotations\n            annotations = dic[\"annotations\"]\n            instances = Instances(self.output.height, self.output.width)\n            for annotation in annotations:\n                if \"bbox\" in annotation:\n                    instances.pred_boxes = Boxes([annotation[\"bbox\"]], mode=BoxMode.XYXY_ABS)\n                if \"segmentation\" in annotation:\n                    instances.pred_masks = PolygonMasks([annotation[\"segmentation\"]], self.output.height, self.output.width)\n                if \"keypoints\" in annotation:\n                    instances.pred_keypoints = Keypoints.from_xyv(annotation[\"keypoints\"], self.output.height, self.output.width)\n                if \"category_id\" in annotation:\n                    instances.pred_classes = [annotation[\"category_id\"]]\n                if \"score\" in annotation:\n                    instances.scores = [annotation[\"score\"]]\n            self.draw_instance_predictions(instances)\n\n        if \"sem_seg\" in dic:\n            # Draw semantic segmentation\n            self.draw_sem_seg(dic[\"sem_seg\"])\n\n        if \"panoptic_seg\" in dic and \"panoptic_seg_info\" in dic:\n            # Draw panoptic segmentation\n            self.draw_panoptic_seg(dic[\"panoptic_seg\"], dic[\"panoptic_seg_info\"])\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "\n        if \"annotations\" in dic:\n            annotations = dic[\"annotations\"]\n            instances = Annotations(annotations)\n            return self.draw_instance_predictions(instances)\n\n        if \"sem_seg\" in dic:\n            sem_seg = dic[\"sem_seg\"]\n            return self.draw_sem_seg(sem_seg)\n\n        if \"panoptic_seg\" in dic:\n            panoptic_seg = dic[\"panoptic_seg\"]\n            segments_info = dic.get(\"segments_info\", None)\n            return self.draw_panoptic_seg(panoptic_seg, segments_info)\n\n        raise ValueError(\"Invalid dataset dictionary. It should contain annotations, sem_seg, or panoptic_seg.\")"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        if \"annotations\" in dic:\n            # Draw instance predictions\n            instances = dic[\"annotations\"]\n            boxes = instances.get(\"bbox\", None)\n            masks = instances.get(\"segmentation\", None)\n            keypoints = instances.get(\"keypoints\", None)\n            scores = instances.get(\"score\", None)\n            classes = instances.get(\"category_id\", None)\n            labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n            if masks:\n                masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n            if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n                colors = [\n                    self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n                ]\n                alpha = 0.8\n            else:\n                colors = None\n                alpha = 0.5\n            if self._instance_mode == ColorMode.IMAGE_BW:\n                self.output.reset_image(\n                    self._create_grayscale_image(\n                        (instances[\"segmentation\"].any(dim=0) > 0).numpy()\n                        if masks\n                        else None\n                    )\n                )\n                alpha = 0.3\n            self.overlay_instances(\n                masks=masks,\n                boxes=boxes,\n                labels=labels,\n                keypoints=keypoints,\n                assigned_colors=colors,\n                alpha=alpha,\n            )\n        if \"sem_seg\" in dic:\n            # Draw semantic segmentation\n            sem_seg = dic[\"sem_seg\"]\n            self.draw_sem_seg(sem_seg)\n        if \"panoptic_seg\" in dic and \"segments_info\" in dic:\n            # Draw panoptic segmentation\n            panoptic_seg = dic[\"panoptic_seg\"]\n            segments_info = dic[\"segments_info\"]\n            self.draw_panoptic_seg(panoptic_seg, segments_info)\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        if \"annotations\" in dic:\n            annotations = dic[\"annotations\"]\n            instances = Annotations(annotations)\n            return self.draw_instance_predictions(instances)\n        elif \"sem_seg\" in dic:\n            sem_seg = dic[\"sem_seg\"]\n            return self.draw_sem_seg(sem_seg)\n        elif \"panoptic_seg\" in dic and \"segments_info\" in dic:\n            panoptic_seg = dic[\"panoptic_seg\"]\n            segments_info = dic[\"segments_info\"]\n            return self.draw_panoptic_seg(panoptic_seg, segments_info)\n        else:\n            raise ValueError(\"Unsupported dataset format\")"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        if \"annotations\" in dic:\n            # Draw annotations\n            annotations = dic[\"annotations\"]\n            instances = Annotations(annotations)\n            return self.draw_instance_predictions(instances)\n\n        if \"sem_seg\" in dic:\n            # Draw semantic segmentation\n            sem_seg = dic[\"sem_seg\"]\n            return self.draw_sem_seg(sem_seg)\n\n        if \"panoptic_seg\" in dic and \"segments_info\" in dic:\n            # Draw panoptic segmentation\n            panoptic_seg = dic[\"panoptic_seg\"]\n            segments_info = dic[\"segments_info\"]\n            return self.draw_panoptic_seg(panoptic_seg, segments_info)\n\n        # If none of the above, return the original image\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        if \"annotations\" in dic:\n            annotations = dic[\"annotations\"]\n            instances = Annotations(annotations, dic[\"height\"], dic[\"width\"])\n            return self.draw_instance_predictions(instances)\n        elif \"sem_seg\" in dic:\n            return self.draw_sem_seg(dic[\"sem_seg\"])\n        elif \"panoptic_seg\" in dic and \"segments_info\" in dic:\n            return self.draw_panoptic_seg(dic[\"panoptic_seg\"], dic[\"segments_info\"])\n        else:\n            raise ValueError(\"Unsupported dataset format\")"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        if \"annotations\" in dic:\n            annotations = dic[\"annotations\"]\n            instances = Annotations(annotations, dic[\"height\"], dic[\"width\"])\n            return self.draw_instance_predictions(instances)\n        elif \"sem_seg\" in dic:\n            return self.draw_sem_seg(dic[\"sem_seg\"])\n        elif \"panoptic_seg\" in dic:\n            return self.draw_panoptic_seg(dic[\"panoptic_seg\"], dic.get(\"segments_info\", None))\n        else:\n            raise ValueError(\"Unsupported data format in the input dictionary\")"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        if \"annotations\" in dic:\n            # Draw bounding boxes, masks, and keypoints\n            instances = dic[\"annotations\"]\n            boxes = [BoxMode.convert(obj[\"bbox\"], BoxMode.XYWH_ABS, BoxMode.XYXY_ABS) for obj in instances]\n            boxes = torch.tensor(boxes)\n            classes = [obj[\"category_id\"] for obj in instances]\n            classes = torch.tensor(classes)\n            masks = [GenericMask(obj[\"segmentation\"], dic[\"height\"], dic[\"width\"]) for obj in instances]\n            keypoints = [Keypoints(torch.tensor(obj[\"keypoints\"]), dic[\"height\"], dic[\"width\"]) for obj in instances]\n\n            self.overlay_instances(\n                masks=masks,\n                boxes=boxes,\n                labels=classes,\n                keypoints=keypoints\n            )\n\n        if \"sem_seg\" in dic:\n            # Draw semantic segmentation\n            sem_seg = dic[\"sem_seg\"]\n            self.draw_sem_seg(sem_seg)\n\n        if \"panoptic_seg\" in dic and \"segments_info\" in dic:\n            # Draw panoptic segmentation\n            panoptic_seg = dic[\"panoptic_seg\"]\n            segments_info = dic[\"segments_info\"]\n            self.draw_panoptic_seg(panoptic_seg, segments_info)\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        if \"annotations\" in dic:\n            annotations = dic[\"annotations\"]\n            instances = Instances((dic[\"height\"], dic[\"width\"]))\n            instances.set(\"pred_boxes\", torch.tensor([x[\"bbox\"] for x in annotations]))\n            instances.set(\"scores\", torch.tensor([x[\"score\"] for x in annotations]))\n            instances.set(\"pred_classes\", torch.tensor([x[\"category_id\"] for x in annotations]))\n            if \"segmentation\" in annotations[0]:\n                masks = [GenericMask(x[\"segmentation\"], dic[\"height\"], dic[\"width\"]) for x in annotations]\n                instances.set(\"pred_masks\", torch.tensor([x.mask for x in masks]))\n            if \"keypoints\" in annotations[0]:\n                keypoints = [x[\"keypoints\"] for x in annotations]\n                instances.set(\"pred_keypoints\", torch.tensor(keypoints))\n            self.draw_instance_predictions(instances)\n\n        if \"sem_seg\" in dic:\n            self.draw_sem_seg(dic[\"sem_seg\"])\n\n        if \"panoptic_seg\" in dic and \"segments_info\" in dic:\n            self.draw_panoptic_seg(dic[\"panoptic_seg\"], dic[\"segments_info\"])\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        if \"annotations\" in dic:\n            return self.draw_instance_predictions(dic[\"annotations\"])\n        elif \"sem_seg\" in dic:\n            return self.draw_sem_seg(dic[\"sem_seg\"])\n        elif \"panoptic_seg\" in dic and \"segments_info\" in dic:\n            return self.draw_panoptic_seg(dic[\"panoptic_seg\"], dic[\"segments_info\"])\n        else:\n            raise ValueError(\"Unsupported dataset format\")"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # Extract necessary information from the input dictionary\n        if \"annotations\" in dic:\n            annotations = dic[\"annotations\"]\n            boxes = [ann[\"bbox\"] for ann in annotations]\n            classes = [ann[\"category_id\"] for ann in annotations]\n            scores = [ann[\"score\"] for ann in annotations] if \"score\" in annotations[0] else None\n            labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n            masks = [GenericMask(ann[\"segmentation\"], dic[\"height\"], dic[\"width\"]) for ann in annotations if \"segmentation\" in ann]\n            keypoints = [ann[\"keypoints\"] for ann in annotations] if \"keypoints\" in annotations[0] else None\n            if \"segmentation\" in annotations[0]:\n                if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n                    colors = [\n                        self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes\n                    ]\n                    alpha = 0.8\n                else:\n                    colors = None\n                    alpha = 0.5\n                if self._instance_mode == ColorMode.IMAGE_BW:\n                    self.output.reset_image(\n                        self._create_grayscale_image(\n                            (np.array([m.mask for m in masks]).any(axis=0) > 0).astype(np.uint8)\n                        )\n                    )\n                    alpha = 0.3\n                self.overlay_instances(\n                    masks=masks,\n                    boxes=boxes,\n                    labels=labels,\n                    keypoints=keypoints,\n                    assigned_colors=colors,\n                    alpha=alpha,\n                )\n        if \"sem_seg\" in dic:\n            sem_seg = dic[\"sem_seg\"]\n            self.draw_sem_seg(sem_seg)\n        if \"panoptic_seg\" in dic and \"panoptic_seg_file\" in dic:\n            panoptic_seg = dic[\"panoptic_seg\"]\n            segments_info = dic[\"panoptic_seg_file\"][\"segments_info\"]\n            self.draw_panoptic_seg(panoptic_seg, segments_info)\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        if \"annotations\" in dic:\n            return self.draw_instance_predictions(dic[\"annotations\"])\n        elif \"sem_seg\" in dic:\n            return self.draw_sem_seg(dic[\"sem_seg\"])\n        elif \"panoptic_seg\" in dic and \"segments_info\" in dic:\n            return self.draw_panoptic_seg(dic[\"panoptic_seg\"], dic[\"segments_info\"])\n        else:\n            raise ValueError(\"Unsupported input format. The input dictionary must contain annotations, sem_seg, or panoptic_seg and segments_info.\")"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        # Implementation of the function goes here\n        # Visualize the annotations/segmentations based on the input dictionary\n        # Return the modified image object with the visualizations drawn on it\n        pass  # Placeholder for the implementation"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        if \"annotations\" in dic:\n            # Process annotations\n            # ...\n            pass\n\n        if \"sem_seg\" in dic:\n            # Process semantic segmentation\n            # ...\n            pass\n\n        if \"pan_seg\" in dic:\n            # Process panoptic segmentation\n            # ...\n            pass\n\n        return self.output"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()  # Create an in-memory buffer\n    torch.jit.save(module, buffer)  # Save the JIT module to the buffer\n    buffer.seek(0)  # Move the buffer's read position to the beginning\n    reloaded_module = torch.jit.load(buffer)  # Load the JIT module back from the buffer\n    return reloaded_module  # Return the reloaded JIT module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()  # Create an in-memory buffer\n    torch.jit.save(module, buffer)  # Save the JIT module to the buffer\n    buffer.seek(0)  # Reset the buffer position to the beginning\n    reloaded_module = torch.jit.load(buffer)  # Load the JIT module back from the buffer\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    # Save the module to an in-memory buffer\n    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    \n    # Load the module back from the buffer\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n    \n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()  # Create an in-memory buffer\n    torch.jit.save(module, buffer)  # Save the JIT module to the buffer\n    buffer.seek(0)  # Reset the buffer position to the beginning\n    reloaded_module = torch.jit.load(buffer)  # Load the module back from the buffer\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    # Save the module to an in-memory buffer\n    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    \n    # Load the module back from the buffer\n    buffer.seek(0)  # Reset the buffer position to the beginning\n    reloaded_module = torch.jit.load(buffer)\n    \n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()  # Create an in-memory buffer\n    torch.jit.save(module, buffer)  # Save the JIT module to the buffer\n    buffer.seek(0)  # Move the buffer position to the start\n    reloaded_module = torch.jit.load(buffer)  # Load the JIT module back from the buffer\n    return reloaded_module  # Return the reloaded JIT module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()  # Create an in-memory buffer\n    torch.jit.save(module, buffer)  # Save the JIT module to the buffer\n    buffer.seek(0)  # Reset the buffer position to the beginning\n    reloaded_module = torch.jit.load(buffer)  # Load the JIT module back from the buffer\n    return reloaded_module  # Return the reloaded JIT module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()  # Create an in-memory buffer\n    torch.jit.save(module, buffer)  # Save the module to the buffer\n    buffer.seek(0)  # Reset the buffer position to the beginning\n    reloaded_module = torch.jit.load(buffer)  # Load the module back from the buffer\n    return reloaded_module  # Return the reloaded JIT module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()  # Create an in-memory buffer\n    torch.jit.save(module, buffer)  # Save the JIT module to the buffer\n    buffer.seek(0)  # Reset the buffer position to the beginning\n    reloaded_module = torch.jit.load(buffer)  # Load the JIT module back from the buffer\n    return reloaded_module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()  # Create an in-memory buffer\n    torch.jit.save(module, buffer)  # Save the JIT module to the in-memory buffer\n    buffer.seek(0)  # Set the buffer position to the beginning\n    reloaded_module = torch.jit.load(buffer)  # Load the JIT module back from the in-memory buffer\n    return reloaded_module  # Return the reloaded JIT module"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    reloaded_module = torch.jit.load(buffer)\n    return reloaded_module"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "\n        mask_color = color if color is not None else random_color(rgb=True, maximum=1)\n        edge_color = edge_color if edge_color is not None else mask_color\n        mask = np.asarray(binary_mask, dtype=np.uint8)\n\n        # Draw the mask\n        for i in range(mask.shape[0]):\n            for j in range(mask.shape[1]):\n                if mask[i, j] == 1:\n                    self.output.ax.add_patch(\n                        mpl.patches.Rectangle(\n                            (j, i),\n                            1,\n                            1,\n                            fill=True,\n                            edgecolor=edge_color,\n                            facecolor=mask_color,\n                            alpha=alpha,\n                        )\n                    )\n\n        # Draw text on the mask\n        if text is not None:\n            text_pos = (j, i)\n            self.draw_text(text, text_pos, color=mask_color)\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        mask = binary_mask.astype(np.uint8)\n        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n        for contour in contours:\n            area = cv2.contourArea(contour)\n            if area < area_threshold:\n                continue\n            if color is None:\n                color = random_color(rgb=True, maximum=1)\n            color = mplc.to_rgb(color)\n            color = tuple(c * 255 for c in color)\n            cv2.drawContours(self.output.img, [contour], -1, color, -1)\n\n            if edge_color is not None:\n                edge_color = mplc.to_rgb(edge_color)\n                edge_color = tuple(c * 255 for c in edge_color)\n                cv2.drawContours(self.output.img, [contour], -1, edge_color, 2)\n\n            if text is not None:\n                x, y, w, h = cv2.boundingRect(contour)\n                cv2.putText(self.output.img, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if binary_mask.sum() < area_threshold:\n            return self.output\n\n        binary_mask = binary_mask.astype(np.uint8)\n        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        # Convert binary mask to polygon mask\n        contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n        for contour in contours:\n            contour = contour.flatten().tolist()\n            self.draw_polygon(contour, color, alpha=alpha)\n\n        if edge_color is not None:\n            for contour in contours:\n                contour = contour.flatten().tolist()\n                self.draw_polygon(contour, edge_color, alpha=alpha, fill=False)\n\n        if text is not None:\n            mask = binary_mask.astype(bool)\n            y, x = np.unravel_index(mask.argmax(), mask.shape)\n            self.draw_text(text, (x, y), color=color)\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if binary_mask is None:\n            return self.output\n\n        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        mask = np.asarray(binary_mask, dtype=np.uint8)\n        contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n\n        for contour in contours:\n            area = cv2.contourArea(contour)\n            if area < area_threshold:\n                continue\n\n            if edge_color is not None:\n                self.output.ax.add_patch(\n                    mpl.patches.PathPatch(\n                        mpl.path.Path(contour.squeeze(), closed=True),\n                        facecolor=color,\n                        edgecolor=edge_color,\n                        alpha=alpha,\n                    )\n                )\n            else:\n                self.output.ax.add_patch(\n                    mpl.patches.PathPatch(\n                        mpl.path.Path(contour.squeeze(), closed=True), facecolor=color, alpha=alpha\n                    )\n                )\n\n        if text is not None:\n            for contour in contours:\n                M = cv2.moments(contour)\n                if M[\"m00\"] != 0:\n                    cX = int(M[\"m10\"] / M[\"m00\"])\n                    cY = int(M[\"m01\"] / M[\"m00\"])\n                    self.draw_text(text, (cX, cY), color=color, font_size=10)\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        mask = binary_mask.astype(np.uint8)\n        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n        for contour in contours:\n            if cv2.contourArea(contour) < area_threshold:\n                continue\n            if color is None:\n                color = random_color(rgb=True, maximum=1)\n            cv2.drawContours(self.output.img, [contour], -1, color, thickness=-1)\n            if edge_color is not None:\n                cv2.drawContours(self.output.img, [contour], -1, edge_color, thickness=2)\n            if text is not None:\n                moments = cv2.moments(contour)\n                if moments[\"m00\"] != 0:\n                    cx = int(moments[\"m10\"] / moments[\"m00\"])\n                    cy = int(moments[\"m01\"] / moments[\"m00\"])\n                    self.draw_text(text, (cx, cy), color=edge_color, rotation=0)\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        mask = np.asarray(binary_mask, dtype=np.uint8)\n        mask = mask.astype(np.uint8)\n\n        # Find contours\n        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n        # Draw contours on the image\n        for contour in contours:\n            if cv2.contourArea(contour) >= area_threshold:\n                if color is None:\n                    color = random_color(rgb=True, maximum=1)\n                color = mplc.to_rgb(color)\n                color = [c * 255 for c in color]\n                color = tuple(color)\n\n                cv2.drawContours(self.output.img, [contour], -1, color, -1)\n\n                if edge_color is not None:\n                    edge_color = mplc.to_rgb(edge_color)\n                    edge_color = [c * 255 for c in edge_color]\n                    edge_color = tuple(edge_color)\n                    cv2.drawContours(self.output.img, [contour], -1, edge_color, 2)\n\n                if text is not None:\n                    M = cv2.moments(contour)\n                    cX = int(M[\"m10\"] / M[\"m00\"])\n                    cY = int(M[\"m01\"] / M[\"m00\"])\n                    cv2.putText(\n                        self.output.img,\n                        text,\n                        (cX, cY),\n                        cv2.FONT_HERSHEY_SIMPLEX,\n                        0.5,\n                        (255, 255, 255),\n                        2,\n                    )\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        binary_mask = np.asarray(binary_mask, dtype=np.uint8)\n        contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n        for contour in contours:\n            if cv2.contourArea(contour) < area_threshold:\n                continue\n\n            if edge_color is not None:\n                edge_color = mplc.to_rgb(edge_color)\n                edge_color = [c * 255 for c in edge_color]\n                edge_color = tuple(edge_color)\n                cv2.drawContours(self.output.img, [contour], -1, edge_color, 1)\n\n            if color is not None:\n                color = mplc.to_rgb(color)\n                color = [c * 255 for c in color]\n                color = tuple(color)\n                cv2.drawContours(self.output.img, [contour], -1, color, -1)\n\n            if text is not None:\n                x, y, w, h = cv2.boundingRect(contour)\n                cv2.putText(self.output.img, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1, cv2.LINE_AA)\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        mask = binary_mask.astype(np.uint8)\n        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n        for contour in contours:\n            area = cv2.contourArea(contour)\n            if area < area_threshold:\n                continue\n\n            if color is None:\n                color = random_color(rgb=True, maximum=1)\n\n            if edge_color is None:\n                edge_color = color\n\n            contour = contour.reshape(-1, 2)\n            self.draw_polygon(contour, color, edge_color, alpha)\n\n            if text is not None:\n                x, y, w, h = cv2.boundingRect(contour)\n                text_pos = (x + w // 2, y + h // 2)\n                self.draw_text(text, text_pos, color=edge_color)\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        mask = np.asarray(binary_mask, dtype=np.uint8)\n        mask = np.where(mask > 0, 255, 0).astype(np.uint8)  # Convert binary mask to grayscale\n\n        # Find contours of the mask\n        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n        # Draw the contours on the image\n        for contour in contours:\n            area = cv2.contourArea(contour)\n            if area >= area_threshold:\n                if color is None:\n                    color = random_color(rgb=True, maximum=1)  # Random color if not specified\n                if edge_color is None:\n                    edge_color = color  # Use the same color for edges if not specified\n\n                # Draw filled polygon\n                cv2.drawContours(self.output.img, [contour], -1, color, thickness=cv2.FILLED)\n\n                # Draw polygon edges\n                cv2.drawContours(self.output.img, [contour], -1, edge_color, thickness=2)\n\n                # Draw text on the mask\n                if text is not None:\n                    moments = cv2.moments(contour)\n                    centroid_x = int(moments[\"m10\"] / moments[\"m00\"])\n                    centroid_y = int(moments[\"m01\"] / moments[\"m00\"])\n                    cv2.putText(\n                        self.output.img,\n                        text,\n                        (centroid_x, centroid_y),\n                        cv2.FONT_HERSHEY_SIMPLEX,\n                        0.5,\n                        color,\n                        2,\n                    )\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        mask = np.asarray(binary_mask, dtype=np.uint8)\n        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n        \n        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        \n        for contour in contours:\n            if cv2.contourArea(contour) < area_threshold:\n                continue\n            cv2.drawContours(self.output.img, [contour], -1, color, -1)\n            if edge_color is not None:\n                cv2.drawContours(self.output.img, [contour], -1, edge_color, 2)\n            if text is not None:\n                moments = cv2.moments(contour)\n                centroid_x = int(moments[\"m10\"] / moments[\"m00\"])\n                centroid_y = int(moments[\"m01\"] / moments[\"m00\"])\n                self.draw_text(text, (centroid_x, centroid_y), color, rotation=0)\n        \n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "    if color is None:\n        color = random_color(rgb=True, maximum=1)\n    if edge_color is None:\n        edge_color = color\n\n    mask = np.asarray(binary_mask, dtype=np.uint8)\n    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n    for contour in contours:\n        area = cv2.contourArea(contour)\n        if area < area_threshold:\n            continue\n\n        if text is not None:\n            M = cv2.moments(contour)\n            if M[\"m00\"] != 0:\n                cX = int(M[\"m10\"] / M[\"m00\"])\n                cY = int(M[\"m01\"] / M[\"m00\"])\n                self.draw_text(text, (cX, cY), color=edge_color, font_size=10)\n\n        contour = contour.reshape(-1, 2)\n        self.draw_polygon(contour, color, edge_color, alpha)\n\n    return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        mask = np.ascontiguousarray(binary_mask).astype(\"uint8\")\n        res = cv2.findContours(mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n        contours = res[-2]\n        hierarchy = res[-1]\n\n        for i in range(len(contours)):\n            if cv2.contourArea(contours[i]) < area_threshold:\n                continue\n            color = color if color is not None else random_color(rgb=True, maximum=1)\n            edge_color = edge_color if edge_color is not None else color\n            cv2.drawContours(self.output.img, contours, i, color, -1)\n            cv2.drawContours(self.output.img, contours, i, edge_color, 2)\n\n            if text is not None:\n                x, y, w, h = cv2.boundingRect(contours[i])\n                self.draw_text(text, (x, y), color=edge_color, font_size=10)\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "    if color is None:\n        color = random_color(rgb=True, maximum=1)\n    mask = np.asarray(binary_mask, dtype=np.uint8)\n    mask = np.where(mask > 0, 1, 0)\n    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    for contour in contours:\n        area = cv2.contourArea(contour)\n        if area < area_threshold:\n            continue\n        if edge_color is None:\n            edge_color = color\n        cv2.drawContours(self.output.img, [contour], -1, color, thickness=-1)\n        cv2.drawContours(self.output.img, [contour], -1, edge_color, thickness=2)\n        if text is not None:\n            moments = cv2.moments(contour)\n            if moments[\"m00\"] != 0:\n                cx = int(moments[\"m10\"] / moments[\"m00\"])\n                cy = int(moments[\"m01\"] / moments[\"m00\"])\n                self.draw_text(text, (cx, cy), color=edge_color, font_size=10)\n    return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        mask = np.ascontiguousarray(binary_mask).astype(\"uint8\")\n        res = cv2.findContours(mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n        contours = res[-2]\n        hierarchy = res[-1]\n        for i in range(len(contours)):\n            if cv2.contourArea(contours[i]) < area_threshold:\n                continue\n            color = color if color is not None else random_color(rgb=True, maximum=1)\n            cv2.drawContours(self.output.img, contours, i, color, -1, cv2.LINE_8, hierarchy, 0)\n            if edge_color is not None:\n                cv2.drawContours(self.output.img, contours, i, edge_color, 2, cv2.LINE_8, hierarchy, 0)\n            if text is not None:\n                x, y, w, h = cv2.boundingRect(contours[i])\n                cv2.putText(self.output.img, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        mask = binary_mask.astype(np.uint8)\n        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n        for contour in contours:\n            area = cv2.contourArea(contour)\n            if area < area_threshold:\n                continue\n\n            if edge_color is not None:\n                edge_color = mplc.to_rgba(edge_color, alpha)\n                self.output.ax.add_patch(\n                    mpl.patches.PathPatch(\n                        mpl.path.Path(contour.squeeze(), closed=True),\n                        facecolor=color,\n                        edgecolor=edge_color,\n                        alpha=alpha,\n                    )\n                )\n            else:\n                self.output.ax.add_patch(\n                    mpl.patches.PathPatch(\n                        mpl.path.Path(contour.squeeze(), closed=True), facecolor=color, alpha=alpha\n                    )\n                )\n\n            if text is not None:\n                x, y, _, _ = cv2.boundingRect(contour)\n                self.draw_text(text, (x, y), color=color)\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        if edge_color is None:\n            edge_color = color\n\n        mask = binary_mask.astype(np.uint8)\n        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n        for contour in contours:\n            area = cv2.contourArea(contour)\n            if area < area_threshold:\n                continue\n\n            if text is not None:\n                moments = cv2.moments(contour)\n                if moments[\"m00\"] != 0:\n                    cx = int(moments[\"m10\"] / moments[\"m00\"])\n                    cy = int(moments[\"m01\"] / moments[\"m00\"])\n                    self.draw_text(text, (cx, cy), color=edge_color)\n\n            contour = contour.reshape(-1, 2)\n            self.draw_polygon(contour, color, edge_color, alpha)\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if binary_mask.sum() < area_threshold:\n            return self.output\n\n        # Convert binary mask to polygon mask\n        mask = np.ascontiguousarray(binary_mask, dtype=np.uint8)\n        res = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n        contours, _ = res\n        polygons = [c.reshape(-1).tolist() for c in contours]\n\n        # Draw the mask\n        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        self.output.ax.add_patch(\n            mpl.patches.Polygon(polygons[0].reshape((-1, 2)), fill=True, color=color, alpha=alpha)\n        )\n\n        # Draw the edge of the mask\n        if edge_color is not None:\n            for polygon in polygons:\n                self.output.ax.add_patch(\n                    mpl.patches.Polygon(\n                        polygon.reshape((-1, 2)),\n                        fill=False,\n                        edgecolor=edge_color,\n                        linewidth=self._default_font_size / 4,\n                    )\n                )\n\n        # Draw text on the mask\n        if text is not None:\n            bbox = mask_util.toBbox(mask_util.frPyObjects([polygons], binary_mask.shape[0], binary_mask.shape[1]))\n            text_pos = (bbox[0], bbox[1])\n            self.draw_text(text, text_pos, color=color, font_size=self._default_font_size)\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        # Convert binary mask to polygon mask\n        contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n        polygons = [c.reshape(-1) for c in contours]\n\n        # Draw the polygon mask\n        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        self.overlay_instances(\n            masks=[polygons],\n            assigned_colors=[color],\n            alpha=alpha\n        )\n\n        # Draw edge of the mask\n        if edge_color is not None:\n            for polygon in polygons:\n                self.draw_polygon(polygon.reshape(-1, 2), edge_color, alpha=alpha)\n\n        # Draw text on the mask\n        if text is not None:\n            bbox = cv2.boundingRect(binary_mask)\n            text_pos = (bbox[0], bbox[1])\n            self.draw_text(text, text_pos, color=edge_color, font_size=10)\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        mask = np.ascontiguousarray(binary_mask).astype(\"uint8\")\n        res = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n        contours = res[-2]\n        if len(contours) == 0:\n            return self.output\n\n        if area_threshold is not None:\n            contours = [c for c in contours if cv2.contourArea(c) >= area_threshold]\n\n        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        for contour in contours:\n            contour = contour.flatten()\n            polygon = contour.reshape(-1, 2)\n            self.draw_polygon(polygon, color, edge_color, alpha)\n\n        if text is not None:\n            x, y, w, h = cv2.boundingRect(contours[0])\n            text_pos = (x, y)\n            self.draw_text(text, text_pos, color, rotation=0)\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        binary_mask = binary_mask.astype(np.uint8)\n        contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n        for contour in contours:\n            area = cv2.contourArea(contour)\n            if area < area_threshold:\n                continue\n\n            if color is None:\n                color = random_color(rgb=True, maximum=1)\n            color = mplc.to_rgb(color)\n\n            if edge_color is not None:\n                edge_color = mplc.to_rgb(edge_color)\n\n            contour = contour.reshape(-1, 2)\n            if len(contour) > 2:\n                self.output.ax.fill(contour[:, 0], contour[:, 1], facecolor=color, edgecolor=edge_color, alpha=alpha)\n\n            if text is not None:\n                text_pos = contour.mean(axis=0)\n                self.draw_text(text, text_pos, color=color, font_size=self._default_font_size)\n\n        return self.output"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if size_as_tensor:\n        assert torch.allclose(input.image_size, other.image_size, rtol=rtol), msg\n    else:\n        assert input.image_size == other.image_size, msg\n\n    for field in input._field_names:\n        input_val = getattr(input, field)\n        other_val = getattr(other, field)\n\n        if isinstance(input_val, Boxes):\n            assert torch.allclose(input_val.tensor, other_val.tensor, rtol=rtol), msg\n        elif isinstance(input_val, ROIMasks):\n            assert torch.allclose(input_val.tensor, other_val.tensor, rtol=rtol), msg\n        elif isinstance(input_val, torch.Tensor):\n            assert torch.allclose(input_val, other_val, rtol=rtol), msg\n        else:\n            assert input_val == other_val, msg"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert isinstance(input, Instances) and isinstance(other, Instances), \"input and other must be Instances\"\n    if size_as_tensor:\n        assert torch.equal(input.image_size, other.image_size), \"image sizes do not match\"\n    else:\n        assert input.image_size == other.image_size, \"image sizes do not match\"\n\n    for field in input.get_fields().keys():\n        input_field = input.get(field)\n        other_field = other.get(field)\n        if isinstance(input_field, Boxes):\n            assert torch.allclose(input_field.tensor, other_field.tensor, rtol=rtol), f\"{field} does not match\"\n        elif isinstance(input_field, ROIMasks):\n            assert torch.allclose(input_field.tensor, other_field.tensor, rtol=rtol), f\"{field} does not match\"\n        elif isinstance(input_field, torch.Tensor):\n            assert torch.allclose(input_field, other_field, rtol=rtol), f\"{field} does not match\"\n        else:\n            assert input_field == other_field, f\"{field} does not match\"\n\n    print(\"Instances all close assertion passed.\")"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    # Check if the image sizes are the same\n    if size_as_tensor:\n        assert torch.allclose(input.image_size, other.image_size, rtol=rtol), msg\n    else:\n        assert input.image_size == other.image_size, msg\n\n    # Check if all fields are equal or close to each other\n    for field in input._field_names:\n        input_val = getattr(input, field)\n        other_val = getattr(other, field)\n\n        if isinstance(input_val, Boxes):\n            assert torch.allclose(input_val.tensor, other_val.tensor, rtol=rtol), msg\n        elif isinstance(input_val, ROIMasks):\n            assert torch.allclose(input_val.tensor, other_val.tensor, rtol=rtol), msg\n        elif isinstance(input_val, torch.Tensor):\n            assert torch.allclose(input_val, other_val, rtol=rtol), msg\n        else:\n            assert input_val == other_val, msg"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if size_as_tensor:\n        assert torch.allclose(input.image_size, other.image_size, rtol=rtol), msg\n    else:\n        assert input.image_size == other.image_size, msg\n\n    for field in input._field_names:\n        if isinstance(getattr(input, field), Boxes):\n            assert torch.allclose(\n                getattr(input, field).tensor, getattr(other, field).tensor, rtol=rtol\n            ), msg\n        elif isinstance(getattr(input, field), ROIMasks):\n            assert torch.allclose(\n                getattr(input, field).tensor, getattr(other, field).tensor, rtol=rtol\n            ), msg\n        elif isinstance(getattr(input, field), torch.Tensor):\n            assert torch.allclose(\n                getattr(input, field), getattr(other, field), rtol=rtol\n            ), msg\n        else:\n            assert getattr(input, field) == getattr(other, field), msg"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if size_as_tensor:\n        assert torch.allclose(\n            input.image_size, other.image_size, rtol=rtol\n        ), f\"{msg}image_size does not match\"\n    else:\n        assert input.image_size == other.image_size, f\"{msg}image_size does not match\"\n\n    for field in input.get_fields():\n        input_val = input[field]\n        other_val = other[field]\n\n        if isinstance(input_val, Boxes):\n            assert torch.allclose(\n                input_val.tensor, other_val.tensor, rtol=rtol\n            ), f\"{msg}{field} does not match\"\n        elif isinstance(input_val, ROIMasks):\n            assert torch.allclose(\n                input_val.tensor, other_val.tensor, rtol=rtol\n            ), f\"{msg}{field} does not match\"\n        elif isinstance(input_val, torch.Tensor):\n            assert torch.allclose(\n                input_val, other_val, rtol=rtol\n            ), f\"{msg}{field} does not match\"\n        else:\n            assert input_val == other_val, f\"{msg}{field} does not match\""}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert isinstance(input, Instances) and isinstance(other, Instances), \"Input and other must be instances of the Instances class\"\n    assert input.image_size == other.image_size, \"Image sizes are not the same\"\n\n    for field in input.get_fields().keys():\n        input_field = getattr(input, field)\n        other_field = getattr(other, field)\n\n        if isinstance(input_field, Boxes):\n            assert torch.allclose(input_field.tensor, other_field.tensor, rtol=rtol), f\"{msg}Field {field} does not match\"\n        elif isinstance(input_field, ROIMasks):\n            assert torch.allclose(input_field.masks, other_field.masks, rtol=rtol), f\"{msg}Field {field} does not match\"\n        elif isinstance(input_field, torch.Tensor):\n            if size_as_tensor:\n                assert torch.allclose(input_field, other_field, rtol=rtol), f\"{msg}Field {field} does not match\"\n            else:\n                assert input_field.equal(other_field), f\"{msg}Field {field} does not match\"\n        else:\n            assert input_field == other_field, f\"{msg}Field {field} does not match\""}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if size_as_tensor:\n        assert torch.allclose(\n            input.image_size, other.image_size, atol=0, rtol=rtol\n        ), f\"{msg}image_size mismatch: {input.image_size} vs {other.image_size}\"\n    else:\n        assert input.image_size == other.image_size, f\"{msg}image_size mismatch: {input.image_size} vs {other.image_size}\"\n\n    for field in input._field_names:\n        input_val = getattr(input, field)\n        other_val = getattr(other, field)\n\n        if isinstance(input_val, Boxes):\n            assert isinstance(other_val, Boxes)\n            assert torch.allclose(\n                input_val.tensor, other_val.tensor, atol=0, rtol=rtol\n            ), f\"{msg}Field {field} mismatch: {input_val} vs {other_val}\"\n\n        elif isinstance(input_val, ROIMasks):\n            assert isinstance(other_val, ROIMasks)\n            assert torch.allclose(\n                input_val.tensor, other_val.tensor, atol=0, rtol=rtol\n            ), f\"{msg}Field {field} mismatch: {input_val} vs {other_val}\"\n\n        elif isinstance(input_val, torch.Tensor):\n            assert torch.allclose(\n                input_val, other_val, atol=0, rtol=rtol\n            ), f\"{msg}Field {field} mismatch: {input_val} vs {other_val}\"\n\n        else:\n            assert input_val == other_val, f\"{msg}Field {field} mismatch: {input_val} vs {other_val}\""}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "\n    if size_as_tensor:\n        assert torch.allclose(input.image_size, other.image_size, rtol=rtol), msg\n    else:\n        assert input.image_size == other.image_size, msg\n\n    for field in input._field_names:\n        input_val = getattr(input, field)\n        other_val = getattr(other, field)\n\n        if isinstance(input_val, Boxes):\n            assert torch.allclose(input_val.tensor, other_val.tensor, rtol=rtol), msg\n        elif isinstance(input_val, ROIMasks):\n            assert torch.allclose(input_val.tensor, other_val.tensor, rtol=rtol), msg\n        elif isinstance(input_val, torch.Tensor):\n            assert torch.allclose(input_val, other_val, rtol=rtol), msg\n        else:\n            assert input_val == other_val, msg"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if size_as_tensor:\n        assert torch.allclose(\n            input.image_size, other.image_size, rtol=rtol\n        ), f\"{msg}Image sizes do not match: {input.image_size} vs {other.image_size}\"\n    else:\n        assert input.image_size == other.image_size, f\"{msg}Image sizes do not match: {input.image_size} vs {other.image_size}\"\n\n    for field in input.get_fields():\n        if isinstance(getattr(input, field), Boxes):\n            assert torch.allclose(\n                getattr(input, field).tensor, getattr(other, field).tensor, rtol=rtol\n            ), f\"{msg}Field {field} does not match\"\n        elif isinstance(getattr(input, field), ROIMasks):\n            assert torch.allclose(\n                getattr(input, field).mask, getattr(other, field).mask, rtol=rtol\n            ), f\"{msg}Field {field} does not match\"\n        elif isinstance(getattr(input, field), torch.Tensor):\n            assert torch.allclose(\n                getattr(input, field), getattr(other, field), rtol=rtol\n            ), f\"{msg}Field {field} does not match\"\n        else:\n            assert getattr(input, field) == getattr(other, field), f\"{msg}Field {field} does not match\""}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if size_as_tensor:\n        assert torch.allclose(\n            input.image_size, other.image_size, rtol=rtol\n        ), f\"{msg}image_size do not match: {input.image_size} vs {other.image_size}\"\n    else:\n        assert input.image_size == other.image_size, f\"{msg}image_size do not match: {input.image_size} vs {other.image_size}\"\n\n    for field in input._field_names:\n        input_val = getattr(input, field)\n        other_val = getattr(other, field)\n\n        if isinstance(input_val, Boxes):\n            assert torch.allclose(\n                input_val.tensor, other_val.tensor, rtol=rtol\n            ), f\"{msg}Field {field} does not match: {input_val.tensor} vs {other_val.tensor}\"\n        elif isinstance(input_val, ROIMasks):\n            assert torch.allclose(\n                input_val.tensor, other_val.tensor, rtol=rtol\n            ), f\"{msg}Field {field} does not match: {input_val.tensor} vs {other_val.tensor}\"\n        elif isinstance(input_val, torch.Tensor):\n            assert torch.allclose(\n                input_val, other_val, rtol=rtol\n            ), f\"{msg}Field {field} does not match: {input_val} vs {other_val}\"\n        else:\n            assert input_val == other_val, f\"{msg}Field {field} does not match: {input_val} vs {other_val}\""}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert isinstance(input, Instances) and isinstance(other, Instances), \"input and other must be Instances\"\n    assert input.image_size == other.image_size, \"image sizes do not match\"\n\n    for field in input.get_fields():\n        input_field = input.get(field)\n        other_field = other.get(field)\n\n        if isinstance(input_field, Boxes):\n            assert torch.allclose(input_field.tensor, other_field.tensor, rtol=rtol), f\"{msg} Boxes field {field} not close\"\n        elif isinstance(input_field, ROIMasks):\n            assert torch.allclose(input_field.tensor, other_field.tensor, rtol=rtol), f\"{msg} ROIMasks field {field} not close\"\n        elif isinstance(input_field, torch.Tensor):\n            assert torch.allclose(input_field, other_field, rtol=rtol), f\"{msg} Tensor field {field} not close\"\n        else:\n            assert input_field == other_field, f\"{msg} Field {field} not equal\""}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "\n    if size_as_tensor:\n        assert torch.allclose(input.image_size, other.image_size, rtol=rtol), f\"{msg}Image sizes do not match\"\n    else:\n        assert input.image_size == other.image_size, f\"{msg}Image sizes do not match\"\n\n    for field in input._field_names:\n        input_val = getattr(input, field)\n        other_val = getattr(other, field)\n\n        if isinstance(input_val, Boxes):\n            assert torch.allclose(input_val.tensor, other_val.tensor, rtol=rtol), f\"{msg}Field {field} does not match\"\n        elif isinstance(input_val, ROIMasks):\n            assert torch.allclose(input_val.tensor, other_val.tensor, rtol=rtol), f\"{msg}Field {field} does not match\"\n        elif isinstance(input_val, torch.Tensor):\n            assert torch.allclose(input_val, other_val, rtol=rtol), f\"{msg}Field {field} does not match\"\n        else:\n            assert input_val == other_val, f\"{msg}Field {field} does not match\""}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if size_as_tensor:\n        assert torch.allclose(\n            input.image_size, other.image_size, rtol=rtol\n        ), f\"{msg}image_size mismatch: {input.image_size} vs {other.image_size}\"\n    else:\n        assert input.image_size == other.image_size, f\"{msg}image_size mismatch: {input.image_size} vs {other.image_size}\"\n\n    for field in input._field_names:\n        input_val = getattr(input, field)\n        other_val = getattr(other, field)\n        if isinstance(input_val, Boxes):\n            assert torch.allclose(\n                input_val.tensor, other_val.tensor, rtol=rtol\n            ), f\"{msg}{field} mismatch\"\n        elif isinstance(input_val, ROIMasks):\n            assert torch.allclose(\n                input_val.tensor, other_val.tensor, rtol=rtol\n            ), f\"{msg}{field} mismatch\"\n        elif isinstance(input_val, torch.Tensor):\n            assert torch.allclose(\n                input_val, other_val, rtol=rtol\n            ), f\"{msg}{field} mismatch\"\n        else:\n            assert input_val == other_val, f\"{msg}{field} mismatch\""}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if size_as_tensor:\n        assert torch.allclose(input.image_size, other.image_size, rtol=rtol), f\"{msg}image_size mismatch\"\n    else:\n        assert input.image_size == other.image_size, f\"{msg}image_size mismatch\"\n\n    for name in input._field_names:\n        if name == \"image_size\":\n            continue\n        input_val = getattr(input, name)\n        other_val = getattr(other, name)\n        if isinstance(input_val, Boxes):\n            assert torch.allclose(input_val.tensor, other_val.tensor, rtol=rtol), f\"{msg}{name} mismatch\"\n        elif isinstance(input_val, ROIMasks):\n            assert torch.allclose(input_val.tensor, other_val.tensor, rtol=rtol), f\"{msg}{name} mismatch\"\n        elif isinstance(input_val, torch.Tensor):\n            assert torch.allclose(input_val, other_val, rtol=rtol), f\"{msg}{name} mismatch\"\n        else:\n            assert input_val == other_val, f\"{msg}{name} mismatch\""}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "\n    # Check if the image sizes are the same\n    if size_as_tensor:\n        assert torch.allclose(input.image_size, other.image_size, rtol=rtol), f\"{msg}Image sizes do not match\"\n    else:\n        assert input.image_size == other.image_size, f\"{msg}Image sizes do not match\"\n\n    # Verify that all fields within the instances are equal or close to each other\n    for field in input._field_names:\n        input_val = getattr(input, field)\n        other_val = getattr(other, field)\n\n        if isinstance(input_val, Boxes):\n            assert torch.allclose(input_val.tensor, other_val.tensor, rtol=rtol), f\"{msg}Field {field} does not match\"\n        elif isinstance(input_val, ROIMasks):\n            assert torch.allclose(input_val.tensor, other_val.tensor, rtol=rtol), f\"{msg}Field {field} does not match\"\n        elif isinstance(input_val, torch.Tensor):\n            assert torch.allclose(input_val, other_val, rtol=rtol), f\"{msg}Field {field} does not match\"\n        else:\n            assert input_val == other_val, f\"{msg}Field {field} does not match\""}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if size_as_tensor:\n        assert torch.allclose(\n            input.image_size, other.image_size, rtol=rtol\n        ), f\"{msg}Image sizes do not match: {input.image_size} vs {other.image_size}\"\n    else:\n        assert input.image_size == other.image_size, f\"{msg}Image sizes do not match: {input.image_size} vs {other.image_size}\"\n\n    for field in input._field_names:\n        if field == \"image_size\":\n            continue\n        input_val = getattr(input, field)\n        other_val = getattr(other, field)\n\n        if isinstance(input_val, Boxes):\n            assert torch.allclose(\n                input_val.tensor, other_val.tensor, rtol=rtol\n            ), f\"{msg}Field {field} does not match: {input_val} vs {other_val}\"\n        elif isinstance(input_val, ROIMasks):\n            assert torch.allclose(\n                input_val.tensor, other_val.tensor, rtol=rtol\n            ), f\"{msg}Field {field} does not match: {input_val} vs {other_val}\"\n        elif isinstance(input_val, torch.Tensor):\n            assert torch.allclose(\n                input_val, other_val, rtol=rtol\n            ), f\"{msg}Field {field} does not match: {input_val} vs {other_val}\"\n        else:\n            assert input_val == other_val, f\"{msg}Field {field} does not match: {input_val} vs {other_val}\""}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if size_as_tensor:\n        assert torch.allclose(\n            input.image_size, other.image_size, rtol=rtol\n        ), f\"{msg}image_size does not match\"\n    else:\n        assert input.image_size == other.image_size, f\"{msg}image_size does not match\"\n\n    for field in input._field_names:\n        input_val = getattr(input, field)\n        other_val = getattr(other, field)\n        if isinstance(input_val, Boxes):\n            assert torch.allclose(\n                input_val.tensor, other_val.tensor, rtol=rtol\n            ), f\"{msg}Field {field} does not match\"\n        elif isinstance(input_val, ROIMasks):\n            assert torch.allclose(\n                input_val.tensor, other_val.tensor, rtol=rtol\n            ), f\"{msg}Field {field} does not match\"\n        elif isinstance(input_val, torch.Tensor):\n            assert torch.allclose(\n                input_val, other_val, rtol=rtol\n            ), f\"{msg}Field {field} does not match\"\n        else:\n            assert input_val == other_val, f\"{msg}Field {field} does not match\""}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if size_as_tensor:\n        assert torch.allclose(\n            input.image_size, other.image_size, rtol=rtol\n        ), f\"{msg}Image sizes do not match: {input.image_size} vs {other.image_size}\"\n    else:\n        assert input.image_size == other.image_size, f\"{msg}Image sizes do not match: {input.image_size} vs {other.image_size}\"\n\n    for field in input._field_names:\n        input_val = getattr(input, field)\n        other_val = getattr(other, field)\n\n        if isinstance(input_val, Boxes):\n            assert torch.allclose(\n                input_val.tensor, other_val.tensor, rtol=rtol\n            ), f\"{msg}Field {field} does not match\"\n        elif isinstance(input_val, ROIMasks):\n            assert torch.allclose(\n                input_val.tensor, other_val.tensor, rtol=rtol\n            ), f\"{msg}Field {field} does not match\"\n        elif isinstance(input_val, torch.Tensor):\n            assert torch.allclose(\n                input_val, other_val, rtol=rtol\n            ), f\"{msg}Field {field} does not match\"\n        else:\n            assert input_val == other_val, f\"{msg}Field {field} does not match\""}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    # Check if the image sizes are the same\n    if size_as_tensor:\n        assert torch.allclose(input.image_size, other.image_size, rtol=rtol), f\"{msg}Image sizes do not match: {input.image_size} vs {other.image_size}\"\n    else:\n        assert input.image_size == other.image_size, f\"{msg}Image sizes do not match: {input.image_size} vs {other.image_size}\"\n\n    # Check if all fields within the instances are equal or close to each other\n    for name in input._field_names:\n        val_input = getattr(input, name)\n        val_other = getattr(other, name)\n        \n        # Special handling for fields that are of type Boxes, ROIMasks, or torch.Tensor\n        if isinstance(val_input, Boxes):\n            assert torch.allclose(val_input.tensor, val_other.tensor, rtol=rtol), f\"{msg}Field {name} does not match\"\n        elif isinstance(val_input, ROIMasks):\n            assert torch.allclose(val_input.tensor, val_other.tensor, rtol=rtol), f\"{msg}Field {name} does not match\"\n        elif isinstance(val_input, torch.Tensor):\n            assert torch.allclose(val_input, val_other, rtol=rtol), f\"{msg}Field {name} does not match\"\n        else:\n            assert val_input == val_other, f\"{msg}Field {name} does not match\""}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    # Check if the image sizes are the same\n    if size_as_tensor:\n        assert torch.allclose(input.image_size, other.image_size, rtol=rtol), msg\n    else:\n        assert input.image_size == other.image_size, msg\n\n    # Check if all fields within the instances are equal or close to each other\n    for name in input._field_names:\n        val_input = getattr(input, name)\n        val_other = getattr(other, name)\n\n        if isinstance(val_input, Boxes):\n            assert torch.allclose(val_input.tensor, val_other.tensor, rtol=rtol), msg\n        elif isinstance(val_input, ROIMasks):\n            assert torch.allclose(val_input.tensor, val_other.tensor, rtol=rtol), msg\n        elif isinstance(val_input, torch.Tensor):\n            assert torch.allclose(val_input, val_other, rtol=rtol), msg\n        else:\n            assert np.allclose(val_input, val_other, rtol=rtol), msg"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    obj = pydoc.locate(name)\n    if obj is None:\n        raise ImportError(f\"Error locating object: {name}\")\n    return obj"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    try:\n        return pydoc.locate(name)\n    except ImportError:\n        raise ImportError(f\"Object '{name}' not found using standard method and fallback method.\")"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    obj = pydoc.locate(name)\n    if obj is None:\n        raise ImportError(f\"Error locating object: {name}\")\n    return obj"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    obj = pydoc.locate(name)\n    if obj is None:\n        raise ImportError(f\"Error: Cannot locate object '{name}' using standard method.\")\n    return obj"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    obj = pydoc.locate(name)\n    if obj is None:\n        raise ImportError(f\"Error locating {name}\")\n    return obj"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    obj = pydoc.locate(name)\n    if obj is not None:\n        return obj\n    else:\n        raise ImportError(f\"Could not locate object: {name}\")"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    try:\n        return pydoc.locate(name)\n    except ImportError:\n        pass\n\n    parts = name.split('.')\n    obj = pydoc.locate(parts[0])\n    for part in parts[1:]:\n        obj = getattr(obj, part)\n\n    if obj is None:\n        raise ImportError(f\"Could not locate object '{name}'\")\n\n    return obj"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    try:\n        return pydoc.locate(name)\n    except ImportError:\n        # Fallback method\n        components = name.split('.')\n        mod = __import__('.'.join(components[:-1]), fromlist=[components[-1]])\n        return getattr(mod, components[-1])"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    obj = pydoc.locate(name)\n    if obj is None:\n        raise ImportError(f\"Error locating object: {name}\")\n    return obj"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    obj = pydoc.locate(name)\n    if obj is not None:\n        return obj\n    else:\n        raise ImportError(f\"Cannot locate object {name}\")"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    obj = pydoc.locate(name)\n    if obj is None:\n        raise ImportError(f\"Error: Cannot locate object '{name}'\")\n    return obj"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    try:\n        return pydoc.locate(name)\n    except ImportError:\n        pass\n\n    # Fallback method\n    parts = name.split('.')\n    module_name, obj_name = '.'.join(parts[:-1]), parts[-1]\n    module = __import__(module_name, fromlist=[obj_name])\n    return getattr(module, obj_name)"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    obj = pydoc.locate(name)\n    if obj is None:\n        raise ImportError(f\"Error locating object {name}\")\n    return obj"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # Standard method to locate the object\n    obj = pydoc.locate(name)\n    if obj is not None:\n        return obj\n\n    # Fallback method to locate the object\n    try:\n        parts = name.rsplit(\".\", 1)\n        mod_name = parts[0]\n        obj_name = parts[1]\n        mod = __import__(mod_name, fromlist=[obj_name])\n        return getattr(mod, obj_name)\n    except (ImportError, AttributeError) as e:\n        raise ImportError(f\"Error locating object '{name}': {e}\")"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    obj = pydoc.locate(name)\n    if obj is None:\n        raise ImportError(f\"Error locating object: {name}\")\n    return obj"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    obj = pydoc.locate(name)\n    if obj is None:\n        raise ImportError(f\"Error locating object: {name}\")\n    return obj"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    try:\n        return pydoc.locate(name)\n    except ImportError:\n        raise ImportError(f\"Cannot locate object {name}\")"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    obj = pydoc.locate(name)\n    if obj is None:\n        raise ImportError(f\"Error locating object: {name}\")\n    return obj"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    obj = pydoc.locate(name)\n    if obj is None:\n        raise ImportError(f\"Error locating object {name}\")\n    return obj"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    try:\n        obj = pydoc.locate(name)\n        if obj is not None:\n            return obj\n    except (ImportError, AttributeError):\n        pass\n\n    # Fallback method\n    try:\n        obj = Registry.get(name)\n        if obj is not None:\n            return obj\n    except KeyError:\n        pass\n\n    raise ImportError(f\"Object {name} not found\")"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "\n    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "\n    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "\n    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "\n    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "\n    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "\n    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "\n    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "\n    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "\n    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "\n    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "\n    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "\n    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "\n    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "\n    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "\n    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "\n    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "\n    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "\n    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "\n    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "\n    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "\n    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError(f\"Segmentor model of type {cfg['type']} is not implemented.\")"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError(f\"Segmentor model of type {cfg['type']} is not implemented yet.\")"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError(f\"Segmentor model of type {cfg['type']} is not implemented yet\")"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError(f\"Segmentor model of type {cfg['type']} is not implemented yet\")"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError(f\"Segmentor model of type {cfg['type']} is not implemented yet\")"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "\n    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError(f\"Segmentor model of type '{cfg['type']}' is not implemented.\")"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError(f\"Segmentor model of type {cfg['type']} is not implemented yet\")"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError(f\"Segmentor model of type '{cfg['type']}' is not implemented yet\")"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "\n    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError(f\"Segmentor model of type {cfg['type']} is not implemented yet.\")"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError(f\"Unsupported segmentor type {cfg['type']}\")"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError(f\"Segmentor model of type {cfg['type']} is not implemented yet.\")"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError(f\"Segmentor model of type '{cfg['type']}' is not implemented yet.\")"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError(f\"Segmentor model of type {cfg['type']} is not implemented yet.\")"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError(f\"Segmentor of type '{cfg['type']}' is not implemented yet.\")"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError(f\"Segmentor model of type {cfg['type']} is not implemented.\")"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "\n    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError(f\"Segmentor model of type '{cfg['type']}' is not implemented.\")"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "\n    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise NotImplementedError(f\"Segmentor model of type {cfg['type']} is not implemented yet.\")"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "\n    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None:\n        warnings.warn('train_cfg is specified in build_detector function. It is recommended to specify it in the model configuration.')\n    if test_cfg is not None:\n        warnings.warn('test_cfg is specified in build_detector function. It is recommended to specify it in the model configuration.')\n\n    if 'train_cfg' in cfg and train_cfg is not None:\n        assert cfg['train_cfg'] == train_cfg, 'train_cfg is duplicated in both the outer field and model field.'\n    if 'test_cfg' in cfg and test_cfg is not None:\n        assert cfg['test_cfg'] == test_cfg, 'test_cfg is duplicated in both the outer field and model field.'\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, train_cfg, test_cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg, train_cfg, test_cfg)"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None:\n        warnings.warn('train_cfg is specified directly, which is not recommended. '\n                      'It should be specified in the model configuration.')\n    if test_cfg is not None:\n        warnings.warn('test_cfg is specified directly, which is not recommended. '\n                      'It should be specified in the model configuration.')\n\n    assert 'train_cfg' not in cfg, '\"train_cfg\" should not be duplicated in the model field and the outer field'\n    assert 'test_cfg' not in cfg, '\"test_cfg\" should not be duplicated in the model field and the outer field'\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None:\n        warnings.warn('train_cfg is specified in build_detector function. '\n                      'It is recommended to specify it in the model config, '\n                      'rather than passing it to the build_detector function')\n    if test_cfg is not None:\n        warnings.warn('test_cfg is specified in build_detector function. '\n                      'It is recommended to specify it in the model config, '\n                      'rather than passing it to the build_detector function')\n\n    if 'train_cfg' in cfg and train_cfg is not None:\n        assert cfg['train_cfg'] == train_cfg, (\n            'train_cfg is specified in both the outer field and model field, '\n            'which is ambiguous.')\n    if 'test_cfg' in cfg and test_cfg is not None:\n        assert cfg['test_cfg'] == test_cfg, (\n            'test_cfg is specified in both the outer field and model field, '\n            'which is ambiguous.')\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, train_cfg, test_cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg, train_cfg, test_cfg)"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None:\n        warnings.warn('train_cfg is specified in build_detector function. It should be specified in the model configuration.')\n    if test_cfg is not None:\n        warnings.warn('test_cfg is specified in build_detector function. It should be specified in the model configuration.')\n\n    assert 'train_cfg' not in cfg, 'train_cfg should not be duplicated in the outer field and model field'\n    assert 'test_cfg' not in cfg, 'test_cfg should not be duplicated in the outer field and model field'\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, train_cfg, test_cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg, train_cfg, test_cfg)"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None:\n        warnings.warn('train_cfg is specified in build_detector function. It should be specified in the model field.')\n    if test_cfg is not None:\n        warnings.warn('test_cfg is specified in build_detector function. It should be specified in the model field.')\n\n    assert 'train_cfg' not in cfg, 'train_cfg is duplicated in the outer field and model field'\n    assert 'test_cfg' not in cfg, 'test_cfg is duplicated in the outer field and model field'\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, train_cfg, test_cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg, train_cfg, test_cfg)"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None:\n        warnings.warn('train_cfg is specified in build_detector function. It should be specified in the model configuration')\n    if test_cfg is not None:\n        warnings.warn('test_cfg is specified in build_detector function. It should be specified in the model configuration')\n\n    assert 'train_cfg' not in cfg, 'train_cfg should not be duplicated in the outer field and model field'\n    assert 'test_cfg' not in cfg, 'test_cfg should not be duplicated in the outer field and model field'\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, train_cfg, test_cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg, train_cfg, test_cfg)"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None:\n        warnings.warn('train_cfg is specified directly, which is not recommended. '\n                      'It should be specified in the model field of the config.')\n    if test_cfg is not None:\n        warnings.warn('test_cfg is specified directly, which is not recommended. '\n                      'It should be specified in the model field of the config.')\n\n    assert 'train_cfg' not in cfg, '`train_cfg` should be specified in the model field of the config'\n    assert 'test_cfg' not in cfg, '`test_cfg` should be specified in the model field of the config'\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, train_cfg, test_cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg, train_cfg, test_cfg)"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None:\n        warnings.warn('train_cfg is specified directly, which is not recommended. '\n                      'It should be specified in the model field of the config.')\n    if test_cfg is not None:\n        warnings.warn('test_cfg is specified directly, which is not recommended. '\n                      'It should be specified in the model field of the config.')\n\n    assert 'train_cfg' not in cfg, '`train_cfg` should not be specified in both the outer field and model field'\n    assert 'test_cfg' not in cfg, '`test_cfg` should not be specified in both the outer field and model field'\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None:\n        warnings.warn('train_cfg is being deprecated, please specify it in the model config')\n\n    if test_cfg is not None:\n        warnings.warn('test_cfg is being deprecated, please specify it in the model config')\n\n    assert 'train_cfg' not in cfg, '\"train_cfg\" should not be specified in both the outer field and model field'\n    assert 'test_cfg' not in cfg, '\"test_cfg\" should not be specified in both the outer field and model field'\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None:\n        warnings.warn('train_cfg is specified in build_detector function. It should be specified in the model field')\n    if test_cfg is not None:\n        warnings.warn('test_cfg is specified in build_detector function. It should be specified in the model field')\n\n    assert 'train_cfg' not in cfg, 'train_cfg is specified in both the outer field and model field'\n    assert 'test_cfg' not in cfg, 'test_cfg is specified in both the outer field and model field'\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, train_cfg, test_cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg, train_cfg, test_cfg)"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None:\n        warnings.warn('train_cfg is specified directly, which is not recommended. '\n                      'It should be specified in the model configuration.')\n    if test_cfg is not None:\n        warnings.warn('test_cfg is specified directly, which is not recommended. '\n                      'It should be specified in the model configuration.')\n\n    assert not ('train_cfg' in cfg and train_cfg is not None), \\\n        'train_cfg is duplicated in the outer field and model field'\n    assert not ('test_cfg' in cfg and test_cfg is not None), \\\n        'test_cfg is duplicated in the outer field and model field'\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None:\n        warnings.warn('train_cfg is specified in build_detector function. It is recommended to specify it in the model config')\n    if test_cfg is not None:\n        warnings.warn('test_cfg is specified in build_detector function. It is recommended to specify it in the model config')\n\n    if 'train_cfg' in cfg and train_cfg is not None:\n        assert cfg['train_cfg'] == train_cfg, 'train_cfg is duplicated in both the outer field and model field'\n    if 'test_cfg' in cfg and test_cfg is not None:\n        assert cfg['test_cfg'] == test_cfg, 'test_cfg is duplicated in both the outer field and model field'\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, train_cfg, test_cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg, train_cfg, test_cfg)"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None:\n        warnings.warn('train_cfg is specified in build_detector function. It should be specified in the model field')\n    if test_cfg is not None:\n        warnings.warn('test_cfg is specified in build_detector function. It should be specified in the model field')\n\n    assert train_cfg is None or 'train_cfg' not in cfg\n    assert test_cfg is None or 'test_cfg' not in cfg\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, train_cfg, test_cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg, train_cfg, test_cfg)"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None:\n        warnings.warn('train_cfg is specified directly, which is deprecated. '\n                      'It should be specified in the model config')\n    if test_cfg is not None:\n        warnings.warn('test_cfg is specified directly, which is deprecated. '\n                      'It should be specified in the model config')\n\n    assert 'train_cfg' not in cfg, '`train_cfg` should not be specified in the model field'\n    assert 'test_cfg' not in cfg, '`test_cfg` should not be specified in the model field'\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None:\n        warnings.warn('train_cfg is deprecated, please specify it in the model config')\n    if test_cfg is not None:\n        warnings.warn('test_cfg is deprecated, please specify it in the model config')\n\n    assert 'train_cfg' not in cfg, 'train_cfg should not be specified in the outer field of the model'\n    assert 'test_cfg' not in cfg, 'test_cfg should not be specified in the outer field of the model'\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, train_cfg, test_cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg, train_cfg, test_cfg)"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None:\n        warnings.warn('train_cfg is specified directly, '\n                      'which is not recommended. It should be specified in the model')\n    if test_cfg is not None:\n        warnings.warn('test_cfg is specified directly, '\n                      'which is not recommended. It should be specified in the model')\n\n    assert 'train_cfg' not in cfg, '\"train_cfg\" should not be specified in both the outer field and model field'\n    assert 'test_cfg' not in cfg, '\"test_cfg\" should not be specified in both the outer field and model field'\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None:\n        warnings.warn('train_cfg is specified in build_detector function. It should be specified in the model field')\n    if test_cfg is not None:\n        warnings.warn('test_cfg is specified in build_detector function. It should be specified in the model field')\n\n    assert 'train_cfg' not in cfg, 'train_cfg is duplicated in the outer field and model field'\n    assert 'test_cfg' not in cfg, 'test_cfg is duplicated in the outer field and model field'\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, train_cfg, test_cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg, train_cfg, test_cfg)"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None:\n        warnings.warn('train_cfg is specified in build_detector function, '\n                      'it will override the original train_cfg in the model')\n    if test_cfg is not None:\n        warnings.warn('test_cfg is specified in build_detector function, '\n                      'it will override the original test_cfg in the model')\n\n    assert train_cfg is None or 'train_cfg' not in cfg\n    assert test_cfg is None or 'test_cfg' not in cfg\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, train_cfg, test_cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg, train_cfg, test_cfg)"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None:\n        warnings.warn('train_cfg is specified in build_detector function, '\n                      'it will override the original train_cfg in the model')\n    if test_cfg is not None:\n        warnings.warn('test_cfg is specified in build_detector function, '\n                      'it will override the original test_cfg in the model')\n\n    assert 'train_cfg' not in cfg, 'train_cfg should be specified in the model'\n    assert 'test_cfg' not in cfg, 'test_cfg should be specified in the model'\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, train_cfg, test_cfg)\n    else:\n        return MMDET_DETECTORS.build(cfg, train_cfg, test_cfg)"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None:\n        warnings.warn('train_cfg is specified in build_detector function, '\n                      'it will override the original train_cfg in the model')\n    if test_cfg is not None:\n        warnings.warn('test_cfg is specified in build_detector function, '\n                      'it will override the original test_cfg in the model')\n\n    assert 'train_cfg' not in cfg, \\\n        'train_cfg is specified in both the outer field and model field'\n    assert 'test_cfg' not in cfg, \\\n        'test_cfg is specified in both the outer field and model field'\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val = val - period * offset\n    val = val - torch.floor(val / period) * period\n    return val + period * offset"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    return (val - period * offset) % period + period * offset"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val = val - period * offset\n    val = val - torch.floor(val / period) * period\n    return val + period * offset"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val = val - period * offset\n    val = val - torch.floor(val / period) * period\n    return val + period * offset"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val = val - period * offset\n    val = val - torch.floor(val / period) * period\n    return val + period * offset"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val = val - period * offset\n    val = val - torch.floor(val / period) * period\n    return val + period * offset"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val = val - period * offset\n    val = val - torch.floor(val / period) * period\n    val = val + period * offset\n    return val"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val = val - period * offset\n    val = val - torch.floor(val / period) * period\n    return val + period * offset"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    if isinstance(val, torch.Tensor):\n        val = val.numpy()\n    val = np.asarray(val)\n    return np.fmod(val - offset * period, period) + offset * period"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val = val - period * offset\n    val = val - torch.floor(val / period) * period\n    return val + period * offset"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val = val - period * offset\n    val = val - torch.floor(val / period) * period\n    return val + period * offset"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val = val - period * offset\n    val = val - torch.floor(val / period) * period\n    return val + period * offset"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val = val - period * offset\n    val = val - torch.floor(val / period) * period\n    return val + period * offset"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val = val - period * offset\n    val = val - torch.floor(val / period) * period\n    return val + period * offset"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val = val - period * offset\n    val = val - torch.floor(val / period) * period\n    val = val + period * offset\n    return val"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val = val - period * offset\n    val = val - torch.floor(val / period) * period\n    return val + period * offset"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val = np.array(val)\n    return np.fmod(val - offset * period, period) + offset * period"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val = val - period * offset\n    val = val - torch.floor(val / period) * period\n    val = val + period * offset\n    return val"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val = np.array(val)\n    return np.fmod(val - offset * period, period) + offset * period"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val = val - period * offset\n    val = val - torch.floor(val / period) * period\n    return val + period * offset"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    gt = {}\n    dt = {}\n    for anno in gt_annos:\n        if anno['name'] not in gt:\n            gt[anno['name']] = []\n        gt[anno['name']].append(anno)\n    for anno in dt_annos:\n        if anno['name'] not in dt:\n            dt[anno['name']] = []\n        dt[anno['name']].append(anno)\n\n    gt_boxes = {}\n    gt_labels = {}\n    for key, annos in gt.items():\n        gt_boxes[key] = np.stack([anno['bbox'] for anno in annos])\n        gt_labels[key] = np.array([label2cat[anno['name']] for anno in annos])\n\n    dt_boxes = {}\n    dt_labels = {}\n    dt_scores = {}\n    for key, annos in dt.items():\n        dt_boxes[key] = np.stack([anno['bbox'] for anno in annos])\n        dt_labels[key] = np.array([label2cat[anno['name']] for anno in annos])\n        dt_scores[key] = np.array([anno['score'] for anno in annos])\n\n    ovthresh = metric\n    pred = {}\n    gt = {}\n    for key in gt_boxes.keys():\n        pred[key] = list(zip(dt_boxes[key], dt_scores[key]))\n        gt[key] = list(zip(gt_boxes[key], gt_labels[key]))\n\n    recall, precision, ap = eval_map_recall(pred, gt, ovthresh)\n\n    ret_dict = {}\n    for i, thresh in enumerate(ovthresh):\n        ret_dict[f'mAP@{thresh}'] = np.mean(list(ap[i].values()))\n        ret_dict[f'mAR@{thresh}'] = np.mean(list(recall[i].values()))\n\n    if logger is not None:\n        ap_strs = []\n        ar_strs = []\n        for i, thresh in enumerate(ovthresh):\n            ap_strs.append([f'{label}: {ap[i][label][0]:.4f}' for label in ap[i]])\n            ar_strs.append([f'{label}: {recall[i][label][0]:.4f}' for label in recall[i]])\n\n        ap_table = AsciiTable([['IoU Threshold'] + [f'{thresh:.2f}' for thresh in ovthresh]])\n        ap_table.table_data.extend(ap_strs)\n        ar_table = AsciiTable([['IoU Threshold'] + [f'{thresh:.2f}' for thresh in ovthresh]])\n        ar_table.table_data.extend(ar_strs)\n        print_log(f'\\n{ap_table.table}', logger=logger)\n        print_log(f'\\n{ar_table.table}', logger=logger)\n\n    return ret_dict"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    gt = {}\n    dt = {}\n    for anno in gt_annos:\n        img_id = anno['image']['image_id']\n        gt[img_id] = []\n        for obj in anno['object']:\n            label = obj['name']\n            bbox = obj['bbox']\n            gt[img_id].append({'bbox': bbox, 'name': label})\n\n    for anno in dt_annos:\n        img_id = anno['image']['image_id']\n        dt[img_id] = []\n        for obj in anno['object']:\n            label = obj['name']\n            bbox = obj['bbox']\n            score = obj['score']\n            dt[img_id].append({'bbox': bbox, 'name': label, 'score': score})\n\n    pred = {}\n    for img_id in dt.keys():\n        pred[img_id] = []\n        for obj in dt[img_id]:\n            label = obj['name']\n            bbox = obj['bbox']\n            score = obj['score']\n            pred[img_id].append((bbox, score))\n\n    gt_dict = {}\n    for img_id in gt.keys():\n        gt_dict[img_id] = []\n        for obj in gt[img_id]:\n            label = obj['name']\n            bbox = obj['bbox']\n            gt_dict[img_id].append({'bbox': bbox, 'name': label})\n\n    pred_dict = {}\n    for img_id in pred.keys():\n        pred_dict[img_id] = []\n        for obj in pred[img_id]:\n            label = obj[1]\n            bbox = obj[0]\n            pred_dict[img_id].append({'bbox': bbox, 'name': label})\n\n    recall, precision, ap = eval_map_recall(pred_dict, gt_dict, metric)\n\n    if logger is not None:\n        table_data = [['Class', 'AP'] + [f'Recall@{iou}' for iou in metric]]\n        for label in ap[0].keys():\n            ap_values = [ap[i][label][0] for i in range(len(ap))]\n            recall_values = [recall[i][label][0] for i in range(len(recall))]\n            row = [label2cat[label]] + ap_values + recall_values\n            table_data.append(row)\n        table = AsciiTable(table_data)\n        if isinstance(logger, str):\n            print_log(table.table, logger)\n        else:\n            logger.info(table.table)\n\n    mAP = {}\n    mAR = {}\n    for i, iou in enumerate(metric):\n        mAP[iou] = np.mean([ap[i][label][0] for label in ap[i].keys()])\n        mAR[iou] = np.mean([recall[i][label][0] for label in recall[i].keys()])\n\n    result = {'mAP': mAP, 'mAR': mAR, 'AP': ap, 'AR': recall}\n    return result"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    pred = {}\n    gt = {}\n    for anno in dt_annos:\n        if anno['name'] not in pred:\n            pred[anno['name']] = []\n        pred[anno['name']].append([anno['bbox'], anno['score']])\n    for anno in gt_annos:\n        if anno['name'] not in gt:\n            gt[anno['name']] = []\n        gt[anno['name']].append(anno)\n\n    ovthresh = metric\n    ret = eval_map_recall(pred, gt, ovthresh)\n\n    if logger is not None:\n        table_data = [['category', 'AP', 'AR']]\n        for i, ov in enumerate(ovthresh):\n            aps = ret[2][i]\n            ars = ret[0][i]\n            for label, ap in aps.items():\n                table_data.append([label2cat[label], f'{ap[0]:.4f}', f'{ars[label][0]:.4f}'])\n            table_data.append(['mAP', f'{np.mean(list(aps.values())):.4f}', f'{np.mean(list(ars.values())):.4f}'])\n            table = AsciiTable(table_data)\n            print_log(table.table, logger=logger)\n    return {'AP': ret[2], 'AR': ret[0]}"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    pred = {}\n    gt = {}\n    for anno in gt_annos:\n        for i in range(len(anno['name'])):\n            name = label2cat[anno['name'][i]]\n            if name not in gt:\n                gt[name] = {}\n            if 'bbox' not in gt[name]:\n                gt[name]['bbox'] = []\n            bbox = anno['bbox'][i]\n            bbox = box_type_3d(bbox, box_mode_3d)\n            gt[name]['bbox'].append(bbox)\n\n    for anno in dt_annos:\n        for i in range(len(anno['name'])):\n            name = label2cat[anno['name'][i]]\n            if name not in pred:\n                pred[name] = {}\n            if 'bbox' not in pred[name]:\n                pred[name]['bbox'] = []\n            if 'score' not in pred[name]:\n                pred[name]['score'] = []\n            bbox = anno['bbox'][i]\n            bbox = box_type_3d(bbox, box_mode_3d)\n            pred[name]['bbox'].append(bbox)\n            pred[name]['score'].append(anno['score'][i])\n\n    ovthresh = metric\n    recall, precision, ap = eval_map_recall(pred, gt, ovthresh)\n\n    ret_dict = {'AP': {}, 'AR': {}}\n    for i, thresh in enumerate(ovthresh):\n        ret_dict['AP'][f'IoU={thresh}'] = {}\n        ret_dict['AR'][f'IoU={thresh}'] = {}\n        for label in gt.keys():\n            name = label2cat[label]\n            ret_dict['AP'][f'IoU={thresh}'][name] = ap[i][label][0]\n            ret_dict['AR'][f'IoU={thresh}'][name] = recall[i][label][0]\n\n    mAP = np.mean([ap[i][label][0] for i in range(len(ovthresh)) for label in gt.keys()])\n    mAR = np.mean([recall[i][label][0] for i in range(len(ovthresh)) for label in gt.keys()])\n\n    ret_dict['mAP'] = mAP\n    ret_dict['mAR'] = mAR\n\n    if logger is not None:\n        table_data = [['Category', 'AP', 'AR']]\n        for label in gt.keys():\n            name = label2cat[label]\n            ap_str = ', '.join([f'{ap[i][label][0]:.3f}' for i in range(len(ovthresh))])\n            ar_str = ', '.join([f'{recall[i][label][0]:.3f}' for i in range(len(ovthresh))])\n            table_data.append([name, ap_str, ar_str])\n        table_data.append(['mAP', f'{mAP:.3f}', ''])\n        table_data.append(['mAR', f'{mAR:.3f}', ''])\n        table = AsciiTable(table_data)\n        print_log(table.table, logger=logger)\n\n    return ret_dict"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    # convert label to cat\n    class2type = {k: label2cat[v] for k, v in label2cat.items()}\n\n    gt_dict = {}\n    dt_dict = {}\n    for anno in gt_annos:\n        name = anno['name']\n        anno_box = anno['bbox']\n        anno_label = anno['label']\n        anno_score = np.ones([anno['bbox'].shape[0]])\n        anno_3d = None\n        if 'alpha' in anno:\n            anno_alpha = anno['alpha']\n        else:\n            anno_alpha = np.zeros([anno['bbox'].shape[0]])\n        if 'dimensions' in anno:\n            anno_dimension = anno['dimensions']\n        else:\n            anno_dimension = np.zeros([anno['bbox'].shape[0], 3])\n        if 'location' in anno:\n            anno_location = anno['location']\n        else:\n            anno_location = np.zeros([anno['bbox'].shape[0], 3])\n        if 'rotation_y' in anno:\n            anno_rotation_y = anno['rotation_y']\n        else:\n            anno_rotation_y = np.zeros([anno['bbox'].shape[0]])\n        if 'score' in anno:\n            anno_score = anno['score']\n        if 'bbox_3d' in anno:\n            anno_3d = anno['bbox_3d']\n        if 'alpha' in anno:\n            anno_alpha = anno['alpha']\n        if 'dimensions' in anno:\n            anno_dimension = anno['dimensions']\n        if 'location' in anno:\n            anno_location = anno['location']\n        if 'rotation_y' in anno:\n            anno_rotation_y = anno['rotation_y']\n\n        anno_box = np.concatenate([anno_box, anno_alpha[:, np.newaxis],\n                                  anno_dimension, anno_location, anno_rotation_y[:, np.newaxis]], axis=1)\n        if anno_3d is not None:\n            anno_3d = np.concatenate([anno_3d, anno_alpha[:, np.newaxis],\n                                     anno_dimension, anno_location, anno_rotation_y[:, np.newaxis]], axis=1)\n        if name in gt_dict:\n            gt_dict[name]['bbox'] = np.concatenate([gt_dict[name]['bbox'], anno_box], axis=0)\n            gt_dict[name]['alpha'] = np.concatenate([gt_dict[name]['alpha'], anno_alpha])\n            gt_dict[name]['dimensions'] = np.concatenate([gt_dict[name]['dimensions'], anno_dimension], axis=0)\n            gt_dict[name]['location'] = np.concatenate([gt_dict[name]['location'], anno_location], axis=0)\n            gt_dict[name]['rotation_y'] = np.concatenate([gt_dict[name]['rotation_y'], anno_rotation_y])\n            gt_dict[name]['score'] = np.concatenate([gt_dict[name]['score'], anno_score])\n            if anno_3d is not None:\n                gt_dict[name]['bbox_3d'] = np.concatenate([gt_dict[name]['bbox_3d'], anno_3d], axis=0)\n        else:\n            gt_dict[name] = {}\n            gt_dict[name]['bbox'] = anno_box\n            gt_dict[name]['alpha'] = anno_alpha\n            gt_dict[name]['dimensions'] = anno_dimension\n            gt_dict[name]['location'] = anno_location\n            gt_dict[name]['rotation_y'] = anno_rotation_y\n            gt_dict[name]['score'] = anno_score\n            if anno_3d is not None:\n                gt_dict[name]['bbox_3d'] = anno_3d\n\n    for anno in dt_annos:\n        name = anno['name']\n        anno_box = anno['bbox']\n        anno_label = anno['label']\n        anno_score = anno['score']\n        anno_3d = None\n        if 'alpha' in anno:\n            anno_alpha = anno['alpha']\n        else:\n            anno_alpha = np.zeros([anno['bbox'].shape[0]])\n        if 'dimensions' in anno:\n            anno_dimension = anno['dimensions']\n        else:\n            anno_dimension = np.zeros([anno['bbox'].shape[0], 3])\n        if 'location' in anno:\n            anno_location = anno['location']\n        else:\n            anno_location = np.zeros([anno['bbox'].shape[0], 3])\n        if 'rotation_y' in anno:\n            anno_rotation_y = anno['rotation_y']\n        else:\n            anno_rotation_y = np.zeros([anno['bbox'].shape[0])\n        if 'bbox_3d' in anno:\n            anno_3d = anno['bbox_3d']\n        if name in dt_dict:\n            dt_dict[name]['bbox'] = np.concatenate([dt_dict[name]['bbox'], anno_box], axis=0)\n            dt_dict[name]['alpha'] = np.concatenate([dt_dict[name]['alpha'], anno_alpha])\n            dt_dict[name]['dimensions'] = np.concatenate([dt_dict[name]['dimensions'], anno_dimension], axis=0)\n            dt_dict[name]['location'] = np.concatenate([dt_dict[name]['location'], anno_location], axis=0)\n            dt_dict[name]['rotation_y'] = np.concatenate([dt_dict[name]['rotation_y'], anno_rotation_y])\n            dt_dict[name]['score'] = np.concatenate([dt_dict[name]['score'], anno_score])\n            if anno_3d is not None:\n                dt_dict[name]['bbox_3d'] = np.concatenate([dt_dict[name]['bbox_3d'], anno_3d], axis=0)\n        else:\n            dt_dict[name] = {}\n            dt_dict[name]['bbox'] = anno_box\n            dt_dict[name]['alpha'] = anno_alpha\n            dt_dict[name]['dimensions'] = anno_dimension\n            dt_dict[name]['location'] = anno_location\n            dt_dict[name]['rotation_y'] = anno_rotation_y\n            dt_dict[name]['score'] = anno_score\n            if anno_3d is not None:\n                dt_dict[name]['bbox_3d'] = anno_3d\n\n    if box_type_3d is not None:\n        assert box_mode_3d is not None\n        for k in gt_dict.keys():\n            if 'bbox_3d' in gt_dict[k]:\n                gt_dict[k]['bbox_3d'] = box_type_3d(gt_dict[k]['bbox_3d'], box_mode_3d, 'lidar', True)\n        for k in dt_dict.keys():\n            if 'bbox_3d' in dt_dict[k]:\n                dt_dict[k]['bbox_3d'] = box_type_3d(dt_dict[k]['bbox_3d'], box_mode_3d, 'lidar', True)\n\n    pred = {}\n    gt = {}\n    for k in gt_dict.keys():\n        if k in dt_dict:\n            pred[k] = dt_dict[k]\n            gt[k] = gt_dict[k]\n\n    ovthresh = metric\n    recall, precision, ap = eval_map_recall(pred, gt, ovthresh)\n    ret_dict = {}\n    for iou_idx, thresh in enumerate(ovthresh):\n        ret_dict['recall@' + str(thresh)] = recall[iou_idx]\n        ret_dict['precision@' + str(thresh)] = precision[iou_idx]\n        ret_dict['AP@' + str(thresh)] = ap[iou_idx]\n\n    if logger is not None:\n        if isinstance(logger, str):\n            print_log('Evaluation results:', logger)\n            table_data = [['class', 'AP', 'AR']]\n            for k, v in ret_dict['AP@' + str(ovthresh[0])].items():\n                table_data.append([class2type[int(k)], '{:.4f}'.format(v), '{:.4f}'.format(ret_dict['recall@' + str(ovthresh[0])][k])])\n            table = AsciiTable(table_data)\n            print_log('\\n' + table.table, logger)\n        else:\n            logger.info('Evaluation results:')\n            table_data = [['class', 'AP', 'AR']]\n            for k, v in ret_dict['AP@' + str(ovthresh[0])].items():\n                table_data.append([class2type[int(k)], '{:.4f}'.format(v), '{:.4f}'.format(ret_dict['recall@' + str(ovthresh[0])][k])])\n            table = AsciiTable(table_data)\n            logger.info('\\n' + table.table)\n\n    return ret_dict"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    pred = {}\n    gt = {}\n    for i, (gt_anno, dt_anno) in enumerate(zip(gt_annos, dt_annos)):\n        image_id = gt_anno[\"image\"][\"image_id\"]\n        pred[image_id] = []\n        for label in dt_anno[\"name\"]:\n            if label in label2cat:\n                label_id = label2cat[label]\n                for i in range(len(dt_anno[\"bbox\"])):\n                    pred[image_id].append(\n                        (dt_anno[\"bbox\"][i], dt_anno[\"score\"][i], label_id))\n        gt[image_id] = []\n        for label in gt_anno[\"name\"]:\n            if label in label2cat:\n                label_id = label2cat[label]\n                for i in range(len(gt_anno[\"bbox\"])):\n                    gt[image_id].append((gt_anno[\"bbox\"][i], label_id))\n\n    ovthresh = metric\n    ret = eval_map_recall(pred, gt, ovthresh)\n\n    result = {}\n    for iou_idx, thresh in enumerate(ovthresh):\n        result[f\"recall@{thresh}\"] = {}\n        result[f\"precision@{thresh}\"] = {}\n        result[f\"ap@{thresh}\"] = {}\n        for label in ret[0].keys():\n            result[f\"recall@{thresh}\"][label] = ret[0][iou_idx][label].mean()\n            result[f\"precision@{thresh}\"][label] = ret[1][iou_idx][label].mean()\n            result[f\"ap@{thresh}\"][label] = ret[2][iou_idx][label]\n\n    mAP = {}\n    mAR = {}\n    for iou_idx, thresh in enumerate(ovthresh):\n        mAP[f\"mAP@{thresh}\"] = np.mean(list(result[f\"ap@{thresh}\"].values()))\n        mAR[f\"mAR@{thresh}\"] = np.mean(list(result[f\"recall@{thresh}\"].values()))\n\n    if logger is not None:\n        table_data = [[\"IoU Threshold\", \"mAP\", \"mAR\"]]\n        for iou_idx, thresh in enumerate(ovthresh):\n            table_data.append([thresh, mAP[f\"mAP@{thresh}\"], mAR[f\"mAR@{thresh}\"]])\n        table = AsciiTable(table_data)\n        print_log(table.table, logger=logger)\n\n    result.update(mAP)\n    result.update(mAR)\n\n    return result"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    pred = {}\n    gt = {}\n    for i, anno in enumerate(gt_annos):\n        gt[i] = {'bbox': anno['bbox'], 'score': np.ones(len(anno['bbox']))}\n    for i, anno in enumerate(dt_annos):\n        pred[i] = [(box, score) for box, score in zip(anno['bbox'], anno['score'])]\n\n    ovthresh = metric\n    ret = eval_map_recall(pred, gt, ovthresh)\n    recall, precision, ap = ret\n\n    # Compute mean Average Precision (mAP) and mean Average Recall (mAR)\n    mAPs = []\n    mARs = []\n    for iou_idx, thresh in enumerate(ovthresh):\n        aps = []\n        ars = []\n        for label in ap[iou_idx].keys():\n            cat = label2cat[label]\n            ap_value = ap[iou_idx][label][0]\n            ar_value = recall[iou_idx][label][0]\n            aps.append(ap_value)\n            ars.append(ar_value)\n            if logger:\n                print_log(f'{cat}: AP {ap_value:.4f}, AR {ar_value:.4f}', logger=logger)\n        mAP = np.mean(aps)\n        mAR = np.mean(ars)\n        mAPs.append(mAP)\n        mARs.append(mAR)\n        if logger:\n            print_log(f'mAP {mAP:.4f}, mAR {mAR:.4f} (IoU={thresh})', logger=logger)\n\n    # Create a dictionary containing the evaluation results\n    eval_results = {\n        'mAP': mAPs,\n        'mAR': mARs,\n        'AP': ap,\n        'AR': recall\n    }\n\n    return eval_results"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    pred = {}\n    gt = {}\n    for i in range(len(gt_annos)):\n        gt_anno = gt_annos[i]\n        dt_anno = dt_annos[i]\n        for j in range(len(gt_anno['name'])):\n            name = gt_anno['name'][j]\n            if name not in gt:\n                gt[name] = []\n                pred[name] = []\n            bbox = gt_anno['bbox'][j]\n            gt[name].append({'bbox': bbox})\n        for j in range(len(dt_anno['name'])):\n            name = dt_anno['name'][j]\n            if name not in pred:\n                pred[name] = []\n                gt[name] = []\n            bbox = dt_anno['bbox'][j]\n            score = dt_anno['score'][j]\n            pred[name].append((bbox, score))\n    ovthresh = metric\n    recall, precision, ap = eval_map_recall(pred, gt, ovthresh)\n    ret_dict = {}\n    for i in range(len(ovthresh)):\n        ret_dict['recall@' + str(ovthresh[i])] = recall[i]\n        ret_dict['precision@' + str(ovthresh[i])] = precision[i]\n        ret_dict['ap@' + str(ovthresh[i])] = ap[i]\n    ret_dict['map'] = np.nanmean(ap)\n    ret_dict['mar'] = np.nanmean(recall)\n    if logger is not None:\n        if isinstance(logger, str):\n            print_log(f\"mAP: {ret_dict['map']:.4f}, mAR: {ret_dict['mar']:.4f}\", logger=logger)\n        else:\n            logger.info(f\"mAP: {ret_dict['map']:.4f}, mAR: {ret_dict['mar']:.4f}\")\n\n    return ret_dict"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    pred = {}\n    gt = {}\n    for i, annos in enumerate(dt_annos):\n        pred[i] = {}\n        for j in range(len(annos['name'])):\n            label = label2cat[annos['name'][j]]\n            if label not in pred[i]:\n                pred[i][label] = []\n            pred[i][label].append((box_type_3d(annos['bbox'][j]), annos['score'][j]))\n\n    for i, annos in enumerate(gt_annos):\n        gt[i] = {}\n        for j in range(len(annos['name'])):\n            label = label2cat[annos['name'][j]]\n            if label not in gt[i]:\n                gt[i][label] = []\n            gt[i][label].append(box_type_3d(annos['bbox'][j]))\n\n    recall, precision, ap = eval_map_recall(pred, gt, metric)\n\n    if logger is not None:\n        table_data = [['Class', 'AP'] + [f'Recall@{iou}' for iou in metric]]\n        for label in ap[0].keys():\n            row = [label]\n            for i in range(len(ap)):\n                row.append(ap[i][label][0])\n                row.extend(recall[i][label].tolist())\n            table_data.append(row)\n        table = AsciiTable(table_data)\n        print_log('\\n' + table.table, logger=logger)\n\n    mAP = {iou: np.mean([ap[i][label][0] for label in ap[i].keys()]) for i, iou in enumerate(metric)}\n    mAR = {iou: np.mean([np.mean(recall[i][label]) for label in recall[i].keys()]) for i, iou in enumerate(metric)}\n\n    return {'mAP': mAP, 'mAR': mAR, 'AP': ap, 'AR': recall}"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    gt = {}\n    dt = {}\n    for i, (gt_anno, dt_anno) in enumerate(zip(gt_annos, dt_annos)):\n        image_id = gt_anno['image_idx']\n        gt_boxes = gt_anno['gt_boxes']\n        gt_labels = gt_anno['gt_labels']\n        dt_boxes = dt_anno['pred_boxes']\n        dt_labels = dt_anno['pred_labels']\n        dt_scores = dt_anno['pred_scores']\n\n        if image_id not in gt:\n            gt[image_id] = {'bbox': [], 'det': []}\n        if image_id not in dt:\n            dt[image_id] = {'bbox': [], 'det': []}\n\n        for j in range(len(gt_boxes)):\n            gt[image_id]['bbox'].append({\n                'bbox': gt_boxes[j],\n                'label': label2cat[gt_labels[j]]\n            })\n            gt[image_id]['det'].append([False] * len(metric))\n\n        for j in range(len(dt_boxes)):\n            dt[image_id]['bbox'].append({\n                'bbox': dt_boxes[j],\n                'label': label2cat[dt_labels[j]],\n                'score': dt_scores[j]\n            })\n            dt[image_id]['det'].append([False] * len(metric))\n\n    pred = {}\n    for image_id in dt.keys():\n        pred[image_id] = {}\n        for i, thresh in enumerate(metric):\n            pred[image_id][i] = []\n            for j in range(len(dt[image_id]['bbox'])):\n                pred[image_id][i].append(\n                    (dt[image_id]['bbox'][j]['bbox'], dt[image_id]['bbox'][j]['score'])\n                )\n\n    gt_dict = {}\n    for image_id in gt.keys():\n        gt_dict[image_id] = []\n        for j in range(len(gt[image_id]['bbox'])):\n            gt_dict[image_id].append((gt[image_id]['bbox'][j]['bbox'], gt[image_id]['bbox'][j]['label']))\n\n    pred_dict = {}\n    for image_id in pred.keys():\n        pred_dict[image_id] = []\n        for i, thresh in enumerate(metric):\n            pred_dict[image_id].append(pred[image_id][i])\n\n    recalls, precisions, aps = eval_map_recall(pred_dict, gt_dict, metric)\n\n    ret_dict = {}\n    for i, thresh in enumerate(metric):\n        ret_dict[f'recall@{thresh}'] = recalls[i]\n        ret_dict[f'precision@{thresh}'] = precisions[i]\n        ret_dict[f'AP@{thresh}'] = aps[i]\n\n    mAPs = [ap.mean() for ap in aps]\n    mARs = [recall.mean() for recall in recalls]\n\n    ret_dict['mAP'] = mAPs\n    ret_dict['mAR'] = mARs\n\n    if logger is not None:\n        table_data = [['IoU', 'mAP', 'mAR']]\n        for i, thresh in enumerate(metric):\n            table_data.append([thresh, mAPs[i], mARs[i]])\n        table = AsciiTable(table_data)\n        print_log(table.table, logger=logger)\n\n    return ret_dict"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    pred = {}\n    gt = {}\n    for i, anno in enumerate(dt_annos):\n        if anno[\"name\"] in pred:\n            pred[anno[\"name\"]].append((anno[\"bbox\"], anno[\"score\"]))\n        else:\n            pred[anno[\"name\"]] = [(anno[\"bbox\"], anno[\"score\"])]\n\n    for i, anno in enumerate(gt_annos):\n        if anno[\"name\"] in gt:\n            gt[anno[\"name\"]].append(anno)\n        else:\n            gt[anno[\"name\"]] = [anno]\n\n    ret = eval_map_recall(pred, gt, metric)\n\n    if logger is not None:\n        if isinstance(logger, str):\n            print_log(f\"mAP summary:\\n\", logger=logger)\n            table_data = [[\"class\", \"AP\"]]\n            for label, ap in ret[2].items():\n                table_data.append([label2cat[label], f\"{ap[0]:.4f}\"])\n            table = AsciiTable(table_data)\n            print_log(table.table, logger=logger)\n        else:\n            logger.info(\"mAP summary:\")\n            table_data = [[\"class\", \"AP\"]]\n            for label, ap in ret[2].items():\n                table_data.append([label2cat[label], f\"{ap[0]:.4f}\"])\n            table = AsciiTable(table_data)\n            logger.info(table.table)\n\n    return {\n        \"ap\": ret[2],\n        \"ar\": ret[0]\n    }"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    pred = {}\n    gt = {}\n    for i in range(len(gt_annos)):\n        gt_anno = gt_annos[i]\n        dt_anno = dt_annos[i]\n        for j in range(len(gt_anno['name'])):\n            name = gt_anno['name'][j]\n            if name not in gt:\n                gt[name] = []\n                pred[name] = []\n            bbox = gt_anno['bbox'][j]\n            gt[name].append({'bbox': bbox})\n        for j in range(len(dt_anno['name'])):\n            name = dt_anno['name'][j]\n            if name not in pred:\n                pred[name] = []\n                gt[name] = []\n            bbox = dt_anno['bbox'][j]\n            score = dt_anno['score'][j]\n            pred[name].append((bbox, score))\n\n    ovthresh = metric\n    recalls, precisions, aps = eval_map_recall(pred, gt, ovthresh)\n\n    if logger is not None:\n        if isinstance(logger, str):\n            logger = print_log\n\n        table_data = [['category', 'AP'] + [\n            'AP@' + str(i) for i in ovthresh\n        ]]\n        for i, classname in enumerate(gt.keys()):\n            if classname in pred:\n                ap_strs = [\n                    '{:.4f}'.format(aps[j][classname][0]) for j in range(len(ovthresh))\n                ]\n                table_data.append([label2cat[classname]] + ['{:.4f}'.format(\n                    aps[j][classname][0]) for j in range(len(ovthresh))])\n        table = AsciiTable(table_data)\n        logger('\\n' + table.table)\n\n        aps = np.array([aps[j][classname][0] for j in range(len(ovthresh))\n                        for classname in gt.keys() if classname in pred])\n        mean_ap = float(np.mean(aps))\n        logger('mAP: {:.4f}'.format(mean_ap))\n\n        recalls = np.array([recalls[j][classname][0] for j in range(len(ovthresh))\n                            for classname in gt.keys() if classname in pred])\n        mean_recall = float(np.mean(recalls))\n        logger('mAR: {:.4f}'.format(mean_recall))\n\n    results = {\n        'ap': aps,\n        'recall': recalls,\n        'map': mean_ap,\n        'mar': mean_recall\n    }\n\n    return results"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    gt = {}\n    dt = {}\n    for anno in gt_annos:\n        img_id = anno['image']['image_id']\n        gt[img_id] = anno['gt_boxes_2d']\n    for anno in dt_annos:\n        img_id = anno['image']['image_id']\n        dt[img_id] = [(box, score) for box, score, label in zip(anno['boxes_2d'], anno['scores_2d'], anno['label'])]\n\n    ovthresh = metric\n    pred = {}\n    for img_id in dt.keys():\n        for box, score in dt[img_id]:\n            label = box.label\n            if label not in pred:\n                pred[label] = {}\n            if img_id not in pred[label]:\n                pred[label][img_id] = []\n            pred[label][img_id].append((box, score))\n\n    gt_dict = {}\n    for img_id in gt.keys():\n        for box in gt[img_id]:\n            label = box.label\n            if label not in gt_dict:\n                gt_dict[label] = {}\n            if img_id not in gt_dict[label]:\n                gt_dict[label][img_id] = []\n            gt_dict[label][img_id].append(box)\n\n    ret = eval_map_recall(pred, gt_dict, ovthresh)\n\n    ap_dict = {}\n    ar_dict = {}\n    for iou_idx, thresh in enumerate(ovthresh):\n        ap_dict[thresh] = {}\n        ar_dict[thresh] = {}\n        for label, (recall, precision, ap) in ret[2][iou_idx].items():\n            ap_dict[thresh][label2cat[label]] = ap\n            ar_dict[thresh][label2cat[label]] = recall[-1]\n\n    mAP = {}\n    mAR = {}\n    for iou_idx, thresh in enumerate(ovthresh):\n        mAP[thresh] = np.mean(list(ap_dict[thresh].values()))\n        mAR[thresh] = np.mean(list(ar_dict[thresh].values()))\n\n    if logger is not None:\n        table_data = [['Class', 'AP', 'AR']]\n        for label in label2cat.values():\n            table_data.append([label, ap_dict[ovthresh[-1]][label], ar_dict[ovthresh[-1]][label]])\n        table_data.append(['mAP', mAP[ovthresh[-1]], mAR[ovthresh[-1]]])\n        table = AsciiTable(table_data)\n        print_log(table.table, logger=logger)\n\n    return {'mAP': mAP, 'mAR': mAR, 'ap': ap_dict, 'ar': ar_dict}"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    pred = {}\n    gt = {}\n    for anno in gt_annos:\n        img_id = anno['image_idx']\n        if img_id not in gt:\n            gt[img_id] = []\n        gt[img_id].append(anno)\n\n    for anno in dt_annos:\n        img_id = anno['image_idx']\n        if img_id not in pred:\n            pred[img_id] = []\n        pred[img_id].append((box_type_3d(anno['bbox'], box_mode_3d), anno['score']))\n\n    pred = {img_id: sorted(pred[img_id], key=lambda x: x[1], reverse=True) for img_id in pred}\n    gt = {img_id: [box_type_3d(anno['bbox'], box_mode_3d) for anno in gt[img_id]] for img_id in gt}\n\n    ovthresh = metric\n    recall, precision, ap = eval_map_recall(pred, gt, ovthresh)\n\n    if logger is not None:\n        if isinstance(logger, str):\n            logger = print_log\n        else:\n            logger = logger.info\n\n        table_data = [['Class', 'AP', 'AR']]\n        for i, thresh in enumerate(ovthresh):\n            table_data.append(['IoU Thr: {}'.format(thresh), '', ''])\n            for label, cat in label2cat.items():\n                table_data.append([cat, '{:.4f}'.format(ap[i][label][0]), '{:.4f}'.format(recall[i][label][0])])\n            table_data.append(['mAP', '{:.4f}'.format(np.mean(list(ap[i].values()))), ''])\n            table_data.append(['mAR', '', '{:.4f}'.format(np.mean(list(recall[i].values())))])\n\n        table = AsciiTable(table_data)\n        logger('\\n' + table.table)\n\n    results = {'recall': recall, 'precision': precision, 'ap': ap}\n    return results"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    # convert label to class name\n    class2label = {v: k for k, v in label2cat.items()}\n    gt = {}\n    dt = {}\n    for anno in gt_annos:\n        img_id = anno['image']['image_id']\n        if 'annotations_3d' in anno:\n            bboxes = anno['annotations_3d']\n        else:\n            bboxes = anno['annotations']\n        if len(bboxes) > 0:\n            gt[img_id] = [anno['name'] for _ in range(len(bboxes))]\n        else:\n            gt[img_id] = []\n\n    for anno in dt_annos:\n        img_id = anno['image']['image_id']\n        if 'annotations_3d' in anno:\n            bboxes = anno['annotations_3d']\n        else:\n            bboxes = anno['annotations']\n        if len(bboxes) > 0:\n            dt[img_id] = [(anno['name'], anno['score']) for _ in range(len(bboxes))]\n        else:\n            dt[img_id] = []\n\n    pred = {}\n    for img_id in dt.keys():\n        for label, score in dt[img_id]:\n            if img_id not in pred:\n                pred[img_id] = [(label, score)]\n            else:\n                pred[img_id].append((label, score))\n\n    gt_dict = {}\n    for img_id in gt.keys():\n        if img_id not in gt_dict:\n            gt_dict[img_id] = [{'bbox': [], 'det': []}]\n        for label in gt[img_id]:\n            gt_dict[img_id][0]['bbox'].append(label)\n\n    pred_dict = {}\n    for img_id in pred.keys():\n        if img_id not in pred_dict:\n            pred_dict[img_id] = [{'bbox': [], 'det': []}]\n        for label, score in pred[img_id]:\n            pred_dict[img_id][0]['bbox'].append(label)\n\n    recall, precision, ap = eval_map_recall(pred_dict, gt_dict, metric)\n\n    if logger is not None:\n        if isinstance(logger, str):\n            logger = print_log\n\n        table_data = [['class', 'AP'] + [f'AR@{iou}' for iou in metric]]\n        for label in label2cat.values():\n            label = class2label[label]\n            aps = [ap[i][label][0] for i in range(len(metric))]\n            ars = [recall[i][label][0] for i in range(len(metric))]\n            table_data.append([label] + aps + ars)\n\n        table = AsciiTable(table_data)\n        logger(table.table)\n\n    ret = {\n        'label2cat': label2cat,\n        'class2label': class2label,\n        'recall': recall,\n        'precision': precision,\n        'ap': ap\n    }\n\n    return ret"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    # convert dt_annos and gt_annos to the format required by eval_det_cls\n    pred = {}\n    gt = {}\n    for i, dt_anno in enumerate(dt_annos):\n        img_id = dt_anno['image_idx']\n        if img_id not in pred:\n            pred[img_id] = []\n        pred[img_id].append((dt_anno['box3d_lidar'], dt_anno['score']))\n    for i, gt_anno in enumerate(gt_annos):\n        img_id = gt_anno['image_idx']\n        if img_id not in gt:\n            gt[img_id] = []\n        gt[img_id].append(gt_anno)\n\n    # evaluate detection results using eval_det_cls\n    recall, precision, ap = eval_map_recall(pred, gt, metric)\n\n    # organize evaluation results into a dictionary\n    eval_results = {}\n    for i, thresh in enumerate(metric):\n        eval_results[f'recall@{thresh}'] = recall[i]\n        eval_results[f'precision@{thresh}'] = precision[i]\n        eval_results[f'AP@{thresh}'] = ap[i]\n\n    # calculate mAP and mAR\n    mAP = {}\n    mAR = {}\n    for i, thresh in enumerate(metric):\n        ap_values = list(ap[i].values())\n        mAP[thresh] = sum(ap_values) / len(ap_values)\n        recall_values = list(recall[i].values())\n        mAR[thresh] = sum(recall_values) / len(recall_values)\n\n    eval_results['mAP'] = mAP\n    eval_results['mAR'] = mAR\n\n    # print mAP summary\n    if logger is not None:\n        if isinstance(logger, str):\n            print_log(f\"mAP summary:\\n\", logger=logger)\n            table_data = [['IoU Threshold', 'mAP']]\n            for i, thresh in enumerate(metric):\n                table_data.append([f'{thresh}', f'{mAP[thresh]:.4f}'])\n            table = AsciiTable(table_data)\n            print_log(f\"{table.table}\\n\", logger=logger)\n        else:\n            logger.info(f\"mAP summary:\")\n            table_data = [['IoU Threshold', 'mAP']]\n            for i, thresh in enumerate(metric):\n                table_data.append([f'{thresh}', f'{mAP[thresh]:.4f}'])\n            table = AsciiTable(table_data)\n            logger.info(f\"{table.table}\\n\")\n\n    return eval_results"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    pred = {}\n    gt = {}\n    for anno in dt_annos:\n        if anno['name'] not in pred:\n            pred[anno['name']] = []\n        pred[anno['name']].append([anno['bbox'], anno['score']])\n    for anno in gt_annos:\n        if anno['name'] not in gt:\n            gt[anno['name']] = []\n        gt[anno['name']].append(anno['bbox'])\n\n    ovthresh = metric\n    recall, precision, ap = eval_map_recall(pred, gt, ovthresh)\n\n    if logger is not None:\n        table_data = [['class', 'AP', 'AR']]\n        for i, ov in enumerate(ovthresh):\n            table_data.append([f'IoU={ov}', '', ''])\n            for label, cat in label2cat.items():\n                if label in ap[i]:\n                    table_data.append([cat, f'{ap[i][label]:.4f}', f'{recall[i][label][0]:.4f}'])\n        table = AsciiTable(table_data)\n        print_log('\\n' + table.table, logger=logger)\n\n    mAP = np.mean([np.mean(ap_val) for ap_val in ap])\n    mAR = np.mean([np.mean(recall_val) for recall_val in recall])\n\n    eval_results = {'mAP': mAP, 'mAR': mAR, 'AP': ap, 'AR': recall}\n\n    return eval_results"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    pred = {}\n    gt = {}\n    for i in range(len(gt_annos)):\n        gt_anno = gt_annos[i]\n        dt_anno = dt_annos[i]\n        for j in range(len(gt_anno['name'])):\n            name = gt_anno['name'][j]\n            if name not in gt:\n                gt[name] = []\n                pred[name] = []\n            bbox = gt_anno['bbox'][j]\n            gt[name].append({'bbox': bbox, 'score': 0})\n        for j in range(len(dt_anno['name'])):\n            name = dt_anno['name'][j]\n            if name not in pred:\n                pred[name] = []\n                gt[name] = []\n            bbox = dt_anno['bbox'][j]\n            score = dt_anno['score'][j]\n            pred[name].append({'bbox': bbox, 'score': score})\n\n    ovthresh = metric\n    recall, precision, ap = eval_map_recall(pred, gt, ovthresh)\n    ret_dict = {}\n    for i in range(len(ovthresh)):\n        ret_dict['recall@' + str(ovthresh[i])] = recall[i]\n        ret_dict['precision@' + str(ovthresh[i])] = precision[i]\n        ret_dict['ap@' + str(ovthresh[i])] = ap[i]\n    ret_dict['map'] = np.nanmean(ap)\n    ret_dict['mar'] = np.nanmean(recall)\n    if logger is not None:\n        log_str = 'mAP: {:.4f}, mAR: {:.4f}\\n'.format(\n            np.nanmean(ap), np.nanmean(recall))\n        class_names = list(gt.keys())\n        header = ['class', 'AP']\n        table_data = [header]\n        for i in range(len(class_names)):\n            table_data.append(\n                [label2cat[class_names[i]], '{:.4f}'.format(ap[0][class_names[i]])])\n        table = AsciiTable(table_data)\n        log_str += table.table\n        if isinstance(logger, str):\n            print_log(log_str, logger=logger)\n        else:\n            print_log(log_str, logger=logger.info)\n    return ret_dict"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "\n    pred = {}\n    gt = {}\n    for i, dt_anno in enumerate(dt_annos):\n        image_id = gt_annos[i]['image_idx']\n        if 'name' in gt_annos[i]:\n            image_id = gt_annos[i]['name']\n        else:\n            image_id = gt_annos[i]['image_idx']\n        if image_id not in pred:\n            pred[image_id] = []\n        if image_id not in gt:\n            gt[image_id] = []\n        for j in range(dt_anno['name'].shape[0]):\n            box3d = dt_anno['box3d_lidar'][j]\n            box3d = box_type_3d(box3d, box_mode_3d)\n            pred[image_id].append([box3d, dt_anno['score'][j], dt_anno['label'][j]])\n\n    for i, anno in enumerate(gt_annos):\n        image_id = anno['image_idx']\n        if 'name' in anno:\n            image_id = anno['name']\n        else:\n            image_id = anno['image_idx']\n        if image_id not in gt:\n            gt[image_id] = []\n        for j in range(anno['name'].shape[0]):\n            box3d = anno['box3d_lidar'][j]\n            box3d = box_type_3d(box3d, box_mode_3d)\n            gt[image_id].append([box3d, 1.0, anno['label'][j]])\n\n    pred = {k: np.array(v) for k, v in pred.items()}\n    gt = {k: np.array(v) for k, v in gt.items()}\n\n    ret = eval_map_recall(pred, gt, metric)\n\n    if logger is not None:\n        table_data = [['class', 'AP', 'AR']]\n        for i, iou in enumerate(metric):\n            table_data.append([f'IOU={iou}', '', ''])\n            for label, ap in ret[2][i].items():\n                table_data.append([label2cat[label], f'{ap:.4f}', f'{ret[0][i][label][0]:.4f}'])\n            table_data.append(['mAP', f'{ret[2][i].mean():.4f}', f'{ret[1][i].mean():.4f}'])\n        table = AsciiTable(table_data)\n        print_log(table.table, logger=logger)\n\n    return ret"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    gt = {}\n    dt = {}\n    for i in range(len(gt_annos)):\n        gt[i] = {'bbox': gt_annos[i]['gt_boxes'], 'det': []}\n    for i in range(len(dt_annos)):\n        dt[i] = {'bbox': dt_annos[i]['boxes'], 'det': []}\n\n    pred = {}\n    for i in range(len(dt_annos)):\n        pred[i] = [(dt_annos[i]['boxes'][j], dt_annos[i]['scores'][j]) for j in range(len(dt_annos[i]['boxes']))]\n\n    gt_dict = {}\n    for i in range(len(gt_annos)):\n        gt_dict[i] = gt_annos[i]['name']\n\n    pred_dict = {}\n    for i in range(len(dt_annos)):\n        pred_dict[i] = dt_annos[i]['name']\n\n    pred_cls = {pred_dict[i]: pred[i] for i in range(len(pred_dict))}\n    gt_cls = {gt_dict[i]: gt[i] for i in range(len(gt_dict))}\n\n    recall, precision, ap = eval_map_recall(pred_cls, gt_cls, metric)\n\n    if logger is not None:\n        table_data = [['Class', 'AP'] + [f'AR@{iou}' for iou in metric]]\n        for i, label in enumerate(gt_annos):\n            class_name = label2cat[label['name']]\n            ap_str = f'{ap[0][label[\"name\"]]:.4f}'\n            ar_str = '  '.join([f'{recall[iou][label[\"name\"]][0]:.4f}' for iou in range(len(metric))])\n            table_data.append([class_name, ap_str] + ar_str.split('  '))\n        table = AsciiTable(table_data)\n        print_log('\\n' + table.table, logger=logger)\n\n    ap_dict = {label2cat[label['name']]: ap[0][label['name']] for label in gt_annos}\n    ar_dict = {label2cat[label['name']]: recall[0][label['name']][0] for label in gt_annos}\n\n    mAP = np.mean(list(ap_dict.values()))\n    mAR = np.mean(list(ar_dict.values()))\n\n    ap_dict['mAP'] = mAP\n    ar_dict['mAR'] = mAR\n\n    return {'AP': ap_dict, 'AR': ar_dict}"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        return 'LiDARBox3D', 'rect'\n    elif box_type == 'Camera':\n        return 'CameraBox3D', 'rect'\n    elif box_type == 'Depth':\n        return 'DepthBox3D', 'depth'\n    else:\n        warning(f'Unsupported box type {box_type}, use \"LiDAR\" by default')\n        return 'LiDARBox3D', 'rect'"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == \"LiDAR\":\n        return (LiDARBox3D, 'LiDAR')\n    elif box_type == \"Camera\":\n        return (CameraBox3D, 'Camera')\n    elif box_type == \"Depth\":\n        return (DepthBox3D, 'Depth')\n    else:\n        raise ValueError(f\"Unrecognized box type: {box_type}. Supported types are 'LiDAR', 'Camera', and 'Depth'.\")"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "\n    if box_type == \"LiDAR\":\n        return (xywhr2xyxyr, 'LiDAR')\n    elif box_type == \"Camera\":\n        # Add implementation for Camera box type here\n        pass\n    elif box_type == \"Depth\":\n        # Add implementation for Depth box type here\n        pass\n    else:\n        raise ValueError(f\"Unrecognized box_type: {box_type}. Please use one of 'LiDAR', 'Camera', or 'Depth'.\")"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == \"LiDAR\":\n        return LiDARBox, \"LiDAR\"\n    elif box_type == \"Camera\":\n        return CameraBox, \"Camera\"\n    elif box_type == \"Depth\":\n        return DepthBox, \"Depth\"\n    else:\n        raise ValueError(f\"Unrecognized box type: {box_type}. Supported types are 'LiDAR', 'Camera', or 'Depth'.\")"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        return 'LiDARBox3D', 'rect'\n    elif box_type == 'Camera':\n        return 'CameraBox3D', 'rect'\n    elif box_type == 'Depth':\n        return 'DepthBox3D', 'depth'\n    else:\n        warning(f'Unsupported box type {box_type}, use LiDAR box as default')\n        return 'LiDARBox3D', 'rect'"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        return 'LiDARBox3D', 'LiDAR'\n    elif box_type == 'Camera':\n        return 'CameraBox3D', 'Camera'\n    elif box_type == 'Depth':\n        return 'DepthBox3D', 'Depth'\n    else:\n        raise ValueError(f'Unrecognized box type: {box_type}. '\n                         f\"Supported box types are 'LiDAR', 'Camera', and 'Depth'.\")"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        return 'LiDARBox3D', 'rect'\n    elif box_type == 'Camera':\n        return 'CameraBox3D', 'bev'\n    elif box_type == 'Depth':\n        return 'DepthBox3D', 'rect'\n    else:\n        warning(f'Unsupported box type {box_type}, use LiDAR box as default')\n        return 'LiDARBox3D', 'rect'"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        return 'LiDARBox3D', 'LiDAR'\n    elif box_type == 'Camera':\n        return 'CameraBox3D', 'Camera'\n    elif box_type == 'Depth':\n        return 'DepthBox3D', 'Depth'\n    else:\n        raise ValueError(f'Unrecognized box type {box_type}. '\n                         f'Supported box types are \"LiDAR\", \"Camera\", \"Depth\".')"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "\n    if box_type == \"LiDAR\":\n        return xywhr2xyxyr, \"LiDAR\"\n    elif box_type == \"Camera\":\n        # Add logic for Camera box type\n        pass\n    elif box_type == \"Depth\":\n        # Add logic for Depth box type\n        pass\n    else:\n        raise ValueError(f\"Unrecognized box type: {box_type}. Supported types are 'LiDAR', 'Camera', and 'Depth'.\")"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == \"LiDAR\":\n        return (xywhr2xyxyr, 'LiDAR')\n    elif box_type == \"Camera\":\n        # Add the corresponding 3D box class and mode for Camera context\n        return (None, 'Camera')\n    elif box_type == \"Depth\":\n        # Add the corresponding 3D box class and mode for Depth context\n        return (None, 'Depth')\n    else:\n        raise ValueError(f\"Unrecognized box_type: {box_type}. Please use one of 'LiDAR', 'Camera', or 'Depth'.\")"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == \"LiDAR\":\n        return LiDARBox, \"LiDAR\"\n    elif box_type == \"Camera\":\n        return CameraBox, \"Camera\"\n    elif box_type == \"Depth\":\n        return DepthBox, \"Depth\"\n    else:\n        raise ValueError(f\"Unrecognized box type: {box_type}. Supported types are 'LiDAR', 'Camera', or 'Depth'.\")"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "\n    if box_type == \"LiDAR\":\n        return (xywhr2xyxyr, 'LiDAR')\n    elif box_type == \"Camera\":\n        return (None, 'Camera')\n    elif box_type == \"Depth\":\n        return (None, 'Depth')\n    else:\n        raise ValueError(f\"Unrecognized box type: {box_type}. Supported types are 'LiDAR', 'Camera', and 'Depth'.\")"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        return 'LiDARBox3D', 'LiDAR'\n    elif box_type == 'Camera':\n        return 'CameraBox3D', 'Camera'\n    elif box_type == 'Depth':\n        return 'DepthBox3D', 'Depth'\n    else:\n        raise ValueError(f'Unrecognized box type {box_type}. '\n                         f'Supported box types are \"LiDAR\", \"Camera\", \"Depth\".')"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        return ('LiDARBox3D', 'LiDAR')\n    elif box_type == 'Camera':\n        return ('CameraBox3D', 'Camera')\n    elif box_type == 'Depth':\n        return ('DepthBox3D', 'Depth')\n    else:\n        raise ValueError(f'Unrecognized box type: {box_type}. '\n                         f'Supported box types are \"LiDAR\", \"Camera\", and \"Depth\".')"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        return 'LiDARBox3D', 'LiDAR'\n    elif box_type == 'Camera':\n        return 'CameraBox3D', 'Camera'\n    elif box_type == 'Depth':\n        return 'DepthBox3D', 'Depth'\n    else:\n        raise ValueError(f'Unrecognized box_type {box_type}, '\n                         f'supported box types are '\n                         f'\"LiDAR\", \"Camera\", \"Depth\".')"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        return ('LiDARBox3D', 'LiDAR')\n    elif box_type == 'Camera':\n        return ('CameraBox3D', 'Camera')\n    elif box_type == 'Depth':\n        return ('DepthBox3D', 'Depth')\n    else:\n        raise ValueError(f'Unsupported box_type {box_type}, '\n                         f'supported box_type are: \"LiDAR\", \"Camera\", \"Depth\"')"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        return ('LiDARBox3D', 'LiDAR')\n    elif box_type == 'Camera':\n        return ('CameraBox3D', 'Camera')\n    elif box_type == 'Depth':\n        return ('DepthBox3D', 'Depth')\n    else:\n        raise ValueError(f'Unrecognized box_type {box_type}')"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == \"LiDAR\":\n        return LiDARBox, \"LiDAR\"\n    elif box_type == \"Camera\":\n        return CameraBox, \"Camera\"\n    elif box_type == \"Depth\":\n        return DepthBox, \"Depth\"\n    else:\n        raise ValueError(f\"Unrecognized box type: {box_type}. Supported types are 'LiDAR', 'Camera', and 'Depth'.\")"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == \"LiDAR\":\n        return LiDARBox, \"LiDAR\"\n    elif box_type == \"Camera\":\n        return CameraBox, \"Camera\"\n    elif box_type == \"Depth\":\n        return DepthBox, \"Depth\"\n    else:\n        raise ValueError(f\"Unrecognized box type: {box_type}. Please use 'LiDAR', 'Camera', or 'Depth'.\")"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        return 'LiDARBox3D', 'LiDAR'\n    elif box_type == 'Camera':\n        return 'CameraBox3D', 'Camera'\n    elif box_type == 'Depth':\n        return 'DepthBox3D', 'Depth'\n    else:\n        raise ValueError(f'Unrecognized box type {box_type}. '\n                         f'Supported box types are \"LiDAR\", \"Camera\", \"Depth\".')"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages:\n      if not all(isinstance(msg, (Message, dict)) for msg in messages):\n        raise TypeError(\"messages must be a list of Message or dict-like objects\")\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.chat", "completion": "\n    if not model:\n      raise RequestError('must provide a model')\n\n    if messages:\n      for msg in messages:\n        if not isinstance(msg, (dict, Message)):\n          raise TypeError(\"messages must be a list of Message or dict-like objects\")\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.chat", "completion": "\n    if not model:\n      raise RequestError('must provide a model')\n\n    if messages:\n      for message in messages:\n        if not isinstance(message, (Message, dict)):\n          raise TypeError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.chat", "completion": "\n    if not model:\n      raise RequestError('must provide a model')\n\n    if messages:\n      if not all(isinstance(msg, (Message, dict)) for msg in messages):\n        raise TypeError(\"messages must be a list of Message or dict-like objects\")\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages:\n      if not all(isinstance(msg, (Message, dict)) and 'role' in msg and 'content' in msg for msg in messages):\n        raise TypeError(\"messages must be a list of Message or dict-like objects with 'role' and 'content'\")\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.chat", "completion": "\n    if not model:\n      raise RequestError('must provide a model')\n\n    if messages:\n      if not all(isinstance(msg, (dict, Message)) and 'role' in msg and 'content' in msg for msg in messages):\n        raise TypeError(\"messages must be a list of Message or dict-like objects with 'role' and 'content' keys\")\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages:\n      if not all(isinstance(msg, (dict, Message)) and 'role' in msg and 'content' in msg for msg in messages):\n        raise TypeError(\"messages must be a list of Message or dict-like objects with 'role' and 'content'\")\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.chat", "completion": "\n    if not model:\n      raise RequestError('must provide a model')\n\n    if messages:\n      if not all(isinstance(msg, (Message, dict)) for msg in messages):\n        raise TypeError(\"messages must be a list of Message or dict-like objects\")\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.chat", "completion": "\n    if not model:\n      raise RequestError('must provide a model')\n\n    if messages:\n      if not all(isinstance(msg, (dict, Message)) and all(k in msg for k in ['role', 'content']) for msg in messages):\n        raise TypeError('messages must be a list of Message or dict-like objects with \"role\" and \"content\"')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.chat", "completion": "\n    if not model:\n      raise RequestError('must provide a model')\n\n    if messages:\n      if not all(isinstance(msg, (dict, Message)) and 'role' in msg and 'content' in msg for msg in messages):\n        raise TypeError(\"messages must be a list of Message or dict-like objects with 'role' and 'content'\")\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages:\n      if not all(isinstance(msg, (Message, dict)) for msg in messages):\n        raise TypeError(\"messages must be a list of Message or dict-like objects\")\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.chat", "completion": "\n    if not model:\n      raise RequestError('must provide a model')\n\n    if messages:\n      if not all(isinstance(msg, (dict, Message)) and 'role' in msg and 'content' in msg for msg in messages):\n        raise TypeError(\"messages must be a list of Message or dict-like objects with 'role' and 'content'\")\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages:\n      if not all(isinstance(msg, (dict, Message)) and all(key in msg for key in ('role', 'content')) for msg in messages):\n        raise TypeError(\"messages must be a list of Message or dict-like objects with 'role' and 'content' keys\")\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages:\n      for message in messages:\n        if not isinstance(message, (dict, Message)):\n          raise TypeError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.chat", "completion": "\n    if not model:\n      raise RequestError('must provide a model')\n\n    if messages:\n      if not all(isinstance(msg, (Message, dict)) for msg in messages):\n        raise TypeError(\"messages must be a list of Message or dict-like objects\")\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages:\n      for msg in messages:\n        if not isinstance(msg, (Message, dict)):\n          raise TypeError(\"messages must be a list of Message or dict-like objects\")\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages:\n      if not all(isinstance(msg, (dict, Message)) and all(key in msg for key in ['role', 'content']) for msg in messages):\n        raise TypeError(\"messages must be a list of Message or dict-like objects with 'role' and 'content' keys\")\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages:\n      for message in messages:\n        if not isinstance(message, (dict, Message)):\n          raise TypeError(\"messages must be a list of Message or dict-like objects\")\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages:\n      if not isinstance(messages, (list, tuple)):\n        raise TypeError(\"messages must be a list of Message or dict-like objects\")\n\n      for message in messages:\n        if not isinstance(message, dict):\n          raise TypeError(\"messages must be a list of Message or dict-like objects\")\n\n        if 'role' not in message or 'content' not in message:\n          raise RequestError(\"each message must contain 'role' and 'content'\")\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages:\n      if not all(isinstance(msg, (dict, Message)) and 'role' in msg and 'content' in msg for msg in messages):\n        raise TypeError(\"messages must be a list of Message or dict-like objects with 'role' and 'content'\")\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "\n    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "        if not model:\n            raise RequestError('must provide a model')\n\n        return self._request_stream(\n            'POST',\n            '/api/pull',\n            json={\n                'model': model,\n                'insecure': insecure,\n            },\n            stream=stream,\n        )"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "\n    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "\n    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.generate", "completion": "\n    request_data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context or [],\n      'raw': raw,\n      'format': format,\n      'images': images or [],\n      'options': options or {},\n      'keep_alive': keep_alive,\n    }\n\n    if stream:\n      return self._request_stream('POST', '/generate', json=request_data, stream=True)\n    else:\n      return self._request('POST', '/generate', json=request_data).json()"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise ValueError(\"Model is required for generating a response\")\n\n    request_params = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context or [],\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive\n    }\n\n    if stream:\n      return self._request_stream('POST', '/generate', json=request_params, stream=True)\n    else:\n      return self._request('POST', '/generate', json=request_params).json()"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise ValueError(\"Model is required for generating a response\")\n\n    if not stream:\n      return self._request(\n        'POST',\n        '/generate',\n        json={\n          'model': model,\n          'prompt': prompt,\n          'system': system,\n          'template': template,\n          'context': context or [],\n          'raw': raw,\n          'format': format,\n          'images': images,\n          'options': options,\n          'keep_alive': keep_alive,\n        },\n      ).json()\n    else:\n      return self._stream(\n        'POST',\n        '/generate',\n        json={\n          'model': model,\n          'prompt': prompt,\n          'system': system,\n          'template': template,\n          'context': context or [],\n          'raw': raw,\n          'format': format,\n          'images': images,\n          'options': options,\n          'keep_alive': keep_alive,\n        },\n      )"}
{"namespace": "ollama._client.Client.generate", "completion": "    request_params = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive\n    }\n\n    if stream:\n      return self._request_stream('POST', '/generate', stream=True, json=request_params)\n    else:\n      return self._request('POST', '/generate', json=request_params).json()"}
{"namespace": "ollama._client.Client.generate", "completion": "\n    if not model:\n      raise ValueError(\"Model must be provided for generating a response\")\n\n    request_data = {\n      \"model\": model,\n      \"prompt\": prompt,\n      \"system\": system,\n      \"template\": template,\n      \"context\": context if context is not None else [],\n      \"raw\": raw,\n      \"format\": format,\n      \"images\": images if images is not None else [],\n      \"options\": options if options is not None else {},\n      \"keep_alive\": keep_alive,\n    }\n\n    if stream:\n      return self._request_stream(\"POST\", \"/generate\", json=request_data, stream=True)\n    else:\n      return self._request(\"POST\", \"/generate\", json=request_data).json()"}
{"namespace": "ollama._client.Client.generate", "completion": "    request_data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context or [],\n      'raw': raw,\n      'format': format,\n      'images': images or [],\n      'options': options or {},\n      'keep_alive': keep_alive\n    }\n\n    if stream:\n      return self._request_stream('POST', '/generate', json=request_data, stream=True)\n    else:\n      return self._request('POST', '/generate', json=request_data)"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise ValueError(\"Model is required for generating a response\")\n\n    request_data = {\n      \"model\": model,\n      \"prompt\": prompt,\n      \"system\": system,\n      \"template\": template,\n      \"context\": context if context is not None else [],\n      \"raw\": raw,\n      \"format\": format,\n      \"images\": images if images is not None else [],\n      \"options\": options if options is not None else {},\n      \"keep_alive\": keep_alive\n    }\n\n    if stream:\n      return self._request_stream(\"POST\", \"/generate\", json=request_data, stream=True)\n    else:\n      return self._request(\"POST\", \"/generate\", json=request_data).json()"}
{"namespace": "ollama._client.Client.generate", "completion": "    request_data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive\n    }\n    if stream:\n      return self._request_stream('POST', '/generate', json=request_data, stream=True)\n    else:\n      return self._request_stream('POST', '/generate', json=request_data)"}
{"namespace": "ollama._client.Client.generate", "completion": "    # Construct the request payload\n    payload = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context if context is not None else [],\n      'raw': raw,\n      'format': format,\n      'images': images if images is not None else [],\n      'options': options if options is not None else {},\n      'keep_alive': keep_alive,\n    }\n\n    # Make the request\n    if stream:\n      return self._request_stream('POST', '/generate', json=payload, stream=True)\n    else:\n      return self._request('POST', '/generate', json=payload)"}
{"namespace": "ollama._client.Client.generate", "completion": "\n    if not model:\n      raise ValueError(\"Model is required for generating a response\")\n\n    request_params = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context or [],\n      'raw': raw,\n      'format': format,\n      'images': images or [],\n      'options': options or {},\n      'keep_alive': keep_alive\n    }\n\n    if stream:\n      return self._request_stream('POST', '/generate', stream=True, json=request_params)\n    else:\n      return self._request('POST', '/generate', json=request_params).json()"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n        raise RequestError(\"Model is required for generating a response\")\n    \n    request_params = {\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'raw': raw,\n        'format': format,\n        'images': images or [],\n        'options': options or {},\n        'keep_alive': keep_alive\n    }\n\n    if stream:\n        return self._request_stream('POST', '/generate', json=request_params, stream=True)\n    else:\n        return self._request('POST', '/generate', json=request_params).json()"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise ValueError(\"Model is required for generating a response\")\n\n    request_params = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context or [],\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive\n    }\n\n    if stream:\n      return self._request_stream('POST', '/generate', stream=True, json=request_params)\n    else:\n      return self._request('POST', '/generate', json=request_params).json()"}
{"namespace": "ollama._client.Client.generate", "completion": "\n    if not model:\n      raise ValueError(\"Model must be provided for generating a response\")\n\n    request_params = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive\n    }\n\n    response = self._request_stream(\n      'POST',\n      '/generate',\n      json=request_params,\n      stream=stream\n    )\n\n    return response"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise ValueError(\"Model is required for generating a response\")\n\n    headers = {}\n    if format == 'json':\n      headers['Accept'] = 'application/json'\n\n    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context or [],\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    if stream:\n      return self._request_stream('POST', '/generate', json=data, stream=True)\n    else:\n      return self._request('POST', '/generate', json=data).json()"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise ValueError(\"Model is required for generating a response\")\n\n    request_params = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive\n    }\n\n    if stream:\n      return self._request_stream('POST', '/generate', stream=True, json=request_params)\n    else:\n      return self._request('POST', '/generate', json=request_params).json()"}
{"namespace": "ollama._client.Client.generate", "completion": "\n    if not model:\n      raise ValueError(\"Model is required for generating a response\")\n\n    request_data = {\n      \"model\": model,\n      \"prompt\": prompt,\n      \"system\": system,\n      \"template\": template,\n      \"context\": context if context is not None else [],\n      \"raw\": raw,\n      \"format\": format,\n      \"images\": images if images is not None else [],\n      \"options\": options if options is not None else {},\n      \"keep_alive\": keep_alive,\n    }\n\n    if stream:\n      return self._request_stream('POST', '/generate', json=request_data, stream=True)\n    else:\n      return self._request_stream('POST', '/generate', json=request_data)"}
{"namespace": "ollama._client.Client.generate", "completion": "\n    if not model:\n        raise ValueError(\"Model is required for generating a response\")\n\n    request_params = {\n        \"model\": model,\n        \"prompt\": prompt,\n        \"system\": system,\n        \"template\": template,\n        \"context\": context,\n        \"raw\": raw,\n        \"format\": format,\n        \"images\": images,\n        \"options\": options,\n        \"keep_alive\": keep_alive\n    }\n\n    if stream:\n        return self._request_stream(\"POST\", \"/generate\", json=request_params, stream=True)\n    else:\n        return self._request(\"POST\", \"/generate\", json=request_params).json()"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise ValueError(\"Model is required for generating a response\")\n\n    request_data = {\n      \"model\": model,\n      \"prompt\": prompt,\n      \"system\": system,\n      \"template\": template,\n      \"context\": context if context else [],\n      \"raw\": raw,\n      \"format\": format,\n      \"images\": images if images else [],\n      \"options\": options if options else {},\n      \"keep_alive\": keep_alive\n    }\n\n    if stream:\n      return self._request_stream('POST', '/generate', json=request_data, stream=True)\n    else:\n      return self._request('POST', '/generate', json=request_data).json()"}
{"namespace": "ollama._client.Client.generate", "completion": "    request_data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive\n    }\n\n    if stream:\n      return self._request_stream('POST', '/generate', json=request_data, stream=True)\n    else:\n      return self._request('POST', '/generate', json=request_data)"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise ValueError(\"Model is required for generating a response\")\n\n    request_params = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    if stream:\n      return self._request_stream('POST', '/generate', stream=True, json=request_params)\n    else:\n      return self._request('POST', '/generate', json=request_params).json()"}
{"namespace": "ollama._client.Client.push", "completion": "\n    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "\n    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "\n    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "\n    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "\n    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "\n    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "\n    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "\n    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "\n    if not path and not modelfile:\n      raise RequestError('either path or modelfile must be provided')\n\n    if path:\n      with open(path, 'r') as file:\n        modelfile = file.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'model': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "\n    if not path and not modelfile:\n      raise RequestError('either path or modelfile must be provided')\n\n    if path:\n      with open(path, 'r') as file:\n        modelfile = file.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'model': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "\n    if not path and not modelfile:\n      raise RequestError('either path or modelfile must be provided')\n\n    if path:\n      with open(path, 'r') as file:\n        modelfile = file.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'model': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('either path or modelfile must be provided')\n\n    if path:\n      with open(path, 'r') as file:\n        modelfile = file.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'model': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "\n    if not path and not modelfile:\n      raise RequestError('either path or modelfile must be provided')\n\n    if path:\n      with open(path, 'r') as file:\n        modelfile = file.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'model': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "\n    if not path and not modelfile:\n      raise RequestError('either path or modelfile must be provided')\n\n    if path:\n      with open(path, 'rb') as file:\n        modelfile = file.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'model': model,\n        'modelfile': b64encode(modelfile).decode('utf-8'),\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "\n    if not path and not modelfile:\n      raise RequestError('either path or modelfile must be provided')\n\n    data = {'model': model}\n\n    if modelfile:\n      data['modelfile'] = modelfile\n    else:\n      with open(path, 'rb') as file:\n        data['modelfile'] = b64encode(file.read()).decode('utf-8')\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json=data,\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "\n    if path is None and modelfile is None:\n      raise RequestError('either path or modelfile must be provided')\n\n    files = {'modelfile': (path if path else 'model', open(path, 'rb').read() if path else modelfile, 'application/octet-stream')}\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      files=files,\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "\n    if not path and not modelfile:\n      raise RequestError('either path or modelfile is required')\n\n    if path:\n      with open(path, 'rb') as file:\n        modelfile = file.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'model': model,\n        'modelfile': b64encode(modelfile).decode('utf-8'),\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('either path or modelfile must be provided')\n\n    if path:\n      with open(path, 'r') as file:\n        modelfile = file.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'model': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "\n    if not path and not modelfile:\n      raise RequestError('either path or modelfile must be provided')\n\n    if path:\n      with open(path, 'r') as file:\n        modelfile = file.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'model': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "\n    if not path and not modelfile:\n      raise RequestError('either path or modelfile must be provided')\n\n    if path:\n      with open(path, 'r') as file:\n        model_content = file.read()\n    else:\n      model_content = modelfile\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'model': model,\n        'content': model_content,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('either path or modelfile must be provided')\n\n    if path:\n      with open(path, 'r') as file:\n        modelfile = file.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'model': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('must provide either path or modelfile')\n\n    if path:\n      with open(path, 'r') as file:\n        modelfile = file.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'model': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('must provide either a path or modelfile')\n\n    if path:\n      with open(path, 'rb') as file:\n        modelfile = file.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'model': model,\n        'modelfile': b64encode(modelfile).decode('utf-8'),\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "\n    if not path and not modelfile:\n      raise RequestError('either path or modelfile must be provided')\n\n    if path:\n      with open(path, 'rb') as file:\n        modelfile = file.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'model': model,\n        'modelfile': b64encode(modelfile).decode('utf-8'),\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "\n    if not path and not modelfile:\n      raise RequestError('either path or modelfile must be provided')\n\n    if path:\n      with open(path, 'rb') as file:\n        modelfile = file.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'model': model,\n        'file': b64encode(modelfile).decode('utf-8'),\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "\n    if not path and not modelfile:\n      raise RequestError('either path or modelfile must be provided')\n\n    if path:\n      with open(path, 'rb') as file:\n        modelfile = file.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'model': model,\n        'modelfile': b64encode(modelfile).decode('utf-8'),\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('either path or modelfile must be provided')\n\n    if path:\n      with open(path, 'r') as file:\n        modelfile = file.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'model': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "\n    if not (path or modelfile):\n      raise RequestError('either path or modelfile is required')\n\n    if path:\n      with open(path, 'r') as file:\n        modelfile = file.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'model': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    with open(path, 'rb') as file:\n        file_data = file.read()\n        file_hash = sha256(file_data).hexdigest()\n        blob_digest = f'sha256:{file_hash}'\n\n    # Check if the blob already exists on the server\n    response = self._client.head(f'/api/blobs/{blob_digest}')\n    if response.status_code == 404:\n        # If blob does not exist, upload the file as a new blob\n        self._client.post(f'/api/blobs/{blob_digest}', data=file_data)\n\n    return blob_digest"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    with open(path, 'rb') as file:\n        file_content = file.read()\n        file_hash = sha256(file_content).hexdigest()\n        blob_url = f'/api/blob/{file_hash}'\n\n        # Check if the blob already exists\n        response = self._client.head(blob_url)\n        if response.status_code == 404:\n            # Blob does not exist, upload the file\n            self._client.post(blob_url, content=file_content)\n        \n        return f'sha256:{file_hash}'"}
{"namespace": "ollama._client.Client._create_blob", "completion": "\n    with open(path, 'rb') as file:\n        file_data = file.read()\n        file_hash = sha256(file_data).hexdigest()\n        blob_digest = f'sha256:{file_hash}'\n\n    # Check if the blob exists on the server\n    response = self._client.head(f'/api/blobs/{blob_digest}')\n    if response.status_code == 404:\n        # If blob not found, upload the file\n        self._client.post(f'/api/blobs/{blob_digest}', content=file_data)\n\n    return blob_digest"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    with open(path, 'rb') as file:\n        file_data = file.read()\n        file_hash = sha256(file_data).hexdigest()\n        blob_url = f'/api/blobs/{file_hash}'\n\n        # Check if blob already exists\n        response = self._client.head(blob_url)\n        if response.status_code == 404:  # Blob not found, upload it\n            self._client.post(blob_url, content=file_data)\n        \n        return f'sha256:{file_hash}'"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    with open(path, 'rb') as file:\n        file_content = file.read()\n        file_digest = sha256(file_content).digest()\n        file_digest_hex = binascii.hexlify(file_digest).decode('utf-8')\n        blob_digest = f'sha256:{file_digest_hex}'\n\n    # Check if blob exists on the server\n    response = self._client.head(f'/api/blobs/{blob_digest}')\n    if response.status_code == 404:\n        # If blob does not exist, upload the file as a new blob\n        self._client.post(f'/api/blobs/{blob_digest}', content=file_content)\n    \n    return blob_digest"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    with open(path, 'rb') as file:\n        file_content = file.read()\n        checksum = sha256(file_content).hexdigest()\n        digest = f'sha256:{checksum}'\n\n    # Check if the blob already exists on the server\n    response = self._client.head(f'/api/blobs/{digest}')\n    if response.status_code == 404:\n        # If blob does not exist, upload the file as a new blob\n        self._client.post(f'/api/blobs/{digest}', content=file_content)\n\n    return digest"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    with open(path, 'rb') as file:\n        file_data = file.read()\n        file_hash = sha256(file_data).hexdigest()\n        digest = f'sha256:{file_hash}'\n\n        # Check if the blob exists on the server\n        response = self._client.head(f'/api/blobs/{digest}')\n        if response.status_code == 404:\n            # If blob does not exist, upload the file\n            self._client.post(f'/api/blobs/{digest}', data=file_data)\n\n    return digest"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    with open(path, 'rb') as file:\n        file_content = file.read()\n        checksum = sha256(file_content).hexdigest()\n        digest = f'sha256:{checksum}'\n\n    # Check if blob with the same digest already exists on the server\n    response = self._client.head(f'/api/blobs/{digest}')\n    if response.status_code == 404:  # Blob not found, upload the file\n        self._client.post(f'/api/blobs/{digest}', content=file_content)\n\n    return digest"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    with open(path, 'rb') as file:\n        file_content = file.read()\n        file_digest = sha256(file_content).hexdigest()\n        blob_url = f'/api/blob/{file_digest}'\n\n        # Check if the blob already exists\n        response = self._client.head(blob_url)\n        if response.status_code == 404:\n            # If the blob does not exist, upload the file\n            self._client.post(blob_url, content=file_content)\n        \n        return f'sha256:{file_digest}'"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    with open(path, 'rb') as file:\n        file_content = file.read()\n        checksum = sha256(file_content).hexdigest()\n\n    # Check if blob with the same checksum already exists\n    response = self._client.head(f'/api/blobs/{checksum}')\n    if response.status_code == 404:\n        # If blob does not exist, upload the file\n        self._client.post(f'/api/blobs/{checksum}', content=file_content)\n\n    return f'sha256:{checksum}'"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    with open(path, 'rb') as file:\n        file_content = file.read()\n        checksum = sha256(file_content).hexdigest()\n\n    # Check if the blob already exists on the server\n    response = self._client.head(f'/api/blobs/{checksum}')\n    if response.status_code == 404:  # Blob not found, upload the file\n        self._client.post(f'/api/blobs/{checksum}', content=file_content)\n\n    return f'sha256:{checksum}'"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    with open(path, 'rb') as file:\n        file_content = file.read()\n        checksum = sha256(file_content).hexdigest()\n        digest = f'sha256:{checksum}'\n\n    # Check if the blob already exists on the server\n    response = self._client.head(f'/api/blobs/{digest}')\n    if response.status_code == 404:\n        # If the blob does not exist, upload it as a new blob\n        self._client.post(f'/api/blobs/{digest}', data=file_content)\n\n    return digest"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    with open(path, \"rb\") as file:\n        file_content = file.read()\n        file_hash = sha256(file_content).hexdigest()\n        blob_digest = f\"sha256:{file_hash}\"\n\n    # Check if the blob exists on the server\n    response = self._client.head(f\"/api/blobs/{blob_digest}\")\n\n    if response.status_code == 404:\n        # Blob does not exist, upload the file\n        self._client.post(f\"/api/blobs/{blob_digest}\", content=file_content)\n\n    return blob_digest"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    with open(path, 'rb') as file:\n        file_content = file.read()\n        file_hash = sha256(file_content).digest()\n        file_digest = 'sha256:' + binascii.hexlify(file_hash).decode('utf-8')\n\n    # Check if the blob already exists on the server\n    response = self._client.head('/api/blobs/' + file_digest)\n    if response.status_code == 404:\n        # If not found, upload the file as a new blob\n        self._client.post('/api/blobs', content=file_content)\n    \n    return file_digest"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    with open(path, 'rb') as file:\n        file_content = file.read()\n        file_digest = sha256(file_content).hexdigest()\n        blob_url = f'/api/blobs/{file_digest}'\n\n        # Check if the blob already exists\n        response = self._client.head(blob_url)\n        if response.status_code == 404:\n            # Blob does not exist, upload the file\n            self._client.post(blob_url, content=file_content)\n        \n        return f'sha256:{file_digest}'"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    with open(path, 'rb') as file:\n        file_content = file.read()\n        file_hash = sha256(file_content).hexdigest()\n\n    response = self._client.head(f'/api/blobs/{file_hash}')\n    if response.status_code == 404:\n        self._client.post(f'/api/blobs/{file_hash}', content=file_content)\n\n    return f'sha256:{file_hash}'"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    with open(path, 'rb') as file:\n        file_content = file.read()\n        file_digest = sha256(file_content).digest()\n        file_digest_hex = binascii.hexlify(file_digest).decode('utf-8')\n        file_digest_encoded = f'sha256:{file_digest_hex}'\n\n    # Check if the blob exists on the server\n    response = self._client.head(f'/api/blobs/{file_digest_encoded}')\n\n    if response.status_code == 404:\n        # Blob not found, upload the file\n        upload_response = self._client.post('/api/blobs', data=file_content)\n        upload_response.raise_for_status()\n\n    return file_digest_encoded"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    # Open the file and calculate its SHA-256 checksum\n    with open(path, 'rb') as file:\n        file_content = file.read()\n        checksum = sha256(file_content).hexdigest()\n\n    # Check if the blob with the checksum already exists on the server\n    response = self._client.head(f'/api/blobs/{checksum}')\n    if response.status_code == 404:\n        # If not found, upload the file as a new blob\n        self._client.post(f'/api/blobs/{checksum}', content=file_content)\n\n    # Return the digest of the file\n    return f'sha256:{checksum}'"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    def _calculate_sha256(file_path: Union[str, Path]) -> str:\n      with open(file_path, 'rb') as file:\n        file_content = file.read()\n        sha256_hash = sha256(file_content).hexdigest()\n      return sha256_hash\n\n    def _check_blob_exists(sha256_digest: str) -> bool:\n      response = self._client.head(f'/api/blobs/{sha256_digest}')\n      return response.status_code == 200\n\n    def _upload_blob(file_path: Union[str, Path], sha256_digest: str) -> None:\n      with open(file_path, 'rb') as file:\n        file_content = file.read()\n        self._client.post('/api/blobs', data=file_content, headers={'Content-Type': 'application/octet-stream', 'Digest': f'sha-256={sha256_digest}'})\n\n    sha256_digest = _calculate_sha256(path)\n    if not _check_blob_exists(sha256_digest):\n      _upload_blob(path, sha256_digest)\n\n    return f'sha256:{sha256_digest}'"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    with open(path, 'rb') as file:\n      file_content = file.read()\n      file_hash = sha256(file_content).digest()\n      digest = 'sha256:' + b64encode(file_hash).decode('utf-8')\n\n    # Check if the blob exists on the server\n    response = self._client.head('/api/blobs/' + digest)\n    if response.status_code == 404:\n      # Blob does not exist, upload the file\n      response = self._client.post('/api/blobs', content=file_content)\n      response.raise_for_status()\n\n    return digest"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "\n        self._state_dict = state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "\n        self._state_dict = state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "\n        self._state_dict = state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "\n        self._state_dict = state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "\n        self._state_dict = state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state: Dict[str, Any] = self._state_dict\n\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\"Mismatch: 'shuffle' parameter in state dictionary does not match the current state.\")\n\n        if state[\"num_workers\"] != self.worker_env.world_size:\n            raise ValueError(\"Mismatch: 'num_workers' parameter in state dictionary does not match the current state.\")\n\n        if state[\"input_dir_path\"] != self.input_dir.path or state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\"Mismatch: 'input directory path or URL' in state dictionary does not match the current state.\")\n\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\"Mismatch: 'seed' parameter in state dictionary does not match the current state.\")\n\n        if state[\"item_loader\"] is not None and self.item_loader is not None:\n            if state[\"item_loader\"] != self.item_loader.state_dict():\n                raise ValueError(\"Mismatch: 'item_loader' state in state dictionary does not match the current state.\")\n\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\"Mismatch: 'drop_last' parameter in state dictionary does not match the current state.\")"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict:\n            state: Dict[str, Any] = self._state_dict\n            if state[\"shuffle\"] != self.shuffle:\n                raise ValueError(\"Shuffle parameter in state dictionary does not match the current state.\")\n            if state[\"num_workers\"] != self.worker_env.world_size:\n                raise ValueError(\"Number of workers in state dictionary does not match the current state.\")\n            if state[\"input_dir_path\"] != self.input_dir.path or state[\"input_dir_url\"] != self.input_dir.url:\n                raise ValueError(\"Input directory path or URL in state dictionary does not match the current state.\")\n            if state[\"seed\"] != self.seed:\n                raise ValueError(\"Seed in state dictionary does not match the current state.\")\n            if state[\"item_loader\"] and state[\"item_loader\"] != self.item_loader.state_dict():\n                raise ValueError(\"Item loader state in state dictionary does not match the current state.\")\n            if state[\"drop_last\"] != self.drop_last:\n                raise ValueError(\"Drop last flag in state dictionary does not match the current state.\")"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict:\n            state: Dict[str, Any] = self._state_dict\n            if state[\"shuffle\"] != self.shuffle:\n                raise ValueError(\"Shuffle parameter in state_dict does not match the current shuffle state.\")\n            if state[\"num_workers\"] != self.worker_env.world_size:\n                raise ValueError(\"Number of workers in state_dict does not match the current number of workers.\")\n            if state[\"input_dir_path\"] != self.input_dir.path:\n                raise ValueError(\"Input directory path in state_dict does not match the current input directory path.\")\n            if state[\"input_dir_url\"] != self.input_dir.url:\n                raise ValueError(\"Input directory URL in state_dict does not match the current input directory URL.\")\n            if state[\"seed\"] != self.seed:\n                raise ValueError(\"Seed in state_dict does not match the current seed.\")\n            if state[\"drop_last\"] != self.drop_last:\n                raise ValueError(\"Drop_last flag in state_dict does not match the current drop_last flag.\")\n            if state[\"item_loader\"] and self.item_loader:\n                if state[\"item_loader\"] != self.item_loader.state_dict():\n                    raise ValueError(\"Item loader state in state_dict does not match the current item loader state.\")\n            elif state[\"item_loader\"] or self.item_loader:\n                raise ValueError(\"Item loader state in state_dict does not match the current item loader state.\")"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict:\n            state: Dict[str, Any] = self._state_dict\n            if state[\"shuffle\"] != self.shuffle:\n                raise ValueError(\"Shuffle parameter in the state dictionary does not match the current state.\")\n            if state[\"num_workers\"] != self.worker_env.world_size:\n                raise ValueError(\"Number of workers in the state dictionary does not match the current state.\")\n            if state[\"input_dir_path\"] != self.input_dir.path:\n                raise ValueError(\"Input directory path in the state dictionary does not match the current state.\")\n            if state[\"input_dir_url\"] != self.input_dir.url:\n                raise ValueError(\"Input directory URL in the state dictionary does not match the current state.\")\n            if state[\"seed\"] != self.seed:\n                raise ValueError(\"Seed in the state dictionary does not match the current state.\")\n            if state[\"item_loader\"] != (self.item_loader.state_dict() if self.item_loader else None):\n                raise ValueError(\"Item loader state in the state dictionary does not match the current state.\")\n            if state[\"drop_last\"] != self.drop_last:\n                raise ValueError(\"Drop last flag in the state dictionary does not match the current state.\")"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict:\n            state: Dict[str, Any] = self._state_dict\n            if state[\"shuffle\"] != self.shuffle:\n                raise ValueError(\"Mismatch in shuffle parameter between state dictionary and current state\")\n            if state[\"num_workers\"] != self.worker_env.world_size:\n                raise ValueError(\"Mismatch in num_workers parameter between state dictionary and current state\")\n            if state[\"input_dir_path\"] != self.input_dir.path:\n                raise ValueError(\"Mismatch in input directory path between state dictionary and current state\")\n            if state[\"input_dir_url\"] != self.input_dir.url:\n                raise ValueError(\"Mismatch in input directory URL between state dictionary and current state\")\n            if state[\"seed\"] != self.seed:\n                raise ValueError(\"Mismatch in seed parameter between state dictionary and current state\")\n            if state[\"item_loader\"] != (self.item_loader.state_dict() if self.item_loader else None):\n                raise ValueError(\"Mismatch in item_loader state between state dictionary and current state\")\n            if state[\"drop_last\"] != self.drop_last:\n                raise ValueError(\"Mismatch in drop_last flag between state dictionary and current state\")"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict:\n            state: Dict[str, Any] = self._state_dict\n            if state[\"shuffle\"] != self.shuffle:\n                raise ValueError(\"Shuffle state in the state dictionary does not match the current shuffle state.\")\n            if state[\"num_workers\"] != self.worker_env.world_size:\n                raise ValueError(\"Number of workers in the state dictionary does not match the current number of workers.\")\n            if state[\"input_dir_path\"] != self.input_dir.path or state[\"input_dir_url\"] != self.input_dir.url:\n                raise ValueError(\"Input directory path or URL in the state dictionary does not match the current input directory.\")\n            if state[\"seed\"] != self.seed:\n                raise ValueError(\"Seed in the state dictionary does not match the current seed.\")\n            if state[\"item_loader\"] and self.item_loader:\n                if state[\"item_loader\"] != self.item_loader.state_dict():\n                    raise ValueError(\"Item loader state in the state dictionary does not match the current item loader state.\")\n            if state[\"drop_last\"] != self.drop_last:\n                raise ValueError(\"Drop last flag in the state dictionary does not match the current drop last flag.\")"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict:\n            state: Dict[str, Any] = self._state_dict\n\n            # Validate shuffle\n            if state[\"shuffle\"] != self.shuffle:\n                raise ValueError(\"Mismatch in shuffle parameter between state dictionary and current state.\")\n\n            # Validate num_workers\n            if state[\"world_size\"] != self.distributed_env.world_size:\n                raise ValueError(\"Mismatch in num_workers parameter between state dictionary and current state.\")\n\n            # Validate input directory path and URL\n            if state[\"input_dir_path\"] != self.input_dir.path or state[\"input_dir_url\"] != self.input_dir.url:\n                raise ValueError(\"Mismatch in input directory path or URL between state dictionary and current state.\")\n\n            # Validate seed\n            if state[\"seed\"] != self.seed:\n                raise ValueError(\"Mismatch in seed parameter between state dictionary and current state.\")\n\n            # Validate item_loader state\n            if state[\"item_loader\"] is not None and self.item_loader is not None:\n                if state[\"item_loader\"] != self.item_loader.state_dict():\n                    raise ValueError(\"Mismatch in item_loader state between state dictionary and current state.\")\n\n            # Validate drop_last flag\n            if state[\"drop_last\"] != self.drop_last:\n                raise ValueError(\"Mismatch in drop_last flag between state dictionary and current state.\")"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict:\n            state: Dict[str, Any] = self._state_dict\n            if state[\"shuffle\"] != self.shuffle:\n                raise ValueError(\"Mismatch: shuffle parameter in state dictionary does not match current state.\")\n            if state[\"num_workers\"] != self.worker_env.world_size:\n                raise ValueError(\"Mismatch: num_workers parameter in state dictionary does not match current state.\")\n            if state[\"input_dir_path\"] != self.input_dir.path:\n                raise ValueError(\"Mismatch: input_dir_path parameter in state dictionary does not match current state.\")\n            if state[\"input_dir_url\"] != self.input_dir.url:\n                raise ValueError(\"Mismatch: input_dir_url parameter in state dictionary does not match current state.\")\n            if state[\"seed\"] != self.seed:\n                raise ValueError(\"Mismatch: seed parameter in state dictionary does not match current state.\")\n            if state[\"item_loader\"] != (self.item_loader.state_dict() if self.item_loader else None):\n                raise ValueError(\"Mismatch: item_loader state in state dictionary does not match current state.\")\n            if state[\"drop_last\"] != self.drop_last:\n                raise ValueError(\"Mismatch: drop_last parameter in state dictionary does not match current state.\")"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict:\n            state: Dict[str, Any] = self._state_dict\n            if state[\"shuffle\"] != self.shuffle:\n                raise ValueError(\"Mismatch in shuffle parameter between state dictionary and current state.\")\n            if state[\"num_workers\"] != self.worker_env.world_size:\n                raise ValueError(\"Mismatch in num_workers parameter between state dictionary and current state.\")\n            if state[\"input_dir_path\"] != self.input_dir.path:\n                raise ValueError(\"Mismatch in input directory path between state dictionary and current state.\")\n            if state[\"input_dir_url\"] != self.input_dir.url:\n                raise ValueError(\"Mismatch in input directory URL between state dictionary and current state.\")\n            if state[\"seed\"] != self.seed:\n                raise ValueError(\"Mismatch in seed parameter between state dictionary and current state.\")\n            if state[\"item_loader\"] and self.item_loader and state[\"item_loader\"] != self.item_loader.state_dict():\n                raise ValueError(\"Mismatch in item_loader state between state dictionary and current state.\")\n            if state[\"drop_last\"] != self.drop_last:\n                raise ValueError(\"Mismatch in drop_last flag between state dictionary and current state.\")"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict:\n            state: Dict[str, Any] = self._state_dict\n\n            if state[\"shuffle\"] != self.shuffle:\n                raise ValueError(\"Mismatch in shuffle parameter between state dictionary and current state\")\n\n            if state[\"num_workers\"] != self.worker_env.world_size:\n                raise ValueError(\"Mismatch in num_workers parameter between state dictionary and current state\")\n\n            if state[\"input_dir_path\"] != self.input_dir.path:\n                raise ValueError(\"Mismatch in input directory path between state dictionary and current state\")\n\n            if state[\"input_dir_url\"] != self.input_dir.url:\n                raise ValueError(\"Mismatch in input directory URL between state dictionary and current state\")\n\n            if state[\"seed\"] != self.seed:\n                raise ValueError(\"Mismatch in seed parameter between state dictionary and current state\")\n\n            if state[\"item_loader\"] is not None and self.item_loader is not None:\n                if state[\"item_loader\"] != self.item_loader.state_dict():\n                    raise ValueError(\"Mismatch in item_loader state between state dictionary and current state\")\n\n            if state[\"drop_last\"] != self.drop_last:\n                raise ValueError(\"Mismatch in drop_last parameter between state dictionary and current state\")"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict:\n            state: Dict[str, Any] = self._state_dict\n            if state[\"shuffle\"] != self.shuffle:\n                raise ValueError(\"Mismatch in 'shuffle' parameter between state dictionary and current state\")\n            if state[\"num_workers\"] != self.worker_env.world_size:\n                raise ValueError(\"Mismatch in 'num_workers' parameter between state dictionary and current state\")\n            if state[\"input_dir_path\"] != self.input_dir.path:\n                raise ValueError(\"Mismatch in 'input_dir_path' parameter between state dictionary and current state\")\n            if state[\"input_dir_url\"] != self.input_dir.url:\n                raise ValueError(\"Mismatch in 'input_dir_url' parameter between state dictionary and current state\")\n            if state[\"seed\"] != self.seed:\n                raise ValueError(\"Mismatch in 'seed' parameter between state dictionary and current state\")\n            if state[\"item_loader\"] != self.item_loader.state_dict() if self.item_loader else None:\n                raise ValueError(\"Mismatch in 'item_loader' parameter between state dictionary and current state\")\n            if state[\"drop_last\"] != self.drop_last:\n                raise ValueError(\"Mismatch in 'drop_last' parameter between state dictionary and current state\")"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict:\n            state: Dict[str, Any] = self._state_dict\n            if state[\"shuffle\"] != self.shuffle:\n                raise ValueError(\"The shuffle parameter in the state dictionary does not match the current state.\")\n            if state[\"num_workers\"] != self.worker_env.world_size:\n                raise ValueError(\"The num_workers parameter in the state dictionary does not match the current state.\")\n            if state[\"input_dir_path\"] != self.input_dir.path:\n                raise ValueError(\"The input directory path in the state dictionary does not match the current state.\")\n            if state[\"input_dir_url\"] != self.input_dir.url:\n                raise ValueError(\"The input directory URL in the state dictionary does not match the current state.\")\n            if state[\"seed\"] != self.seed:\n                raise ValueError(\"The seed parameter in the state dictionary does not match the current state.\")\n            if state[\"drop_last\"] != self.drop_last:\n                raise ValueError(\"The drop_last parameter in the state dictionary does not match the current state.\")\n            if state[\"item_loader\"]:\n                if not self.item_loader or state[\"item_loader\"] != self.item_loader.state_dict():\n                    raise ValueError(\"The item_loader state in the state dictionary does not match the current state.\")"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict:\n            state: Dict[str, Any] = self._state_dict\n            if state[\"shuffle\"] != self.shuffle:\n                raise ValueError(\"Mismatch in shuffle parameter between state dictionary and current state\")\n            if state[\"num_workers\"] != self.worker_env.world_size:\n                raise ValueError(\"Mismatch in num_workers parameter between state dictionary and current state\")\n            if state[\"input_dir_path\"] != self.input_dir.path:\n                raise ValueError(\"Mismatch in input directory path between state dictionary and current state\")\n            if state[\"input_dir_url\"] != self.input_dir.url:\n                raise ValueError(\"Mismatch in input directory URL between state dictionary and current state\")\n            if state[\"seed\"] != self.seed:\n                raise ValueError(\"Mismatch in seed parameter between state dictionary and current state\")\n            if state[\"item_loader\"] != self.item_loader.state_dict() if self.item_loader else None:\n                raise ValueError(\"Mismatch in item_loader state between state dictionary and current state\")\n            if state[\"drop_last\"] != self.drop_last:\n                raise ValueError(\"Mismatch in drop_last flag between state dictionary and current state\")"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict is None:\n            return\n\n        state: Dict[str, Any] = self._state_dict\n\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\"Mismatch in shuffle parameter between state dictionary and current state\")\n\n        if state[\"num_workers\"] != self.worker_env.world_size:\n            raise ValueError(\"Mismatch in num_workers between state dictionary and current state\")\n\n        if state[\"input_dir_path\"] != self.input_dir.path or state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\"Mismatch in input directory path or URL between state dictionary and current state\")\n\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\"Mismatch in seed between state dictionary and current state\")\n\n        if state[\"item_loader\"] is not None and self.item_loader is not None:\n            if state[\"item_loader\"] != self.item_loader.state_dict():\n                raise ValueError(\"Mismatch in item_loader state between state dictionary and current state\")\n\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\"Mismatch in drop_last flag between state dictionary and current state\")"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict:\n            state: Dict[str, Any] = self._state_dict\n            if state[\"shuffle\"] != self.shuffle:\n                raise ValueError(\"Mismatch in 'shuffle' parameter between state dictionary and current state\")\n            if state[\"num_workers\"] != self.worker_env.world_size:\n                raise ValueError(\"Mismatch in 'num_workers' parameter between state dictionary and current state\")\n            if state[\"input_dir_path\"] != self.input_dir.path:\n                raise ValueError(\"Mismatch in 'input_dir_path' parameter between state dictionary and current state\")\n            if state[\"input_dir_url\"] != self.input_dir.url:\n                raise ValueError(\"Mismatch in 'input_dir_url' parameter between state dictionary and current state\")\n            if state[\"seed\"] != self.seed:\n                raise ValueError(\"Mismatch in 'seed' parameter between state dictionary and current state\")\n            if state[\"item_loader\"] != (self.item_loader.state_dict() if self.item_loader else None):\n                raise ValueError(\"Mismatch in 'item_loader' parameter between state dictionary and current state\")\n            if state[\"drop_last\"] != self.drop_last:\n                raise ValueError(\"Mismatch in 'drop_last' parameter between state dictionary and current state\")"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict:\n            state: Dict[str, Any] = self._state_dict\n\n            if state[\"shuffle\"] != self.shuffle:\n                raise ValueError(\"Mismatch in shuffle parameter between state dictionary and current state\")\n\n            if state[\"num_workers\"] != self.worker_env.world_size:\n                raise ValueError(\"Mismatch in num_workers parameter between state dictionary and current state\")\n\n            if state[\"input_dir_path\"] != self.input_dir.path or state[\"input_dir_url\"] != self.input_dir.url:\n                raise ValueError(\"Mismatch in input directory path or URL between state dictionary and current state\")\n\n            if state[\"seed\"] != self.seed:\n                raise ValueError(\"Mismatch in seed parameter between state dictionary and current state\")\n\n            if state[\"item_loader\"] and self.item_loader:\n                if state[\"item_loader\"] != self.item_loader.state_dict():\n                    raise ValueError(\"Mismatch in item_loader state between state dictionary and current state\")\n\n            if state[\"drop_last\"] != self.drop_last:\n                raise ValueError(\"Mismatch in drop_last parameter between state dictionary and current state\")"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        state: Dict[str, Any] = self._state_dict\n\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\"Mismatch in shuffle parameter between state dictionary and current state\")\n\n        if state[\"num_workers\"] != self.worker_env.world_size:\n            raise ValueError(\"Mismatch in num_workers parameter between state dictionary and current state\")\n\n        if state[\"input_dir_path\"] != self.input_dir.path or state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\"Mismatch in input directory path or URL between state dictionary and current state\")\n\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\"Mismatch in seed parameter between state dictionary and current state\")\n\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\"Mismatch in drop_last parameter between state dictionary and current state\")\n\n        if state[\"item_loader\"]:\n            if not self.item_loader or state[\"item_loader\"] != self.item_loader.state_dict():\n                raise ValueError(\"Mismatch in item_loader state between state dictionary and current state\")"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict is None:\n            return\n\n        state: Dict[str, Any] = self._state_dict\n\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\"Mismatch in shuffle parameter between state dictionary and current state\")\n\n        if state[\"num_workers\"] != self.worker_env.world_size:\n            raise ValueError(\"Mismatch in num_workers parameter between state dictionary and current state\")\n\n        if state[\"input_dir_path\"] != self.input_dir.path or state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\"Mismatch in input directory path or URL between state dictionary and current state\")\n\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\"Mismatch in seed parameter between state dictionary and current state\")\n\n        if state[\"item_loader\"] != (self.item_loader.state_dict() if self.item_loader else None):\n            raise ValueError(\"Mismatch in item_loader state between state dictionary and current state\")\n\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\"Mismatch in drop_last parameter between state dictionary and current state\")"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self._state_dict:\n            state: Dict[str, Any] = self._state_dict\n            if state[\"shuffle\"] != self.shuffle:\n                raise ValueError(\"Mismatch in shuffle parameter between state dictionary and current state.\")\n            if state[\"num_workers\"] != self.worker_env.world_size:\n                raise ValueError(\"Mismatch in num_workers parameter between state dictionary and current state.\")\n            if state[\"input_dir_path\"] != self.input_dir.path:\n                raise ValueError(\"Mismatch in input directory path between state dictionary and current state.\")\n            if state[\"input_dir_url\"] != self.input_dir.url:\n                raise ValueError(\"Mismatch in input directory URL between state dictionary and current state.\")\n            if state[\"seed\"] != self.seed:\n                raise ValueError(\"Mismatch in seed parameter between state dictionary and current state.\")\n            if state[\"drop_last\"] != self.drop_last:\n                raise ValueError(\"Mismatch in drop_last parameter between state dictionary and current state.\")\n            if state[\"item_loader\"]:\n                if not self.item_loader or state[\"item_loader\"] != self.item_loader.state_dict():\n                    raise ValueError(\"Mismatch in item_loader state between state dictionary and current state.\")"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "    if self._state_dict is None:\n        return\n\n    state: Dict[str, Any] = self._state_dict\n\n    if state[\"shuffle\"] != self.shuffle:\n        raise ValueError(\"Mismatch in shuffle parameter between state dictionary and current state.\")\n\n    if state[\"num_workers\"] != self.worker_env.world_size:\n        raise ValueError(\"Mismatch in num_workers parameter between state dictionary and current state.\")\n\n    if state[\"input_dir_path\"] != self.input_dir.path or state[\"input_dir_url\"] != self.input_dir.url:\n        raise ValueError(\"Mismatch in input directory path or URL between state dictionary and current state.\")\n\n    if state[\"seed\"] != self.seed:\n        raise ValueError(\"Mismatch in seed parameter between state dictionary and current state.\")\n\n    if state[\"drop_last\"] != self.drop_last:\n        raise ValueError(\"Mismatch in drop_last parameter between state dictionary and current state.\")\n\n    if state[\"item_loader\"] is not None and self.item_loader is not None:\n        item_loader_state = state[\"item_loader\"]\n        if item_loader_state != self.item_loader.state_dict():\n            raise ValueError(\"Mismatch in item_loader state between state dictionary and current state.\")\n    elif state[\"item_loader\"] is not None or self.item_loader is not None:\n        raise ValueError(\"Mismatch in item_loader presence between state dictionary and current state.\")"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent Command Line Interface')\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', nargs='+', type=str, help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', choices=['auto', 'manual'], help='Operational mode, which can be \"auto\" or \"manual\", specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file, specifying where to find the configuration settings.')\n\n    args = parser.parse_args()\n\n    return args"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent Command Line Interface')\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', nargs='+', type=str, help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', choices=['auto', 'manual'], help='Operational mode, which can be \"auto\" or \"manual\", specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file, specifying where to find the configuration settings.')\n\n    return parser.parse_args()"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent Command Line Interface')\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', nargs='+', type=str, help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', choices=['auto', 'manual'], help='Operational mode, which can be \"auto\" or \"manual\", specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file, specifying where to find the configuration settings.')\n\n    return parser.parse_args()"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent Command Line Interface')\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', nargs='+', type=str, help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', choices=['auto', 'manual'], help='Operational mode, which can be \"auto\" or \"manual\", specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file, specifying where to find the configuration settings.')\n\n    return parser.parse_args()"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent Command Line Interface')\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', nargs='+', type=str, help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', help='Operational mode, which can be \"auto\" or \"manual\", specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file, specifying where to find the configuration settings.')\n\n    return parser.parse_args()"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent Command Line Interface')\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', nargs='+', type=str, help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', choices=['auto', 'manual'], help='Operational mode, which can be \"auto\" or \"manual\", specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file, specifying where to find the configuration settings.')\n\n    args = parser.parse_args()\n    return args"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent Command Line Interface')\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', nargs='+', type=str, help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', choices=['auto', 'manual'], help='Operational mode, which can be \"auto\" or \"manual\", specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file, specifying where to find the configuration settings.')\n    \n    return parser.parse_args()"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent Command Line Interface')\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', nargs='+', type=str, help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', choices=['auto', 'manual'], help='Operational mode, which can be \"auto\" or \"manual\", specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file, specifying where to find the configuration settings.')\n\n    args = parser.parse_args()\n    return args"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent Command Line Interface')\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', type=str, nargs='+', help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', choices=['auto', 'manual'], help='Operational mode, which can be \"auto\" or \"manual\", specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file, specifying where to find the configuration settings.')\n\n    return parser.parse_args()"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent Command Line Interface')\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', nargs='+', type=str, help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', help='Operational mode, which can be \"auto\" or \"manual\", specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file, specifying where to find the configuration settings.')\n\n    return parser.parse_args()"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent Command Line Interface')\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', nargs='+', type=str, help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', choices=['auto', 'manual'], help='Operational mode, which can be \"auto\" or \"manual\", specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file, specifying where to find the configuration settings.')\n\n    args = parser.parse_args()\n    return args"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent Command Line Interface')\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', nargs='+', type=str, help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', choices=['auto', 'manual'], help='Operational mode, which can be \"auto\" or \"manual\", specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file, specifying where to find the configuration settings.')\n\n    args = parser.parse_args()\n\n    return args"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent Command Line Interface')\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', nargs='+', type=str, help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', choices=['auto', 'manual'], help='Operational mode, which can be \"auto\" or \"manual\", specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file, specifying where to find the configuration settings.')\n\n    args = parser.parse_args()\n\n    return args"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='Parse command line arguments')\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', nargs='+', type=str, help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', choices=['auto', 'manual'], help='Operational mode, which can be \"auto\" or \"manual\", specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file, specifying where to find the configuration settings.')\n    return parser.parse_args()"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"XAgent Command Line Interface\")\n    parser.add_argument(\"--task\", type=str, required=True, help=\"The task description, specifying what task should be performed.\")\n    parser.add_argument(\"--upload-files\", nargs='+', type=str, help=\"List of files to upload, allowing multiple files to be specified.\")\n    parser.add_argument(\"--model\", type=str, help=\"Model identifier for the task, specifying which model to use.\")\n    parser.add_argument(\"--record-dir\", type=str, help=\"Directory to record task execution logs, specifying where to save the logs.\")\n    parser.add_argument(\"--mode\", type=str, default=\"auto\", help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\")\n    parser.add_argument(\"--quiet\", action=\"store_true\", help=\"If set, the program runs in quiet mode with minimal output.\")\n    parser.add_argument(\"--max-subtask-chain-length\", type=int, help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\")\n    parser.add_argument(\"--enable-ask-human-for-help\", action=\"store_true\", help=\"Flag to enable asking for human assistance during task execution.\")\n    parser.add_argument(\"--max-plan-refine-chain-length\", type=int, help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\")\n    parser.add_argument(\"--max-plan-tree-depth\", type=int, help=\"Maximum depth of the plan tree, specifying how deep the plan tree can be.\")\n    parser.add_argument(\"--max-plan-tree-width\", type=int, help=\"Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.\")\n    parser.add_argument(\"--max-retry-times\", type=int, help=\"Maximum number of retry attempts, specifying how many times a task can be retried upon failure.\")\n    parser.add_argument(\"--config-file\", type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help=\"Path to the configuration file, specifying where to find the configuration settings.\")\n\n    return parser.parse_args()"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent Command Line Interface')\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', type=str, nargs='+', help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', choices=['auto', 'manual'], help='Operational mode, which can be \"auto\" or \"manual\", specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file, specifying where to find the configuration settings.')\n\n    return parser.parse_args()"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent Command Line Interface')\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', nargs='+', type=str, help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', choices=['auto', 'manual'], help='Operational mode, which can be \"auto\" or \"manual\", specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type=str, default=os.environ.get('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file, specifying where to find the configuration settings.')\n\n    args = parser.parse_args()\n\n    return args"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent Command Line Interface')\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', nargs='+', type=str, help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', choices=['auto', 'manual'], help='Operational mode, which can be \"auto\" or \"manual\", specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file, specifying where to find the configuration settings.')\n\n    return parser.parse_args()"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='Parse command line arguments')\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', nargs='+', type=str, help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', help='Operational mode, which can be \"auto\" or \"manual\", specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file, specifying where to find the configuration settings.')\n\n    return parser.parse_args()"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent Command Line Interface')\n    parser.add_argument('--task', type=str, required=True, help='The task description, specifying what task should be performed.')\n    parser.add_argument('--upload-files', nargs='+', type=str, help='List of files to upload, allowing multiple files to be specified.')\n    parser.add_argument('--model', type=str, help='Model identifier for the task, specifying which model to use.')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs, specifying where to save the logs.')\n    parser.add_argument('--mode', type=str, default='auto', choices=['auto', 'manual'], help='Operational mode, which can be \"auto\" or \"manual\", specifying how the task should be executed.')\n    parser.add_argument('--quiet', action='store_true', help='If set, the program runs in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain, specifying how long a subtask chain can be.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Flag to enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain, specifying the limit for refining plans.')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree, specifying how deep the plan tree can be.')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree, specifying the maximum number of branches at any level of the tree.')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts, specifying how many times a task can be retried upon failure.')\n    parser.add_argument('--config-file', type=str, default=os.getenv('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file, specifying where to find the configuration settings.')\n\n    args = parser.parse_args()\n\n    return args"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n    else:\n        input_dir = input_dir.encode(\"utf-8\")\n\n    # Generate a unique directory name by hashing the input directory\n    cache_dir_name = hashlib.md5(input_dir).hexdigest()\n\n    # Create the cache directory in the default location or a specified location\n    cache_dir_path = os.path.join(_DEFAULT_CACHE_DIR, cache_dir_name)\n\n    try:\n        os.makedirs(cache_dir_path, exist_ok=True)\n        return cache_dir_path\n    except OSError:\n        return None"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.md5(input_dir.encode()).hexdigest())\n    else:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.md5(\"\".encode()).hexdigest())\n\n    if not os.path.exists(cache_dir):\n        os.makedirs(cache_dir)\n\n    return cache_dir"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.md5(input_dir.encode()).hexdigest())\n    else:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.md5(\"\".encode()).hexdigest())\n\n    try:\n        os.makedirs(cache_dir, exist_ok=True)\n        return cache_dir\n    except Exception as e:\n        logger.warning(f\"Unable to create cache directory: {e}\")\n        return None"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir:\n        dir_hash = hashlib.md5(input_dir.encode()).hexdigest()\n        cache_dir = os.path.join(os.getenv(\"CACHE_DIR\", _DEFAULT_CACHE_DIR), dir_hash)\n        try:\n            os.makedirs(cache_dir, exist_ok=True)\n            return cache_dir\n        except OSError:\n            return None\n    else:\n        return None"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Generate a unique directory name by hashing the input directory\n    cache_dir_name = hashlib.md5(input_dir.encode()).hexdigest()\n\n    # Check if the environment variables are set\n    if \"LIT_CACHE_DIR\" in os.environ:\n        cache_dir = os.environ[\"LIT_CACHE_DIR\"]\n    else:\n        cache_dir = _DEFAULT_CACHE_DIR\n\n    # Create the cache directory\n    cache_path = os.path.join(cache_dir, cache_dir_name)\n    try:\n        os.makedirs(cache_path, exist_ok=True)\n        return cache_path\n    except OSError:\n        return None"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Generate a unique directory name by hashing the input directory\n    cache_dir_name = hashlib.md5(input_dir.encode()).hexdigest()\n\n    # Check if environment variables are set\n    if \"CACHE_DIR\" in os.environ:\n        cache_dir = os.path.join(os.environ[\"CACHE_DIR\"], cache_dir_name)\n    else:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, cache_dir_name)\n\n    # Attempt to create the cache directory\n    try:\n        os.makedirs(cache_dir, exist_ok=True)\n        return cache_dir\n    except Exception as e:\n        logger.error(f\"Error creating cache directory: {e}\")\n        return None"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Create a unique directory name by hashing the input directory\n    cache_dir_name = hashlib.md5(input_dir.encode()).hexdigest()\n\n    # Check if the environment variable for the cache directory is set\n    cache_dir_env = os.getenv(\"LIT_CACHE_DIR\")\n    if cache_dir_env:\n        cache_dir = os.path.join(cache_dir_env, cache_dir_name)\n    else:\n        # Use the default cache directory location\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, cache_dir_name)\n\n    # Attempt to create the cache directory\n    try:\n        os.makedirs(cache_dir, exist_ok=True)\n        return cache_dir\n    except Exception as e:\n        logger.error(f\"Failed to create cache directory: {e}\")\n        return None"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = ''\n\n    # Generate a unique directory name by hashing the input directory\n    cache_dir_name = hashlib.md5(input_dir.encode()).hexdigest()\n\n    # Check if environment variables are set for cache directory location\n    cache_dir_env = os.environ.get('CACHE_DIR')\n    if cache_dir_env:\n        cache_dir = os.path.join(cache_dir_env, cache_dir_name)\n        try:\n            os.makedirs(cache_dir, exist_ok=True)\n            return cache_dir\n        except OSError:\n            return None\n    else:\n        # Create the cache directory in the default location\n        default_cache_dir = os.path.join(_DEFAULT_CACHE_DIR, cache_dir_name)\n        try:\n            os.makedirs(default_cache_dir, exist_ok=True)\n            return default_cache_dir\n        except OSError:\n            return None"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    cache_dir = None\n    if input_dir:\n        input_dir_hash = hashlib.md5(input_dir.encode()).hexdigest()\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, input_dir_hash)\n    else:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, \"default_cache\")\n\n    try:\n        os.makedirs(cache_dir, exist_ok=True)\n    except Exception as e:\n        logger.error(f\"Error creating cache directory: {str(e)}\")\n        cache_dir = None\n\n    return cache_dir"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir:\n        input_dir = input_dir.encode(\"utf-8\")\n        cache_dir = hashlib.md5(input_dir).hexdigest()\n    else:\n        cache_dir = hashlib.md5(b\"\").hexdigest()\n\n    if \"LIT_CACHE_DIR\" in os.environ:\n        cache_path = os.path.join(os.environ[\"LIT_CACHE_DIR\"], cache_dir)\n    else:\n        cache_path = os.path.join(_DEFAULT_CACHE_DIR, cache_dir)\n\n    try:\n        os.makedirs(cache_path, exist_ok=True)\n        return cache_path\n    except Exception as e:\n        logger.warning(f\"Failed to create cache directory: {e}\")\n        return None"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.md5(input_dir.encode()).hexdigest())\n    else:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.md5(\"\".encode()).hexdigest())\n\n    try:\n        os.makedirs(cache_dir, exist_ok=True)\n        return cache_dir\n    except Exception as e:\n        logger.error(f\"Error creating cache directory: {e}\")\n        return None"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.md5(input_dir.encode()).hexdigest())\n    os.makedirs(cache_dir, exist_ok=True)\n    return cache_dir"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is not None:\n        input_dir = input_dir.encode(\"utf-8\")\n        cache_dir = hashlib.md5(input_dir).hexdigest()\n    else:\n        cache_dir = \"\"\n\n    # Check if environment variables are set\n    if \"LITDATA_CACHE_DIR\" in os.environ:\n        cache_path = os.path.join(os.environ[\"LITDATA_CACHE_DIR\"], cache_dir)\n    else:\n        cache_path = os.path.join(_DEFAULT_CACHE_DIR, cache_dir)\n\n    try:\n        os.makedirs(cache_path, exist_ok=True)\n        return cache_path\n    except Exception as e:\n        logger.warning(f\"Failed to create cache directory: {e}\")\n        return None"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Generate a unique directory name by hashing the input directory\n    cache_dir_name = hashlib.md5(input_dir.encode()).hexdigest()\n\n    # Check if environment variables are set\n    cache_dir_path = os.environ.get(\"CACHE_DIR_PATH\")\n    if cache_dir_path:\n        cache_dir = os.path.join(cache_dir_path, cache_dir_name)\n    else:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, cache_dir_name)\n\n    # Attempt to create the cache directory\n    try:\n        os.makedirs(cache_dir, exist_ok=True)\n        return cache_dir\n    except Exception as e:\n        logger.warning(f\"Failed to create cache directory: {e}\")\n        return None"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is not None:\n        input_dir = input_dir.encode(\"utf-8\")\n        cache_dir_name = hashlib.md5(input_dir).hexdigest()\n    else:\n        cache_dir_name = \"\"\n\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, cache_dir_name)\n\n    if not os.path.exists(cache_dir):\n        try:\n            os.makedirs(cache_dir)\n        except Exception as e:\n            logger.warning(f\"Failed to create cache directory: {e}\")\n            return None\n\n    return cache_dir"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n    else:\n        input_dir = input_dir.encode(\"utf-8\")\n\n    cache_dir = hashlib.md5(input_dir).hexdigest()\n\n    # Check if environment variables are set\n    cache_path = os.environ.get(\"CACHE_DIR_PATH\")\n    if cache_path:\n        cache_dir = os.path.join(cache_path, cache_dir)\n    else:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, cache_dir)\n\n    try:\n        os.makedirs(cache_dir, exist_ok=True)\n        return cache_dir\n    except Exception as e:\n        logger.error(f\"Error creating cache directory: {e}\")\n        return None"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Create a unique hash for the input directory\n    cache_name = hashlib.md5(input_dir.encode()).hexdigest()\n\n    # Create the cache directory in the default location if environment variables are not set\n    if not os.getenv(\"DATA_OPTIMIZER_GLOBAL_RANK\") and not os.getenv(\"DATA_OPTIMIZER_LOCAL_RANK\"):\n        cache_path = os.path.join(_DEFAULT_CACHE_DIR, cache_name)\n    else:\n        # Create the cache directory in the specified location\n        cache_path = os.path.join(os.getcwd(), cache_name)\n\n    # Attempt to create the cache directory\n    try:\n        os.makedirs(cache_path, exist_ok=True)\n        return cache_path\n    except Exception as e:\n        logger.error(f\"Failed to create cache directory: {e}\")\n        return None"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.md5(input_dir.encode(\"utf-8\")).hexdigest())\n    else:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.md5(\"\".encode(\"utf-8\")).hexdigest())\n\n    try:\n        os.makedirs(cache_dir, exist_ok=True)\n        return cache_dir\n    except Exception as e:\n        logger.error(f\"Error creating cache directory: {e}\")\n        return None"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.md5(input_dir.encode()).hexdigest())\n    else:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.md5(\"\".encode()).hexdigest())\n\n    if not os.path.exists(cache_dir):\n        os.makedirs(cache_dir)\n\n    return cache_dir"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Generate a unique directory name by hashing the input directory\n    cache_dir_name = hashlib.md5(input_dir.encode()).hexdigest()\n\n    # Check if environment variables are set\n    if os.getenv(\"MY_CACHE_DIR\"):\n        cache_dir = os.path.join(os.getenv(\"MY_CACHE_DIR\"), cache_dir_name)\n    else:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, cache_dir_name)\n\n    # Create the cache directory\n    try:\n        os.makedirs(cache_dir, exist_ok=True)\n        return cache_dir\n    except Exception as e:\n        logger.error(f\"Error creating cache directory: {e}\")\n        return None"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\":\n        return True\n    # Add additional conditions to check if the path starts with specific prefixes\n    # For example:\n    # if path.startswith(\"/special_prefix\"):\n    #     return True\n    return False"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\":\n        return True\n    # Add more conditions to check if the path is considered special and should be replaced\n    # For example, check if the path starts with specific prefixes\n    # Example:\n    # if path.startswith(\"/special_prefix\"):\n    #     return True\n    return False"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\" or path.startswith(\"/cache\") or path.startswith(\"s3://\"):\n        return True\n    else:\n        return False"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\" or path.startswith(\"/special_prefix\"):\n        return True\n    else:\n        return False"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\" or path.startswith(\"/cache\") or path.startswith(\"s3://\") or path.startswith(\"gs://\"):\n        return True\n    else:\n        return False"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\" or path.startswith((\"/special_prefix1\", \"/special_prefix2\")):\n        return True\n    else:\n        return False"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\" or path.startswith(\"/cache\") or path.startswith(_DEFAULT_CACHE_DIR):\n        return True\n    else:\n        return False"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    return path is None or path == \"\" or path.startswith(\"/special_prefix\") or path.startswith(\"special_prefix\") "}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\" or path.startswith(\"/special_prefix\"):\n        return True\n    else:\n        return False"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\" or path.startswith(\"/special_prefix\"):  # Add your specific prefixes here\n        return True\n    else:\n        return False"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\" or path.startswith(\"/cache\") or path.startswith(\"gs://\"):\n        return True\n    else:\n        return False"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\" or path.startswith(\"/cache\") or path.startswith(\"s3://\"):\n        return True\n    else:\n        return False"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    return path is None or path == \"\" or path.startswith((\"/special_prefix1\", \"/special_prefix2\"))"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\" or path.startswith(\"/cache\") or path.startswith(\"s3://\"):\n        return True\n    return False"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if not path:\n        return True\n    return path.startswith(\"/\") or path.startswith(\"s3://\") or path.startswith(\"gs://\")"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\" or path.startswith(\"/cache\") or path.startswith(\"gs://\") or path.startswith(\"s3://\"):\n        return True\n    else:\n        return False"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\" or path.startswith(\"/cache\") or path.startswith(\"gs://\") or path.startswith(\"s3://\"):\n        return True\n    return False"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\":\n        return True\n    # Add additional conditions to check for specific prefixes if needed\n    return False"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\" or path.startswith(\"/special_prefix\"):\n        return True\n    else:\n        return False"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\" or path.startswith(\"/special_prefix\"):\n        return True\n    else:\n        return False"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    samples_per_worker = num_samples_yielded // batch_size // num_workers\n    remaining_samples = num_samples_yielded // batch_size % num_workers\n\n    worker_samples = {i: samples_per_worker for i in range(num_workers)}\n    for i in range(remaining_samples):\n        worker_samples[i] += 1\n\n    return worker_samples"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    samples_per_worker = num_samples_yielded // num_workers\n    remaining_samples = num_samples_yielded % num_workers\n\n    samples_distribution = {i: samples_per_worker for i in range(num_workers)}\n\n    for i in range(remaining_samples):\n        samples_distribution[i] += 1\n\n    return samples_distribution"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    samples_per_worker = num_samples_yielded // num_workers\n    remaining_samples = num_samples_yielded % num_workers\n\n    samples_distribution = {i: samples_per_worker for i in range(num_workers)}\n    for i in range(remaining_samples):\n        samples_distribution[i] += 1\n\n    return samples_distribution"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    samples_per_worker = num_samples_yielded // num_workers\n    remaining_samples = num_samples_yielded % num_workers\n\n    samples_distribution = {i: samples_per_worker for i in range(num_workers)}\n    for i in range(remaining_samples):\n        samples_distribution[i] += 1\n\n    return samples_distribution"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    samples_per_worker = {}\n    samples_per_worker_even = num_samples_yielded // num_workers\n    remaining_samples = num_samples_yielded % num_workers\n\n    for worker_idx in range(num_workers):\n        if remaining_samples > 0:\n            samples_per_worker[worker_idx] = samples_per_worker_even + 1\n            remaining_samples -= 1\n        else:\n            samples_per_worker[worker_idx] = samples_per_worker_even\n\n    return samples_per_worker"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    samples_per_worker = num_samples_yielded // num_workers\n    remaining_samples = num_samples_yielded % num_workers\n    worker_samples = {i: samples_per_worker for i in range(num_workers)}\n    for i in range(remaining_samples):\n        worker_samples[i] += 1\n    return worker_samples"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    samples_per_worker = num_samples_yielded // num_workers\n    remaining_samples = num_samples_yielded % num_workers\n\n    samples_distribution = {i: samples_per_worker for i in range(num_workers)}\n    for i in range(remaining_samples):\n        samples_distribution[i] += 1\n\n    return samples_distribution"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    samples_per_worker = num_samples_yielded // num_workers\n    remaining_samples = num_samples_yielded % num_workers\n\n    samples_distribution = {i: samples_per_worker for i in range(num_workers)}\n    for i in range(remaining_samples):\n        samples_distribution[i] += 1\n\n    return samples_distribution"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "\n    samples_per_worker = num_samples_yielded // num_workers\n    remaining_samples = num_samples_yielded % num_workers\n\n    samples_dict = {i: samples_per_worker for i in range(num_workers)}\n\n    for i in range(remaining_samples):\n        samples_dict[i] += 1\n\n    return samples_dict"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    samples_per_worker = num_samples_yielded // num_workers\n    remaining_samples = num_samples_yielded % num_workers\n\n    samples_processed = {i: samples_per_worker for i in range(num_workers)}\n    for i in range(remaining_samples):\n        samples_processed[i] += 1\n\n    return samples_processed"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    samples_per_worker = num_samples_yielded // num_workers\n    remaining_samples = num_samples_yielded % num_workers\n\n    # Distribute the remaining samples among workers\n    samples_distribution = {i: samples_per_worker for i in range(num_workers)}\n    for i in range(remaining_samples):\n        samples_distribution[i] += 1\n\n    return samples_distribution"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    samples_per_worker = num_samples_yielded // num_workers\n    remaining_samples = num_samples_yielded % num_workers\n\n    samples_processed = {i: samples_per_worker for i in range(num_workers)}\n    for i in range(remaining_samples):\n        samples_processed[i] += 1\n\n    return samples_processed"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    samples_per_worker = num_samples_yielded // num_workers\n    remaining_samples = num_samples_yielded % num_workers\n\n    samples_distribution = {i: samples_per_worker for i in range(num_workers)}\n\n    for i in range(remaining_samples):\n        samples_distribution[i] += 1\n\n    return samples_distribution"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    samples_per_worker = num_samples_yielded // num_workers\n    remaining_samples = num_samples_yielded % num_workers\n\n    # Distribute samples evenly among workers\n    samples_distribution = {i: samples_per_worker for i in range(num_workers)}\n\n    # Distribute remaining samples\n    for i in range(remaining_samples):\n        samples_distribution[i] += 1\n\n    return samples_distribution"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    samples_per_worker = {}\n    samples_per_worker_base = num_samples_yielded // (batch_size * num_workers)\n    remaining_samples = num_samples_yielded % (batch_size * num_workers)\n\n    for worker_idx in range(num_workers):\n        samples_per_worker[worker_idx] = samples_per_worker_base\n\n    # Distribute remaining samples\n    for i in range(remaining_samples):\n        worker_idx = i % num_workers\n        samples_per_worker[worker_idx] += 1\n\n    return samples_per_worker"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    samples_per_worker = num_samples_yielded // num_workers\n    remaining_samples = num_samples_yielded % num_workers\n\n    samples_distribution = {i: samples_per_worker for i in range(num_workers)}\n    for i in range(remaining_samples):\n        samples_distribution[i] += 1\n\n    return samples_distribution"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples processed per worker\n    samples_per_worker = num_samples_yielded // batch_size // num_workers\n    remaining_samples = num_samples_yielded // batch_size % num_workers\n\n    # Create a dictionary to store the number of samples processed per worker\n    samples_processed = {}\n\n    # Distribute the samples evenly among workers\n    for i in range(num_workers):\n        samples_processed[i] = samples_per_worker\n\n    # Distribute any remaining samples\n    for i in range(remaining_samples):\n        samples_processed[i] += 1\n\n    return samples_processed"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    samples_per_worker = num_samples_yielded // num_workers\n    remaining_samples = num_samples_yielded % num_workers\n\n    samples_dict = {i: samples_per_worker for i in range(num_workers)}\n\n    for i in range(remaining_samples):\n        samples_dict[i] += 1\n\n    return samples_dict"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    samples_per_worker = {}\n    samples_per_batch = batch_size * num_workers\n    num_full_batches = num_samples_yielded // samples_per_batch\n    remaining_samples = num_samples_yielded % samples_per_batch\n\n    for i in range(num_workers):\n        if i < remaining_samples:\n            samples_per_worker[i] = (num_full_batches + 1) * batch_size\n        else:\n            samples_per_worker[i] = num_full_batches * batch_size\n\n    return samples_per_worker"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    samples_per_worker = num_samples_yielded // num_workers\n    remaining_samples = num_samples_yielded % num_workers\n\n    samples_distribution = {i: samples_per_worker for i in range(num_workers)}\n    for i in range(remaining_samples):\n        samples_distribution[i] += 1\n\n    return samples_distribution"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(\"Remote file path must use the 's3' scheme\")\n\n        if not os.path.exists(local_filepath):\n            with FileLock(local_filepath + \".lock\", timeout=10):\n                if not os.path.exists(local_filepath):  # Double check in case another process created the file\n                    if self._s5cmd_available:\n                        subprocess.run([\"s5cmd\", \"cp\", remote_filepath, local_filepath])\n                    else:\n                        self._client.download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(\"Remote file path must use the 's3' scheme\")\n\n        if not os.path.exists(local_filepath):\n            with FileLock(local_filepath + \".lock\", timeout=10):\n                if self._s5cmd_available:\n                    subprocess.run([\"s5cmd\", \"cp\", remote_filepath, local_filepath], check=True)\n                else:\n                    self._client.download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(\"Remote file path must use the 's3' scheme\")\n\n        if not os.path.exists(local_filepath):\n            with FileLock(local_filepath + \".lock\", timeout=10):\n                if self._s5cmd_available:\n                    subprocess.run([\"s5cmd\", \"cp\", remote_filepath, local_filepath])\n                else:\n                    self._client.download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(\"Remote file path must use the 's3' scheme\")\n\n        if not os.path.exists(local_filepath):\n            lock_file = local_filepath + \".lock\"\n            with FileLock(lock_file, timeout=10):\n                if self._s5cmd_available:\n                    subprocess.run([\"s5cmd\", \"cp\", remote_filepath, local_filepath])\n                else:\n                    self._client.download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(\"Remote file path must use the 's3' scheme\")\n\n        if not os.path.exists(local_filepath):\n            with FileLock(local_filepath + \".lock\", timeout=10):\n                if self._s5cmd_available:\n                    subprocess.run([\"s5cmd\", \"cp\", remote_filepath, local_filepath])\n                else:\n                    self._client.download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(\"Remote file path must use the 's3' scheme\")\n\n        if not os.path.exists(local_filepath):\n            lock_filepath = local_filepath + \".lock\"\n            with FileLock(lock_filepath, timeout=10):\n                if self._s5cmd_available:\n                    subprocess.run([\"s5cmd\", \"cp\", remote_filepath, local_filepath])\n                else:\n                    self._client.download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != 's3':\n            raise ValueError(\"Remote file path must use the 's3' scheme\")\n\n        if not os.path.exists(local_filepath):\n            with FileLock(local_filepath + '.lock', timeout=10):\n                if self._s5cmd_available:\n                    subprocess.run([\"s5cmd\", \"cp\", remote_filepath, local_filepath])\n                else:\n                    self._client.download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(\"Remote file path must use the 's3' scheme\")\n\n        if not os.path.exists(local_filepath):\n            lock_filepath = local_filepath + \".lock\"\n            with FileLock(lock_filepath, timeout=10):\n                if self._s5cmd_available:\n                    subprocess.run([\"s5cmd\", \"cp\", remote_filepath, local_filepath])\n                else:\n                    self._client.download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(\"Remote file path must use the 's3' scheme\")\n\n        if not os.path.exists(local_filepath):\n            with FileLock(local_filepath + \".lock\", timeout=10):\n                if self._s5cmd_available:\n                    subprocess.run([\"s5cmd\", \"cp\", remote_filepath, local_filepath], check=True)\n                else:\n                    self._client.download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != 's3':\n            raise ValueError(\"Remote file path must use the 's3' scheme\")\n\n        if os.path.exists(local_filepath):\n            return  # File already exists, no need to download\n\n        if self._s5cmd_available:\n            subprocess.run([\"s5cmd\", \"cp\", remote_filepath, local_filepath])\n        else:\n            with FileLock(local_filepath + \".lock\", timeout=10):\n                self._client.download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if not remote_filepath.startswith(\"s3://\"):\n            raise ValueError(\"Remote file path must use the 's3' scheme\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        lock_filepath = local_filepath + \".lock\"\n        with FileLock(lock_filepath, timeout=60):\n            if self._s5cmd_available:\n                subprocess.run([\"s5cmd\", \"cp\", remote_filepath, local_filepath])\n            else:\n                self._client.download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != 's3':\n            raise ValueError(\"The remote file path must use the 's3' scheme.\")\n\n        if not os.path.exists(local_filepath):\n            with FileLock(local_filepath + \".lock\", timeout=10):\n                if self._s5cmd_available:\n                    subprocess.run([\"s5cmd\", \"cp\", remote_filepath, local_filepath], check=True)\n                else:\n                    self._client.download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(\"Remote file path must use the 's3' scheme\")\n\n        if not os.path.exists(local_filepath):\n            lock_file = local_filepath + \".lock\"\n            with FileLock(lock_file, timeout=60):\n                if self._s5cmd_available:\n                    subprocess.run([\"s5cmd\", \"cp\", remote_filepath, local_filepath])\n                else:\n                    self._client.download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != 's3':\n            raise ValueError(\"Remote file path must use the 's3' scheme\")\n\n        if not os.path.exists(local_filepath):\n            with FileLock(local_filepath + \".lock\", timeout=10):\n                if self._s5cmd_available:\n                    subprocess.run([\"s5cmd\", \"cp\", remote_filepath, local_filepath], check=True)\n                else:\n                    self._client.download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != 's3':\n            raise ValueError(\"Remote file path must use the 's3' scheme\")\n\n        if not os.path.exists(local_filepath):\n            with FileLock(local_filepath + '.lock', timeout=10):\n                if self._s5cmd_available:\n                    subprocess.run(['s5cmd', 'cp', remote_filepath, local_filepath])\n                else:\n                    self._client.download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != 's3':\n            raise ValueError(\"Remote file path must use the 's3' scheme\")\n\n        if os.path.exists(local_filepath):\n            return  # File already exists\n\n        with FileLock(local_filepath + '.lock', timeout=10):\n            if self._s5cmd_available:\n                subprocess.run([\"s5cmd\", \"cp\", remote_filepath, local_filepath])\n            else:\n                self._client.download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != 's3':\n            raise ValueError(\"Remote file path must use the 's3' scheme\")\n\n        if os.path.exists(local_filepath):\n            return  # File already exists, no need to download\n\n        lock_filepath = local_filepath + '.lock'\n        with FileLock(lock_filepath, timeout=60):\n            if self._s5cmd_available:\n                subprocess.run(['s5cmd', 'cp', remote_filepath, local_filepath], check=True)\n            else:\n                self._client.download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(\"Remote file path must use the 's3' scheme\")\n\n        if not os.path.exists(local_filepath):\n            if self._s5cmd_available:\n                subprocess.run([\"s5cmd\", \"cp\", remote_filepath, local_filepath])\n            else:\n                with FileLock(local_filepath + \".lock\", timeout=10):\n                    self._client.download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if not remote_filepath.startswith(\"s3://\"):\n            raise ValueError(\"Remote file path must use the 's3' scheme\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        with FileLock(local_filepath + \".lock\", timeout=10):\n            if self._s5cmd_available:\n                subprocess.run([\"s5cmd\", \"cp\", remote_filepath, local_filepath])\n            else:\n                self._client.download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != 's3':\n            raise ValueError(\"Remote file path must use the 's3' scheme\")\n\n        if not os.path.exists(local_filepath):\n            lockfile = local_filepath + \".lock\"\n            with FileLock(lockfile, timeout=10):\n                if self._s5cmd_available:\n                    subprocess.run([\"s5cmd\", \"cp\", remote_filepath, local_filepath], check=True)\n                else:\n                    self._client.download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    workers_chunks = {}\n    workers_intervals = {}\n    for i in range(num_workers):\n        workers_chunks[i] = []\n        workers_intervals[i] = []\n\n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        if i % worker_env.world_size != worker_env.rank:\n            continue\n        worker_index = i % num_workers\n        workers_chunks[worker_index].append(chunk_index)\n        workers_intervals[worker_index].append(chunk_interval)\n\n    return workers_chunks, workers_intervals"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    chunks_per_replica = len(chunks_replica)\n    chunks_per_worker = chunks_per_replica // num_workers\n    remaining_chunks = chunks_per_replica % num_workers\n\n    workers_chunks = {}\n    workers_intervals = {}\n\n    start = 0\n    for worker_rank in range(num_workers):\n        num_chunks = chunks_per_worker + (1 if worker_rank < remaining_chunks else 0)\n        end = start + num_chunks\n\n        workers_chunks[worker_rank] = chunks_replica[start:end]\n        workers_intervals[worker_rank] = intervals_replica[start:end]\n\n        start = end\n\n    return workers_chunks, workers_intervals"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # Calculate the number of chunks per worker\n    chunks_per_worker = len(chunks_replica) // num_workers\n    remaining_chunks = len(chunks_replica) % num_workers\n\n    # Distribute the chunks and intervals to workers\n    workers_chunks = {}\n    workers_intervals = {}\n    start_chunk = 0\n    for i in range(num_workers):\n        num_chunks = chunks_per_worker + (i < remaining_chunks)\n        end_chunk = start_chunk + num_chunks\n        workers_chunks[i] = chunks_replica[start_chunk:end_chunk]\n        workers_intervals[i] = intervals_replica[start_chunk:end_chunk]\n        start_chunk = end_chunk\n\n    return workers_chunks, workers_intervals"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "\n    workers_chunks = {}\n    workers_intervals = {}\n\n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        worker_index = i % worker_env.world_size\n        if worker_index not in workers_chunks:\n            workers_chunks[worker_index] = []\n            workers_intervals[worker_index] = []\n        workers_chunks[worker_index].append(chunk_index)\n        workers_intervals[worker_index].append(chunk_interval)\n\n    return workers_chunks, workers_intervals"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    workers_chunks = {}\n    workers_intervals = {}\n\n    for i in range(num_workers):\n        workers_chunks[i] = []\n        workers_intervals[i] = []\n\n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        worker_index = i % worker_env.world_size\n        workers_chunks[worker_index].append(chunk_index)\n        workers_intervals[worker_index].append(chunk_interval)\n\n    return workers_chunks, workers_intervals"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    \n    workers_chunks = {}\n    workers_intervals = {}\n    \n    for i in range(num_workers):\n        workers_chunks[i] = []\n        workers_intervals[i] = []\n    \n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        worker_index = i % worker_env.world_size\n        workers_chunks[worker_index].append(chunk_index)\n        workers_intervals[worker_index].append(chunk_interval)\n    \n    return workers_chunks, workers_intervals"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # Calculate the number of chunks and intervals per worker\n    chunks_per_worker = len(chunks_replica) // num_workers\n    intervals_per_worker = len(intervals_replica) // num_workers\n\n    # Calculate the remaining chunks and intervals after evenly distributing among workers\n    remaining_chunks = len(chunks_replica) % num_workers\n    remaining_intervals = len(intervals_replica) % num_workers\n\n    # Initialize dictionaries to store chunks and intervals assigned to each worker\n    workers_chunks = {}\n    workers_intervals = {}\n\n    # Distribute chunks and intervals to each worker based on their index and world size\n    for i in range(num_workers):\n        start_chunk = i * chunks_per_worker + min(i, remaining_chunks)\n        end_chunk = start_chunk + chunks_per_worker + (1 if i < remaining_chunks else 0)\n\n        start_interval = i * intervals_per_worker + min(i, remaining_intervals)\n        end_interval = start_interval + intervals_per_worker + (1 if i < remaining_intervals else 0)\n\n        workers_chunks[i] = chunks_replica[start_chunk:end_chunk]\n        workers_intervals[i] = intervals_replica[start_interval:end_interval]\n\n    return workers_chunks, workers_intervals"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # Calculate the number of chunks per worker\n    chunks_per_worker = len(chunks_replica) // num_workers\n    remainder = len(chunks_replica) % num_workers\n\n    # Distribute the chunks and intervals to workers\n    workers_chunks = {}\n    workers_intervals = {}\n\n    start = 0\n    for i in range(num_workers):\n        # Calculate the number of chunks for this worker\n        num_chunks = chunks_per_worker + (1 if i < remainder else 0)\n\n        # Assign chunks and intervals to the current worker\n        workers_chunks[i] = chunks_replica[start : start + num_chunks]\n        workers_intervals[i] = intervals_replica[start : start + num_chunks]\n\n        # Update the start index for the next worker\n        start += num_chunks\n\n    return workers_chunks, workers_intervals"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    workers_chunks = {}\n    workers_intervals = {}\n\n    for i in range(num_workers):\n        workers_chunks[i] = []\n        workers_intervals[i] = []\n\n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        worker_index = i % worker_env.world_size\n        workers_chunks[worker_index].append(chunk_index)\n        workers_intervals[worker_index].append(chunk_interval)\n\n    return workers_chunks, workers_intervals"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "\n    workers_chunks = {}\n    workers_intervals = {}\n\n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        worker_index = i % worker_env.world_size\n        if worker_index not in workers_chunks:\n            workers_chunks[worker_index] = []\n        if worker_index not in workers_intervals:\n            workers_intervals[worker_index] = []\n\n        workers_chunks[worker_index].append(chunk_index)\n        workers_intervals[worker_index].append(chunk_interval)\n\n    return workers_chunks, workers_intervals"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    workers_chunks = {}\n    workers_intervals = {}\n\n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        worker_index = i % worker_env.world_size\n        if worker_index not in workers_chunks:\n            workers_chunks[worker_index] = []\n            workers_intervals[worker_index] = []\n\n        workers_chunks[worker_index].append(chunk_index)\n        workers_intervals[worker_index].append(chunk_interval)\n\n    return workers_chunks, workers_intervals"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    workers_chunks = {}\n    workers_intervals = {}\n    for i in range(num_workers):\n        workers_chunks[i] = []\n        workers_intervals[i] = []\n\n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        if i % worker_env.world_size != worker_env.rank:\n            continue\n        worker_index = i % num_workers\n        workers_chunks[worker_index].append(chunk_index)\n        workers_intervals[worker_index].append(chunk_interval)\n\n    return workers_chunks, workers_intervals"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    workers_chunks = {}\n    workers_intervals = {}\n\n    for i in range(num_workers):\n        workers_chunks[i] = []\n        workers_intervals[i] = []\n\n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        worker_index = i % worker_env.world_size\n        workers_chunks[worker_index].append(chunk_index)\n        workers_intervals[worker_index].append(chunk_interval)\n\n    return workers_chunks, workers_intervals"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    num_chunks = len(chunks_replica)\n    chunks_per_worker = num_chunks // num_workers\n    remainder = num_chunks % num_workers\n\n    workers_chunks = {}\n    workers_intervals = {}\n\n    start = 0\n    for worker_idx in range(num_workers):\n        worker_chunks = chunks_per_worker + 1 if worker_idx < remainder else chunks_per_worker\n        end = start + worker_chunks\n\n        workers_chunks[worker_idx] = chunks_replica[start:end]\n        workers_intervals[worker_idx] = [intervals_replica[i] for i in range(start, end)]\n\n        start = end\n\n    return workers_chunks, workers_intervals"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    chunks_per_replica = len(chunks_replica)\n    chunks_per_worker = chunks_per_replica // num_workers\n    remaining_chunks = chunks_per_replica % num_workers\n\n    intervals_per_replica = [interval[1] - interval[0] for interval in intervals_replica]\n    intervals_per_worker = [sum(intervals_per_replica[i * chunks_per_worker : (i + 1) * chunks_per_worker]) for i in range(num_workers)]\n    remaining_intervals = sum(intervals_per_replica[chunks_per_worker * num_workers :])\n\n    workers_chunks = {}\n    workers_intervals = {}\n\n    for i in range(num_workers):\n        start_chunk = i * chunks_per_worker + min(i, remaining_chunks)\n        end_chunk = start_chunk + chunks_per_worker + (1 if i < remaining_chunks else 0)\n\n        workers_chunks[i] = chunks_replica[start_chunk:end_chunk]\n        workers_intervals[i] = intervals_replica[start_chunk:end_chunk]\n\n    return workers_chunks, workers_intervals"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "\n    workers_chunks = {}\n    workers_intervals = {}\n\n    for i in range(num_workers):\n        workers_chunks[i] = []\n        workers_intervals[i] = []\n\n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        worker_index = i % worker_env.world_size\n        workers_chunks[worker_index].append(chunk_index)\n        workers_intervals[worker_index].append(chunk_interval)\n\n    return workers_chunks, workers_intervals"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # Calculate the number of chunks per worker\n    chunks_per_worker = len(chunks_replica) // num_workers\n    remainder = len(chunks_replica) % num_workers\n\n    # Assign chunks and intervals to workers\n    workers_chunks = {}\n    workers_intervals = {}\n\n    start = 0\n    for i in range(num_workers):\n        num_chunks = chunks_per_worker + (1 if i < remainder else 0)\n        end = start + num_chunks\n\n        worker_index = (worker_env.rank + i) % worker_env.world_size\n        workers_chunks[worker_index] = chunks_replica[start:end]\n        workers_intervals[worker_index] = intervals_replica[start:end]\n\n        start = end\n\n    return workers_chunks, workers_intervals"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    chunks_per_worker = len(chunks_replica) // num_workers\n    intervals_per_worker = len(intervals_replica) // num_workers\n\n    workers_chunks = {}\n    workers_intervals = {}\n\n    for i in range(num_workers):\n        start_chunk = i * chunks_per_worker\n        end_chunk = (i + 1) * chunks_per_worker\n\n        start_interval = i * intervals_per_worker\n        end_interval = (i + 1) * intervals_per_worker\n\n        if i == num_workers - 1:\n            end_chunk = len(chunks_replica)\n            end_interval = len(intervals_replica)\n\n        workers_chunks[i] = chunks_replica[start_chunk:end_chunk]\n        workers_intervals[i] = intervals_replica[start_interval:end_interval]\n\n    return workers_chunks, workers_intervals"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    workers_chunks = {}\n    workers_intervals = {}\n\n    for i in range(num_workers):\n        workers_chunks[i] = []\n        workers_intervals[i] = []\n\n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        if i % worker_env.world_size != worker_env.rank:\n            continue\n        worker_index = i % num_workers\n        workers_chunks[worker_index].append(chunk_index)\n        workers_intervals[worker_index].append(chunk_interval)\n\n    return workers_chunks, workers_intervals"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    workers_chunks = {}\n    workers_intervals = {}\n\n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        worker_index = i % worker_env.world_size\n        if worker_index not in workers_chunks:\n            workers_chunks[worker_index] = []\n            workers_intervals[worker_index] = []\n        workers_chunks[worker_index].append(chunk_index)\n        workers_intervals[worker_index].append(chunk_interval)\n\n    return workers_chunks, workers_intervals"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath.replace(\"local:\", \"\")\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath.replace(\"local:\", \"\")\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath.replace(\"local:\", \"\")\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath.replace(\"local:\", \"\", 1)\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath.replace(\"local:\", \"\", 1)\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath.replace(\"local:\", \"\", 1)\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath.replace(\"local:\", \"\")\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[6:]  # Remove the \"local:\" prefix\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath.replace(\"local:\", \"\")\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath.replace(\"local:\", \"\", 1)\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath.replace(\"local:\", \"\", 1)\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath.replace(\"local:\", \"\")\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath.replace(\"local:\", \"\")\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath.replace(\"local:\", \"\")\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath.replace(\"local:\", \"\")\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath.replace(\"local:\", \"\")\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath.replace(\"local:\", \"\")\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath.replace(\"local:\", \"\", 1)\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath.replace(\"local:\", \"\")\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath.replace(\"local:\", \"\", 1)\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "\n    chunks_index = {}\n    updated_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        chunk_index = 0\n        for interval in intervals:\n            interval_size = interval[1] - interval[0]\n            if indexes[worker_idx] < interval_size:\n                chunks_index[worker_idx] = chunk_index\n                updated_indexes[worker_idx] = indexes[worker_idx]\n                break\n            else:\n                indexes[worker_idx] -= interval_size\n                chunk_index += 1\n\n    return chunks_index, updated_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "\n    chunks_index = {}\n    updated_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        # Calculate the total size of the intervals for the worker\n        total_interval_size = sum(interval[-1] - interval[0] for interval in intervals)\n\n        # Calculate the number of chunks based on the total interval size\n        num_chunks = len(intervals)\n\n        # Update the chunk index for the worker\n        chunks_index[worker_idx] = (indexes[worker_idx] // total_interval_size) % num_chunks\n\n        # Update the index within the chunk for the worker\n        updated_indexes[worker_idx] = indexes[worker_idx] % total_interval_size\n\n    return chunks_index, updated_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "\n    chunks_index = {}\n    updated_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        chunk_index = 0\n        index = indexes[worker_idx]\n\n        for i, interval in enumerate(intervals):\n            interval_size = interval[1] - interval[0]\n            if index < interval_size:\n                chunk_index = i\n                break\n            else:\n                index -= interval_size\n\n        chunks_index[worker_idx] = chunk_index\n        updated_indexes[worker_idx] = index\n\n    return chunks_index, updated_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "\n    chunks_index = {}\n    updated_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        current_index = indexes[worker_idx]\n        chunk_index = 0\n\n        for interval in intervals:\n            interval_size = interval[1] - interval[0]\n            if current_index < interval_size:\n                break\n            current_index -= interval_size\n            chunk_index += 1\n\n        chunks_index[worker_idx] = chunk_index\n        updated_indexes[worker_idx] = current_index\n\n    return chunks_index, updated_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunk_indexes = {}\n    updated_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        chunk_index = 0\n        current_index = indexes[worker_idx]\n\n        for interval in intervals:\n            interval_size = interval[1] - interval[0]\n            if current_index < interval_size:\n                chunk_indexes[worker_idx] = chunk_index\n                updated_indexes[worker_idx] = current_index\n                break\n            else:\n                current_index -= interval_size\n                chunk_index += 1\n\n    return chunk_indexes, updated_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    updated_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        chunk_index = 0\n        for interval in intervals:\n            interval_size = interval[1] - interval[0]\n            if indexes[worker_idx] < interval_size:\n                chunks_index[worker_idx] = chunk_index\n                updated_indexes[worker_idx] = indexes[worker_idx]\n                break\n            else:\n                indexes[worker_idx] -= interval_size\n                chunk_index += 1\n\n    return chunks_index, updated_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    \n    chunks_index = {}\n    updated_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        # Calculate the total size of intervals for the worker\n        total_interval_size = sum([interval[-1] - interval[0] for interval in intervals])\n\n        # Determine the chunk index and the updated index within the chunks\n        chunk_index = 0\n        current_index = indexes[worker_idx]\n        for interval in intervals:\n            interval_size = interval[-1] - interval[0]\n            if current_index < interval_size:\n                break\n            current_index -= interval_size\n            chunk_index += 1\n\n        chunks_index[worker_idx] = chunk_index\n        updated_indexes[worker_idx] = current_index\n\n    return chunks_index, updated_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "\n    chunks_index = {}\n    updated_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        if worker_idx in indexes:\n            current_index = indexes[worker_idx]\n            current_chunk_index = 0\n\n            for interval in intervals:\n                interval_size = interval[1] - interval[0]\n                if current_index < interval_size:\n                    updated_indexes[worker_idx] = current_index\n                    chunks_index[worker_idx] = current_chunk_index\n                    break\n                else:\n                    current_index -= interval_size\n                    current_chunk_index += 1\n\n    return chunks_index, updated_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "\n    chunks_index = {}\n    new_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        chunk_index = 0\n        for interval in intervals:\n            if indexes[worker_idx] < interval[1]:\n                break\n            chunk_index += 1\n        chunks_index[worker_idx] = chunk_index\n        new_indexes[worker_idx] = indexes[worker_idx] - intervals[chunk_index][0]\n\n    return chunks_index, new_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    updated_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        if worker_idx not in indexes:\n            indexes[worker_idx] = 0\n\n        current_index = indexes[worker_idx]\n\n        for i, interval in enumerate(intervals):\n            interval_size = interval[1] - interval[0]\n            if current_index < interval_size:\n                chunks_index[worker_idx] = i\n                updated_indexes[worker_idx] = current_index\n                break\n            else:\n                current_index -= interval_size\n\n    return chunks_index, updated_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "\n    chunks_index = {}\n    updated_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        current_index = indexes[worker_idx]\n        chunk_index = 0\n\n        for i, interval in enumerate(intervals):\n            interval_size = interval[1] - interval[0]\n            if current_index < interval_size:\n                chunk_index = i\n                break\n            else:\n                current_index -= interval_size\n\n        chunks_index[worker_idx] = chunk_index\n        updated_indexes[worker_idx] = current_index\n\n    return chunks_index, updated_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "\n    chunks_index = {}\n    updated_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        chunk_index = 0\n        current_index = indexes[worker_idx]\n\n        for i, interval in enumerate(intervals):\n            interval_size = interval[1] - interval[0]\n            if current_index < interval_size:\n                chunk_index = i\n                break\n            else:\n                current_index -= interval_size\n\n        chunks_index[worker_idx] = chunk_index\n        updated_indexes[worker_idx] = current_index\n\n    return chunks_index, updated_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    updated_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        chunk_index = 0\n        current_index = indexes[worker_idx]\n\n        for i, interval in enumerate(intervals):\n            interval_size = interval[1] - interval[0]\n            if current_index < interval_size:\n                chunk_index = i\n                break\n            else:\n                current_index -= interval_size\n\n        chunks_index[worker_idx] = chunk_index\n        updated_indexes[worker_idx] = current_index\n\n    return chunks_index, updated_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "\n    chunks_index = {}\n    updated_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        # Calculate the chunk index based on the current index\n        chunk_index = 0\n        current_index = indexes[worker_idx]\n        for interval in intervals:\n            interval_size = interval[1] - interval[0]\n            if current_index < interval_size:\n                break\n            current_index -= interval_size\n            chunk_index += 1\n\n        chunks_index[worker_idx] = chunk_index\n        updated_indexes[worker_idx] = current_index\n\n    return chunks_index, updated_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunk_indexes = {}\n    updated_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        current_index = indexes[worker_idx]\n        chunk_index = 0\n\n        for interval in intervals:\n            interval_size = interval[1] - interval[0]\n            if current_index < interval_size:\n                chunk_indexes[worker_idx] = chunk_index\n                updated_indexes[worker_idx] = current_index\n                break\n            else:\n                current_index -= interval_size\n                chunk_index += 1\n\n    return chunk_indexes, updated_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunk_indexes = {}\n    updated_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        chunk_index = 0\n        for interval in intervals:\n            interval_size = interval[1] - interval[0]\n            if indexes[worker_idx] < interval_size:\n                chunk_indexes[worker_idx] = chunk_index\n                updated_indexes[worker_idx] = indexes[worker_idx]\n                break\n            else:\n                indexes[worker_idx] -= interval_size\n                chunk_index += 1\n\n    return chunk_indexes, updated_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "\n    chunks_index = {}\n    updated_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        chunk_index = 0\n        current_index = indexes[worker_idx]\n\n        for interval in intervals:\n            interval_size = interval[1] - interval[0]\n            if current_index < interval_size:\n                chunks_index[worker_idx] = chunk_index\n                updated_indexes[worker_idx] = current_index\n                break\n            else:\n                current_index -= interval_size\n                chunk_index += 1\n\n    return chunks_index, updated_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "\n    chunk_indexes = {}\n    updated_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        chunk_index = 0\n        current_index = indexes[worker_idx]\n\n        # Calculate the chunk index and the updated index based on the intervals\n        for interval in intervals:\n            interval_size = interval[1] - interval[0]\n            if current_index < interval_size:\n                chunk_indexes[worker_idx] = chunk_index\n                updated_indexes[worker_idx] = current_index\n                break\n            else:\n                current_index -= interval_size\n                chunk_index += 1\n\n    return chunk_indexes, updated_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    updated_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        # Calculate the total size of the intervals for the worker\n        total_interval_size = sum([interval[-1] - interval[0] for interval in intervals])\n\n        # Calculate the updated chunk index for the worker\n        chunk_index = 0\n        for i, interval in enumerate(intervals):\n            if indexes[worker_idx] < (interval[-1] - interval[0]):\n                chunk_index = i\n                break\n            indexes[worker_idx] -= (interval[-1] - interval[0])\n\n        chunks_index[worker_idx] = chunk_index\n        updated_indexes[worker_idx] = indexes[worker_idx]\n\n    return chunks_index, updated_indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "\n    chunks_index = {}\n    updated_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        current_index = indexes[worker_idx]\n        chunk_index = 0\n\n        for interval in intervals:\n            interval_size = interval[1] - interval[0]\n            if current_index < interval_size:\n                break\n            current_index -= interval_size\n            chunk_index += 1\n\n        chunks_index[worker_idx] = chunk_index\n        updated_indexes[worker_idx] = current_index\n\n    return chunks_index, updated_indexes"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        mode = item.mode\n        width, height = item.size\n        raw_data = item.tobytes()\n\n        # Serialize image data\n        serialized_data = (\n            width.to_bytes(4, byteorder=\"big\") +\n            height.to_bytes(4, byteorder=\"big\") +\n            len(mode).to_bytes(4, byteorder=\"big\") +\n            mode.encode(\"utf-8\") +\n            raw_data\n        )\n\n        return serialized_data, None"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        with io.BytesIO() as output:\n            item.save(output, format=\"PNG\")\n            serialized_data = output.getvalue()\n        return serialized_data, None"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        with io.BytesIO() as output:\n            item.save(output, format=\"PNG\")\n            serialized_data = output.getvalue()\n        return serialized_data, None"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        with io.BytesIO() as output:\n            item.save(output, format=\"PNG\")\n            serialized_data = output.getvalue()\n        mode_str = item.mode.encode(\"utf-8\")\n        return (\n            serialized_data,\n            mode_str,\n        )"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        with io.BytesIO() as output:\n            # Save the image to a temporary file\n            item.save(output, format=\"PNG\")\n            # Get the raw pixel data\n            serialized_data = output.getvalue()\n        \n        # Return the serialized data along with None\n        return serialized_data, None"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        with io.BytesIO() as output:\n            item.save(output, format=\"PNG\")\n            serialized_data = output.getvalue()\n        return serialized_data, None"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        with io.BytesIO() as output:\n            item.save(output, format=\"PNG\")\n            data = output.getvalue()\n        return data, None"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        with io.BytesIO() as output:\n            item.save(output, format=\"PNG\")\n            serialized_data = output.getvalue()\n        return serialized_data, None"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        width, height = item.size\n        mode = item.mode\n        image_data = item.tobytes()\n\n        serialized_data = (\n            width.to_bytes(4, byteorder=\"big\") +\n            height.to_bytes(4, byteorder=\"big\") +\n            len(mode).to_bytes(4, byteorder=\"big\") +\n            mode.encode(\"utf-8\") +\n            image_data\n        )\n\n        return serialized_data, None"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        mode = item.mode\n        width, height = item.size\n        raw_data = item.tobytes()\n\n        # Serialize image data\n        serialized_data = (\n            width.to_bytes(4, byteorder=\"big\") +\n            height.to_bytes(4, byteorder=\"big\") +\n            len(mode).to_bytes(1, byteorder=\"big\") +\n            mode.encode(\"utf-8\") +\n            raw_data\n        )\n\n        return serialized_data, None"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        with io.BytesIO() as output:\n            # Save the image to a bytes buffer\n            item.save(output, format=\"PNG\")\n            serialized_data = output.getvalue()\n        \n        # Get the mode of the image\n        mode_str = item.mode.encode(\"utf-8\")\n        \n        # Create a tuple with the serialized data and the mode\n        return serialized_data, mode_str"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        width, height = item.size\n        mode = item.mode\n        data = item.tobytes()\n\n        serialized_data = (\n            width.to_bytes(4, byteorder=\"big\")\n            + height.to_bytes(4, byteorder=\"big\")\n            + len(mode).to_bytes(1, byteorder=\"big\")\n            + mode.encode(\"utf-8\")\n            + data\n        )\n\n        return serialized_data, None"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        image_data = io.BytesIO()\n        item.save(image_data, format=\"PNG\")\n        image_bytes = image_data.getvalue()\n        mode = item.mode.encode(\"utf-8\")\n        dimensions = (item.width, item.height)\n        serialized_data = (\n            dimensions.to_bytes(8, byteorder=\"big\")\n            + len(mode).to_bytes(4, byteorder=\"big\")\n            + mode\n            + image_bytes\n        )\n        return serialized_data, None"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        with io.BytesIO() as output:\n            item.save(output, format=\"PNG\")\n            data = output.getvalue()\n        return data, None"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        with io.BytesIO() as output:\n            item.save(output, format=\"PNG\")\n            serialized_data = output.getvalue()\n            mode_bytes = item.mode.encode(\"utf-8\")\n            metadata = bytes([item.width, item.height, len(mode_bytes)])\n            return metadata + mode_bytes + serialized_data, None"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        with io.BytesIO() as output:\n            item.save(output, format=item.format)\n            serialized_data = output.getvalue()\n        return serialized_data, None"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        with io.BytesIO() as output:\n            item.save(output, format=\"PNG\")\n            serialized_data = output.getvalue()\n        return serialized_data, None"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        with io.BytesIO() as output:\n            item.save(output, format=\"PNG\")\n            serialized_data = output.getvalue()\n        mode_bytes = item.mode.encode(\"utf-8\")\n        mode_length = len(mode_bytes).to_bytes(4, byteorder=\"big\")\n        width_bytes = item.width.to_bytes(4, byteorder=\"big\")\n        height_bytes = item.height.to_bytes(4, byteorder=\"big\")\n        serialized_data = width_bytes + height_bytes + mode_length + mode_bytes + serialized_data\n        return serialized_data, None"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        with io.BytesIO() as output:\n            item.save(output, format=\"PNG\")\n            serialized_data = output.getvalue()\n        return serialized_data, None"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        with io.BytesIO() as output:\n            # Save the image data to a bytes buffer\n            item.save(output, format=\"PNG\")\n            serialized_data = output.getvalue()\n\n        # Get the image mode and encode it in UTF-8\n        mode_encoded = item.mode.encode(\"utf-8\")\n\n        # Get the dimensions of the image\n        width, height = item.size\n        dimensions = (width, height)\n\n        # Serialize the dimensions, mode, and raw pixel data\n        serialized_dimensions = pickle.dumps(dimensions)\n        serialized_mode = pickle.dumps(mode_encoded)\n\n        return serialized_dimensions + serialized_mode + serialized_data, None"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if not isinstance(item, (Image.Image, JpegImageFile)):\n            raise TypeError(\"Unsupported image type. Expected PIL Image or JPEG Image File.\")\n\n        if isinstance(item, JpegImageFile) and item.filename:\n            with open(item.filename, \"rb\") as f:\n                data = f.read()\n            return data, None\n        else:\n            with io.BytesIO() as output:\n                item.save(output, format=\"JPEG\")\n                data = output.getvalue()\n            return data, None"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile) and hasattr(item, \"filename\") and os.path.exists(item.filename):\n            with open(item.filename, \"rb\") as f:\n                data = f.read()\n            return data, None\n        elif _PIL_AVAILABLE and isinstance(item, Image.Image) and not isinstance(item, JpegImageFile):\n            with io.BytesIO() as output:\n                item.save(output, format=\"JPEG\")\n                data = output.getvalue()\n            return data, None\n        else:\n            raise TypeError(\"Unsupported image type for JPEG serialization\")"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile) and item.filename:\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        elif _PIL_AVAILABLE and isinstance(item, Image.Image):\n            with io.BytesIO() as output:\n                item.save(output, format=\"JPEG\")\n                return output.getvalue(), None\n        else:\n            raise TypeError(\"Unsupported image type for JPEG serialization\")"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile) and item.filename:\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        elif isinstance(item, Image.Image):\n            with io.BytesIO() as output:\n                item.save(output, format=\"JPEG\")\n                return output.getvalue(), None\n        else:\n            raise TypeError(\"Unsupported image type for JPEG serialization\")"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if not _PIL_AVAILABLE:\n            raise RuntimeError(\"Pillow is not installed. JPEG serialization is not available.\")\n\n        if not isinstance(item, Image.Image):\n            raise TypeError(f\"Expected PIL Image, but got {type(item)}\")\n\n        if isinstance(item, JpegImageFile) and hasattr(item, \"filename\") and os.path.exists(item.filename):\n            with open(item.filename, \"rb\") as f:\n                data = f.read()\n            return data, None\n        else:\n            with io.BytesIO() as output:\n                item.save(output, format=\"JPEG\")\n                data = output.getvalue()\n            return data, None"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile) and item.filename:\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        elif _PIL_AVAILABLE and isinstance(item, Image.Image):\n            with io.BytesIO() as output:\n                item.save(output, format=\"JPEG\")\n                return output.getvalue(), None\n        else:\n            raise TypeError(\"Unsupported image type for JPEG serialization\")"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if not _PIL_AVAILABLE:\n            raise RuntimeError(\"PIL library is not available. Please install PIL to use JPEGSerializer.\")\n\n        if not isinstance(item, Image.Image):\n            raise TypeError(f\"Unsupported image type: {type(item)}. JPEGSerializer supports only PIL Image.\")\n\n        if isinstance(item, JpegImageFile):\n            if item.filename:\n                with open(item.filename, \"rb\") as f:\n                    return f.read(), None\n            else:\n                raise ValueError(\"Item is a JPEG but does not have a defined filename.\")\n\n        if item.format == \"JPEG\":\n            with io.BytesIO() as output:\n                item.save(output, format=\"JPEG\")\n                return output.getvalue(), None\n\n        raise TypeError(f\"Unsupported image format: {item.format}. JPEGSerializer supports only JPEG images.\")"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if not _PIL_AVAILABLE:\n            raise RuntimeError(\"PIL library is not available. Install it using `pip install pillow`.\")\n        if not isinstance(item, Image.Image) and not isinstance(item, JpegImageFile):\n            raise TypeError(f\"Unsupported image type: {type(item)}. Only PIL Image or JpegImageFile is supported.\")\n\n        if isinstance(item, JpegImageFile) and item.filename:\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        else:\n            with io.BytesIO() as f:\n                item.save(f, format=\"JPEG\")\n                return f.getvalue(), None"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            if item.filename and os.path.isfile(item.filename):\n                with open(item.filename, \"rb\") as f:\n                    return f.read(), None\n            else:\n                raise ValueError(\"JpegImageFile item must have a valid filename to be serialized.\")\n        elif isinstance(item, Image.Image):\n            with io.BytesIO() as output:\n                item.save(output, format=\"JPEG\")\n                return output.getvalue(), None\n        else:\n            raise TypeError(\"Unsupported image type for JPEG serialization.\")"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if not isinstance(item, JpegImageFile):\n            if not isinstance(item, Image.Image):\n                raise TypeError(\"Unsupported image type. Only PIL Image or its subclasses are supported.\")\n            with io.BytesIO() as output:\n                item.save(output, format=\"JPEG\")\n                return output.getvalue(), None\n        else:\n            filename = item.filename\n            if filename and os.path.exists(filename):\n                with open(filename, \"rb\") as file:\n                    return file.read(), None\n            else:\n                raise ValueError(\"The item is a JPEG but does not have a valid filename.\")"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if not _PIL_AVAILABLE:\n            raise RuntimeError(\"PIL is not available. Install PIL to use the JPEGSerializer.\")\n\n        if not isinstance(item, Image.Image):\n            raise TypeError(f\"Unsupported image type: {type(item)}. Only PIL Image objects are supported.\")\n\n        if isinstance(item, JpegImageFile):\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n\n        with io.BytesIO() as f:\n            item.save(f, format=\"JPEG\")\n            return f.getvalue(), None"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            if item.filename and os.path.exists(item.filename):\n                with open(item.filename, \"rb\") as f:\n                    return f.read(), None\n            else:\n                raise ValueError(\"Item is a JPEG but does not have a valid filename.\")\n        elif isinstance(item, Image.Image):\n            with io.BytesIO() as output:\n                item.save(output, format=\"JPEG\")\n                return output.getvalue(), None\n        else:\n            raise TypeError(\"Item is not a supported image type for JPEG serialization.\")"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile) and hasattr(item, \"filename\") and os.path.exists(item.filename):\n            with open(item.filename, \"rb\") as f:\n                data = f.read()\n            return data, None\n        elif isinstance(item, Image.Image):\n            with io.BytesIO() as output:\n                item.save(output, format=\"JPEG\")\n                data = output.getvalue()\n            return data, None\n        else:\n            raise TypeError(\"Unsupported image type for JPEG serialization\")"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            filename = item.filename\n            if filename and os.path.exists(filename):\n                with open(filename, \"rb\") as f:\n                    return f.read(), None\n            else:\n                raise ValueError(\"Item is a JPEG but does not have a defined filename or the file does not exist.\")\n\n        if not isinstance(item, Image.Image):\n            raise TypeError(\"Item should be an instance of Image class or its subclasses.\")\n\n        with io.BytesIO() as output:\n            item.save(output, format=\"JPEG\")\n            return output.getvalue(), None"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile) and item.filename:\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        elif isinstance(item, Image.Image):\n            with io.BytesIO() as output:\n                item.save(output, format=\"JPEG\")\n                return output.getvalue(), None\n        else:\n            raise TypeError(\"Unsupported image type for JPEG serialization\")"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile) and item.filename:\n            with open(item.filename, \"rb\") as f:\n                data = f.read()\n            return data, None\n        elif _PIL_AVAILABLE and isinstance(item, Image.Image):\n            with io.BytesIO() as output:\n                item.save(output, format=\"JPEG\")\n                data = output.getvalue()\n            return data, None\n        else:\n            raise TypeError(\"Unsupported image type for JPEG serialization\")"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if not isinstance(item, JpegImageFile):\n            if not isinstance(item, Image.Image):\n                raise TypeError(\"Unsupported image type. Only PIL Image or its subclasses are supported.\")\n            with io.BytesIO() as output:\n                item.save(output, format=\"JPEG\")\n                return output.getvalue(), None\n        else:\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            if item.filename:\n                with open(item.filename, \"rb\") as f:\n                    return f.read(), None\n            else:\n                raise ValueError(\"Item is a JPEG but has no filename\")\n        elif isinstance(item, Image.Image):\n            with io.BytesIO() as output:\n                item.save(output, format=\"JPEG\")\n                return output.getvalue(), None\n        else:\n            raise TypeError(\"Item is not a supported image type for JPEG serialization\")"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if not _PIL_AVAILABLE:\n            raise RuntimeError(\"PIL is not available. JPEGSerializer requires PIL to be installed.\")\n\n        if not isinstance(item, Image.Image):\n            raise TypeError(f\"Unsupported image type: {type(item)}. JPEGSerializer supports PIL Image types only.\")\n\n        if isinstance(item, JpegImageFile) and hasattr(item, \"filename\") and os.path.exists(item.filename):\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        else:\n            with io.BytesIO() as output:\n                item.save(output, format=\"JPEG\")\n                return output.getvalue(), None"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if not _PIL_AVAILABLE:\n            raise RuntimeError(\"PIL is not available. Please install PIL to use JPEG serialization.\")\n\n        if not isinstance(item, Image.Image):\n            raise TypeError(\"Item should be an instance of PIL Image class or its subclasses.\")\n\n        if isinstance(item, JpegImageFile) and hasattr(item, \"filename\") and os.path.exists(item.filename):\n            with open(item.filename, \"rb\") as f:\n                return f.read(), None\n        else:\n            with io.BytesIO() as output:\n                item.save(output, format=\"JPEG\")\n                return output.getvalue(), None"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data, dtype=np.uint32, count=3)\n        width, height, mode_length = ints\n        mode = data[12:12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length:]\n        return Image.frombytes(mode, (width, height), raw)"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_length = ints\n        mode = data[12:12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length:]\n        return Image.frombytes(mode, (width, height), raw)"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_length = ints\n        mode = data[12:12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length:]\n        return Image.frombytes(mode, (width, height), raw)"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data, dtype=np.uint32, count=3)\n        width, height, mode_length = ints\n        mode = data[12:12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length:]\n        return Image.frombytes(mode, (width, height), raw)"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_length = ints\n        mode = data[12:12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length:]\n        return Image.frombytes(mode, (width, height), raw)"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data, dtype=np.uint32, count=3)\n        width, height, mode_length = ints\n        mode = data[12:12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length:]\n        return Image.frombytes(mode, (width, height), raw)"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data, dtype=np.uint32, count=3)\n        width, height, mode_length = ints\n        mode = data[12:12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length:]\n        return Image.frombytes(mode, (width, height), raw)"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_length = ints\n        mode = data[12:12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length:]\n        return Image.frombytes(mode, (width, height), raw)"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_length = ints\n        mode = data[12:12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length:]\n        return Image.frombytes(mode, (width, height), raw)"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_length = ints\n        mode = data[12:12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length:]\n        return Image.frombytes(mode, (width, height), raw)"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_length = ints\n        mode = data[12:12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length:]\n        return Image.frombytes(mode, (width, height), raw)"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_length = ints\n        mode = data[12:12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length:]\n\n        # Reconstruct the image from the extracted data\n        image = Image.frombytes(mode, (width, height), raw)\n        return image"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data, dtype=np.uint32, count=3)\n        width, height, mode_length = ints\n        mode = data[12:12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length:]\n        return Image.frombytes(mode, (width, height), raw)"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_length = ints\n        mode = data[12:12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length:]\n        return Image.frombytes(mode, (width, height), raw)"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_length = ints\n        mode = data[12:12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length:]\n        return Image.frombytes(mode, (width, height), raw)"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data, dtype=np.uint32, count=3)\n        width, height, mode_length = ints\n        mode = data[12:12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length:]\n        return Image.frombytes(mode, (width, height), raw)"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_length = ints\n        mode = data[12:12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length:]\n        return Image.frombytes(mode, (width, height), raw)"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data, dtype=np.uint32, count=3)\n        width, height, mode_len = ints\n        mode = data[12:12 + mode_len].decode(\"utf-8\")\n        raw = data[12 + mode_len:]\n        return Image.frombytes(mode, (width, height), raw)"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], dtype=np.uint32)\n        width, height, mode_length = ints\n        mode = data[12:12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length:]\n        return Image.frombytes(mode, (width, height), raw)"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_length = ints\n        mode = data[12:12 + mode_length].decode(\"utf-8\")\n        raw = data[12 + mode_length:]\n        return Image.frombytes(mode, (width, height), raw)"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_index = np.frombuffer(data, dtype=np.uint32, count=1)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_index]\n        shape_length = np.frombuffer(data, dtype=np.uint32, count=1, offset=4)[0]\n        shape = tuple(np.frombuffer(data, dtype=np.uint32, count=shape_length, offset=8))\n        tensor_data = np.frombuffer(data, dtype=np.uint8, offset=8 + shape_length * 4)\n        tensor = torch.from_numpy(tensor_data).view(shape).to(dtype)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[:4], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_len = np.frombuffer(data[4:8], np.uint32)[0]\n        shape = tuple(np.frombuffer(data[8:8 + 4 * shape_len], np.uint32))\n        tensor_data = np.frombuffer(data[8 + 4 * shape_len:], _NUMPY_DTYPES_MAPPING[dtype])\n        return torch.from_numpy(tensor_data).view(shape).to(dtype)"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[:4], np.uint32)[0]\n        shape_len = np.frombuffer(data[4:8], np.uint32)[0]\n        shape = tuple(np.frombuffer(data[8:8 + shape_len * 4], np.uint32))\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        tensor_data = np.frombuffer(data[8 + shape_len * 4:], dtype=_NUMPY_DTYPES_MAPPING[dtype])\n        return torch.from_numpy(tensor_data).view(shape).to(dtype)"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[:4], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_length = np.frombuffer(data[4:8], np.uint32)[0]\n        shape = tuple(np.frombuffer(data[8 : 8 + shape_length * 4], np.uint32))\n        raw_data = np.frombuffer(data[8 + shape_length * 4 :], dtype=_NUMPY_DTYPES_MAPPING[dtype])\n        tensor = torch.from_numpy(raw_data).view(shape).to(dtype)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[:4], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_len = np.frombuffer(data[4:8], np.uint32)[0]\n        shape = tuple(np.frombuffer(data[8:8 + 4 * shape_len], np.uint32))\n        tensor_data = np.frombuffer(data[8 + 4 * shape_len:], dtype=_NUMPY_DTYPES_MAPPING[dtype])\n        return torch.from_numpy(tensor_data).view(shape).to(dtype)"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[:4], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_len = np.frombuffer(data[4:8], np.uint32)[0]\n        shape = tuple(np.frombuffer(data[8:8 + shape_len * 4], np.uint32))\n        tensor_data = np.frombuffer(data[8 + shape_len * 4:], dtype=_NUMPY_DTYPES_MAPPING[dtype])\n        return torch.from_numpy(tensor_data).view(shape).to(dtype)"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_idx = np.frombuffer(data, dtype=np.uint32, count=1)[0]\n        dtype = list(_TORCH_DTYPES_MAPPING.values())[dtype_idx]\n        shape_len = np.frombuffer(data[4:8], dtype=np.uint32, count=1)[0]\n        shape = tuple(np.frombuffer(data[8:8 + 4 * shape_len], dtype=np.uint32))\n        tensor_data = np.frombuffer(data[8 + 4 * shape_len:], dtype=dtype)\n        return torch.from_numpy(tensor_data).view(shape)"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_index = np.frombuffer(data[:4], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_index]\n        shape_len = np.frombuffer(data[4:8], np.uint32)[0]\n        shape = tuple(np.frombuffer(data[8:8 + shape_len * 4], np.uint32))\n        tensor_data = np.frombuffer(data[8 + shape_len * 4:], dtype=_NUMPY_DTYPES_MAPPING[dtype])\n        tensor = torch.from_numpy(tensor_data).view(shape)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[:4], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        idx = 4\n        shape_len = np.frombuffer(data[idx : idx + 4], np.uint32)[0]\n        idx += 4\n        shape = tuple(np.frombuffer(data[idx : idx + 4 * shape_len], np.uint32))\n        idx += 4 * shape_len\n        tensor_data = np.frombuffer(data[idx:], dtype=_NUMPY_DTYPES_MAPPING[dtype])\n        tensor = torch.from_numpy(tensor_data).view(shape)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_index = int.from_bytes(data[:4], byteorder=\"little\", signed=False)\n        dtype = list(_TORCH_DTYPES_MAPPING.keys())[dtype_index]\n        shape_length = int.from_bytes(data[4:8], byteorder=\"little\", signed=False)\n        shape = tuple(int.from_bytes(data[i:i+4], byteorder=\"little\", signed=False) for i in range(8, 8 + shape_length * 4))\n        tensor_data = np.frombuffer(data[8 + shape_length * 4:], dtype=_NUMPY_DTYPES_MAPPING[dtype])\n        tensor = torch.from_numpy(tensor_data).view(shape)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[:4], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_len = np.frombuffer(data[4:8], np.uint32)[0]\n        shape = tuple(np.frombuffer(data[8:8 + 4 * shape_len], np.uint32))\n        tensor_data = np.frombuffer(data[8 + 4 * shape_len:], _NUMPY_DTYPES_MAPPING[dtype])\n        tensor = torch.from_numpy(tensor_data)\n        tensor = tensor.view(shape)\n        tensor = tensor.type(dtype)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_idx = np.frombuffer(data[:4], np.uint32)[0]\n        dtype = list(_TORCH_DTYPES_MAPPING.keys())[dtype_idx]\n        shape_len = np.frombuffer(data[4:8], np.uint32)[0]\n        shape = tuple(np.frombuffer(data[8:8 + 4 * shape_len], np.uint32))\n        tensor_data = np.frombuffer(data[8 + 4 * shape_len:], dtype=_TORCH_DTYPES_MAPPING[dtype])\n        return torch.from_numpy(tensor_data).reshape(shape).to(dtype)"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[:4], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_len = np.frombuffer(data[4:8], np.uint32)[0]\n        shape = tuple(np.frombuffer(data[8:8 + 4 * shape_len], np.uint32))\n        tensor_data = np.frombuffer(data[8 + 4 * shape_len:], dtype=_NUMPY_DTYPES_MAPPING[dtype])\n        return torch.from_numpy(tensor_data).view(shape)"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[:4], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_len = np.frombuffer(data[4:8], np.uint32)[0]\n        shape = tuple(np.frombuffer(data[8:8 + shape_len * 4], np.uint32))\n        raw_data = np.frombuffer(data[8 + shape_len * 4:], _NUMPY_DTYPES_MAPPING[dtype])\n        tensor = torch.from_numpy(raw_data).view(shape).to(dtype)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_index = np.frombuffer(data[:4], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_index]\n        shape_length = np.frombuffer(data[4:8], np.uint32)[0]\n        shape = tuple(np.frombuffer(data[8:8 + shape_length * 4], np.uint32))\n        tensor_data = np.frombuffer(data[8 + shape_length * 4:], dtype=_NUMPY_DTYPES_MAPPING[dtype])\n        return torch.from_numpy(tensor_data).view(shape).to(dtype)"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[:4], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_len = np.frombuffer(data[4:8], np.uint32)[0]\n        shape = tuple(np.frombuffer(data[8:8 + shape_len * 4], np.uint32))\n        tensor_data = np.frombuffer(data[8 + shape_len * 4:], dtype=_NUMPY_DTYPES_MAPPING[dtype])\n        tensor = torch.from_numpy(tensor_data).view(shape)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[:4], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_len = np.frombuffer(data[4:8], np.uint32)[0]\n        shape = tuple(np.frombuffer(data[8:8 + shape_len * 4], np.uint32))\n        raw_data = np.frombuffer(data[8 + shape_len * 4:], _NUMPY_DTYPES_MAPPING[dtype])\n        tensor = torch.from_numpy(raw_data).view(shape).to(dtype)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[:4], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_len = np.frombuffer(data[4:8], np.uint32)[0]\n        shape = tuple(np.frombuffer(data[8:8 + shape_len * 4], np.uint32))\n        raw_data = np.frombuffer(data[8 + shape_len * 4:], dtype=_NUMPY_DTYPES_MAPPING[dtype])\n        tensor = torch.from_numpy(raw_data).view(shape)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[:4], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_len = np.frombuffer(data[4:8], np.uint32)[0]\n        shape = tuple(np.frombuffer(data[8:8 + shape_len * 4], np.uint32))\n        tensor_data = np.frombuffer(data[8 + shape_len * 4:], dtype=_NUMPY_DTYPES_MAPPING[dtype])\n        tensor = torch.from_numpy(tensor_data).view(shape)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[:4], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_len = np.frombuffer(data[4:8], np.uint32)[0]\n        shape = tuple(np.frombuffer(data[8:8 + shape_len * 4], np.uint32))\n        tensor_data = np.frombuffer(data[8 + shape_len * 4:], dtype=_NUMPY_DTYPES_MAPPING[dtype])\n        tensor = torch.from_numpy(tensor_data).view(shape)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_idx = self._dtype_to_indices[item.dtype]\n        shape = np.array(item.shape, np.int32)\n        data = item.numpy().tobytes()\n        header = np.array([dtype_idx, len(shape)], np.uint32).tobytes()\n        return header + shape.tobytes() + data, None"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = self._dtype_to_indices[item.dtype]\n        shape = np.array(item.shape, dtype=np.uint32)\n        raw = item.contiguous().view(-1).numpy().tobytes()\n        return dtype.encode(\"utf-8\") + shape.tobytes() + raw, None"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_idx = self._dtype_to_indices[item.dtype]\n        shape = np.array(item.shape, dtype=np.uint32)\n        raw = item.numpy().tobytes()\n        return dtype_idx.to_bytes(1, \"big\") + shape.tobytes() + raw, None"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = self._dtype_to_indices[item.dtype]\n        shape = np.array(item.shape, dtype=np.uint32)\n        data = item.tobytes()\n        return dtype.encode(\"utf-8\") + shape.tobytes() + data, None"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = self._dtype_to_indices[item.dtype]\n        shape = np.array(item.shape, dtype=np.int32)\n        raw_data = item.numpy().tobytes()\n        return dtype.tobytes() + shape.tobytes() + raw_data, None"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = item.dtype\n        shape = item.shape\n        raw_data = item.tobytes()\n        dtype_index = _TORCH_DTYPES_MAPPING[dtype]\n        dtype_bytes = np.array([dtype_index], np.uint8).tobytes()\n        shape_bytes = np.array(shape, np.int32).tobytes()\n        return dtype_bytes + shape_bytes + raw_data, None"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = item.dtype\n        shape = item.shape\n        raw_data = item.numpy().tobytes()\n        dtype_idx = _TORCH_DTYPES_MAPPING[dtype]\n        dtype_bytes = np.array([dtype_idx], np.uint8).tobytes()\n        shape_bytes = np.array(shape, np.uint32).tobytes()\n        return dtype_bytes + shape_bytes + raw_data, None"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = self._dtype_to_indices[item.dtype]\n        shape = np.array(item.shape, dtype=np.uint32)\n        raw = item.numpy().tobytes()\n        return dtype.encode(\"utf-8\") + shape.tobytes() + raw, None"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_idx = self._dtype_to_indices[item.dtype]\n        shape = np.array(item.shape, np.uint32)\n        raw = item.numpy().tobytes()\n        return dtype_idx.to_bytes(1, \"big\") + shape.tobytes() + raw, None"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = self._dtype_to_indices[item.dtype]\n        shape = np.array(item.shape, dtype=np.uint32)\n        raw = item.numpy().tobytes()\n        return dtype.encode(\"utf-8\") + shape.tobytes() + raw, None"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = self._dtype_to_indices[item.dtype]\n        shape = np.array(item.shape, dtype=np.uint32)\n        data = item.tobytes()\n        return dtype.encode(\"utf-8\") + shape.tobytes() + data, None"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = self._dtype_to_indices[item.dtype]\n        shape = np.array(item.shape, dtype=np.uint32)\n        raw = item.numpy().tobytes()\n        return dtype.encode(\"utf-8\") + shape.tobytes() + raw, None"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_idx = self._dtype_to_indices[item.dtype]\n        shape = np.array(item.shape, dtype=np.uint32)\n        data = item.contiguous().view(-1).numpy().tobytes()\n        return dtype_idx.to_bytes(1, byteorder=\"big\") + shape.tobytes() + data, None"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = self._dtype_to_indices[item.dtype]\n        shape = np.array(item.shape, dtype=np.uint32)\n        data = item.numpy().tobytes()\n        return dtype.encode(\"utf-8\") + shape.tobytes() + data, None"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = item.dtype\n        shape = np.array(item.shape, dtype=np.uint32)\n        raw = item.tobytes()\n        dtype_idx = _TORCH_DTYPES_MAPPING[dtype]\n        return dtype_idx.to_bytes(1, \"big\") + shape.tobytes() + raw, None"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_idx = self._dtype_to_indices[item.dtype]\n        shape = np.array(item.shape, dtype=np.uint32)\n        raw = item.numpy().tobytes()\n        return dtype_idx.tobytes() + shape.tobytes() + raw, None"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_idx = self._dtype_to_indices[item.dtype]\n        shape = np.array(item.shape, dtype=np.uint32)\n        data = item.numpy().tobytes()\n        return dtype_idx.to_bytes(1, \"big\") + shape.tobytes() + data, None"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_idx = self._dtype_to_indices[item.dtype]\n        shape = np.array(item.shape, dtype=np.int32)\n        data = item.numpy().tobytes()\n        return dtype_idx.tobytes() + shape.tobytes() + data, None"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = item.dtype\n        shape = item.shape\n        raw_data = item.numpy().tobytes()\n        dtype_idx = _TORCH_DTYPES_MAPPING[dtype]\n        dtype_bytes = np.array([dtype_idx], np.uint8).tobytes()\n        shape_bytes = np.array(shape, np.int32).tobytes()\n        return dtype_bytes + shape_bytes + raw_data, None"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = item.dtype\n        shape = np.array(item.shape, dtype=np.int32)\n        raw = item.numpy().tobytes()\n        dtype_str = self._dtype_to_indices[dtype]\n        return dtype_str.encode(\"utf-8\") + shape.tobytes() + raw, None"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb * 25 / 323\n  linear1 = xnp.maximum(eps, (srgb + 11) / 211) ** (12 / 5)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb * 25 / 323\n  linear1 = xnp.maximum(eps, (srgb + 11) / 211) ** (12 / 5)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb * 25 / 323\n  linear1 = xnp.maximum(eps, (srgb + 11) / 211) ** (12 / 5)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 12.92\n  linear1 = xnp.maximum(eps, ((srgb + 0.055) / 1.055) ** 2.4)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 12.92\n  linear1 = ((srgb + 0.055) / 1.055) ** 2.4\n  return xnp.where(srgb <= 0.04045, linear0, linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 12.92\n  linear1 = xnp.maximum(eps, ((srgb + 0.055) / 1.055) ** 2.4)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb * 25 / 323\n  linear1 = xnp.maximum(eps, (srgb + 11) / 211) ** (12 / 5)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 12.92\n  linear1 = xnp.maximum(eps, ((srgb + 0.055) / 1.055) ** 2.4)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 12.92\n  linear1 = xnp.maximum(eps, ((srgb + 0.055) / 1.055) ** 2.4)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb * 25 / 323\n  linear1 = xnp.maximum(eps, (srgb + 11) / 211) ** (12 / 5)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb * 25 / 323\n  linear1 = xnp.maximum(eps, (srgb + 11) / 211) ** (12 / 5)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 12.92\n  linear1 = xnp.maximum(eps, ((srgb + 0.055) / 1.055) ** 2.4)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb * (25 / 323)\n  linear1 = xnp.maximum(eps, ((srgb + 11) / 211) ** (12 / 5))\n  return xnp.where(srgb <= 0.04045, linear0, linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 12.92\n  linear1 = xnp.maximum(eps, ((srgb + 0.055) / 1.055) ** 2.4)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb * (25 / 323)\n  linear1 = xnp.maximum(eps, (srgb + 11) / 211) ** (12 / 5)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 12.92\n  linear1 = xnp.power((srgb + 0.055) / 1.055, 2.4)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 12.92\n  linear1 = xnp.maximum(eps, ((srgb + 0.055) / 1.055) ** 2.4)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 12.92\n  linear1 = xnp.maximum(eps, ((srgb + 0.055) / 1.055) ** 2.4)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb * (25 / 323)\n  linear1 = xnp.maximum(eps, (srgb + 11) / 211) ** (12 / 5)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 12.92\n  linear1 = ((srgb + 0.055) / 1.055) ** 2.4\n  return xnp.where(srgb <= 0.04045, linear0, linear1)"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'NEAREST':\n    # Round the locations to the nearest integer\n    locations = jnp.round(locations).astype(jnp.int32)\n    # Gather from data at the rounded locations\n    resampled_data = gather_volume(data, locations, coordinate_order)\n  elif method == 'TRILINEAR':\n    # If half pixel centering is used, adjust the locations\n    if half_pixel_center:\n      locations -= 0.5\n    # Extract the integer and fractional parts of the locations\n    int_locations = jnp.floor(locations).astype(jnp.int32)\n    frac_locations = locations - int_locations\n    # Handle edge behavior\n    if edge_behavior == 'CONSTANT_OUTSIDE':\n      # Pad the input volume with constant values\n      padded_data = jnp.pad(data, 1, constant_values=constant_values)\n      # Gather from data at the integer locations\n      gathered_data = gather_volume(padded_data, int_locations, coordinate_order)\n    elif edge_behavior == 'CLAMP':\n      # Clamp the integer locations to the volume boundaries\n      clamped_locations = jnp.clip(int_locations, 0, jnp.array(data.shape) - 1)\n      # Gather from data at the clamped locations\n      gathered_data = gather_volume(data, clamped_locations, coordinate_order)\n    # Calculate the trilinear interpolation weights\n    weights = jnp.prod(1 - frac_locations, axis=-1, keepdims=True)\n    # Interpolate along the x-axis\n    interp_x0 = gathered_data\n    interp_x1 = gather_volume(data, int_locations + 1, coordinate_order)\n    interp_x = interp_x0 * (1 - frac_locations[..., 0:1]) + interp_x1 * frac_locations[..., 0:1]\n    # Interpolate along the y-axis\n    interp_y0 = interp_x\n    interp_y1 = gather_volume(data, int_locations + jnp.array([0, 1, 0]), coordinate_order)\n    interp_y = interp_y0 * (1 - frac_locations[..., 1:2]) + interp_y1 * frac_locations[..., 1:2]\n    # Interpolate along the z-axis\n    interp_z0 = interp_y\n    interp_z1 = gather_volume(data, int_locations + jnp.array([0, 0, 1]), coordinate_order)\n    interp_z = interp_z0 * (1 - frac_locations[..., 2:3]) + interp_z1 * frac_locations[..., 2:3]\n    # Assign the interpolated values to the resampled data\n    resampled_data = interp_z\n  return resampled_data"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'NEAREST':\n    # Round the locations to the nearest integer\n    locations = jnp.round(locations).astype(jnp.int32)\n    # Gather data at the rounded locations\n    resampled_data = gather_volume(data, locations, coordinate_order)\n  elif method == 'TRILINEAR':\n    # If half-pixel centering is used, adjust the locations by 0.5\n    if half_pixel_center:\n      locations = locations - 0.5\n    # Extract the integer coordinates\n    x0 = jnp.floor(locations[..., 0]).astype(jnp.int32)\n    x1 = x0 + 1\n    y0 = jnp.floor(locations[..., 1]).astype(jnp.int32)\n    y1 = y0 + 1\n    z0 = jnp.floor(locations[..., 2]).astype(jnp.int32)\n    z1 = z0 + 1\n    # Clamp the coordinates to the range of the input volume\n    x0 = jnp.clip(x0, 0, data.shape[2] - 1)\n    x1 = jnp.clip(x1, 0, data.shape[2] - 1)\n    y0 = jnp.clip(y0, 0, data.shape[1] - 1)\n    y1 = jnp.clip(y1, 0, data.shape[1] - 1)\n    z0 = jnp.clip(z0, 0, data.shape[0] - 1)\n    z1 = jnp.clip(z1, 0, data.shape[0] - 1)\n    # Calculate the fractional part for interpolation\n    xd = locations[..., 0] - x0\n    yd = locations[..., 1] - y0\n    zd = locations[..., 2] - z0\n    # Gather the data at the 8 corners of the cube\n    c000 = gather_volume(data, jnp.stack([z0, y0, x0], axis=-1), coordinate_order)\n    c001 = gather_volume(data, jnp.stack([z0, y0, x1], axis=-1), coordinate_order)\n    c010 = gather_volume(data, jnp.stack([z0, y1, x0], axis=-1), coordinate_order)\n    c011 = gather_volume(data, jnp.stack([z0, y1, x1], axis=-1), coordinate_order)\n    c100 = gather_volume(data, jnp.stack([z1, y0, x0], axis=-1), coordinate_order)\n    c101 = gather_volume(data, jnp.stack([z1, y0, x1], axis=-1), coordinate_order)\n    c110 = gather_volume(data, jnp.stack([z1, y1, x0], axis=-1), coordinate_order)\n    c111 = gather_volume(data, jnp.stack([z1, y1, x1], axis=-1), coordinate_order)\n    # Perform trilinear interpolation\n    resampled_data = (\n        c000 * (1 - xd) * (1 - yd) * (1 - zd) +\n        c001 * (1 - xd) * (1 - yd) * zd +\n        c010 * (1 - xd) * yd * (1 - zd) +\n        c011 * (1 - xd) * yd * zd +\n        c100 * xd * (1 - yd) * (1 - zd) +\n        c101 * xd * (1 - yd) * zd +\n        c110 * xd * yd * (1 - zd) +\n        c111 * xd * yd * zd\n    )\n  else:\n    raise ValueError(\"Invalid method. Method must be 'NEAREST' or 'TRILINEAR'.\")\n\n  # Handle edge behavior\n  if edge_behavior == 'CONSTANT_OUTSIDE':\n    # Mask the locations outside the volume and fill with constant values\n    outside_mask = jnp.any(jnp.logical_or(locations < 0, locations >= jnp.array(data.shape[:-1])[None]), axis=-1, keepdims=True)\n    resampled_data = jnp.where(outside_mask, constant_values, resampled_data)\n  elif edge_behavior == 'CLAMP':\n    # Clamp the locations to the range of the input volume\n    locations = jnp.clip(locations, 0, jnp.array(data.shape[:-1])[None] - 1)\n    resampled_data = gather_volume(data, locations, coordinate_order)\n  else:\n    raise ValueError(\"Invalid edge_behavior. Edge behavior must be 'CONSTANT_OUTSIDE' or 'CLAMP'.\")\n\n  return resampled_data"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'NEAREST':\n    # Round the locations to the nearest integer\n    locations = jnp.round(locations).astype(jnp.int32)\n\n    # Clamp the locations to the input volume shape\n    if edge_behavior == 'CLAMP':\n      locations = jnp.clip(locations, 0, jnp.array(data.shape[:-1]) - 1)\n\n    # Gather from data at the rounded locations\n    resampled_data = gather_volume(data, locations, coordinate_order)\n\n  elif method == 'TRILINEAR':\n    # If half-pixel centering is used, shift the locations by 0.5\n    if half_pixel_center:\n      locations = locations + 0.5\n\n    # Compute the floor and ceil indices for the trilinear interpolation\n    floor_locations = jnp.floor(locations).astype(jnp.int32)\n    ceil_locations = jnp.ceil(locations).astype(jnp.int32)\n\n    # Compute the fractional part for interpolation\n    fractional = locations - floor_locations\n\n    # Clamp the floor and ceil indices to the input volume shape\n    floor_locations = jnp.clip(floor_locations, 0, jnp.array(data.shape[:-1]) - 1)\n    ceil_locations = jnp.clip(ceil_locations, 0, jnp.array(data.shape[:-1]) - 1)\n\n    # Gather the data at the floor and ceil indices\n    data_floor = gather_volume(data, floor_locations, coordinate_order)\n    data_ceil = gather_volume(data, ceil_locations, coordinate_order)\n\n    # Perform trilinear interpolation\n    resampled_data = (1 - fractional) * data_floor + fractional * data_ceil\n\n  else:\n    raise ValueError(\"Invalid method. Method must be either 'NEAREST' or 'TRILINEAR'.\")\n\n  return resampled_data"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'NEAREST':\n    # Round the locations to the nearest integer\n    locations = jnp.round(locations).astype(jnp.int32)\n    # Gather the data at the rounded locations\n    resampled_data = gather_volume(data, locations, coordinate_order)\n  elif method == 'TRILINEAR':\n    # If half-pixel centering is used, adjust the locations\n    if half_pixel_center:\n      locations -= 0.5\n    # Extract the integer and fractional parts of the locations\n    int_locations = jnp.floor(locations).astype(jnp.int32)\n    fractional = locations - int_locations\n    # Handle edge behavior\n    if edge_behavior == 'CONSTANT_OUTSIDE':\n      # Pad the input data with constant values\n      padded_data = jnp.pad(data, 1, mode='constant', constant_values=constant_values)\n      # Gather the data at the integer locations\n      gathered_data = gather_volume(padded_data, int_locations, coordinate_order)\n    elif edge_behavior == 'CLAMP':\n      # Clamp the integer locations to the valid range\n      int_locations = jnp.clip(int_locations, 0, jnp.array(data.shape) - 1)\n      # Gather the data at the clamped integer locations\n      gathered_data = gather_volume(data, int_locations, coordinate_order)\n    else:\n      raise ValueError(\"Invalid edge_behavior. Supported options are 'CONSTANT_OUTSIDE' and 'CLAMP'.\")\n      \n    # Interpolate along the x-axis\n    x0 = gathered_data[..., 0]\n    x1 = gathered_data[..., 1]\n    fx0 = x0 * (1 - fractional[..., 0]) + x1 * fractional[..., 0]\n    # Interpolate along the y-axis\n    y0 = gathered_data[..., 2]\n    y1 = gathered_data[..., 3]\n    fx1 = y0 * (1 - fractional[..., 1]) + y1 * fractional[..., 1]\n    # Interpolate along the z-axis\n    z0 = fx0\n    z1 = fx1\n    resampled_data = z0 * (1 - fractional[..., 2]) + z1 * fractional[..., 2]\n  else:\n    raise ValueError(\"Invalid method. Supported options are 'TRILINEAR' and 'NEAREST'.\")\n\n  return resampled_data"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'NEAREST':\n    # Round the locations to the nearest integer\n    locations = jnp.round(locations).astype(jnp.int32)\n    # Gather the data at the rounded locations\n    resampled_data = gather_volume(data, locations, coordinate_order)\n  elif method == 'TRILINEAR':\n    # If half-pixel centering is used, adjust the locations\n    if half_pixel_center:\n      locations -= 0.5\n    # Extract the integer and fractional parts of the locations\n    int_locations = jnp.floor(locations).astype(jnp.int32)\n    frac_locations = locations - int_locations\n    # Handle edge behavior based on the specified method\n    if edge_behavior == 'CONSTANT_OUTSIDE':\n      # Pad the input data with constant values\n      padded_data = jnp.pad(data, 1, mode='constant', constant_values=constant_values)\n      # Gather the data at the integer locations\n      gathered_data = gather_volume(padded_data, int_locations, coordinate_order)\n      # Perform trilinear interpolation\n      resampled_data = (\n          (1 - frac_locations) ** 3 * gathered_data\n          + 3 * (1 - frac_locations) ** 2 * frac_locations * gathered_data[1:]\n          + 3 * (1 - frac_locations) * frac_locations ** 2 * gathered_data[2:]\n          + frac_locations ** 3 * gathered_data[3:]\n      )\n    elif edge_behavior == 'CLAMP':\n      # Clamp the integer locations to the valid range\n      clamped_locations = jnp.clip(int_locations, 0, jnp.array(data.shape) - 1)\n      # Gather the data at the clamped integer locations\n      resampled_data = gather_volume(data, clamped_locations, coordinate_order)\n    else:\n      raise ValueError(\"Invalid edge_behavior. Supported options are 'CONSTANT_OUTSIDE' and 'CLAMP'.\")\n  else:\n    raise ValueError(\"Invalid method. Supported options are 'TRILINEAR' and 'NEAREST'.\")\n\n  return resampled_data"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'NEAREST':\n    # Round the locations to the nearest integer\n    rounded_locations = jnp.round(locations).astype(jnp.int32)\n    # Gather from data at rounded locations\n    resampled_data = gather_volume(data, rounded_locations, coordinate_order)\n  elif method == 'TRILINEAR':\n    if half_pixel_center:\n      # Adjust locations for half-pixel centering\n      locations -= 0.5\n    # Extract integer and fractional parts of the locations\n    int_locations = jnp.floor(locations).astype(jnp.int32)\n    fractional = locations - int_locations\n    # Handle edge behavior\n    if edge_behavior == 'CONSTANT_OUTSIDE':\n      # Pad the data with constant values\n      data = jnp.pad(data, 1, constant_values=constant_values)\n      # Adjust integer locations for padding\n      int_locations += 1\n    elif edge_behavior == 'CLAMP':\n      # Clamp the integer locations to the valid range\n      int_locations = jnp.clip(int_locations, 0, jnp.array(data.shape) - 1)\n    # Gather the 8 corners of the cube around the locations\n    c000 = gather_volume(data, int_locations, coordinate_order)\n    c100 = gather_volume(data, int_locations + [1, 0, 0], coordinate_order)\n    c010 = gather_volume(data, int_locations + [0, 1, 0], coordinate_order)\n    c001 = gather_volume(data, int_locations + [0, 0, 1], coordinate_order)\n    c110 = gather_volume(data, int_locations + [1, 1, 0], coordinate_order)\n    c101 = gather_volume(data, int_locations + [1, 0, 1], coordinate_order)\n    c011 = gather_volume(data, int_locations + [0, 1, 1], coordinate_order)\n    c111 = gather_volume(data, int_locations + [1, 1, 1], coordinate_order)\n    # Perform trilinear interpolation\n    resampled_data = (\n        (1 - fractional[..., 0]) * (1 - fractional[..., 1]) * (1 - fractional[..., 2]) * c000\n        + fractional[..., 0] * (1 - fractional[..., 1]) * (1 - fractional[..., 2]) * c100\n        + (1 - fractional[..., 0]) * fractional[..., 1] * (1 - fractional[..., 2]) * c010\n        + (1 - fractional[..., 0]) * (1 - fractional[..., 1]) * fractional[..., 2] * c001\n        + fractional[..., 0] * fractional[..., 1] * (1 - fractional[..., 2]) * c110\n        + fractional[..., 0] * (1 - fractional[..., 1]) * fractional[..., 2] * c101\n        + (1 - fractional[..., 0]) * fractional[..., 1] * fractional[..., 2] * c011\n        + fractional[..., 0] * fractional[..., 1] * fractional[..., 2] * c111\n    )\n  return resampled_data"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'NEAREST':\n    # Round the locations to the nearest integer\n    rounded_locations = jnp.round(locations).astype(jnp.int32)\n\n    if edge_behavior == 'CLAMP':\n      # Clamp the rounded locations to the volume bounds\n      rounded_locations = jnp.clip(rounded_locations, 0, jnp.array(data.shape[:-1]) - 1)\n\n    # Gather from data at rounded locations\n    resampled_data = gather_volume(data, rounded_locations, coordinate_order)\n\n  elif method == 'TRILINEAR':\n    if half_pixel_center:\n      # Adjust the locations for half-pixel centering\n      half = 0.5\n      locations = locations - half\n\n    # Extract the integer and fractional parts of the locations\n    int_locations = jnp.floor(locations).astype(jnp.int32)\n    frac_locations = locations - int_locations\n\n    if edge_behavior == 'CLAMP':\n      # Clamp the integer locations to the volume bounds\n      int_locations = jnp.clip(int_locations, 0, jnp.array(data.shape[:-1]) - 1)\n\n    # Gather from data at the integer locations\n    gathered_data = gather_volume(data, int_locations, coordinate_order)\n\n    # Compute the weights for trilinear interpolation\n    weights = [\n        (1 - frac_locations) * (1 - frac_locations),\n        (1 - frac_locations) * frac_locations,\n        frac_locations * (1 - frac_locations),\n        frac_locations * frac_locations,\n    ]\n\n    # Perform trilinear interpolation\n    resampled_data = jnp.sum(\n        gathered_data * weights[None, None, None, :, None], axis=-1\n    )\n\n  else:\n    raise ValueError(\"Invalid method. Method must be 'NEAREST' or 'TRILINEAR'.\")\n\n  return resampled_data"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'NEAREST':\n    # Round the locations to the nearest integer\n    locations = jnp.round(locations).astype(jnp.int32)\n    # Gather the data at the rounded locations\n    resampled_data = gather_volume(data, locations, coordinate_order)\n  elif method == 'TRILINEAR':\n    # If half pixel centering is used, adjust the locations\n    if half_pixel_center:\n      locations -= 0.5\n    # Extract the integer and fractional parts of the locations\n    int_locations = jnp.floor(locations).astype(jnp.int32)\n    frac_locations = locations - int_locations\n    # Handle edge behavior\n    if edge_behavior == 'CONSTANT_OUTSIDE':\n      # Pad the input data with constant values\n      padded_data = jnp.pad(data, 1, constant_values=constant_values)\n      # Gather the data at the integer locations\n      gathered_data = gather_volume(padded_data, int_locations, coordinate_order)\n    elif edge_behavior == 'CLAMP':\n      # Clamp the integer locations to the valid range\n      int_locations = jnp.clip(int_locations, 0, jnp.array(data.shape) - 1)\n      # Gather the data at the clamped integer locations\n      gathered_data = gather_volume(data, int_locations, coordinate_order)\n    else:\n      raise ValueError(\"Invalid edge_behavior. Supported options are 'CONSTANT_OUTSIDE' and 'CLAMP'.\")\n    # Calculate the weights for trilinear interpolation\n    weights = jnp.prod(1 - frac_locations, axis=-1, keepdims=True)\n    # Interpolate along the x-axis\n    interp_x = gathered_data * (1 - frac_locations) + gather_volume(gathered_data, int_locations + 1, coordinate_order) * frac_locations\n    # Interpolate along the y-axis\n    interp_y = interp_x * weights + gather_volume(gathered_data, int_locations + jnp.array([0, 1]), coordinate_order) * (1 - weights)\n    # Interpolate along the z-axis\n    resampled_data = interp_y * weights + gather_volume(interp_x, int_locations[:, :, 1] + 1, coordinate_order) * (1 - weights)\n  else:\n    raise ValueError(\"Invalid method. Supported options are 'TRILINEAR' and 'NEAREST'.\")\n\n  return resampled_data"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'NEAREST':\n    # Round the locations to the nearest integer\n    rounded_locations = jnp.round(locations).astype(jnp.int32)\n    # Gather the data at the rounded locations\n    resampled_data = gather_volume(data, rounded_locations, coordinate_order)\n  elif method == 'TRILINEAR':\n    # Calculate the floor and ceil of the locations\n    floor_locations = jnp.floor(locations).astype(jnp.int32)\n    ceil_locations = jnp.ceil(locations).astype(jnp.int32)\n    # Gather data at the floor and ceil locations\n    floor_data = gather_volume(data, floor_locations, coordinate_order)\n    ceil_data = gather_volume(data, ceil_locations, coordinate_order)\n    # Calculate the interpolation weights\n    alpha = locations - floor_locations\n    # Perform trilinear interpolation\n    resampled_data = (\n        (1 - alpha[..., 0]) * (1 - alpha[..., 1]) * (1 - alpha[..., 2]) * floor_data +\n        alpha[..., 0] * (1 - alpha[..., 1]) * (1 - alpha[..., 2]) * ceil_data +\n        (1 - alpha[..., 0]) * alpha[..., 1] * (1 - alpha[..., 2]) * floor_data +\n        alpha[..., 0] * alpha[..., 1] * (1 - alpha[..., 2]) * ceil_data +\n        (1 - alpha[..., 0]) * (1 - alpha[..., 1]) * alpha[..., 2] * floor_data +\n        alpha[..., 0] * (1 - alpha[..., 1]) * alpha[..., 2] * ceil_data +\n        (1 - alpha[..., 0]) * alpha[..., 1] * alpha[..., 2] * floor_data +\n        alpha[..., 0] * alpha[..., 1] * alpha[..., 2] * ceil_data\n    )\n  else:\n    raise ValueError(\"Invalid method. Method must be either 'TRILINEAR' or 'NEAREST'.\")\n\n  return resampled_data"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'NEAREST':\n    # Round the locations to the nearest integer\n    rounded_locations = jnp.round(locations).astype(int)\n\n    if edge_behavior == 'CONSTANT_OUTSIDE':\n      # Pad the input volume with constant values\n      padded_data = jnp.pad(data, 1, constant_values=constant_values)\n\n      # Gather the nearest neighbor values from the padded volume\n      resampled_data = gather_volume(padded_data, rounded_locations, coordinate_order)\n\n    elif edge_behavior == 'CLAMP':\n      # Clamp the rounded locations to the input volume boundaries\n      clamped_locations = jnp.clip(rounded_locations, 0, jnp.array(data.shape) - 1)\n\n      # Gather the nearest neighbor values from the input volume\n      resampled_data = gather_volume(data, clamped_locations, coordinate_order)\n\n  elif method == 'TRILINEAR':\n    # Calculate the integer floor of the locations\n    floor_locations = jnp.floor(locations).astype(int)\n\n    if edge_behavior == 'CONSTANT_OUTSIDE':\n      # Pad the input volume with constant values\n      padded_data = jnp.pad(data, 1, constant_values=constant_values)\n\n      # Gather the trilinear interpolated values from the padded volume\n      resampled_data = trilinear_interpolation(padded_data, locations, floor_locations, coordinate_order, half_pixel_center)\n\n    elif edge_behavior == 'CLAMP':\n      # Clamp the floor locations to the input volume boundaries\n      clamped_locations = jnp.clip(floor_locations, 0, jnp.array(data.shape) - 1)\n\n      # Gather the trilinear interpolated values from the input volume\n      resampled_data = trilinear_interpolation(data, locations, clamped_locations, coordinate_order, half_pixel_center)\n\n  return resampled_data"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'NEAREST':\n    # Round the locations to the nearest integer\n    rounded_locations = jnp.round(locations).astype(jnp.int32)\n    # Gather the data at the rounded locations\n    resampled_data = gather_volume(data, rounded_locations, coordinate_order)\n  elif method == 'TRILINEAR':\n    # If half pixel centering is used, adjust the locations\n    if half_pixel_center:\n      locations -= 0.5\n    # Extract the integer and fractional parts of the locations\n    floor_locations = jnp.floor(locations).astype(jnp.int32)\n    ceil_locations = jnp.ceil(locations).astype(jnp.int32)\n    frac_locations = locations - floor_locations\n    # Handle edge behavior based on the specified method\n    if edge_behavior == 'CONSTANT_OUTSIDE':\n      # Pad the input volume with constant values\n      padded_data = jnp.pad(data, 1, constant_values=constant_values)\n      # Gather the data at the floor and ceil locations\n      floor_data = gather_volume(padded_data, floor_locations, coordinate_order)\n      ceil_data = gather_volume(padded_data, ceil_locations, coordinate_order)\n    elif edge_behavior == 'CLAMP':\n      # Clamp the locations to the valid range\n      floor_locations = jnp.clip(floor_locations, 0, jnp.array(data.shape)-1)\n      ceil_locations = jnp.clip(ceil_locations, 0, jnp.array(data.shape)-1)\n      # Gather the data at the floor and ceil locations\n      floor_data = gather_volume(data, floor_locations, coordinate_order)\n      ceil_data = gather_volume(data, ceil_locations, coordinate_order)\n    # Perform trilinear interpolation\n    resampled_data = (1-frac_locations) * floor_data + frac_locations * ceil_data\n  return resampled_data"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'TRILINEAR':\n    # Trilinear interpolation\n    if half_pixel_center:\n      locations -= 0.5\n\n    if edge_behavior == 'CONSTANT_OUTSIDE':\n      # Pad the input volume with constant values\n      data = jnp.pad(data, ((1, 1), (1, 1), (1, 1), (0, 0)), mode='constant', constant_values=constant_values)\n      locations = jnp.clip(locations, 0, (data.shape[0] - 1, data.shape[1] - 1, data.shape[2] - 1))\n\n    x = locations[..., 0]\n    y = locations[..., 1]\n    z = locations[..., 2]\n\n    x0 = jnp.floor(x).astype(jnp.int32)\n    x1 = x0 + 1\n    y0 = jnp.floor(y).astype(jnp.int32)\n    y1 = y0 + 1\n    z0 = jnp.floor(z).astype(jnp.int32)\n    z1 = z0 + 1\n\n    x0 = jnp.clip(x0, 0, data.shape[2] - 1)\n    x1 = jnp.clip(x1, 0, data.shape[2] - 1)\n    y0 = jnp.clip(y0, 0, data.shape[1] - 1)\n    y1 = jnp.clip(y1, 0, data.shape[1] - 1)\n    z0 = jnp.clip(z0, 0, data.shape[0] - 1)\n    z1 = jnp.clip(z1, 0, data.shape[0] - 1)\n\n    xd = x - x0\n    yd = y - y0\n    zd = z - z0\n\n    c000 = gather_volume(data, jnp.stack([z0, y0, x0], axis=-1), coordinate_order)\n    c001 = gather_volume(data, jnp.stack([z0, y0, x1], axis=-1), coordinate_order)\n    c010 = gather_volume(data, jnp.stack([z0, y1, x0], axis=-1), coordinate_order)\n    c011 = gather_volume(data, jnp.stack([z0, y1, x1], axis=-1), coordinate_order)\n    c100 = gather_volume(data, jnp.stack([z1, y0, x0], axis=-1), coordinate_order)\n    c101 = gather_volume(data, jnp.stack([z1, y0, x1], axis=-1), coordinate_order)\n    c110 = gather_volume(data, jnp.stack([z1, y1, x0], axis=-1), coordinate_order)\n    c111 = gather_volume(data, jnp.stack([z1, y1, x1], axis=-1), coordinate_order)\n\n    c00 = c000 * (1 - xd) + c100 * xd\n    c01 = c001 * (1 - xd) + c101 * xd\n    c10 = c010 * (1 - xd) + c110 * xd\n    c11 = c011 * (1 - xd) + c111 * xd\n\n    c0 = c00 * (1 - yd) + c10 * yd\n    c1 = c01 * (1 - yd) + c11 * yd\n\n    c = c0 * (1 - zd) + c1 * zd\n\n    return c\n\n  elif method == 'NEAREST':\n    # Nearest neighbor interpolation\n    if edge_behavior == 'CONSTANT_OUTSIDE':\n      # Pad the input volume with constant values\n      data = jnp.pad(data, ((1, 1), (1, 1), (1, 1), (0, 0)), mode='constant', constant_values=constant_values)\n      locations = jnp.clip(locations, 0, (data.shape[0] - 1, data.shape[1] - 1, data.shape[2] - 1))\n\n    locations = jnp.round(locations).astype(jnp.int32)\n    return gather_volume(data, locations, coordinate_order)\n  else:\n    raise ValueError(\"Invalid method. Method must be either 'TRILINEAR' or 'NEAREST'.\")"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'NEAREST':\n    # Round the locations to the nearest integer\n    rounded_locations = jnp.round(locations).astype(jnp.int32)\n\n    # Clamp the rounded locations to the volume boundaries if edge behavior is set to 'CLAMP'\n    if edge_behavior == 'CLAMP':\n      rounded_locations = jnp.clip(rounded_locations, 0, jnp.array(data.shape) - 1)\n\n    # Gather from the data at the rounded locations\n    resampled_data = gather_volume(data, rounded_locations, coordinate_order)\n\n  elif method == 'TRILINEAR':\n    # If half-pixel centering is used, adjust the locations\n    if half_pixel_center:\n      locations -= 0.5\n\n    # Extract the integer and fractional parts of the locations\n    int_locations = jnp.floor(locations).astype(jnp.int32)\n    frac_locations = locations - int_locations\n\n    # Clamp the integer locations to the volume boundaries if edge behavior is set to 'CLAMP'\n    if edge_behavior == 'CLAMP':\n      int_locations = jnp.clip(int_locations, 0, jnp.array(data.shape) - 1)\n\n    # Calculate the weights for trilinear interpolation\n    w000 = (1 - frac_locations[..., 0]) * (1 - frac_locations[..., 1]) * (1 - frac_locations[..., 2])\n    w001 = (1 - frac_locations[..., 0]) * (1 - frac_locations[..., 1]) * frac_locations[..., 2]\n    w010 = (1 - frac_locations[..., 0]) * frac_locations[..., 1] * (1 - frac_locations[..., 2])\n    w011 = (1 - frac_locations[..., 0]) * frac_locations[..., 1] * frac_locations[..., 2]\n    w100 = frac_locations[..., 0] * (1 - frac_locations[..., 1]) * (1 - frac_locations[..., 2])\n    w101 = frac_locations[..., 0] * (1 - frac_locations[..., 1]) * frac_locations[..., 2]\n    w110 = frac_locations[..., 0] * frac_locations[..., 1] * (1 - frac_locations[..., 2])\n    w111 = frac_locations[..., 0] * frac_locations[..., 1] * frac_locations[..., 2]\n\n    # Gather the data at the integer locations\n    data_000 = gather_volume(data, int_locations, coordinate_order)\n    data_001 = gather_volume(data, int_locations + jnp.array([0, 0, 1]), coordinate_order)\n    data_010 = gather_volume(data, int_locations + jnp.array([0, 1, 0]), coordinate_order)\n    data_011 = gather_volume(data, int_locations + jnp.array([0, 1, 1]), coordinate_order)\n    data_100 = gather_volume(data, int_locations + jnp.array([1, 0, 0]), coordinate_order)\n    data_101 = gather_volume(data, int_locations + jnp.array([1, 0, 1]), coordinate_order)\n    data_110 = gather_volume(data, int_locations + jnp.array([1, 1, 0]), coordinate_order)\n    data_111 = gather_volume(data, int_locations + jnp.array([1, 1, 1]), coordinate_order)\n\n    # Perform trilinear interpolation\n    resampled_data = (\n        w000 * data_000 + w001 * data_001 + w010 * data_010 + w011 * data_011 +\n        w100 * data_100 + w101 * data_101 + w110 * data_110 + w111 * data_111\n    )\n\n  else:\n    raise ValueError(\"Invalid method. Method must be 'TRILINEAR' or 'NEAREST'.\")\n\n  return resampled_data"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'NEAREST':\n    # Round the locations to the nearest integer\n    locations = jnp.round(locations).astype(int)\n\n    # Clamp the locations if edge behavior is set to 'CLAMP'\n    if edge_behavior == 'CLAMP':\n      locations = jnp.clip(locations, 0, jnp.array(data.shape[:-1]) - 1)\n\n    # Gather from data at the rounded locations\n    resampled_data = gather_volume(data, locations, coordinate_order)\n\n  elif method == 'TRILINEAR':\n    # Calculate the floor and ceil coordinates for interpolation\n    floor_locations = jnp.floor(locations).astype(int)\n    ceil_locations = jnp.ceil(locations).astype(int)\n\n    # Clamp the floor and ceil locations if edge behavior is set to 'CLAMP'\n    if edge_behavior == 'CLAMP':\n      floor_locations = jnp.clip(floor_locations, 0, jnp.array(data.shape[:-1]) - 1)\n      ceil_locations = jnp.clip(ceil_locations, 0, jnp.array(data.shape[:-1]) - 1)\n\n    # Calculate the fractional part for interpolation\n    fractional = locations - floor_locations\n\n    # Gather data at the floor and ceil locations\n    data_floor = gather_volume(data, floor_locations, coordinate_order)\n    data_ceil = gather_volume(data, ceil_locations, coordinate_order)\n\n    # Perform trilinear interpolation\n    resampled_data = (1 - fractional) * data_floor + fractional * data_ceil\n\n  return resampled_data"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'NEAREST':\n    # Round the locations to the nearest integer\n    locations = jnp.round(locations).astype(int)\n\n    if edge_behavior == 'CONSTANT_OUTSIDE':\n      # Clamp the locations to the volume boundaries\n      locations = jnp.clip(locations, 0, jnp.array(data.shape[:-1]) - 1)\n\n      # Gather from data at the rounded locations\n      resampled_data = gather_volume(data, locations, coordinate_order)\n\n    elif edge_behavior == 'CLAMP':\n      # Clamp the locations to the volume boundaries\n      locations = jnp.clip(locations, 0, jnp.array(data.shape[:-1]) - 1)\n\n      # Gather from data at the rounded locations\n      resampled_data = gather_volume(data, locations, coordinate_order)\n\n  elif method == 'TRILINEAR':\n    # If half-pixel centering is used, adjust the locations\n    if half_pixel_center:\n      locations -= 0.5\n\n    # Extract the integer and fractional parts of the locations\n    int_locations = jnp.floor(locations).astype(int)\n    frac_locations = locations - int_locations\n\n    if edge_behavior == 'CONSTANT_OUTSIDE':\n      # Pad the volume with constant values\n      padded_data = jnp.pad(data, ((1, 1), (1, 1), (1, 1), (0, 0)), mode='constant', constant_values=constant_values)\n\n      # Gather from data at the rounded locations\n      gathered_data = gather_volume(padded_data, int_locations + 1, coordinate_order)\n\n      # Trilinear interpolation\n      resampled_data = (\n          (1 - frac_locations) * gathered_data\n          + frac_locations * gather_volume(padded_data, int_locations + 1, coordinate_order)\n      )\n\n    elif edge_behavior == 'CLAMP':\n      # Clamp the locations to the volume boundaries\n      int_locations = jnp.clip(int_locations, 0, jnp.array(data.shape[:-1]) - 1)\n\n      # Gather from data at the rounded locations\n      gathered_data = gather_volume(data, int_locations, coordinate_order)\n\n      # Trilinear interpolation\n      resampled_data = (\n          (1 - frac_locations) * gathered_data\n          + frac_locations * gather_volume(data, int_locations + 1, coordinate_order)\n      )\n\n  return resampled_data"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'NEAREST':\n    # Round the locations to the nearest integer\n    locations = jnp.round(locations).astype(jnp.int32)\n    # Gather the data at the rounded locations\n    resampled_data = gather_volume(data, locations, coordinate_order)\n  elif method == 'TRILINEAR':\n    # Get the integer floor of the locations\n    floor_locations = jnp.floor(locations).astype(jnp.int32)\n    # Get the fractional part of the locations\n    delta = locations - floor_locations\n    # Gather the data at the floor locations\n    c000 = gather_volume(data, floor_locations, coordinate_order)\n    c100 = gather_volume(data, floor_locations + jnp.array([1, 0, 0]), coordinate_order)\n    c010 = gather_volume(data, floor_locations + jnp.array([0, 1, 0]), coordinate_order)\n    c001 = gather_volume(data, floor_locations + jnp.array([0, 0, 1]), coordinate_order)\n    c110 = gather_volume(data, floor_locations + jnp.array([1, 1, 0]), coordinate_order)\n    c101 = gather_volume(data, floor_locations + jnp.array([1, 0, 1]), coordinate_order)\n    c011 = gather_volume(data, floor_locations + jnp.array([0, 1, 1]), coordinate_order)\n    c111 = gather_volume(data, floor_locations + jnp.array([1, 1, 1]), coordinate_order)\n    # Perform trilinear interpolation\n    resampled_data = (\n        (1 - delta[..., 0]) * (1 - delta[..., 1]) * (1 - delta[..., 2]) * c000 +\n        delta[..., 0] * (1 - delta[..., 1]) * (1 - delta[..., 2]) * c100 +\n        (1 - delta[..., 0]) * delta[..., 1] * (1 - delta[..., 2]) * c010 +\n        (1 - delta[..., 0]) * (1 - delta[..., 1]) * delta[..., 2] * c001 +\n        delta[..., 0] * delta[..., 1] * (1 - delta[..., 2]) * c110 +\n        delta[..., 0] * (1 - delta[..., 1]) * delta[..., 2] * c101 +\n        (1 - delta[..., 0]) * delta[..., 1] * delta[..., 2] * c011 +\n        delta[..., 0] * delta[..., 1] * delta[..., 2] * c111\n    )\n  else:\n    raise ValueError(\"Invalid method. Method must be 'TRILINEAR' or 'NEAREST'.\")\n\n  return resampled_data"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'NEAREST':\n    # Round the locations to the nearest integer\n    if half_pixel_center:\n      locations = locations - 0.5\n    locations = jnp.round(locations).astype(jnp.int32)\n\n    # Clamp the locations if edge_behavior is set to 'CLAMP'\n    if edge_behavior == 'CLAMP':\n      locations = jnp.clip(locations, 0, jnp.array(data.shape[:3]) - 1)\n\n    # Gather from data at the rounded locations\n    resampled_data = gather_volume(data, locations, coordinate_order)\n\n  elif method == 'TRILINEAR':\n    # Calculate the floor and ceil coordinates for trilinear interpolation\n    floor_locations = jnp.floor(locations).astype(jnp.int32)\n    ceil_locations = jnp.ceil(locations).astype(jnp.int32)\n\n    # Calculate the fractional part for trilinear interpolation\n    fractional_part = locations - floor_locations\n\n    # Clamp the floor and ceil locations if edge_behavior is set to 'CLAMP'\n    if edge_behavior == 'CLAMP':\n      floor_locations = jnp.clip(floor_locations, 0, jnp.array(data.shape[:3]) - 1)\n      ceil_locations = jnp.clip(ceil_locations, 0, jnp.array(data.shape[:3]) - 1)\n\n    # Gather the 8 corner values for trilinear interpolation\n    c000 = gather_volume(data, floor_locations, coordinate_order)\n    c001 = gather_volume(data, jnp.stack([floor_locations[..., 0], floor_locations[..., 1], ceil_locations[..., 2]], axis=-1), coordinate_order)\n    c010 = gather_volume(data, jnp.stack([floor_locations[..., 0], ceil_locations[..., 1], floor_locations[..., 2]], axis=-1), coordinate_order)\n    c011 = gather_volume(data, jnp.stack([floor_locations[..., 0], ceil_locations[..., 1], ceil_locations[..., 2]], axis=-1), coordinate_order)\n    c100 = gather_volume(data, jnp.stack([ceil_locations[..., 0], floor_locations[..., 1], floor_locations[..., 2]], axis=-1), coordinate_order)\n    c101 = gather_volume(data, jnp.stack([ceil_locations[..., 0], floor_locations[..., 1], ceil_locations[..., 2]], axis=-1), coordinate_order)\n    c110 = gather_volume(data, jnp.stack([ceil_locations[..., 0], ceil_locations[..., 1], floor_locations[..., 2]], axis=-1), coordinate_order)\n    c111 = gather_volume(data, ceil_locations, coordinate_order)\n\n    # Perform trilinear interpolation\n    resampled_data = (\n        (1 - fractional_part[..., 0]) * (1 - fractional_part[..., 1]) * (1 - fractional_part[..., 2]) * c000 +\n        (1 - fractional_part[..., 0]) * (1 - fractional_part[..., 1]) * fractional_part[..., 2] * c001 +\n        (1 - fractional_part[..., 0]) * fractional_part[..., 1] * (1 - fractional_part[..., 2]) * c010 +\n        (1 - fractional_part[..., 0]) * fractional_part[..., 1] * fractional_part[..., 2] * c011 +\n        fractional_part[..., 0] * (1 - fractional_part[..., 1]) * (1 - fractional_part[..., 2]) * c100 +\n        fractional_part[..., 0] * (1 - fractional_part[..., 1]) * fractional_part[..., 2] * c101 +\n        fractional_part[..., 0] * fractional_part[..., 1] * (1 - fractional_part[..., 2]) * c110 +\n        fractional_part[..., 0] * fractional_part[..., 1] * fractional_part[..., 2] * c111\n    )\n\n  return resampled_data"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'NEAREST':\n    # Round the locations to the nearest integer\n    rounded_locations = jnp.round(locations).astype(jnp.int32)\n    # Gather the data at the rounded locations\n    resampled_data = gather_volume(data, rounded_locations, coordinate_order)\n  elif method == 'TRILINEAR':\n    # If half-pixel centering is used, adjust the locations\n    if half_pixel_center:\n      locations -= 0.5\n    # Extract the integer and fractional parts of the locations\n    int_locations = jnp.floor(locations).astype(jnp.int32)\n    fractional = locations - int_locations\n    # Handle edge behavior based on the specified method\n    if edge_behavior == 'CONSTANT_OUTSIDE':\n      # Pad the input data with constant values\n      padded_data = jnp.pad(data, 1, constant_values=constant_values)\n      # Gather the data at the integer locations\n      gathered_data = gather_volume(padded_data, int_locations, coordinate_order)\n    elif edge_behavior == 'CLAMP':\n      # Clamp the integer locations to the valid range\n      clamped_locations = jnp.clip(int_locations, 0, jnp.array(data.shape) - 1)\n      # Gather the data at the clamped locations\n      gathered_data = gather_volume(data, clamped_locations, coordinate_order)\n    else:\n      raise ValueError(\"Invalid edge_behavior. Must be 'CONSTANT_OUTSIDE' or 'CLAMP'.\")\n    # Calculate the trilinear interpolation weights\n    w000 = (1 - fractional[..., 0]) * (1 - fractional[..., 1]) * (1 - fractional[..., 2])\n    w001 = (1 - fractional[..., 0]) * (1 - fractional[..., 1]) * fractional[..., 2]\n    w010 = (1 - fractional[..., 0]) * fractional[..., 1] * (1 - fractional[..., 2])\n    w011 = (1 - fractional[..., 0]) * fractional[..., 1] * fractional[..., 2]\n    w100 = fractional[..., 0] * (1 - fractional[..., 1]) * (1 - fractional[..., 2])\n    w101 = fractional[..., 0] * (1 - fractional[..., 1]) * fractional[..., 2]\n    w110 = fractional[..., 0] * fractional[..., 1] * (1 - fractional[..., 2])\n    w111 = fractional[..., 0] * fractional[..., 1] * fractional[..., 2]\n    # Perform trilinear interpolation\n    resampled_data = (\n        w000 * gathered_data[Ellipsis, 0] + w001 * gathered_data[Ellipsis, 1] +\n        w010 * gathered_data[Ellipsis, 2] + w011 * gathered_data[Ellipsis, 3] +\n        w100 * gathered_data[Ellipsis, 4] + w101 * gathered_data[Ellipsis, 5] +\n        w110 * gathered_data[Ellipsis, 6] + w111 * gathered_data[Ellipsis, 7])\n  else:\n    raise ValueError(\"Invalid method. Must be 'TRILINEAR' or 'NEAREST'.\")\n\n  return resampled_data"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'NEAREST':\n    # Round the locations to the nearest integer\n    locations = jnp.round(locations).astype(jnp.int32)\n    # Gather the data at the rounded locations\n    resampled_data = gather_volume(data, locations, coordinate_order)\n  elif method == 'TRILINEAR':\n    if half_pixel_center:\n      # Adjust the locations for half-pixel centering\n      locations -= 0.5\n    # Get the floor and ceil coordinates for trilinear interpolation\n    floor_locations = jnp.floor(locations).astype(jnp.int32)\n    ceil_locations = jnp.ceil(locations).astype(jnp.int32)\n    # Calculate the alpha, beta, and gamma values for trilinear interpolation\n    alpha = locations - floor_locations\n    beta = locations - ceil_locations\n    gamma = 1 - alpha\n    delta = 1 - beta\n    # Gather the data at the floor and ceil coordinates\n    data_floor = gather_volume(data, floor_locations, coordinate_order)\n    data_ceil = gather_volume(data, ceil_locations, coordinate_order)\n    # Perform trilinear interpolation\n    resampled_data = (\n        gamma * delta * data_floor +\n        gamma * beta * data_ceil +\n        alpha * delta * data_floor +\n        alpha * beta * data_ceil\n    )\n  else:\n    raise ValueError(\"Invalid method. Method must be 'NEAREST' or 'TRILINEAR'.\")\n  \n  if edge_behavior == 'CONSTANT_OUTSIDE':\n    # Mask the locations outside the input volume\n    mask = jnp.all((locations >= 0) & (locations < jnp.array(data.shape)[:-1]), axis=-1, keepdims=True)\n    # Apply constant values to the masked locations\n    resampled_data = jnp.where(mask, resampled_data, constant_values)\n  elif edge_behavior == 'CLAMP':\n    # Clamp the locations to the input volume boundaries\n    locations = jnp.clip(locations, 0, jnp.array(data.shape)[:-1] - 1)\n    # Gather the data at the clamped locations\n    resampled_data = gather_volume(data, locations, coordinate_order)\n  else:\n    raise ValueError(\"Invalid edge_behavior. Edge behavior must be 'CONSTANT_OUTSIDE' or 'CLAMP'.\")\n  \n  return resampled_data"}
{"namespace": "resample.resample_3d", "completion": "  if method == 'NEAREST':\n    # Round the locations to the nearest integer\n    locations = jnp.round(locations).astype(jnp.int32)\n    # Gather the data at the rounded locations\n    resampled_data = gather_volume(data, locations, coordinate_order)\n  elif method == 'TRILINEAR':\n    # If half-pixel centering is used, adjust the locations\n    if half_pixel_center:\n      locations -= 0.5\n    # Extract the integer and fractional parts of the locations\n    int_locations = jnp.floor(locations).astype(jnp.int32)\n    frac_locations = locations - int_locations\n    # Handle edge behavior based on the specified method\n    if edge_behavior == 'CONSTANT_OUTSIDE':\n      # Pad the input volume with constant values\n      padded_data = jnp.pad(data, 1, constant_values=constant_values)\n      # Gather the data at the integer locations\n      gathered_data = gather_volume(padded_data, int_locations, coordinate_order)\n    elif edge_behavior == 'CLAMP':\n      # Clamp the integer locations to the valid range\n      int_locations = jnp.clip(int_locations, 0, jnp.array(data.shape) - 1)\n      # Gather the data at the clamped integer locations\n      gathered_data = gather_volume(data, int_locations, coordinate_order)\n    else:\n      raise ValueError(\"Unsupported edge_behavior: {}\".format(edge_behavior))\n    # Calculate the trilinear interpolation weights\n    weights = jnp.prod(1 - frac_locations, axis=-1, keepdims=True)\n    # Interpolate along the x-axis\n    interp_x0 = gathered_data\n    interp_x1 = jnp.roll(gathered_data, shift=-1, axis=-1)\n    interp_x = interp_x0 * (1 - frac_locations[Ellipsis, 0:1]) + interp_x1 * frac_locations[Ellipsis, 0:1]\n    # Interpolate along the y-axis\n    interp_y0 = interp_x\n    interp_y1 = jnp.roll(interp_x, shift=-1, axis=-2)\n    interp_y = interp_y0 * (1 - frac_locations[Ellipsis, 1:2]) + interp_y1 * frac_locations[Ellipsis, 1:2]\n    # Interpolate along the z-axis\n    interp_z0 = interp_y\n    interp_z1 = jnp.roll(interp_y, shift=-1, axis=-3)\n    interp_z = interp_z0 * (1 - frac_locations[Ellipsis, 2:3]) + interp_z1 * frac_locations[Ellipsis, 2:3]\n    # Assign the interpolated values to the output\n    resampled_data = interp_z\n  else:\n    raise ValueError(\"Unsupported method: {}\".format(method))\n\n  return resampled_data"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)"}
{"namespace": "linspline.integrate", "completion": "  check_zero_endpoints(w)\n  return jnp.trapz(w, t)"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, x=t)"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  check_zero_endpoints(w)\n  return jnp.trapz(w, x=t)"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)"}
{"namespace": "linspline.integrate", "completion": "  check_zero_endpoints(w)\n  return jnp.trapz(w, t)"}
{"namespace": "linspline.integrate", "completion": "  check_zero_endpoints(w)\n  return jnp.trapz(w, t)"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, x=t)"}
{"namespace": "linspline.integrate", "completion": "  check_zero_endpoints(w)\n  return jnp.trapz(w, t)"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)"}
{"namespace": "linspline.integrate", "completion": "  check_zero_endpoints(w)\n  return jnp.trapz(w, t)"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)"}
{"namespace": "linspline.query", "completion": "  check_zero_endpoints(v)\n  spline_fn = functools.partial(jnp.interp, xp=t, fp=v, left=0.0, right=0.0)\n  return spline_fn(tq)"}
{"namespace": "linspline.query", "completion": "  check_zero_endpoints(v)\n  spline_fn = functools.partial(math.linear_interpolation, x=t, y=v)\n  return jnp.where((tq >= t[0]) & (tq <= t[-1]), spline_fn(tq), 0)"}
{"namespace": "linspline.query", "completion": "  check_zero_endpoints(v)\n  spline_fn = functools.partial(math.linear_interp, t=t, y=v)\n  return jnp.where((tq < t[0]) | (tq > t[-1]), 0, spline_fn(tq))"}
{"namespace": "linspline.query", "completion": "  check_zero_endpoints(v)\n\n  # Ensure t and v are sorted\n  sort_indices = jnp.argsort(t)\n  t = t[sort_indices]\n  v = v[sort_indices]\n\n  # Interpolate the values at the query points\n  interpolated_values = jnp.interp(tq, t, v, period=None, extrapolation='constant', left=0.0, right=0.0)\n\n  return interpolated_values"}
{"namespace": "linspline.query", "completion": "  check_zero_endpoints(v)\n  spline_fn = functools.partial(math.linear_spline, t=t, y=v)\n  return jax.vmap(lambda t: spline_fn(t, extrapolate=True))(tq)"}
{"namespace": "linspline.query", "completion": "  check_zero_endpoints(v)\n  spline_fn = functools.partial(math.linear_interp, t=t, y=v)\n  return jnp.where((tq >= t[0]) & (tq <= t[-1]), spline_fn(tq), 0)"}
{"namespace": "linspline.query", "completion": "  check_zero_endpoints(v)\n  spline_fn = functools.partial(math.linear_spline, t=t, v=v)\n  return jnp.where((tq >= t[0]) & (tq <= t[-1]), spline_fn(tq), 0)"}
{"namespace": "linspline.query", "completion": "  check_zero_endpoints(v)\n  spline_fn = functools.partial(math.linear_spline, t=t, v=v)\n  return jnp.where((tq >= t[0]) & (tq <= t[-1]), spline_fn(tq), 0)"}
{"namespace": "linspline.query", "completion": "  check_zero_endpoints(v)\n\n  # Ensure t and v are sorted by time\n  sort_indices = jnp.argsort(t)\n  t = t[sort_indices]\n  v = v[sort_indices]\n\n  # Interpolate the values at the query points\n  return jnp.interp(tq, t, v, period=None, extrapolation='constant', left=0.0, right=0.0)"}
{"namespace": "linspline.query", "completion": "  check_zero_endpoints(v)\n  spline_fn = functools.partial(utils.linear_spline, t, v)\n  return jnp.where((tq >= t[0]) & (tq <= t[-1]), spline_fn(tq), 0)"}
{"namespace": "linspline.query", "completion": "  check_zero_endpoints(v)\n  spline_fn = functools.partial(utils.linear_spline, t, v)\n  return jnp.where((tq < t[0]) | (tq > t[-1]), 0, spline_fn(tq))"}
{"namespace": "linspline.query", "completion": "  check_zero_endpoints(v)\n  spline_fn = functools.partial(math.linear_spline, t=t, v=v)\n  return jnp.where((tq >= t[0]) & (tq <= t[-1]), spline_fn(tq), 0)"}
{"namespace": "linspline.query", "completion": "  check_zero_endpoints(v)\n  spline_fn = functools.partial(math.linear_spline, t=t, v=v)\n  return jnp.where((tq >= t[0]) & (tq <= t[-1]), spline_fn(tq), 0)"}
{"namespace": "linspline.query", "completion": "  check_zero_endpoints(v)\n  spline_fn = functools.partial(utils.linear_interp, t=t, y=v)\n  return jnp.where((tq >= t[0]) & (tq <= t[-1]), spline_fn(tq), 0)"}
{"namespace": "linspline.query", "completion": "  check_zero_endpoints(v)\n  spline_fn = functools.partial(math.linear_interpolation, t=t, v=v)\n  return jnp.where((tq >= t[0]) & (tq <= t[-1]), spline_fn(tq), 0)"}
{"namespace": "linspline.query", "completion": "  check_zero_endpoints(v)\n  spline_fn = functools.partial(utils.linear_interpolation, t=t, v=v)\n  return jnp.where((tq >= t[0]) & (tq <= t[-1]), spline_fn(tq), 0)"}
{"namespace": "linspline.query", "completion": "  check_zero_endpoints(v)\n  spline_fn = functools.partial(math.linear_interp, t=t, y=v)\n  return jnp.where((tq >= t[0]) & (tq <= t[-1]), spline_fn(tq), 0)"}
{"namespace": "linspline.query", "completion": "  check_zero_endpoints(v)\n\n  # Ensure t and v have the same shape\n  t, v = jnp.broadcast_arrays(t, v)\n\n  # Ensure t is sorted\n  order = jnp.argsort(t)\n  t = t[order]\n  v = v[order]\n\n  # Interpolate the values at the query points\n  return jnp.interp(tq, t, v, period=None, extrapolate=True)"}
{"namespace": "linspline.query", "completion": "  check_zero_endpoints(v)\n  spline = jax.scipy.interpolate.interp1d(t, v, kind='linear', fill_value=\"extrapolate\")\n  return spline(tq)"}
{"namespace": "linspline.query", "completion": "  check_zero_endpoints(v)\n  spline_fn = functools.partial(jnp.interp, xp=t, fp=v, left=0.0, right=0.0)\n  return spline_fn(tq)"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-6  # Small epsilon to account for numerical precision issues\n  normalized_dir1 = spin_math.normalize(dir1)  # Normalize the direction vector of the first line\n  normalized_dir2 = spin_math.normalize(dir2)  # Normalize the direction vector of the second line\n  dot_product = jnp.dot(normalized_dir1, normalized_dir2)  # Calculate the dot product of the normalized direction vectors\n  return jnp.abs(dot_product - 1) < epsilon  # Check if the absolute difference between the dot product and 1 is less than epsilon to determine if the lines are parallel"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-6  # Small epsilon to account for numerical precision\n  dir1 = spin_math.normalize(dir1)  # Normalize the direction vector of the first line\n  dir2 = spin_math.normalize(dir2)  # Normalize the direction vector of the second line\n  dot_product = jnp.dot(dir1, dir2)  # Calculate the dot product of the normalized direction vectors\n  return jnp.abs(dot_product - 1) < epsilon  # Return True if the absolute difference between the dot product and 1 is less than epsilon, indicating parallel lines"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-6  # Small epsilon to account for numerical precision\n\n  # Normalize the direction vectors\n  dir1_normalized = spin_math.normalize(dir1)\n  dir2_normalized = spin_math.normalize(dir2)\n\n  # Compute the dot product of the normalized direction vectors\n  dot_product = jnp.dot(dir1_normalized, dir2_normalized)\n\n  # Check if the dot product is close to 1 or -1, indicating parallel lines\n  is_parallel = jnp.abs(dot_product - 1) < epsilon or jnp.abs(dot_product + 1) < epsilon\n\n  return is_parallel"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-6  # Small epsilon to account for numerical precision issues\n  dir1 = spin_math.normalize(dir1)  # Normalize the direction vector of the first line\n  dir2 = spin_math.normalize(dir2)  # Normalize the direction vector of the second line\n  dot_product = jnp.dot(dir1, dir2)  # Calculate the dot product of the normalized direction vectors\n  return jnp.abs(dot_product - 1) < epsilon  # Return True if the dot product is close to 1 (considering numerical precision), indicating parallel lines, otherwise False"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-6  # Small value to account for numerical precision\n  normalized_dir1 = spin_math.normalize(dir1)  # Normalize the direction vector of the first line\n  normalized_dir2 = spin_math.normalize(dir2)  # Normalize the direction vector of the second line\n  dot_product = jnp.dot(normalized_dir1, normalized_dir2)  # Compute the dot product of the normalized direction vectors\n  return jnp.abs(1 - dot_product) < epsilon  # Check if the absolute difference from 1 is less than epsilon to determine parallelism"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-6  # Small epsilon to account for numerical precision issues\n  normalized_dir1 = spin_math.normalize(dir1)  # Normalize the direction vector of the first line\n  normalized_dir2 = spin_math.normalize(dir2)  # Normalize the direction vector of the second line\n  dot_product = jnp.dot(normalized_dir1, normalized_dir2)  # Calculate the dot product of the normalized direction vectors\n  return jnp.abs(dot_product - 1) < epsilon  # Check if the absolute difference from 1 is less than epsilon to determine parallelism"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-6  # Small epsilon to account for numerical precision\n  dir1_normalized = spin_math.normalize(dir1)  # Normalize the direction vector of the first line\n  dir2_normalized = spin_math.normalize(dir2)  # Normalize the direction vector of the second line\n  dot_product = jnp.dot(dir1_normalized, dir2_normalized)  # Compute the dot product of the normalized direction vectors\n  return jnp.abs(dot_product - 1) < epsilon  # Check if the absolute difference between the dot product and 1 is less than epsilon"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-6  # Small epsilon to account for numerical precision\n  normalized_dir1 = spin_math.normalize(dir1)  # Normalize the direction vector of the first line\n  normalized_dir2 = spin_math.normalize(dir2)  # Normalize the direction vector of the second line\n  dot_product = jnp.dot(normalized_dir1, normalized_dir2)  # Calculate the dot product of the normalized direction vectors\n  return jnp.abs(dot_product - 1) < epsilon  # Check if the absolute difference between the dot product and 1 is less than epsilon"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-8  # Small epsilon to account for numerical precision\n  dir1_normalized = spin_math.normalize(dir1)  # Normalize the direction vector of the first line\n  dir2_normalized = spin_math.normalize(dir2)  # Normalize the direction vector of the second line\n  dot_product = jnp.dot(dir1_normalized, dir2_normalized)  # Calculate the dot product of the normalized direction vectors\n  return jnp.abs(dot_product - 1) < epsilon  # Return True if the absolute difference between the dot product and 1 is less than epsilon, indicating parallel lines"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-6  # small epsilon to account for numerical precision\n  dir1_normalized = spin_math.normalize(dir1)  # normalize the direction vector of the first line\n  dir2_normalized = spin_math.normalize(dir2)  # normalize the direction vector of the second line\n  dot_product = jnp.dot(dir1_normalized, dir2_normalized)  # compute the dot product of the normalized direction vectors\n  return jnp.abs(dot_product - 1) < epsilon  # return True if the absolute difference is less than epsilon, indicating parallel lines"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-6  # Small epsilon to account for numerical precision issues\n  normalized_dir1 = spin_math.normalize(dir1)  # Normalize the direction vector of the first line\n  normalized_dir2 = spin_math.normalize(dir2)  # Normalize the direction vector of the second line\n  dot_product = jnp.dot(normalized_dir1, normalized_dir2)  # Calculate the dot product of the normalized direction vectors\n  return jnp.abs(dot_product - 1) < epsilon  # Check if the absolute difference between the dot product and 1 is less than epsilon"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-6  # Small epsilon to account for numerical precision\n  dir1_normalized = spin_math.normalize(dir1)  # Normalize the direction vector of the first line\n  dir2_normalized = spin_math.normalize(dir2)  # Normalize the direction vector of the second line\n  dot_product = jnp.dot(dir1_normalized, dir2_normalized)  # Compute the dot product of the normalized direction vectors\n  return jnp.abs(dot_product - 1) < epsilon  # Return True if the absolute difference between the dot product and 1 is less than epsilon, indicating parallel lines"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-8  # Small epsilon to account for numerical precision\n  dir1_normalized = spin_math.normalize(dir1)  # Normalize the direction vector of the first line\n  dir2_normalized = spin_math.normalize(dir2)  # Normalize the direction vector of the second line\n  dot_product = jnp.dot(dir1_normalized, dir2_normalized)  # Compute the dot product of the normalized direction vectors\n  return jnp.abs(dot_product - 1) < epsilon  # Check if the absolute difference from 1 is less than epsilon to determine parallelism"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-6  # Small epsilon to account for numerical precision\n  dir1_normalized = spin_math.normalize(dir1)  # Normalize the direction vector of the first line\n  dir2_normalized = spin_math.normalize(dir2)  # Normalize the direction vector of the second line\n  dot_product = jnp.dot(dir1_normalized, dir2_normalized)  # Compute the dot product of the normalized direction vectors\n  return jnp.abs(dot_product - 1) < epsilon  # Check if the absolute difference from 1 is less than epsilon to determine if the lines are parallel"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-6  # Small epsilon to account for numerical precision\n  dir1_normalized = spin_math.normalize(dir1)  # Normalize the direction vector of the first line\n  dir2_normalized = spin_math.normalize(dir2)  # Normalize the direction vector of the second line\n  dot_product = jnp.dot(dir1_normalized, dir2_normalized)  # Compute the dot product of the normalized direction vectors\n  return jnp.abs(dot_product - 1) < epsilon  # Check if the absolute difference from 1 is less than epsilon to determine if the lines are parallel"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-6  # Small value to account for numerical precision\n  normalized_dir1 = spin_math.normalize(dir1)  # Normalize the direction vector of the first line\n  normalized_dir2 = spin_math.normalize(dir2)  # Normalize the direction vector of the second line\n  dot_product = jnp.dot(normalized_dir1, normalized_dir2)  # Compute the dot product of the normalized direction vectors\n  return jnp.abs(dot_product - 1) < epsilon  # Check if the absolute difference between the dot product and 1 is less than epsilon"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-6  # Small epsilon to account for numerical precision\n  dir1 = spin_math.normalize(dir1)  # Normalize the direction vector of the first line\n  dir2 = spin_math.normalize(dir2)  # Normalize the direction vector of the second line\n  dot_product = jnp.dot(dir1, dir2)  # Calculate the dot product of the normalized direction vectors\n  return jnp.abs(dot_product - 1) < epsilon  # Check if the absolute difference between the dot product and 1 is less than epsilon"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-8  # Small epsilon to account for numerical precision issues\n  normalized_dir1 = spin_math.normalize(dir1)  # Normalize the direction vector of the first line\n  normalized_dir2 = spin_math.normalize(dir2)  # Normalize the direction vector of the second line\n  dot_product = jnp.dot(normalized_dir1, normalized_dir2)  # Calculate the dot product of the normalized direction vectors\n  return jnp.abs(dot_product - 1) < epsilon  # Check if the absolute difference between the dot product and 1 is less than epsilon"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-6  # Small value to account for numerical precision\n  dir1_normalized = spin_math.normalize(dir1)  # Normalize the direction vector of the first line\n  dir2_normalized = spin_math.normalize(dir2)  # Normalize the direction vector of the second line\n  dot_product = jnp.dot(dir1_normalized, dir2_normalized)  # Compute the dot product of the normalized direction vectors\n  return jnp.abs(dot_product - 1) < epsilon  # Return True if the absolute difference between the dot product and 1 is less than epsilon, indicating parallel lines"}
{"namespace": "geometry.are_lines_parallel", "completion": "  epsilon = 1e-8  # Small epsilon to account for numerical precision\n  dir1_normalized = dir1 / jnp.linalg.norm(dir1)  # Normalize the direction vector of the first line\n  dir2_normalized = dir2 / jnp.linalg.norm(dir2)  # Normalize the direction vector of the second line\n  dot_product = jnp.dot(dir1_normalized, dir2_normalized)  # Compute the dot product of the normalized direction vectors\n  return jnp.abs(dot_product - 1) < epsilon  # Check if the absolute difference between the dot product and 1 is less than epsilon"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.array([x, y, z])"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.array([x, y, z])"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.array([x, y, z])"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.array([x, y, z])"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.array([x, y, z])"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.array([x, y, z])"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.array([x, y, z])"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.array([x, y, z])"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.array([x, y, z])"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.array([x, y, z])"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.array([x, y, z])"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.array([x, y, z])"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.array([x, y, z])"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.array([x, y, z])"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.array([x, y, z])"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.array([x, y, z])"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.array([x, y, z])"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.array([x, y, z])"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.array([x, y, z])"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.array([x, y, z])"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Generate all possible combinations of integer weights that sum to v\n  weights = np.array(list(itertools.product(range(v + 1), repeat=2)))\n  weights = weights[weights.sum(axis=1) <= v]\n\n  # Normalize the weights to get the barycentric coordinates\n  weights = weights / v\n\n  return weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Define the vertices of the original triangle\n  vertices = np.array([[0, 0], [1, 0], [0.5, np.sqrt(3)/2]])\n\n  # Generate all possible combinations of weights for the tessellation factor\n  weights = np.array(list(itertools.product(range(v + 1), repeat=2)))\n  weights = weights[weights.sum(axis=1) <= v]  # Keep only combinations that sum to v or less\n\n  # Normalize the weights to get the barycentric coordinates\n  normalized_weights = weights / v\n\n  return normalized_weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Generate all possible combinations of integer weights that sum to v\n  weights = np.array(list(itertools.product(range(v + 1), repeat=2)))\n  weights = weights[weights.sum(axis=1) <= v]\n\n  # Normalize the weights to get the barycentric coordinates\n  normalized_weights = weights / v\n\n  return normalized_weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Get the vertices of the triangle\n  vertices = np.array([[0, 0], [1, 0], [0.5, np.sqrt(3)/2]])\n\n  # Generate all possible combinations of integer weights that sum to v\n  weights = np.array(list(itertools.product(range(v+1), repeat=2)))\n  weights = weights[weights.sum(axis=1) <= v]\n\n  # Normalize the weights to get the barycentric coordinates\n  barycentric_weights = weights / v\n\n  return barycentric_weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Generate all possible combinations of weights that sum to v\n  weights = np.array(list(itertools.product(range(v + 1), repeat=2)))\n  weights = weights[weights.sum(axis=1) <= v]\n\n  # Add the third weight to sum to v\n  weights = np.concatenate((weights, np.array([[v - x - y, x, y] for x, y in weights])), axis=0)\n\n  # Normalize the weights to get the barycentric coordinates\n  weights = weights / v\n\n  return weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Generate all possible combinations of integer weights that sum to v\n  weights = np.array(list(itertools.product(range(v + 1), repeat=2)))\n  weights = weights[weights.sum(axis=1) <= v]\n\n  # Normalize the weights to get the barycentric coordinates\n  weights = weights / v\n\n  return weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Generate all possible combinations of integers i, j, k such that i + j + k = v and 0 <= i, j, k <= v.\n  weights = np.array(list(itertools.product(range(v + 1), repeat=2)))\n  weights = np.concatenate((weights, v - weights.sum(axis=1)[:, None]), axis=1)\n  \n  # Normalize the weights to get the barycentric coordinates.\n  weights = weights / v\n  \n  return weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Define the vertices of the original triangle\n  vertices = np.array([[0, 0],\n                       [1, 0],\n                       [0.5, np.sqrt(3)/2]])\n\n  # Generate all possible combinations of integers that sum to v\n  weights = np.array(list(itertools.product(range(v+1), repeat=2)))\n  weights = weights[weights.sum(axis=1) <= v]  # Keep only combinations that sum to v or less\n\n  # Normalize the weights to get the barycentric coordinates\n  weights = weights / v\n\n  return weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Define the vertices of the triangle\n  vertices = np.array([[0, 0], [1, 0], [0.5, np.sqrt(3)/2]])\n\n  # Generate all possible combinations of weights for tessellating the triangle\n  weights = np.array([[i, j, v - i - j] for i, j in itertools.product(range(v+1), repeat=2) if i + j <= v])\n\n  # Normalize the weights to get the barycentric coordinates\n  barycentric_weights = weights / v\n\n  return barycentric_weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Generate all possible combinations of weights for the tessellation factor\n  weights = np.array(list(itertools.product(range(v + 1), repeat=2)))\n  weights = weights[weights.sum(axis=1) <= v]  # Keep only the weights that sum to v or less\n\n  # Normalize the weights to get the barycentric coordinates\n  weights = weights / v\n  return weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Generate all possible integer weights for the tessellation factor\n  weights = np.array([[i, j, v - i - j] for i, j in itertools.product(range(v + 1), repeat=2) if i + j <= v])\n\n  # Normalize the weights to get the barycentric coordinates\n  weights = weights / v\n\n  return weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Generate all possible combinations of integer weights for the vertices of the triangle\n  weights = np.array([[i, j, v - i - j] for i, j in itertools.product(range(v + 1), repeat=2) if i + j <= v])\n\n  # Normalize the weights to get the barycentric coordinates\n  weights = weights / v\n\n  return weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Define the vertices of the triangle\n  vertices = np.array([[0, 0], [1, 0], [0.5, np.sqrt(3) / 2]])\n\n  # Generate all possible combinations of weights for the vertices\n  weights = np.array(list(itertools.product(range(v + 1), repeat=2)))\n  weights = weights[weights.sum(axis=1) <= v]  # Keep only the combinations that sum to v or less\n\n  # Normalize the weights to get the barycentric coordinates\n  barycentric_weights = weights / v\n\n  return barycentric_weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Generate all possible combinations of integer weights that sum to v\n  weights = np.array(list(itertools.product(range(v + 1), repeat=2)))\n  weights = weights[weights.sum(axis=1) <= v]\n  \n  # Normalize the weights to get the barycentric coordinates\n  barycentric_weights = weights / v\n  \n  return barycentric_weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Generate all possible combinations of integer weights that sum to the tessellation factor\n  weights = np.array([[i, j, v - i - j] for i, j in itertools.product(range(v + 1), repeat=2) if i + j <= v])\n\n  # Normalize the weights to get the barycentric coordinates\n  weights = weights / v\n\n  return weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if v < 1:\n    raise ValueError(\"Tessellation factor must be greater than or equal to 1\")\n\n  # Generate all possible integer combinations of weights that sum to v\n  weights = np.array(list(itertools.product(range(v + 1), repeat=2)))\n  weights = weights[weights.sum(axis=1) <= v]  # Filter out combinations that sum to more than v\n\n  # Normalize the weights to get the barycentric coordinates\n  barycentric_weights = weights / v\n\n  return barycentric_weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Generate integer weights for each vertex of the triangle.\n  weights = np.array([[i, j, v - i - j] for i, j in itertools.product(range(v + 1), repeat=2) if i + j <= v])\n\n  # Normalize the weights to get the barycentric coordinates.\n  weights = weights / v\n\n  return weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Generate all possible combinations of integer weights that sum to v\n  weights = np.array(list(itertools.product(range(v + 1), repeat=2)))\n  weights = weights[weights.sum(axis=1) <= v]\n\n  # Normalize the weights to get the barycentric coordinates\n  bary_weights = weights / v\n\n  return bary_weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Generate all possible integer weights for the tessellation factor v\n  weights = np.array([[i, j, v - i - j] for i, j in itertools.product(range(v + 1), repeat=2) if i + j <= v])\n\n  # Normalize the weights to get the barycentric coordinates\n  weights = weights / v\n\n  return weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Generate all possible combinations of weights for the vertices of the triangle\n  weights = np.array(list(itertools.product(range(v+1), repeat=2)))\n  weights = weights[weights.sum(axis=1) <= v]  # Keep only the combinations that sum to v or less\n\n  # Normalize the weights to get the barycentric coordinates\n  weights = weights / v\n\n  return weights"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = jnp.split(cartesian_vector, 3, axis=-1)\n\n  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  r = jnp.where(r < eps, eps, r)\n\n  theta = jnp.arccos(z / r)\n  phi = jnp.arctan2(y, x)\n\n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = jnp.split(cartesian_vector, 3, axis=-1)\n\n  r = jnp.sqrt(x**2 + y**2 + z**2)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n\n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = jnp.split(cartesian_vector, 3, axis=-1)\n  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  r = jnp.where(r < eps, eps, r)  # Prevent division by zero\n  theta = jnp.arccos(z / r)\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = jnp.split(cartesian_vector, 3, axis=-1)\n  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = jnp.split(cartesian_vector, 3, axis=-1)\n\n  r = jnp.sqrt(x**2 + y**2 + z**2)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n\n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = jnp.split(cartesian_vector, 3, axis=-1)\n  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = jnp.split(cartesian_vector, 3, axis=-1)\n  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = jnp.split(cartesian_vector, 3, axis=-1)\n  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = jnp.split(cartesian_vector, 3, axis=-1)\n  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = jnp.split(cartesian_vector, 3, axis=-1)\n  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  \n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = jnp.split(cartesian_vector, 3, axis=-1)\n  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = jnp.split(cartesian_vector, 3, axis=-1)\n  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = jnp.split(cartesian_vector, 3, axis=-1)\n  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = jnp.split(cartesian_vector, 3, axis=-1)\n  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = jnp.split(cartesian_vector, 3, axis=-1)\n  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = jnp.split(cartesian_vector, 3, axis=-1)\n  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n  r = jnp.linalg.norm(cartesian_vector, axis=-1)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = jnp.split(cartesian_vector, 3, axis=-1)\n  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = jnp.split(cartesian_vector, 3, axis=-1)\n  r = jnp.sqrt(x**2 + y**2 + z**2)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = jnp.split(cartesian_vector, 3, axis=-1)\n  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  norms_mat0 = np.sum(mat0**2, axis=0, keepdims=True)\n  norms_mat1 = np.sum(mat1**2, axis=0, keepdims=True)\n  sq_dist = norms_mat0.T + norms_mat1 - 2 * np.dot(mat0.T, mat1)\n  sq_dist[sq_dist < 0] = 0\n  return sq_dist"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  norms_mat0 = np.sum(mat0 ** 2, axis=0, keepdims=True)\n  norms_mat1 = np.sum(mat1 ** 2, axis=0, keepdims=True)\n  dot_product = np.dot(mat0.T, mat1)\n  sq_dist = np.maximum(norms_mat0.T + norms_mat1 - 2 * dot_product, 0)\n  return sq_dist"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  norms_mat0 = np.sum(mat0**2, axis=0)\n  norms_mat1 = np.sum(mat1**2, axis=0)\n  dot_product = np.dot(mat0.T, mat1)\n  sq_dist = np.maximum(norms_mat0[:, np.newaxis] + norms_mat1 - 2 * dot_product, 0)\n  return sq_dist"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  norm_mat0 = np.sum(mat0 ** 2, axis=0, keepdims=True)\n  norm_mat1 = np.sum(mat1 ** 2, axis=0, keepdims=True)\n\n  sq_dist = norm_mat0.T + norm_mat1 - 2 * np.dot(mat0.T, mat1)\n\n  # Ensure compatibility with numerical errors\n  sq_dist[sq_dist < 0] = 0\n\n  return sq_dist"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  norm_mat0 = np.sum(mat0**2, axis=0, keepdims=True)\n  norm_mat1 = np.sum(mat1**2, axis=0, keepdims=True)\n\n  sq_dist = norm_mat0.T + norm_mat1 - 2 * np.dot(mat0.T, mat1)\n  sq_dist[sq_dist < 0] = 0\n\n  return sq_dist"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  norms_mat0 = np.sum(mat0**2, axis=0, keepdims=True)\n  norms_mat1 = np.sum(mat1**2, axis=0, keepdims=True)\n  sq_dist = norms_mat0.T + norms_mat1 - 2 * np.dot(mat0.T, mat1)\n  sq_dist[sq_dist < 0] = 0\n  return sq_dist"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  dot_product = np.dot(mat0.T, mat1)\n  norms_mat0 = np.sum(mat0 ** 2, axis=0, keepdims=True)\n  norms_mat1 = np.sum(mat1 ** 2, axis=0, keepdims=True)\n  sq_dist = norms_mat0.T + norms_mat1 - 2 * dot_product\n  sq_dist[sq_dist < 0] = 0\n  return sq_dist"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  norms_mat0 = np.sum(mat0**2, axis=0, keepdims=True)\n  norms_mat1 = np.sum(mat1**2, axis=0, keepdims=True)\n  dot_product = np.dot(mat0.T, mat1)\n  sq_dist = np.maximum(norms_mat0.T + norms_mat1 - 2 * dot_product, 0)\n  return sq_dist"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  sq_norm_mat0 = np.sum(mat0 ** 2, axis=0, keepdims=True)\n  sq_norm_mat1 = np.sum(mat1 ** 2, axis=0, keepdims=True)\n\n  sq_dist = np.maximum(sq_norm_mat0.T + sq_norm_mat1 - 2 * np.dot(mat0.T, mat1), 0)\n\n  return sq_dist"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  dot_product = np.dot(mat0.T, mat1)\n  norm_squared_mat0 = np.sum(mat0 ** 2, axis=0, keepdims=True)\n  norm_squared_mat1 = np.sum(mat1 ** 2, axis=0, keepdims=True)\n  sq_dist = norm_squared_mat0.T + norm_squared_mat1 - 2 * dot_product\n  sq_dist[sq_dist < 0] = 0\n  return sq_dist"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  norms_mat0 = np.sum(mat0**2, axis=0, keepdims=True)\n  norms_mat1 = np.sum(mat1**2, axis=0, keepdims=True)\n  sq_dist = norms_mat0.T + norms_mat1 - 2 * np.dot(mat0.T, mat1)\n  sq_dist[sq_dist < 0] = 0\n  return sq_dist"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  sq_norms0 = np.sum(mat0**2, axis=0, keepdims=True)\n  sq_norms1 = np.sum(mat1**2, axis=0, keepdims=True)\n  sq_dist = sq_norms0.T + sq_norms1 - 2 * np.dot(mat0.T, mat1)\n  sq_dist[sq_dist < 0] = 0\n  return sq_dist"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n      mat1 = mat0\n  sq_dist = np.square(np.linalg.norm(mat0[:, np.newaxis] - mat1, axis=2))\n  return np.maximum(sq_dist, 0)"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  norms_mat0 = np.sum(mat0 ** 2, axis=0, keepdims=True)\n  norms_mat1 = np.sum(mat1 ** 2, axis=0, keepdims=True)\n  dot_product = np.dot(mat0.T, mat1)\n  sq_dist = np.maximum(norms_mat0.T + norms_mat1 - 2 * dot_product, 0)\n  return sq_dist"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  norms_mat0 = np.sum(mat0 ** 2, axis=0)\n  norms_mat1 = np.sum(mat1 ** 2, axis=0)\n  dot_product = np.dot(mat0.T, mat1)\n  sq_dist = np.maximum(norms_mat0[:, np.newaxis] + norms_mat1 - 2 * dot_product, 0)\n  return sq_dist"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  norms_mat0 = np.sum(mat0 ** 2, axis=0, keepdims=True)\n  norms_mat1 = np.sum(mat1 ** 2, axis=0, keepdims=True)\n  dot_product = np.dot(mat0.T, mat1)\n  sq_dist = np.maximum(norms_mat0.T + norms_mat1 - 2 * dot_product, 0)\n  return sq_dist"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  dot_product = np.dot(mat0.T, mat1)\n  norm_squared_mat0 = np.sum(mat0 ** 2, axis=0, keepdims=True)\n  norm_squared_mat1 = np.sum(mat1 ** 2, axis=0, keepdims=True)\n\n  sq_dist = norm_squared_mat0.T + norm_squared_mat1 - 2 * dot_product\n  sq_dist[sq_dist < 0] = 0\n\n  return sq_dist"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  norms_mat0 = np.sum(mat0 ** 2, axis=0, keepdims=True)\n  norms_mat1 = np.sum(mat1 ** 2, axis=0, keepdims=True)\n  return np.maximum(norms_mat0.T + norms_mat1 - 2 * np.dot(mat0.T, mat1), 0)"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  sq_norm_mat0 = np.sum(mat0**2, axis=0, keepdims=True)\n  sq_norm_mat1 = np.sum(mat1**2, axis=0, keepdims=True)\n\n  sq_dist = sq_norm_mat0.T + sq_norm_mat1 - 2 * np.dot(mat0.T, mat1)\n\n  # Set negative distances to zero\n  sq_dist[sq_dist < 0] = 0\n\n  return sq_dist"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  sq_norm_mat0 = np.sum(mat0**2, axis=0, keepdims=True)\n  sq_norm_mat1 = np.sum(mat1**2, axis=0, keepdims=True)\n  sq_dist = sq_norm_mat0.T + sq_norm_mat1 - 2 * np.dot(mat0.T, mat1)\n  sq_dist[sq_dist < 0] = 0\n\n  return sq_dist"}
{"namespace": "math.plus_eps", "completion": "  return np.nextafter(x, np.inf) if x < tiny_val else x"}
{"namespace": "math.plus_eps", "completion": "  return jnp.maximum(tiny_val, jnp.nextafter(x, max_val))"}
{"namespace": "math.plus_eps", "completion": "  return jnp.maximum(x, tiny_val)"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(x < tiny_val, tiny_val, jnp.nextafter(x, max_val))"}
{"namespace": "math.plus_eps", "completion": "  return jnp.maximum(tiny_val, x)"}
{"namespace": "math.plus_eps", "completion": "  return jnp.maximum(tiny_val, x + np.nextafter(x, np.inf))"}
{"namespace": "math.plus_eps", "completion": "  return jnp.maximum(tiny_val, x)"}
{"namespace": "math.plus_eps", "completion": "  return jnp.maximum(tiny_val, x + np.nextafter(x, np.inf))"}
{"namespace": "math.plus_eps", "completion": "  return jnp.maximum(tiny_val, x + np.nextafter(x, max_val))"}
{"namespace": "math.plus_eps", "completion": "    return jnp.maximum(tiny_val, x)"}
{"namespace": "math.plus_eps", "completion": "  return jnp.maximum(tiny_val, x)"}
{"namespace": "math.plus_eps", "completion": "  if x < tiny_val:\n    return tiny_val\n  else:\n    return np.nextafter(x, np.inf)"}
{"namespace": "math.plus_eps", "completion": "  return jnp.maximum(tiny_val, x)"}
{"namespace": "math.plus_eps", "completion": "  return jnp.maximum(tiny_val, x)"}
{"namespace": "math.plus_eps", "completion": "  return jnp.maximum(tiny_val, x)"}
{"namespace": "math.plus_eps", "completion": "  return jnp.maximum(tiny_val, x)"}
{"namespace": "math.plus_eps", "completion": "    return jnp.maximum(x, tiny_val)"}
{"namespace": "math.plus_eps", "completion": "  return jnp.maximum(tiny_val, x)"}
{"namespace": "math.plus_eps", "completion": "  return jnp.maximum(tiny_val, x)"}
{"namespace": "math.plus_eps", "completion": "  return jnp.maximum(tiny_val, x)"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "\n  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "\n  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "\n  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "    return generate_safe_fn(\n        jnp.exp,\n        lambda x, y, x_dot: y * x_dot,\n        (min_val, max_val),\n    )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "\n  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        try:\n            if _TORCH_VISION_AVAILABLE:\n                tensor = decode_jpeg(data)\n                return tensor\n        except RuntimeError:\n            pass\n\n        if _PIL_AVAILABLE:\n            return PILSerializer.deserialize(data)\n\n        raise RuntimeError(\"Unable to deserialize the JPEG image data. PIL or torchvision is required.\")"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                tensor = decode_jpeg(data)\n                return tensor\n            except RuntimeError:\n                # If decoding as JPEG fails, fall back to using PIL to deserialize the data\n                pil_image = Image.open(io.BytesIO(data))\n                return pil_image\n        else:\n            # If torchvision is not available, use PIL to deserialize the data\n            pil_image = Image.open(io.BytesIO(data))\n            return pil_image"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                tensor = decode_jpeg(data)\n                return tensor\n            except RuntimeError:\n                # Fallback to using PIL to deserialize the data\n                return PILSerializer.deserialize(data)\n        else:\n            # If torchvision is not available, use PIL to deserialize the data\n            return PILSerializer.deserialize(data)"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        try:\n            if _TORCH_VISION_AVAILABLE:\n                # Try to decode using torchvision\n                tensor = decode_jpeg(data)\n                return pil_to_tensor(tensor) if isinstance(tensor, Image.Image) else tensor\n        except Exception as e:\n            pass\n\n        # Fallback to using PIL\n        return PILSerializer.deserialize(data)"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                tensor = decode_jpeg(data)\n                return tensor\n            except RuntimeError:\n                # Fallback to PIL\n                pil_image = Image.open(io.BytesIO(data))\n                if pil_image.mode != \"RGB\":\n                    pil_image = pil_image.convert(\"RGB\")\n                return pil_image\n        else:\n            pil_image = Image.open(io.BytesIO(data))\n            if pil_image.mode != \"RGB\":\n                pil_image = pil_image.convert(\"RGB\")\n            return pil_image"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                # Attempt to decode the data using torchvision\n                tensor = decode_jpeg(data)\n                return tensor\n            except RuntimeError:\n                # If decoding fails, fall back to using PIL\n                pil_image = Image.open(io.BytesIO(data))\n                if pil_image.mode != \"RGB\":\n                    pil_image = pil_image.convert(\"RGB\")\n                return pil_image\n        else:\n            # If torchvision is not available, use PIL to deserialize the data\n            pil_image = Image.open(io.BytesIO(data))\n            if pil_image.mode != \"RGB\":\n                pil_image = pil_image.convert(\"RGB\")\n            return pil_image"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                # Try to decode using torchvision\n                tensor = decode_jpeg(data)\n                return tensor\n            except RuntimeError:\n                # If decoding fails, fall back to using PIL\n                pil_image = PILSerializer.deserialize(data)\n                return pil_to_tensor(pil_image)\n\n        else:\n            # If torchvision is not available, use PIL to deserialize the data\n            return PILSerializer.deserialize(data)"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        try:\n            if _TORCH_VISION_AVAILABLE:\n                # Attempt to decode using torchvision\n                tensor = decode_jpeg(data)\n                return tensor\n        except Exception as e:\n            # Fallback to using PIL to deserialize the data\n            pil_image = PILSerializer.deserialize(data)\n            if _TORCH_VISION_AVAILABLE:\n                # Convert the PIL image to a PyTorch tensor\n                tensor = pil_to_tensor(pil_image)\n                return tensor\n            else:\n                return pil_image"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                tensor = decode_jpeg(data)\n                return tensor\n            except RuntimeError:\n                # Fallback to using PIL to deserialize the data\n                pil_image = PILSerializer.deserialize(data)\n                return pil_to_tensor(pil_image)\n        else:\n            # Fallback to using PIL to deserialize the data\n            return PILSerializer.deserialize(data)"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        try:\n            if _TORCH_VISION_AVAILABLE:\n                tensor = decode_jpeg(data)\n                return tensor\n        except RuntimeError:\n            pass\n\n        # Fallback to using PIL to deserialize the data\n        pil_image = PILSerializer.deserialize(data)\n        if _TORCH_VISION_AVAILABLE:\n            tensor = pil_to_tensor(pil_image)\n            return tensor\n        else:\n            return pil_image"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                tensor = decode_jpeg(data)\n                return tensor\n            except RuntimeError:\n                # Fallback to using PIL to deserialize the data\n                pil_image = Image.open(io.BytesIO(data))\n                if pil_image.mode != \"RGB\":\n                    pil_image = pil_image.convert(\"RGB\")\n                return pil_image\n        else:\n            pil_image = Image.open(io.BytesIO(data))\n            if pil_image.mode != \"RGB\":\n                pil_image = pil_image.convert(\"RGB\")\n            return pil_image"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                # Attempt to decode the data as a JPEG using torchvision\n                tensor = decode_jpeg(data)\n                return tensor\n            except RuntimeError:\n                # If decoding fails due to a runtime error, fall back to using PIL to deserialize the data\n                pil_image = PILSerializer.deserialize(data)\n                return pil_to_tensor(pil_image)\n        else:\n            # If torchvision is not available, use PIL to deserialize the data\n            pil_image = PILSerializer.deserialize(data)\n            return pil_image"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                tensor = decode_jpeg(data)\n                return tensor\n            except RuntimeError:\n                pass\n\n        # Fallback to using PIL\n        pil_image = Image.open(io.BytesIO(data))\n        if _TORCH_VISION_AVAILABLE:\n            return pil_to_tensor(pil_image)\n        else:\n            return pil_image"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        try:\n            if _TORCH_VISION_AVAILABLE:\n                tensor = decode_jpeg(data)\n                return tensor\n        except RuntimeError as e:\n            pass\n\n        pil_image = PILSerializer.deserialize(data)\n        if _TORCH_VISION_AVAILABLE:\n            tensor = pil_to_tensor(pil_image)\n            return tensor\n        else:\n            return pil_image"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                # Try to decode the data using torchvision\n                img_tensor, _ = decode_jpeg(data)\n                return img_tensor\n            except RuntimeError:\n                pass\n\n        # Fallback to using PIL to deserialize the data\n        pil_image = PILSerializer.deserialize(data)\n\n        if _TORCH_VISION_AVAILABLE:\n            # Convert the PIL image to a PyTorch tensor\n            return pil_to_tensor(pil_image)\n\n        return pil_image"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                image = decode_jpeg(data)\n                return pil_to_tensor(image)\n            except RuntimeError:\n                pass\n        return PILSerializer.deserialize(data)"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                pil_image = Image.open(io.BytesIO(data))\n                tensor_image = pil_to_tensor(pil_image)\n                return tensor_image\n            except Exception:\n                pass\n\n        return PILSerializer.deserialize(data)"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                tensor = decode_jpeg(data)\n                return tensor\n            except RuntimeError:\n                pass\n\n        # Fallback to using PIL to deserialize the data\n        pil_image = PILSerializer.deserialize(data)\n        if _TORCH_VISION_AVAILABLE:\n            tensor = pil_to_tensor(pil_image)\n            return tensor\n        else:\n            return pil_image"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                tensor = decode_jpeg(data)\n                return tensor\n            except RuntimeError:\n                pass\n\n        # Fallback to PIL\n        pil_image = PILSerializer.deserialize(data)\n        if _TORCH_VISION_AVAILABLE:\n            return pil_to_tensor(pil_image)\n        else:\n            return pil_image"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                decoded_image = decode_jpeg(data)\n                return pil_to_tensor(decoded_image)\n            except RuntimeError:\n                pass\n        if _PIL_AVAILABLE:\n            return PILSerializer.deserialize(data)\n        raise ValueError(\"Neither torchvision nor PIL is available for deserializing JPEG image.\")"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(item.numpy().tobytes(order=\"C\"))\n        serialized_data = b\"\".join(data)\n        data_type_string = f\"no_header_tensor:{dtype_indice}\"\n        return serialized_data, data_type_string"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [f\"no_header_tensor:{dtype_indice}\".encode(\"utf-8\")]\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.numpy().tobytes(order=\"C\"))\n        serialized_data = b\"\".join(data)\n        data_type_string = f\"no_header_tensor:{dtype_indice}\"\n        return serialized_data, data_type_string"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.numpy().tobytes(order=\"C\"))\n        serialized_data = b\"\".join(data)\n        data_type_str = f\"no_header_tensor:{dtype_indice}\"\n        return serialized_data, data_type_str"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.numpy().tobytes(order=\"C\"))\n        serialized_data = b\"\".join(data)\n        data_type_index = f\"no_header_tensor:{dtype_indice}\"\n        return serialized_data, data_type_index"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.numpy().tobytes(order=\"C\"))\n        serialized_data = b\"\".join(data)\n        data_type_index = f\"no_header_tensor:{dtype_indice}\"\n        return serialized_data, data_type_index"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_tensor:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = _TORCH_DTYPES_MAPPING[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.numpy().tobytes(order=\"C\"))\n        serialized_data = b\"\".join(data)\n        data_type_index = f\"no_header_tensor:{dtype_indice}\"\n        return serialized_data, data_type_index"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.numpy().tobytes(order=\"C\"))\n        serialized_data = b\"\".join(data)\n        data_type_index = f\"no_header_tensor:{dtype_indice}\"\n        return serialized_data, data_type_index"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_tensor:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(item.numpy().tobytes(order=\"C\"))\n        serialized_data = b\"\".join(data)\n        data_type_string = f\"no_header_tensor:{dtype_indice}\"\n        return serialized_data, data_type_string"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [f\"no_header_tensor:{dtype_indice}\".encode(\"utf-8\")]\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.numpy().tobytes(order=\"C\"))\n        serialized_data = b\"\".join(data)\n        data_type_index = f\"no_header_tensor:{dtype_indice}\"\n        return serialized_data, data_type_index"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.numpy().tobytes(order=\"C\"))\n        serialized_data = b\"\".join(data)\n        data_type_string = f\"no_header_tensor:{dtype_indice}\"\n        return serialized_data, data_type_string"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.numpy().tobytes(order=\"C\"))\n        serialized_data = b\"\".join(data)\n        data_type_string = f\"no_header_tensor:{dtype_indice}\"\n        return serialized_data, data_type_string"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [f\"{dtype_indice}\".encode()]\n        data.append(f\"{len(item.shape)}\".encode())\n        for dim in item.shape:\n            data.append(f\"{dim}\".encode())\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_tensor:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = _TORCH_DTYPES_MAPPING[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.numpy().tobytes(order=\"C\"))\n        serialized_data = b\"\".join(data)\n        data_type_str = f\"no_header_tensor:{dtype_indice}\"\n        return serialized_data, data_type_str"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_tensor:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = _TORCH_DTYPES_MAPPING[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.numpy().tobytes(order=\"C\"))\n        serialized_data = b\"\".join(data)\n        data_type_str = f\"no_header_tensor:{dtype_indice}\"\n        return serialized_data, data_type_str"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_tensor:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        dtype = self._dtype\n        tensor = torch.frombuffer(data, dtype=dtype)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        shape = (len(data) // self._dtype.itemsize,)\n        return torch.frombuffer(data, dtype=self._dtype).reshape(shape)"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        dtype = self._dtype\n        if dtype is None:\n            raise ValueError(\"No data type specified for deserialization. Call setup() method first.\")\n        return torch.frombuffer(data, dtype=dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        dtype = self._dtype\n        tensor = torch.frombuffer(data, dtype=dtype)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        tensor = torch.frombuffer(data, dtype=self._dtype)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        dtype = self._dtype\n        tensor = torch.frombuffer(data, dtype=dtype)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        dtype = self._dtype\n        tensor = torch.frombuffer(data, dtype=dtype)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        tensor = torch.frombuffer(data, dtype=self._dtype)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        dtype = self._dtype\n        tensor = torch.frombuffer(data, dtype=dtype)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        dtype = self._dtype\n        tensor = torch.frombuffer(data, dtype=dtype)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        dtype = self._dtype\n        tensor = torch.frombuffer(data, dtype=dtype)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        tensor = torch.frombuffer(data, dtype=self._dtype)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        dtype = self._dtype\n        tensor = torch.frombuffer(data, dtype=dtype)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        tensor = torch.frombuffer(data, dtype=self._dtype)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        dtype = self._dtype\n        tensor = torch.frombuffer(data, dtype=dtype)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        tensor = torch.frombuffer(data, dtype=self._dtype)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        shape = (len(data) // self._dtype.itemsize,)\n        return torch.frombuffer(data, dtype=self._dtype).reshape(shape)"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        dtype = self._dtype\n        tensor = torch.frombuffer(data, dtype=dtype)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        tensor = torch.frombuffer(data, dtype=self._dtype)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        tensor = torch.frombuffer(data, dtype=self._dtype)\n        return tensor"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        return np.reshape(array, tuple(shape))"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        return array.reshape(shape)"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array_data = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        return array_data.reshape(shape)"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        return array.reshape(shape)"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array_data = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        return np.reshape(array_data, shape)"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array_data = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        return array_data.reshape(shape)"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array_data = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        return np.reshape(array_data, tuple(shape))"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array_data = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        return np.reshape(array_data, tuple(shape))"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array_data = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        return np.reshape(array_data, shape)"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        return array.reshape(shape)"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array_data = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        return np.reshape(array_data, tuple(shape))"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        return array.reshape(shape)"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        return array.reshape(shape)"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array_data = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        return np.reshape(array_data, shape)"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array_data = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        return np.reshape(array_data, shape)"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        return array.reshape(shape)"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        array = array.reshape(shape)\n        return array"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        array = array.reshape(shape)\n        return array"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        return array.reshape(shape)"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array_data = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        return np.reshape(array_data, shape)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = _NUMPY_DTYPES_MAPPING[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_numpy:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = _NUMPY_DTYPES_MAPPING[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_numpy:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = _NUMPY_DTYPES_MAPPING[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_numpy:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = _NUMPY_DTYPES_MAPPING[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_numpy:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = _NUMPY_DTYPES_MAPPING[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_numpy:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = _NUMPY_DTYPES_MAPPING[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_numpy:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = _NUMPY_DTYPES_MAPPING[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_numpy:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = _NUMPY_DTYPES_MAPPING[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_numpy:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = _NUMPY_DTYPES_MAPPING[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_numpy:{dtype_indice}\""}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = _NUMPY_DTYPES_MAPPING[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = _NUMPY_DTYPES_MAPPING[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = _NUMPY_DTYPES_MAPPING[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = _NUMPY_DTYPES_MAPPING[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = _NUMPY_DTYPES_MAPPING[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = _NUMPY_DTYPES_MAPPING[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = _NUMPY_DTYPES_MAPPING[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = _NUMPY_DTYPES_MAPPING[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = _NUMPY_DTYPES_MAPPING[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = _NUMPY_DTYPES_MAPPING[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = _NUMPY_DTYPES_MAPPING[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = _NUMPY_DTYPES_MAPPING[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = _NUMPY_DTYPES_MAPPING[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = _NUMPY_DTYPES_MAPPING[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = _NUMPY_DTYPES_MAPPING[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = _NUMPY_DTYPES_MAPPING[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = _NUMPY_DTYPES_MAPPING[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = {\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded\": self._num_samples_yielded_streaming,\n            \"latest_worker_idx\": self._latest_worker_idx,\n        }\n\n        if isinstance(self.dataset, StreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        else:\n            state[\"dataset\"] = {\n                \"num_samples_yielded_combined\": self._num_samples_yielded_combined,\n                \"inner_dataset_state\": self.dataset.state_dict(),\n            }\n\n        return state"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = {\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded\": self._num_samples_yielded_streaming,\n            \"latest_worker_idx\": self._latest_worker_idx,\n        }\n\n        if isinstance(self.dataset, StreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        else:\n            state[\"dataset\"] = {\n                \"type\": \"CombinedStreamingDataset\",\n                \"num_samples_yielded\": self._num_samples_yielded_combined,\n            }\n\n        return state"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = {\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded\": self._num_samples_yielded_streaming,\n            \"latest_worker_idx\": self._latest_worker_idx\n        }\n\n        if isinstance(self.dataset, StreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        else:\n            state[\"dataset\"] = {\n                \"type\": \"CombinedStreamingDataset\",\n                \"num_samples_yielded\": self._num_samples_yielded_combined\n            }\n\n        return state"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state_dict = {\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded\": self._num_samples_yielded_streaming,\n            \"latest_worker_idx\": self._latest_worker_idx\n        }\n\n        if isinstance(self.dataset, StreamingDataset):\n            state_dict[\"dataset\"] = self.dataset.state_dict()\n        else:\n            state_dict[\"dataset\"] = {\n                \"combined_dataset\": self.dataset.combined_dataset.state_dict(),\n                \"num_samples_yielded_combined\": self._num_samples_yielded_combined\n            }\n\n        return state_dict"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = {\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded\": self._num_samples_yielded_streaming,\n            \"latest_worker_idx\": self._latest_worker_idx,\n        }\n\n        if isinstance(self.dataset, StreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        else:\n            state[\"dataset\"] = {\n                \"type\": \"CombinedStreamingDataset\",\n                \"num_samples_yielded\": self._num_samples_yielded_combined,\n            }\n\n        return state"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = {\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded\": self._num_samples_yielded_streaming,\n            \"latest_worker_idx\": self._latest_worker_idx\n        }\n\n        if isinstance(self.dataset, StreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        else:\n            state[\"dataset\"] = {\n                \"type\": \"CombinedStreamingDataset\",\n                \"num_samples_yielded\": self._num_samples_yielded_combined\n            }\n\n        return state"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state_dict = {\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded\": self._num_samples_yielded_streaming,\n            \"latest_worker_idx\": self._latest_worker_idx\n        }\n\n        if isinstance(self.dataset, StreamingDataset):\n            state_dict[\"dataset\"] = self.dataset.state_dict()\n        else:\n            state_dict[\"dataset\"] = {\n                \"type\": \"CombinedStreamingDataset\",\n                \"num_samples_yielded\": self._num_samples_yielded_combined\n            }\n\n        return state_dict"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = {\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded\": self._num_samples_yielded_streaming,\n            \"latest_worker_idx\": self._latest_worker_idx\n        }\n\n        if isinstance(self.dataset, StreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        else:\n            state[\"dataset\"] = {\n                \"type\": \"CombinedStreamingDataset\",\n                \"num_samples_yielded\": self._num_samples_yielded_combined\n            }\n\n        return state"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = {\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded\": self._num_samples_yielded_streaming,\n            \"latest_worker_idx\": self._latest_worker_idx\n        }\n\n        if isinstance(self.dataset, StreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        else:\n            state[\"dataset\"] = {\n                \"type\": \"CombinedStreamingDataset\",\n                \"num_samples_yielded\": self._num_samples_yielded_combined\n            }\n\n        return state"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = {\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded\": self._num_samples_yielded_streaming\n            if isinstance(self.dataset, StreamingDataset)\n            else self._num_samples_yielded_combined,\n            \"latest_worker_idx\": self._latest_worker_idx,\n        }\n\n        if isinstance(self.dataset, StreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        else:\n            state[\"dataset\"] = {}\n            for worker_idx, num_samples in self._num_samples_yielded_combined.items():\n                state[\"dataset\"][worker_idx] = {\n                    \"num_samples_yielded\": num_samples,\n                }\n\n        return state"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state_dict = {\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded\": self._num_samples_yielded_streaming,\n            \"latest_worker_idx\": self._latest_worker_idx\n        }\n\n        if isinstance(self.dataset, StreamingDataset):\n            state_dict[\"dataset\"] = self.dataset.state_dict()\n        else:\n            state_dict[\"dataset\"] = {}\n            for worker_idx, num_samples_yielded in self._num_samples_yielded_combined.items():\n                state_dict[\"dataset\"][worker_idx] = {\n                    \"num_samples_yielded\": num_samples_yielded\n                }\n\n        return state_dict"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = {\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded\": self._num_samples_yielded_streaming,\n            \"latest_worker_idx\": self._latest_worker_idx\n        }\n\n        if isinstance(self.dataset, StreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        else:\n            state[\"dataset\"] = {\n                \"type\": \"CombinedStreamingDataset\",\n                \"num_samples_yielded\": self._num_samples_yielded_combined\n            }\n\n        return state"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state_dict = {\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded\": self._num_samples_yielded_streaming,\n            \"latest_worker_idx\": self._latest_worker_idx\n        }\n\n        if isinstance(self.dataset, StreamingDataset):\n            state_dict[\"dataset\"] = self.dataset.state_dict()\n        else:\n            state_dict[\"dataset\"] = {\n                \"type\": \"CombinedStreamingDataset\",\n                \"num_samples_yielded\": self._num_samples_yielded_combined\n            }\n\n        return state_dict"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = {\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded\": self._num_samples_yielded_streaming,\n            \"latest_worker_idx\": self._latest_worker_idx\n        }\n\n        if isinstance(self.dataset, StreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        else:\n            state[\"dataset\"] = {\n                \"type\": \"CombinedStreamingDataset\",\n                \"num_samples_yielded\": self._num_samples_yielded_combined\n            }\n\n        return state"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = {\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded\": self._num_samples_yielded_streaming,\n            \"latest_worker_idx\": self._latest_worker_idx\n        }\n\n        if isinstance(self.dataset, StreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        else:\n            state[\"dataset\"] = {}\n            for worker_idx, num_samples in self._num_samples_yielded_combined.items():\n                state[\"dataset\"][f\"worker_{worker_idx}\"] = {\n                    \"num_samples_yielded\": num_samples\n                }\n\n        return state"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "    state = {\n        \"current_epoch\": self.current_epoch,\n        \"num_samples_yielded\": self._num_samples_yielded_streaming,\n        \"latest_worker_idx\": self._latest_worker_idx,\n    }\n\n    if isinstance(self.dataset, StreamingDataset):\n        state[\"dataset\"] = self.dataset.state_dict()\n    else:\n        state[\"dataset\"] = {\n            \"type\": \"CombinedStreamingDataset\",\n            \"num_samples_yielded\": self._num_samples_yielded_combined,\n        }\n\n    return state"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        \n        state = {\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded\": self._num_samples_yielded_streaming\n            if isinstance(self.dataset, StreamingDataset)\n            else self._num_samples_yielded_combined,\n            \"latest_worker_idx\": self._latest_worker_idx\n        }\n\n        if isinstance(self.dataset, StreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        else:\n            state[\"dataset\"] = {\n                \"combined_dataset\": self.dataset._datasets,\n                \"use_streaming_dataloader\": self.dataset._use_streaming_dataloader\n            }\n\n        return state"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = {\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded\": self._num_samples_yielded_streaming\n            if isinstance(self.dataset, StreamingDataset)\n            else self._num_samples_yielded_combined,\n            \"latest_worker_idx\": self._latest_worker_idx,\n        }\n\n        if isinstance(self.dataset, StreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        else:\n            state[\"dataset\"] = {\n                \"dataset_type\": \"CombinedStreamingDataset\",\n                \"num_samples_yielded\": self._num_samples_yielded_combined,\n            }\n\n        return state"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = {\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded\": self._num_samples_yielded_streaming,\n            \"latest_worker_idx\": self._latest_worker_idx\n        }\n\n        if isinstance(self.dataset, StreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        else:\n            state[\"dataset\"] = {\n                \"type\": \"CombinedStreamingDataset\",\n                \"num_samples_yielded\": self._num_samples_yielded_combined\n            }\n\n        return state"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = {\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded\": self._num_samples_yielded_streaming,\n            \"latest_worker_idx\": self._latest_worker_idx,\n        }\n        \n        if isinstance(self.dataset, StreamingDataset):\n            state[\"dataset\"] = self.dataset.state_dict()\n        else:\n            state[\"dataset\"] = {\n                \"type\": \"CombinedStreamingDataset\",\n                \"num_samples_yielded\": self._num_samples_yielded_combined,\n            }\n        \n        return state"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE or not _AV_AVAILABLE:\n            raise Exception(\"Torchvision and av libraries are required for deserializing video data.\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_file:\n            temp_file.write(data)\n            temp_file_path = temp_file.name\n\n        try:\n            video, audio, info = torchvision.io.read_video(temp_file_path, pts_unit=\"sec\")\n            return video\n        finally:\n            os.unlink(temp_file_path)"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE or not _AV_AVAILABLE:\n            raise Exception(\"torchvision and av libraries are required for deserializing video data\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_file:\n            temp_file.write(data)\n            temp_file_path = temp_file.name\n\n        try:\n            video, audio, info = torchvision.io.read_video(temp_file_path, pts_unit=\"sec\")\n            return video\n        finally:\n            os.unlink(temp_file_path)"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE or not _AV_AVAILABLE:\n            raise Exception(\"torchvision and av libraries are required for deserializing video. Please install them.\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_file:\n            temp_file.write(data)\n            temp_file_path = temp_file.name\n\n        try:\n            video, audio, info = torchvision.io.read_video(temp_file_path, pts_unit=\"sec\")\n            return video\n        finally:\n            os.unlink(temp_file_path)"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE or not _AV_AVAILABLE:\n            raise Exception(\"torchvision and av libraries are required for deserializing video data.\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_file:\n            temp_file.write(data)\n            temp_file_path = temp_file.name\n\n        try:\n            video, audio, info = torchvision.io.read_video(temp_file_path)\n            return video\n        finally:\n            os.unlink(temp_file_path)"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE or not _AV_AVAILABLE:\n            raise Exception(\"torchvision and av libraries are required for deserializing video data.\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_file:\n            temp_file.write(data)\n            temp_file_path = temp_file.name\n\n        try:\n            video, audio, info = torchvision.io.read_video(temp_file_path, pts_unit=\"sec\")\n            return video\n        finally:\n            os.unlink(temp_file_path)"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE or not _AV_AVAILABLE:\n            raise Exception(\"torchvision and av libraries are required for deserializing video data.\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_file:\n            temp_file.write(data)\n            temp_file_path = temp_file.name\n\n        try:\n            video, audio, info = torchvision.io.read_video(temp_file_path)\n            return video\n        finally:\n            os.unlink(temp_file_path)"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE or not _AV_AVAILABLE:\n            raise Exception(\"torchvision and av libraries are required for deserializing video data.\")\n\n        with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp4\") as temp_file:\n            temp_file.write(data)\n            temp_file_path = temp_file.name\n\n        try:\n            video, audio, info = torchvision.io.read_video(temp_file_path)\n            return video\n        finally:\n            os.unlink(temp_file_path)"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE or not _AV_AVAILABLE:\n            raise Exception(\"torchvision and av libraries are required for deserializing video data.\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\") as temp_file:\n            temp_file.write(data)\n            temp_file.flush()\n            video, audio, info = torchvision.io.read_video(temp_file.name, pts_unit=\"sec\")\n            return video"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE or not _AV_AVAILABLE:\n            raise Exception(\"torchvision and av libraries are required for deserializing video data.\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_file:\n            temp_file.write(data)\n            temp_file_path = temp_file.name\n\n        try:\n            video, audio, info = torchvision.io.read_video(temp_file_path, pts_unit=\"sec\")\n            return video\n        finally:\n            os.unlink(temp_file_path)"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE or not _AV_AVAILABLE:\n            raise Exception(\"torchvision and av libraries are required for deserializing video data.\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_file:\n            temp_file.write(data)\n            temp_file_path = temp_file.name\n\n        try:\n            video, audio, info = torchvision.io.read_video(temp_file_path, pts_unit=\"sec\")\n            return video\n        finally:\n            os.unlink(temp_file_path)"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE or not _TORCH_VISION_AVAILABLE:\n            raise Exception(\"Required libraries (torchvision and av) are not installed.\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_file:\n            temp_file.write(data)\n            temp_file_path = temp_file.name\n\n        try:\n            video, audio, info = torchvision.io.read_video(temp_file_path, pts_unit=\"sec\")\n            return video\n        finally:\n            os.unlink(temp_file_path)"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE or not _AV_AVAILABLE:\n            raise Exception(\"torchvision and av libraries are required for deserializing video data\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_file:\n            temp_file.write(data)\n            temp_file_path = temp_file.name\n\n        try:\n            video, audio, info = torchvision.io.read_video(temp_file_path)\n            return video\n        finally:\n            os.unlink(temp_file_path)"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE or not _AV_AVAILABLE:\n            raise Exception(\"torchvision and av libraries are required for deserializing video data.\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_file:\n            temp_file.write(data)\n            temp_file_path = temp_file.name\n\n        try:\n            video, audio, info = torchvision.io.read_video(temp_file_path, pts_unit=\"sec\")\n            return video\n        finally:\n            os.unlink(temp_file_path)"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE or not _AV_AVAILABLE:\n            raise Exception(\"torchvision and av libraries are required for deserializing video data\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_file:\n            temp_file.write(data)\n            temp_file_path = temp_file.name\n\n        try:\n            video, audio, info = torchvision.io.read_video(temp_file_path)\n            return video\n        finally:\n            os.unlink(temp_file_path)"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE or not _AV_AVAILABLE:\n            raise Exception(\"torchvision and av libraries are required for deserializing video data.\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as f:\n            f.write(data)\n            filepath = f.name\n\n        try:\n            video, audio, info = torchvision.io.read_video(filepath, pts_unit=\"sec\")\n            return video\n        finally:\n            os.unlink(filepath)"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE or not _AV_AVAILABLE:\n            raise Exception(\"Required libraries (torchvision and av) are not installed\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_file:\n            temp_file.write(data)\n            temp_file_path = temp_file.name\n\n        try:\n            video, audio, info = torchvision.io.read_video(temp_file_path, pts_unit=\"sec\")\n            return video\n        finally:\n            os.unlink(temp_file_path)"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE or not _AV_AVAILABLE:\n            raise RuntimeError(\"torchvision and av are required for deserializing video data\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as f:\n            f.write(data)\n            filepath = f.name\n\n        try:\n            video, audio, info = torchvision.io.read_video(filepath)\n            return video\n        finally:\n            os.unlink(filepath)"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE or not _AV_AVAILABLE:\n            raise Exception(\"torchvision and av libraries are required for deserializing video data.\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_file:\n            temp_file.write(data)\n            temp_file_path = temp_file.name\n\n        try:\n            video, audio, info = torchvision.io.read_video(temp_file_path, pts_unit=\"sec\")\n            return video\n        finally:\n            os.unlink(temp_file_path)"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE or not _AV_AVAILABLE:\n            raise Exception(\"torchvision and av libraries are required for deserializing video data.\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_file:\n            temp_file.write(data)\n            temp_file_path = temp_file.name\n\n        try:\n            video, audio, info = torchvision.io.read_video(temp_file_path)\n            return video\n        finally:\n            os.unlink(temp_file_path)"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE or not _AV_AVAILABLE:\n            raise Exception(\"torchvision and av libraries are required for deserializing video data.\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_file:\n            temp_file.write(data)\n            temp_file_path = temp_file.name\n\n        try:\n            video, audio, info = torchvision.io.read_video(temp_file_path)\n            return video\n        finally:\n            os.unlink(temp_file_path)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while not self.filled:\n            self.write_chunk()\n        return [self.write_chunks_index()]\n        self._is_done = True"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while not self.filled:\n            self.write_chunk()\n        file_paths = [self.write_chunks_index()]\n        self._is_done = True\n        return file_paths"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while not self.filled:\n            self.write_chunk()\n        file_paths = []\n        for _ in range(self._chunk_index):\n            file_paths.append(self.write_chunk())\n        file_paths.append(self.write_chunks_index())\n        self._is_done = True\n        return file_paths"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while not self.filled:\n            self.write_chunk()\n        paths = []\n        while not self.filled:\n            paths.append(self.write_chunk())\n        paths.append(self.write_chunks_index())\n        self._is_done = True\n        return paths"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        written_chunks = []\n        while not self.filled:\n            chunk_path = self.write_chunk()\n            written_chunks.append(chunk_path)\n        index_path = self.write_chunks_index()\n        written_chunks.append(index_path)\n        self._is_done = True\n        return written_chunks"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while not self.filled:\n            self.write_chunk()\n        index_file = self.write_chunks_index()\n        return [index_file]\n        self._is_done = True"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while not self.filled:\n            self.write_chunk()\n        paths = []\n        while not self.filled:\n            paths.append(self.write_chunk())\n        paths.append(self.write_chunks_index())\n        self._is_done = True\n        return paths"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while not self.filled:\n            self.write_chunk()\n        file_paths = [os.path.join(self._cache_dir, f\"chunk-{self.rank}-{i}.bin\") for i in range(self._chunk_index)]\n        index_file_path = self.write_chunks_index()\n        file_paths.append(index_file_path)\n        self._is_done = True\n        return file_paths"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        written_chunks = []\n        while not self.filled:\n            written_chunk = self.write_chunk()\n            written_chunks.append(written_chunk)\n        index_file = self.write_chunks_index()\n        written_chunks.append(index_file)\n        self._is_done = True\n        return written_chunks"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while not self.filled:\n            self.write_chunk()\n        file_paths = [os.path.join(self._cache_dir, f\"chunk-{self.rank}-{i}.bin\") for i in range(self._chunk_index)]\n        index_file_path = self.write_chunks_index()\n        if index_file_path:\n            file_paths.append(index_file_path)\n        self._is_done = True\n        return file_paths"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        written_chunks = []\n        while not self.filled:\n            chunk_path = self.write_chunk()\n            written_chunks.append(chunk_path)\n        index_path = self.write_chunks_index()\n        written_chunks.append(index_path)\n        self._is_done = True\n        return written_chunks"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        written_chunks = []\n        while not self.filled:\n            chunk_path = self.write_chunk()\n            written_chunks.append(chunk_path)\n        index_path = self.write_chunks_index()\n        written_chunks.append(index_path)\n        self._is_done = True\n        return written_chunks"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while not self.filled:\n            self.write_chunk()\n        chunks_written = [self.write_chunks_index()]\n        self._is_done = True\n        return chunks_written"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while not self.filled:\n            self.write_chunk()\n        file_paths = []\n        for _ in range(self._chunk_index):\n            file_paths.append(self.write_chunk(on_done=True))\n        file_paths.append(self.write_chunks_index())\n        self._is_done = True\n        return file_paths"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while not self.filled:\n            self.write_chunk()\n        file_paths = []\n        while not self.filled:\n            file_paths.append(self.write_chunk())\n        file_paths.append(self.write_chunks_index())\n        self._is_done = True\n        return file_paths"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        file_paths = []\n        while not self.filled:\n            file_paths.append(self.write_chunk())\n        file_paths.append(self.write_chunks_index())\n        self._is_done = True\n        return file_paths"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        written_chunks = []\n        while not self.filled:\n            written_chunks.append(self.write_chunk())\n        index_file = self.write_chunks_index()\n        if index_file:\n            written_chunks.append(index_file)\n        self._is_done = True\n        return written_chunks"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        written_chunks = []\n        while not self.filled:\n            written_chunks.append(self.write_chunk())\n        index_file = self.write_chunks_index()\n        written_chunks.append(index_file)\n        self._is_done = True\n        return written_chunks"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while not self.filled:\n            self.write_chunk()\n        file_paths = []\n        for _ in range(self._chunk_index):\n            file_paths.append(self.write_chunk())\n        file_paths.append(self.write_chunks_index())\n        self._is_done = True\n        return file_paths"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        written_chunks = []\n        while not self.filled:\n            written_chunks.append(self.write_chunk())\n        index_file = self.write_chunks_index()\n        written_chunks.append(index_file)\n        self._is_done = True\n        return written_chunks"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        self.current_epoch = obj[\"current_epoch\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        self._num_samples_yielded_streaming = obj.get(\"num_samples_yielded\", 0)\n\n        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        else:\n            raise RuntimeError(\"The dataset associated with the StreamingDataLoader must be either a StreamingDataset or a CombinedStreamingDataset.\")"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        self.current_epoch = obj[\"current_epoch\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n\n        if isinstance(self.dataset, StreamingDataset):\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n        else:\n            raise RuntimeError(\"The dataset associated with the StreamingDataLoader must be a StreamingDataset or CombinedStreamingDataset.\")"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        else:\n            raise RuntimeError(\"Dataset should be either StreamingDataset or CombinedStreamingDataset.\")"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        self.current_epoch = obj[\"current_epoch\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        self.restore = True\n\n        if isinstance(self.dataset, StreamingDataset):\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        else:\n            raise RuntimeError(\"Dataset should be either StreamingDataset or CombinedStreamingDataset.\")"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        else:\n            raise RuntimeError(\"The dataset associated with the StreamingDataLoader must be either a StreamingDataset or a CombinedStreamingDataset.\")"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        else:\n            raise RuntimeError(\"Dataset should be either a StreamingDataset or a CombinedStreamingDataset.\")"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        self.current_epoch = obj[\"current_epoch\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n\n        if isinstance(self.dataset, StreamingDataset):\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self.restore = True\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self.restore = True\n        else:\n            raise RuntimeError(\"Dataset should be either StreamingDataset or CombinedStreamingDataset.\")\n\n        self.dataset.load_state_dict(obj[\"dataset\"])"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        self.current_epoch = obj[\"current_epoch\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        if isinstance(self.dataset, StreamingDataset):\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        else:\n            raise RuntimeError(\"The dataset associated with StreamingDataLoader must be either StreamingDataset or CombinedStreamingDataset.\")"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj['dataset'])\n            self.current_epoch = obj['current_epoch']\n            self._num_samples_yielded_streaming = obj['num_samples_yielded']\n            self._latest_worker_idx = obj['latest_worker_idx']\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj['dataset'])\n            self.current_epoch = obj['current_epoch']\n            self._num_samples_yielded_combined = obj['num_samples_yielded']\n            self._latest_worker_idx = obj['latest_worker_idx']\n        else:\n            raise RuntimeError(\"The dataset associated with StreamingDataLoader must be either a StreamingDataset or a CombinedStreamingDataset.\")"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        self.current_epoch = obj[\"current_epoch\"]\n        self._num_samples_yielded_streaming = obj.get(\"num_samples_yielded\", 0)\n        self._latest_worker_idx = obj.get(\"latest_worker_idx\", 0)\n        \n        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        else:\n            raise RuntimeError(\"Dataset must be either StreamingDataset or CombinedStreamingDataset.\")"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        self.current_epoch = obj[\"current_epoch\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        self._num_samples_yielded_streaming = obj.get(\"num_samples_yielded\", 0)\n\n        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self._num_samples_yielded_combined = obj.get(\"num_samples_yielded\", {})\n            self.dataset.load_state_dict(obj[\"dataset\"], self.num_workers, self.batch_size, self._num_samples_yielded_combined)\n        else:\n            raise RuntimeError(\"The dataset associated with the StreamingDataLoader must be either a StreamingDataset or a CombinedStreamingDataset.\")"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.restore = True\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.restore = True\n        else:\n            raise RuntimeError(\"The dataset associated with the StreamingDataLoader must be either a StreamingDataset or a CombinedStreamingDataset.\")"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        self.current_epoch = obj[\"current_epoch\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        self.restore = True\n\n        if isinstance(self.dataset, StreamingDataset):\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        else:\n            raise RuntimeError(\"The dataset associated with the StreamingDataLoader must be either a StreamingDataset or a CombinedStreamingDataset.\")"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        else:\n            raise RuntimeError(\"Dataset should be either a StreamingDataset or a CombinedStreamingDataset.\")"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        else:\n            raise RuntimeError(\"The dataset associated with the StreamingDataLoader must be either a StreamingDataset or a CombinedStreamingDataset.\")"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.restore = True\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.restore = True\n        else:\n            raise RuntimeError(\"The dataset associated with the StreamingDataLoader must be either a StreamingDataset or a CombinedStreamingDataset.\")"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        else:\n            raise RuntimeError(\"The dataset associated with the StreamingDataLoader must be either a StreamingDataset or a CombinedStreamingDataset.\")"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        else:\n            raise RuntimeError(\"The dataset associated with the StreamingDataLoader must be either a StreamingDataset or a CombinedStreamingDataset.\")\n        \n        self.current_epoch = obj[\"current_epoch\"]\n        self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        self.current_epoch = obj[\"current_epoch\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        self._num_samples_yielded_streaming = obj.get(\"num_samples_yielded\", 0)\n\n        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            if \"num_samples_yielded\" in obj:\n                self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self.dataset.load_state_dict(obj[\"dataset\"], self.num_workers, self.batch_size)\n        else:\n            raise RuntimeError(\"Dataset should be either StreamingDataset or CombinedStreamingDataset.\")"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        else:\n            raise RuntimeError(\"Dataset should be either a StreamingDataset or CombinedStreamingDataset.\")"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "\n        state = {}\n\n        if self._iterator is None and num_samples_yielded is None:\n            return state\n\n        state[\"num_workers\"] = num_workers\n        state[\"batch_size\"] = batch_size\n\n        if self._iterator is not None:\n            state[\"iterator_state\"] = self._iterator.state_dict()\n        else:\n            state[\"datasets_state\"] = [dataset.state_dict() for dataset in self._datasets]\n\n        if num_samples_yielded is not None:\n            state[\"num_samples_yielded\"] = num_samples_yielded\n\n        return state"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None and num_samples_yielded is None:\n            return {}  # Return empty dictionary if internal iterator is None and num_samples_yielded is not provided\n        else:\n            if self._iterator is not None:\n                return self._iterator.state_dict(num_workers, batch_size, num_samples_yielded)\n            else:\n                state_dict = {\n                    \"num_samples_yielded\": num_samples_yielded,\n                    \"num_workers\": num_workers,\n                    \"batch_size\": batch_size\n                }\n                return state_dict"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "\n        state_dict = {}\n\n        if self._iterator is None and num_samples_yielded is None:\n            return state_dict\n\n        state_dict[\"_seed\"] = self._seed\n        state_dict[\"_weights\"] = self._weights\n        state_dict[\"_use_streaming_dataloader\"] = self._use_streaming_dataloader\n        state_dict[\"_current_epoch\"] = self._current_epoch\n\n        if self._iterator is not None:\n            state_dict[\"_iterator\"] = self._iterator.state_dict(num_workers, batch_size)\n        else:\n            state_dict[\"_num_samples_yielded\"] = num_samples_yielded\n\n        return state_dict"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        state = {}\n        if self._iterator is None and num_samples_yielded is None:\n            return state\n\n        if self._iterator is not None:\n            state = self._iterator.state_dict(num_workers, batch_size, num_samples_yielded)\n        else:\n            state[\"current_epoch\"] = self._current_epoch\n            state[\"datasets\"] = [dataset.state_dict() for dataset in self._datasets]\n\n        return state"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "\n        state_dict = {}\n        if self._iterator is None and num_samples_yielded is None:\n            return state_dict\n\n        state_dict[\"num_workers\"] = num_workers\n        state_dict[\"batch_size\"] = batch_size\n\n        if self._iterator is not None:\n            state_dict[\"iterator_state\"] = self._iterator.state_dict(num_samples_yielded)\n        else:\n            state_dict[\"num_samples_yielded\"] = num_samples_yielded\n\n        return state_dict"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        state_dict = {}\n\n        if self._iterator is None and num_samples_yielded is None:\n            return state_dict\n\n        state_dict[\"num_workers\"] = num_workers\n        state_dict[\"batch_size\"] = batch_size\n\n        if self._iterator is not None:\n            state_dict[\"iterator_state\"] = self._iterator.state_dict()\n        else:\n            state_dict[\"datasets_state\"] = [dataset.state_dict() for dataset in self._datasets]\n\n        if num_samples_yielded is not None:\n            state_dict[\"num_samples_yielded\"] = num_samples_yielded\n\n        return state_dict"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "\n        state_dict = {}\n        if self._iterator is None and num_samples_yielded is None:\n            return state_dict\n\n        if self._iterator is not None:\n            state_dict = self._iterator.state_dict()\n        else:\n            state_dict[\"num_samples_yielded\"] = num_samples_yielded\n            state_dict[\"num_workers\"] = num_workers\n            state_dict[\"batch_size\"] = batch_size\n\n        return state_dict"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        state = {}\n        if self._iterator is None and num_samples_yielded is None:\n            return state\n        else:\n            if self._iterator is not None:\n                state[\"iterator_state\"] = self._iterator.state_dict()\n            if num_samples_yielded is not None:\n                state[\"num_samples_yielded\"] = num_samples_yielded\n            state[\"num_workers\"] = num_workers\n            state[\"batch_size\"] = batch_size\n            return state"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "\n        state = {}\n\n        if self._iterator is None and num_samples_yielded is None:\n            return state\n\n        state[\"num_workers\"] = num_workers\n        state[\"batch_size\"] = batch_size\n\n        if self._iterator is not None:\n            state.update(self._iterator.state_dict())\n        else:\n            state[\"num_samples_yielded\"] = num_samples_yielded\n\n        return state"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        state = {}\n        if self._iterator is None and num_samples_yielded is None:\n            return state\n        else:\n            if self._iterator is not None:\n                state = self._iterator.state_dict()\n            else:\n                state[\"num_samples_yielded\"] = num_samples_yielded\n                state[\"num_workers\"] = num_workers\n                state[\"batch_size\"] = batch_size\n            return state"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "\n        state_dict = {}\n\n        if self._iterator is None and num_samples_yielded is None:\n            return state_dict\n\n        if self._iterator is not None:\n            state_dict.update(self._iterator.state_dict(num_workers, batch_size))\n        else:\n            state_dict[\"num_samples_yielded\"] = num_samples_yielded\n\n        return state_dict"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        state_dict = {}\n        if self._iterator is None and num_samples_yielded is None:\n            return state_dict\n\n        state_dict[\"_seed\"] = self._seed\n        state_dict[\"_weights\"] = self._weights\n        state_dict[\"_current_epoch\"] = self._current_epoch\n\n        if self._iterator is not None:\n            state_dict[\"_iterator\"] = self._iterator.state_dict(\n                num_workers, batch_size, num_samples_yielded\n            )\n        else:\n            state_dict[\"_num_samples_yielded\"] = self._num_samples_yielded\n\n        return state_dict"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "\n        state_dict = {}\n        if self._iterator is None and num_samples_yielded is None:\n            return state_dict\n\n        if self._iterator is not None:\n            state_dict = self._iterator.state_dict()\n        else:\n            state_dict[\"datasets\"] = [dataset.state_dict() for dataset in self._datasets]\n            state_dict[\"seed\"] = self._seed\n            state_dict[\"weights\"] = self._weights\n            state_dict[\"use_streaming_dataloader\"] = self._use_streaming_dataloader\n            state_dict[\"current_epoch\"] = self._current_epoch\n\n        state_dict[\"num_workers\"] = num_workers\n        state_dict[\"batch_size\"] = batch_size\n        state_dict[\"num_samples_yielded\"] = num_samples_yielded\n\n        return state_dict"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "\n        state_dict = {}\n\n        if self._iterator is None and num_samples_yielded is None:\n            return state_dict\n\n        state_dict[\"num_workers\"] = num_workers\n        state_dict[\"batch_size\"] = batch_size\n\n        if self._iterator is not None:\n            state_dict[\"iterator_state\"] = self._iterator.state_dict()\n        else:\n            state_dict[\"datasets_state\"] = [dataset.state_dict() for dataset in self._datasets]\n\n        if num_samples_yielded is not None:\n            state_dict[\"num_samples_yielded\"] = num_samples_yielded\n\n        return state_dict"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "\n        state_dict = {}\n        if self._iterator is None and num_samples_yielded is None:\n            return state_dict\n        else:\n            if self._iterator is not None:\n                state_dict = self._iterator.state_dict()\n            else:\n                state_dict[\"num_samples_yielded\"] = num_samples_yielded\n                state_dict[\"num_workers\"] = num_workers\n                state_dict[\"batch_size\"] = batch_size\n            return state_dict"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "\n        state_dict = {}\n\n        if self._iterator is None and num_samples_yielded is None:\n            return state_dict\n        else:\n            state_dict[\"num_workers\"] = num_workers\n            state_dict[\"batch_size\"] = batch_size\n\n            if num_samples_yielded is not None:\n                state_dict[\"num_samples_yielded\"] = num_samples_yielded\n            else:\n                state_dict[\"datasets\"] = [dataset.state_dict() for dataset in self._datasets]\n\n            return state_dict"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        state_dict = {}\n\n        if self._iterator is None and num_samples_yielded is None:\n            return state_dict\n        else:\n            state_dict[\"num_workers\"] = num_workers\n            state_dict[\"batch_size\"] = batch_size\n\n            if self._iterator is not None:\n                state_dict[\"iterator_state\"] = self._iterator.state_dict()\n            if num_samples_yielded is not None:\n                state_dict[\"num_samples_yielded\"] = num_samples_yielded\n\n            return state_dict"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "\n        state = {}\n\n        if self._iterator is None and num_samples_yielded is None:\n            return state\n\n        state[\"_seed\"] = self._seed\n        state[\"_weights\"] = self._weights\n        state[\"_use_streaming_dataloader\"] = self._use_streaming_dataloader\n        state[\"_current_epoch\"] = self._current_epoch\n\n        if self._iterator:\n            state[\"_iterator\"] = self._iterator.state_dict(num_workers, batch_size, num_samples_yielded)\n        else:\n            state[\"_num_samples_yielded\"] = self._num_samples_yielded\n\n        return state"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "\n        state_dict = {}\n\n        if self._iterator is None and num_samples_yielded is None:\n            return state_dict\n        else:\n            if self._iterator is not None:\n                state_dict = self._iterator.state_dict()\n            else:\n                state_dict = {\n                    \"num_workers\": num_workers,\n                    \"batch_size\": batch_size,\n                    \"num_samples_yielded\": num_samples_yielded\n                }\n\n        return state_dict"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        state = {}\n\n        if self._iterator is None and num_samples_yielded is None:\n            return state\n        else:\n            if self._iterator is not None:\n                state[\"iterator_state\"] = self._iterator.state_dict()\n            if num_samples_yielded is not None:\n                state[\"num_samples_yielded\"] = num_samples_yielded\n            state[\"num_workers\"] = num_workers\n            state[\"batch_size\"] = batch_size\n            return state"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            # If the iterator is not initialized, update the state of each dataset\n            for dataset, dataset_state in zip(self._datasets, state_dict[\"datasets\"]):\n                dataset.load_state_dict(dataset_state)\n            self._num_samples_yielded = state_dict[\"num_samples_yielded\"]\n        else:\n            # If the iterator is initialized, update the state of the iterator\n            self._iterator.load_state_dict(state_dict)"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is not None:\n            self._iterator.load_state_dict(state_dict)\n        else:\n            # Update the state of each dataset within CombinedStreamingDataset\n            for dataset, dataset_state in zip(self._datasets, state_dict[\"datasets\"]):\n                dataset.load_state_dict(dataset_state)\n\n            # Update the number of samples yielded by the streaming dataloader\n            if __NUM_SAMPLES_YIELDED_KEY__ in state_dict:\n                self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            # If the iterator is not initialized, update the state of the datasets\n            for dataset, dataset_state in zip(self._datasets, state_dict[\"datasets\"]):\n                dataset.load_state_dict(dataset_state)\n            if __NUM_SAMPLES_YIELDED_KEY__ in state_dict:\n                self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n        else:\n            # If the iterator is initialized, update the state of the iterator\n            self._iterator.load_state_dict(state_dict)"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            # If the iterator is not initialized, the state_dict is empty and there's nothing to load\n            return\n\n        num_workers = state_dict.get(\"num_workers\")\n        batch_size = state_dict.get(\"batch_size\")\n        num_samples_yielded = state_dict.get(\"num_samples_yielded\")\n\n        # Update the state of the iterator\n        self._iterator.load_state_dict(state_dict)\n\n        # Update the state of each dataset within the CombinedStreamingDataset\n        for dataset, dataset_state in zip(self._datasets, state_dict[\"datasets\"]):\n            dataset.load_state_dict(dataset_state)\n\n        # Update the number of samples yielded if applicable\n        if num_samples_yielded is not None:\n            self._num_samples_yielded = num_samples_yielded"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is not None:\n            self._iterator.load_state_dict(state_dict)\n        else:\n            num_samples_yielded = state_dict.get(__NUM_SAMPLES_YIELDED_KEY__)\n            if num_samples_yielded is not None:\n                self._num_samples_yielded = num_samples_yielded"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            # If the iterator is not initialized, update the state of each dataset\n            for dataset, dataset_state in zip(self._datasets, state_dict[\"datasets\"]):\n                dataset.load_state_dict(dataset_state)\n\n            # Update the number of samples yielded if available\n            if __NUM_SAMPLES_YIELDED_KEY__ in state_dict:\n                self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n        else:\n            # If the iterator is initialized, update the state of the iterator\n            self._iterator.load_state_dict(state_dict)"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            # If the iterator is not initialized, update the state of each dataset\n            for dataset, dataset_state in zip(self._datasets, state_dict[\"datasets\"]):\n                dataset.load_state_dict(dataset_state)\n            if __NUM_SAMPLES_YIELDED_KEY__ in state_dict:\n                self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n        else:\n            # If the iterator is initialized, update the state of the iterator\n            self._iterator.load_state_dict(state_dict)"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            # If the iterator is not initialized, update the state of the datasets\n            for dataset, dataset_state in zip(self._datasets, state_dict[\"datasets\"]):\n                dataset.load_state_dict(dataset_state)\n            if state_dict[\"num_samples_yielded\"] is not None:\n                self._num_samples_yielded = state_dict[\"num_samples_yielded\"]\n        else:\n            # If the iterator is initialized, update the state of the iterator\n            self._iterator.load_state_dict(state_dict)"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            # If the iterator is not initialized, update the state of each dataset\n            for dataset, dataset_state in zip(self._datasets, state_dict[\"datasets\"]):\n                dataset.load_state_dict(dataset_state)\n            if __NUM_SAMPLES_YIELDED_KEY__ in state_dict:\n                self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n        else:\n            # If the iterator is initialized, update the state of the iterator\n            self._iterator.load_state_dict(state_dict)"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is not None:\n            self._iterator.load_state_dict(state_dict)\n        else:\n            # Update the state of each dataset within the CombinedStreamingDataset\n            for dataset, dataset_state in zip(self._datasets, state_dict[\"datasets\"]):\n                dataset.load_state_dict(dataset_state)\n\n            # Update the number of samples yielded by the streaming dataloader\n            if __NUM_SAMPLES_YIELDED_KEY__ in state_dict:\n                self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            # If the iterator is not initialized, update the state of each dataset\n            for dataset, dataset_state in zip(self._datasets, state_dict[\"datasets\"]):\n                dataset.load_state_dict(dataset_state)\n            if \"__NUM_SAMPLES_YIELDED__\" in state_dict:\n                self._num_samples_yielded = state_dict[\"__NUM_SAMPLES_YIELDED__\"]\n        else:\n            # If the iterator is initialized, update the state of the iterator\n            self._iterator.load_state_dict(state_dict)"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is not None:\n            self._iterator.load_state_dict(state_dict)\n        else:\n            # Update the state of each dataset within the CombinedStreamingDataset\n            for dataset in self._datasets:\n                dataset.load_state_dict(state_dict)\n            \n            # Update the number of samples yielded by the streaming dataloader\n            if __NUM_SAMPLES_YIELDED_KEY__ in state_dict:\n                self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is not None:\n            self._iterator.load_state_dict(state_dict)\n        else:\n            # If the iterator is not initialized, update the state of each dataset\n            for dataset, dataset_state in zip(self._datasets, state_dict[\"datasets\"]):\n                dataset.load_state_dict(dataset_state)\n\n            if __NUM_SAMPLES_YIELDED_KEY__ in state_dict:\n                self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            return\n        self._iterator.load_state_dict(state_dict)"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            # If the iterator is not initialized, update the state of the datasets\n            for dataset, dataset_state in zip(self._datasets, state_dict[\"datasets\"]):\n                dataset.load_state_dict(dataset_state)\n            if state_dict[\"num_samples_yielded\"] is not None:\n                self._num_samples_yielded = state_dict[\"num_samples_yielded\"]\n        else:\n            # If the iterator is initialized, update the state of the iterator\n            self._iterator.load_state_dict(state_dict)"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if \"__datasets__\" in state_dict:\n            datasets_state = state_dict[\"__datasets__\"]\n            for dataset, dataset_state in zip(self._datasets, datasets_state):\n                dataset.load_state_dict(dataset_state)\n\n        if __NUM_SAMPLES_YIELDED_KEY__ in state_dict:\n            self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            # If the iterator is not initialized, update the state of each dataset\n            for dataset, dataset_state in zip(self._datasets, state_dict[\"datasets\"]):\n                dataset.load_state_dict(dataset_state)\n            # Update the number of samples yielded by the streaming dataloader\n            self._num_samples_yielded = state_dict[\"num_samples_yielded\"]\n        else:\n            # If the iterator is initialized, update the state of the iterator\n            self._iterator.load_state_dict(state_dict)"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            # If the iterator is not initialized, update the state of the datasets\n            for dataset, dataset_state in zip(self._datasets, state_dict[\"datasets\"]):\n                dataset.load_state_dict(dataset_state)\n            if \"__NUM_SAMPLES_YIELDED__\" in state_dict:\n                self._num_samples_yielded = state_dict[\"__NUM_SAMPLES_YIELDED__\"]\n        else:\n            # If the iterator is initialized, update the state of the iterator\n            self._iterator.load_state_dict(state_dict)"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            self._num_samples_yielded = state_dict.get(__NUM_SAMPLES_YIELDED_KEY__)\n        else:\n            self._iterator.load_state_dict(state_dict)"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            self._num_samples_yielded = state_dict.get(__NUM_SAMPLES_YIELDED_KEY__)\n            for dataset, dataset_state in zip(self._datasets, state_dict.get(__SAMPLES_KEY__, [])):\n                dataset.load_state_dict(dataset_state)\n        else:\n            self._iterator.load_state_dict(state_dict)"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "\n    if isinstance(dir_path, Dir):\n        return dir_path  # If dir_path is already a Dir object, return it as is\n\n    if isinstance(dir_path, str):\n        if dir_path.startswith(\"s3://\"):\n            return Dir(path=dir_path, url=dir_path)  # If dir_path is an S3 URL, set both path and URL attributes\n        else:\n            return Dir(path=dir_path)  # If dir_path is a local path, set only the path attribute\n\n    return Dir()  # If dir_path is None or of an unsupported type, return an empty Dir object"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "\n    if isinstance(dir_path, Dir):\n        return dir_path  # If dir_path is already a Dir object, no need to resolve, just return it\n\n    if dir_path is None:\n        return Dir()  # If dir_path is None, return an empty Dir object\n\n    if isinstance(dir_path, str):\n        if dir_path.startswith(\"s3://\"):\n            # Process S3 URL\n            parsed_url = parse.urlparse(dir_path)\n            return Dir(path=None, url=dir_path)\n        else:\n            # Assume it's a local path\n            return Dir(path=dir_path)\n\n    # If dir_path is not a Dir object, nor a string, return an empty Dir object\n    return Dir()"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if \"s3://\" in dir_path:\n        return Dir(url=dir_path)\n\n    if _LIGHTNING_SDK_AVAILABLE and Machine.is_project_dir(dir_path):\n        return Dir(url=Studio.get_project_url(dir_path))\n\n    return Dir(path=dir_path)"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n    elif isinstance(dir_path, str):\n        parsed_url = parse.urlparse(dir_path)\n        if parsed_url.scheme == 's3':\n            return Dir(url=dir_path)\n        else:\n            return Dir(path=dir_path)\n    else:\n        return Dir()"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if \"s3://\" in dir_path:\n        return Dir(url=dir_path)\n\n    if _LIGHTNING_SDK_AVAILABLE and Machine.is_project_dir(dir_path):\n        project = Machine.from_dir(dir_path).project\n        return Dir(path=dir_path, url=project.url)\n\n    return Dir(path=dir_path)"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if isinstance(dir_path, str):\n        if dir_path.startswith(\"s3://\"):\n            parsed_url = parse.urlparse(dir_path)\n            return Dir(path=None, url=dir_path)\n        elif dir_path.startswith(\"http://\") or dir_path.startswith(\"https://\"):\n            return Dir(path=None, url=dir_path)\n        else:\n            return Dir(path=dir_path)"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if isinstance(dir_path, str):\n        if dir_path.startswith(\"s3://\"):\n            parsed_url = parse.urlparse(dir_path)\n            return Dir(path=None, url=dir_path)\n        elif dir_path.startswith(\"http://\") or dir_path.startswith(\"https://\"):\n            return Dir(path=None, url=dir_path)\n        else:\n            return Dir(path=dir_path)\n\n    raise ValueError(f\"Invalid directory path: {dir_path}\")"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if \"s3://\" in dir_path:\n        parsed_url = parse.urlparse(dir_path)\n        return Dir(path=None, url=dir_path)\n\n    if _LIGHTNING_SDK_AVAILABLE:\n        studio = Studio()\n        if studio.is_project_path(dir_path):\n            return Dir(path=dir_path, url=None)\n\n    return Dir(path=dir_path, url=None)"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if \"s3://\" in dir_path:\n        return Dir(url=dir_path)\n\n    if _LIGHTNING_SDK_AVAILABLE and Machine.is_project_dir(dir_path):\n        return Dir(path=dir_path, url=Studio.get_project_url(dir_path))\n\n    return Dir(path=dir_path)"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if not dir_path:\n        return Dir()\n\n    if isinstance(dir_path, str):\n        parsed_url = parse.urlparse(dir_path)\n        if parsed_url.scheme in [\"s3\", \"s3a\", \"s3n\"]:\n            return Dir(url=dir_path)\n        elif _BOTO3_AVAILABLE and re.match(r\"s3://\", dir_path):\n            return Dir(url=dir_path)\n        elif _LIGHTNING_SDK_AVAILABLE and re.match(r\"studio://\", dir_path):\n            return Dir(url=dir_path)\n\n    return Dir(path=dir_path)"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if isinstance(dir_path, str):\n        parsed_url = parse.urlparse(dir_path)\n        if parsed_url.scheme in ('s3', 's3a', 's3n'):\n            return Dir(url=dir_path)\n        elif _LIGHTNING_SDK_AVAILABLE and Machine.is_project_path(dir_path):\n            return Dir(path=dir_path)\n        else:\n            return Dir(path=os.path.abspath(dir_path))\n\n    raise ValueError(\"Invalid dir_path format\")"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if isinstance(dir_path, str):\n        parsed_url = parse.urlparse(dir_path)\n        if parsed_url.scheme == 's3':\n            return Dir(url=dir_path)\n        elif _LIGHTNING_SDK_AVAILABLE and re.match(r'^\\w+://', dir_path):\n            return Dir(url=dir_path)\n        elif os.path.exists(dir_path):\n            return Dir(path=dir_path)\n\n    return Dir()"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n    elif isinstance(dir_path, str):\n        if dir_path.startswith(\"s3://\") and _BOTO3_AVAILABLE:\n            parsed_url = parse.urlparse(dir_path)\n            bucket = parsed_url.netloc\n            key = parsed_url.path.lstrip('/')\n            s3 = boto3.client('s3')\n            try:\n                s3.head_object(Bucket=bucket, Key=key)\n                return Dir(path=dir_path, url=dir_path)\n            except botocore.exceptions.ClientError as e:\n                if e.response['Error']['Code'] == \"404\":\n                    raise FileNotFoundError(f\"The S3 object at {dir_path} does not exist.\")\n                else:\n                    raise\n        elif dir_path.startswith(\"http://\") or dir_path.startswith(\"https://\"):\n            return Dir(path=None, url=dir_path)\n        else:\n            return Dir(path=dir_path, url=None)\n    else:\n        raise ValueError(\"Invalid dir_path type. Expected str or Dir.\")"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "\n    if isinstance(dir_path, Dir):\n        return dir_path  # If dir_path is already a Dir object, return it as is\n    elif isinstance(dir_path, str):\n        if dir_path.startswith(\"s3://\"):\n            # Handle S3 URL\n            parsed_url = parse.urlparse(dir_path)\n            return Dir(path=None, url=dir_path)\n        else:\n            # Handle local path\n            return Dir(path=dir_path, url=None)\n    else:\n        return Dir(path=None, url=None)  # Return an empty Dir object if dir_path is None or of unknown type"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if \"s3://\" in dir_path:\n        parsed_url = parse.urlparse(dir_path)\n        return Dir(path=None, url=dir_path)\n\n    if _LIGHTNING_SDK_AVAILABLE and Machine.is_project_path(dir_path):\n        return Dir(path=dir_path, url=Studio.get_project_url(dir_path))\n\n    return Dir(path=dir_path)"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if \"s3://\" in dir_path:\n        parsed_url = parse.urlparse(dir_path)\n        return Dir(path=None, url=dir_path)\n\n    if _LIGHTNING_SDK_AVAILABLE and Machine.is_project_path(dir_path):\n        return Dir(path=dir_path, url=Studio.get_remote_url(dir_path))\n\n    return Dir(path=dir_path)"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n    elif isinstance(dir_path, str):\n        if dir_path.startswith(\"s3://\"):\n            parsed_url = parse.urlparse(dir_path)\n            return Dir(path=None, url=dir_path)\n        elif re.match(r\"^\\w+://\", dir_path):\n            return Dir(path=None, url=dir_path)\n        else:\n            return Dir(path=dir_path, url=None)\n    else:\n        return Dir(path=None, url=None)"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if \"s3://\" in dir_path:\n        url_components = parse.urlparse(dir_path)\n        return Dir(path=None, url=dir_path)\n\n    if _LIGHTNING_SDK_AVAILABLE and Machine.current():\n        project_path = Studio.current().project_path\n        if dir_path.startswith(project_path):\n            return Dir(path=dir_path)\n\n    return Dir(path=dir_path)"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n    elif isinstance(dir_path, str):\n        if dir_path.startswith(\"s3://\"):\n            parsed_url = parse.urlparse(dir_path)\n            return Dir(path=None, url=dir_path)\n        elif _LIGHTNING_SDK_AVAILABLE and Machine.is_project_path(dir_path):\n            project = Machine.project_from_path(dir_path)\n            url = f\"{Studio.get_instance().base_url}/projects/{project.id}/files/{dir_path}\"\n            return Dir(path=dir_path, url=url)\n        else:\n            return Dir(path=dir_path)\n    else:\n        return Dir()"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if isinstance(dir_path, str):\n        if dir_path.startswith(\"s3://\"):\n            return Dir(path=None, url=dir_path)\n        elif dir_path.startswith(\"http://\") or dir_path.startswith(\"https://\"):\n            return Dir(path=None, url=dir_path)\n        else:\n            return Dir(path=dir_path)\n\n    return Dir()"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "\n    class DNSOptimizationContext:\n        def __init__(self, enable: bool):\n            self.enable = enable\n            self.previous_state = None\n\n        def __enter__(self):\n            if self.enable:\n                # Enable DNS optimization\n                self.previous_state = os.getenv(\"DNS_OPTIMIZATION_ENABLED\", None)\n                os.environ[\"DNS_OPTIMIZATION_ENABLED\"] = \"1\"\n            else:\n                # Disable DNS optimization\n                self.previous_state = os.getenv(\"DNS_OPTIMIZATION_ENABLED\", None)\n                os.environ[\"DNS_OPTIMIZATION_ENABLED\"] = \"0\"\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            # Reset DNS optimization to previous state\n            if self.previous_state is not None:\n                os.environ[\"DNS_OPTIMIZATION_ENABLED\"] = self.previous_state\n            else:\n                del os.environ[\"DNS_OPTIMIZATION_ENABLED\"]\n\n    return DNSOptimizationContext(enable)"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    class DNSOptimizationContext:\n        def __init__(self, enable: bool):\n            self.enable = enable\n            self.previous_setting = None\n\n        def __enter__(self):\n            if self.enable:\n                # Enable DNS optimization\n                self.previous_setting = os.getenv(\"DNS_OPTIMIZATION_ENABLED\", None)\n                os.environ[\"DNS_OPTIMIZATION_ENABLED\"] = \"True\"\n            else:\n                # Disable DNS optimization\n                self.previous_setting = os.getenv(\"DNS_OPTIMIZATION_ENABLED\", None)\n                os.environ[\"DNS_OPTIMIZATION_ENABLED\"] = \"False\"\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            # Reset DNS optimization to previous setting\n            if self.previous_setting is not None:\n                os.environ[\"DNS_OPTIMIZATION_ENABLED\"] = self.previous_setting\n            else:\n                os.environ.pop(\"DNS_OPTIMIZATION_ENABLED\", None)\n\n    return DNSOptimizationContext(enable)"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    class DNSOptimizationContext:\n        def __enter__(self):\n            if enable:\n                # Enable DNS optimization\n                self.process = Popen([\"sudo\", \"networksetup\", \"-setdnsservers\", \"Wi-Fi\", \"8.8.8.8\"], stdout=DEVNULL, stderr=DEVNULL)\n            return self\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            # Always disable DNS optimization after operations\n            if self.process:\n                self.process.terminate()\n\n    return DNSOptimizationContext()"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "\n    class DNSOptimizationContext:\n        def __enter__(self):\n            if enable:\n                # Enable DNS optimization\n                with open(os.devnull, 'w') as devnull:\n                    Popen(['sudo', 'networksetup', '-setdnsservers', 'Wi-Fi', '8.8.8.8'], stdout=devnull, stderr=devnull)\n\n        def __exit__(self, exc_type, exc_val, exc_tb):\n            # Always disable DNS optimization after the operations\n            with open(os.devnull, 'w') as devnull:\n                Popen(['sudo', 'networksetup', '-setdnsservers', 'Wi-Fi', 'empty'], stdout=devnull, stderr=devnull)\n\n    return DNSOptimizationContext()"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "\n    class DnsContextManager:\n        def __init__(self, enable: bool):\n            self.enable = enable\n            self.previous_state = None\n\n        def __enter__(self):\n            if self.enable:\n                # Enable DNS optimization\n                self.previous_state = os.environ.get(\"DATA_OPTIMIZER_GLOBAL_RANK\", None)\n                os.environ[\"DATA_OPTIMIZER_GLOBAL_RANK\"] = \"1\"\n            else:\n                # Disable DNS optimization\n                self.previous_state = os.environ.get(\"DATA_OPTIMIZER_GLOBAL_RANK\", None)\n                os.environ[\"DATA_OPTIMIZER_GLOBAL_RANK\"] = \"0\"\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            # Reset DNS optimization to previous state\n            if self.previous_state is not None:\n                os.environ[\"DATA_OPTIMIZER_GLOBAL_RANK\"] = self.previous_state\n            else:\n                os.environ.pop(\"DATA_OPTIMIZER_GLOBAL_RANK\", None)\n\n    return DnsContextManager(enable)"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "\n    class DNSOptimizationContext:\n        def __enter__(self):\n            if enable:\n                # Enable DNS optimization\n                process = Popen([\"sudo\", \"launchctl\", \"kickstart\", \"-k\", \"network\"], stdout=DEVNULL, stderr=DEVNULL)\n                process.communicate()\n            else:\n                # Disable DNS optimization\n                process = Popen([\"sudo\", \"launchctl\", \"kickstart\", \"-k\", \"network\"], stdout=DEVNULL, stderr=DEVNULL)\n                process.communicate()\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            # Always ensure DNS optimization is disabled after the operations\n            process = Popen([\"sudo\", \"launchctl\", \"kickstart\", \"-k\", \"network\"], stdout=DEVNULL, stderr=DEVNULL)\n            process.communicate()\n\n    return DNSOptimizationContext()"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    class DNSOptimizationContext:\n        def __init__(self, enable: bool):\n            self.enable = enable\n            self.previous_state = None\n\n        def __enter__(self):\n            if self.enable:\n                # Enable DNS optimization\n                self.previous_state = os.getenv(\"DATA_OPTIMIZER_GLOBAL_RANK\")\n                os.environ[\"DATA_OPTIMIZER_GLOBAL_RANK\"] = \"1\"\n            else:\n                # Disable DNS optimization\n                self.previous_state = os.getenv(\"DATA_OPTIMIZER_GLOBAL_RANK\")\n                os.environ[\"DATA_OPTIMIZER_GLOBAL_RANK\"] = \"0\"\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            # Reset DNS optimization to previous state\n            if self.previous_state is not None:\n                os.environ[\"DATA_OPTIMIZER_GLOBAL_RANK\"] = self.previous_state\n\n    return DNSOptimizationContext(enable)"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "\n    class DNSOptimizationContext:\n        def __init__(self, enable: bool):\n            self.enable = enable\n            self.previous_state = None\n\n        def __enter__(self):\n            if self.enable:\n                # Enable DNS optimization\n                self.previous_state = os.getenv(\"LIGHTNING_CLOUD_DNS_OPTIMIZATION\", None)\n                os.environ[\"LIGHTNING_CLOUD_DNS_OPTIMIZATION\"] = \"1\"\n            else:\n                # Disable DNS optimization\n                self.previous_state = os.getenv(\"LIGHTNING_CLOUD_DNS_OPTIMIZATION\", None)\n                os.environ[\"LIGHTNING_CLOUD_DNS_OPTIMIZATION\"] = \"0\"\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            # Reset DNS optimization to previous state\n            if self.previous_state is not None:\n                os.environ[\"LIGHTNING_CLOUD_DNS_OPTIMIZATION\"] = self.previous_state\n            else:\n                del os.environ[\"LIGHTNING_CLOUD_DNS_OPTIMIZATION\"]\n\n    return DNSOptimizationContext(enable)"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    class DnsContext:\n        def __enter__(self):\n            if enable:\n                # Enable DNS optimization\n                p = Popen([\"sudo\", \"networksetup\", \"-setdnsservers\", \"Wi-Fi\", \"127.0.0.1\"], stdout=DEVNULL, stderr=DEVNULL)\n                p.wait()\n            return self\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            # Disable DNS optimization\n            p = Popen([\"sudo\", \"networksetup\", \"-setdnsservers\", \"Wi-Fi\", \"empty\"], stdout=DEVNULL, stderr=DEVNULL)\n            p.wait()\n\n    return DnsContext()"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "\n    class DNSOptimizationContext:\n        def __enter__(self):\n            if enable:\n                # Enable DNS optimization\n                process = Popen([\"sudo\", \"networksetup\", \"-setdnsservers\", \"Wi-Fi\", \"empty\"], stdout=DEVNULL, stderr=DEVNULL)\n                process.wait()\n            return self\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            # Disable DNS optimization\n            process = Popen([\"sudo\", \"networksetup\", \"-setdnsservers\", \"Wi-Fi\", \"empty\"], stdout=DEVNULL, stderr=DEVNULL)\n            process.wait()\n\n    return DNSOptimizationContext()"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    class DNSOptimizationContext:\n        def __init__(self, enable: bool):\n            self.enable = enable\n            self.previous_setting = None\n\n        def __enter__(self):\n            if self.enable:\n                # Enable DNS optimization\n                self.previous_setting = os.getenv(\"LIGHTNING_CLOUD_LATEST\")\n                os.environ[\"LIGHTNING_CLOUD_LATEST\"] = \"True\"\n            else:\n                # Disable DNS optimization\n                self.previous_setting = os.getenv(\"LIGHTNING_CLOUD_LATEST\")\n                os.environ[\"LIGHTNING_CLOUD_LATEST\"] = \"False\"\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            # Reset DNS optimization to previous setting\n            if self.previous_setting is not None:\n                os.environ[\"LIGHTNING_CLOUD_LATEST\"] = self.previous_setting\n            else:\n                os.environ.pop(\"LIGHTNING_CLOUD_LATEST\", None)\n\n    return DNSOptimizationContext(enable)"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    class DNSOptimizationContext:\n        def __enter__(self):\n            if enable:\n                # Enable DNS optimization\n                subprocess.run([\"sudo\", \"networksetup\", \"-setdnsservers\", \"Wi-Fi\", \"empty\"], stdout=DEVNULL, stderr=DEVNULL)\n            else:\n                # Disable DNS optimization\n                subprocess.run([\"sudo\", \"networksetup\", \"-setdnsservers\", \"Wi-Fi\", \"empty\"], stdout=DEVNULL, stderr=DEVNULL)\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            # Always disable DNS optimization after operations\n            subprocess.run([\"sudo\", \"networksetup\", \"-setdnsservers\", \"Wi-Fi\", \"empty\"], stdout=DEVNULL, stderr=DEVNULL)\n\n    return DNSOptimizationContext()"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "\n    class DNSOptimizationContext:\n        def __init__(self, enable: bool):\n            self.enable = enable\n            self.previous_state = None\n\n        def __enter__(self):\n            if self.enable:\n                # Enable DNS optimization\n                self.previous_state = os.getenv(\"DATA_OPTIMIZER_GLOBAL_RANK\")\n                os.environ[\"DATA_OPTIMIZER_GLOBAL_RANK\"] = \"1\"\n            else:\n                # Disable DNS optimization\n                self.previous_state = os.getenv(\"DATA_OPTIMIZER_GLOBAL_RANK\")\n                os.environ[\"DATA_OPTIMIZER_GLOBAL_RANK\"] = \"0\"\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            # Reset DNS optimization to previous state\n            if self.previous_state is not None:\n                os.environ[\"DATA_OPTIMIZER_GLOBAL_RANK\"] = self.previous_state\n\n    return DNSOptimizationContext(enable)"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "\n    class DNSOptimizationContext:\n        def __enter__(self):\n            if enable:\n                # Enable DNS optimization\n                process = Popen([\"sudo\", \"networksetup\", \"-setdnsservers\", \"Wi-Fi\", \"8.8.8.8\"], stdout=DEVNULL, stderr=DEVNULL)\n                process.wait()\n            else:\n                # Disable DNS optimization\n                process = Popen([\"sudo\", \"networksetup\", \"-setdnsservers\", \"Wi-Fi\", \"empty\"], stdout=DEVNULL, stderr=DEVNULL)\n                process.wait()\n\n        def __exit__(self, exc_type, exc_val, exc_tb):\n            # Always disable DNS optimization after the operations are done\n            process = Popen([\"sudo\", \"networksetup\", \"-setdnsservers\", \"Wi-Fi\", \"empty\"], stdout=DEVNULL, stderr=DEVNULL)\n            process.wait()\n\n    return DNSOptimizationContext()"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    try:\n        original_dns_value = os.getenv(\"LIGHTNING_CLOUD_OPTIMIZE_DNS\", None)\n        if enable:\n            os.environ[\"LIGHTNING_CLOUD_OPTIMIZE_DNS\"] = \"1\"\n        else:\n            os.environ[\"LIGHTNING_CLOUD_OPTIMIZE_DNS\"] = \"0\"\n        yield\n    finally:\n        if original_dns_value is not None:\n            os.environ[\"LIGHTNING_CLOUD_OPTIMIZE_DNS\"] = original_dns_value\n        else:\n            del os.environ[\"LIGHTNING_CLOUD_OPTIMIZE_DNS\"]"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "\n    class DNSOptimizationContext:\n        def __init__(self, enable: bool):\n            self.enable = enable\n            self.original_dns_setting = None\n\n        def __enter__(self):\n            if self.enable:\n                # Enable DNS optimization\n                self.original_dns_setting = os.getenv(\"DNS_OPTIMIZATION\")\n                os.environ[\"DNS_OPTIMIZATION\"] = \"enabled\"\n            else:\n                # Disable DNS optimization\n                self.original_dns_setting = os.getenv(\"DNS_OPTIMIZATION\")\n                os.environ[\"DNS_OPTIMIZATION\"] = \"disabled\"\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            os.environ[\"DNS_OPTIMIZATION\"] = self.original_dns_setting\n\n    return DNSOptimizationContext(enable)"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    class DnsOptimizationContext:\n        def __enter__(self):\n            if enable:\n                # Enable DNS optimization\n                p = Popen([\"sudo\", \"networksetup\", \"-setdnsservers\", \"Wi-Fi\", \"8.8.8.8\"], stdout=DEVNULL, stderr=DEVNULL)\n                p.wait()\n            return self\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            # Disable DNS optimization\n            p = Popen([\"sudo\", \"networksetup\", \"-setdnsservers\", \"Wi-Fi\", \"empty\"], stdout=DEVNULL, stderr=DEVNULL)\n            p.wait()\n\n    return DnsOptimizationContext()"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "\n    class DNSOptimizationContext:\n        def __init__(self, enable: bool):\n            self.enable = enable\n\n        def __enter__(self):\n            if self.enable:\n                # Enable DNS optimization\n                process = Popen([\"sudo\", \"networksetup\", \"-setdnsservers\", \"Wi-Fi\", \"empty\"], stdout=DEVNULL, stderr=DEVNULL)\n                process.wait()\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            # Always disable DNS optimization after operations\n            process = Popen([\"sudo\", \"networksetup\", \"-setdnsservers\", \"Wi-Fi\", \"empty\"], stdout=DEVNULL, stderr=DEVNULL)\n            process.wait()\n\n    return DNSOptimizationContext(enable)"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "\n    class DnsOptimizationContext:\n        def __init__(self, enable: bool):\n            self.enable = enable\n            self.previous_state = None\n\n        def __enter__(self):\n            if self.enable:\n                self.previous_state = os.getenv(\"LIGHTNING_CLOUD_DNS_OPTIMIZATION\")\n                os.environ[\"LIGHTNING_CLOUD_DNS_OPTIMIZATION\"] = \"1\"\n            else:\n                self.previous_state = os.getenv(\"LIGHTNING_CLOUD_DNS_OPTIMIZATION\")\n                os.environ[\"LIGHTNING_CLOUD_DNS_OPTIMIZATION\"] = \"0\"\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            if self.previous_state is not None:\n                os.environ[\"LIGHTNING_CLOUD_DNS_OPTIMIZATION\"] = self.previous_state\n            else:\n                os.environ.pop(\"LIGHTNING_CLOUD_DNS_OPTIMIZATION\", None)\n\n    return DnsOptimizationContext(enable)"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    class _OptimizeDnsContext:\n        def __init__(self, enable: bool):\n            self.enable = enable\n            self.previous_setting = None\n\n        def __enter__(self):\n            if self.enable:\n                # Enable DNS optimization\n                self.previous_setting = os.environ.get(\"PYTHONDNSOPTIMIZE\")\n                os.environ[\"PYTHONDNSOPTIMIZE\"] = \"1\"\n            else:\n                # Disable DNS optimization\n                self.previous_setting = os.environ.get(\"PYTHONDNSOPTIMIZE\")\n                os.environ[\"PYTHONDNSOPTIMIZE\"] = \"0\"\n\n        def __exit__(self, exc_type, exc_value, traceback):\n            # Reset DNS optimization to previous setting\n            if self.previous_setting is not None:\n                os.environ[\"PYTHONDNSOPTIMIZE\"] = self.previous_setting\n            else:\n                os.environ.pop(\"PYTHONDNSOPTIMIZE\", None)\n\n    return _OptimizeDnsContext(enable)"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    total_chunks = len(indexes)\n    chunks_per_rank = total_chunks // distributed_env.world_size\n    remainder = total_chunks % distributed_env.world_size\n\n    chunks_per_ranks = []\n    start = 0\n    for rank in range(distributed_env.world_size):\n        if rank < remainder:\n            end = start + chunks_per_rank + 1\n        else:\n            end = start + chunks_per_rank\n        if end > total_chunks:\n            end = total_chunks\n        chunks_per_ranks.append(indexes[start:end])\n        start = end\n\n    chunk_intervals_per_ranks = []\n    start = 0\n    for rank_chunks in chunks_per_ranks:\n        rank_intervals = []\n        for chunk_index in rank_chunks:\n            rank_intervals.append(chunk_intervals[chunk_index])\n        chunk_intervals_per_ranks.append(rank_intervals)\n\n    if drop_last and remainder > 0:\n        chunks_per_ranks = chunks_per_ranks[:-1]\n        chunk_intervals_per_ranks = chunk_intervals_per_ranks[:-1]\n\n    return chunks_per_ranks, chunk_intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    total_chunks = len(indexes)\n    chunks_per_rank = total_chunks // distributed_env.world_size\n    if drop_last:\n        chunks_per_ranks = [indexes[i * chunks_per_rank: (i + 1) * chunks_per_rank] for i in range(distributed_env.world_size)]\n    else:\n        chunks_per_ranks = [indexes[i * chunks_per_rank: (i + 1) * chunks_per_rank] for i in range(distributed_env.world_size - 1)]\n        chunks_per_ranks.append(indexes[(distributed_env.world_size - 1) * chunks_per_rank:])\n\n    # Associate chunk intervals to ranks\n    chunk_intervals_per_ranks = []\n    start = 0\n    for chunks in chunks_per_ranks:\n        end = start + len(chunks)\n        chunk_intervals_per_ranks.append(chunk_intervals[start:end])\n        start = end\n\n    return chunks_per_ranks, chunk_intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    total_chunks = len(indexes)\n    chunks_per_rank = total_chunks // distributed_env.world_size\n    remainder = total_chunks % distributed_env.world_size\n\n    chunks_per_ranks = []\n    chunk_intervals_per_ranks = []\n\n    start = 0\n    for rank in range(distributed_env.world_size):\n        num_chunks = chunks_per_rank + (1 if rank < remainder else 0)\n        end = start + num_chunks\n        chunks_per_ranks.append(indexes[start:end])\n        chunk_intervals_per_ranks.append(chunk_intervals[start:end])\n        start = end\n\n    if drop_last and remainder > 0:\n        chunks_per_ranks[-1] = chunks_per_ranks[-1][:-1]\n        chunk_intervals_per_ranks[-1] = chunk_intervals_per_ranks[-1][:-1]\n\n    return chunks_per_ranks, chunk_intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    total_chunks = len(indexes)\n    chunks_per_rank = total_chunks // distributed_env.world_size\n    remainder = total_chunks % distributed_env.world_size\n\n    chunks_per_ranks = []\n    start = 0\n    for rank in range(distributed_env.world_size):\n        num_chunks = chunks_per_rank + (1 if rank < remainder else 0)\n        end = start + num_chunks\n        chunks_per_ranks.append(indexes[start:end])\n        start = end\n\n    intervals_per_ranks = []\n    start = 0\n    for rank in range(distributed_env.world_size):\n        num_chunks = len(chunks_per_ranks[rank])\n        end = start + num_chunks\n        intervals_per_ranks.append(chunk_intervals[start:end])\n        start = end\n\n    if drop_last and remainder > 0:\n        chunks_per_ranks[-1].extend(chunks_per_ranks[-2])\n        del chunks_per_ranks[-2]\n        intervals_per_ranks[-1].extend(intervals_per_ranks[-2])\n        del intervals_per_ranks[-2]\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    total_items = len(indexes)\n    items_per_rank = total_items // distributed_env.world_size\n    remainder = total_items % distributed_env.world_size\n\n    chunks_per_ranks = []\n    intervals_per_ranks = []\n\n    start = 0\n    for rank in range(distributed_env.world_size):\n        num_items = items_per_rank + (1 if rank < remainder else 0)\n        end = start + num_items\n        chunks_per_ranks.append(indexes[start:end])\n        intervals_per_ranks.append(chunk_intervals[start:end])\n        start = end\n\n    if drop_last and remainder > 0:\n        chunks_per_ranks[-1] = chunks_per_ranks[-1][:-1]\n        intervals_per_ranks[-1] = intervals_per_ranks[-1][:-1]\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    total_chunks = len(indexes)\n    chunks_per_rank = total_chunks // distributed_env.world_size\n    if not drop_last and total_chunks % distributed_env.world_size != 0:\n        chunks_per_rank += 1\n\n    chunks_per_ranks = [indexes[i * chunks_per_rank: (i + 1) * chunks_per_rank] for i in range(distributed_env.world_size)]\n    if drop_last:\n        chunks_per_ranks[-1] = indexes[chunks_per_rank * (distributed_env.world_size - 1):]\n\n    intervals_per_ranks = []\n    for chunk_interval in chunk_intervals:\n        start, end = chunk_interval\n        interval_per_rank = []\n        for i in range(distributed_env.world_size):\n            chunk_start = max(start, i * chunks_per_rank)\n            chunk_end = min(end, (i + 1) * chunks_per_rank)\n            if not drop_last and i == distributed_env.world_size - 1:\n                chunk_end = end\n            interval_per_rank.append((chunk_start, chunk_end))\n        intervals_per_ranks.append(interval_per_rank)\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    total_items = len(indexes)\n    items_per_rank = total_items // distributed_env.world_size\n    remainder = total_items % distributed_env.world_size\n\n    chunks_per_ranks = []\n    intervals_per_ranks = []\n\n    start = 0\n    for rank in range(distributed_env.world_size):\n        num_items = items_per_rank + (1 if rank < remainder else 0)\n        end = start + num_items\n\n        chunk_indexes = indexes[start:end]\n        chunk_intervals = chunk_intervals[start:end]\n\n        chunks_per_ranks.append(chunk_indexes)\n        intervals_per_ranks.append(chunk_intervals)\n\n        start = end\n\n    if drop_last and remainder > 0:\n        chunks_per_ranks[-1] = chunks_per_ranks[-1][:-1]\n        intervals_per_ranks[-1] = intervals_per_ranks[-1][:-1]\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    total_items = len(indexes)\n    items_per_rank = total_items // distributed_env.world_size\n    remainder = total_items % distributed_env.world_size\n\n    chunks_per_ranks = []\n    intervals_per_ranks = []\n\n    start = 0\n    for rank in range(distributed_env.world_size):\n        num_items = items_per_rank + (1 if rank < remainder else 0)\n        end = start + num_items\n        chunks_per_ranks.append(indexes[start:end])\n        intervals_per_ranks.append(chunk_intervals[start:end])\n        start = end\n\n    if drop_last and remainder > 0:\n        chunks_per_ranks[-1] = chunks_per_ranks[-1][:-1]\n        intervals_per_ranks[-1] = intervals_per_ranks[-1][:-1]\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    total_chunks = len(indexes)\n    chunks_per_rank = total_chunks // distributed_env.world_size\n    remainder = total_chunks % distributed_env.world_size\n\n    chunks_per_ranks = []\n    start = 0\n    for rank in range(distributed_env.world_size):\n        num_chunks = chunks_per_rank + (1 if rank < remainder else 0)\n        end = start + num_chunks\n        chunks_per_ranks.append(indexes[start:end])\n        start = end\n\n    chunk_intervals_per_ranks = []\n    start = 0\n    for rank in range(distributed_env.world_size):\n        num_chunks = len(chunks_per_ranks[rank])\n        end = start + num_chunks\n        chunk_intervals_per_ranks.append(chunk_intervals[start:end])\n        start = end\n\n    if drop_last and remainder > 0:\n        chunks_per_ranks[-1] = chunks_per_ranks[-1][:-1]\n        chunk_intervals_per_ranks[-1] = chunk_intervals_per_ranks[-1][:-1]\n\n    return chunks_per_ranks, chunk_intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    total_items = len(indexes)\n    items_per_rank = total_items // distributed_env.world_size\n    remainder = total_items % distributed_env.world_size\n\n    # Calculate the number of items each rank should process\n    items_per_rank_list = [items_per_rank] * distributed_env.world_size\n    if not drop_last and remainder > 0:\n        for i in range(remainder):\n            items_per_rank_list[i] += 1\n\n    # Assign chunks and their intervals to each rank accordingly\n    chunks_per_ranks = []\n    intervals_per_ranks = []\n\n    start = 0\n    for i in range(distributed_env.world_size):\n        end = start + items_per_rank_list[i]\n        if i < remainder and not drop_last:\n            end += 1\n\n        chunks_per_ranks.append(indexes[start:end])\n        intervals_per_ranks.append(chunk_intervals[start:end])\n\n        start = end\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    total_chunks = len(indexes)\n    chunks_per_rank = total_chunks // distributed_env.world_size\n    remainder = total_chunks % distributed_env.world_size\n\n    chunks_per_ranks = [chunks_per_rank + 1 if i < remainder else chunks_per_rank for i in range(distributed_env.world_size)]\n\n    if drop_last and remainder > 0:\n        chunks_per_ranks[-1] -= 1\n\n    # distribute chunks to ranks\n    distributed_chunks = []\n    start = 0\n    for num_chunks in chunks_per_ranks:\n        end = start + num_chunks\n        distributed_chunks.append(indexes[start:end])\n        start = end\n\n    # associate intervals to ranks\n    distributed_intervals = []\n    start = 0\n    for num_chunks in chunks_per_ranks:\n        end = start + num_chunks\n        distributed_intervals.append(chunk_intervals[start:end])\n        start = end\n\n    return distributed_chunks, distributed_intervals"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    total_chunks = len(indexes)\n    chunks_per_rank = total_chunks // distributed_env.world_size\n    remainder = total_chunks % distributed_env.world_size\n\n    # Calculate the number of chunks each rank should process\n    chunks_per_ranks = [chunks_per_rank + 1 if i < remainder else chunks_per_rank for i in range(distributed_env.world_size)]\n\n    # Assign chunks and intervals to each rank\n    chunk_indexes_per_ranks = []\n    chunk_intervals_per_ranks = []\n\n    start = 0\n    for i in range(distributed_env.world_size):\n        end = start + chunks_per_ranks[i]\n        if i < remainder:\n            end += 1\n        chunk_indexes_per_ranks.append(indexes[start:end])\n        chunk_intervals_per_ranks.append(chunk_intervals[start:end])\n        start = end\n\n    return chunk_indexes_per_ranks, chunk_intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    total_chunks = len(indexes)\n    chunks_per_rank = total_chunks // distributed_env.world_size\n    remainder = total_chunks % distributed_env.world_size\n\n    chunks_per_ranks = []\n    start = 0\n    for rank in range(distributed_env.world_size):\n        num_chunks = chunks_per_rank + (1 if rank < remainder else 0)\n        end = start + num_chunks\n        chunks_per_ranks.append(indexes[start:end])\n        start = end\n\n    if drop_last and remainder > 0:\n        chunks_per_ranks[-1] = chunks_per_ranks[-1][:-1]\n\n    intervals_per_ranks = []\n    for rank_chunks in chunks_per_ranks:\n        intervals = [chunk_intervals[i] for i in rank_chunks]\n        intervals_per_ranks.append(intervals)\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    total_chunks = len(indexes)\n    chunks_per_rank = total_chunks // distributed_env.world_size\n    remainder = total_chunks % distributed_env.world_size\n\n    chunks_per_ranks = []\n    start = 0\n    for rank in range(distributed_env.world_size):\n        num_chunks = chunks_per_rank + (1 if rank < remainder else 0)\n        end = start + num_chunks\n        chunks_per_ranks.append(indexes[start:end])\n        start = end\n\n    interval_per_ranks = []\n    start = 0\n    for rank in range(distributed_env.world_size):\n        num_chunks = len(chunks_per_ranks[rank])\n        intervals = chunk_intervals[start : start + num_chunks]\n        interval_per_ranks.append(intervals)\n        start += num_chunks\n\n    if drop_last and remainder > 0:\n        chunks_per_ranks[-1] = []\n        interval_per_ranks[-1] = []\n\n    return chunks_per_ranks, interval_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    total_chunks = len(indexes)\n    chunks_per_rank = total_chunks // distributed_env.world_size\n    remainder = total_chunks % distributed_env.world_size\n\n    chunks_per_ranks = [\n        [i * chunks_per_rank + min(i, remainder), (i + 1) * chunks_per_rank + min(i + 1, remainder)]\n        for i in range(distributed_env.world_size)\n    ]\n\n    if drop_last:\n        chunks_per_ranks[-1][1] -= 1\n\n    chunk_indexes_per_ranks = [[] for _ in range(distributed_env.world_size)]\n    chunk_intervals_per_ranks = [[] for _ in range(distributed_env.world_size)]\n\n    for i, (start, end) in enumerate(chunk_intervals):\n        for rank, (rank_start, rank_end) in enumerate(chunks_per_ranks):\n            if start >= rank_start and end <= rank_end:\n                chunk_indexes_per_ranks[rank].append(indexes[i])\n                chunk_intervals_per_ranks[rank].append((start, end))\n                break\n\n    return chunk_indexes_per_ranks, chunk_intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    total_items = len(indexes)\n    items_per_rank = total_items // distributed_env.world_size\n    remainder = total_items % distributed_env.world_size\n\n    chunks_per_ranks = []\n    intervals_per_ranks = []\n\n    start = 0\n    for rank in range(distributed_env.world_size):\n        num_items = items_per_rank + (1 if rank < remainder else 0)\n        end = start + num_items\n        chunks_per_ranks.append(indexes[start:end])\n        intervals_per_ranks.append(chunk_intervals[start:end])\n        start = end\n\n    if drop_last and remainder > 0:\n        chunks_per_ranks[-1].extend(indexes[-remainder:])\n        intervals_per_ranks[-1].extend(chunk_intervals[-remainder:])\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    total_chunks = len(indexes)\n    chunks_per_rank = total_chunks // distributed_env.world_size\n    remainder = total_chunks % distributed_env.world_size\n\n    chunks_per_ranks = []\n    start = 0\n    for rank in range(distributed_env.world_size):\n        num_chunks = chunks_per_rank + (1 if rank < remainder else 0)\n        end = start + num_chunks\n        chunks_per_ranks.append(indexes[start:end])\n        start = end\n\n    if drop_last and remainder > 0:\n        chunks_per_ranks[-1] = chunks_per_ranks[-1][:-1]\n\n    intervals_per_ranks = []\n    for chunks in chunks_per_ranks:\n        intervals = [chunk_intervals[i] for i in chunks]\n        intervals_per_ranks.append(intervals)\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    total_chunks = len(indexes)\n    chunks_per_rank = total_chunks // distributed_env.world_size\n    remainder = total_chunks % distributed_env.world_size\n\n    chunks_per_ranks = []\n    start = 0\n    for i in range(distributed_env.world_size):\n        num_chunks = chunks_per_rank + (1 if i < remainder else 0)\n        end = start + num_chunks\n        chunks_per_ranks.append(indexes[start:end])\n        start = end\n\n    intervals_per_ranks = []\n    start = 0\n    for chunks in chunks_per_ranks:\n        intervals = []\n        for chunk_index in chunks:\n            intervals.append(chunk_intervals[chunk_index])\n        intervals_per_ranks.append(intervals)\n\n    if drop_last and remainder > 0:\n        chunks_per_ranks[-1] = chunks_per_ranks[-1][:-1]\n        intervals_per_ranks[-1] = intervals_per_ranks[-1][:-1]\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    total_chunks = len(indexes)\n    chunks_per_rank = total_chunks // distributed_env.world_size\n    remainder = total_chunks % distributed_env.world_size\n\n    chunks_per_ranks = []\n    start = 0\n    for rank in range(distributed_env.world_size):\n        num_chunks = chunks_per_rank + (1 if rank < remainder else 0)\n        end = start + num_chunks\n        chunks_per_ranks.append(indexes[start:end])\n        start = end\n\n    intervals_per_ranks = []\n    start = 0\n    for rank in range(distributed_env.world_size):\n        num_chunks = len(chunks_per_ranks[rank])\n        end = start + num_chunks\n        intervals_per_ranks.append(chunk_intervals[start:end])\n        start = end\n\n    if drop_last and remainder > 0:\n        chunks_per_ranks[-1] = []\n        intervals_per_ranks[-1] = []\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    total_chunks = len(indexes)\n    chunks_per_rank = total_chunks // distributed_env.world_size\n    remainder = total_chunks % distributed_env.world_size\n\n    chunks_per_ranks = []\n    start = 0\n    for rank in range(distributed_env.world_size):\n        num_chunks = chunks_per_rank + (1 if rank < remainder else 0)\n        end = start + num_chunks\n        chunks_per_ranks.append(indexes[start:end])\n        start = end\n\n    chunk_intervals_per_ranks = []\n    start = 0\n    for rank in range(distributed_env.world_size):\n        num_chunks = len(chunks_per_ranks[rank])\n        end = start + num_chunks\n        chunk_intervals_per_ranks.append(chunk_intervals[start:end])\n        start = end\n\n    if drop_last and remainder > 0:\n        chunks_per_ranks[-1] = []\n\n    return chunks_per_ranks, chunk_intervals_per_ranks"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs: Dict[str, Any] = {\"output_dir\": output_dir}\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, **kwargs)"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_device:\n            self._fn(item_metadata, output_dir, device=self._device, is_last=is_last)\n        else:\n            self._fn(item_metadata, output_dir, is_last=is_last)"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_device:\n            self._fn(item_metadata, output_dir, device=self._device)\n        else:\n            self._fn(item_metadata, output_dir)\n\n        if self._contains_is_last:\n            self._fn(item_metadata, output_dir, is_last=is_last)"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_device:\n            self._fn(item_metadata, output_dir, device=self._device)\n        elif self._contains_is_last:\n            self._fn(item_metadata, output_dir, is_last=is_last)\n        else:\n            self._fn(item_metadata, output_dir)"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_device:\n            self._fn(item_metadata, output_dir, device=self._device)\n        else:\n            if self._contains_is_last:\n                self._fn(item_metadata, output_dir, is_last=is_last)\n            else:\n                self._fn(item_metadata, output_dir)"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_device:\n            self._fn(item_metadata, output_dir, device=self._device)\n        elif self._contains_is_last:\n            self._fn(item_metadata, output_dir, is_last=is_last)\n        else:\n            self._fn(item_metadata, output_dir)"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_device:\n            self._fn(item_metadata, output_dir, device=self._device)\n        elif self._contains_is_last:\n            self._fn(item_metadata, output_dir, is_last=is_last)\n        else:\n            self._fn(item_metadata, output_dir)"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_device:\n            self._fn(item_metadata, output_dir, device=self._device)\n        else:\n            if self._contains_is_last:\n                self._fn(item_metadata, output_dir, is_last=is_last)\n            else:\n                self._fn(item_metadata, output_dir)"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_is_last:\n            self._fn(item_metadata, output_dir, is_last)\n        else:\n            self._fn(item_metadata, output_dir)"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_is_last:\n            self._fn(item_metadata, output_dir, is_last)\n        else:\n            self._fn(item_metadata, output_dir)"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {\"device\": self._device} if self._contains_device else {}\n\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        # Call the transformation function with the provided arguments and keyword arguments\n        self._fn(item_metadata, output_dir, **kwargs)"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        device = self._device if self._contains_device else None\n        kwargs = {\"device\": device}\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {\"device\": self._device} if self._contains_device else {}\n\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs: Dict[str, Any] = {\"output_dir\": output_dir}\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, **kwargs)"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "    if self._contains_device:\n        self._fn(item_metadata, output_dir, device=self._device)\n    elif self._contains_is_last:\n        self._fn(item_metadata, output_dir, is_last=is_last)\n    else:\n        self._fn(item_metadata, output_dir)"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {\"device\": self._device} if self._contains_device else {}\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n        self._fn(item_metadata, output_dir, **kwargs)"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_device:\n            self._fn(item_metadata, output_dir, device=self._device)\n        else:\n            self._fn(item_metadata, output_dir)"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            error_code = e.response[\"Error\"][\"Code\"]\n            if error_code == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            error_code = e.response[\"Error\"][\"Code\"]\n            if error_code == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            if e.response['Error']['Code'] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            error_code = e.response[\"Error\"][\"Code\"]\n            if error_code == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            if e.response['Error']['Code'] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            if e.response['Error']['Code'] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            if e.response['Error']['Code'] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            if e.response['Error']['Code'] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip('/'))\n            return response\n        except botocore.exceptions.ClientError as e:\n            if e.response['Error']['Code'] == '404':\n                sleep(sleep_time)\n            else:\n                raise e"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            error_code = e.response[\"Error\"][\"Code\"]\n            if error_code == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            error_code = e.response[\"Error\"][\"Code\"]\n            if error_code == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            if e.response['Error']['Code'] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            error_code = e.response[\"Error\"][\"Code\"]\n            if error_code == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            error_code = e.response[\"Error\"][\"Code\"]\n            if error_code == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            response = s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n            return response\n        except botocore.exceptions.ClientError as e:\n            if e.response['Error']['Code'] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        stat = shutil.disk_usage(input_dir)\n        free_space_gb = stat.free / (2**30)  # Convert bytes to gigabytes\n        if free_space_gb < threshold_in_gb:\n            break\n        sleep(sleep_time)"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "\n    while True:\n        total, used, free = shutil.disk_usage(input_dir)\n        free_gb = free / (2**30)  # Convert bytes to gigabytes\n        if free_gb <= threshold_in_gb:\n            break\n        else:\n            sleep(sleep_time)"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        total, used, free = shutil.disk_usage(input_dir)\n        free_gb = free / (2**30)  # Convert bytes to gigabytes\n        if free_gb < threshold_in_gb:\n            break\n        sleep(sleep_time)"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        total, used, free = shutil.disk_usage(input_dir)\n        free_gb = free / 2**30  # convert bytes to gigabytes\n        if free_gb < threshold_in_gb:\n            break\n        sleep(sleep_time)"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        total, used, free = shutil.disk_usage(input_dir)\n        if free / (2**30) > threshold_in_gb:\n            sleep(sleep_time)\n        else:\n            break"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        total, used, free = shutil.disk_usage(input_dir)\n        free_gb = free / (2**30)  # Convert bytes to gigabytes\n        if free_gb <= threshold_in_gb:\n            break\n        sleep(sleep_time)"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    threshold_in_bytes = threshold_in_gb * (1024 ** 3)  # Convert threshold from GB to bytes\n    while True:\n        usage = shutil.disk_usage(input_dir)\n        if usage.free < threshold_in_bytes:\n            break\n        sleep(sleep_time)"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        total, used, free = shutil.disk_usage(input_dir)\n        free_gb = free / (2**30)  # convert bytes to gigabytes\n        if free_gb <= threshold_in_gb:\n            break\n        else:\n            sleep(sleep_time)"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        total, used, free = shutil.disk_usage(input_dir)\n        free_gb = free / (2**30)  # Convert bytes to gigabytes\n        if free_gb <= threshold_in_gb:\n            break\n        sleep(sleep_time)"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        total, used, free = shutil.disk_usage(input_dir)\n        free_gb = free / (2**30)  # Convert bytes to gigabytes\n        if free_gb <= threshold_in_gb:\n            break\n        else:\n            sleep(sleep_time)"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    threshold_in_bytes = threshold_in_gb * 1024 * 1024 * 1024  # Convert threshold from GB to bytes\n    while True:\n        usage = shutil.disk_usage(input_dir)\n        if usage.free < threshold_in_bytes:\n            break\n        sleep(sleep_time)"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "\n    while True:\n        total, used, free = shutil.disk_usage(input_dir)\n        free_gb = free / (2**30)  # Convert bytes to gigabytes\n        if free_gb > threshold_in_gb:\n            sleep(sleep_time)\n        else:\n            break"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        total, used, free = shutil.disk_usage(input_dir)\n        free_gb = free / (2**30)  # Convert bytes to gigabytes\n        if free_gb <= threshold_in_gb:\n            break\n        sleep(sleep_time)"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        total, used, free = shutil.disk_usage(input_dir)\n        free_gb = free / (2**30)  # Convert bytes to gigabytes\n        if free_gb < threshold_in_gb:\n            break\n        sleep(sleep_time)"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "\n    while True:\n        total, used, free = shutil.disk_usage(input_dir)\n        free_gb = free / (2**30)  # Convert bytes to gigabytes\n        if free_gb < threshold_in_gb:\n            break\n        sleep(sleep_time)"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        total, used, free = shutil.disk_usage(input_dir)\n        free_gb = free / (2**30)  # Convert bytes to gigabytes\n        if free_gb < threshold_in_gb:\n            break\n        sleep(sleep_time)"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        total, used, free = shutil.disk_usage(input_dir)\n        free_gb = free / (2**30)  # Convert bytes to gigabytes\n        if free_gb <= threshold_in_gb:\n            break\n        else:\n            sleep(sleep_time)"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "\n    while True:\n        total, used, free = shutil.disk_usage(input_dir)\n        free_gb = free / 2**30  # Convert bytes to gigabytes\n        if free_gb <= threshold_in_gb:\n            break\n        else:\n            sleep(sleep_time)"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        total, used, free = shutil.disk_usage(input_dir)\n        free_gb = free / (2**30)  # Convert bytes to gigabytes\n        if free_gb < threshold_in_gb:\n            break\n        sleep(sleep_time)"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        total, used, free = shutil.disk_usage(input_dir)\n        free_gb = free / (2**30)  # Convert bytes to gigabytes\n        if free_gb < threshold_in_gb:\n            break\n        sleep(sleep_time)"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            weights=weights,\n            reader=reader,\n        )\n        with optimize_dns_context(True):\n            return data_processor.run(LambdaDataChunkRecipe(fn, inputs, chunk_size, chunk_bytes, compression))\n    return _execute(\n        f\"data-prep-optimize-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    # Implementation of the optimize function\n    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            weights=weights,\n            reader=reader,\n        )\n        with optimize_dns_context(True):\n            return data_processor.run(LambdaDataChunkRecipe(fn, inputs, chunk_size, chunk_bytes, compression))\n    return _execute(\n        f\"data-prep-optimize-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.optimize", "completion": "\n    # Implementation of the optimize function based on the provided code\n    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            weights=weights,\n            reader=reader,\n        )\n        with optimize_dns_context(True):\n            return data_processor.run(LambdaDataChunkRecipe(fn, inputs, chunk_size, chunk_bytes, compression))\n    return _execute(\n        f\"data-prep-optimize-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.optimize", "completion": "\n    map(\n        fn=fn,\n        inputs=inputs,\n        output_dir=output_dir,\n        weights=weights,\n        chunk_size=chunk_size,\n        chunk_bytes=chunk_bytes,\n        compression=compression,\n        num_workers=num_workers,\n        fast_dev_run=fast_dev_run,\n        num_nodes=num_nodes,\n        machine=machine,\n        num_downloaders=num_downloaders,\n        num_uploaders=num_uploaders,\n        reorder_files=reorder_files,\n        reader=reader,\n        batch_size=batch_size,\n    )"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            weights=weights,\n            reader=reader,\n        )\n        with optimize_dns_context(True):\n            return data_processor.run(LambdaDataChunkRecipe(fn, inputs, chunk_size, chunk_bytes, compression))\n    return _execute(\n        f\"data-prep-optimize-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    map(\n        fn=fn,\n        inputs=inputs,\n        output_dir=output_dir,\n        weights=weights,\n        chunk_size=chunk_size,\n        chunk_bytes=chunk_bytes,\n        compression=compression,\n        num_workers=num_workers,\n        fast_dev_run=fast_dev_run,\n        num_nodes=num_nodes,\n        machine=machine,\n        num_downloaders=num_downloaders,\n        num_uploaders=num_uploaders,\n        reorder_files=reorder_files,\n        reader=reader,\n        batch_size=batch_size,\n    )"}
{"namespace": "litdata.processing.functions.optimize", "completion": "\n    # The optimize function implementation goes here\n    # Refer to the original map function for the implementation details"}
{"namespace": "litdata.processing.functions.optimize", "completion": "\n    # The optimize function is not implemented here as it is already implemented in the provided code.\n    # The provided code includes the implementation of the optimize function."}
{"namespace": "litdata.processing.functions.optimize", "completion": "    map(\n        fn,\n        inputs,\n        output_dir,\n        weights,\n        num_workers,\n        fast_dev_run,\n        num_nodes,\n        machine,\n        num_downloaders,\n        num_uploaders,\n        reorder_files,\n        reader,\n        batch_size,\n    )"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            weights=weights,\n            reader=reader,\n        )\n        with optimize_dns_context(True):\n            return data_processor.run(LambdaDataChunkRecipe(fn, inputs, chunk_size, chunk_bytes, compression))\n    return _execute(\n        f\"data-prep-map-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.optimize", "completion": "\n    # Function implementation\n    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            weights=weights,\n            reader=reader,\n        )\n        with optimize_dns_context(True):\n            return data_processor.run(LambdaDataChunkRecipe(fn, inputs, chunk_size, chunk_bytes, compression))\n    return _execute(\n        f\"data-prep-optimize-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    map(\n        fn,\n        inputs,\n        output_dir,\n        weights,\n        num_workers,\n        fast_dev_run,\n        num_nodes,\n        machine,\n        num_downloaders,\n        num_uploaders,\n        reorder_files,\n        reader,\n        batch_size,\n    )"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    map(\n        fn=fn,\n        inputs=inputs,\n        output_dir=output_dir,\n        weights=weights,\n        num_workers=num_workers,\n        fast_dev_run=fast_dev_run,\n        num_nodes=num_nodes,\n        machine=machine,\n        num_downloaders=num_downloaders,\n        num_uploaders=num_uploaders,\n        reorder_files=reorder_files,\n        reader=reader,\n        batch_size=batch_size,\n    )"}
{"namespace": "litdata.processing.functions.optimize", "completion": "\n    map(\n        fn=fn,\n        inputs=inputs,\n        output_dir=output_dir,\n        weights=weights,\n        chunk_size=chunk_size,\n        chunk_bytes=chunk_bytes,\n        compression=compression,\n        num_workers=num_workers,\n        fast_dev_run=fast_dev_run,\n        num_nodes=num_nodes,\n        machine=machine,\n        num_downloaders=num_downloaders,\n        num_uploaders=num_uploaders,\n        reorder_files=reorder_files,\n        reader=reader,\n        batch_size=batch_size,\n    )"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            weights=weights,\n            reader=reader,\n        )\n        with optimize_dns_context(True):\n            return data_processor.run(LambdaDataChunkRecipe(fn, inputs, chunk_size, chunk_bytes, compression))\n    return _execute(\n        f\"data-prep-optimize-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.optimize", "completion": "\n    map(\n        fn,\n        inputs,\n        output_dir,\n        weights,\n        num_workers,\n        fast_dev_run,\n        num_nodes,\n        machine,\n        num_downloaders,\n        num_uploaders,\n        reorder_files,\n        reader,\n        batch_size,\n    )"}
{"namespace": "litdata.processing.functions.optimize", "completion": "\n    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            weights=weights,\n            reader=reader,\n        )\n        with optimize_dns_context(True):\n            return data_processor.run(LambdaDataChunkRecipe(fn, inputs, chunk_size, chunk_bytes, compression))\n    return _execute(\n        f\"data-prep-map-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            weights=weights,\n            reader=reader,\n        )\n        with optimize_dns_context(True):\n            return data_processor.run(LambdaDataChunkRecipe(fn, inputs, chunk_size, chunk_bytes, compression))\n    return _execute(\n        f\"data-prep-optimize-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.optimize", "completion": "\n    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            weights=weights,\n            reader=reader,\n        )\n        with optimize_dns_context(True):\n            return data_processor.run(LambdaDataChunkRecipe(fn, inputs, chunk_size, chunk_bytes, compression))\n    return _execute(\n        f\"data-prep-optimize-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.optimize", "completion": "\n    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            weights=weights,\n            reader=reader,\n        )\n        with optimize_dns_context(True):\n            return data_processor.run(LambdaDataChunkRecipe(fn, inputs, chunk_size, chunk_bytes, compression))\n    return _execute(\n        f\"data-prep-optimize-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\",\n        num_nodes,\n        machine,\n    )"}
{"namespace": "litdata.processing.functions.map", "completion": "    # Get the input directory\n    input_dir = _get_input_dir(inputs)\n\n    # Get the default number of workers if not provided\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    # Prepare the data transform recipe\n    data_transform_recipe = LambdaDataTransformRecipe(fn, inputs)\n\n    # Create the streaming data loader\n    streaming_data_loader = StreamingDataLoader(\n        data_transform_recipe,\n        output_dir,\n        weights=weights,\n        num_workers=num_workers,\n        fast_dev_run=fast_dev_run,\n        num_nodes=num_nodes,\n        machine=machine,\n        num_downloaders=num_downloaders,\n        num_uploaders=num_uploaders,\n        reorder_files=reorder_files,\n        error_when_not_empty=error_when_not_empty,\n        reader=reader,\n        batch_size=batch_size,\n    )\n\n    # Process the inputs\n    streaming_data_loader.process(input_dir)"}
{"namespace": "litdata.processing.functions.map", "completion": "    # Check if the output_dir is empty, if not, raise an error\n    if error_when_not_empty:\n        _assert_dir_is_empty(output_dir)\n\n    # Resolve the input directory\n    input_dir = _get_input_dir(inputs)\n\n    # Create the DataTransformRecipe\n    data_transform_recipe = LambdaDataTransformRecipe(fn, inputs)\n\n    # Create the DataProcessor\n    data_processor = DataProcessor(\n        data_transform_recipe,\n        output_dir,\n        weights=weights,\n        num_workers=num_workers or _get_default_num_workers(),\n        fast_dev_run=fast_dev_run,\n        num_nodes=num_nodes,\n        machine=machine,\n        num_downloaders=num_downloaders,\n        num_uploaders=num_uploaders,\n        reorder_files=reorder_files,\n        reader=reader,\n        batch_size=batch_size,\n    )\n\n    # Process the data\n    data_processor.process(input_dir)"}
{"namespace": "litdata.processing.functions.map", "completion": "    # Get the input directory\n    input_dir = _get_input_dir(inputs)\n\n    # Set the default number of workers if not specified\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    # Create a LambdaDataTransformRecipe\n    data_transform_recipe = LambdaDataTransformRecipe(fn, inputs)\n\n    # Create a StreamingDataLoader\n    data_loader = StreamingDataLoader(\n        data_transform_recipe,\n        output_dir,\n        weights=weights,\n        num_workers=num_workers,\n        fast_dev_run=fast_dev_run,\n        num_nodes=num_nodes,\n        machine=machine,\n        num_downloaders=num_downloaders,\n        num_uploaders=num_uploaders,\n        reorder_files=reorder_files,\n        error_when_not_empty=error_when_not_empty,\n        reader=reader,\n        batch_size=batch_size,\n    )\n\n    # Process the inputs using the data loader\n    data_loader.process(input_dir)"}
{"namespace": "litdata.processing.functions.map", "completion": "    # Determine the number of workers to use\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    # Determine the input directory\n    input_dir = _get_input_dir(inputs)\n\n    # Create the data transform recipe\n    data_transform_recipe = LambdaDataTransformRecipe(fn, inputs)\n\n    # Create the data chunk recipe\n    data_chunk_recipe = LambdaDataChunkRecipe(data_transform_recipe, inputs, batch_size, None, None)\n\n    # Create the streaming data loader\n    streaming_data_loader = StreamingDataLoader(\n        input_dir,\n        output_dir,\n        weights,\n        num_workers,\n        fast_dev_run,\n        num_nodes,\n        machine,\n        num_downloaders,\n        num_uploaders,\n        reorder_files,\n        error_when_not_empty,\n        reader,\n        data_chunk_recipe,\n    )\n\n    # Process the inputs and store the results in the output directory\n    streaming_data_loader.process()"}
{"namespace": "litdata.processing.functions.map", "completion": "\n    # Get the input directory\n    input_dir = _get_input_dir(inputs)\n\n    # Set the default number of workers if not provided\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    # Create a data transform recipe\n    data_transform_recipe = LambdaDataTransformRecipe(fn, inputs)\n\n    # Create a streaming data loader\n    data_loader = StreamingDataLoader(\n        input_dir=input_dir,\n        output_dir=output_dir,\n        weights=weights,\n        num_workers=num_workers,\n        fast_dev_run=fast_dev_run,\n        num_nodes=num_nodes,\n        machine=machine,\n        num_downloaders=num_downloaders,\n        num_uploaders=num_uploaders,\n        reorder_files=reorder_files,\n        error_when_not_empty=error_when_not_empty,\n        reader=reader,\n        batch_size=batch_size,\n    )\n\n    # Process the inputs using the data transform recipe and streaming data loader\n    data_loader.process(data_transform_recipe)"}
{"namespace": "litdata.processing.functions.map", "completion": "    # Create a LambdaDataTransformRecipe object\n    data_transform_recipe = LambdaDataTransformRecipe(fn, inputs)\n\n    # Get the input directory\n    input_dir = _get_input_dir(inputs)\n\n    # If num_workers is not specified, get the default number of workers\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    # If the output directory is not empty and error_when_not_empty is True, raise an error\n    if error_when_not_empty:\n        _assert_dir_is_empty(output_dir)\n\n    # If the output directory is a directory, ensure it has an index file\n    if isinstance(output_dir, Dir):\n        _assert_dir_has_index_file(output_dir)\n\n    # Resolve the input directory\n    resolved_input_dir = _resolve_dir(input_dir)\n\n    # Create a StreamingDataLoader object\n    data_loader = StreamingDataLoader(\n        data_transform_recipe,\n        resolved_input_dir,\n        output_dir,\n        weights=weights,\n        num_workers=num_workers,\n        fast_dev_run=fast_dev_run,\n        num_nodes=num_nodes,\n        machine=machine,\n        num_downloaders=num_downloaders,\n        num_uploaders=num_uploaders,\n        reorder_files=reorder_files,\n        reader=reader,\n        batch_size=batch_size,\n    )\n\n    # Execute the data loader\n    _execute(data_loader)"}
{"namespace": "litdata.processing.functions.map", "completion": "    # Get the default number of workers if not specified\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    # Get the input directory\n    input_dir = _get_input_dir(inputs)\n\n    # Create the data transform recipe\n    data_transform_recipe = LambdaDataTransformRecipe(fn, inputs)\n\n    # Create the data chunk recipe\n    data_chunk_recipe = LambdaDataChunkRecipe(fn, inputs, chunk_size=batch_size, chunk_bytes=None, compression=None)\n\n    # Resolve the input directory\n    resolved_input_dir = _resolve_dir(input_dir)\n\n    # Assert that the input directory has an index file\n    _assert_dir_has_index_file(resolved_input_dir)\n\n    # Assert that the input directory is empty\n    if error_when_not_empty:\n        _assert_dir_is_empty(output_dir)\n\n    # Optimize the DNS context\n    optimize_dns_context()\n\n    # Execute the mapping\n    with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor:\n        _execute(\n            executor,\n            resolved_input_dir,\n            output_dir,\n            data_transform_recipe,\n            data_chunk_recipe,\n            weights=weights,\n            fast_dev_run=fast_dev_run,\n            num_nodes=num_nodes,\n            machine=machine,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            reader=reader,\n        )"}
{"namespace": "litdata.processing.functions.map", "completion": "    input_dir = _get_input_dir(inputs)\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if _IS_IN_STUDIO:\n        output_dir = _resolve_dir(output_dir, error_when_not_empty=error_when_not_empty)\n        _assert_dir_is_empty(output_dir)\n\n    if isinstance(output_dir, Dir):\n        output_dir = output_dir.path\n\n    if not reorder_files:\n        _assert_dir_has_index_file(input_dir)\n\n    if weights is None:\n        weights = [1] * len(inputs)\n\n    if batch_size is None:\n        batch_size = len(inputs)\n\n    with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor:\n        futures = []\n        for i, weight in enumerate(weights):\n            future = executor.submit(\n                _execute,\n                fn,\n                inputs[i],\n                output_dir,\n                fast_dev_run,\n                num_nodes,\n                machine,\n                num_downloaders,\n                num_uploaders,\n                reorder_files,\n                error_when_not_empty,\n                reader,\n            )\n            futures.append(future)\n\n        for future in concurrent.futures.as_completed(futures):\n            future.result()"}
{"namespace": "litdata.processing.functions.map", "completion": "    # Process the inputs and store the results in the specified output directory\n    # using the provided function and parameters\n\n    # Determine the number of workers to use during processing\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    # Create a data transform recipe using the provided function and inputs\n    data_transform_recipe = LambdaDataTransformRecipe(fn, inputs)\n\n    # Create a streaming data loader with the specified parameters\n    data_loader = StreamingDataLoader(\n        data_transform_recipe,\n        output_dir,\n        weights=weights,\n        num_workers=num_workers,\n        fast_dev_run=fast_dev_run,\n        num_nodes=num_nodes,\n        machine=machine,\n        num_downloaders=num_downloaders,\n        num_uploaders=num_uploaders,\n        reorder_files=reorder_files,\n        error_when_not_empty=error_when_not_empty,\n        reader=reader,\n        batch_size=batch_size\n    )\n\n    # Process the inputs using the streaming data loader\n    data_loader.process()"}
{"namespace": "litdata.processing.functions.map", "completion": "\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if weights is not None and len(weights) != len(inputs):\n        raise ValueError(\"The number of weights should match the number of inputs.\")\n\n    if isinstance(output_dir, Dir):\n        output_dir = _resolve_dir(output_dir)\n\n    if isinstance(output_dir, str) and error_when_not_empty:\n        _assert_dir_is_empty(output_dir)\n\n    if isinstance(output_dir, str) and reorder_files:\n        _assert_dir_has_index_file(output_dir)\n\n    input_dir = _get_input_dir(inputs)\n\n    if _IS_IN_STUDIO:\n        optimize_dns_context()\n\n    if num_nodes is None:\n        num_nodes = 1\n\n    if machine is None:\n        machine = \"cpu\"\n\n    if num_downloaders is None:\n        num_downloaders = 1\n\n    if num_uploaders is None:\n        num_uploaders = 1\n\n    if isinstance(output_dir, str) and reorder_files:\n        output_dir = _execute(output_dir)\n\n    if isinstance(output_dir, str):\n        output_dir = Dir(output_dir)\n\n    if batch_size is None:\n        batch_size = len(inputs)\n\n    if isinstance(output_dir, Dir):\n        output_dir = output_dir.path\n\n    if isinstance(output_dir, str):\n        output_dir = Path(output_dir)\n\n    if not output_dir.exists():\n        output_dir.mkdir(parents=True, exist_ok=True)\n\n    data_processor = DataProcessor(\n        num_workers=num_workers,\n        num_nodes=num_nodes,\n        machine=machine,\n        num_downloaders=num_downloaders,\n        num_uploaders=num_uploaders,\n        batch_size=batch_size,\n        reader=reader,\n    )\n\n    data_processor.process(\n        fn=fn,\n        inputs=inputs,\n        output_dir=output_dir,\n        weights=weights,\n        fast_dev_run=fast_dev_run,\n    )"}
{"namespace": "litdata.processing.functions.map", "completion": "\n    # Implementation of the map function\n    input_dir = _get_input_dir(inputs)\n\n    if weights is not None and len(weights) != len(inputs):\n        raise ValueError(\"The number of weights should be equal to the number of inputs.\")\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if _IS_IN_STUDIO:\n        num_workers = 1\n\n    if num_downloaders is None:\n        num_downloaders = max(1, num_workers // 2)\n\n    if num_uploaders is None:\n        num_uploaders = max(1, num_workers // 2)\n\n    if isinstance(output_dir, Dir):\n        _assert_dir_is_empty(output_dir)\n    else:\n        output_dir = _resolve_dir(output_dir)\n        if error_when_not_empty:\n            _assert_dir_is_empty(output_dir)\n        _assert_dir_has_index_file(output_dir)\n\n    if batch_size is not None:\n        inputs = list(inputs)\n        if len(inputs) % batch_size != 0:\n            raise ValueError(f\"Length of inputs {len(inputs)} should be multiple of batch_size {batch_size}.\")\n\n    with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor:\n        futures = []\n        for index, input_item in enumerate(inputs):\n            future = executor.submit(\n                _execute,\n                input_item,\n                input_dir,\n                output_dir,\n                fn,\n                weights[index] if weights is not None else None,\n                reader,\n                reorder_files,\n            )\n            futures.append(future)\n\n        for future in concurrent.futures.as_completed(futures):\n            future.result()\n\n    if _IS_IN_STUDIO:\n        optimize_dns_context(output_dir)"}
{"namespace": "litdata.processing.functions.map", "completion": "    # Get the default number of workers if not specified\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    # Get the input directory\n    input_dir = _get_input_dir(inputs)\n\n    # Initialize the data processor\n    data_processor = DataProcessor(\n        reader=reader,\n        num_workers=num_workers,\n        num_nodes=num_nodes,\n        machine=machine,\n        num_downloaders=num_downloaders,\n        num_uploaders=num_uploaders,\n        reorder_files=reorder_files,\n        error_when_not_empty=error_when_not_empty,\n    )\n\n    # Create the data transform recipe\n    data_transform_recipe = LambdaDataTransformRecipe(fn, inputs)\n\n    # Process the inputs using the data processor\n    data_processor.process(\n        data_transform_recipe,\n        input_dir=input_dir,\n        output_dir=output_dir,\n        weights=weights,\n        batch_size=batch_size,\n        fast_dev_run=fast_dev_run,\n    )"}
{"namespace": "litdata.processing.functions.map", "completion": "\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if weights is not None and len(weights) != len(inputs):\n        raise ValueError(\"The number of weights must match the number of inputs.\")\n\n    if isinstance(output_dir, Dir):\n        output_dir = _resolve_dir(output_dir)\n\n    input_dir = _get_input_dir(inputs)\n\n    if input_dir is None:\n        raise ValueError(\"No valid input paths found.\")\n\n    if error_when_not_empty:\n        _assert_dir_is_empty(output_dir)\n\n    if reorder_files:\n        _assert_dir_has_index_file(output_dir)\n\n    if _IS_IN_STUDIO:\n        optimize_dns_context()\n\n    with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor:\n        for input_item in inputs:\n            executor.submit(\n                _execute,\n                fn,\n                input_item,\n                output_dir,\n                weights,\n                reader,\n                batch_size,\n                reorder_files,\n            )"}
{"namespace": "litdata.processing.functions.map", "completion": "            from litdata.streaming.studio import _map as _studio_map\n    input_dir = _get_input_dir(inputs)\n    num_workers = num_workers or _get_default_num_workers()\n\n    if _IS_IN_STUDIO:\n        from litdata.streaming.studio import _map as _studio_map\n\n        _studio_map(\n            fn,\n            inputs,\n            output_dir,\n            weights,\n            num_workers,\n            fast_dev_run,\n            num_nodes,\n            machine,\n            num_downloaders,\n            num_uploaders,\n            reorder_files,\n            error_when_not_empty,\n            reader,\n            batch_size,\n        )\n        return\n\n    if num_nodes is not None or machine is not None:\n        # Remote execution\n        _resolve_dir(output_dir, error_when_not_empty=error_when_not_empty)\n        _execute(\n            fn,\n            inputs,\n            output_dir,\n            weights,\n            num_workers,\n            fast_dev_run,\n            num_nodes,\n            machine,\n            num_downloaders,\n            num_uploaders,\n            reorder_files,\n            error_when_not_empty,\n            reader,\n            batch_size,\n        )\n        return\n\n    if batch_size:\n        # Process in batches\n        _process_in_batches(\n            fn,\n            inputs,\n            output_dir,\n            weights,\n            num_workers,\n            fast_dev_run,\n            num_downloaders,\n            num_uploaders,\n            reorder_files,\n            error_when_not_empty,\n            reader,\n            batch_size,\n        )\n        return\n\n    # Regular processing\n    _process_regular(\n        fn,\n        inputs,\n        output_dir,\n        weights,\n        num_workers,\n        fast_dev_run,\n        num_downloaders,\n        num_uploaders,\n        reorder_files,\n        error_when_not_empty,\n        reader,\n    )"}
{"namespace": "litdata.processing.functions.map", "completion": "\n    # Your code goes here\n    # Implement the logic for mapping the callable function over the inputs and processing them based on the specified parameters.\n    # Use concurrent.futures for parallel processing, handle input batches, and customize the processing environment.\n    # Consider remote execution options, such as num_nodes and machine, if applicable.\n    # Ensure error handling for empty output directory and other relevant scenarios.\n    # Use the provided fn and inputs to process the data and store the results in the output directory."}
{"namespace": "litdata.processing.functions.map", "completion": "    input_dir = _get_input_dir(inputs)\n    num_workers = num_workers or _get_default_num_workers()\n\n    if _IS_IN_STUDIO:\n        num_workers = 1\n\n    if _TORCH_GREATER_EQUAL_2_1_0:\n        with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor:\n            futures = [\n                executor.submit(\n                    _execute,\n                    fn,\n                    inputs,\n                    output_dir,\n                    weights,\n                    fast_dev_run,\n                    num_nodes,\n                    machine,\n                    num_downloaders,\n                    num_uploaders,\n                    reorder_files,\n                    error_when_not_empty,\n                    reader,\n                    batch_size,\n                )\n            ]\n    else:\n        with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:\n            futures = [\n                executor.submit(\n                    _execute,\n                    fn,\n                    inputs,\n                    output_dir,\n                    weights,\n                    fast_dev_run,\n                    num_nodes,\n                    machine,\n                    num_downloaders,\n                    num_uploaders,\n                    reorder_files,\n                    error_when_not_empty,\n                    reader,\n                    batch_size,\n                )\n            ]\n\n    for future in concurrent.futures.as_completed(futures):\n        future.result()"}
{"namespace": "litdata.processing.functions.map", "completion": "    # Get the default number of workers if not provided\n    num_workers = num_workers if num_workers is not None else _get_default_num_workers()\n\n    # Get the input directory from the inputs\n    input_dir = _get_input_dir(inputs)\n\n    # Resolve the output directory\n    output_dir = _resolve_dir(output_dir)\n\n    # Create the data transform recipe\n    data_transform_recipe = LambdaDataTransformRecipe(fn, inputs)\n\n    # Create the data chunk recipe\n    data_chunk_recipe = LambdaDataChunkRecipe(fn, inputs, chunk_size=batch_size, chunk_bytes=None, compression=None)\n\n    # Create the data processor\n    data_processor = DataProcessor(\n        data_transform_recipe=data_transform_recipe,\n        data_chunk_recipe=data_chunk_recipe,\n        output_dir=output_dir,\n        weights=weights,\n        num_workers=num_workers,\n        fast_dev_run=fast_dev_run,\n        num_nodes=num_nodes,\n        machine=machine,\n        num_downloaders=num_downloaders,\n        num_uploaders=num_uploaders,\n        reorder_files=reorder_files,\n        error_when_not_empty=error_when_not_empty,\n        reader=reader,\n    )\n\n    # Process the inputs\n    data_processor.process(input_dir)"}
{"namespace": "litdata.processing.functions.map", "completion": "    if _IS_IN_STUDIO:\n        # Ensure the output_dir is empty if required\n        if error_when_not_empty:\n            _assert_dir_is_empty(output_dir)\n\n        # Ensure the output_dir has an index file\n        _assert_dir_has_index_file(output_dir)\n\n    # Resolve the output_dir\n    output_dir = _resolve_dir(output_dir)\n\n    # Get the input_dir\n    input_dir = _get_input_dir(inputs)\n\n    # Get the default num_workers if not provided\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    # Optimize DNS context if running in Lightning Studio\n    if _IS_IN_STUDIO:\n        optimize_dns_context(machine, num_nodes, num_downloaders, num_uploaders)\n\n    # Create the data transform recipe\n    data_transform_recipe = LambdaDataTransformRecipe(fn, inputs)\n\n    # Create the data processor\n    data_processor = DataProcessor(\n        data_transform_recipe,\n        output_dir,\n        weights=weights,\n        num_workers=num_workers,\n        fast_dev_run=fast_dev_run,\n        num_nodes=num_nodes,\n        machine=machine,\n        num_downloaders=num_downloaders,\n        num_uploaders=num_uploaders,\n        reorder_files=reorder_files,\n        reader=reader,\n        batch_size=batch_size,\n    )\n\n    # Process the inputs\n    data_processor.process(input_dir)"}
{"namespace": "litdata.processing.functions.map", "completion": "\n    input_dir = _get_input_dir(inputs)\n    num_workers = num_workers or _get_default_num_workers()\n\n    if _IS_IN_STUDIO:\n        return _execute(\n            fn,\n            inputs,\n            output_dir,\n            weights,\n            num_workers,\n            fast_dev_run,\n            num_nodes,\n            machine,\n            num_downloaders,\n            num_uploaders,\n            reorder_files,\n            error_when_not_empty,\n            reader,\n            batch_size,\n        )\n\n    with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor:\n        future_to_input = {\n            executor.submit(\n                _execute,\n                fn,\n                input_item,\n                output_dir,\n                weights,\n                1,\n                fast_dev_run,\n                num_nodes,\n                machine,\n                num_downloaders,\n                num_uploaders,\n                reorder_files,\n                error_when_not_empty,\n                reader,\n                batch_size,\n            ): input_item\n            for input_item in inputs\n        }\n\n        for future in concurrent.futures.as_completed(future_to_input):\n            future_to_input[future]"}
{"namespace": "litdata.processing.functions.map", "completion": "    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    input_dir = _get_input_dir(inputs)\n\n    if input_dir is None:\n        raise ValueError(\"No valid input directory found.\")\n\n    if isinstance(output_dir, Dir):\n        output_dir = _resolve_dir(output_dir, input_dir)\n\n    if isinstance(output_dir, str):\n        output_dir = _resolve_dir(Dir(output_dir), input_dir)\n\n    if error_when_not_empty:\n        _assert_dir_is_empty(output_dir)\n\n    if reorder_files:\n        _assert_dir_has_index_file(input_dir)\n        inputs = list(_execute(input_dir, output_dir, weights))\n\n    if _IS_IN_STUDIO:\n        optimize_dns_context()\n\n    if num_downloaders is None:\n        num_downloaders = max(1, num_workers // 4)\n\n    if num_uploaders is None:\n        num_uploaders = max(1, num_workers // 4)\n\n    if batch_size is None:\n        batch_size = len(inputs)\n\n    with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:\n        futures = {\n            executor.submit(\n                StreamingDataLoader(\n                    reader=reader,\n                    data_chunk_recipe=LambdaDataChunkRecipe(\n                        fn=fn,\n                        inputs=inputs[i : i + batch_size],\n                        chunk_size=batch_size,\n                        chunk_bytes=\"1GB\",\n                        compression=\"gzip\",\n                    ),\n                    output_dir=output_dir,\n                    weights=weights,\n                    num_downloaders=num_downloaders,\n                    num_uploaders=num_uploaders,\n                ).process,\n                inputs[i : i + batch_size],\n            ): i\n            for i in range(0, len(inputs), batch_size)\n        }\n\n        for future in concurrent.futures.as_completed(futures):\n            i = futures[future]\n            try:\n                future.result()\n            except Exception as e:\n                print(f\"Processing of batch {i} - {i + batch_size} failed with error: {e}\")"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "\n    s3 = S3Client()\n\n    while True:\n        try:\n            index, file_paths = queue_in.get(timeout=1)\n        except Empty:\n            continue\n\n        # Check if the files are already downloaded\n        all_files_exist = all(Path(cache_dir) / file_path for file_path in file_paths)\n\n        if not all_files_exist:\n            # Download missing files\n            for file_path in file_paths:\n                obj = parse.urlparse(str(input_dir / file_path))\n                _wait_for_file_to_exist(s3, obj)\n                s3.download_file(obj.netloc, obj.path.lstrip(\"/\"), str(Path(cache_dir) / file_path))\n\n        # Signal completion by putting the task index into the output queue\n        queue_out.put(index)"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = input_dir.s3\n    while True:\n        try:\n            index, files = queue_in.get(timeout=1)\n        except Empty:\n            continue\n\n        for file in files:\n            file = parse.urlparse(file)\n            local_path = os.path.join(cache_dir, file.path.lstrip(\"/\"))\n            local_dir = os.path.dirname(local_path)\n\n            if not os.path.exists(local_dir):\n                os.makedirs(local_dir)\n\n            if not os.path.exists(local_path):\n                if s3 is not None:\n                    s3.download_file(Bucket=file.netloc, Key=file.path.lstrip(\"/\"), Filename=local_path)\n                else:\n                    _wait_for_file_to_exist(s3, file)\n                    shutil.copyfile(file.geturl(), local_path)\n\n        queue_out.put(index)"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client()\n\n    while True:\n        try:\n            index, files = queue_in.get(timeout=1)\n        except Empty:\n            continue\n\n        for file in files:\n            obj = parse.urlparse(file)\n\n            # Check if the file already exists in the cache\n            cache_file = os.path.join(cache_dir, obj.path.lstrip(\"/\"))\n            if os.path.exists(cache_file):\n                continue\n\n            # Wait for the file to exist on the remote server\n            _wait_for_file_to_exist(s3, obj)\n\n            # Download the file to the cache directory\n            s3.download_file(obj.netloc, obj.path.lstrip(\"/\"), cache_file)\n\n        # Signal completion by putting the task index into the output queue\n        queue_out.put(index)"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client()\n\n    while True:\n        try:\n            index, file_paths = queue_in.get(timeout=1)\n            for file_path in file_paths:\n                obj = parse.urlparse(file_path)\n                local_path = os.path.join(cache_dir, obj.path.lstrip(\"/\"))\n                if not os.path.exists(local_path):\n                    if obj.scheme == \"s3\":\n                        s3.download_file(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"), Filename=local_path)\n                    else:\n                        raise ValueError(f\"Unsupported scheme {obj.scheme} in {file_path}\")\n            queue_out.put(index)\n        except Empty:\n            break"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "\n    s3 = S3Client()\n    while True:\n        try:\n            index, file_paths = queue_in.get(timeout=1)\n            downloaded_files = []\n            for file_path in file_paths:\n                file_url = input_dir.joinpath(file_path)\n                file_url_parsed = parse.urlparse(file_url)\n                file_name = Path(file_url_parsed.path).name\n                local_file_path = os.path.join(cache_dir, file_name)\n\n                if not os.path.exists(local_file_path):\n                    s3.download_file(file_url_parsed.netloc, file_url_parsed.path.lstrip(\"/\"), local_file_path)\n                downloaded_files.append(local_file_path)\n\n            queue_out.put(index)\n        except Empty:\n            break"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client()\n    while True:\n        try:\n            index, files = queue_in.get(timeout=1)\n            for file in files:\n                obj = parse.urlparse(file)\n                target = os.path.join(cache_dir, Path(obj.path).name)\n                if not os.path.exists(target):\n                    os.makedirs(os.path.dirname(target), exist_ok=True)\n                    if obj.scheme == \"s3\":\n                        _wait_for_file_to_exist(s3, obj)\n                        s3.download_file(obj.netloc, obj.path.lstrip(\"/\"), target)\n                    else:\n                        shutil.copyfile(file, target)\n            queue_out.put(index)\n        except Empty:\n            break"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client()\n\n    while True:\n        try:\n            index, files = queue_in.get(timeout=1)\n        except Empty:\n            continue\n\n        local_files = []\n        for file in files:\n            file = parse.urlparse(file)\n            local_file = os.path.join(cache_dir, file.path.lstrip(\"/\"))\n            local_files.append(local_file)\n            if not os.path.exists(local_file):\n                os.makedirs(os.path.dirname(local_file), exist_ok=True)\n                s3.client.download_file(Bucket=file.netloc, Key=file.path.lstrip(\"/\"), Filename=local_file)\n\n        queue_out.put(index)"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "\n    s3 = S3Client()\n\n    while True:\n        try:\n            index, file_paths = queue_in.get(timeout=1)\n            file_paths = list(file_paths)\n\n            for file_path in file_paths:\n                file_url = input_dir.resolve(file_path)\n                file_name = os.path.basename(file_url.path)\n\n                cache_file_path = os.path.join(cache_dir, file_name)\n\n                if not os.path.exists(cache_file_path):\n                    s3.download_file(file_url.netloc, file_url.path.lstrip(\"/\"), cache_file_path)\n\n            queue_out.put(index)\n\n        except Empty:\n            # Handle empty queue\n            pass"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client()\n    while True:\n        try:\n            index, file_paths = queue_in.get(timeout=1)\n            if not isinstance(file_paths, list):\n                file_paths = [file_paths]\n\n            for file_path in file_paths:\n                obj = parse.urlparse(file_path)\n                target_path = os.path.join(cache_dir, obj.path.lstrip(\"/\"))\n\n                if not os.path.exists(target_path):\n                    if isinstance(input_dir, S3Client):\n                        _wait_for_file_to_exist(input_dir, obj)\n                        input_dir.download(file_path, target_path)\n                    else:\n                        input_dir.download(file_path, target_path)\n\n            queue_out.put(index)\n\n        except Empty:\n            break\n        except Exception as e:\n            logger.error(f\"Error downloading data: {e}\")\n            queue_out.put(None)\n            break"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client()\n    while True:\n        try:\n            index, file_paths = queue_in.get(timeout=5)\n            for file_path in file_paths:\n                obj = parse.urlparse(file_path)\n                local_path = os.path.join(cache_dir, obj.path.lstrip(\"/\"))\n                if not os.path.exists(local_path):\n                    os.makedirs(os.path.dirname(local_path), exist_ok=True)\n                    s3.download_file(obj.netloc, obj.path.lstrip(\"/\"), local_path)\n            queue_out.put(index)\n        except Empty:\n            break"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client()\n    while True:\n        try:\n            index, files = queue_in.get(timeout=1)\n            for file in files:\n                file_path = Path(cache_dir) / file\n                if not file_path.exists():\n                    obj = parse.urlparse(input_dir.url / file)\n                    _wait_for_file_to_exist(s3, obj)\n                    file_path.parent.mkdir(parents=True, exist_ok=True)\n                    s3.download_file(obj.netloc, obj.path.lstrip(\"/\"), str(file_path))\n            queue_out.put(index)\n        except Empty:\n            return"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "\n    s3 = S3Client()\n    while True:\n        try:\n            index, file_paths = queue_in.get(timeout=1)\n            for file_path in file_paths:\n                obj = parse.urlparse(file_path)\n                local_file_path = os.path.join(cache_dir, obj.path.lstrip(\"/\"))\n                if not os.path.exists(local_file_path):\n                    os.makedirs(os.path.dirname(local_file_path), exist_ok=True)\n                    s3.download_file(obj.netloc, obj.path.lstrip(\"/\"), local_file_path)\n            queue_out.put(index)\n        except Empty:\n            break\n        except Exception as e:\n            logger.error(f\"Error downloading file: {e}\")"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client()\n    while True:\n        try:\n            # Fetch download task from input queue\n            try:\n                task_index, file_paths = queue_in.get(timeout=1)\n            except Empty:\n                continue\n\n            # Check if files are already downloaded\n            all_downloaded = all([os.path.exists(os.path.join(cache_dir, Path(file_path).name)) for file_path in file_paths])\n\n            if not all_downloaded:\n                # Download missing files\n                for file_path in file_paths:\n                    obj = parse.urlparse(input_dir.joinpath(file_path).as_uri())\n                    if obj.scheme == \"s3\":\n                        _wait_for_file_to_exist(s3, obj)\n                        s3.download_file(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"), Filename=os.path.join(cache_dir, Path(file_path).name))\n                    else:\n                        raise ValueError(f\"Unsupported scheme: {obj.scheme}\")\n\n            # Signal completion by putting task index into output queue\n            queue_out.put(task_index)\n        except Exception as e:\n            logger.error(f\"Error in _download_data_target: {e}\\n{traceback.format_exc()}\")"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "\n    s3 = S3Client()\n    while True:\n        try:\n            index, file_paths = queue_in.get(timeout=1)\n        except Empty:\n            continue\n\n        if not isinstance(file_paths, list):\n            file_paths = [file_paths]\n\n        for file_path in file_paths:\n            obj = parse.urlparse(file_path)\n            target_path = os.path.join(cache_dir, obj.path.lstrip(\"/\"))\n\n            if not os.path.exists(target_path):\n                os.makedirs(os.path.dirname(target_path), exist_ok=True)\n                s3.download_file(obj.netloc, obj.path.lstrip(\"/\"), target_path)\n                logging.info(f\"Downloaded {file_path} to {target_path}\")\n\n        queue_out.put(index)"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    while True:\n        try:\n            index, file_paths = queue_in.get(timeout=0.1)\n            for file_path in file_paths:\n                local_file_path = os.path.join(cache_dir, file_path)\n                if not os.path.exists(local_file_path):\n                    s3 = S3Client()\n                    obj = parse.urlparse(input_dir.joinpath(file_path).as_uri())\n                    _wait_for_file_to_exist(s3, obj)\n                    os.makedirs(os.path.dirname(local_file_path), exist_ok=True)\n                    s3.download_file(obj.netloc, obj.path.lstrip(\"/\"), local_file_path)\n            queue_out.put(index)\n        except Empty:\n            break"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client()\n\n    while True:\n        try:\n            index, file_paths = queue_in.get(timeout=1)\n        except Empty:\n            continue\n\n        try:\n            for file_path in file_paths:\n                cache_path = os.path.join(cache_dir, file_path)\n                if not os.path.exists(cache_path):\n                    obj = parse.urlparse(input_dir.resolve(file_path))\n                    os.makedirs(os.path.dirname(cache_path), exist_ok=True)\n                    s3.download_file(obj.netloc, obj.path.lstrip(\"/\"), cache_path)\n            queue_out.put(index)\n        except Exception as e:\n            logger.error(f\"Error downloading files: {e}\")\n            traceback.print_exc()"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "\n    s3 = input_dir.s3\n    for i, files in iter(queue_in.get, None):\n        downloaded_files = []\n        for file in files:\n            file_path = Path(cache_dir) / file\n            if not file_path.exists():\n                obj = parse.urlparse(f\"{input_dir.url}/{file}\")\n                _wait_for_file_to_exist(s3, obj)\n                s3.download_file(obj.netloc, obj.path.lstrip(\"/\"), str(file_path))\n            downloaded_files.append(file)\n        queue_out.put(i)\n    return"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "\n    s3 = S3Client()\n    while True:\n        try:\n            index, files = queue_in.get(timeout=5)\n        except Empty:\n            continue\n\n        for file in files:\n            # Check if the file already exists in the cache directory\n            local_file_path = os.path.join(cache_dir, file)\n            if not os.path.exists(local_file_path):\n                # File does not exist, download it from the remote directory\n                remote_file_path = parse.urljoin(input_dir.url, file)\n                obj = parse.urlparse(remote_file_path)\n                _wait_for_file_to_exist(s3, obj)\n                s3.download_file(input_dir.bucket, remote_file_path, local_file_path)\n\n        # Signal completion by putting the task index into the output queue\n        queue_out.put(index)"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client()\n    while True:\n        try:\n            index, files = queue_in.get(timeout=1)\n            for file in files:\n                file_path = Path(cache_dir) / file\n                if not file_path.exists():\n                    obj = parse.urlparse(str(input_dir / file))\n                    _wait_for_file_to_exist(s3, obj)\n                    s3.download_file(obj.netloc, obj.path.lstrip(\"/\"), str(file_path))\n            queue_out.put(index)\n        except Empty:\n            return"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "\n    s3 = S3Client()\n    cache = Cache(cache_dir)\n\n    while True:\n        try:\n            index, files = queue_in.get(timeout=1)\n            downloaded_files = []\n            for file in files:\n                obj = parse.urlparse(file)\n                local_file_path = os.path.join(cache_dir, obj.path.lstrip(\"/\"))\n                if not os.path.isfile(local_file_path):\n                    s3.download_file(obj, cache_dir)\n                downloaded_files.append(local_file_path)\n            queue_out.put(index)\n        except Empty:\n            break"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            remove_queue.put(None)\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            temp_dir, path = r\n        else:\n            temp_dir = None\n            path = r\n\n        # 4. Determine the destination path\n        if output_dir.url:\n            dest_path = parse.urljoin(output_dir.url, path.replace(cache_dir, \"\"))\n        else:\n            dest_path = os.path.join(output_dir.path, path.replace(cache_dir, \"\"))\n\n        # 5. Upload the file to the destination\n        if output_dir.url:\n            with open(path, \"rb\") as f:\n                s3.client.upload_fileobj(f, output_dir.url, dest_path)\n        else:\n            os.makedirs(os.path.dirname(dest_path), exist_ok=True)\n            shutil.move(path, dest_path)\n\n        # 6. Inform the worker the current file is successfully uploaded\n        if temp_dir:\n            remove_queue.put(temp_dir)\n        else:\n            remove_queue.put(path)"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Union[str, Tuple[str, str]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            remove_queue.put(None)\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            temp_dir, path = r\n        else:\n            temp_dir = None\n            path = r\n\n        # 4. Upload the file to the output directory\n        if output_dir.url is not None:\n            # Upload to S3\n            obj = parse.urlparse(output_dir.url)\n            if obj.scheme == \"s3\":\n                with open(path, \"rb\") as f:\n                    s3.client.upload_fileobj(f, obj.netloc, obj.path.lstrip(\"/\"))\n        else:\n            # Move within local filesystem\n            if temp_dir:\n                shutil.move(path, os.path.join(output_dir.path, os.path.basename(path)))\n            else:\n                shutil.move(path, os.path.join(output_dir.path, os.path.basename(path)))\n\n        # 5. Inform the worker that the file has been uploaded\n        remove_queue.put(path)"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Union[str, Tuple[str, str]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            remove_queue.put(None)\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            temp_dir, path = r\n            local_path = os.path.join(temp_dir, path)\n        else:\n            local_path = r\n\n        # 4. Upload to the output directory\n        if output_dir.url is not None or output_dir.path is not None:\n            if output_dir.url:\n                if output_dir.path:\n                    remote_path = output_dir.url + local_path.replace(cache_dir, \"\")\n                else:\n                    remote_path = output_dir.url + local_path\n            else:\n                remote_path = os.path.join(output_dir.path, local_path.replace(cache_dir, \"\"))\n\n            if output_dir.url and output_dir.path:\n                remote_path = output_dir.path + local_path.replace(cache_dir, \"\")\n\n            obj = parse.urlparse(remote_path)\n\n            if obj.scheme == \"s3\":\n                with open(local_path, \"rb\") as f:\n                    s3.client.upload_fileobj(f, obj.netloc, obj.path.lstrip(\"/\"))\n\n            elif os.path.isfile(local_path):\n                if not local_path.startswith(\"/teamspace/studios/this_studio\"):\n                    os.makedirs(os.path.dirname(remote_path), exist_ok=True)\n                    shutil.copyfile(local_path, remote_path)\n            else:\n                raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n        # 5. Inform the worker the current file is uploaded\n        remove_queue.put(local_path)"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "\n    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Union[str, Tuple[str, str]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            remove_queue.put(None)\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            temp_dir, path = r\n        else:\n            temp_dir = None\n            path = r\n\n        # 4. Upload the file to the output directory\n        if output_dir.url is not None:\n            # Upload to S3\n            obj = parse.urlparse(output_dir.url)\n            if obj.scheme == \"s3\":\n                with open(path, \"rb\") as f:\n                    s3.client.upload_fileobj(f, obj.netloc, obj.path.lstrip(\"/\"))\n\n        elif os.path.isdir(output_dir.path):\n            # Move within the local filesystem\n            new_path = os.path.join(output_dir.path, os.path.basename(path))\n            shutil.move(path, new_path)\n\n        # 5. Inform the worker that the file has been uploaded\n        remove_queue.put(path)\n        if temp_dir:\n            remove_queue.put(temp_dir)"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Union[str, Tuple[str, str]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            remove_queue.put(None)\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            temp_dir, path = r\n            local_path = os.path.join(temp_dir, path)\n        else:\n            local_path = r\n\n        # 4. Upload the file to the output directory\n        if output_dir.path:\n            # Local directory\n            if os.path.exists(local_path):\n                shutil.move(local_path, os.path.join(output_dir.path, os.path.basename(local_path)))\n            else:\n                logger.warning(f\"File {local_path} does not exist. Skipping upload.\")\n\n        elif output_dir.url:\n            # S3 bucket\n            obj = parse.urlparse(output_dir.url)\n\n            with open(local_path, \"rb\") as f:\n                s3.client.upload_fileobj(f, obj.netloc, obj.path.lstrip(\"/\"))\n\n        # 5. Inform the worker the current file is uploaded\n        remove_queue.put(local_path)"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the upload queue\n        item = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if item is None:\n            remove_queue.put(None)\n            return\n\n        # 3. If the item is a tuple, unpack it\n        if isinstance(item, tuple):\n            temp_dir, path = item\n            local_path = os.path.join(temp_dir, path)\n        else:\n            local_path = item\n\n        # 4. Determine the output path based on the output directory's scheme\n        if output_dir.url:\n            output_path = parse.urljoin(output_dir.url, Path(local_path).name)\n        else:\n            output_path = os.path.join(output_dir.path, Path(local_path).name)\n\n        # 5. Upload the file to the output directory\n        if output_dir.url:\n            with open(local_path, \"rb\") as f:\n                s3.client.upload_fileobj(f, output_dir.netloc, output_path.lstrip(\"/\"))\n        else:\n            shutil.move(local_path, output_path)\n\n        # 6. Send the file path to the remove queue for deletion\n        remove_queue.put(local_path)"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Union[str, Tuple[str, str]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            remove_queue.put(None)\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            temp_dir, path = r\n        else:\n            temp_dir, path = None, r\n\n        # 4. Construct the target path\n        if output_dir.path:\n            target_path = path.replace(cache_dir, output_dir.path)\n        else:\n            target_path = path.replace(cache_dir, output_dir.url)\n\n        # 5. Upload the file to the target directory\n        if output_dir.path:\n            os.makedirs(os.path.dirname(target_path), exist_ok=True)\n            shutil.move(path, target_path)\n        else:\n            obj = parse.urlparse(target_path)\n\n            if obj.scheme == \"s3\":\n                with open(path, \"rb\") as f:\n                    s3.client.upload_fileobj(f, obj.netloc, obj.path.lstrip(\"/\"))\n\n        # 6. Add the temporary directory to the remove queue for cleanup\n        if temp_dir:\n            remove_queue.put(temp_dir)"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            remove_queue.put(None)\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            temp_dir, path = r\n        else:\n            temp_dir = None\n            path = r\n\n        # 4. Upload the file to the output directory\n        if output_dir.url is not None:\n            obj = parse.urlparse(output_dir.url)\n            if obj.scheme == \"s3\":\n                with open(path, \"rb\") as f:\n                    s3.client.upload_fileobj(f, obj.netloc, obj.path.lstrip(\"/\"))\n            else:\n                shutil.move(path, output_dir.path)\n\n        # 5. Inform the removal worker that the file is uploaded\n        if temp_dir is not None:\n            remove_queue.put(temp_dir)\n        else:\n            remove_queue.put(path)"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            remove_queue.put(None)\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            temp_dir, path = r\n        else:\n            temp_dir = None\n            path = r\n\n        # 4. Upload the file to the output directory\n        if output_dir.url is not None:\n            # Upload to S3\n            obj = parse.urlparse(output_dir.url)\n            if obj.scheme == \"s3\":\n                with open(path, \"rb\") as f:\n                    s3.client.upload_fileobj(f, obj.netloc, obj.path.lstrip(\"/\"))\n\n        else:\n            # Move file within the local filesystem\n            output_path = os.path.join(output_dir.path, os.path.basename(path))\n            shutil.move(path, output_path)\n\n        # 5. Send the path to the remove queue for cleanup\n        if temp_dir:\n            remove_queue.put(temp_dir)\n        else:\n            remove_queue.put(path)"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        item = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if item is None:\n            return\n\n        # 3. Unpack\n        if isinstance(item, tuple):\n            temp_dir, path = item\n        else:\n            temp_dir = None\n            path = item\n\n        # 4. Determine the destination path\n        if output_dir.path:\n            dest_path = path.replace(cache_dir, output_dir.path)\n        else:\n            dest_path = path\n\n        # 5. Upload the file to the target directory\n        if output_dir.url:\n            obj = parse.urlparse(dest_path)\n\n            if obj.scheme == \"s3\":\n                with open(path, \"rb\") as f:\n                    s3.client.upload_fileobj(f, obj.netloc, obj.path.lstrip(\"/\"))\n\n            else:\n                shutil.copyfile(path, dest_path)\n\n        # 6. Send the path for removal\n        remove_queue.put(dest_path)\n\n        # 7. Remove the temporary directory if it exists\n        if temp_dir:\n            shutil.rmtree(temp_dir)"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "\n    while True:\n        # 1. Fetch from the queue\n        r = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            remove_queue.put(None)\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            temp_dir, path = r\n        else:\n            temp_dir = None\n            path = r\n\n        # 4. Construct the output path\n        if output_dir.path:\n            output_path = path.replace(cache_dir, output_dir.path)\n        else:\n            output_path = path.replace(cache_dir, output_dir.url)\n\n        # 5. Upload the file to the output directory\n        if output_dir.path:\n            os.makedirs(os.path.dirname(output_path), exist_ok=True)\n            shutil.move(path, output_path)\n        else:\n            s3 = S3Client()\n            with open(path, \"rb\") as f:\n                s3.client.upload_fileobj(f, output_dir.netloc, output_path.lstrip(\"/\"))\n\n        # 6. Send the path to the remove queue for deletion\n        if temp_dir:\n            remove_queue.put(temp_dir)\n        else:\n            remove_queue.put(path)"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            remove_queue.put(None)\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            temp_dir, file_path = r\n        else:\n            temp_dir, file_path = None, r\n\n        # 4. Determine the target path\n        if output_dir.url:\n            target_path = parse.urljoin(output_dir.url, file_path.lstrip(\"/\"))\n        else:\n            target_path = os.path.join(output_dir.path, file_path.lstrip(\"/\"))\n\n        # 5. Upload the file to the target path\n        if output_dir.url:\n            with open(file_path, \"rb\") as f:\n                s3.client.upload_fileobj(f, target_path.netloc, target_path.path.lstrip(\"/\"))\n        else:\n            os.makedirs(os.path.dirname(target_path), exist_ok=True)\n            shutil.copyfile(file_path, target_path)\n\n        # 6. Inform the worker the current file is uploaded\n        remove_queue.put(file_path)"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            remove_queue.put(None)\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            temp_dir, path = r\n            path = os.path.join(temp_dir, path)\n        else:\n            path = r\n\n        # 4. Upload the file to the output directory\n        if output_dir.url is not None or output_dir.path is not None:\n            if output_dir.url:\n                if output_dir.path:\n                    path = path.replace(cache_dir, output_dir.path)\n\n                with open(path, \"rb\") as f:\n                    s3.client.upload_fileobj(f, output_dir.url, path.replace(cache_dir, \"\").lstrip(\"/\"))\n\n            elif os.path.isdir(output_dir.path):\n                shutil.move(path, os.path.join(output_dir.path, os.path.basename(path)))"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Union[str, Tuple[str, str]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            remove_queue.put(None)\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            temp_dir, file_path = r\n            local_path = os.path.join(temp_dir, file_path)\n        else:\n            file_path = r\n            local_path = file_path\n\n        # 4. Determine the destination path\n        if output_dir.url:\n            destination_path = parse.urlparse(output_dir.url)\n            destination_path = os.path.join(destination_path.path, file_path.lstrip(\"/\"))\n        else:\n            destination_path = os.path.join(output_dir.path, file_path.lstrip(\"/\"))\n\n        # 5. Upload the file to the destination\n        if output_dir.url:\n            with open(local_path, \"rb\") as f:\n                s3.client.upload_fileobj(f, destination_path)\n        else:\n            os.makedirs(os.path.dirname(destination_path), exist_ok=True)\n            shutil.copyfile(local_path, destination_path)\n\n        # 6. Inform the worker that the file has been uploaded\n        remove_queue.put(file_path)"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "\n    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Union[str, Tuple[str, str]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            remove_queue.put(None)\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            temp_dir, path = r\n        else:\n            temp_dir = None\n            path = r\n\n        # 4. Upload the file to the output directory\n        if output_dir.url:\n            # Upload to S3 bucket\n            obj = parse.urlparse(output_dir.url)\n            if obj.scheme == \"s3\":\n                with open(path, \"rb\") as f:\n                    s3.client.upload_fileobj(f, obj.netloc, obj.path.lstrip(\"/\"))\n        else:\n            # Move within the local filesystem\n            output_path = os.path.join(output_dir.path, os.path.basename(path))\n            shutil.move(path, output_path)\n\n        # 5. Inform the remove queue about the file path for removal\n        if temp_dir:\n            remove_queue.put(temp_dir)\n        else:\n            remove_queue.put(path)"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Union[str, Tuple[str, str]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            remove_queue.put(None)\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            temp_dir, file_path = r\n        else:\n            file_path = r\n\n        # 4. Prepare the destination path\n        if output_dir.path:\n            dest_path = file_path.replace(cache_dir, output_dir.path)\n        else:\n            dest_path = file_path\n\n        # 5. Upload the file to the output directory\n        if output_dir.url:\n            with open(file_path, \"rb\") as f:\n                s3.client.upload_fileobj(f, output_dir.url, dest_path)\n        else:\n            os.makedirs(os.path.dirname(dest_path), exist_ok=True)\n            shutil.move(file_path, dest_path)\n\n        # 6. Send the file path to the remove queue for cleanup\n        remove_queue.put(file_path)"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Union[str, Tuple[str, str]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            remove_queue.put(None)\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            tmp_dir, path = r\n        else:\n            tmp_dir = None\n            path = r\n\n        # 4. Determine the target path\n        if output_dir.path:\n            target_path = path.replace(cache_dir, output_dir.path)\n        else:\n            target_path = path.replace(cache_dir, output_dir.url)\n\n        # 5. Upload the file to the target directory\n        if output_dir.path:\n            os.makedirs(os.path.dirname(target_path), exist_ok=True)\n            shutil.move(path, target_path)\n        elif output_dir.url:\n            obj = parse.urlparse(target_path)\n\n            if obj.scheme == \"s3\":\n                with open(path, \"rb\") as f:\n                    s3.client.upload_fileobj(f, obj.netloc, obj.path.lstrip(\"/\"))\n            else:\n                raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n        # 6. Inform the worker that the file is uploaded\n        remove_queue.put(target_path)\n\n        # 7. Clean up the temporary directory if it exists\n        if tmp_dir:\n            shutil.rmtree(tmp_dir)"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "\n    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            remove_queue.put(None)\n            return\n\n        # 3. Unpack the item from the queue\n        if isinstance(r, tuple):\n            temp_dir, path = r\n            local_path = os.path.join(temp_dir, path)\n        else:\n            local_path = r\n\n        # 4. Check if the file is already uploaded\n        if output_dir.path and os.path.exists(local_path.replace(cache_dir, output_dir.path)):\n            remove_queue.put(local_path)\n            continue\n\n        # 5. Upload the file to the output directory\n        if output_dir.url is not None or output_dir.path is not None:\n            if output_dir.url:\n                if output_dir.path:\n                    local_path = local_path.replace(cache_dir, output_dir.path)\n\n                # 6. Upload to S3 bucket\n                if output_dir.url.startswith(\"s3\"):\n                    obj = parse.urlparse(output_dir.url)\n                    with open(local_path, \"rb\") as f:\n                        s3.client.upload_fileobj(f, obj.netloc, obj.path.lstrip(\"/\"))\n\n            elif os.path.exists(local_path):\n                if not local_path.startswith(\"/teamspace/studios/this_studio\"):\n                    # 7. Move file within the local filesystem\n                    output_path = local_path.replace(cache_dir, output_dir.path)\n                    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n                    shutil.move(local_path, output_path)\n\n        # 8. Inform the remove queue about the successful upload\n        remove_queue.put(local_path)"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Collect paths\n        paths = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if paths is None:\n            remove_queue.put(None)\n            return\n\n        # 3. Upload the files to the output directory\n        if output_dir.url is not None or output_dir.path is not None:\n            if output_dir.url:\n                for path in paths:\n                    obj = parse.urlparse(path)\n                    if obj.scheme == \"s3\":\n                        with open(path, \"rb\") as f:\n                            s3.client.upload_fileobj(f, obj.netloc, obj.path.lstrip(\"/\"))\n                    else:\n                        raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n            else:\n                for path in paths:\n                    shutil.move(path, output_dir.path)\n        else:\n            raise ValueError(\"Output directory must have a URL or a path.\")\n\n        # 4. Inform the removal worker the current files are uploaded\n        remove_queue.put(paths)"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Union[str, Tuple[str, str]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            remove_queue.put(None)\n            return\n\n        # 3. Unpack\n        if isinstance(r, str):\n            src_path = r\n            dest_path = os.path.join(output_dir.path, os.path.basename(r)) if output_dir.path else r\n        elif isinstance(r, tuple) and len(r) == 2:\n            temp_dir, src_path = r\n            dest_path = os.path.join(output_dir.path, os.path.basename(src_path)) if output_dir.path else src_path\n            dest_path = os.path.join(output_dir.path, os.path.basename(src_path)) if output_dir.path else src_path\n        else:\n            raise ValueError(\"Invalid item in the upload queue\")\n\n        # 4. Upload the file to the output directory\n        if output_dir.url:\n            s3.client.upload_file(src_path, output_dir.netloc, dest_path.lstrip(\"/\"))\n        else:\n            shutil.move(src_path, dest_path)\n\n        # 5. Inform the worker that the file has been uploaded\n        remove_queue.put(dest_path)"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    if weights is None:\n        weights = [1] * len(user_items)\n\n    total_weight = sum(weights)\n\n    # Calculate the total number of workers across all nodes\n    num_nodes = _get_num_nodes()\n    world_size = num_nodes * num_workers\n\n    # Distribute items to workers based on provided weights\n    num_items_per_worker = [0] * world_size\n    for i, item in enumerate(user_items):\n        worker_idx = i % world_size\n        num_items_per_worker[worker_idx] += weights[i]\n\n    # Print the distribution details for workers on the current node\n    node_rank = _get_node_rank()\n    worker_idx_start = node_rank * num_workers\n    worker_idx_end = (node_rank + 1) * num_workers\n    for worker_idx in range(worker_idx_start, worker_idx_end):\n        worker_weight = num_items_per_worker[worker_idx]\n        items_assigned = len(user_items) * (worker_weight / total_weight)\n        if file_size:\n            items_assigned = items_assigned / (1024 * 1024)  # Convert to megabytes\n            print(f\"Node {node_rank}, Worker {worker_idx % num_workers}: {items_assigned:.2f} MB\")\n        else:\n            print(f\"Node {node_rank}, Worker {worker_idx % num_workers}: {items_assigned:.2f} items\")\n\n    # Return a list of items for each worker, with the items shuffled\n    out = []\n    for worker_idx in range(world_size):\n        start = sum(num_items_per_worker[:worker_idx])\n        end = start + num_items_per_worker[worker_idx]\n        worker_items = user_items[start:end]\n        random.shuffle(worker_items)\n        out.append(worker_items)\n\n    return out"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    if weights is None:\n        weights = [1] * len(user_items)\n\n    total_weight = sum(weights)\n    num_nodes = _get_num_nodes()\n    world_size = num_nodes * num_workers\n\n    # Calculate the weighted distribution of items\n    weighted_items = []\n    for item, weight in zip(user_items, weights):\n        weighted_items.extend([item] * int((weight / total_weight) * world_size))\n\n    # Shuffle the weighted items\n    random.shuffle(weighted_items)\n\n    # Distribute the items to the workers based on node rank\n    num_items_per_worker = len(weighted_items) // world_size\n    num_items_per_worker = [num_items_per_worker for _ in range(world_size)]\n    reminder = len(weighted_items) % world_size\n\n    for worker_idx in range(len(num_items_per_worker) - 1, -1, -1):\n        if reminder == 0:\n            break\n        num_items_per_worker[worker_idx] += 1\n        reminder -= 1\n\n    num_items_cumsum_per_worker = np.cumsum([0] + num_items_per_worker)\n\n    out = []\n    node_rank = _get_node_rank()\n    worker_idx_start = node_rank * num_workers\n    worker_idx_end = (node_rank + 1) * num_workers\n\n    for worker_idx in range(world_size):\n        if worker_idx_start <= worker_idx and worker_idx < worker_idx_end:\n            start = num_items_cumsum_per_worker[worker_idx]\n            end = num_items_cumsum_per_worker[worker_idx + 1]\n            out.append(weighted_items[start:end])\n\n    if len(out) != num_workers:\n        raise RuntimeError(\"The items didn't haven't been assigned properly. Please, open an issue on Github.\")\n\n    return out"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Calculate the total number of workers across all nodes\n    num_nodes = _get_num_nodes()\n    world_size = num_nodes * num_workers\n\n    # If weights are not provided, consider all items to have equal weight\n    if weights is None:\n        weights = [1] * len(user_items)\n\n    # Calculate the total weight of all items\n    total_weight = sum(weights)\n\n    # Calculate the number of items each worker should receive based on weights\n    num_items_per_worker = [int((weight / total_weight) * len(user_items)) for weight in weights]\n\n    # Calculate the remainder of items after distribution based on weights\n    remainder = len(user_items) - sum(num_items_per_worker)\n\n    # Distribute the remainder of items to the workers with the highest weights\n    for i in range(remainder):\n        max_weight_idx = weights.index(max(weights))\n        num_items_per_worker[max_weight_idx] += 1\n        weights[max_weight_idx] = 0\n\n    # Calculate the cumulative sum of items per worker\n    num_items_cumsum_per_worker = np.cumsum([0] + num_items_per_worker)\n\n    # Initialize a list to store the items for each worker\n    out = []\n\n    # Get the node rank\n    node_rank = _get_node_rank()\n\n    # Calculate the start and end index of workers for the current node\n    worker_idx_start = node_rank * num_workers\n    worker_idx_end = (node_rank + 1) * num_workers\n\n    # Assign items to workers based on their indices\n    for worker_idx in range(world_size):\n        if worker_idx_start <= worker_idx < worker_idx_end:\n            start = num_items_cumsum_per_worker[worker_idx]\n            end = num_items_cumsum_per_worker[worker_idx + 1]\n            worker_items = user_items[start:end]\n            random.shuffle(worker_items)  # Shuffle the items for each worker\n            out.append(worker_items)\n\n    # Check if all workers have been assigned items properly\n    if len(out) != num_workers:\n        raise RuntimeError(\"The items haven't been assigned properly. Please open an issue on Github.\")\n\n    return out"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "\n    if weights is None:\n        weights = [1] * len(user_items)\n\n    if len(user_items) != len(weights):\n        raise ValueError(\"Length of weights should be equal to the length of user_items\")\n\n    total_weight = sum(weights)\n\n    num_nodes = _get_num_nodes()\n    world_size = num_nodes * num_workers\n\n    # Calculate the total number of items per worker based on weights\n    num_items_per_worker = [0] * world_size\n    for i, item in enumerate(user_items):\n        worker_idx = i % world_size\n        num_items_per_worker[worker_idx] += weights[i]\n\n    # Print distribution details for workers on the current node\n    node_rank = _get_node_rank()\n    worker_idx_start = node_rank * num_workers\n    worker_idx_end = (node_rank + 1) * num_workers\n\n    for worker_idx in range(worker_idx_start, worker_idx_end):\n        if worker_idx < world_size:\n            if file_size:\n                print(f\"Worker {worker_idx % num_workers} on Node {node_rank}: {num_items_per_worker[worker_idx] / 1e6:.2f} MB\")\n            else:\n                print(f\"Worker {worker_idx % num_workers} on Node {node_rank}: {num_items_per_worker[worker_idx]}\")\n\n    # Distribute the items to the workers\n    out = [[] for _ in range(num_workers)]\n    for i, item in enumerate(user_items):\n        worker_idx = i % world_size\n        out[worker_idx % num_workers].append(item)\n\n    # Shuffle the items in each worker's list\n    for i in range(num_workers):\n        random.shuffle(out[i])\n\n    return out"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Calculate the total number of workers across all nodes\n    num_nodes = _get_num_nodes()\n    world_size = num_nodes * num_workers\n    \n    # If weights are not provided, consider all items to have equal weight\n    if weights is None:\n        weights = [1] * len(user_items)\n    \n    # Calculate the total weight of all items\n    total_weight = sum(weights)\n    \n    # Calculate the number of items per worker based on weights and total workers\n    num_items_per_worker = [int((w / total_weight) * len(user_items)) for w in weights]\n    \n    # Calculate the reminder for uneven distribution\n    reminder = len(user_items) - sum(num_items_per_worker)\n    \n    # Distribute the reminder items to workers based on weights\n    for worker_idx in range(len(num_items_per_worker)):\n        if reminder == 0:\n            break\n        num_items_per_worker[worker_idx] += 1\n        reminder -= 1\n    \n    # Calculate the cumulative sum of items per worker\n    num_items_cumsum_per_worker = np.cumsum([0] + num_items_per_worker)\n    \n    # Initialize the output list\n    out = []\n    node_rank = _get_node_rank()\n    worker_idx_start = node_rank * num_workers\n    worker_idx_end = (node_rank + 1) * num_workers\n    \n    # Assign items to workers based on node rank and number of workers\n    for worker_idx in range(world_size):\n        if worker_idx_start <= worker_idx and worker_idx < worker_idx_end:\n            start = num_items_cumsum_per_worker[worker_idx]\n            end = num_items_cumsum_per_worker[worker_idx + 1]\n            worker_items = user_items[start:end]\n            random.shuffle(worker_items)  # Shuffle the items for each worker\n            out.append(worker_items)\n    \n    # Check if all workers have been assigned items properly\n    if len(out) != num_workers:\n        raise RuntimeError(\"The items didn't haven't been assigned properly. Please, open an issue on Github.\")\n    \n    return out"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "\n    if weights is None:\n        weights = [1] * len(user_items)\n\n    total_weight = sum(weights)\n    num_nodes = _get_num_nodes()\n    world_size = num_nodes * num_workers\n\n    weighted_items = []\n    for item, weight in zip(user_items, weights):\n        weighted_items.extend([item] * int((weight / total_weight) * world_size))\n\n    random.shuffle(weighted_items)\n\n    num_items_per_worker = len(weighted_items) // world_size\n    num_items_per_worker = [num_items_per_worker] * world_size\n    reminder = len(weighted_items) % world_size\n\n    for worker_idx in range(world_size):\n        if reminder == 0:\n            break\n        num_items_per_worker[worker_idx] += 1\n        reminder -= 1\n\n    num_items_cumsum_per_worker = np.cumsum([0] + num_items_per_worker)\n\n    out = []\n    node_rank = _get_node_rank()\n    worker_idx_start = node_rank * num_workers\n    worker_idx_end = (node_rank + 1) * num_workers\n\n    for worker_idx in range(world_size):\n        if worker_idx_start <= worker_idx and worker_idx < worker_idx_end:\n            start = num_items_cumsum_per_worker[worker_idx]\n            end = num_items_cumsum_per_worker[worker_idx + 1]\n            out.append(weighted_items[start:end])\n\n    if len(out) != num_workers:\n        raise RuntimeError(\"The items didn't haven't been assigned properly. Please, open an issue on Github.\")\n\n    return out"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Calculate the total number of workers across all nodes\n    num_nodes = _get_num_nodes()\n    world_size = num_nodes * num_workers\n    \n    # If weights are not provided, consider all items to have equal weight\n    if weights is None:\n        weights = [1] * len(user_items)\n    \n    # Calculate the total weight of all items\n    total_weight = sum(weights)\n    \n    # Calculate the weighted number of items per worker\n    weighted_items_per_worker = [int((weight / total_weight) * len(user_items)) for weight in weights]\n    \n    # Distribute the remaining items to the workers based on the remainder\n    remainder = len(user_items) - sum(weighted_items_per_worker)\n    for i in range(remainder):\n        weighted_items_per_worker[i] += 1\n    \n    # Print the distribution details for workers on the current node\n    node_rank = _get_node_rank()\n    worker_idx_start = node_rank * num_workers\n    worker_idx_end = (node_rank + 1) * num_workers\n    \n    for worker_idx in range(world_size):\n        if worker_idx_start <= worker_idx and worker_idx < worker_idx_end:\n            start = sum(weighted_items_per_worker[:worker_idx])\n            end = start + weighted_items_per_worker[worker_idx]\n            worker_items = user_items[start:end]\n            if file_size:\n                print(f\"Worker {worker_idx % num_workers} on Node {node_rank} has {len(worker_items)} items with total size {sum(weights[start:end])} MB\")\n            else:\n                print(f\"Worker {worker_idx % num_workers} on Node {node_rank} has {len(worker_items)} items with total weight {sum(weights[start:end])}\")\n    \n    # Shuffle and return the list of items for each worker\n    out = []\n    for i in range(world_size):\n        start = sum(weighted_items_per_worker[:i])\n        end = start + weighted_items_per_worker[i]\n        worker_items = user_items[start:end]\n        random.shuffle(worker_items)\n        out.append(worker_items)\n    \n    return out"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Calculate the total number of workers across all nodes\n    num_nodes = _get_num_nodes()\n    world_size = num_nodes * num_workers\n\n    # If weights are not provided, consider all items to have equal weight\n    if weights is None:\n        weights = [1] * len(user_items)\n\n    # Calculate the total weight of all items\n    total_weight = sum(weights)\n\n    # Calculate the number of items per worker based on their weights\n    num_items_per_worker = [int((weight / total_weight) * len(user_items)) for weight in weights]\n\n    # Distribute the remaining items to the workers with the highest weights\n    remaining_items = len(user_items) - sum(num_items_per_worker)\n    for _ in range(remaining_items):\n        max_weight_idx = weights.index(max(weights))\n        num_items_per_worker[max_weight_idx] += 1\n\n    # Calculate the cumulative sum of items per worker\n    num_items_cumsum_per_worker = np.cumsum([0] + num_items_per_worker)\n\n    # Initialize a list to store the items for each worker\n    out = []\n\n    # Get the node rank\n    node_rank = _get_node_rank()\n\n    # Calculate the start and end indices for the workers on the current node\n    worker_idx_start = node_rank * num_workers\n    worker_idx_end = (node_rank + 1) * num_workers\n\n    # Assign items to workers based on their indices\n    for worker_idx in range(world_size):\n        if worker_idx_start <= worker_idx < worker_idx_end:\n            start = num_items_cumsum_per_worker[worker_idx]\n            end = num_items_cumsum_per_worker[worker_idx + 1]\n            worker_items = user_items[start:end]\n            random.shuffle(worker_items)  # Shuffle the items for each worker\n            out.append(worker_items)\n\n    # Verify that all workers have been assigned items\n    if len(out) != num_workers:\n        raise RuntimeError(\"The items were not assigned properly. Please open an issue on Github.\")\n\n    return out"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Calculate the total number of workers across all nodes\n    num_nodes = _get_num_nodes()\n    world_size = num_nodes * num_workers\n    \n    # If weights are not provided, assume all items have equal weight\n    if weights is None:\n        weights = [1] * len(user_items)\n    \n    # Distribute items to workers based on weights\n    total_weight = sum(weights)\n    num_items_per_worker = [0] * world_size\n    items_assigned = [0] * len(user_items)\n    \n    for i in range(len(user_items)):\n        worker_idx = i % world_size\n        num_items_per_worker[worker_idx] += weights[i]\n        items_assigned[i] = worker_idx\n    \n    # Print distribution details for workers on the current node\n    node_rank = _get_node_rank()\n    worker_idx_start = node_rank * num_workers\n    worker_idx_end = (node_rank + 1) * num_workers\n    \n    for worker_idx in range(worker_idx_start, worker_idx_end):\n        if worker_idx < world_size:\n            if file_size:\n                print(f\"Worker {worker_idx}: {num_items_per_worker[worker_idx]} MB\")\n            else:\n                print(f\"Worker {worker_idx}: {num_items_per_worker[worker_idx]} items\")\n    \n    # Shuffle the items assigned to each worker\n    out = [[] for _ in range(num_workers)]\n    for i, worker_idx in enumerate(items_assigned):\n        out[worker_idx].append(user_items[i])\n    \n    for i in range(num_workers):\n        random.shuffle(out[i])\n    \n    return out"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    if weights is None:\n        weights = [1] * len(user_items)\n\n    if len(user_items) != len(weights):\n        raise ValueError(\"Length of user_items and weights must be the same.\")\n\n    total_weight = sum(weights)\n    num_nodes = _get_num_nodes()\n    world_size = num_nodes * num_workers\n\n    weighted_items = []\n    for item, weight in zip(user_items, weights):\n        weighted_items.extend([item] * int(weight / total_weight * world_size))\n\n    random.shuffle(weighted_items)\n\n    num_items_per_worker = len(weighted_items) // world_size\n    num_items_per_worker = [num_items_per_worker for _ in range(world_size)]\n\n    reminder = len(weighted_items) % world_size\n    for worker_idx in range(len(num_items_per_worker) - 1, -1, -1):\n        if reminder == 0:\n            break\n        num_items_per_worker[worker_idx] += 1\n        reminder -= 1\n\n    num_items_cumsum_per_worker = np.cumsum([0] + num_items_per_worker)\n\n    out = []\n    node_rank = _get_node_rank()\n    worker_idx_start = node_rank * num_workers\n    worker_idx_end = (node_rank + 1) * num_workers\n\n    for worker_idx in range(world_size):\n        if worker_idx_start <= worker_idx and worker_idx < worker_idx_end:\n            start = num_items_cumsum_per_worker[worker_idx]\n            end = num_items_cumsum_per_worker[worker_idx + 1]\n            out.append(weighted_items[start:end])\n\n    if len(out) != num_workers:\n        raise RuntimeError(\"The items didn't haven't been assigned properly. Please, open an issue on Github.\")\n\n    return out"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Calculate the total number of workers across all nodes\n    num_nodes = _get_num_nodes()\n    world_size = num_nodes * num_workers\n    \n    # If weights are not provided, consider all items to have equal weight\n    if weights is None:\n        weights = [1] * len(user_items)\n    \n    # Calculate the total weight of all items\n    total_weight = sum(weights)\n    \n    # Calculate the weight per worker\n    weight_per_worker = total_weight / world_size\n    \n    # Calculate the cumulative sum of weights\n    cumulative_weights = np.cumsum(weights)\n    \n    # Initialize variables to store the items assigned to each worker\n    assigned_items = [[] for _ in range(world_size)]\n    current_worker = 0\n    current_weight = 0\n    \n    # Iterate through the items and assign them to workers based on weights\n    for item, weight in zip(user_items, weights):\n        # If considering file size, convert weight to megabytes\n        if file_size:\n            weight_mb = weight / (1024 * 1024)\n        else:\n            weight_mb = weight\n        \n        # Print the item and its weight\n        print(f\"Item: {item}, Weight: {weight_mb} MB\")\n        \n        # Assign the item to the current worker\n        assigned_items[current_worker].append(item)\n        \n        # Update the current weight for the worker\n        current_weight += weight\n        \n        # If the current weight exceeds the weight per worker, move to the next worker\n        while current_weight > weight_per_worker:\n            current_worker += 1\n            current_weight -= weight_per_worker\n    \n    # Shuffle the assigned items for each worker\n    for i in range(world_size):\n        random.shuffle(assigned_items[i])\n    \n    # Print the distribution details for workers on the current node\n    node_rank = _get_node_rank()\n    worker_idx_start = node_rank * num_workers\n    worker_idx_end = (node_rank + 1) * num_workers\n    for worker_idx in range(worker_idx_start, worker_idx_end):\n        print(f\"Worker {worker_idx}: {len(assigned_items[worker_idx])} items\")\n    \n    return assigned_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    if weights is None:\n        weights = [1] * len(user_items)\n\n    total_weight = sum(weights)\n    num_nodes = _get_num_nodes()\n    world_size = num_nodes * num_workers\n    weighted_items = []\n\n    for i, item in enumerate(user_items):\n        weighted_items.extend([item] * int((weights[i] / total_weight) * world_size))\n\n    random.shuffle(weighted_items)\n\n    num_items_per_worker = len(weighted_items) // world_size\n    num_items_per_worker = [num_items_per_worker for _ in range(world_size)]\n    reminder = len(weighted_items) % world_size\n\n    for worker_idx in range(len(num_items_per_worker) - 1, -1, -1):\n        if reminder == 0:\n            break\n        num_items_per_worker[worker_idx] += 1\n        reminder -= 1\n\n    num_items_cumsum_per_worker = np.cumsum([0] + num_items_per_worker)\n\n    out = []\n    node_rank = _get_node_rank()\n    worker_idx_start = node_rank * num_workers\n    worker_idx_end = (node_rank + 1) * num_workers\n\n    for worker_idx in range(world_size):\n        if worker_idx_start <= worker_idx and worker_idx < worker_idx_end:\n            start = num_items_cumsum_per_worker[worker_idx]\n            end = num_items_cumsum_per_worker[worker_idx + 1]\n            out.append(weighted_items[start:end])\n\n    if len(out) != num_workers:\n        raise RuntimeError(\"The items didn't haven't been assigned properly. Please, open an issue on Github.\")\n\n    return out"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "\n    num_nodes = _get_num_nodes()\n    world_size = num_nodes * num_workers\n\n    if weights is None:\n        weights = [1] * len(user_items)\n\n    total_weight = sum(weights)\n\n    num_items_per_worker = [0] * world_size\n\n    for i, weight in enumerate(weights):\n        worker_idx = i % world_size\n        num_items_per_worker[worker_idx] += weight\n\n    if file_size:\n        print(f\"Total file size: {total_weight / (1024 * 1024):.2f} MB\")\n        print(\"Items distribution:\")\n        for i in range(world_size):\n            print(f\"Worker {i}: {num_items_per_worker[i]} items, {sum(weights[i::world_size]) / (1024 * 1024):.2f} MB\")\n    else:\n        print(f\"Total weight: {total_weight}\")\n        print(\"Items distribution:\")\n        for i in range(world_size):\n            print(f\"Worker {i}: {num_items_per_worker[i]} items, {sum(weights[i::world_size])}\")\n\n    items_assigned = [[] for _ in range(world_size)]\n\n    for i, item in enumerate(user_items):\n        worker_idx = i % world_size\n        items_assigned[worker_idx].append(item)\n\n    for i in range(world_size):\n        random.shuffle(items_assigned[i])\n\n    return items_assigned"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # If weights are not provided, set all weights to 1\n    if weights is None:\n        weights = [1] * len(user_items)\n\n    # Calculate the total weight\n    total_weight = sum(weights)\n\n    # Calculate the weight per worker\n    weight_per_worker = total_weight / (num_workers * _get_num_nodes())\n\n    # Calculate the cumulative weights\n    cumulative_weights = np.cumsum(weights)\n\n    # Initialize the distribution\n    distribution = [[] for _ in range(num_workers)]\n\n    # Assign items to workers based on weights\n    for idx, item in enumerate(user_items):\n        assigned = False\n        for worker_idx in range(num_workers):\n            if cumulative_weights[idx] <= weight_per_worker * (worker_idx + 1):\n                distribution[worker_idx].append(item)\n                assigned = True\n                break\n        if not assigned:\n            distribution[-1].append(item)\n\n    # Shuffle the items in each worker's list\n    for worker_idx in range(num_workers):\n        random.shuffle(distribution[worker_idx])\n\n    # Print distribution details for workers on the current node\n    node_rank = _get_node_rank()\n    if node_rank == 0:\n        print(f\"Distribution details for workers on node {node_rank}:\")\n        for worker_idx in range(num_workers):\n            if file_size:\n                total_size_mb = sum(weights[user_items.index(item)] for item in distribution[worker_idx]) / 1e6\n                print(f\"Worker {worker_idx}: {len(distribution[worker_idx])} items, total size: {total_size_mb:.2f} MB\")\n            else:\n                print(f\"Worker {worker_idx}: {len(distribution[worker_idx])} items, total weight: {sum(weights[user_items.index(item)] for item in distribution[worker_idx])}\")\n\n    return distribution"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    if weights is None:\n        weights = [1] * len(user_items)\n\n    total_weight = sum(weights)\n    weighted_items = []\n\n    for item, weight in zip(user_items, weights):\n        weighted_items.extend([item] * weight)\n\n    num_nodes = _get_num_nodes()\n    world_size = num_nodes * num_workers\n    num_items_per_worker = [int(len(weighted_items) / world_size)] * world_size\n\n    reminder = len(weighted_items) % world_size\n\n    for worker_idx in range(len(num_items_per_worker) - 1, -1, -1):\n        if reminder == 0:\n            break\n        num_items_per_worker[worker_idx] += 1\n        reminder -= 1\n\n    num_items_cumsum_per_worker = np.cumsum([0] + num_items_per_worker)\n\n    out = []\n    node_rank = _get_node_rank()\n    worker_idx_start = node_rank * num_workers\n    worker_idx_end = (node_rank + 1) * num_workers\n\n    for worker_idx in range(world_size):\n        if worker_idx_start <= worker_idx and worker_idx < worker_idx_end:\n            start = num_items_cumsum_per_worker[worker_idx]\n            end = num_items_cumsum_per_worker[worker_idx + 1]\n            worker_items = weighted_items[start:end]\n            random.shuffle(worker_items)\n            out.append(worker_items)\n\n    if len(out) != num_workers:\n        raise RuntimeError(\"The items didn't haven't been assigned properly. Please, open an issue on Github.\")\n\n    return out"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # If weights are not provided, set all weights to 1\n    if weights is None:\n        weights = [1] * len(user_items)\n\n    # Calculate the total weight\n    total_weight = sum(weights)\n\n    # Calculate the weight per worker\n    weight_per_worker = total_weight / (num_workers * _get_num_nodes())\n\n    # Calculate the cumulative weights\n    cumulative_weights = np.cumsum(weights)\n\n    # Initialize the items assigned to each worker\n    items_assigned = [[] for _ in range(num_workers)]\n\n    # Assign items to workers based on weights\n    for i, item in enumerate(user_items):\n        # Calculate the worker index based on cumulative weights\n        worker_idx = np.searchsorted(cumulative_weights, (i + 1) * weight_per_worker, side=\"right\")\n\n        # Ensure the worker index is within bounds\n        worker_idx = min(worker_idx, num_workers - 1)\n\n        # Assign the item to the corresponding worker\n        items_assigned[worker_idx].append(item)\n\n    # Shuffle the items for each worker\n    for i in range(num_workers):\n        random.shuffle(items_assigned[i])\n\n    # Print the distribution details for workers on the current node\n    node_rank = _get_node_rank()\n    if node_rank == 0:\n        print(f\"Worker distribution details:\")\n        for i in range(num_workers):\n            if file_size:\n                total_size_mb = sum(weights[user_items.index(item)] for item in items_assigned[i]) / (1024 * 1024)\n                print(f\"Worker {i}: {len(items_assigned[i])} items, total size: {total_size_mb:.2f} MB\")\n            else:\n                total_weight = sum(weights[user_items.index(item)] for item in items_assigned[i])\n                print(f\"Worker {i}: {len(items_assigned[i])} items, total weight: {total_weight}\")\n\n    return items_assigned"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "\n    if weights is None:\n        weights = [1] * len(user_items)\n\n    total_workers = _get_num_nodes() * num_workers\n    total_weight = sum(weights)\n\n    # Calculate the number of items each worker should get\n    items_per_worker = [0] * total_workers\n    for i, item in enumerate(user_items):\n        worker_idx = i % total_workers\n        items_per_worker[worker_idx] += weights[i]\n\n    # Print distribution details\n    if file_size:\n        print(\"File distribution details:\")\n        for i in range(total_workers):\n            print(f\"Worker {i}: {items_per_worker[i] / 1e6:.2f} MB\")\n    else:\n        print(\"Weight distribution details:\")\n        for i in range(total_workers):\n            print(f\"Worker {i}: {items_per_worker[i] / total_weight:.2%}\")\n\n    # Assign items to workers\n    assigned_items = [[] for _ in range(total_workers)]\n    for i, item in enumerate(user_items):\n        worker_idx = i % total_workers\n        assigned_items[worker_idx].append(item)\n\n    # Shuffle the assigned items\n    for i in range(total_workers):\n        random.shuffle(assigned_items[i])\n\n    return assigned_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "\n    # Calculate the total number of workers across all nodes\n    num_nodes = _get_num_nodes()\n    world_size = num_nodes * num_workers\n\n    # If weights are not provided, assume all items have equal weight\n    if weights is None:\n        weights = [1] * len(user_items)\n\n    # Distribute items to workers based on provided weights\n    total_weight = sum(weights)\n    num_items_per_worker = [0] * world_size\n    items_indices = list(range(len(user_items)))\n\n    for worker_idx in range(world_size):\n        start_idx = int(worker_idx * len(user_items) / world_size)\n        end_idx = int((worker_idx + 1) * len(user_items) / world_size)\n\n        # Calculate the total weight of items assigned to this worker\n        worker_weight = sum(weights[i] for i in items_indices[start_idx:end_idx])\n\n        # Calculate the number of items assigned to this worker\n        num_items_per_worker[worker_idx] = int(len(user_items) * worker_weight / total_weight)\n\n    # Distribute the remaining items to workers based on the remainder\n    remainder = len(user_items) - sum(num_items_per_worker)\n    for i in range(remainder):\n        worker_idx = i % world_size\n        num_items_per_worker[worker_idx] += 1\n\n    # Print the distribution details for workers on the current node\n    node_rank = _get_node_rank()\n    worker_idx_start = node_rank * num_workers\n    worker_idx_end = (node_rank + 1) * num_workers\n\n    for worker_idx in range(world_size):\n        if worker_idx_start <= worker_idx < worker_idx_end:\n            start_idx = sum(num_items_per_worker[:worker_idx])\n            end_idx = start_idx + num_items_per_worker[worker_idx]\n\n            if file_size:\n                # Print the file sizes in megabytes\n                total_size_mb = sum(weights[i] for i in items_indices[start_idx:end_idx]) / (1024 * 1024)\n                print(f\"Worker {worker_idx} on Node {node_rank}: {num_items_per_worker[worker_idx]} items, Total Size: {total_size_mb:.2f} MB\")\n            else:\n                # Print the total weight of items\n                total_weight = sum(weights[i] for i in items_indices[start_idx:end_idx])\n                print(f\"Worker {worker_idx} on Node {node_rank}: {num_items_per_worker[worker_idx]} items, Total Weight: {total_weight}\")\n\n    # Return a list of items for each worker, with the items shuffled randomly\n    items_assigned = []\n    for worker_idx in range(world_size):\n        start_idx = sum(num_items_per_worker[:worker_idx])\n        end_idx = start_idx + num_items_per_worker[worker_idx]\n        worker_items = [user_items[i] for i in items_indices[start_idx:end_idx]]\n        random.shuffle(worker_items)\n        items_assigned.append(worker_items)\n\n    return items_assigned"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "\n    num_nodes = _get_num_nodes()\n    world_size = num_nodes * num_workers\n\n    if weights is None:\n        weights = [1] * len(user_items)\n\n    total_weight = sum(weights)\n    items_with_weights = list(zip(user_items, weights))\n\n    items_distribution = []\n    for i in range(world_size):\n        items_distribution.append([])\n\n    for item, weight in items_with_weights:\n        assigned = False\n        for i in range(world_size):\n            if not assigned and len(items_distribution[i]) < total_weight / world_size:\n                items_distribution[i].append(item)\n                assigned = True\n\n    for i in range(world_size):\n        random.shuffle(items_distribution[i])\n\n    return items_distribution"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Calculate the total number of workers across all nodes\n    num_nodes = _get_num_nodes()\n    world_size = num_nodes * num_workers\n\n    # If weights are not provided, consider all items to have equal weight\n    if weights is None:\n        weights = [1] * len(user_items)\n\n    # Distribute items to workers based on provided weights\n    total_weight = sum(weights)\n    num_items_per_worker = [0] * world_size\n    items_assigned = [set() for _ in range(world_size)]\n\n    for idx, item in enumerate(user_items):\n        weight = weights[idx]\n        if file_size:\n            weight_mb = weight / (1024 * 1024)  # Convert weight to megabytes for printing purposes\n            logging.info(f\"Item {idx} has a size of {weight_mb:.2f} MB\")\n        else:\n            logging.info(f\"Item {idx} has a weight of {weight}\")\n\n        # Assign the item to the worker with the least total weight\n        min_idx = num_items_per_worker.index(min(num_items_per_worker))\n        num_items_per_worker[min_idx] += weight\n        items_assigned[min_idx].add(item)\n\n    # Print distribution details for workers on the current node\n    node_rank = _get_node_rank()\n    worker_idx_start = node_rank * num_workers\n    worker_idx_end = (node_rank + 1) * num_workers\n\n    for worker_idx in range(world_size):\n        if worker_idx_start <= worker_idx and worker_idx < worker_idx_end:\n            logging.info(f\"Worker {worker_idx} has {len(items_assigned[worker_idx])} items assigned\")\n\n    # Shuffle the items assigned to each worker\n    out = [list(items) for items in items_assigned]\n    for items in out:\n        random.shuffle(items)\n\n    return out"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    total_items = len(user_items)\n    total_workers = _get_num_nodes() * num_workers\n    items_per_worker = total_items // total_workers\n    extra_items = total_items % total_workers\n\n    start = 0\n    distributed_items = []\n    for i in range(total_workers):\n        end = start + items_per_worker + (1 if i < extra_items else 0)\n        distributed_items.append(user_items[start:end])\n        start = end\n\n    if len(distributed_items) != total_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    return distributed_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    total_items = len(user_items)\n    total_workers = num_workers * _get_num_nodes()\n    items_per_worker = total_items // total_workers\n    remainder = total_items % total_workers\n\n    start_idx = 0\n    distributed_items = []\n\n    for i in range(num_workers):\n        extra = 1 if i < remainder else 0\n        worker_items = user_items[start_idx:start_idx + items_per_worker + extra]\n        distributed_items.append(worker_items)\n        start_idx += len(worker_items)\n\n    if start_idx != total_items:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    return distributed_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "\n    total_workers = _get_num_nodes() * num_workers\n    total_items = len(user_items)\n    items_per_worker = total_items // total_workers\n    extra_items = total_items % total_workers\n\n    start = 0\n    end = 0\n    result = []\n\n    for i in range(total_workers):\n        end += items_per_worker + (1 if i < extra_items else 0)\n        result.append(user_items[start:end])\n        start = end\n\n    if len(result) != total_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    return result"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    total_workers = _get_num_nodes() * num_workers\n    items_per_worker = len(user_items) // total_workers\n    remainder = len(user_items) % total_workers\n\n    start = 0\n    result = []\n\n    for i in range(total_workers):\n        end = start + items_per_worker + (1 if i < remainder else 0)\n        result.append(user_items[start:end])\n        start = end\n\n    if len(result) != total_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    return result"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "\n    total_workers = _get_num_nodes() * num_workers\n    total_items = len(user_items)\n    items_per_worker = total_items // total_workers\n    remainder = total_items % total_workers\n\n    start_idx = 0\n    end_idx = 0\n    assigned_items = []\n\n    for i in range(total_workers):\n        end_idx += items_per_worker + (1 if i < remainder else 0)\n        assigned_items.append(user_items[start_idx:end_idx])\n        start_idx = end_idx\n\n    if len(assigned_items) != total_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    return assigned_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    total_workers = _get_num_nodes() * num_workers\n    total_items = len(user_items)\n    items_per_worker = total_items // total_workers\n    remainder = total_items % total_workers\n\n    start = 0\n    assigned_items = []\n\n    for i in range(total_workers):\n        end = start + items_per_worker + (1 if i < remainder else 0)\n        assigned_items.append(user_items[start:end])\n        start = end\n\n    if len(assigned_items) != total_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    return assigned_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    total_workers = _get_num_nodes() * num_workers\n    total_items = len(user_items)\n\n    items_per_worker = total_items // total_workers\n    remainder = total_items % total_workers\n\n    worker_assignments = [items_per_worker] * total_workers\n\n    for i in range(remainder):\n        worker_assignments[-(i + 1)] += 1\n\n    start_indices = [0] + list(np.cumsum(worker_assignments))[:-1]\n    end_indices = list(np.cumsum(worker_assignments))\n\n    if len(end_indices) != num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    assigned_items = [user_items[start:end] for start, end in zip(start_indices, end_indices)]\n\n    return assigned_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    total_workers = _get_num_nodes() * num_workers\n    total_items = len(user_items)\n    items_per_worker = total_items // total_workers\n    extra_items = total_items % total_workers\n\n    start = 0\n    end = 0\n    assigned_items = []\n\n    for i in range(total_workers):\n        end += items_per_worker + (1 if i < extra_items else 0)\n        assigned_items.append(user_items[start:end])\n        start = end\n\n    if len(assigned_items) != num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    return assigned_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "\n    total_workers = _get_num_nodes() * num_workers\n    num_items = len(user_items)\n    items_per_worker = num_items // total_workers\n    remainder = num_items % total_workers\n\n    start = 0\n    assigned_items = []\n\n    for i in range(total_workers):\n        end = start + items_per_worker + (1 if i < remainder else 0)\n        assigned_items.append(user_items[start:end])\n        start = end\n\n    if len(assigned_items) != total_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    return assigned_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    total_workers = _get_num_nodes() * num_workers\n    num_items = len(user_items)\n    items_per_worker = num_items // total_workers\n    remainder = num_items % total_workers\n\n    worker_assignments = [items_per_worker] * total_workers\n    for i in range(remainder):\n        worker_assignments[-(i + 1)] += 1\n\n    start_indices = [0] + list(np.cumsum(worker_assignments))[:-1]\n    end_indices = list(np.cumsum(worker_assignments))\n\n    if len(end_indices) != num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    assigned_items = [user_items[start_indices[i]:end_indices[i]] for i in range(num_workers)]\n\n    return assigned_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "\n    total_items = len(user_items)\n    total_workers = _get_num_nodes() * num_workers\n    items_per_worker = total_items // total_workers\n    remainder = total_items % total_workers\n\n    worker_assignments = []\n\n    start_idx = 0\n    for i in range(num_workers):\n        extra = 1 if i < remainder else 0\n        end_idx = start_idx + items_per_worker + extra\n        worker_assignments.append(user_items[start_idx:end_idx])\n        start_idx = end_idx\n\n    if len(worker_assignments) != num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    return worker_assignments"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "\n    total_workers = _get_num_nodes() * num_workers\n    num_items = len(user_items)\n    items_per_worker = num_items // total_workers\n    remainder = num_items % total_workers\n\n    start_idx = 0\n    distributed_items = []\n\n    for i in range(total_workers):\n        end_idx = start_idx + items_per_worker + (1 if i < remainder else 0)\n        distributed_items.append(user_items[start_idx:end_idx])\n        start_idx = end_idx\n\n    if len(distributed_items) != total_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    return distributed_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "\n    # Calculate the total number of workers across all nodes\n    total_workers = _get_num_nodes() * num_workers\n\n    # Calculate the number of items each worker should process\n    items_per_worker = len(user_items) // total_workers\n    remainder = len(user_items) % total_workers\n\n    # Distribute the items among the workers\n    start_idx = 0\n    distributed_items = []\n\n    for i in range(total_workers):\n        end_idx = start_idx + items_per_worker + (1 if i < remainder else 0)\n        distributed_items.append(user_items[start_idx:end_idx])\n        start_idx = end_idx\n\n    # Check if the distribution is proper\n    if len(distributed_items) != total_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    return distributed_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "\n    total_workers = _get_num_nodes() * num_workers\n    total_items = len(user_items)\n    items_per_worker = total_items // total_workers\n    remaining_items = total_items % total_workers\n\n    start = 0\n    assigned_items = []\n\n    for i in range(total_workers):\n        end = start + items_per_worker + (1 if i < remaining_items else 0)\n        assigned_items.append(user_items[start:end])\n        start = end\n\n    if len(assigned_items) != total_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    return assigned_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "\n    total_items = len(user_items)\n    total_workers = _get_num_nodes() * num_workers\n    items_per_worker = total_items // total_workers\n    remainder = total_items % total_workers\n\n    start_idx = 0\n    result = []\n\n    for i in range(num_workers):\n        extra = 1 if i < remainder else 0\n        worker_items = user_items[start_idx:start_idx + items_per_worker + extra]\n        result.append(worker_items)\n        start_idx += len(worker_items)\n\n    if start_idx != total_items:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    return result"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "\n    total_workers = _get_num_nodes() * num_workers\n    items_per_worker = len(user_items) // total_workers\n    extra_items = len(user_items) % total_workers\n\n    start = 0\n    end = 0\n    distributed_items = []\n\n    for i in range(total_workers):\n        end += items_per_worker + (1 if i < extra_items else 0)\n        distributed_items.append(user_items[start:end])\n        start = end\n\n    if len(distributed_items) != total_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    return distributed_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    total_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n    \n    total_workers = total_nodes * num_workers\n    total_items = len(user_items)\n    \n    items_per_worker = total_items // total_workers\n    remainder = total_items % total_workers\n    \n    start_idx = 0\n    end_idx = 0\n    worker_assignments = []\n    \n    for i in range(total_workers):\n        if i < remainder:\n            end_idx = start_idx + items_per_worker + 1\n        else:\n            end_idx = start_idx + items_per_worker\n        \n        worker_assignments.append(user_items[start_idx:end_idx])\n        start_idx = end_idx\n    \n    if len(worker_assignments) != num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n    \n    return worker_assignments"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "\n    total_workers = _get_num_nodes() * num_workers\n    total_items = len(user_items)\n    items_per_worker = total_items // total_workers\n    remainder = total_items % total_workers\n\n    start = 0\n    end = 0\n    items_assigned = []\n\n    for i in range(total_workers):\n        end += items_per_worker + (1 if i < remainder else 0)\n        items_assigned.append(user_items[start:end])\n        start = end\n\n    if len(items_assigned) != total_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    return items_assigned"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "\n    total_items = len(user_items)\n    total_workers = _get_num_nodes() * num_workers\n    items_per_worker = total_items // total_workers\n    extra_items = total_items % total_workers\n\n    start_idx = 0\n    end_idx = 0\n    worker_items = []\n\n    for i in range(total_workers):\n        end_idx += items_per_worker + (1 if i < extra_items else 0)\n        worker_items.append(user_items[start_idx:end_idx])\n        start_idx = end_idx\n\n    if len(worker_items) != num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    return worker_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    total_workers = _get_num_nodes() * num_workers\n    num_items = len(user_items)\n    items_per_worker = num_items // total_workers\n    remainder = num_items % total_workers\n\n    worker_assignments = []\n    start_idx = 0\n    for i in range(total_workers):\n        end_idx = start_idx + items_per_worker\n        if i < remainder:\n            end_idx += 1\n        worker_assignments.append(user_items[start_idx:end_idx])\n        start_idx = end_idx\n\n    if len(worker_assignments) != total_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    return worker_assignments"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "    cache_dir = _get_cache_dir()\n    cache_data_dir = _get_cache_data_dir()\n\n    # Remove cache directories if they exist\n    if os.path.exists(cache_dir):\n        shutil.rmtree(cache_dir)\n    if os.path.exists(cache_data_dir):\n        shutil.rmtree(cache_data_dir)\n\n    # Recreate cache directories\n    os.makedirs(cache_dir, exist_ok=True)\n    os.makedirs(cache_data_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "    cache_dirs = [_get_cache_dir(), _get_cache_data_dir()]\n    for cache_dir in cache_dirs:\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir)\n        os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "    # Remove cache directories if they exist\n    cache_data_dir = _get_cache_data_dir()\n    cache_chunks_dir = _get_cache_dir()\n    if os.path.exists(cache_data_dir):\n        shutil.rmtree(cache_data_dir)\n    if os.path.exists(cache_chunks_dir):\n        shutil.rmtree(cache_chunks_dir)\n    \n    # Recreate the cache directories\n    os.makedirs(cache_data_dir, exist_ok=True)\n    os.makedirs(cache_chunks_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "    cache_dirs = [_get_cache_dir(), _get_cache_data_dir()]\n\n    for cache_dir in cache_dirs:\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir)\n\n    for cache_dir in cache_dirs:\n        os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "    cache_dirs = [_get_cache_dir(), _get_cache_data_dir()]\n    for cache_dir in cache_dirs:\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir)\n        os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "    cache_dirs = [_get_cache_dir(), _get_cache_data_dir()]\n    \n    for dir in cache_dirs:\n        if os.path.exists(dir):\n            shutil.rmtree(dir)\n        os.makedirs(dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "    cache_dir = _get_cache_dir()\n    cache_data_dir = _get_cache_data_dir()\n\n    if os.path.exists(cache_dir):\n        shutil.rmtree(cache_dir)\n    os.makedirs(cache_dir, exist_ok=True)\n\n    if os.path.exists(cache_data_dir):\n        shutil.rmtree(cache_data_dir)\n    os.makedirs(cache_data_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "    cache_dirs = [_get_cache_dir(), _get_cache_data_dir()]\n    for cache_dir in cache_dirs:\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir)\n        os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_data_dir = _get_cache_data_dir()\n        cache_chunks_dir = _get_cache_dir()\n\n        if os.path.exists(cache_data_dir):\n            shutil.rmtree(cache_data_dir)\n        os.makedirs(cache_data_dir, exist_ok=True)\n\n        if os.path.exists(cache_chunks_dir):\n            shutil.rmtree(cache_chunks_dir)\n        os.makedirs(cache_chunks_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "    cache_dirs = [_get_cache_dir(), _get_cache_data_dir()]\n    for cache_dir in cache_dirs:\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir)\n        os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "    cache_dir = _get_cache_dir()\n    cache_data_dir = _get_cache_data_dir()\n\n    if os.path.exists(cache_dir):\n        shutil.rmtree(cache_dir)\n    os.makedirs(cache_dir, exist_ok=True)\n\n    if os.path.exists(cache_data_dir):\n        shutil.rmtree(cache_data_dir)\n    os.makedirs(cache_data_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "    cache_dir = _get_cache_dir()\n    cache_data_dir = _get_cache_data_dir()\n\n    if os.path.exists(cache_dir):\n        shutil.rmtree(cache_dir)\n    os.makedirs(cache_dir, exist_ok=True)\n\n    if os.path.exists(cache_data_dir):\n        shutil.rmtree(cache_data_dir)\n    os.makedirs(cache_data_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "    cache_dirs = [_get_cache_dir(), _get_cache_data_dir()]\n\n    for cache_dir in cache_dirs:\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir)\n\n    for cache_dir in cache_dirs:\n        os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "    cache_dirs = [_get_cache_dir(), _get_cache_data_dir()]\n    \n    for cache_dir in cache_dirs:\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir)\n        os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "    cache_dir = _get_cache_dir()\n    cache_data_dir = _get_cache_data_dir()\n\n    # Remove cache directories if they exist\n    if os.path.exists(cache_dir):\n        shutil.rmtree(cache_dir)\n    if os.path.exists(cache_data_dir):\n        shutil.rmtree(cache_data_dir)\n\n    # Recreate cache directories\n    os.makedirs(cache_dir, exist_ok=True)\n    os.makedirs(cache_data_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "    cache_data_dir = _get_cache_data_dir()\n    cache_chunks_dir = _get_cache_dir()\n\n    # Remove cache directories if they exist\n    if os.path.exists(cache_data_dir):\n        shutil.rmtree(cache_data_dir)\n    if os.path.exists(cache_chunks_dir):\n        shutil.rmtree(cache_chunks_dir)\n\n    # Recreate cache directories\n    os.makedirs(cache_data_dir, exist_ok=True)\n    os.makedirs(cache_chunks_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "    cache_dirs = [_get_cache_dir(), _get_cache_data_dir()]\n    for cache_dir in cache_dirs:\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir)\n        os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "    # Remove cache directories if they exist\n    cache_data_dir = _get_cache_data_dir()\n    cache_chunks_dir = _get_cache_dir()\n    if os.path.exists(cache_data_dir):\n        shutil.rmtree(cache_data_dir)\n    if os.path.exists(cache_chunks_dir):\n        shutil.rmtree(cache_chunks_dir)\n\n    # Recreate the cache directories\n    os.makedirs(cache_data_dir, exist_ok=True)\n    os.makedirs(cache_chunks_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "    cache_dirs = [_get_cache_dir(), _get_cache_data_dir()]\n    for cache_dir in cache_dirs:\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir)\n        os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "    cache_dir = _get_cache_dir()\n    cache_data_dir = _get_cache_data_dir()\n\n    if os.path.exists(cache_dir):\n        shutil.rmtree(cache_dir)\n\n    if os.path.exists(cache_data_dir):\n        shutil.rmtree(cache_data_dir)\n\n    os.makedirs(cache_dir, exist_ok=True)\n    os.makedirs(cache_data_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    with concurrent.futures.ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n        file_sizes = list(executor.map(lambda item: _get_num_bytes(item, base_path), items))\n    return file_sizes"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    with concurrent.futures.ThreadPoolExecutor() as executor:\n        file_sizes = list(executor.map(lambda item: _get_num_bytes(item, base_path), items))\n    return file_sizes"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "\n    def _get_file_size(item: Any) -> int:\n        if isinstance(item, str):\n            item = Path(item)\n            if base_path:\n                item = Path(base_path) / item\n            if item.exists():\n                return os.path.getsize(item)\n            else:\n                raise FileNotFoundError(f\"File not found: {item}\")\n        else:\n            return _get_num_bytes(item, base_path)\n\n    with concurrent.futures.ThreadPoolExecutor() as executor:\n        file_sizes = list(executor.map(_get_file_size, items))\n\n    return file_sizes"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    with concurrent.futures.ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n        file_sizes = list(executor.map(lambda item: _get_num_bytes(item, base_path), items))\n    return file_sizes"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    with concurrent.futures.ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n        file_sizes = list(executor.map(lambda item: _get_num_bytes(item, base_path), items))\n    return file_sizes"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    with concurrent.futures.ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n        file_sizes = list(executor.map(lambda item: _get_num_bytes(item, base_path), items))\n    return file_sizes"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    with concurrent.futures.ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n        file_sizes = list(executor.map(lambda item: _get_num_bytes(item, base_path), items))\n    return file_sizes"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    num_workers = os.cpu_count() or 1\n    with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:\n        file_sizes = list(executor.map(lambda item: _get_num_bytes(item, base_path), items))\n    return file_sizes"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    with concurrent.futures.ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n        file_sizes = list(executor.map(lambda item: _get_num_bytes(item, base_path), items))\n    return file_sizes"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    with concurrent.futures.ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n        file_sizes = list(executor.map(lambda item: _get_num_bytes(item, base_path), items))\n    return file_sizes"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    with concurrent.futures.ThreadPoolExecutor() as executor:\n        file_sizes = list(executor.map(lambda item: _get_num_bytes(item, base_path), items))\n    return file_sizes"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    with concurrent.futures.ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n        file_sizes = list(executor.map(lambda item: _get_num_bytes(item, base_path), items))\n    return file_sizes"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    with concurrent.futures.ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n        file_sizes = list(executor.map(lambda item: _get_num_bytes(item, base_path), items))\n    return file_sizes"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    with concurrent.futures.ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n        file_sizes = list(executor.map(lambda item: _get_num_bytes(item, base_path), items))\n    return file_sizes"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    with concurrent.futures.ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n        file_sizes = list(executor.map(lambda item: _get_num_bytes(item, base_path), items))\n    return file_sizes"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    with concurrent.futures.ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n        file_sizes = list(executor.map(lambda item: _get_num_bytes(item, base_path), items))\n    return file_sizes"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    with concurrent.futures.ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n        file_sizes = list(executor.map(lambda item: _get_num_bytes(item, base_path), items))\n    return file_sizes"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    file_sizes = []\n    for item in items:\n        file_sizes.append(_get_num_bytes(item, base_path))\n    return file_sizes"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    with concurrent.futures.ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n        file_sizes = list(executor.map(lambda item: _get_num_bytes(item, base_path), items))\n    return file_sizes"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    with concurrent.futures.ThreadPoolExecutor() as executor:\n        file_sizes = list(executor.map(lambda item: _get_num_bytes(item, base_path), items))\n    return file_sizes"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        path = Path(element)\n        if input_dir:\n            input_path = Path(input_dir)\n            if path.is_absolute():\n                return path.is_file() or path.is_dir()\n            else:\n                return (input_path / path).is_file() or (input_path / path).is_dir()\n        else:\n            return path.is_file() or path.is_dir()\n    else:\n        return False"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "\n    if isinstance(element, str):\n        if input_dir and element.startswith(input_dir):\n            return True\n        elif os.path.exists(element):\n            return True\n        else:\n            return False\n    else:\n        return False"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        # Convert to absolute path if necessary\n        element = str(Path(element).resolve())\n        \n        if input_dir:\n            # Check if the element starts with the input directory\n            return element.startswith(input_dir)\n        else:\n            # Check if the element exists in the file system\n            return os.path.exists(element)\n    else:\n        return False"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        path = Path(element)\n        if input_dir:\n            input_path = Path(input_dir)\n            if path.is_absolute():\n                return path.is_file() or path.is_dir()\n            else:\n                return (input_path / path).is_file() or (input_path / path).is_dir()\n        else:\n            return path.is_file() or path.is_dir()\n    else:\n        return False"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        element = str(Path(element).resolve())\n        if input_dir:\n            input_dir = str(Path(input_dir).resolve())\n            if element.startswith(input_dir):\n                return True\n        return os.path.exists(element)\n    return False"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        path = Path(element)\n        if path.is_absolute():\n            return path.exists()\n        elif input_dir:\n            return (Path(input_dir) / path).exists()\n        else:\n            return path.exists()\n    else:\n        return False"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        path = Path(element)\n        if input_dir:\n            input_path = Path(input_dir)\n            if path.is_absolute() and input_path in path.parents:\n                return True\n            elif not path.is_absolute() and (input_path / path).exists():\n                return True\n            else:\n                return path.exists()\n        else:\n            return path.exists()\n    else:\n        return False"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        if input_dir and element.startswith(input_dir):\n            return True\n        elif os.path.exists(element):\n            return True\n    return False"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        path = Path(element)\n        if input_dir:\n            input_path = Path(input_dir)\n            if path.is_absolute():\n                return str(path).startswith(str(input_path))\n            else:\n                return (input_path / path).exists()\n        else:\n            return path.exists()\n    else:\n        return False"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        # Convert to absolute path if not already\n        element = os.path.abspath(element)\n\n        if input_dir:\n            # Check if the element starts with the input directory\n            return element.startswith(input_dir)\n        else:\n            # Check if the path exists in the file system\n            return os.path.exists(element)\n    else:\n        return False"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        element = str(Path(element).resolve())\n        if input_dir:\n            return element.startswith(input_dir) or Path(element).exists()\n        else:\n            return Path(element).exists()\n    else:\n        return False"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        element = str(Path(element).resolve())\n        if input_dir:\n            return element.startswith(str(Path(input_dir).resolve()))\n        else:\n            return Path(element).exists()\n    else:\n        return False"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        path_to_check = element if input_dir is None else os.path.join(input_dir, element)\n        return os.path.exists(path_to_check)\n    else:\n        return False"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        path = Path(element)\n        if input_dir and path.is_absolute():\n            return str(path).startswith(input_dir) and path.exists()\n        else:\n            return path.exists()\n    else:\n        return False"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        path = Path(element)\n        if input_dir:\n            input_path = Path(input_dir)\n            if path.is_absolute():\n                return path.is_file() or path.is_dir()\n            else:\n                return (input_path / path).is_file() or (input_path / path).is_dir()\n        else:\n            return path.is_file() or path.is_dir()\n    else:\n        return False"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        # Convert to absolute path if not already\n        element = os.path.abspath(element)\n\n        if input_dir:\n            # Check if the element starts with the specified input directory\n            input_dir = os.path.abspath(input_dir)\n            return element.startswith(input_dir) and os.path.exists(element)\n        else:\n            # Check if the element exists in the file system\n            return os.path.exists(element)\n    else:\n        return False"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        path = Path(element)\n        if input_dir:\n            input_path = Path(input_dir)\n            if path.is_absolute():\n                return path.is_file() or path.is_dir()\n            else:\n                return (input_path / path).is_file() or (input_path / path).is_dir()\n        else:\n            return path.is_file() or path.is_dir()\n    return False"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        path = Path(element)\n        if input_dir:\n            input_path = Path(input_dir)\n            if path.is_absolute():\n                return path.is_file() or path.is_dir()\n            else:\n                return (input_path / path).is_file() or (input_path / path).is_dir()\n        else:\n            return path.is_file() or path.is_dir()\n    else:\n        return False"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        if input_dir:\n            element = os.path.join(input_dir, element)  # Convert to absolute path\n\n        return os.path.exists(element)\n    else:\n        return False"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if isinstance(element, str):\n        path = Path(element)\n        if input_dir:\n            input_path = Path(input_dir)\n            if path.is_absolute():\n                return str(path).startswith(str(input_path))\n            else:\n                return (input_path / path).exists()\n        else:\n            return path.exists()\n    else:\n        return False"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = _safe_sqrt(jnp.sum(screw_axis[:3]**2))\n  w = screw_axis[:3] / theta\n  v = screw_axis[3:]\n\n  W = skew(w)\n  R = exp_so3(w * theta, eps)\n  p = jnp.dot((jnp.eye(3) * theta + (1 - jnp.cos(theta)) * W + (theta - jnp.sin(theta)) * jnp.dot(W, W)), v) / theta\n\n  return jnp.block([[R, jnp.reshape(p, (3, 1))], [jnp.array([[0.0, 0.0, 0.0, 1.0]])]])"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = _safe_sqrt(jnp.sum(screw_axis[:3]**2))\n  w = screw_axis[:3] / theta\n  v = screw_axis[3:]\n\n  W = skew(w)\n  R = exp_so3(w * theta, eps)\n  p = jnp.where(theta > eps, jnp.linalg.inv(jnp.eye(3) - R) @ v, v)\n\n  X = jnp.block([[R, p[:, jnp.newaxis]], [jnp.array([[0.0, 0.0, 0.0, 1.0]])]])\n  return X"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = _safe_sqrt(jnp.sum(screw_axis[:3]**2))\n  w = screw_axis[:3] / theta\n  v = screw_axis[3:]\n\n  W = skew(w)\n  R = exp_so3(w * theta, eps)\n  G_inv = jnp.eye(3) * theta - W + (1 - jnp.cos(theta)) * spin_math.matmul(W, W)\n\n  p = jnp.dot(G_inv, v)\n\n  X = jnp.block([[R, p[:, jnp.newaxis]], [jnp.array([[0.0, 0.0, 0.0, 1.0]])]])\n  return X"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = _safe_sqrt(jnp.sum(screw_axis[:3]**2))\n  w = screw_axis[:3] / theta\n  v = screw_axis[3:]\n\n  W = skew(w)\n  R = exp_so3(w * theta, eps)\n  p = (jnp.eye(3) * theta + (1 - jnp.cos(theta)) * W + (theta - jnp.sin(theta)) * spin_math.matmul(W, W)) @ v / theta\n\n  X = jnp.block([[R, p.reshape(3, 1)], [jnp.array([[0.0, 0.0, 0.0, 1.0]])]])\n  return X"}
{"namespace": "rigid_body.exp_se3", "completion": "  w = screw_axis[:3]\n  v = screw_axis[3:]\n\n  theta = _safe_sqrt(jnp.sum(w**2))\n  W = skew(w)\n  V = jnp.outer(w, v)\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  X_taylor = jnp.eye(3) + W + 0.5 * spin_math.matmul(W, W) + V\n\n  # Prevent bad gradients from propagating back when theta is small.\n  w_safe = jnp.where(theta > eps, w, 0.0)\n  theta_safe = jnp.where(theta > eps, theta, 1.0)\n  W_safe = skew(w_safe)\n  V_safe = jnp.outer(w_safe, v)\n\n  X = (\n      jnp.eye(3)\n      + jnp.sin(theta_safe) * W_safe\n      + (1.0 - jnp.cos(theta_safe)) * spin_math.matmul(W_safe, W_safe)\n      + (1.0 - jnp.cos(theta_safe)) * (theta_safe - jnp.sin(theta_safe)) * spin_math.matmul(W_safe, V_safe)\n  )\n\n  return jnp.where(theta > eps, X, X_taylor)"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = _safe_sqrt(jnp.sum(screw_axis[:3]**2))\n  w = screw_axis[:3] / theta\n  v = screw_axis[3:]\n\n  W = skew(w)\n  V = jnp.outer(w, v)\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  X_taylor = jnp.eye(4) + rp_to_se3(W, V)\n\n  # Prevent bad gradients from propagating back when theta is small.\n  w_safe = jnp.where(theta > eps, w, 0.0)\n  theta_safe = jnp.where(theta > eps, theta, 1.0)\n  W_safe = skew(w_safe)\n  V_safe = jnp.outer(w_safe, v)\n  X = jnp.eye(4) + rp_to_se3(W_safe, V_safe)\n\n  return jnp.where(theta > eps, X, X_taylor)"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = _safe_sqrt(jnp.sum(screw_axis[:3]**2))\n  w = screw_axis[:3] / theta\n  v = screw_axis[3:]\n\n  W = skew(w)\n  R = exp_so3(w * theta, eps)\n  G_inv = jnp.eye(3) * theta - W + (1.0 - jnp.cos(theta)) * spin_math.matmul(W, W)\n  p = spin_math.matmul(G_inv, v)\n\n  X = jnp.block([[R, p], [jnp.array([[0.0, 0.0, 0.0, 1.0]])]])\n  return X"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = _safe_sqrt(jnp.sum(screw_axis[:3]**2))\n  w = screw_axis[:3] / theta\n  v = screw_axis[3:]\n\n  W = skew(w)\n  R = exp_so3(w * theta, eps)\n  p = jnp.where(theta > eps, jnp.linalg.inv(jnp.eye(3) - R) @ v, v)\n\n  X = jnp.block([[R, p[:, jnp.newaxis]], [jnp.array([[0.0, 0.0, 0.0, 1.0]])]])\n  return X"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = _safe_sqrt(jnp.sum(screw_axis[:3]**2, axis=-1))\n  w = screw_axis[:3] / theta\n  v = screw_axis[3:]\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  R_taylor = jnp.eye(3) + skew(w) * jnp.sin(theta) + (1 - jnp.cos(theta)) * skew(w) @ skew(w)\n\n  # Prevent bad gradients from propagating back when theta is small.\n  w_safe = jnp.where(theta > eps, w, 0.0)\n  theta_safe = jnp.where(theta > eps, theta, 1.0)\n  V = jnp.eye(3) + (1 - jnp.cos(theta_safe)) * skew(w_safe) + (theta_safe - jnp.sin(theta_safe)) * skew(w_safe) @ skew(w_safe)\n\n  p = jnp.where(theta > eps, V @ v / theta, v)\n  R = jnp.where(theta > eps, exp_so3(w, eps), R_taylor)\n\n  return rp_to_se3(R, p)"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = _safe_sqrt(jnp.sum(screw_axis[:3]**2))\n  w = screw_axis[:3] / theta\n  v = screw_axis[3:]\n\n  W = skew(w)\n  t = (jnp.eye(3) - exp_so3(W, eps)) @ jnp.cross(w, v) + jnp.outer(w, jnp.dot(w, v)) * theta\n\n  T = jnp.block([[exp_so3(W, eps), jnp.reshape(t, (3, 1))], [jnp.array([0.0, 0.0, 0.0, 1.0])]])\n  return T"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = _safe_sqrt(jnp.sum(screw_axis[:3]**2))\n  w = screw_axis[:3] / theta\n  v = screw_axis[3:]\n\n  W = skew(w)\n  V = jnp.outer(w, v)\n\n  R = exp_so3(w.reshape(1, -1) * theta, eps)\n  t = (jnp.eye(3) * theta + (1 - jnp.cos(theta)) * W + (theta - jnp.sin(theta)) * spin_math.matmul(W, W)) @ v\n\n  T = jnp.block([[R, t.reshape(-1, 1)], [jnp.zeros((1, 3)), jnp.array([[1.0]])]])\n  return T"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = _safe_sqrt(jnp.sum(screw_axis[:3]**2))\n  w = screw_axis[:3] / theta\n  v = screw_axis[3:]\n\n  W = skew(w)\n  R = exp_so3(w * theta, eps)\n  p = jnp.where(theta > eps, jnp.linalg.inv(jnp.eye(3) - R) @ v, v)\n\n  T = jnp.block([[R, p.reshape(3, 1)], [jnp.array([[0.0, 0.0, 0.0, 1.0]])]])\n  return T"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = _safe_sqrt(jnp.sum(screw_axis[:3]**2))\n  w = screw_axis[:3] / theta\n  v = screw_axis[3:]\n\n  W = skew(w)\n  R = exp_so3(w * theta, eps)\n  G_inv = jnp.eye(3) * theta - W + (1.0 - jnp.cos(theta)) * spin_math.matmul(W, W)\n\n  p = jnp.dot(G_inv, v)\n\n  X = jnp.block([[R, p[:, jnp.newaxis]], [jnp.array([[0.0, 0.0, 0.0, 1.0]])]])\n  return X"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = _safe_sqrt(jnp.sum(screw_axis[:3]**2))\n  w = screw_axis[:3] / theta\n  v = screw_axis[3:]\n\n  W = skew(w)\n  R = exp_so3(w * theta, eps)\n  V = jnp.eye(3) * theta + (1 - jnp.cos(theta)) * W + (theta - jnp.sin(theta)) * spin_math.matmul(W, W)\n\n  G_inv = jnp.block([[R.T, -spin_math.matmul(R.T, V)], [jnp.zeros((1, 3)), 1]])\n  t = spin_math.matmul(G_inv, jnp.reshape(v, (3, 1)))\n\n  T = jnp.block([[R, t], [jnp.zeros((1, 3)), 1]])\n  return T"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = _safe_sqrt(jnp.sum(screw_axis[:3]**2))\n  w = screw_axis[:3] / theta\n  v = screw_axis[3:]\n\n  W = skew(w)\n  R = exp_so3(w * theta, eps)\n\n  # Avoid division by zero\n  taylor_factor = jnp.where(theta > eps, (jnp.eye(3) * theta + (1 - jnp.cos(theta)) * W + (theta - jnp.sin(theta)) * spin_math.matmul(W, W)) @ v, v)\n\n  T = jnp.eye(4)\n  T = jax.ops.index_update(T, jax.ops.index[:3, :3], R)\n  T = jax.ops.index_update(T, jax.ops.index[:3, 3], taylor_factor)\n\n  return T"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = _safe_sqrt(jnp.sum(screw_axis[:3]**2))\n  w = screw_axis[:3] / theta\n  v = screw_axis[3:]\n\n  W = skew(w)\n  R = exp_so3(w * theta, eps)\n  V = jnp.eye(3) * theta + (1 - jnp.cos(theta)) * W + (theta - jnp.sin(theta)) * spin_math.matmul(W, W)\n\n  G_inv = jnp.block([[R.T, -spin_math.matmul(R.T, V)], [jnp.zeros((1, 3)), 1]])\n  t = spin_math.matmul(G_inv[Ellipsis, :3, :3], v)\n  return jnp.block([[R, t], [jnp.array([[0.0, 0.0, 0.0, 1.0]])]])"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = _safe_sqrt(jnp.sum(screw_axis[:3]**2))\n  w = screw_axis[:3] / theta\n  v = screw_axis[3:]\n\n  W = skew(w)\n  V = jnp.outer(w, v)\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  X_taylor = jnp.eye(3) + W + 0.5 * spin_math.matmul(W, W) + jnp.outer(w, v)\n\n  # Prevent bad gradients from propagating back when theta is small.\n  theta_safe = jnp.where(theta > eps, theta, 1.0)\n  w_safe = jnp.where(theta > eps, w, 0.0)\n  v_safe = jnp.where(theta > eps, v, 0.0)\n\n  X = (\n      jnp.eye(3)\n      + jnp.sin(theta_safe) * W\n      + (1.0 - jnp.cos(theta_safe)) * spin_math.matmul(W, W)\n      + (1.0 - jnp.cos(theta_safe)) * V\n      + (theta_safe - jnp.sin(theta_safe)) * jnp.outer(w_safe, w_safe)\n  )\n\n  return jnp.where(theta > eps, jnp.block([[X, v_safe], [jnp.array([0.0, 0.0, 0.0, 1.0])]]), X_taylor)"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = _safe_sqrt(jnp.sum(screw_axis[:3]**2))\n  w = screw_axis[:3] / theta\n  v = screw_axis[3:]\n\n  W = skew(w)\n  R = exp_so3(w * theta, eps)\n  G_inv = jnp.eye(3) * theta - W + (1 - jnp.cos(theta)) * spin_math.matmul(W, W)\n  V = jnp.eye(3) * theta + (1 - jnp.cos(theta)) * W + (theta - jnp.sin(theta)) * spin_math.matmul(W, W)\n\n  t = spin_math.matmul(V, v)\n\n  top = jnp.concatenate([R, t.reshape(3, 1)], axis=1)\n  bottom = jnp.array([[0, 0, 0, 1]])\n\n  return jnp.concatenate([top, bottom], axis=0)"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = _safe_sqrt(jnp.sum(screw_axis[:3]**2))\n  w = screw_axis[:3] / theta\n  v = screw_axis[3:]\n\n  W = skew(w)\n  V = jnp.outer(w, v)\n\n  R = exp_so3(w * theta, eps)\n  t = jnp.where(theta > eps, jnp.linalg.inv(jnp.eye(3) - R) @ V, v)\n\n  return jnp.block([[R, t.reshape(3, 1)], [jnp.array([0.0, 0.0, 0.0, 1.0])]])"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = _safe_sqrt(jnp.sum(screw_axis[:3]**2))\n  w = screw_axis[:3] / theta\n  v = screw_axis[3:]\n\n  W = skew(w)\n  R = exp_so3(w * theta, eps)\n  G_inv = jnp.eye(3) * theta - W + (1.0 - theta * jnp.cos(theta)) / (theta**2) * spin_math.matmul(W, W)\n\n  p = jnp.dot(G_inv, v)\n\n  X = jnp.block([[R, p[:, jnp.newaxis]], [jnp.array([[0.0, 0.0, 0.0, 1.0]])]])\n  return X"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  if theta < eps:\n    return jnp.eye(3) + skew(axis_angle)\n\n  k = axis_angle / theta\n  K = skew(k)\n  return jnp.eye(3) + jnp.sin(theta) * K + (1 - jnp.cos(theta)) * (K @ K)"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  if theta < eps:\n    return jnp.eye(3) + skew(axis_angle)\n  else:\n    k = axis_angle / theta\n    K = skew(k)\n    return jnp.eye(3) + jnp.sin(theta) * K + (1 - jnp.cos(theta)) * (K @ K)"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  if theta < eps:\n    return jnp.eye(3) + skew(axis_angle)\n  else:\n    k = axis_angle / theta\n    K = skew(k)\n    return jnp.eye(3) + jnp.sin(theta) * K + (1 - jnp.cos(theta)) * K @ K"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  axis = axis_angle / (theta + eps)\n  k = skew(axis)\n  R = jnp.eye(3) + jnp.sin(theta) * k + (1 - jnp.cos(theta)) * k @ k\n  return R"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  if theta < eps:\n    return jnp.eye(3) + skew(axis_angle)\n  else:\n    k = axis_angle / theta\n    K = skew(k)\n    return jnp.eye(3) + jnp.sin(theta) * K + (1 - jnp.cos(theta)) * K @ K"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  if theta < eps:\n    return jnp.eye(3) + skew(axis_angle)\n  else:\n    k = axis_angle / theta\n    K = skew(k)\n    return jnp.eye(3) + jnp.sin(theta) * K + (1 - jnp.cos(theta)) * K @ K"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  axis = axis_angle / (theta + eps)\n  K = skew(axis)\n  R = jnp.eye(3) + jnp.sin(theta) * K + (1 - jnp.cos(theta)) * K @ K\n  return R"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  if theta < eps:\n    return jnp.eye(3) + skew(axis_angle)\n  else:\n    k = axis_angle / theta\n    K = skew(k)\n    return jnp.eye(3) + jnp.sin(theta) * K + (1 - jnp.cos(theta)) * (K @ K)"}
{"namespace": "rigid_body.exp_so3", "completion": "  angle = jnp.linalg.norm(axis_angle)\n  axis = axis_angle / (angle + eps)\n\n  skew_matrix = skew(axis)\n  rotation_matrix = jnp.eye(3) + jnp.sin(angle) * skew_matrix + (1 - jnp.cos(angle)) * (skew_matrix @ skew_matrix)\n\n  return rotation_matrix"}
{"namespace": "rigid_body.exp_so3", "completion": "  angle = jnp.linalg.norm(axis_angle)\n  axis = axis_angle / (angle + eps)\n  skew_matrix = skew(axis)\n  rotation_matrix = jnp.eye(3) + jnp.sin(angle) * skew_matrix + (1 - jnp.cos(angle)) * skew_matrix @ skew_matrix\n  return rotation_matrix"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  if theta < eps:\n    return jnp.eye(3) + skew(axis_angle)\n  else:\n    k = axis_angle / theta\n    K = skew(k)\n    return jnp.eye(3) + jnp.sin(theta) * K + (1 - jnp.cos(theta)) * (K @ K)"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  axis = axis_angle / (theta + eps)\n  K = skew(axis)\n  R = jnp.eye(3) + jnp.sin(theta) * K + (1 - jnp.cos(theta)) * (K @ K)\n  return R"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  W = skew(axis_angle)\n  W_norm = jnp.linalg.norm(W)\n  R = jnp.eye(3) + (jnp.sin(theta) / theta) * W + ((1 - jnp.cos(theta)) / (theta**2)) * (W @ W)\n  R = jnp.where(W_norm < eps, jnp.eye(3), R)\n  return R"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  if theta < eps:\n    return jnp.eye(3) + skew(axis_angle)\n  else:\n    k = axis_angle / theta\n    K = skew(k)\n    return jnp.eye(3) + jnp.sin(theta) * K + (1 - jnp.cos(theta)) * (K @ K)"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  W = skew(axis_angle)\n  W_norm = jnp.linalg.norm(W)\n\n  R = jnp.eye(3) + (jnp.sin(theta) / theta) * W + ((1 - jnp.cos(theta)) / (theta ** 2)) * (W @ W)\n\n  # Ensure numerical stability for small angles\n  R = jnp.where(W_norm < eps, jnp.eye(3), R)\n\n  return R"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  axis = axis_angle / (theta + eps)\n  skew_matrix = skew(axis)\n  return jnp.eye(3) + jnp.sin(theta) * skew_matrix + (1 - jnp.cos(theta)) * (skew_matrix @ skew_matrix)"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  if theta < eps:\n    return jnp.eye(3) + skew(axis_angle)\n  else:\n    k = axis_angle / theta\n    K = skew(k)\n    return jnp.eye(3) + jnp.sin(theta) * K + (1 - jnp.cos(theta)) * (K @ K)"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  if theta < eps:\n    return jnp.eye(3) + skew(axis_angle)\n  else:\n    k = axis_angle / theta\n    K = skew(k)\n    return jnp.eye(3) + jnp.sin(theta) * K + (1 - jnp.cos(theta)) * K @ K"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  if theta < eps:\n    return jnp.eye(3) + skew(axis_angle)\n  else:\n    k = axis_angle / theta\n    K = skew(k)\n    return jnp.eye(3) + jnp.sin(theta) * K + (1 - jnp.cos(theta)) * K @ K"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  if theta < eps:\n    return jnp.eye(3) + skew(axis_angle)\n  else:\n    k = axis_angle / theta\n    K = skew(k)\n    return jnp.eye(3) + jnp.sin(theta) * K + (1 - jnp.cos(theta)) * (K @ K)"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= base_radius**2\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  t_mean = t_mean * d\n  t_var = t_var * d**2\n  r_var = r_var * base_radius**2\n\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  t_mean = t_mean * d\n  r_var = r_var * base_radius ** 2\n  t_var = t_var * (d ** 2)\n\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  t_mean *= d\n  t_var *= jnp.sum(d**2)\n  r_var *= base_radius ** 2\n\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  t_mean *= d\n  t_var *= jnp.sum(d**2)\n  r_var *= base_radius**2\n\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n  return mean, cov"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  # Calculate the means and variances using the gaussianize_frustum function\n  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n\n  # Calculate the covariance matrix based on the diagonal flag\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n  return mean, cov"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  t_mean *= d\n  t_var *= d**2\n  r_var *= base_radius**2\n\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  t_mean *= d\n  t_var *= d**2\n  r_var *= base_radius**2\n\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  t_mean *= d\n  t_var *= d**2\n  r_var *= base_radius**2\n\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  t_mean = t_mean * d\n  t_var = t_var * d**2\n  r_var = r_var * base_radius**2\n\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  t_mean = t_mean * d\n  t_var = t_var * (d ** 2)\n  r_var = r_var * (base_radius ** 2)\n\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n\n  t_mean = t_mean * d\n  t_var = t_var * d**2\n  r_var = r_var * base_radius**2\n\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  t_mean *= d\n  t_var *= d**2\n  r_var *= base_radius**2\n\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n\n  # Calculate the radius at t0 and t1\n  r0 = base_radius * t0\n  r1 = base_radius * t1\n\n  # Calculate the mean\n  mean = d[Ellipsis, None, :] * t_mean[Ellipsis, None]\n\n  # Calculate the diagonal covariance\n  if diag:\n    cov_diag = jnp.diag(jnp.array([t_var, (r0**2 + r1**2) * r_var / 3, (r0**2 + r1**2) * r_var / 3]))\n    return mean, cov_diag\n  else:\n    # Calculate the full covariance\n    cov = jnp.array([[t_var, r0**2 * r_var, r0**2 * r_var],\n                    [r0**2 * r_var, (r0**2 + r1**2) * r_var / 3, (r0**2 + r1**2) * r_var / 6],\n                    [r0**2 * r_var, (r0**2 + r1**2) * r_var / 6, (r0**2 + r1**2) * r_var / 3]])\n    return mean, cov"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= base_radius**2\n\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  t_mean *= d\n  t_var *= jnp.sum(d**2)\n  r_var *= base_radius**2\n\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  t_mean *= base_radius\n  t_var *= base_radius**2\n  r_var *= base_radius**2\n\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "    t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n    r_var *= radius**2\n    mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n    return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= radius**2\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Convert pixel coordinates to camera coordinates.\n  pix_coords = xnp.stack([pix_x_int, pix_y_int, xnp.ones_like(pix_x_int)], axis=-1)\n  cam_coords = xnp.einsum('...ij,...j->...i', pixtocams, pix_coords)\n\n  # Convert camera coordinates to world coordinates.\n  world_coords = xnp.einsum('...ij,...j->...i', camtoworlds[..., :3, :3], cam_coords)\n  origins = camtoworlds[..., :3, -1]\n\n  # Compute ray directions based on the camera projection type.\n  if camtype == ProjectionType.PERSPECTIVE:\n    directions = world_coords - origins\n    viewdirs = xnp.linalg.norm(directions, axis=-1, keepdims=True)\n    directions = directions / viewdirs\n  elif camtype == ProjectionType.FISHEYE:\n    # Compute normalized view directions for fisheye projection.\n    directions = world_coords - origins\n    viewdirs = xnp.linalg.norm(directions, axis=-1, keepdims=True)\n    directions = directions / viewdirs\n  elif camtype == ProjectionType.PANORAMIC:\n    # Compute normalized view directions for panoramic projection.\n    directions = world_coords - origins\n    viewdirs = xnp.linalg.norm(directions, axis=-1, keepdims=True)\n    directions = directions / viewdirs\n  else:\n    raise ValueError(\"Unsupported camera projection type\")\n\n  # Apply distortion correction if distortion parameters are provided.\n  if distortion_params:\n    k1 = distortion_params.get('k1', 0.0)\n    k2 = distortion_params.get('k2', 0.0)\n    k3 = distortion_params.get('k3', 0.0)\n    k4 = distortion_params.get('k4', 0.0)\n    p1 = distortion_params.get('p1', 0.0)\n    p2 = distortion_params.get('p2', 0.0)\n\n    # Undistort pixel coordinates.\n    undistorted_x, undistorted_y = _radial_and_tangential_undistort(\n        pix_x_int, pix_y_int, k1, k2, k3, k4, p1, p2, xnp=xnp\n    )\n\n    # Convert undistorted pixel coordinates to camera coordinates.\n    undistorted_pix_coords = xnp.stack([undistorted_x, undistorted_y, xnp.ones_like(undistorted_x)], axis=-1)\n    undistorted_cam_coords = xnp.einsum('...ij,...j->...i', pixtocams, undistorted_pix_coords)\n\n    # Convert undistorted camera coordinates to world coordinates.\n    undistorted_world_coords = xnp.einsum('...ij,...j->...i', camtoworlds[..., :3, :3], undistorted_cam_coords)\n    undistorted_origins = camtoworlds[..., :3, -1]\n\n    # Compute undistorted ray directions based on the camera projection type.\n    if camtype == ProjectionType.PERSPECTIVE:\n      undistorted_directions = undistorted_world_coords - undistorted_origins\n      undistorted_viewdirs = xnp.linalg.norm(undistorted_directions, axis=-1, keepdims=True)\n      undistorted_directions = undistorted_directions / undistorted_viewdirs\n    elif camtype == ProjectionType.FISHEYE:\n      # Compute normalized view directions for fisheye projection.\n      undistorted_directions = undistorted_world_coords - undistorted_origins\n      undistorted_viewdirs = xnp.linalg.norm(undistorted_directions, axis=-1, keepdims=True)\n      undistorted_directions = undistorted_directions / undistorted_viewdirs\n    elif camtype == ProjectionType.PANORAMIC:\n      # Compute normalized view directions for panoramic projection.\n      undistorted_directions = undistorted_world_coords - undistorted_origins\n      undistorted_viewdirs = xnp.linalg.norm(undistorted_directions, axis=-1, keepdims=True)\n      undistorted_directions = undistorted_directions / undistorted_viewdirs\n    else:\n      raise ValueError(\"Unsupported camera projection type\")\n\n    # Use the undistorted ray directions and origins.\n    directions = undistorted_directions\n    viewdirs = undistorted_viewdirs\n    origins = undistorted_origins\n\n  # Convert ray origins and directions to Normalized Device Coordinates (NDC) if pixtocam_ndc is provided.\n  if pixtocam_ndc is not None:\n    origins_ndc, directions_ndc = convert_to_ndc(origins, directions, pixtocam_ndc, xnp=xnp)\n    return origins, directions, viewdirs, directions_ndc, pix_coords\n  else:\n    return origins, directions, viewdirs, None, pix_coords"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "\n  # Convert pixel coordinates to normalized device coordinates (NDC)\n  if pixtocam_ndc is not None:\n    origins_ndc, directions_ndc = convert_to_ndc(\n        origins=pix_x_int,\n        directions=pix_y_int,\n        pixtocam=pixtocam_ndc,\n        xnp=xnp\n    )\n  else:\n    # Convert pixel coordinates to camera coordinates\n    origins_cam = xnp.linalg.inv(pixtocams) @ xnp.stack([pix_x_int, pix_y_int, xnp.ones_like(pix_x_int)], axis=-1)\n    origins_cam = origins_cam / xnp.linalg.norm(origins_cam, axis=-1, keepdims=True)\n\n    # Convert camera coordinates to world coordinates\n    origins_world = camtoworlds @ xnp.concatenate([origins_cam, xnp.ones_like(pix_x_int)[:, :, None]], axis=-1)\n\n    # Calculate the normalized direction vectors of the rays\n    directions_world = origins_world - camtoworlds[:, :, :3, 3]\n\n    # Calculate the differential radii of the rays\n    radii = xnp.linalg.norm(directions_world, axis=-1, keepdims=True)\n\n    # Normalize the direction vectors\n    viewdirs = directions_world / radii\n\n    # Calculate the xy coordinates on the image plane\n    imageplane = origins_world[:, :, :2] / xnp.maximum(origins_world[:, :, 2:3], 1e-10)\n\n    return origins_world, directions_world, viewdirs, radii, imageplane"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "\n    # Convert pixel coordinates to NDC if pixtocam_ndc is provided\n    if pixtocam_ndc is not None:\n      origins_ndc, directions_ndc = convert_to_ndc(\n          pix_x_int, pix_y_int, pixtocam_ndc, xnp=xnp\n      )\n    else:\n      # Convert pixel coordinates to camera coordinates using inverse intrinsics\n      pix_coords = xnp.stack([pix_x_int, pix_y_int, xnp.ones_like(pix_x_int)], axis=-1)\n      cam_coords = xnp.einsum('...ij,...j->...i', pixtocams, pix_coords)\n\n      # Apply distortion correction if distortion_params are provided\n      if distortion_params is not None:\n        k1, k2, k3, k4, p1, p2 = distortion_params['k1'], distortion_params['k2'], distortion_params['k3'], distortion_params['k4'], distortion_params['p1'], distortion_params['p2']\n        distorted_x, distorted_y = _radial_and_tangential_distort(cam_coords[..., 0], cam_coords[..., 1], k1, k2, k3, k4, p1, p2)\n        cam_coords = xnp.stack([distorted_x, distorted_y, cam_coords[..., 2]], axis=-1)\n\n      # Convert camera coordinates to world coordinates using extrinsics\n      origins = xnp.einsum('...ij,...j->...i', camtoworlds[..., :3, :3], cam_coords) + camtoworlds[..., :3, 3]\n      directions = xnp.einsum('...ij,...j->...i', camtoworlds[..., :3, :3], cam_coords)  # Same as cam_coords since directions are not affected by translation\n\n      # Normalize the directions to get view directions\n      viewdirs = xnp.linalg.norm(directions, axis=-1, keepdims=True)\n      directions = directions / viewdirs\n\n      return origins, directions, viewdirs, None, cam_coords[..., :2]"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "\n  # Convert pixel coordinates to camera coordinates\n  cam_coords = xnp.stack([pix_x_int, pix_y_int, xnp.ones_like(pix_x_int)], axis=-1)\n  cam_coords = cam_coords @ xnp.transpose(pixtocams, (-1, -2))\n\n  # Apply distortion correction if distortion parameters are provided\n  if distortion_params is not None:\n    k1, k2, k3, k4, p1, p2 = (\n        distortion_params.get('k1', 0),\n        distortion_params.get('k2', 0),\n        distortion_params.get('k3', 0),\n        distortion_params.get('k4', 0),\n        distortion_params.get('p1', 0),\n        distortion_params.get('p2', 0),\n    )\n    x, y = cam_coords[..., 0], cam_coords[..., 1]\n    x, y = _radial_and_tangential_distort(x, y, k1, k2, k3, k4, p1, p2)\n    cam_coords = xnp.stack([x, y, xnp.ones_like(x)], axis=-1)\n\n  # Convert camera coordinates to world coordinates\n  origins = cam_coords @ xnp.transpose(camtoworlds, (-1, -2))\n\n  # Calculate ray directions\n  if camtype == ProjectionType.PERSPECTIVE:\n    directions = origins - camtoworlds[..., :3, -1:]\n  elif camtype == ProjectionType.FISHEYE:\n    # Calculate normalized direction vectors for fisheye projection\n    directions = xnp.linalg.norm(origins, axis=-1, keepdims=True)\n    directions = origins / directions\n  elif camtype == ProjectionType.PANORAMIC:\n    # Calculate normalized direction vectors for panoramic projection\n    directions = xnp.cross(origins, xnp.array([0, 0, 1]))\n    directions = xnp.linalg.norm(directions, axis=-1, keepdims=True)\n    directions = directions / xnp.linalg.norm(directions, axis=-1, keepdims=True)\n  else:\n    raise ValueError(\"Invalid camtype\")\n\n  # Calculate normalized view directions\n  viewdirs = xnp.linalg.norm(directions, axis=-1, keepdims=True)\n  viewdirs = directions / viewdirs\n\n  # Calculate ray differential radii\n  radii = xnp.linalg.norm(cam_coords[..., :2], axis=-1, keepdims=True)\n\n  # Calculate image plane coordinates\n  imageplane = cam_coords[..., :2]\n\n  return origins, directions, viewdirs, radii, imageplane"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Convert pixel coordinates to camera coordinates\n  pixel_coords = xnp.stack([pix_x_int, pix_y_int, xnp.ones_like(pix_x_int)], axis=-1)\n  cam_coords = xnp.einsum('...ij,...j->...i', pixtocams, pixel_coords)\n\n  # Apply distortion correction if distortion parameters are provided\n  if distortion_params:\n    k1 = distortion_params.get('k1', 0)\n    k2 = distortion_params.get('k2', 0)\n    k3 = distortion_params.get('k3', 0)\n    k4 = distortion_params.get('k4', 0)\n    p1 = distortion_params.get('p1', 0)\n    p2 = distortion_params.get('p2', 0)\n\n    # Apply radial and tangential distortion correction\n    x_distorted, y_distorted = _radial_and_tangential_distort(\n        cam_coords[..., 0], cam_coords[..., 1], k1, k2, k3, k4, p1, p2\n    )\n    cam_coords = xnp.stack([x_distorted, y_distorted, cam_coords[..., 2]], axis=-1)\n\n  # Convert camera coordinates to world coordinates\n  world_coords = xnp.einsum('...ij,...j->...i', camtoworlds[..., :3, :3], cam_coords) + camtoworlds[..., :3, 3]\n\n  # Compute ray directions\n  if camtype == ProjectionType.PERSPECTIVE:\n    # For perspective projection, ray directions are computed as normalized vectors from camera origin to world coordinates\n    origins = camtoworlds[..., :3, 3]\n    directions = xnp.einsum('...ij,...j->...i', camtoworlds[..., :3, :3], cam_coords) - origins\n    viewdirs = xnp.linalg.norm(directions, axis=-1, keepdims=True)\n    directions = directions / viewdirs\n  elif camtype == ProjectionType.FISHEYE:\n    # For fisheye projection, ray directions are computed using the fisheye projection model\n    raise NotImplementedError(\"Fisheye projection is not yet supported.\")\n  elif camtype == ProjectionType.PANORAMIC:\n    # For panoramic projection, ray directions are computed using the panoramic projection model\n    raise NotImplementedError(\"Panoramic projection is not yet supported.\")\n  else:\n    raise ValueError(\"Invalid camera projection type.\")\n\n  # Compute ray differential radii\n  radii = xnp.zeros_like(pix_x_int)  # Placeholder for ray differential radii, currently set to zero\n\n  # Compute image plane coordinates\n  imageplane = xnp.stack([pix_x_int, pix_y_int], axis=-1)\n\n  return origins, directions, viewdirs, radii, imageplane"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "\n  # Convert pixel coordinates to camera coordinates\n  cam_coords = xnp.stack([pix_x_int, pix_y_int, xnp.ones_like(pix_x_int)], axis=-1)\n  cam_coords = xnp.einsum('...ij,...j->...i', pixtocams, cam_coords)\n\n  # Apply distortion correction if distortion parameters are provided\n  if distortion_params is not None:\n    k1, k2, k3, k4, p1, p2 = (\n        distortion_params.get('k1', 0.0),\n        distortion_params.get('k2', 0.0),\n        distortion_params.get('k3', 0.0),\n        distortion_params.get('k4', 0.0),\n        distortion_params.get('p1', 0.0),\n        distortion_params.get('p2', 0.0)\n    )\n    x, y = cam_coords[..., 0], cam_coords[..., 1]\n    x, y = _radial_and_tangential_distort(x, y, k1, k2, k3, k4, p1, p2)\n    cam_coords = xnp.stack([x, y, cam_coords[..., 2]], axis=-1)\n\n  # Convert camera coordinates to world coordinates\n  origins = xnp.einsum('...ij,...j->...i', camtoworlds[..., :3, :3], cam_coords)\n  origins += camtoworlds[..., :3, 3]\n\n  # Compute ray directions\n  directions = origins - camtoworlds[..., :3, 3]\n\n  # Normalize ray directions to get view directions\n  viewdirs = xnp.linalg.norm(directions, axis=-1, keepdims=True)\n  directions = directions / viewdirs\n\n  # Convert ray origins and directions into Normalized Device Coordinates (NDC) space if pixtocam_ndc is provided\n  if pixtocam_ndc is not None:\n    origins_ndc, directions_ndc = convert_to_ndc(origins, directions, pixtocam_ndc, xnp=xnp)\n    return origins, directions, viewdirs, None, origins_ndc\n\n  return origins, directions, viewdirs, None, None"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Convert pixel coordinates to NDC if pixtocam_ndc is provided\n  if pixtocam_ndc is not None:\n    origins_ndc, directions_ndc = convert_to_ndc(\n        origins=pix_x_int,\n        directions=pix_y_int,\n        pixtocam=pixtocam_ndc,\n        xnp=xnp\n    )\n  else:\n    origins_ndc, directions_ndc = None, None\n\n  # Apply distortion correction if distortion_params are provided\n  if distortion_params is not None:\n    # Apply distortion correction to pixel coordinates\n    pix_x_int, pix_y_int = _radial_and_tangential_distort(\n        pix_x_int,\n        pix_y_int,\n        **distortion_params\n    )\n\n  # Compute ray origins and directions based on the camera projection type\n  if camtype == ProjectionType.PERSPECTIVE:\n    # Compute ray origins and directions for perspective projection\n    origins, directions = xnp.moveaxis(pixtocams, -1, 0) @ xnp.stack(\n        [pix_x_int, pix_y_int, xnp.ones_like(pix_x_int)], axis=0\n    )\n    directions = xnp.moveaxis(directions, 0, -1)\n  elif camtype == ProjectionType.FISHEYE:\n    # Compute ray origins and directions for fisheye projection\n    origins, directions = _radial_and_tangential_undistort(\n        pix_x_int,\n        pix_y_int,\n        **distortion_params,\n        xnp=xnp\n    )\n  elif camtype == ProjectionType.PANORAMIC:\n    # Compute ray origins and directions for panoramic projection\n    origins, directions = _compute_panoramic_rays(\n        pix_x_int,\n        pix_y_int,\n        pixtocams,\n        camtoworlds,\n        xnp=xnp\n    )\n  else:\n    raise ValueError(\"Invalid camera projection type\")\n\n  # Normalize the ray directions\n  viewdirs = xnp.linalg.norm(directions, axis=-1, keepdims=True)\n  directions = directions / viewdirs\n\n  # Compute ray differential radii\n  radii = None  # Placeholder for computing ray differential radii\n\n  # Compute image plane coordinates\n  imageplane = xnp.stack([pix_x_int, pix_y_int], axis=-1)\n\n  return origins, directions, viewdirs, radii, imageplane"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "\n  # Convert pixel coordinates to camera coordinates\n  origins_cam = xnp.matmul(pixtocams, xnp.stack([pix_x_int, pix_y_int, xnp.ones_like(pix_x_int)], axis=0))\n  \n  # Apply distortion correction if distortion parameters are provided\n  if distortion_params:\n    k1, k2, k3, k4, p1, p2 = distortion_params['k1'], distortion_params['k2'], distortion_params['k3'], distortion_params['k4'], distortion_params['p1'], distortion_params['p2']\n    x_distorted, y_distorted = _radial_and_tangential_distort(pix_x_int, pix_y_int, k1, k2, k3, k4, p1, p2)\n    origins_cam = xnp.matmul(pixtocams, xnp.stack([x_distorted, y_distorted, xnp.ones_like(pix_x_int)], axis=0))\n\n  # Convert camera coordinates to world coordinates\n  origins_world = xnp.matmul(camtoworlds, xnp.concatenate([origins_cam, xnp.ones_like(pix_x_int)[xnp.newaxis, :]], axis=0))\n\n  # Compute normalized view directions\n  directions_world = origins_world - camtoworlds[..., :3, 3]\n\n  # Calculate differential radii\n  radii = xnp.linalg.norm(directions_world, axis=-1, keepdims=True)\n\n  # Normalize view directions\n  viewdirs = directions_world / radii\n\n  # Convert pixel coordinates to image plane coordinates\n  if pixtocam_ndc is not None:\n    origins_ndc, directions_ndc = convert_to_ndc(origins_world, directions_world, pixtocam_ndc)\n    imageplane = origins_ndc[..., :2] / -origins_ndc[..., 2, xnp.newaxis]\n  else:\n    imageplane = origins_world[..., :2] / -origins_world[..., 2, xnp.newaxis]\n\n  return origins_world, directions_world, viewdirs, radii, imageplane"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "\n    # Convert pixel coordinates to camera coordinates\n    cam_coords = xnp.einsum('...ij,...j->...i', pixtocams, xnp.stack([pix_x_int, pix_y_int, xnp.ones_like(pix_x_int)], axis=-1))\n\n    # Apply distortion correction if distortion parameters are provided\n    if distortion_params:\n        k1, k2, k3, k4, p1, p2 = distortion_params['k1'], distortion_params['k2'], distortion_params['k3'], distortion_params['k4'], distortion_params['p1'], distortion_params['p2']\n        x_distorted, y_distorted = _radial_and_tangential_distort(cam_coords[..., 0], cam_coords[..., 1], k1, k2, k3, k4, p1, p2)\n        cam_coords = xnp.stack([x_distorted, y_distorted, xnp.ones_like(x_distorted)], axis=-1)\n\n    # Convert camera coordinates to world coordinates\n    world_coords = xnp.einsum('...ij,...j->...i', camtoworlds[..., :3, :3], cam_coords) + camtoworlds[..., :3, 3]\n\n    # Compute ray directions\n    if camtype == ProjectionType.PERSPECTIVE:\n        ray_dirs = world_coords - camtoworlds[..., :3, 3, None]\n        ray_dirs = ray_dirs / xnp.linalg.norm(ray_dirs, axis=-1, keepdims=True)\n    elif camtype == ProjectionType.FISHEYE:\n        raise NotImplementedError(\"Fisheye projection type not implemented yet\")\n    elif camtype == ProjectionType.PANORAMIC:\n        raise NotImplementedError(\"Panoramic projection type not implemented yet\")\n    else:\n        raise ValueError(\"Invalid camera projection type\")\n\n    # Compute normalized view directions\n    view_dirs = ray_dirs\n\n    # Compute ray differential radii\n    radii = xnp.zeros_like(pix_x_int)  # Placeholder for ray differential radii, can be computed based on application\n\n    # Compute image plane coordinates\n    image_plane_coords = xnp.stack([pix_x_int, pix_y_int], axis=-1)\n\n    return world_coords, ray_dirs, view_dirs, radii, image_plane_coords"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "    pixcoords = xnp.stack([pix_x_int, pix_y_int, xnp.ones_like(pix_x_int)], axis=-1)\n    camcoords = xnp.einsum('...ij,...j->...i', pixtocams, pixcoords)\n\n    # Apply distortion correction if distortion parameters are provided\n    if distortion_params is not None:\n      k1 = distortion_params.get('k1', 0)\n      k2 = distortion_params.get('k2', 0)\n      k3 = distortion_params.get('k3', 0)\n      k4 = distortion_params.get('k4', 0)\n      p1 = distortion_params.get('p1', 0)\n      p2 = distortion_params.get('p2', 0)\n\n      # Apply radial and tangential distortion correction\n      x, y = camcoords[..., 0], camcoords[..., 1]\n      x, y = _radial_and_tangential_distort(x, y, k1, k2, k3, k4, p1, p2)\n      camcoords = xnp.stack([x, y, camcoords[..., 2]], axis=-1)\n\n    # Convert camera coordinates to world coordinates using extrinsics\n    origins = xnp.einsum('...ij,...j->...i', camtoworlds[..., :3, :3], camcoords) + camtoworlds[..., :3, 3]\n\n    # Compute ray directions in world coordinates\n    directions = origins - camtoworlds[..., :3, 3]\n\n    # Normalize the ray directions to get the view directions\n    viewdirs = xnp.linalg.norm(directions, axis=-1, keepdims=True)\n    directions /= viewdirs\n    viewdirs = xnp.squeeze(viewdirs, axis=-1)\n\n    # Compute the differential radii of the rays\n    radii = xnp.linalg.norm(directions, axis=-1, keepdims=True)\n\n    # Convert ray origins and directions into NDC space if pixtocam_ndc is provided\n    if pixtocam_ndc is not None:\n      origins_ndc, directions_ndc = convert_to_ndc(origins, directions, pixtocam_ndc, xnp=xnp)\n      return origins, directions, viewdirs, radii, origins_ndc, directions_ndc\n\n    # Compute the xy coordinates on the image plane\n    imageplane = origins[..., :2] / xnp.expand_dims(origins[..., 2], axis=-1)\n\n    return origins, directions, viewdirs, radii, imageplane"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Convert pixel coordinates to camera coordinates.\n  pix_coords = xnp.stack([pix_x_int, pix_y_int], axis=-1)\n  pix_coords = xnp.concatenate([pix_coords, xnp.ones(pix_coords.shape[:-1] + (1,))], axis=-1)\n  cam_coords = xnp.einsum('...ij,...j->...i', pixtocams, pix_coords)\n\n  # Convert camera coordinates to world coordinates.\n  world_coords = xnp.einsum('...ij,...j->...i', camtoworlds[..., :3, :3], cam_coords)\n  world_coords += camtoworlds[..., :3, 3]\n\n  # Compute ray origins and directions.\n  origins = camtoworlds[..., :3, 3]\n  directions = world_coords - origins\n  viewdirs = xnp.linalg.norm(directions, axis=-1)\n  directions = directions / xnp.maximum(viewdirs[..., None], 1e-7)\n  viewdirs = xnp.maximum(viewdirs, 1e-7)\n\n  # Apply distortion correction if distortion parameters are provided.\n  if distortion_params is not None:\n    if camtype == ProjectionType.PERSPECTIVE:\n      # Apply radial and tangential distortion correction for perspective projection.\n      k1, k2, k3, k4, p1, p2 = (\n          distortion_params.get('k1', 0.0),\n          distortion_params.get('k2', 0.0),\n          distortion_params.get('k3', 0.0),\n          distortion_params.get('k4', 0.0),\n          distortion_params.get('p1', 0.0),\n          distortion_params.get('p2', 0.0),\n      )\n      x, y = pix_x_int, pix_y_int\n      xd, yd = _radial_and_tangential_distort(x, y, k1, k2, k3, k4, p1, p2)\n      x, y = _radial_and_tangential_undistort(xd, yd, k1, k2, k3, k4, p1, p2)\n      imageplane = xnp.stack([x, y], axis=-1)\n    else:\n      # Handle other projection types (e.g., fisheye or panoramic) if needed.\n      raise NotImplementedError(\"Distortion correction for this projection type is not implemented yet.\")\n  else:\n    imageplane = pix_coords[..., :2]\n\n  # Convert ray origins and directions to Normalized Device Coordinates (NDC) if pixtocam_ndc is provided.\n  if pixtocam_ndc is not None:\n    origins_ndc, directions_ndc = convert_to_ndc(origins, directions, pixtocam_ndc, xnp=xnp)\n    return origins, directions, viewdirs, None, origins_ndc, directions_ndc, imageplane\n  else:\n    return origins, directions, viewdirs, None, None, None, imageplane"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Convert pixel coordinates to NDC space if pixtocam_ndc is provided\n  if pixtocam_ndc is not None:\n    origins, directions = convert_to_ndc(\n        origins=pix_x_int,\n        directions=pix_y_int,\n        pixtocam=pixtocam_ndc,\n        near=1.0,\n        xnp=xnp,\n    )\n  else:\n    # Compute ray origins and directions using the camera intrinsics and extrinsics\n    origins = xnp.linalg.inv(pixtocams) @ xnp.stack([pix_x_int, pix_y_int, xnp.ones_like(pix_x_int)], axis=-1)[..., None]\n    directions = xnp.dot(xnp.linalg.inv(camtoworlds)[..., :3, :3], origins)  # Transform to world coordinates\n\n  # Normalize the ray directions\n  viewdirs = xnp.linalg.norm(directions, axis=-2)\n  directions = directions / viewdirs\n\n  # Compute the radii for the rays\n  radii = xnp.linalg.norm(origins, axis=-2)\n\n  # Compute the image plane coordinates\n  imageplane = xnp.stack([pix_x_int, pix_y_int], axis=-1)\n\n  return origins, directions, viewdirs, radii, imageplane"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "\n    # Convert pixel coordinates to camera coordinates\n    cam_coords = xnp.linalg.inv(pixtocams) @ xnp.stack([pix_x_int, pix_y_int, xnp.ones_like(pix_x_int)], axis=0)\n\n    # Apply distortion correction if distortion parameters are provided\n    if distortion_params:\n      k1, k2, k3, k4, p1, p2 = (\n          distortion_params.get('k1', 0.0),\n          distortion_params.get('k2', 0.0),\n          distortion_params.get('k3', 0.0),\n          distortion_params.get('k4', 0.0),\n          distortion_params.get('p1', 0.0),\n          distortion_params.get('p2', 0.0),\n      )\n      x_dist, y_dist = _radial_and_tangential_distort(\n          cam_coords[0], cam_coords[1], k1, k2, k3, k4, p1, p2\n      )\n      cam_coords[:2] = x_dist, y_dist\n\n    # Convert camera coordinates to world coordinates using extrinsics\n    world_coords = camtoworlds @ xnp.concatenate([cam_coords, xnp.ones_like(cam_coords[0:1])], axis=0)\n    \n    # Calculate ray origins and directions\n    origins = world_coords[Ellipsis, :3, 3]\n    directions = world_coords[Ellipsis, :3, 2]\n    \n    # Normalize the direction vectors\n    viewdirs = xnp.linalg.norm(directions, axis=-1, keepdims=True)\n    directions /= viewdirs\n    \n    # Compute the differential radii of the rays\n    radii = xnp.ones_like(viewdirs)\n    \n    # Project the pixel coordinates to the image plane in world space\n    imageplane = world_coords[Ellipsis, :2, 3]\n\n    return origins, directions, viewdirs, radii, imageplane"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  if camtype == ProjectionType.PERSPECTIVE:\n    # Convert pixel coordinates to camera coordinates using inverse intrinsics.\n    cam_x = (pix_x_int - pixtocams[..., 0, 2]) / pixtocams[..., 0, 0]\n    cam_y = (pix_y_int - pixtocams[..., 1, 2]) / pixtocams[..., 1, 1]\n    cam_z = xnp.ones_like(cam_x)\n    cam_coords = xnp.stack([cam_x, cam_y, cam_z], axis=-1)\n\n    # Transform camera coordinates to world coordinates using extrinsics.\n    world_coords = xnp.einsum('...ij,...kj->...ki', camtoworlds[..., :3, :3], cam_coords) + camtoworlds[..., :3, 3, None]\n\n    # Compute ray origins and directions.\n    origins = camtoworlds[..., :3, 3]\n    directions = xnp.linalg.norm(world_coords - origins, axis=-1)\n    viewdirs = xnp.linalg.norm(directions, axis=-1)\n\n    # Compute differential radii for the rays.\n    radii = xnp.zeros_like(viewdirs)\n\n    # Compute image plane coordinates.\n    imageplane = xnp.stack([pix_x_int, pix_y_int], axis=-1)\n\n    return origins, directions, viewdirs, radii, imageplane\n\n  elif camtype == ProjectionType.FISHEYE:\n    # Convert pixel coordinates to camera coordinates using inverse intrinsics.\n    cam_x = (pix_x_int - pixtocams[..., 0, 2]) / pixtocams[..., 0, 0]\n    cam_y = (pix_y_int - pixtocams[..., 1, 2]) / pixtocams[..., 1, 1]\n    cam_z = xnp.ones_like(cam_x)\n    cam_coords = xnp.stack([cam_x, cam_y, cam_z], axis=-1)\n\n    # Transform camera coordinates to world coordinates using extrinsics.\n    world_coords = xnp.einsum('...ij,...kj->...ki', camtoworlds[..., :3, :3], cam_coords) + camtoworlds[..., :3, 3, None]\n\n    # Compute ray origins and directions.\n    origins = camtoworlds[..., :3, 3]\n    directions = xnp.linalg.norm(world_coords - origins, axis=-1)\n    viewdirs = xnp.linalg.norm(directions, axis=-1)\n\n    # Compute differential radii for the rays.\n    radii = xnp.zeros_like(viewdirs)\n\n    # Compute image plane coordinates.\n    imageplane = xnp.stack([pix_x_int, pix_y_int], axis=-1)\n\n    return origins, directions, viewdirs, radii, imageplane\n\n  elif camtype == ProjectionType.PANORAMIC:\n    # Convert pixel coordinates to camera coordinates using inverse intrinsics for NDC.\n    origins_ndc, directions_ndc = convert_to_ndc(origins, directions, pixtocam_ndc, xnp=xnp)\n\n    # Compute ray origins and directions.\n    origins = camtoworlds[..., :3, 3]\n    directions = xnp.linalg.norm(directions_ndc, axis=-1)\n    viewdirs = xnp.linalg.norm(directions, axis=-1)\n\n    # Compute differential radii for the rays.\n    radii = xnp.zeros_like(viewdirs)\n\n    # Compute image plane coordinates.\n    imageplane = xnp.stack([pix_x_int, pix_y_int], axis=-1)\n\n    return origins, directions, viewdirs, radii, imageplane\n\n  else:\n    raise ValueError(\"Unsupported camera projection type. Please use either 'perspective', 'fisheye', or 'pano'.\")"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Convert pixel coordinates to camera coordinates\n  origins_cam = xnp.matmul(pixtocams, xnp.stack([pix_x_int, pix_y_int, xnp.ones_like(pix_x_int)], axis=0))\n  \n  # Apply distortion correction if distortion parameters are provided\n  if distortion_params is not None:\n    k1 = distortion_params.get('k1', 0)\n    k2 = distortion_params.get('k2', 0)\n    k3 = distortion_params.get('k3', 0)\n    k4 = distortion_params.get('k4', 0)\n    p1 = distortion_params.get('p1', 0)\n    p2 = distortion_params.get('p2', 0)\n    \n    # Apply distortion correction to the pixel coordinates\n    distorted_x, distorted_y = _radial_and_tangential_distort(pix_x_int, pix_y_int, k1, k2, k3, k4, p1, p2)\n    \n    # Update the origins_cam with the distorted coordinates\n    origins_cam = xnp.matmul(pixtocams, xnp.stack([distorted_x, distorted_y, xnp.ones_like(pix_x_int)], axis=0))\n  \n  # Convert camera coordinates to world coordinates\n  origins_world = xnp.matmul(camtoworlds, xnp.concatenate([origins_cam, xnp.ones_like(pix_x_int)], axis=0))\n  \n  # Compute the ray directions\n  directions_world = origins_world - camtoworlds[:, :, 3]\n  \n  # Normalize the ray directions\n  viewdirs = xnp.linalg.norm(directions_world, axis=0)\n  directions_world = directions_world / viewdirs\n  \n  # Compute the differential radii of the rays\n  radii = xnp.linalg.norm(directions_world, axis=0)\n  \n  # Convert pixel coordinates to image plane coordinates\n  imageplane = xnp.stack([pix_x_int, pix_y_int], axis=0)\n  \n  return origins_world, directions_world, viewdirs, radii, imageplane"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Convert pixel coordinates to normalized device coordinates (NDC) if pixtocam_ndc is provided\n  if pixtocam_ndc is not None:\n    pix_x_ndc = (2 * pix_x_int / pixtocams[0, 0] - 1)\n    pix_y_ndc = (2 * pix_y_int / pixtocams[1, 1] - 1)\n  else:\n    pix_x_ndc = pix_x_int\n    pix_y_ndc = pix_y_int\n\n  # Apply distortion correction if distortion_params are provided\n  if distortion_params is not None:\n    k1 = distortion_params.get('k1', 0)\n    k2 = distortion_params.get('k2', 0)\n    k3 = distortion_params.get('k3', 0)\n    k4 = distortion_params.get('k4', 0)\n    p1 = distortion_params.get('p1', 0)\n    p2 = distortion_params.get('p2', 0)\n    # Apply distortion correction to pixel coordinates\n    pix_x_distorted, pix_y_distorted = _radial_and_tangential_distort(\n        pix_x_ndc, pix_y_ndc, k1, k2, k3, k4, p1, p2\n    )\n  else:\n    pix_x_distorted = pix_x_ndc\n    pix_y_distorted = pix_y_ndc\n\n  # Convert pixel coordinates to camera coordinates\n  cam_coords = xnp.stack([pix_x_distorted, pix_y_distorted, xnp.ones_like(pix_x_distorted)], axis=-1)\n  cam_coords = xnp.matmul(cam_coords, xnp.linalg.inv(pixtocams))\n\n  # Convert camera coordinates to world coordinates\n  world_coords = xnp.matmul(cam_coords, xnp.transpose(camtoworlds, (0, 2, 1)))\n  world_coords = world_coords[..., :3] / world_coords[..., 3:4]\n\n  # Compute ray origins and directions\n  origins = world_coords\n  directions = origins - camtoworlds[..., :3, 3:4]\n\n  # Normalize ray directions to get view directions\n  viewdirs = xnp.linalg.norm(directions, axis=-1, keepdims=True)\n  directions = directions / viewdirs\n\n  # Compute ray differential radii\n  radii = xnp.zeros_like(pix_x_int)  # Placeholder for ray differential radii\n\n  # Compute image plane coordinates\n  imageplane = xnp.stack([pix_x_int, pix_y_int], axis=-1)\n\n  return origins, directions, viewdirs, radii, imageplane"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "\n  # Convert pixel coordinates to NDC if pixtocam_ndc is provided\n  if pixtocam_ndc is not None:\n    origins, directions = convert_to_ndc(\n        origins=pix_x_int,\n        directions=pix_y_int,\n        pixtocam=pixtocam_ndc,\n        xnp=xnp\n    )\n  else:\n    # Convert pixel coordinates to camera coordinates\n    cam_coords = xnp.stack([pix_x_int, pix_y_int, xnp.ones_like(pix_x_int)], axis=-1)\n    cam_coords = xnp.einsum('...ij,...j->...i', pixtocams, cam_coords)\n\n    # Apply distortion correction if distortion_params are provided\n    if distortion_params is not None:\n      k1 = distortion_params.get('k1', 0)\n      k2 = distortion_params.get('k2', 0)\n      k3 = distortion_params.get('k3', 0)\n      k4 = distortion_params.get('k4', 0)\n      p1 = distortion_params.get('p1', 0)\n      p2 = distortion_params.get('p2', 0)\n      x, y = cam_coords[..., 0], cam_coords[..., 1]\n      x, y = _radial_and_tangential_distort(x, y, k1, k2, k3, k4, p1, p2)\n      cam_coords = xnp.stack([x, y, cam_coords[..., 2]], axis=-1)\n\n    # Convert camera coordinates to world coordinates\n    origins = xnp.einsum('...ij,...j->...i', camtoworlds[..., :3, :3], cam_coords) + camtoworlds[..., :3, 3]\n\n    # Compute ray directions\n    directions = origins - camtoworlds[..., :3, 3]\n\n  # Normalize ray directions\n  viewdirs = xnp.linalg.norm(directions, axis=-1, keepdims=True)\n  directions /= viewdirs\n\n  # Compute differential radii\n  radii = xnp.zeros(pix_x_int.shape[:-1] + (1,))\n\n  # Compute image plane coordinates\n  imageplane = xnp.stack([pix_x_int, pix_y_int], axis=-1)\n\n  return origins, directions, viewdirs, radii, imageplane"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "\n  # Convert pixel coordinates to normalized device coordinates (NDC)\n  if pixtocam_ndc is not None:\n    origins_ndc, directions_ndc = convert_to_ndc(\n        origins=pix_x_int,\n        directions=pix_y_int,\n        pixtocam=pixtocam_ndc,\n        xnp=xnp\n    )\n  else:\n    origins_ndc, directions_ndc = pix_x_int, pix_y_int\n\n  # If distortion parameters are provided, undistort the pixel coordinates\n  if distortion_params is not None:\n    # Apply distortion correction based on the camera projection type\n    if camtype == ProjectionType.PERSPECTIVE:\n      # Undistort the pixel coordinates using the radial and tangential distortion parameters\n      undistorted_x, undistorted_y = _radial_and_tangential_undistort(\n          xd=pix_x_int,\n          yd=pix_y_int,\n          k1=distortion_params['k1'],\n          k2=distortion_params['k2'],\n          k3=distortion_params['k3'],\n          k4=distortion_params['k4'],\n          p1=distortion_params['p1'],\n          p2=distortion_params['p2'],\n          xnp=xnp\n      )\n    elif camtype == ProjectionType.FISHEYE:\n      # Undistort the pixel coordinates using the fisheye distortion parameters\n      undistorted_x, undistorted_y = fisheye_undistort(\n          xd=pix_x_int,\n          yd=pix_y_int,\n          k1=distortion_params['k1'],\n          k2=distortion_params['k2'],\n          k3=distortion_params['k3'],\n          k4=distortion_params['k4'],\n          xnp=xnp\n      )\n    else:\n      raise ValueError(\"Unsupported camera projection type\")\n\n    # Update the pixel coordinates with the undistorted values\n    pix_x_int, pix_y_int = undistorted_x, undistorted_y\n\n  # Calculate the ray origins and directions using the pixel coordinates, inverse intrinsics, and extrinsics\n  origins, directions = calculate_ray_origins_and_directions(\n      pix_x_int=pix_x_int,\n      pix_y_int=pix_y_int,\n      pixtocams=pixtocams,\n      camtoworlds=camtoworlds,\n      xnp=xnp\n  )\n\n  # Calculate the normalized view directions\n  viewdirs = normalize(directions, axis=-1)\n\n  # Calculate the ray differential radii\n  radii = calculate_ray_differential_radii(\n      pix_x_int=pix_x_int,\n      pix_y_int=pix_y_int,\n      pixtocams=pixtocams,\n      camtoworlds=camtoworlds,\n      xnp=xnp\n  )\n\n  # Calculate the image plane coordinates\n  imageplane = calculate_image_plane_coordinates(\n      pix_x_int=pix_x_int,\n      pix_y_int=pix_y_int,\n      pixtocams=pixtocams,\n      camtoworlds=camtoworlds,\n      xnp=xnp\n  )\n\n  return origins, directions, viewdirs, radii, imageplane"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "\n  # Convert pixel coordinates to camera coordinates\n  if camtype == ProjectionType.PERSPECTIVE:\n    origins_ndc, directions_ndc = convert_to_ndc(\n        pix_x_int, pix_y_int, pixtocams, xnp=xnp\n    )\n  else:\n    raise ValueError(\"Unsupported camera projection type\")\n\n  # Convert camera coordinates to world coordinates\n  origins = origins_ndc @ camtoworlds\n  directions = directions_ndc @ camtoworlds\n\n  # Normalize the direction vectors\n  viewdirs = xnp.linalg.norm(directions, axis=-1, keepdims=True)\n  directions = directions / viewdirs\n\n  # Compute the differential radii of the rays\n  radii = None  # Placeholder for computing the differential radii\n\n  # Compute the image plane coordinates\n  imageplane = None  # Placeholder for computing the image plane coordinates\n\n  return origins, directions, viewdirs, radii, imageplane"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Convert pixel coordinates to homogeneous coordinates\n  pix_homogeneous = xnp.stack([pix_x_int, pix_y_int, xnp.ones_like(pix_x_int)], axis=-1)\n\n  # Apply distortion correction if distortion parameters are provided\n  if distortion_params:\n    k1, k2, k3, k4, p1, p2 = (\n        distortion_params.get('k1', 0.0),\n        distortion_params.get('k2', 0.0),\n        distortion_params.get('k3', 0.0),\n        distortion_params.get('k4', 0.0),\n        distortion_params.get('p1', 0.0),\n        distortion_params.get('p2', 0.0),\n    )\n    # Apply radial and tangential distortion correction\n    pix_x_distorted, pix_y_distorted = _radial_and_tangential_distort(\n        pix_x_int, pix_y_int, k1, k2, k3, k4, p1, p2\n    )\n    # Update the pixel coordinates with the distortion correction\n    pix_homogeneous = xnp.stack([pix_x_distorted, pix_y_distorted, xnp.ones_like(pix_x_int)], axis=-1)\n\n  # Apply inverse intrinsics to convert pixel coordinates to camera coordinates\n  cam_coords = xnp.einsum('...ij,...j->...i', pixtocams, pix_homogeneous)\n\n  # Apply Normalized Device Coordinates (NDC) projection if pixtocam_ndc is provided\n  if pixtocam_ndc is not None:\n    cam_coords_ndc = xnp.einsum('...ij,...j->...i', pixtocam_ndc, pix_homogeneous)\n  else:\n    cam_coords_ndc = None\n\n  # Apply extrinsics to convert camera coordinates to world coordinates\n  world_coords = xnp.einsum('...ij,...j->...i', camtoworlds[..., :3, :3], cam_coords) + camtoworlds[..., :3, 3]\n\n  # Compute ray directions by subtracting the camera origin from the world coordinates\n  directions = world_coords - camtoworlds[..., :3, 3]\n\n  # Normalize the ray directions to obtain view directions\n  viewdirs = xnp.linalg.norm(directions, axis=-1, keepdims=True)\n  directions = directions / viewdirs\n  viewdirs = directions\n\n  # Compute differential radii of the rays\n  radii = xnp.linalg.norm(directions, axis=-1, keepdims=True)\n\n  # Compute image plane coordinates by projecting the world coordinates onto the image plane\n  if camtype == ProjectionType.PERSPECTIVE:\n    # For perspective projection, the image plane coordinates are the x and y components of the world coordinates\n    imageplane = world_coords[..., :2]\n  else:\n    # For other projection types, the image plane coordinates need to be computed differently\n    # (e.g., fisheye or panoramic projection)\n    imageplane = None\n\n  return world_coords, directions, viewdirs, radii, imageplane"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  dt = jnp.diff(t)\n  pdf = w / dt\n  return pdf"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  # Calculate the differences between consecutive elements in t\n  dt = jnp.diff(t)\n\n  # Divide the weights by the differences to obtain the PDF\n  pdf = w / dt\n\n  return pdf"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  # Calculate the differences between consecutive elements in t\n  dt = jnp.diff(t)\n\n  # Divide the weights by the differences to obtain the PDF\n  pdf = w / dt\n\n  return pdf"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  dt = jnp.diff(t)\n  pdf = w / dt\n  return pdf"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  dt = jnp.diff(t)\n  pdf = w / dt\n  return pdf"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  # Calculate the differences between consecutive elements in t\n  dt = jnp.diff(t)\n  \n  # Calculate the PDF by dividing the weights by the differences\n  pdf = w / dt\n  \n  return pdf"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  # Calculate the differences between consecutive elements in t\n  dt = jnp.diff(t)\n\n  # Divide the weights by the differences to obtain the PDF\n  pdf = w / dt\n\n  return pdf"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  dt = jnp.diff(t)\n  pdf = w / dt\n  return pdf"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  dt = jnp.diff(t)\n  pdf = w / dt\n  return pdf"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  dt = jnp.diff(t)\n  pdf = w / dt\n  return pdf"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  dt = jnp.diff(t)  # Calculate the difference between consecutive elements in t\n  pdf = w / dt  # Divide the weights by the difference between consecutive elements\n  return pdf  # Return the resulting PDF"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  dt = jnp.diff(t)\n  pdf = w / dt\n  return pdf"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  # Calculate the differences between consecutive elements in t\n  dt = jnp.diff(t)\n\n  # Calculate the PDF by dividing the weights by the differences\n  pdf = w / dt\n\n  return pdf"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  dt = jnp.diff(t)  # Calculate the difference between consecutive elements in t\n  pdf = w / dt  # Divide the weights by the difference between consecutive elements\n  return pdf  # Return the resulting PDF"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  dt = jnp.diff(t)\n  pdf = w / dt\n  return pdf"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  # Calculate the differences between consecutive elements in t\n  dt = jnp.diff(t)\n  # Divide the weights by the differences to obtain the PDF\n  pdf = w / dt\n  return pdf"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  # Calculate the differences between consecutive elements in t\n  dt = jnp.diff(t)\n\n  # Divide the weights by the differences to obtain the PDF\n  pdf = w / dt\n\n  return pdf"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  dt = jnp.diff(t)\n  pdf = w / dt\n  return pdf"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  # Calculate the differences between consecutive elements in the input vector t\n  dt = t[1:] - t[:-1]\n  # Divide the weights by the differences to obtain the PDF\n  pdf = w / dt\n  return pdf"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  dt = jnp.diff(t)\n  pdf = w / dt\n  return pdf"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist * jnp.linalg.norm(dirs, axis=-1, keepdims=True)\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist * jnp.linalg.norm(dirs, axis=-1, keepdims=True)\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist * jnp.linalg.norm(dirs, axis=-1, keepdims=True)\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist * jnp.linalg.norm(dirs, axis=-1, keepdims=True)\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist * jnp.linalg.norm(dirs, axis=-1, keepdims=True)\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist * jnp.linalg.norm(dirs, axis=-1, keepdims=True)\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist / jnp.linalg.norm(dirs, axis=-1, keepdims=True)\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * jnp.linalg.norm(dirs, axis=-1) * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist * jnp.linalg.norm(dirs, axis=-1, keepdims=True)\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist / jnp.linalg.norm(dirs, axis=-1, keepdims=True)\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist * jnp.linalg.norm(dirs, axis=-1, keepdims=True)\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist / jnp.linalg.norm(dirs, axis=-1, keepdims=True)\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist\n\n  # Call the helper function to compute alpha weights\n  weights = compute_alpha_weights_helper(density_delta, **kwargs)\n\n  return weights"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist / jnp.linalg.norm(dirs, axis=-1, keepdims=True)\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist / jnp.linalg.norm(dirs, axis=-1, keepdims=True)\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * tdist\n  weights = compute_alpha_weights_helper(density_delta, **kwargs)\n  return weights"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, p * td)"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, p * td)"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, p * td)"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, p * td)"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, p * td)"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_mul(p, td))"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, p * td)"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_mul(p, td))"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, p * td)"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, p * td)"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, p * td)"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, p * td)"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, p * td)"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return p * td"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return p * td"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return p * td"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, p * td)"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, p * td)"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, p * td)"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, p * td)"}
{"namespace": "stepfun.sample", "completion": "  if rng is None:\n    # Deterministic sampling\n    if deterministic_center:\n      # Centered sampling\n      t_mid = (t[..., :-1] + t[..., 1:]) / 2\n      w = jax.nn.softmax(w_logits, axis=-1)\n      cdf = integrate_weights(w)\n      cdf = jnp.clip(cdf, 0, 1)\n      u = jnp.linspace(0 + eps, 1 - eps, num_samples)\n      samples = math.sorted_interp(u, cdf, t_mid, utils.device_is_tpu())\n    else:\n      # Uniform sampling\n      t_ext = jnp.concatenate([t[..., :1], t, t[..., -1:]], axis=-1)\n      w = jax.nn.softmax(w_logits, axis=-1)\n      cdf = integrate_weights(w)\n      cdf = jnp.clip(cdf, 0, 1)\n      u = jnp.linspace(0 + eps, 1 - eps, num_samples)\n      samples = math.sorted_interp(u, cdf, t_ext, utils.device_is_tpu())\n  else:\n    # Random sampling\n    key, subkey = jax.random.split(rng)\n    u = jax.random.uniform(subkey, (num_samples,), minval=eps, maxval=1 - eps)\n    t_new = invert_cdf(u, t, w_logits)\n    if single_jitter:\n      jitter = jax.random.uniform(subkey, (num_samples,), minval=-eps, maxval=eps)\n      samples = t_new + jitter\n    else:\n      jitter = jax.random.uniform(subkey, (num_samples, t_new.shape[-1]), minval=-eps, maxval=eps)\n      samples = t_new + jitter\n  return samples"}
{"namespace": "stepfun.sample", "completion": "  # Check if rng is None and use deterministic sampling based on linspace\n  if rng is None:\n    tq = linspline.linspace(t[..., :1], t[..., -1:], num_samples + 1)\n    tq = tq[..., 1:]\n    return query(tq, t, w_logits)\n\n  # Generate random samples using the provided random number generator\n  u = jax.random.uniform(rng, (num_samples,) + w_logits.shape[:-1], dtype=jnp.float32)\n  t_new = invert_cdf(u, t, w_logits)\n\n  # Jitter the samples\n  if single_jitter:\n    jitter = jax.random.uniform(rng, (num_samples,) + w_logits.shape[:-1], dtype=jnp.float32) * jnp.diff(t).mean() / 2\n    t_new += jitter\n  else:\n    jitter = jax.random.uniform(rng, (num_samples, 1) + w_logits.shape[:-1], dtype=jnp.float32) * jnp.diff(t).mean() / 2\n    t_new += jitter\n\n  # Adjust the samples based on deterministic_center flag\n  if deterministic_center:\n    t_new += jnp.diff(t) / 2 - eps\n\n  return t_new"}
{"namespace": "stepfun.sample", "completion": "  if rng is not None:\n    u = jax.random.uniform(rng, (num_samples,) + t.shape[:-1] + (1,), minval=eps, maxval=1.0 - eps)\n    t_samples = invert_cdf(u, t, w_logits)\n    if single_jitter:\n      jitter = jax.random.uniform(rng, (num_samples,) + t.shape[:-1] + (1,), minval=-0.5, maxval=0.5)\n      t_samples += jitter * jnp.diff(t).squeeze(-1)\n  else:\n    if deterministic_center:\n      t_samples = linspline.linspace(t, num_samples)\n    else:\n      t_samples = linspline.linspace(t, num_samples, endpoint=False)\n  return t_samples"}
{"namespace": "stepfun.sample", "completion": "  if rng is not None:\n    u = jax.random.uniform(rng, (num_samples,) + t.shape[:-1] + (1,), minval=eps, maxval=1.0 - eps)\n    t_samples = invert_cdf(u, t, w_logits)\n    if single_jitter:\n      jitter = jax.random.uniform(rng, (num_samples,) + t.shape[:-1] + (1,), minval=-0.5, maxval=0.5)\n      t_samples += jitter * jnp.diff(t).squeeze(-1)\n    if deterministic_center:\n      t_samples = t_samples - 0.5 * jnp.diff(t).squeeze(-1)\n  else:\n    t_samples = linspline.linspace(t, num_samples, endpoint=False)\n  return t_samples"}
{"namespace": "stepfun.sample", "completion": "  if rng is None:\n    # Deterministic sampling based on linspace.\n    tq = linspline.linspace(t, num_samples, endpoint=False)\n  else:\n    # Random sampling based on uniform distribution.\n    u = jax.random.uniform(rng, (num_samples,) + w_logits.shape[:-1] + (1,), minval=eps, maxval=1.0 - eps)\n    tq = invert_cdf(u, t, w_logits)\n\n  if single_jitter:\n    # Add jitter to each sample independently.\n    jitter = jax.random.uniform(rng, tq.shape) * jnp.diff(t)[..., None] / 2\n    samples = tq + jitter - jnp.diff(t)[..., None] / 2\n  else:\n    # Add the same jitter to all samples.\n    jitter = jax.random.uniform(rng, (1,) + tq.shape[-1:]) * jnp.diff(t)[..., None] / 2\n    samples = tq + jitter - jnp.diff(t)[..., None] / 2\n\n  if deterministic_center:\n    # Center the samples in each interval.\n    samples = samples + jnp.diff(t)[..., None] / 2\n\n  return samples"}
{"namespace": "stepfun.sample", "completion": "  # Ensure valid input\n  utils.assert_valid_stepfun(t, w_logits)\n\n  # Compute the PDF and CDF for each weight vector\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  # Generate random samples\n  if rng is not None:\n    u = jax.random.uniform(rng, shape=(num_samples,) + w.shape[:-1] + (1,), minval=0, maxval=1 - eps)\n  else:\n    u = jnp.linspace(0, 1 - eps, num_samples)\n\n  # Interpolate into the inverse CDF\n  t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n\n  # Jitter the samples\n  if single_jitter:\n    jitter = jax.random.uniform(rng, shape=(num_samples,) + t.shape[:-1] + (1,), minval=-0.5, maxval=0.5)\n  else:\n    jitter = jax.random.uniform(rng, shape=(num_samples,) + t.shape, minval=-0.5, maxval=0.5)\n\n  t_jittered = t_new + jitter * jnp.diff(t).reshape((1,) * (t_new.ndim - 1) + t.shape)\n  t_new = jnp.where(rng is not None, t_jittered, t_new)\n\n  # Ensure the samples are centered in each interval of the PDF\n  if deterministic_center:\n    t_diff = jnp.diff(t) / 2\n    t_new = t_new + t_diff\n\n  return t_new"}
{"namespace": "stepfun.sample", "completion": "  if rng is not None:\n    u = jax.random.uniform(rng, shape=(num_samples,) + t.shape[:-1] + (1,), dtype=t.dtype)\n    t_samples = invert_cdf(u, t, w_logits)\n  else:\n    t_samples = linspline.linspace(t, num_samples, eps)\n\n  if single_jitter:\n    jitter = jax.random.uniform(rng, shape=(num_samples,) + t.shape[:-1] + (1,), dtype=t.dtype)\n  else:\n    jitter = jax.random.uniform(rng, shape=t_samples.shape, dtype=t.dtype)\n\n  if deterministic_center:\n    t_samples = t_samples + (0.5 - jitter) * jnp.diff(t_samples)\n\n  return t_samples"}
{"namespace": "stepfun.sample", "completion": "  if rng is not None:\n    u = jax.random.uniform(rng, (num_samples,) + t.shape[:-1] + (1,), minval=eps, maxval=1.0 - eps)\n    t_new = invert_cdf(u, t, w_logits)\n  else:\n    t_new = linspline.linspace(t, num_samples, endpoint=False)\n    t_new = t_new[..., :-1]\n\n  if single_jitter:\n    jitter = jax.random.uniform(rng, (1,) + t.shape[:-1] + (1,), minval=0.0, maxval=1.0)\n  else:\n    jitter = jax.random.uniform(rng, (num_samples,) + t.shape[:-1] + (1,), minval=0.0, maxval=1.0)\n\n  if deterministic_center:\n    t_diff = jnp.diff(t, axis=-1)\n    t_new = t_new + 0.5 * t_diff\n\n  return t_new + (jitter - 0.5) * t_diff"}
{"namespace": "stepfun.sample", "completion": "  if rng is None:\n    # Deterministic sampling\n    if deterministic_center:\n      # Centered sampling\n      u = jnp.linspace(0, 1, num_samples + 1)\n      u = 0.5 * (u[:-1] + u[1:])\n    else:\n      # Uniform sampling\n      u = jnp.linspace(0, 1, num_samples)\n  else:\n    # Random sampling\n    u = jax.random.uniform(rng, (num_samples,))\n\n  # Invert the CDF to get the sample locations\n  t_new = invert_cdf(u, t, w_logits)\n\n  if single_jitter:\n    # Apply single jitter to all samples\n    jitter = jax.random.uniform(rng, (num_samples,)) * (t[1] - t[0])\n    t_new = t_new + jitter\n  else:\n    # Apply independent jitter to each sample\n    jitter = jax.random.uniform(rng, (num_samples,)) * (t[1] - t[0]) - (t[1] - t[0]) / 2\n    t_new = t_new + jitter\n\n  return t_new"}
{"namespace": "stepfun.sample", "completion": "  if rng is None:\n    # Deterministic sampling\n    if deterministic_center:\n      # Centered sampling in each interval\n      t_mid = (t[..., :-1] + t[..., 1:]) / 2\n      t_mid = jnp.expand_dims(t_mid, axis=-1)\n      samples = t_mid\n    else:\n      # Uniformly spaced sampling\n      samples = linspline.linspace(t[..., :-1], t[..., 1:], num_samples)\n  else:\n    # Random sampling\n    u = jax.random.uniform(rng, (num_samples,) + w_logits.shape[:-1] + (1,), minval=eps, maxval=1.0 - eps)\n    t_new = invert_cdf(u, t, w_logits)\n    if single_jitter:\n      jitter = jax.random.uniform(rng, (num_samples,) + (1,) * (t_new.ndim - 1), minval=-0.5, maxval=0.5)\n      t_new = t_new + jitter * jnp.diff(t_new).squeeze(-1)\n    samples = t_new\n\n  return samples"}
{"namespace": "stepfun.sample", "completion": "  if rng is not None:\n    u = jax.random.uniform(rng, shape=(num_samples,) + t.shape[:-1] + (1,), dtype=t.dtype)\n    t_samples = invert_cdf(u, t, w_logits)\n  else:\n    t_samples = linspline.linspace(t, num_samples, endpoint=False)\n    if deterministic_center:\n      t_samples += jnp.linspace(0.5 / num_samples, 1 - 0.5 / num_samples, num_samples)\n  if single_jitter:\n    t_samples += jax.random.uniform(rng, shape=(num_samples,) + t.shape[:-1], dtype=t.dtype) * jnp.diff(t).squeeze(-1) / num_samples\n  else:\n    t_samples += jax.random.uniform(rng, shape=(num_samples,) + t.shape[:-1], dtype=t.dtype) * jnp.diff(t).expand_dims(-1)\n  return query(t_samples, t, w_logits)"}
{"namespace": "stepfun.sample", "completion": "  if rng is not None:\n    u = jax.random.uniform(rng, (num_samples,) + t.shape[:-1] + (1,), dtype=jnp.float32)\n  else:\n    u = jnp.linspace(0, 1, num_samples + 2)[1:-1]\n    u = u[None, ..., None]\n\n  t_new = invert_cdf(u, t, w_logits)\n\n  if single_jitter:\n    jitter = jax.random.uniform(rng, (num_samples,) + t.shape[:-1] + (1,), dtype=jnp.float32) * eps\n  else:\n    jitter = jax.random.uniform(rng, (num_samples,) + t.shape[:-1] + (1,), dtype=jnp.float32) * eps\n\n  if deterministic_center:\n    samples = t_new + jitter - eps / 2\n  else:\n    samples = t_new + jitter\n\n  return samples"}
{"namespace": "stepfun.sample", "completion": "  if rng is None:\n    # Deterministic sampling\n    if deterministic_center:\n      # Centered sampling\n      u = jnp.linspace(0, 1, num_samples + 1)\n      u = 0.5 * (u[:-1] + u[1:])\n    else:\n      # Uniform sampling\n      u = jnp.linspace(0, 1, num_samples)\n  else:\n    # Random sampling\n    u = jax.random.uniform(rng, (num_samples,))\n    if single_jitter:\n      u = u + jax.random.uniform(rng, (num_samples,)) * (2 * eps) - eps\n    else:\n      u = u + jax.random.uniform(rng, (num_samples,)) * (2 * eps) - eps\n\n  # Invert the CDF to get the sampled values\n  samples = invert_cdf(u, t, w_logits)\n\n  return samples"}
{"namespace": "stepfun.sample", "completion": "  if rng is not None:\n    u = jax.random.uniform(rng, (num_samples,) + t.shape[:-1] + (1,), minval=eps, maxval=1.0 - eps)\n    t_new = invert_cdf(u, t, w_logits)\n  else:\n    t_new = linspline.linspace(t, num_samples, eps)\n\n  if single_jitter:\n    jitter = jax.random.uniform(rng, (num_samples,) + t.shape[:-1] + (1,), minval=-eps, maxval=eps)\n    t_new += jitter\n  elif rng is not None:\n    jitter = jax.random.uniform(rng, (num_samples,) + t.shape[:-1] + (1,), minval=-eps, maxval=eps)\n    t_new += jitter\n  else:\n    t_new += linspline.linspace(t, num_samples, -eps)\n\n  if deterministic_center:\n    t_mid = 0.5 * (t_new[..., :-1] + t_new[..., 1:])\n    return t_mid\n  else:\n    return t_new"}
{"namespace": "stepfun.sample", "completion": "  if rng is not None:\n    # Random sampling\n    u = jax.random.uniform(rng, shape=(num_samples,) + t.shape[:-1] + (1,))\n    if single_jitter:\n      # Add jitter to each sample independently\n      u = u + jax.random.uniform(rng, shape=(1,) + t.shape[:-1] + (num_samples,))\n    else:\n      # Add independent jitter to each sample\n      u = u + jax.random.uniform(rng, shape=(num_samples,) + t.shape[:-1] + (num_samples,))\n    u = jnp.clip(u, 0 + eps, 1 - eps)  # Avoid sampling at the edges\n  else:\n    # Deterministic sampling\n    if deterministic_center:\n      # Center the samples in each interval\n      u = jnp.linspace(0 + eps, 1 - eps, num_samples + 2)[1:-1]\n    else:\n      # Sample uniformly across the entire PDF\n      u = jnp.linspace(0 + eps, 1 - eps, num_samples)\n\n  # Invert the CDF to get the samples\n  samples = invert_cdf(u, t, w_logits)\n\n  return samples"}
{"namespace": "stepfun.sample", "completion": "  if rng is not None:\n    u = jax.random.uniform(rng, shape=(num_samples,) + t.shape[:-1] + (1,))\n  else:\n    u = jnp.linspace(0.5 / num_samples, 1 - 0.5 / num_samples, num_samples)\n    u = jnp.expand_dims(u, axis=-1)\n\n  t_new = invert_cdf(u, t, w_logits)\n\n  if single_jitter:\n    jitter = jax.random.uniform(rng, shape=(num_samples,) + t.shape[:-1] + (1,))\n  else:\n    jitter = jax.random.uniform(rng, shape=t_new.shape)\n\n  if deterministic_center:\n    t_diff = jnp.diff(t, axis=-1)\n    jitter = jitter * t_diff\n\n  return t_new + jitter * eps"}
{"namespace": "stepfun.sample", "completion": "  if rng is not None:\n    u = jax.random.uniform(rng, (num_samples,) + t.shape[:-1] + (1,), minval=eps, maxval=1.0 - eps)\n    t_samples = invert_cdf(u, t, w_logits)\n    if single_jitter:\n      jitter = jax.random.uniform(rng, (num_samples,) + t.shape[:-1] + (1,), minval=-0.5, maxval=0.5)\n      t_samples = t_samples + jitter * jnp.diff(t).reshape(t.shape[:-1] + (1,))\n    if deterministic_center:\n      t_samples = t_samples - 0.5 * jnp.diff(t).reshape(t.shape[:-1] + (1,))\n  else:\n    t_samples = linspline.linspace(t, num_samples, endpoint=False)\n\n  return t_samples"}
{"namespace": "stepfun.sample", "completion": "  if rng is not None:\n    u = jax.random.uniform(rng, shape=(num_samples,) + t.shape[:-1] + (1,), dtype=t.dtype)\n    t_new = invert_cdf(u, t, w_logits)\n  else:\n    if deterministic_center:\n      t_new = linspline.linspace(t[..., :-1], t[..., 1:], num_samples, endpoint=False)\n    else:\n      t_new = linspline.linspace(t[..., 0:1], t[..., -1:], num_samples, endpoint=True)\n\n  if single_jitter:\n    jitter = jax.random.uniform(rng, shape=(num_samples,) + t.shape[:-1] + (1,), dtype=t.dtype) * (t_new[..., 1:] - t_new[..., :-1])\n    t_new = t_new[..., :-1] + jitter\n\n  return t_new"}
{"namespace": "stepfun.sample", "completion": "  if rng is not None:\n    u = jax.random.uniform(rng, (num_samples,) + t.shape[:-1] + (1,), minval=eps, maxval=1.0 - eps)\n    t_samples = invert_cdf(u, t, w_logits)\n    if single_jitter:\n      t_samples += jax.random.uniform(rng, t_samples.shape, minval=-0.5, maxval=0.5)\n    else:\n      t_samples += jax.random.uniform(rng, t_samples.shape, minval=-0.5, maxval=0.5)\n  else:\n    if deterministic_center:\n      t_samples = linspline.linspace(t, num_samples)\n    else:\n      t_samples = linspline.linspace(t, num_samples, endpoint=False)\n\n  return t_samples"}
{"namespace": "stepfun.sample", "completion": "  if rng is None:\n    # Deterministic sampling based on linspace.\n    if deterministic_center:\n      # Centered sampling within each interval.\n      u = jnp.linspace(0, 1, num_samples + 1)[..., 1:-1]\n    else:\n      # Uniform sampling across the entire PDF.\n      u = jnp.linspace(0, 1, num_samples, endpoint=False)\n  else:\n    # Random sampling based on uniform distribution.\n    u = jax.random.uniform(rng, (num_samples,) + t.shape[:-1] + (1,), dtype=t.dtype)\n\n  # Invert the CDF to get the sampled values.\n  t_new = invert_cdf(u, t, w_logits)\n\n  if single_jitter:\n    # Apply single jitter to all samples.\n    t_new += (jnp.random.uniform(0, 1, (num_samples,) + t.shape[:-1] + (1,), dtype=t.dtype) - 0.5) * eps\n  else:\n    # Apply independent jitter to each sample.\n    t_new += (jax.random.uniform(rng, (num_samples,) + t.shape[:-1] + (1,), dtype=t.dtype) - 0.5) * eps\n\n  return t_new"}
{"namespace": "stepfun.sample_intervals", "completion": "  t_samples = sample(rng, t, w_logits, num_samples, single_jitter=single_jitter)\n\n  # Calculate midpoints between adjacent samples\n  t_mid = (t_samples[..., :-1] + t_samples[..., 1:]) / 2\n\n  # Adjust the first and last intervals to ensure they are within the specified domain\n  t_mid = jnp.clip(t_mid, domain[0], domain[1])\n\n  return t_mid"}
{"namespace": "stepfun.sample_intervals", "completion": "  t_samples = sample(rng, t, w_logits, num_samples, single_jitter=single_jitter)\n\n  # Calculate midpoints between adjacent samples\n  t_midpoints = (t_samples[..., :-1] + t_samples[..., 1:]) / 2\n\n  # Adjust the first and last intervals to fit within the specified domain\n  t_midpoints = jnp.clip(t_midpoints, domain[0], domain[1])\n\n  return t_midpoints"}
{"namespace": "stepfun.sample_intervals", "completion": "  t_samples = sample(rng, t, w_logits, num_samples, single_jitter)\n  t_midpoints = (t_samples[..., :-1] + t_samples[..., 1:]) / 2\n\n  # Adjust the first and last intervals to fit within the specified domain\n  t_midpoints = jnp.clip(t_midpoints, domain[0], domain[1])\n\n  return t_midpoints"}
{"namespace": "stepfun.sample_intervals", "completion": "  t_samples = sample(rng, t, w_logits, num_samples, single_jitter)\n  # Calculate midpoints between adjacent samples\n  midpoints = (t_samples[..., :-1] + t_samples[..., 1:]) / 2\n  # Adjust the first and last intervals to fit within the specified domain\n  midpoints = jnp.clip(midpoints, domain[0], domain[1])\n  return jnp.stack((midpoints[..., :-1], midpoints[..., 1:]), axis=-1)"}
{"namespace": "stepfun.sample_intervals", "completion": "  t_samples = sample(rng, t, w_logits, num_samples, single_jitter)\n  # Calculate midpoints between adjacent samples\n  interval_midpoints = (t_samples[..., :-1] + t_samples[..., 1:]) / 2\n  # Adjust the first and last intervals to fit within the specified domain\n  interval_midpoints = jnp.clip(interval_midpoints, domain[0], domain[1])\n  return interval_midpoints"}
{"namespace": "stepfun.sample_intervals", "completion": "  # Draw samples from the step function\n  samples = sample(rng, t, w_logits, num_samples, single_jitter)\n\n  # Calculate midpoints between adjacent samples\n  intervals = (samples[..., :-1] + samples[..., 1:]) / 2\n\n  # Adjust the first and last intervals to fit within the specified domain\n  intervals = jnp.clip(intervals, domain[0], domain[1])\n\n  return intervals"}
{"namespace": "stepfun.sample_intervals", "completion": "  samples = sample(rng, t, w_logits, num_samples, single_jitter)\n  midpoints = (samples[..., :-1] + samples[..., 1:]) / 2\n  midpoints = jnp.clip(midpoints, domain[0], domain[1])\n  first_interval = jnp.minimum(samples[..., 0], midpoints[..., 0])\n  last_interval = jnp.minimum(samples[..., -1], midpoints[..., -1])\n  return jnp.concatenate([jnp.expand_dims(first_interval, axis=-1), midpoints, jnp.expand_dims(last_interval, axis=-1)], axis=-1)"}
{"namespace": "stepfun.sample_intervals", "completion": "  t_samples = sample(rng, t, w_logits, num_samples, single_jitter=single_jitter)\n\n  # Calculate midpoints between adjacent samples\n  t_midpoints = (t_samples[..., :-1] + t_samples[..., 1:]) / 2\n\n  # Adjust the first and last intervals to fit within the specified domain\n  t_midpoints = jnp.clip(t_midpoints, domain[0], domain[1])\n\n  return t_midpoints"}
{"namespace": "stepfun.sample_intervals", "completion": "  t_samples = sample(rng, t, w_logits, num_samples, single_jitter=single_jitter)\n\n  # Calculate midpoints between adjacent samples\n  t_midpoints = (t_samples[..., :-1] + t_samples[..., 1:]) / 2\n\n  # Adjust the first and last intervals to fit within the specified domain\n  t_midpoints = jnp.clip(t_midpoints, domain[0], domain[1])\n\n  return t_midpoints"}
{"namespace": "stepfun.sample_intervals", "completion": "  t_samples = sample(rng, t, w_logits, num_samples, single_jitter=single_jitter)\n\n  # Calculate midpoints between adjacent samples\n  t_midpoints = (t_samples[..., :-1] + t_samples[..., 1:]) / 2\n\n  # Adjust the first and last intervals to fit within the specified domain\n  t_midpoints = jnp.clip(t_midpoints, domain[0], domain[1])\n\n  return t_midpoints"}
{"namespace": "stepfun.sample_intervals", "completion": "  # Draw samples from the step function\n  t_samples = sample(rng, t, w_logits, num_samples, single_jitter=single_jitter)\n\n  # Calculate midpoints between adjacent samples\n  t_midpoints = (t_samples[..., :-1] + t_samples[..., 1:]) / 2\n\n  # Adjust the first and last intervals to fit within the specified domain\n  t_midpoints = jnp.clip(t_midpoints, domain[0], domain[1])\n\n  return t_midpoints"}
{"namespace": "stepfun.sample_intervals", "completion": "  t_samples = sample(rng, t, w_logits, num_samples, single_jitter)\n  # Calculate midpoints between adjacent samples\n  interval_midpoints = (t_samples[..., :-1] + t_samples[..., 1:]) / 2\n  # Adjust the first and last intervals to fit within the specified domain\n  interval_midpoints = jnp.clip(interval_midpoints, domain[0], domain[1])\n  return interval_midpoints"}
{"namespace": "stepfun.sample_intervals", "completion": "  t_samples = sample(rng, t, w_logits, num_samples, single_jitter=single_jitter)\n\n  # Calculate midpoints between adjacent samples\n  midpoints = (t_samples[..., :-1] + t_samples[..., 1:]) / 2\n\n  # Adjust the first and last intervals to fit within the specified domain\n  midpoints = jnp.clip(midpoints, domain[0], domain[1])\n\n  return jnp.stack([midpoints[..., i] - midpoints[..., i-1] for i in range(1, num_samples)], axis=-1)"}
{"namespace": "stepfun.sample_intervals", "completion": "  t_samples = sample(rng, t, w_logits, num_samples, single_jitter=single_jitter)\n  midpoints = (t_samples[..., :-1] + t_samples[..., 1:]) / 2\n  midpoints = jnp.clip(midpoints, domain[0], domain[1])\n  return jnp.stack([midpoints[..., :-1], midpoints[..., 1:]], axis=-1)"}
{"namespace": "stepfun.sample_intervals", "completion": "  t_samples = sample(rng, t, w_logits, num_samples, single_jitter)\n  # Calculate midpoints between adjacent samples\n  interval_midpoints = (t_samples[..., :-1] + t_samples[..., 1:]) / 2\n  # Adjust the first and last intervals to fit within the specified domain\n  interval_midpoints = jnp.clip(interval_midpoints, domain[0], domain[1])\n  return interval_midpoints"}
{"namespace": "stepfun.sample_intervals", "completion": "  # Draw samples from the step function\n  samples = sample(rng, t, w_logits, num_samples, single_jitter)\n\n  # Calculate midpoints between adjacent samples\n  intervals = (samples[..., :-1] + samples[..., 1:]) / 2\n\n  # Adjust the first and last intervals to fit within the specified domain\n  intervals = jnp.clip(intervals, domain[0], domain[1])\n\n  return intervals"}
{"namespace": "stepfun.sample_intervals", "completion": "  t_samples = sample(rng, t, w_logits, num_samples, single_jitter)\n  # Calculate midpoints between adjacent samples\n  midpoints = (t_samples[..., :-1] + t_samples[..., 1:]) / 2\n  # Adjust the first and last intervals to ensure they are within the specified domain\n  midpoints = jnp.clip(midpoints, domain[0], domain[1])\n  return jnp.stack([midpoints[..., 0], midpoints[..., -1]], axis=-1)"}
{"namespace": "stepfun.sample_intervals", "completion": "  # Draw samples from the step function\n  samples = sample(rng, t, w_logits, num_samples, single_jitter)\n\n  # Calculate midpoints between adjacent samples\n  intervals = (samples[..., :-1] + samples[..., 1:]) / 2.0\n\n  # Adjust the first and last intervals to fit within the specified domain\n  intervals = jnp.clip(intervals, domain[0], domain[1])\n\n  return intervals"}
{"namespace": "stepfun.sample_intervals", "completion": "  # Draw samples from the step function\n  samples = sample(rng, t, w_logits, num_samples, single_jitter)\n\n  # Calculate midpoints between adjacent samples\n  midpoints = (samples[..., :-1] + samples[..., 1:]) / 2\n\n  # Adjust the first and last intervals to fit within the specified domain\n  midpoints = jnp.clip(midpoints, domain[0], domain[1])\n\n  return midpoints"}
{"namespace": "stepfun.sample_intervals", "completion": "  # Sample points from the step function\n  samples = sample(rng, t, w_logits, num_samples, single_jitter)\n\n  # Calculate midpoints between adjacent samples\n  midpoints = (samples[..., :-1] + samples[..., 1:]) / 2\n\n  # Adjust the first and last intervals to fit within the specified domain\n  midpoints = jnp.clip(midpoints, domain[0], domain[1])\n\n  return midpoints"}
{"namespace": "stepfun.weighted_percentile", "completion": "  # Ensure that the weights sum to 1\n  w_sum = jnp.sum(w, axis=-1)\n  if not jnp.allclose(w_sum, 1):\n    raise ValueError(\"Weights 'w' must sum to 1.\")\n\n  # Compute the integrated weights\n  cw = integrate_weights(w)\n\n  # Interpolate into the integrated weights to find the x-values corresponding to the percentiles\n  percentiles = linspline.interp(ps / 100, cw, t)\n\n  return percentiles"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  cw = integrate_weights(w)\n  return math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  cw = integrate_weights(w)\n  return math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Ensure that the weights sum to 1\n  w = jnp.clip(w, 0, 1)\n  w = w / jnp.sum(w, axis=-1, keepdims=True)\n\n  # Integrate the weights\n  cw = integrate_weights(w)\n\n  # Interpolate into the integrated weights to find the percentiles\n  percentiles = linspline.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n\n  return percentiles"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  cw = integrate_weights(w)\n  return math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  cw = integrate_weights(w)\n  return math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Ensure that the weights sum to 1\n  w_sum = jnp.sum(w, axis=-1)\n  if not jnp.allclose(w_sum, 1):\n    raise ValueError(\"Weights must sum to 1\")\n\n  # Compute the cumulative sum of the weights\n  cw = integrate_weights(w)\n\n  # Interpolate into the cumulative weights to find the x-values corresponding to the percentiles\n  t_percentiles = math.sorted_interp(ps / 100.0, cw, t, utils.device_is_tpu())\n\n  return t_percentiles"}
{"namespace": "stepfun.weighted_percentile", "completion": "  # Ensure that the weights sum to 1\n  w = jnp.asarray(w)\n  w = w / jnp.sum(w)\n\n  # Compute the cumulative sum of the weights\n  cw = integrate_weights(w)\n\n  # Interpolate into the inverse CDF to find the x-values corresponding to the percentiles\n  t_percentiles = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n\n  return t_percentiles"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  cw = integrate_weights(w)\n  return math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  cw = integrate_weights(w)\n  return math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())"}
{"namespace": "stepfun.weighted_percentile", "completion": "  # Ensure that the weights sum to 1\n  w = jnp.asarray(w)\n  w = w / jnp.sum(w)\n\n  # Compute the cumulative sum of the weights\n  cw = integrate_weights(w)\n\n  # Interpolate into the inverse CDF to find the x-values for the given percentiles\n  t_percentiles = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n\n  return t_percentiles"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Ensure that the weights sum to 1\n  w = jnp.clip(w, 0, 1)\n  w = w / jnp.sum(w)\n\n  # Integrate the weights\n  cw = integrate_weights(w)\n\n  # Interpolate into the integrated weights to find the percentiles\n  return math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  cw = integrate_weights(w)\n  return math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())"}
{"namespace": "stepfun.weighted_percentile", "completion": "  # Ensure that the weights sum to 1\n  w = jnp.asarray(w)\n  w = w / jnp.sum(w)\n\n  # Compute the cumulative sum of the weights\n  cw = integrate_weights(w)\n\n  # Interpolate into the integrated weights to find the x-values corresponding to the percentiles\n  t_percentiles = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n\n  return t_percentiles"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Ensure that the weights sum to 1\n  w = jnp.clip(w, 0, 1)\n  w = w / jnp.sum(w, axis=-1, keepdims=True)\n\n  # Integrate the weights\n  cw = integrate_weights(w)\n\n  # Interpolate into the integrated weights to find the percentiles\n  percentiles = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n\n  return percentiles"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  cw = integrate_weights(w)  # Compute the cumulative sum of the weights\n  return math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())  # Interpolate to find the x-values corresponding to the percentiles"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  cw = integrate_weights(w)\n  return math.sorted_interp(ps / 100.0, cw, t, utils.device_is_tpu())"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  cw = integrate_weights(w)\n  return math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  cw = integrate_weights(w)\n  return math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  cw = integrate_weights(w)\n  return math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to a probability density function (PDF)\n  p = weight_to_pdf(t, w)\n  \n  # Blur the PDF using a Gaussian filter\n  blurred_p = linspline.gaussian_filter1d(p, blur_halfwidth)\n  \n  # Resample the blurred PDF to match the new time points\n  resampled_w = pdf_to_weight(tq, resample(tq, t, blurred_p))\n  \n  return resampled_w"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to a probability density function (PDF)\n  p = weight_to_pdf(t, w)\n\n  # Blur the PDF using a Gaussian filter\n  blurred_p = linspline.gaussian_filter(p, blur_halfwidth)\n\n  # Resample the blurred PDF to match the new time points\n  resampled_w = pdf_to_weight(tq, blurred_p)\n\n  return resampled_w"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to PDF\n  p = weight_to_pdf(t, w)\n\n  # Blur the PDF\n  blurred_p = linspline.blur(p, blur_halfwidth)\n\n  # Resample the blurred PDF to match the new time points\n  resampled_w = pdf_to_weight(tq, resample(tq, t, blurred_p))\n\n  return resampled_w"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to a probability density function (PDF)\n  p = weight_to_pdf(t, w)\n\n  # Blur the PDF using a Gaussian filter\n  blurred_p = linspline.gaussian_filter(p, blur_halfwidth)\n\n  # Convert the blurred PDF back to weights\n  w_blurred = pdf_to_weight(t, blurred_p)\n\n  # Resample the blurred weights to match the new time points\n  w_resampled = resample(tq, t, w_blurred)\n\n  return w_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to a probability density function (PDF)\n  p = weight_to_pdf(t, w)\n  \n  # Blur the PDF using a Gaussian filter\n  blurred_p = linspline.gaussian_filter1d(p, blur_halfwidth)\n  \n  # Resample the blurred PDF to match the new time points\n  resampled_w = pdf_to_weight(tq, resample(tq, t, blurred_p))\n  \n  return resampled_w"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to a probability density function (PDF)\n  p = weight_to_pdf(t, w)\n\n  # Blur the PDF using a Gaussian filter\n  blurred_p = linspline.gaussian_filter1d(p, blur_halfwidth)\n\n  # Resample the blurred PDF to match the new time points\n  resampled_w = pdf_to_weight(tq, blurred_p)\n\n  return resampled_w"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to PDF\n  p = weight_to_pdf(t, w)\n\n  # Blur the PDF\n  blurred_p = linspline.blur(p, blur_halfwidth)\n\n  # Resample the blurred PDF\n  resampled_w = pdf_to_weight(tq, resample(tq, t, blurred_p))\n\n  return resampled_w"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to a probability density function (PDF)\n  p = weight_to_pdf(t, w)\n\n  # Blur the PDF using a Gaussian filter\n  blurred_p = linspline.gaussian_filter1d(p, blur_halfwidth)\n\n  # Resample the blurred PDF to match the new time points\n  resampled_w = pdf_to_weight(tq, resample(tq, t, blurred_p))\n\n  return resampled_w"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to PDF\n  p = weight_to_pdf(t, w)\n\n  # Blur the PDF\n  blurred_p = linspline.blur_1d(p, blur_halfwidth)\n\n  # Resample the blurred PDF to match the new time points\n  resampled_w = pdf_to_weight(tq, resample(tq, t, blurred_p))\n\n  return resampled_w"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to a probability density function (PDF)\n  p = weight_to_pdf(t, w)\n  \n  # Blur the PDF\n  blurred_p = linspline.blur(p, blur_halfwidth)\n  \n  # Convert the blurred PDF back to weights\n  blurred_w = pdf_to_weight(t, blurred_p)\n  \n  # Resample the blurred weights to match the new time points\n  resampled_w = resample(tq, t, blurred_w)\n  \n  return resampled_w"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to a probability density function (PDF)\n  p = weight_to_pdf(t, w)\n\n  # Blur the PDF using a Gaussian filter\n  blurred_p = linspline.gaussian_filter1d(p, blur_halfwidth)\n\n  # Resample the blurred PDF to match the new time points\n  resampled_w = pdf_to_weight(tq, blurred_p)\n\n  return resampled_w"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to PDF\n  p = weight_to_pdf(t, w)\n  \n  # Blur the PDF\n  blurred_p = linspline.blur(p, blur_halfwidth)\n  \n  # Resample the blurred PDF to match the new time points\n  resampled_w = pdf_to_weight(tq, resample(tq, t, blurred_p))\n  \n  return resampled_w"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to PDF\n  p = weight_to_pdf(t, w)\n\n  # Blur the PDF\n  blurred_p = linspline.blur(p, blur_halfwidth)\n\n  # Resample the blurred PDF to match the new time points\n  resampled_w = pdf_to_weight(tq, resample(tq, t, blurred_p))\n\n  return resampled_w"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to a probability density function (PDF)\n  p = weight_to_pdf(t, w)\n  \n  # Blur the PDF using a Gaussian kernel\n  blurred_p = linspline.gaussian_blur(p, blur_halfwidth)\n  \n  # Convert the blurred PDF back to weights\n  w_resampled = pdf_to_weight(tq, blurred_p)\n  \n  return w_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to a probability density function (PDF)\n  p = weight_to_pdf(t, w)\n  \n  # Blur the PDF\n  blurred_p = linspline.blur(p, blur_halfwidth)\n  \n  # Resample the blurred PDF to match the new time points\n  resampled_w = pdf_to_weight(tq, resample(tq, t, blurred_p))\n  \n  return resampled_w"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to PDF\n  p = weight_to_pdf(t, w)\n\n  # Blur the PDF\n  blurred_p = linspline.blur(p, blur_halfwidth)\n\n  # Convert blurred PDF back to weights\n  blurred_w = pdf_to_weight(t, blurred_p)\n\n  # Resample the weights based on the new query time points\n  resampled_w = resample(tq, t, blurred_w)\n\n  return resampled_w"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to a PDF\n  p = weight_to_pdf(t, w)\n  \n  # Blur the PDF\n  blurred_p = linspline.blur(p, blur_halfwidth)\n  \n  # Resample the blurred PDF to match the new time points\n  resampled_w = pdf_to_weight(tq, resample(tq, t, blurred_p))\n  \n  return resampled_w"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to a probability density function (PDF)\n  p = weight_to_pdf(t, w)\n\n  # Blur the PDF using a Gaussian filter\n  blurred_p = linspline.gaussian_filter1d(p, blur_halfwidth)\n\n  # Resample the blurred PDF to match the new time points\n  resampled_w = pdf_to_weight(tq, resample(tq, t, blurred_p))\n\n  return resampled_w"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to a probability density function (PDF)\n  p = weight_to_pdf(t, w)\n  \n  # Blur the PDF using a Gaussian filter\n  blurred_p = linspline.gaussian_filter1d(p, blur_halfwidth)\n\n  # Resample the blurred PDF to match the new time points\n  resampled_w = pdf_to_weight(tq, resample(tq, t, blurred_p))\n\n  return resampled_w"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to a probability density function (PDF)\n  p = weight_to_pdf(t, w)\n  \n  # Blur the PDF using a Gaussian filter\n  blurred_p = linspline.gaussian_filter1d(p, blur_halfwidth)\n  \n  # Convert the blurred PDF back to weights\n  w_resampled = pdf_to_weight(tq, blurred_p)\n  \n  return w_resampled"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "\n    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "\n    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "\n    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "\n    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "        if not model:\n            raise RequestError('must provide a model')\n\n        return await self._request_stream(\n            'POST',\n            '/api/generate',\n            json={\n                'model': model,\n                'prompt': prompt,\n                'system': system,\n                'template': template,\n                'context': context or [],\n                'stream': stream,\n                'raw': raw,\n                'images': [_encode_image(image) for image in images or []],\n                'format': format,\n                'options': options or {},\n                'keep_alive': keep_alive,\n            },\n            stream=stream,\n        )"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "\n    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "\n    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "\n    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "  if not model:\n    raise RequestError('must provide a model')\n\n  for message in messages or []:\n    if not isinstance(message, dict):\n      raise TypeError('messages must be a list of Message or dict-like objects')\n    if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n      raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n    if not message.get('content'):\n      raise RequestError('messages must contain content')\n    if images := message.get('images'):\n      message['images'] = [_encode_image(image) for image in images]\n\n  return await self._request_stream(\n    'POST',\n    '/api/chat',\n    json={\n      'model': model,\n      'messages': messages,\n      'stream': stream,\n      'format': format,\n      'options': options or {},\n      'keep_alive': keep_alive,\n    },\n    stream=stream,\n  )"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    async with aiofiles.open(path, 'rb') as r:\n      while True:\n        chunk = await r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      async with aiofiles.open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=await r.read())\n\n    return digest"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    async with aiofiles.open(path, 'rb') as r:\n      while True:\n        chunk = await r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      async with aiofiles.open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=await r.read())\n\n    return digest"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    async with aiofiles.open(path, 'rb') as r:\n      while True:\n        chunk = await r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      async with aiofiles.open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=await r.read())\n\n    return digest"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    async with aiofiles.open(path, 'rb') as r:\n      while True:\n        chunk = await r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      async with aiofiles.open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    async with aiofiles.open(path, 'rb') as r:\n      while True:\n        chunk = await r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      async with aiofiles.open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=await r.read())\n\n    return digest"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    async with aiofiles.open(path, 'rb') as f:\n        chunk = await f.read(32 * 1024)\n        while chunk:\n            sha256sum.update(chunk)\n            chunk = await f.read(32 * 1024)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n        await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n        if e.status_code != 404:\n            raise\n\n        async with aiofiles.open(path, 'rb') as r:\n            await self._request('POST', f'/api/blobs/{digest}', content=await r.read())\n\n    return digest"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    async with aiofiles.open(path, 'rb') as r:\n      while True:\n        chunk = await r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      async with aiofiles.open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=await r.read())\n\n    return digest"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    async with open(path, 'rb') as r:\n      async for chunk in r.iter_chunks(32 * 1024):\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      async with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    async with aiofiles.open(path, 'rb') as r:\n      while True:\n        chunk = await r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      async with aiofiles.open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=await r.read())\n\n    return digest"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    async with aiofiles.open(path, 'rb') as r:\n      while True:\n        chunk = await r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      async with aiofiles.open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=await r.read())\n\n    return digest"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    async with open(path, 'rb') as r:\n      while True:\n        chunk = await r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      async with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    async with open(path, 'rb') as r:\n      async for chunk in r.iter_chunks(32 * 1024):\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      async with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "\n    sha256sum = sha256()\n    async with aiofiles.open(path, 'rb') as r:\n      while True:\n        chunk = await r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      async with aiofiles.open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=await r.read())\n\n    return digest"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    async with aiofiles.open(path, 'rb') as r:\n      while True:\n        chunk = await r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      async with aiofiles.open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    async with aiofiles.open(path, 'rb') as r:\n      while True:\n        chunk = await r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      async with aiofiles.open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    async with aiofiles.open(path, 'rb') as file:\n        chunk = await file.read(32 * 1024)\n        while chunk:\n            sha256sum.update(chunk)\n            chunk = await file.read(32 * 1024)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n        await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n        if e.status_code != 404:\n            raise\n\n        async with aiofiles.open(path, 'rb') as file:\n            await self._request('POST', f'/api/blobs/{digest}', content=await file.read())\n\n    return digest"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    async with aiofiles.open(path, 'rb') as r:\n      while True:\n        chunk = await r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      async with aiofiles.open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=await r.read())\n\n    return digest"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        with tempfile.TemporaryDirectory() as tmpdir:\n            # Create a temporary file for the combined user code and test code\n            tmp_file_path = Path(tmpdir) / \"temp_code.py\"\n            with open(tmp_file_path, \"w\") as file:\n                file.write(user_code + \"\\n\" + test_code)\n\n            # Run Pyright to perform type checking\n            process = subprocess.run(\n                [\"pyright\", \"--outputjson\", str(tmp_file_path)],\n                capture_output=True,\n                text=True,\n            )\n\n            # Parse the output of Pyright\n            output = process.stdout\n            error_messages = []\n            for line in output.splitlines():\n                match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n                if match:\n                    line_number, error_message = match.groups()\n                    error_messages.append(f\"Line {line_number}: {error_message}\")\n\n            # Determine if the type check passed or failed\n            passed = len(error_messages) == 0\n            message = \"Type check passed\" if passed else \"Type check failed\"\n\n            # Create the TypeCheckResult object\n            return TypeCheckResult(message, passed, {\"error_messages\": error_messages})"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        result = subprocess.run(\n            [\"npx\", \"pyright\", \"--outputjson\", \"-\"],\n            input=(user_code + test_code).encode(\"utf-8\"),\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            check=False,\n        )\n\n        if result.returncode != 0:\n            error_lines = []\n            for line in result.stderr.decode(\"utf-8\").split(\"\\n\"):\n                match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n                if match:\n                    error_lines.append(int(match.group(1)))\n\n            if any(cls.EXPECT_ERROR_COMMENT in line for line in user_code.split(\"\\n\")):\n                passed = bool(error_lines)\n                message = \"Type check failed as expected.\"\n            else:\n                passed = False\n                message = \"Type check failed.\"\n\n            return TypeCheckResult(message, passed, {\"error_lines\": error_lines})\n        else:\n            return TypeCheckResult(\"Type check passed.\", True)"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create temporary files to write the user code and test code\n        with tempfile.TemporaryDirectory() as tmp_dir:\n            user_code_file = Path(tmp_dir) / \"user_code.py\"\n            test_code_file = Path(tmp_dir) / \"test_code.py\"\n            \n            # Write user code and test code to temporary files\n            user_code_file.write_text(user_code, encoding=\"utf-8\")\n            test_code_file.write_text(test_code, encoding=\"utf-8\")\n            \n            # Run Pyright to perform type checking\n            pyright_output = subprocess.run(\n                [\"npx\", \"pyright\", \"--outputjson\", str(user_code_file), str(test_code_file)],\n                capture_output=True,\n                text=True\n            )\n            \n            # Parse Pyright output to identify type errors\n            error_messages = []\n            for line in pyright_output.stdout.splitlines():\n                match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n                if match:\n                    line_no, error_message = match.groups()\n                    error_messages.append(f\"Line {line_no}: {error_message}\")\n            \n            # Determine if the type check passed or failed based on error messages\n            passed = len(error_messages) == 0\n            if passed:\n                message = \"Type check passed. No type errors found.\"\n            else:\n                message = \"Type check failed. Type errors found:\\n\" + \"\\n\".join(error_messages)\n            \n            # Return the type check result\n            return TypeCheckResult(message, passed)"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create temporary files for user code and test code\n        with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\") as user_file, tempfile.NamedTemporaryFile(\n            mode=\"w\", suffix=\".py\"\n        ) as test_file:\n            user_file.write(user_code)\n            test_file.write(test_code)\n            user_file.seek(0)\n            test_file.seek(0)\n\n            # Run Pyright to perform type checking\n            process = subprocess.run(\n                [\"npx\", \"pyright\", \"--outputjson\", user_file.name, test_file.name],\n                capture_output=True,\n                text=True,\n            )\n\n            # Parse the output from Pyright\n            output = process.stdout\n            error_messages = []\n            passed = True\n            for line in output.splitlines():\n                match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n                if match:\n                    line_no, error_message = match.groups()\n                    error_messages.append(f\"Line {line_no}: {error_message}\")\n                    passed = False\n\n            # Return the result of the type check\n            return TypeCheckResult(\n                message=\"\\n\".join(error_messages) if error_messages else \"Type check passed\",\n                passed=passed,\n                debug_info={\"pyright_output\": output},\n            )"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create temporary files to store user code and test code\n        with tempfile.NamedTemporaryFile(mode=\"w\", delete=False) as user_file, tempfile.NamedTemporaryFile(mode=\"w\", delete=False) as test_file:\n            user_file.write(user_code)\n            test_file.write(test_code)\n\n        # Run Pyright to perform type checking\n        pyright_output = subprocess.check_output([\"pyright\", user_file.name, test_file.name], text=True)\n\n        # Parse Pyright output to identify type errors\n        type_errors = []\n        for line in pyright_output.splitlines():\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                line_no, error_message = match.groups()\n                type_errors.append((int(line_no), error_message))\n\n        # Check if there are any type errors\n        if type_errors:\n            message = \"Type check failed. Errors found in the following lines:\"\n            debug_info = {\"type_errors\": type_errors}\n            passed = False\n        else:\n            message = \"Type check passed. No errors found.\"\n            debug_info = {}\n            passed = True\n\n        # Return the type check result\n        return TypeCheckResult(message, passed, debug_info)"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        result = subprocess.run(\n            [\"pyright\", \"--outputjson\"],\n            input=(user_code + test_code).encode(),\n            capture_output=True,\n            text=True,\n        )\n        if result.returncode != 0:\n            return TypeCheckResult(\n                message=\"Type check failed. Pyright command returned a non-zero exit code.\",\n                passed=False,\n            )\n\n        pyright_output = result.stdout\n        error_lines = []\n        for line in pyright_output.splitlines():\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                error_lines.append(int(match.group(1)))\n\n        if error_lines:\n            return TypeCheckResult(\n                message=\"Type check failed. Expected type errors found on lines: {}\".format(\n                    \", \".join(map(str, error_lines))\n                ),\n                passed=False,\n            )\n        else:\n            return TypeCheckResult(\n                message=\"Type check passed. No type errors found.\",\n                passed=True,\n            )"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Use a temporary file to store the combined code\n        with tempfile.NamedTemporaryFile(mode=\"w\", delete=False) as temp_file:\n            temp_file.write(user_code + test_code)\n\n        # Run Pyright to perform type checking\n        process = subprocess.Popen(\n            [\"pyright\", \"--outputjson\", temp_file.name],\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True,\n        )\n        stdout, stderr = process.communicate()\n\n        # Parse the output of Pyright to identify type errors\n        type_errors = []\n        for line in stderr.split(\"\\n\"):\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                line_no, error_message = match.groups()\n                type_errors.append((int(line_no), error_message))\n\n        # Check if any type errors were found\n        if type_errors:\n            message = \"Type check failed. Errors found in the following lines:\\n\"\n            for line_no, error_message in type_errors:\n                message += f\"Line {line_no}: {error_message}\\n\"\n            passed = False\n        else:\n            message = \"Type check passed. No errors found.\"\n            passed = True\n\n        # Return the type check result\n        return TypeCheckResult(message, passed)"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        process = subprocess.run(\n            [\"pyright\", \"--outputjson\", \"--useLibraryCodeForTypes\", \"-\"],\n            input=(user_code + \"\\n\" + test_code).encode(),\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True,\n        )\n\n        if process.returncode != 0:\n            return TypeCheckResult(\n                message=\"Type check failed\",\n                passed=False,\n                debug_info={\"error_output\": process.stderr},\n            )\n\n        error_lines = []\n        for line in process.stdout.split(\"\\n\"):\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                error_lines.append(int(match.group(1)))\n\n        if any(\n            cls.EXPECT_ERROR_COMMENT in line for line in (user_code + test_code).split(\"\\n\")\n        ):\n            if not error_lines:\n                return TypeCheckResult(\n                    message=\"Expected type error not found\",\n                    passed=False,\n                    debug_info={\"error_output\": process.stdout},\n                )\n\n        return TypeCheckResult(\n            message=\"Type check passed\",\n            passed=True,\n            debug_info={\"error_lines\": error_lines},\n        )"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create a temporary file to hold the combined user code and test code\n        with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as temp_file:\n            temp_file.write(user_code + test_code)\n\n        # Run Pyright to perform the type check\n        pyright_cmd = f\"pyright {temp_file.name}\"\n        result = subprocess.run(pyright_cmd, shell=True, capture_output=True, text=True)\n\n        # Parse the Pyright output to identify type errors\n        error_lines = []\n        for line in result.stderr.splitlines():\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                error_lines.append(int(match.group(1)))\n\n        # Determine if the type check passed or failed based on the presence of type errors\n        passed = len(error_lines) == 0\n        message = \"Type check passed\" if passed else \"Type check failed\"\n\n        # Construct the TypeCheckResult object with the outcome and error message\n        type_check_result = TypeCheckResult(message, passed)\n\n        # Add debug info with error line numbers if type check failed\n        if not passed:\n            type_check_result.debug_info[\"error_lines\"] = error_lines\n\n        # Delete the temporary file\n        Path(temp_file.name).unlink()\n\n        return type_check_result"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create temporary files to store user code and test code\n        with tempfile.TemporaryDirectory() as tmp_dir:\n            user_code_path = Path(tmp_dir) / \"user_code.py\"\n            test_code_path = Path(tmp_dir) / \"test_code.py\"\n            user_code_path.write_text(user_code, encoding=\"utf-8\")\n            test_code_path.write_text(test_code, encoding=\"utf-8\")\n\n            # Run Pyright type check using subprocess\n            pyright_output = subprocess.run(\n                [\"npx\", \"pyright\", \"--outputjson\", str(user_code_path), str(test_code_path)],\n                capture_output=True,\n                text=True,\n            )\n\n            # Parse Pyright output to identify type errors\n            error_messages = []\n            for line in pyright_output.stdout.splitlines():\n                match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n                if match:\n                    line_no, error_message = match.groups()\n                    error_messages.append(f\"Line {line_no}: {error_message}\")\n\n            # Determine if the type check passed or failed\n            passed = not bool(error_messages)\n\n            # Prepare the result object\n            result = TypeCheckResult(\n                message=\"Type check passed\" if passed else \"Type check failed\",\n                passed=passed,\n                debug_info={\"pyright_output\": pyright_output.stdout, \"error_messages\": error_messages},\n            )\n\n        return result"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create temporary files to store the user code and test code\n        with tempfile.NamedTemporaryFile(mode=\"w\", delete=False) as user_file, tempfile.NamedTemporaryFile(\n            mode=\"w\", delete=False\n        ) as test_file:\n            user_file.write(user_code)\n            test_file.write(test_code)\n\n        # Run Pyright type check using subprocess\n        pyright_output = subprocess.run(\n            [\n                \"pyright\",\n                \"--outputjson\",\n                \"--useLibraryCodeForTypes\",\n                user_file.name,\n                test_file.name,\n            ],\n            capture_output=True,\n            text=True,\n        )\n\n        # Parse Pyright output to identify type errors\n        type_errors = []\n        for line in pyright_output.stdout.splitlines():\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                line_no, error_message = match.groups()\n                type_errors.append((int(line_no), error_message))\n\n        # Delete temporary files\n        Path(user_file.name).unlink()\n        Path(test_file.name).unlink()\n\n        # Determine if the type check passed or failed\n        passed = len(type_errors) == 0\n        if passed:\n            message = \"Type check passed. No type errors found.\"\n        else:\n            message = f\"Type check failed. {len(type_errors)} type error(s) found.\"\n\n        return TypeCheckResult(message, passed, {\"type_errors\": type_errors})"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create a temporary file to write the combined user code and test code\n        with tempfile.NamedTemporaryFile(mode=\"w\", delete=False) as temp_file:\n            temp_file.write(user_code + test_code)\n\n        # Run Pyright to perform type checking on the temporary file\n        process = subprocess.run(\n            [\"npx\", \"pyright\", \"--outputjson\", temp_file.name],\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True,\n        )\n\n        # Parse the output of Pyright to identify type errors\n        error_lines = []\n        for line in process.stderr.splitlines():\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                error_lines.append((int(match.group(1)), match.group(2)))\n\n        # Delete the temporary file\n        temp_file.unlink()\n\n        # Determine if the type check passed or failed based on the presence of type errors\n        passed = len(error_lines) == 0\n\n        # Create a TypeCheckResult object with the outcome of the type check\n        result = TypeCheckResult(\n            message=\"Type check passed\" if passed else \"Type check failed\",\n            passed=passed,\n            debug_info={\"error_lines\": error_lines},\n        )\n\n        return result"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        result = subprocess.run(\n            [\"npx\", \"pyright\", \"--outputjson\"],\n            input=(user_code + test_code).encode(\"utf-8\"),\n            capture_output=True,\n            text=True,\n        )\n\n        if result.returncode != 0:\n            return TypeCheckResult(\n                message=\"Type check failed. Pyright returned a non-zero exit code.\",\n                passed=False,\n                debug_info={\"stdout\": result.stdout, \"stderr\": result.stderr},\n            )\n\n        errors = []\n        for line in result.stdout.splitlines():\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                line_no, error_message = match.groups()\n                errors.append(f\"Line {line_no}: {error_message}\")\n\n        if errors:\n            return TypeCheckResult(\n                message=\"Type check failed. Type errors found.\",\n                passed=False,\n                debug_info={\"errors\": errors},\n            )\n        else:\n            return TypeCheckResult(\n                message=\"Type check passed. No type errors found.\",\n                passed=True,\n            )"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create temporary files to store user code and test code\n        with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as user_file, \\\n             tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as test_file:\n\n            # Write user code and test code to the temporary files\n            user_file.write(user_code)\n            test_file.write(test_code)\n\n            # Close the files to ensure the data is written\n            user_file.close()\n            test_file.close()\n\n            # Run Pyright to perform type checking\n            process = subprocess.Popen(\n                [\"pyright\", \"--outputjson\", user_file.name, test_file.name],\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE,\n                text=True\n            )\n            stdout, stderr = process.communicate()\n\n            # Parse the output to identify type errors\n            type_errors = []\n            for line in stderr.splitlines():\n                match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n                if match:\n                    line_no, error_message = match.groups()\n                    type_errors.append((int(line_no), error_message))\n\n            # Delete the temporary files\n            Path(user_file.name).unlink()\n            Path(test_file.name).unlink()\n\n            # Check if there are any type errors\n            if type_errors:\n                message = f\"Type check failed with {len(type_errors)} error(s).\"\n                debug_info = {\"type_errors\": type_errors}\n                return TypeCheckResult(message, False, debug_info)\n            else:\n                return TypeCheckResult(\"Type check passed with no errors.\", True)"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create a temporary file to write the combined user code and test code\n        with tempfile.NamedTemporaryFile(mode=\"w\", delete=False) as temp_file:\n            temp_file.write(user_code + test_code)\n\n        # Run Pyright to perform type checking on the temporary file\n        result = subprocess.run(\n            [\"pyright\", \"--outputjson\", temp_file.name],\n            capture_output=True,\n            text=True\n        )\n\n        # Parse the output of Pyright to identify type errors\n        error_lines = []\n        for line in result.stdout.splitlines():\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                error_lines.append(int(match.group(1)))\n\n        # Determine if the type check passed or failed based on the presence of type errors\n        passed = len(error_lines) == 0\n        message = \"Type check passed\" if passed else \"Type check failed\"\n        debug_info = {\"error_lines\": error_lines}\n\n        # Return the TypeCheckResult object with the type check outcome\n        return TypeCheckResult(message, passed, debug_info)"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "\n        # Perform type check using Pyright\n        pyright_output = subprocess.run(\n            [\"npx\", \"pyright\", \"--outputjson\", \"-\"],\n            input=(user_code + test_code).encode(\"utf-8\"),\n            capture_output=True,\n            text=True,\n        )\n\n        # Process Pyright output to identify errors\n        error_lines = []\n        for line in pyright_output.stdout.split(\"\\n\"):\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                error_lines.append((int(match.group(1)), match.group(2)))\n\n        # Check if there are any errors\n        if error_lines:\n            message = \"Type check failed. Errors found in the code.\"\n            passed = False\n            debug_info = {\"error_lines\": error_lines}\n        else:\n            message = \"Type check passed. No errors found in the code.\"\n            passed = True\n            debug_info = {}\n\n        return TypeCheckResult(message, passed, debug_info)"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create temporary files to store the user code and test code\n        with tempfile.TemporaryDirectory() as tmp_dir:\n            user_code_file = Path(tmp_dir) / \"user_code.py\"\n            test_code_file = Path(tmp_dir) / \"test_code.py\"\n\n            # Write the user code and test code to the temporary files\n            user_code_file.write_text(user_code, encoding=\"utf-8\")\n            test_code_file.write_text(test_code, encoding=\"utf-8\")\n\n            # Run Pyright to perform type checking\n            result = subprocess.run(\n                [\"pyright\", \"--outputjson\", str(user_code_file), str(test_code_file)],\n                capture_output=True,\n                text=True,\n            )\n\n            # Parse the Pyright output to identify type errors\n            error_messages = []\n            for line in result.stdout.splitlines():\n                match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n                if match:\n                    line_no, error_message = match.groups()\n                    error_messages.append(f\"Line {line_no}: {error_message}\")\n\n            # Determine if the type check passed or failed\n            passed = len(error_messages) == 0\n            message = \"Type check passed\" if passed else \"Type check failed\"\n\n            # Create the TypeCheckResult object\n            return TypeCheckResult(message, passed, {\"error_messages\": error_messages})"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        result = subprocess.run(\n            [\"npx\", \"pyright\", \"--outputjson\", \"--useLibraryCodeForTypes\", \"-\"],\n            input=(user_code + test_code).encode(\"utf-8\"),\n            capture_output=True,\n            text=True,\n        )\n\n        if result.returncode != 0:\n            return TypeCheckResult(\n                message=\"Type check failed. Please check your code for type errors.\",\n                passed=False,\n                debug_info={\"error_output\": result.stderr},\n            )\n\n        errors = []\n        for line in result.stdout.split(\"\\n\"):\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                line_no, error_message = match.groups()\n                errors.append(f\"Line {line_no}: {error_message}\")\n\n        if errors:\n            return TypeCheckResult(\n                message=\"Type check failed. Please check your code for type errors.\",\n                passed=False,\n                debug_info={\"type_errors\": errors},\n            )\n        else:\n            return TypeCheckResult(\n                message=\"Type check passed. No type errors found.\",\n                passed=True,\n            )"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        result = subprocess.run(\n            [\"pyright\", \"--outputjson\", \"-\"],\n            input=(user_code + test_code).encode(\"utf-8\"),\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            check=False,\n        )\n\n        if result.returncode == 0:\n            return TypeCheckResult(\"Type check passed\", True)\n        else:\n            error_messages = []\n            for line in result.stderr.decode(\"utf-8\").split(\"\\n\"):\n                match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n                if match:\n                    error_messages.append(match.group(1))\n\n            debug_info = {\"error_lines\": error_messages}\n            return TypeCheckResult(\"Type check failed\", False, debug_info)"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "\n        # Create temporary files for user code and test code\n        with tempfile.NamedTemporaryFile(mode=\"w\", delete=False) as user_file, tempfile.NamedTemporaryFile(mode=\"w\", delete=False) as test_file:\n            user_file.write(user_code)\n            test_file.write(test_code)\n\n        # Run Pyright to perform type checking\n        try:\n            process = subprocess.run(\n                [\"pyright\", \"--outputjson\", user_file.name, test_file.name],\n                capture_output=True,\n                text=True,\n                check=True,\n            )\n            output = process.stdout\n        except subprocess.CalledProcessError as e:\n            return TypeCheckResult(\n                message=f\"Type check failed: {e.stderr}\",\n                passed=False,\n                debug_info={\"error_output\": e.stderr},\n            )\n\n        # Parse the output to identify type errors\n        error_lines = []\n        for line in output.splitlines():\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                error_lines.append(int(match.group(1)))\n\n        # If there are no error lines, type check passed\n        if not error_lines:\n            return TypeCheckResult(\n                message=\"Type check passed\",\n                passed=True,\n            )\n        else:\n            return TypeCheckResult(\n                message=\"Type check failed\",\n                passed=False,\n                debug_info={\"error_lines\": error_lines},\n            )"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "\n    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            return aot_module(fn, get_compiler_fn(\"AOT Module Compilation\"))\n    else:\n        with no_fake_tensor():\n            return aot_function(fn, get_compiler_fn(\"AOT Function Compilation\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            compiled_fn = aot_module(fn, get_compiler_fn())\n    else:\n        with no_fake_tensor():\n            compiled_fn = aot_function(fn, get_compiler_fn())\n\n    return compiled_fn"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            return aot_module(fn, get_compiler_fn())\n    else:\n        with no_fake_tensor():\n            return aot_function(fn, get_compiler_fn())"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            compiled_module = aot_module(fn, get_compiler_fn(\"Forward Graph\"), get_compiler_fn(\"Backward Graph\"))\n        return compiled_module\n    else:\n        with no_fake_tensor():\n            compiled_function = aot_function(fn, get_compiler_fn(\"Forward Graph\"), get_compiler_fn(\"Backward Graph\"))\n        return compiled_function"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "\n    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            return aot_module(fn, get_compiler_fn(\"Compiled AOT Module\"))\n    else:\n        with no_fake_tensor():\n            return aot_function(fn, get_compiler_fn(\"Compiled AOT Function\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            compiled_module = aot_module(fn, get_compiler_fn(\"Forward Graph\"), get_compiler_fn(\"Backward Graph\"))\n        return compiled_module\n    else:\n        with no_fake_tensor():\n            compiled_function = aot_function(fn, get_compiler_fn(\"Forward Graph\"), get_compiler_fn(\"Backward Graph\"))\n        return compiled_function"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "\n    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            return aot_module(fn, get_compiler_fn())\n    else:\n        return aot_function(fn, get_compiler_fn())"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            compiled_module = aot_module(fn, get_compiler_fn(\"Forward Graph\"), get_compiler_fn(\"Backward Graph\"))\n        return compiled_module\n    else:\n        with no_fake_tensor():\n            compiled_function = aot_function(fn, get_compiler_fn(\"Forward Graph\"), get_compiler_fn(\"Backward Graph\"))\n        return compiled_function"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "\n    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            compiled_fn = aot_module(fn, get_compiler_fn(\"Forward Graph\"), get_compiler_fn(\"Backward Graph\"))\n    else:\n        with no_fake_tensor():\n            compiled_fn = aot_function(fn, get_compiler_fn(\"Forward Graph\"), get_compiler_fn(\"Backward Graph\"))\n\n    return compiled_fn"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "\n    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            compiled_fn = aot_module(fn, get_compiler_fn())\n    else:\n        with no_fake_tensor():\n            compiled_fn = aot_function(fn, get_compiler_fn())\n    \n    return compiled_fn"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            compiled_module = aot_module(fn, get_compiler_fn(\"Forward Graph\"))\n            compiled_module = aot_module(compiled_module, get_compiler_fn(\"Backward Graph\"))\n            return compiled_module\n    else:\n        with no_fake_tensor():\n            compiled_fn = aot_function(fn, get_compiler_fn(\"Forward Graph\"))\n            compiled_fn = aot_function(compiled_fn, get_compiler_fn(\"Backward Graph\"))\n            return compiled_fn"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            compiled_module = aot_module(fn, get_compiler_fn(\"Forward Graph\"), get_compiler_fn(\"Backward Graph\"))\n        return compiled_module\n    else:\n        with no_fake_tensor():\n            compiled_function = aot_function(fn, get_compiler_fn(\"Forward Graph\"), get_compiler_fn(\"Backward Graph\"))\n        return compiled_function"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            compiled_fn = aot_module(fn, get_compiler_fn(\"Forward Graph\"), get_compiler_fn(\"Backward Graph\"))\n    else:\n        with no_fake_tensor():\n            compiled_fn = aot_function(fn, get_compiler_fn(\"Forward Graph\"), get_compiler_fn(\"Backward Graph\"))\n\n    return compiled_fn"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            compiled_module = aot_module(fn, get_compiler_fn(\"Forward Graph\"), get_compiler_fn(\"Backward Graph\"))\n        return compiled_module\n    else:\n        with no_fake_tensor():\n            compiled_function = aot_function(fn, get_compiler_fn(\"Forward Graph\"), get_compiler_fn(\"Backward Graph\"))\n        return compiled_function"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "\n    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            return aot_module(fn, get_compiler_fn(\"AOT Module Compilation\"))\n    else:\n        with no_fake_tensor():\n            return aot_function(fn, get_compiler_fn(\"AOT Function Compilation\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            compiled_fn = aot_module(fn, get_compiler_fn(\"Forward Graph\"), get_compiler_fn(\"Backward Graph\"))\n    else:\n        with no_fake_tensor():\n            compiled_fn = aot_function(fn, get_compiler_fn(\"Forward Graph\"), get_compiler_fn(\"Backward Graph\"))\n    \n    return compiled_fn"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "\n    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            compiled_fn = aot_module(fn, get_compiler_fn(\"Forward and Backward Compiler for Module\"))\n    else:\n        with no_fake_tensor():\n            compiled_fn = aot_function(fn, get_compiler_fn(\"Forward and Backward Compiler for Function\"))\n\n    return compiled_fn"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            compiled_fn = aot_module(fn, get_compiler_fn())\n    else:\n        with no_fake_tensor():\n            compiled_fn = aot_function(fn, get_compiler_fn())\n\n    return compiled_fn"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            return aot_module(fn, get_compiler_fn(\"Forward Graph\"), get_compiler_fn(\"Backward Graph\"))\n    else:\n        return aot_function(fn, get_compiler_fn(\"Forward Graph\"), get_compiler_fn(\"Backward Graph\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            compiled_module = aot_module(fn, get_compiler_fn(\"Forward Graph\"), get_compiler_fn(\"Backward Graph\"))\n        return compiled_module\n    else:\n        with no_fake_tensor():\n            compiled_function = aot_function(fn, get_compiler_fn(\"Forward Graph\"), get_compiler_fn(\"Backward Graph\"))\n        return compiled_function"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_path = os.path.join(trial_path, 'summary.csv')\n    config_path = os.path.join(trial_path, 'config.yaml')\n\n    if not os.path.exists(summary_path):\n        raise FileNotFoundError(f\"Summary file not found in {trial_path}\")\n\n    if not os.path.exists(config_path):\n        raise FileNotFoundError(f\"Config file not found in {trial_path}\")\n\n    summary_df = load_summary_file(summary_path)\n    with open(config_path, 'r') as file:\n        config_dict = yaml.safe_load(file)\n\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        if not output_path.endswith('.yaml') and not output_path.endswith('.yml'):\n            raise ValueError(\"Output file extension must be .yaml or .yml\")\n        with open(output_path, 'w') as file:\n            yaml.dump(best_config, file)\n\n    return best_config"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_file = os.path.join(trial_path, 'summary.csv')\n    config_file = os.path.join(trial_path, 'config.yaml')\n\n    try:\n        summary_df = load_summary_file(summary_file)\n        with open(config_file, 'r') as file:\n            config_dict = yaml.safe_load(file)\n    except FileNotFoundError as e:\n        logger.error(f\"File not found: {e.filename}\")\n        return {}\n\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        if output_path.endswith('.yaml') or output_path.endswith('.yml'):\n            with open(output_path, 'w') as file:\n                yaml.dump(best_config, file, default_flow_style=False)\n        else:\n            logger.error(\"Output file must have .yaml or .yml extension\")\n            return {}\n\n    return best_config"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    # Load config yaml\n    config_path = os.path.join(trial_path, 'config.yaml')\n    with open(config_path, 'r') as file:\n        config_dict = yaml.safe_load(file)\n\n    # Load summary csv\n    summary_path = os.path.join(trial_path, 'summary.csv')\n    summary_df = load_summary_file(summary_path)\n\n    # Convert summary dataframe to config yaml\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    # Save to YAML file if output_path is provided\n    if output_path:\n        if output_path.endswith('.yaml') or output_path.endswith('.yml'):\n            with open(output_path, 'w') as file:\n                yaml.dump(best_config, file, default_flow_style=False)\n        else:\n            logger.warning(\"Output path file extension must be .yaml or .yml\")\n\n    return best_config"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_file = os.path.join(trial_path, \"summary.csv\")\n    config_file = os.path.join(trial_path, \"config.yaml\")\n\n    summary_df = load_summary_file(summary_file)\n    with open(config_file, 'r') as file:\n        config_dict = yaml.safe_load(file)\n\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        if output_path.endswith(\".yaml\") or output_path.endswith(\".yml\"):\n            with open(output_path, 'w') as file:\n                yaml.dump(best_config, file, default_flow_style=False)\n        else:\n            logger.warning(\"Output file must have a .yaml or .yml extension. Configuration not saved.\")\n\n    return best_config"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    # Load the configuration file\n    config_file = os.path.join(trial_path, \"config.yaml\")\n    with open(config_file, \"r\") as file:\n        config_dict = yaml.safe_load(file)\n\n    # Load the summary file\n    summary_file = os.path.join(trial_path, \"summary.csv\")\n    summary_df = load_summary_file(summary_file)\n\n    # Convert summary dataframe to config yaml file\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    # Save the configuration to a YAML file if output_path is provided\n    if output_path:\n        if output_path.endswith(('.yaml', '.yml')):\n            with open(output_path, \"w\") as file:\n                yaml.dump(best_config, file, default_flow_style=False)\n        else:\n            logger.warning(\"Output file extension must be .yaml or .yml\")\n\n    return best_config"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_file_path = os.path.join(trial_path, \"summary.csv\")\n    config_file_path = os.path.join(trial_path, \"config.yaml\")\n\n    summary_df = load_summary_file(summary_file_path)\n    with open(config_file_path, \"r\") as file:\n        config_dict = yaml.safe_load(file)\n\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        if not output_path.endswith(('.yaml', '.yml')):\n            raise ValueError(\"Output file path must have .yaml or .yml extension\")\n        with open(output_path, \"w\") as file:\n            yaml.dump(best_config, file)\n\n    return best_config"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_file = os.path.join(trial_path, 'summary.csv')\n    config_file = os.path.join(trial_path, 'config.yaml')\n\n    summary_df = load_summary_file(summary_file)\n    with open(config_file, 'r') as f:\n        config_dict = yaml.safe_load(f)\n\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        if output_path.endswith('.yaml') or output_path.endswith('.yml'):\n            with open(output_path, 'w') as file:\n                yaml.dump(best_config, file, default_flow_style=False)\n        else:\n            logger.warning(\"Output path must have a .yaml or .yml extension. Configuration not saved.\")\n\n    return best_config"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    config_path = os.path.join(trial_path, 'config.yaml')\n    summary_path = os.path.join(trial_path, 'summary.csv')\n\n    with open(config_path, 'r') as file:\n        config_dict = yaml.safe_load(file)\n\n    summary_df = load_summary_file(summary_path)\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        if output_path.endswith('.yaml') or output_path.endswith('.yml'):\n            with open(output_path, 'w') as file:\n                yaml.dump(best_config, file, default_flow_style=False)\n        else:\n            logger.warning(\"Output path file extension must be .yaml or .yml\")\n\n    return best_config"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_file = os.path.join(trial_path, \"summary.csv\")\n    config_file = os.path.join(trial_path, \"config.yaml\")\n\n    summary_df = load_summary_file(summary_file)\n    with open(config_file, \"r\") as f:\n        config_dict = yaml.safe_load(f)\n\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        if output_path.endswith(\".yaml\") or output_path.endswith(\".yml\"):\n            with open(output_path, \"w\") as f:\n                yaml.safe_dump(best_config, f)\n        else:\n            logger.warning(\"Output file format not supported. Please provide a .yaml or .yml file extension.\")\n\n    return best_config"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_file = os.path.join(trial_path, \"summary.csv\")\n    config_file = os.path.join(trial_path, \"config.yaml\")\n\n    summary_df = load_summary_file(summary_file)\n    with open(config_file, 'r') as file:\n        config_dict = yaml.safe_load(file)\n\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        if output_path.endswith('.yaml') or output_path.endswith('.yml'):\n            with open(output_path, 'w') as file:\n                yaml.dump(best_config, file)\n        else:\n            logger.warning(\"Output file must have .yaml or .yml extension. Configuration not saved.\")\n\n    return best_config"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_file = os.path.join(trial_path, \"summary.csv\")\n    config_file = os.path.join(trial_path, \"config.yaml\")\n\n    summary_df = load_summary_file(summary_file)\n    with open(config_file, 'r') as file:\n        config_dict = yaml.safe_load(file)\n\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        if output_path.endswith('.yaml') or output_path.endswith('.yml'):\n            with open(output_path, 'w') as file:\n                yaml.dump(best_config, file, default_flow_style=False)\n        else:\n            logger.warning(\"Output file format not supported. Please use .yaml or .yml extension.\")\n\n    return best_config"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    # Load the configuration file\n    with open(os.path.join(trial_path, \"config.yaml\"), \"r\") as file:\n        config_dict = yaml.safe_load(file)\n\n    # Load the summary file\n    summary_df = load_summary_file(os.path.join(trial_path, \"summary.csv\"))\n\n    # Convert summary dataframe to config yaml file\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    # Save to YAML file if output_path is provided\n    if output_path:\n        if output_path.endswith(\".yaml\") or output_path.endswith(\".yml\"):\n            with open(output_path, \"w\") as file:\n                yaml.dump(best_config, file, default_flow_style=False)\n        else:\n            logger.warning(\"Output path file extension must be .yaml or .yml\")\n\n    return best_config"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_file = os.path.join(trial_path, 'summary.csv')\n    config_file = os.path.join(trial_path, 'config.yaml')\n\n    summary_df = load_summary_file(summary_file)\n    with open(config_file, 'r') as file:\n        config_dict = yaml.safe_load(file)\n\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        if output_path.endswith('.yaml') or output_path.endswith('.yml'):\n            with open(output_path, 'w') as file:\n                yaml.dump(best_config, file, default_flow_style=False)\n        else:\n            logger.warning(\"Output path file extension must be .yaml or .yml\")\n\n    return best_config"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_file = os.path.join(trial_path, 'summary.csv')\n    config_file = os.path.join(trial_path, 'config.yaml')\n\n    if not os.path.exists(summary_file) or not os.path.exists(config_file):\n        raise FileNotFoundError(\"Summary.csv or config.yaml file not found in the trial directory.\")\n\n    summary_df = load_summary_file(summary_file)\n    with open(config_file, 'r') as file:\n        config_dict = yaml.safe_load(file)\n\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        if not output_path.endswith(('.yaml', '.yml')):\n            raise ValueError(\"Output file must have .yaml or .yml extension.\")\n        with open(output_path, 'w') as file:\n            yaml.dump(best_config, file)\n\n    return best_config"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_file = os.path.join(trial_path, 'summary.csv')\n    config_file = os.path.join(trial_path, 'config.yaml')\n\n    if not os.path.exists(summary_file):\n        raise FileNotFoundError(f\"Summary file not found in {trial_path}\")\n\n    if not os.path.exists(config_file):\n        raise FileNotFoundError(f\"Config file not found in {trial_path}\")\n\n    summary_df = load_summary_file(summary_file)\n    with open(config_file, 'r') as f:\n        config_dict = yaml.safe_load(f)\n\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        if not output_path.endswith(('.yaml', '.yml')):\n            raise ValueError(\"Output file path must have .yaml or .yml extension\")\n        with open(output_path, 'w') as f:\n            yaml.dump(best_config, f)\n\n    return best_config"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_file = os.path.join(trial_path, \"summary.csv\")\n    config_file = os.path.join(trial_path, \"config.yaml\")\n\n    if not os.path.exists(summary_file):\n        raise FileNotFoundError(f\"Summary file not found in {trial_path}\")\n\n    if not os.path.exists(config_file):\n        raise FileNotFoundError(f\"Config file not found in {trial_path}\")\n\n    summary_df = load_summary_file(summary_file)\n    with open(config_file, 'r') as file:\n        config_dict = yaml.safe_load(file)\n\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        if not output_path.endswith(('.yaml', '.yml')):\n            raise ValueError(\"Output file must have .yaml or .yml extension\")\n        with open(output_path, 'w') as file:\n            yaml.dump(best_config, file)\n\n    return best_config"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_file = os.path.join(trial_path, 'summary.csv')\n    config_file = os.path.join(trial_path, 'config.yaml')\n\n    if not os.path.exists(summary_file):\n        raise FileNotFoundError(f\"Summary file not found at {summary_file}\")\n\n    if not os.path.exists(config_file):\n        raise FileNotFoundError(f\"Config file not found at {config_file}\")\n\n    summary_df = load_summary_file(summary_file)\n    with open(config_file, 'r') as file:\n        config_dict = yaml.safe_load(file)\n\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        if not output_path.endswith('.yaml') and not output_path.endswith('.yml'):\n            raise ValueError(\"Output file must have .yaml or .yml extension\")\n\n        with open(output_path, 'w') as file:\n            yaml.dump(best_config, file)\n\n    return best_config"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_file_path = os.path.join(trial_path, 'summary.csv')\n    config_file_path = os.path.join(trial_path, 'config.yaml')\n\n    if not os.path.exists(summary_file_path):\n        raise FileNotFoundError(f\"summary.csv not found in {trial_path}\")\n\n    if not os.path.exists(config_file_path):\n        raise FileNotFoundError(f\"config.yaml not found in {trial_path}\")\n\n    summary_df = load_summary_file(summary_file_path)\n    with open(config_file_path, 'r') as file:\n        config_dict = yaml.safe_load(file)\n\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        if not output_path.endswith(('.yaml', '.yml')):\n            raise ValueError(\"Output file must have .yaml or .yml extension\")\n        with open(output_path, 'w') as file:\n            yaml.dump(best_config, file)\n\n    return best_config"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_file_path = os.path.join(trial_path, \"summary.csv\")\n    config_file_path = os.path.join(trial_path, \"config.yaml\")\n\n    if not os.path.exists(summary_file_path):\n        raise FileNotFoundError(f\"Summary file not found in {trial_path}\")\n\n    if not os.path.exists(config_file_path):\n        raise FileNotFoundError(f\"Config file not found in {trial_path}\")\n\n    summary_df = load_summary_file(summary_file_path)\n    with open(config_file_path, 'r') as file:\n        config_dict = yaml.safe_load(file)\n\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        if not output_path.endswith(\".yaml\") and not output_path.endswith(\".yml\"):\n            raise ValueError(\"Output file must have .yaml or .yml extension\")\n\n        with open(output_path, 'w') as file:\n            yaml.dump(best_config, file)\n\n    return best_config"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_file = os.path.join(trial_path, 'summary.csv')\n    config_file = os.path.join(trial_path, 'config.yaml')\n\n    summary_df = load_summary_file(summary_file)\n    with open(config_file, 'r') as f:\n        config_dict = yaml.safe_load(f)\n\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path:\n        if output_path.endswith('.yaml') or output_path.endswith('.yml'):\n            with open(output_path, 'w') as f:\n                yaml.dump(best_config, f)\n        else:\n            logger.warning(\"Output path must have .yaml or .yml extension. Configuration not saved.\")\n\n    return best_config"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    cache = {}\n    lock = threading.Lock()\n\n    @functools.wraps(func)\n    def lazy_trace_wrapper(*args, **kwargs):\n        nonlocal cache\n        key = (func, args, frozenset(kwargs.items()))\n        with lock:\n            if key not in cache:\n                if isinstance(func, torch.nn.Module):\n                    traced_module, _ = trace_with_kwargs(func, **kwargs_)\n                    if ts_compiler:\n                        traced_module = ts_compiler(traced_module)\n                    cache[key] = traced_module\n                else:\n                    traced_func = better_trace(func, **kwargs_)\n                    if ts_compiler:\n                        traced_func = ts_compiler(traced_func)\n                    cache[key] = traced_func\n        if isinstance(func, torch.nn.Module):\n            return cache[key](*args, **kwargs)\n        else:\n            return cache[key](*args, **kwargs)\n\n    return lazy_trace_wrapper"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    cache = {}\n\n    @functools.wraps(func)\n    def lazy_trace_wrapper(*args, **kwargs):\n        key = (func, args, frozenset(kwargs.items()))\n        with threading.Lock():\n            if key in cache:\n                traced_module, _ = cache[key]\n            else:\n                example_inputs = args\n                example_kwarg_inputs = kwargs\n                traced_module, _ = trace_with_kwargs(func, example_inputs, example_kwarg_inputs, **kwargs_)\n                if ts_compiler is not None:\n                    traced_module = ts_compiler(traced_module)\n                cache[key] = (traced_module, None)\n\n        return traced_module(*args, **kwargs)\n\n    return lazy_trace_wrapper"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    lock = threading.Lock()\n    cache = {}\n\n    @functools.wraps(func)\n    def lazy_traced_func(*args, **kwargs):\n        nonlocal cache\n        key = (func, args, frozenset(kwargs.items()))\n        with lock:\n            if key not in cache:\n                if isinstance(func, torch.nn.Module):\n                    traced_module, _ = trace_with_kwargs(\n                        func.forward, example_inputs=args, example_kwarg_inputs=kwargs, **kwargs_)\n                else:\n                    traced_module, _ = trace_with_kwargs(\n                        func, example_inputs=args, example_kwarg_inputs=kwargs, **kwargs_)\n                if ts_compiler is not None:\n                    traced_module = ts_compiler(traced_module)\n                cache[key] = traced_module\n        return cache[key](*args, **kwargs)\n\n    return lazy_traced_func"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    cache = {}\n    lock = threading.Lock()\n\n    @functools.wraps(func)\n    def lazy_trace_wrapper(*args, **kwargs):\n        nonlocal cache\n        nonlocal lock\n\n        key = (func, args, frozenset(kwargs.items()))\n        with lock:\n            if key not in cache:\n                if isinstance(func, torch.nn.Module):\n                    traced_module, _ = trace_with_kwargs(func, **kwargs_)\n                    if ts_compiler:\n                        traced_module = ts_compiler(traced_module)\n                    cache[key] = traced_module\n                else:\n                    traced_module, _ = trace_with_kwargs(func, example_inputs=args, example_kwarg_inputs=kwargs, **kwargs_)\n                    if ts_compiler:\n                        traced_module = ts_compiler(traced_module)\n                    cache[key] = traced_module\n\n        return cache[key](*args, **kwargs)\n\n    return lazy_trace_wrapper"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    cache = {}\n    lock = threading.Lock()\n\n    @functools.wraps(func)\n    def lazy_trace_wrapper(*args, **kwargs):\n        key = (func, args, frozenset(kwargs.items()))\n        with lock:\n            if key not in cache:\n                if isinstance(func, torch.nn.Module):\n                    traced_module, _ = trace_with_kwargs(\n                        func, **kwargs_, example_inputs=args, example_kwarg_inputs=kwargs)\n                    if ts_compiler:\n                        traced_module = ts_compiler(traced_module)\n                    cache[key] = traced_module\n                else:\n                    traced_fn = better_trace(func, *args, **kwargs_)\n                    if ts_compiler:\n                        traced_fn = ts_compiler(traced_fn)\n                    cache[key] = traced_fn\n        if isinstance(func, torch.nn.Module):\n            return cache[key](*args, **kwargs)\n        else:\n            return cache[key]\n\n    return lazy_trace_wrapper"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    cache = {}\n    lock = threading.Lock()\n\n    @functools.wraps(func)\n    def lazy_traced_func(*args, **kwargs):\n        key = (func, args, frozenset(kwargs.items()))\n        with lock:\n            if key not in cache:\n                if isinstance(func, torch.nn.Module):\n                    traced_module, _ = trace_with_kwargs(\n                        func, *args, **kwargs, **kwargs_)\n                    if ts_compiler:\n                        traced_module = ts_compiler(traced_module)\n                    cache[key] = traced_module\n                else:\n                    traced_func = better_trace(func, *args, **kwargs, **kwargs_)\n                    if ts_compiler:\n                        traced_func = ts_compiler(traced_func)\n                    cache[key] = traced_func\n        return cache[key](*args, **kwargs)\n\n    return lazy_traced_func"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    cache = {}\n    lock = threading.Lock()\n\n    @functools.wraps(func)\n    def lazy_traced_func(*args, **kwargs):\n        key = (func, args, frozenset(kwargs.items()))\n        with lock:\n            if key not in cache:\n                traced_module, _ = trace_with_kwargs(func, *args, **kwargs, **kwargs_)\n                if ts_compiler:\n                    traced_module = ts_compiler(traced_module)\n                cache[key] = traced_module\n        return cache[key](*args, **kwargs)\n\n    return lazy_traced_func"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    cache = {}\n\n    @functools.wraps(func)\n    def lazy_trace_wrapper(*args, **kwargs):\n        key = (func, args, frozenset(kwargs.items()))\n        if key not in cache:\n            with threading.Lock():\n                if key not in cache:\n                    traced_module, _ = trace_with_kwargs(func, *args, **kwargs, **kwargs_)\n                    if ts_compiler:\n                        traced_module = ts_compiler(traced_module)\n                    cache[key] = traced_module\n        return cache[key]\n\n    return lazy_trace_wrapper"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    cache = {}\n    lock = threading.Lock()\n\n    @functools.wraps(func)\n    def lazy_trace_wrapper(*args, **kwargs):\n        key = (func, args, frozenset(kwargs.items()))\n        with lock:\n            if key not in cache:\n                if isinstance(func, torch.nn.Module):\n                    traced_module, _ = trace_with_kwargs(func, **kwargs_)\n                    if ts_compiler:\n                        traced_module = ts_compiler(traced_module)\n                    cache[key] = traced_module\n                else:\n                    traced_func = torch.jit.trace(func, *args, **kwargs)\n                    if ts_compiler:\n                        traced_func = ts_compiler(traced_func)\n                    cache[key] = traced_func\n            traced = cache[key]\n        if isinstance(traced, torch.jit.ScriptModule):\n            return traced(*args, **kwargs)\n        else:\n            return traced(*args)\n    return lazy_trace_wrapper"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    cache = {}\n\n    @functools.wraps(func)\n    def lazy_trace_wrapper(*args, **kwargs):\n        key = (func, args, frozenset(kwargs.items()))\n        if key not in cache:\n            with threading.Lock():\n                if key not in cache:\n                    traced_module, _ = trace_with_kwargs(func, *args, **kwargs, **kwargs_)\n                    if ts_compiler:\n                        traced_module = ts_compiler(traced_module)\n                    cache[key] = traced_module\n        return cache[key]\n\n    return lazy_trace_wrapper"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    cache = {}\n    lock = threading.Lock()\n\n    @functools.wraps(func)\n    def lazy_traced_func(*args, **kwargs):\n        key = (func, args, frozenset(kwargs.items()))\n        with lock:\n            if key not in cache:\n                if isinstance(func, torch.nn.Module):\n                    traced_module, _ = trace_with_kwargs(func, **kwargs_)\n                    if ts_compiler:\n                        traced_module = ts_compiler(traced_module)\n                    cache[key] = traced_module\n                else:\n                    traced_module, _ = trace_with_kwargs(func, *args, **kwargs_)\n                    if ts_compiler:\n                        traced_module = ts_compiler(traced_module)\n                    cache[key] = traced_module\n        return cache[key](*args, **kwargs)\n\n    return lazy_traced_func"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    cache = {}\n\n    def wrapped(*args, **kwargs):\n        key = (func, tuple(args), tuple(kwargs.items()))\n        if key not in cache:\n            with threading.Lock():\n                if key not in cache:\n                    traced_module, _ = trace_with_kwargs(func, *args, **kwargs, **kwargs_)\n                    if ts_compiler:\n                        traced_module = ts_compiler(traced_module)\n                    cache[key] = traced_module\n        return cache[key](*args, **kwargs)\n\n    return wrapped"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    cache = {}\n\n    def wrapper(*args, **kwargs):\n        key = (func, ts_compiler, frozenset(kwargs_.items()))\n        if key not in cache:\n            with threading.Lock():\n                if key not in cache:\n                    traced_module, _ = trace_with_kwargs(func, **kwargs_)\n                    if ts_compiler:\n                        traced_module = ts_compiler(traced_module)\n                    cache[key] = traced_module\n        return cache[key](*args, **kwargs)\n\n    return wrapper"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    cache = {}\n    lock = threading.Lock()\n\n    @functools.wraps(func)\n    def lazy_traced_func(*args, **kwargs):\n        nonlocal cache\n        key = (func, args, frozenset(kwargs.items()))\n        with lock:\n            if key not in cache:\n                if isinstance(func, torch.nn.Module):\n                    traced_module, _ = trace_with_kwargs(func, **kwargs_)\n                    cache[key] = traced_module\n                else:\n                    traced_module = better_trace(func, **kwargs_)\n                    cache[key] = traced_module\n        return cache[key](*args, **kwargs)\n\n    return lazy_traced_func"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    cache = {}\n    lock = threading.Lock()\n\n    @functools.wraps(func)\n    def lazy_trace_wrapper(*args, **kwargs):\n        key = (func, args, frozenset(kwargs.items()))\n        with lock:\n            if key not in cache:\n                if isinstance(func, torch.nn.Module):\n                    traced_module, _ = trace_with_kwargs(func, **kwargs_)\n                else:\n                    traced_module = torch.jit.trace(func, example_inputs=args, **kwargs_)\n                if ts_compiler:\n                    traced_module = ts_compiler(traced_module)\n                cache[key] = traced_module\n        return cache[key](*args, **kwargs)\n\n    return lazy_trace_wrapper"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    cache = {}\n    lock = threading.Lock()\n\n    @functools.wraps(func)\n    def lazy_trace_wrapper(*args, **kwargs):\n        nonlocal cache\n        nonlocal lock\n\n        key = (func, args, frozenset(kwargs.items()))\n        with lock:\n            if key not in cache:\n                if isinstance(func, torch.nn.Module):\n                    traced_module, _ = trace_with_kwargs(func, **kwargs_)\n                    if ts_compiler:\n                        traced_module = ts_compiler(traced_module)\n                    cache[key] = traced_module\n                else:\n                    traced_func = better_trace(func, *args, **kwargs_)\n                    if ts_compiler:\n                        traced_func = ts_compiler(traced_func)\n                    cache[key] = traced_func\n\n        if isinstance(func, torch.nn.Module):\n            return cache[key](*args, **kwargs)\n        else:\n            return cache[key]\n\n    return lazy_trace_wrapper"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    cache = {}\n    lock = threading.Lock()\n\n    @functools.wraps(func)\n    def lazy_trace_wrapper(*args, **kwargs):\n        nonlocal cache\n        key = (func, args, frozenset(kwargs.items()))\n        with lock:\n            if key not in cache:\n                if isinstance(func, torch.nn.Module):\n                    traced_module, wrapper = trace_with_kwargs(func, **kwargs_)\n                    if ts_compiler:\n                        traced_module = ts_compiler(traced_module)\n                    cache[key] = (wrapper(traced_module), wrapper)\n                else:\n                    traced_fn = better_trace(func, *args, **kwargs_)\n                    if ts_compiler:\n                        traced_fn = ts_compiler(traced_fn)\n                    cache[key] = traced_fn\n        if isinstance(func, torch.nn.Module):\n            return cache[key][0](*args, **kwargs)\n        else:\n            return cache[key](*args, **kwargs)\n\n    return lazy_trace_wrapper"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    cache = {}\n    lock = threading.Lock()\n\n    @functools.wraps(func)\n    def lazy_trace_wrapper(*args, **kwargs):\n        nonlocal cache\n        nonlocal lock\n        key = (func, args, tuple(sorted(kwargs.items())))\n        with lock:\n            if key not in cache:\n                if isinstance(func, torch.nn.Module):\n                    traced_module, _ = trace_with_kwargs(func, **kwargs_)\n                    if ts_compiler:\n                        traced_module = ts_compiler(traced_module)\n                    cache[key] = traced_module\n                else:\n                    traced_module = better_trace(func, *args, **kwargs_)\n                    if ts_compiler:\n                        traced_module = ts_compiler(traced_module)\n                    cache[key] = traced_module\n        return cache[key](*args, **kwargs)\n\n    return lazy_trace_wrapper"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    cache = {}\n    lock = threading.Lock()\n\n    @functools.wraps(func)\n    def lazy_trace_wrapper(*args, **kwargs):\n        nonlocal cache\n        key = (func, args, frozenset(kwargs.items()))\n        with lock:\n            if key not in cache:\n                if isinstance(func, torch.nn.Module):\n                    traced_module, _ = trace_with_kwargs(func, **kwargs_)\n                else:\n                    traced_module, _ = trace_with_kwargs(func, example_inputs=args, **kwargs_)\n                if ts_compiler:\n                    traced_module = ts_compiler(traced_module)\n                cache[key] = traced_module\n        return cache[key](*args, **kwargs)\n\n    return lazy_trace_wrapper"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    cache = {}\n    lock = threading.Lock()\n\n    @functools.wraps(func)\n    def lazy_trace_wrapper(*args, **kwargs):\n        nonlocal cache\n        key = (func, args, frozenset(kwargs.items()))\n        with lock:\n            if key not in cache:\n                traced_module, _ = trace_with_kwargs(func, *args, **kwargs, **kwargs_)\n                if ts_compiler is not None:\n                    traced_module = ts_compiler(traced_module)\n                cache[key] = traced_module\n        return cache[key](*args, **kwargs)\n\n    return lazy_trace_wrapper"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config_dict = extract_best_config(trial_path)\n        project_dir = os.path.dirname(trial_path)\n        return cls(config_dict, project_dir)"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config_dict = extract_best_config(trial_path)\n        project_dir = os.path.dirname(trial_path)\n        return cls(config_dict, project_dir)"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config_yaml_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_yaml_path, 'r') as f:\n            try:\n                config = yaml.safe_load(f)\n            except yaml.YAMLError as exc:\n                logger.error(exc)\n                raise exc\n        project_dir = os.path.dirname(trial_path)\n        return cls(config, project_dir=project_dir)"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config_yaml_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_yaml_path, 'r') as f:\n            try:\n                config = yaml.safe_load(f)\n            except yaml.YAMLError as exc:\n                logger.error(exc)\n                raise exc\n        project_dir = os.path.dirname(trial_path)\n        return cls(config, project_dir=project_dir)"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config_dict = extract_best_config(trial_path)\n        project_dir = os.path.dirname(trial_path)\n        return cls(config_dict, project_dir=project_dir)"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config_yaml_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_yaml_path, 'r') as f:\n            try:\n                config = yaml.safe_load(f)\n            except yaml.YAMLError as exc:\n                logger.error(exc)\n                raise exc\n        project_dir = os.path.dirname(trial_path)\n        return cls(config, project_dir=project_dir)"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config_yaml_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_yaml_path, 'r') as f:\n            try:\n                config = yaml.safe_load(f)\n            except yaml.YAMLError as exc:\n                logger.error(exc)\n                raise exc\n        project_dir = os.path.dirname(trial_path)\n        return cls(config, project_dir=project_dir)"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config_yaml_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_yaml_path, 'r') as f:\n            config = yaml.safe_load(f)\n        project_dir = os.path.dirname(trial_path)\n        return cls(config, project_dir=project_dir)"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config_yaml_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_yaml_path, 'r') as f:\n            config = yaml.safe_load(f)\n        project_dir = os.path.dirname(trial_path)\n        return cls(config, project_dir)"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config_yaml_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_yaml_path, 'r') as f:\n            config = yaml.safe_load(f)\n        project_dir = os.path.dirname(trial_path)\n        return cls(config, project_dir=project_dir)"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config_yaml_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_yaml_path, 'r') as f:\n            try:\n                config = yaml.safe_load(f)\n            except yaml.YAMLError as exc:\n                logger.error(exc)\n                raise exc\n        project_dir = os.path.dirname(trial_path)\n        return cls(config, project_dir=project_dir)"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config = extract_best_config(trial_path)\n        project_dir = os.path.dirname(trial_path)\n        return cls(config, project_dir)"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config = extract_best_config(trial_path)\n        project_dir = os.path.dirname(trial_path)\n        return cls(config, project_dir)"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config_yaml_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_yaml_path, 'r') as f:\n            try:\n                config = yaml.safe_load(f)\n            except yaml.YAMLError as exc:\n                logger.error(exc)\n                raise exc\n        project_dir = os.path.dirname(trial_path)\n        return cls(config, project_dir=project_dir)"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        output_path = os.path.join(trial_path, 'best_config.yaml')\n        yaml_dict = extract_best_config(trial_path, output_path)\n        project_dir = os.path.dirname(trial_path)\n        return cls(yaml_dict, project_dir)"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config_yaml_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_yaml_path, 'r') as f:\n            config = yaml.safe_load(f)\n        project_dir = os.path.dirname(trial_path)\n        return cls(config, project_dir=project_dir)"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config_dict = extract_best_config(trial_path)\n        project_dir = os.path.dirname(trial_path)\n        return cls(config_dict, project_dir)"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        output_path = os.path.join(trial_path, 'config.yaml')\n        yaml_dict = extract_best_config(trial_path, output_path)\n        project_dir = os.path.dirname(trial_path)\n        return cls(yaml_dict, project_dir)"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config_dict = extract_best_config(trial_path)\n        project_dir = os.path.dirname(trial_path)\n        return cls(config_dict, project_dir=project_dir)"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config_dict = extract_best_config(trial_path)\n        project_dir = os.path.dirname(trial_path)\n        return cls(config_dict, project_dir)"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "\n    filtered_results = [result for result, val in zip(results, value) if val <= threshold]\n    if metadatas:\n        filtered_metadatas = [meta for meta, val in zip(metadatas, value) if val <= threshold]\n    else:\n        filtered_metadatas = []\n\n    return filtered_results, filtered_metadatas"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "\n    filtered_results = [result for result, val in zip(results, value) if val <= threshold]\n    if metadatas:\n        filtered_metadatas = [meta for meta, val in zip(metadatas, value) if val <= threshold]\n    else:\n        filtered_metadatas = []\n\n    return filtered_results, filtered_metadatas"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    filtered_results = [result for result, val in zip(results, value) if val <= threshold]\n    filtered_metadatas = [metadata for metadata, val in zip(metadatas or [None] * len(results), value) if val <= threshold]\n    return filtered_results, filtered_metadatas"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "\n    filtered_results = [result for result, val in zip(results, value) if val <= threshold]\n    if metadatas:\n        filtered_metadatas = [metadata for result, val, metadata in zip(results, value, metadatas) if val <= threshold]\n    else:\n        filtered_metadatas = []\n\n    return filtered_results, filtered_metadatas"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "\n    filtered_results = [result for result, val in zip(results, value) if val <= threshold]\n    if metadatas:\n        filtered_metadatas = [metadata for metadata, val in zip(metadatas, value) if val <= threshold]\n    else:\n        filtered_metadatas = []\n\n    return filtered_results, filtered_metadatas"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    filtered_results = [result for result, val in zip(results, value) if val <= threshold]\n    if metadatas:\n        filtered_metadatas = [meta for result, val, meta in zip(results, value, metadatas) if val <= threshold]\n    else:\n        filtered_metadatas = []\n    return filtered_results, filtered_metadatas"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    filtered_results = [result for result, val in zip(results, value) if val <= threshold]\n    if metadatas:\n        filtered_metadatas = [metadata for metadata, val in zip(metadatas, value) if val <= threshold]\n    else:\n        filtered_metadatas = []\n\n    return filtered_results, filtered_metadatas"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "\n    filtered_results = [result for result, val in zip(results, value) if val <= threshold]\n    if metadatas:\n        filtered_metadatas = [metadata for metadata, val in zip(metadatas, value) if val <= threshold]\n    else:\n        filtered_metadatas = []\n\n    return filtered_results, filtered_metadatas"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "\n    filtered_results = [result for result, val in zip(results, value) if val <= threshold]\n    if metadatas:\n        filtered_metadatas = [meta for meta, val in zip(metadatas, value) if val <= threshold]\n    else:\n        filtered_metadatas = []\n\n    return filtered_results, filtered_metadatas"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "\n    filtered_results = [result for i, result in enumerate(results) if value[i] <= threshold]\n    filtered_metadatas = [metadata for i, metadata in enumerate(metadatas) if value[i] <= threshold] if metadatas else []\n\n    return filtered_results, filtered_metadatas"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "\n    # Apply the avoid_empty_result decorator to the filter_by_threshold function\n    @avoid_empty_result([0, 1])\n\n    def filter_by_threshold(results, value, threshold, metadatas=None) -> Tuple[List, List]:\n        filtered_results = [result for result, val in zip(results, value) if val <= threshold]\n        filtered_metadatas = [metadata for result, val, metadata in zip(results, value, metadatas) if val <= threshold] if metadatas else []\n        return filtered_results, filtered_metadatas\n\n    return filter_by_threshold(results, value, threshold, metadatas)"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "\n    filtered_results = [result for result, val in zip(results, value) if val <= threshold]\n    filtered_metadatas = [metadata for metadata, val in zip(metadatas, value) if val <= threshold] if metadatas else []\n\n    return filtered_results, filtered_metadatas"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "\n    # Zip the results, values, and metadatas (if available) together\n    zipped_data = zip(results, value, metadatas) if metadatas else zip(results, value)\n\n    # Filter the zipped data based on the threshold\n    filtered_data = [(res, meta) for res, val, meta in zipped_data if val <= threshold]\n\n    # Unzip the filtered data to get the filtered results and metadatas\n    filtered_results, filtered_metadatas = zip(*filtered_data) if filtered_data else ([], [])\n\n    return filtered_results, filtered_metadatas"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "\n    filtered_results = [result for result, val in zip(results, value) if val <= threshold]\n    if metadatas:\n        filtered_metadatas = [metadata for metadata, val in zip(metadatas, value) if val <= threshold]\n    else:\n        filtered_metadatas = []\n\n    return filtered_results, filtered_metadatas"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    filtered_results = [result for result, val in zip(results, value) if val <= threshold]\n    filtered_metadatas = [metadata for metadata, val in zip(metadatas or [None] * len(results), value) if val <= threshold]\n    return filtered_results, filtered_metadatas"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "\n    filtered_results = [result for i, result in enumerate(results) if value[i] <= threshold]\n    if metadatas:\n        filtered_metadatas = [metadata for i, metadata in enumerate(metadatas) if value[i] <= threshold]\n    else:\n        filtered_metadatas = []\n\n    return filtered_results, filtered_metadatas"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    filtered_results = [result for result, val in zip(results, value) if val <= threshold]\n    if metadatas:\n        filtered_metadatas = [meta for result, val, meta in zip(results, value, metadatas) if val <= threshold]\n    else:\n        filtered_metadatas = []\n    return filtered_results, filtered_metadatas"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "\n    filtered_results = [result for result, val in zip(results, value) if val <= threshold]\n    if metadatas:\n        filtered_metadatas = [metadata for result, val, metadata in zip(results, value, metadatas) if val <= threshold]\n    else:\n        filtered_metadatas = []\n\n    return filtered_results, filtered_metadatas"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "\n    filtered_results = [result for result, val in zip(results, value) if val <= threshold]\n    if metadatas:\n        filtered_metadatas = [metadata for metadata, val in zip(metadatas, value) if val <= threshold]\n    else:\n        filtered_metadatas = []\n\n    return filtered_results, filtered_metadatas"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "\n    filtered_results = [result for result, val in zip(results, value) if val <= threshold]\n    if metadatas:\n        filtered_metadatas = [meta for result, val, meta in zip(results, value, metadatas) if val <= threshold]\n    else:\n        filtered_metadatas = []\n\n    return filtered_results, filtered_metadatas"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Initialize empty list to store results\n    results = []\n\n    # Loop through each module and its parameters\n    for module, params in zip(modules, module_params):\n        # Run the retrieval module with the given parameters\n        result = module(previous_result, **params)\n\n        # Measure the speed of the retrieval module execution\n        speed = measure_speed(module, previous_result, **params)\n\n        # Apply speed threshold filtering if specified in the strategies\n        if 'speed_threshold' in strategies:\n            result = filter_by_threshold(result, speed, strategies['speed_threshold'])\n\n        # Evaluate the retrieval module result\n        evaluation_metrics = evaluate_retrieval(result, previous_result)\n\n        # Append the result, speed, and evaluation metrics to the results list\n        results.append((result, speed, evaluation_metrics))\n\n    # Select the best retrieval module result based on the specified strategies\n    best_result = select_best_average(results, strategies)\n\n    # Save the results and a summary of the execution times and evaluation metrics to disk\n    result_path = os.path.join(node_line_dir, 'retrieval_results.csv')\n    summary_path = os.path.join(node_line_dir, 'summary.csv')\n\n    best_result.to_csv(result_path, index=False)\n    summary_data = load_summary_file(summary_path)\n    summary_data.append((best_result, results))\n    summary_data.to_csv(summary_path, index=False)\n\n    # Return the best result dataframe, which combines the previous result columns with the selected retrieval node's result columns\n    return best_result"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Initialize empty lists to store results and execution times\n    results = []\n    execution_times = []\n\n    # Loop through each module and its parameters\n    for module, params in zip(modules, module_params):\n        # Run the retrieval module with the specified parameters\n        result, execution_time = module(previous_result, **params)\n\n        # Measure the speed of the retrieval module execution\n        speed = measure_speed(execution_time)\n\n        # Apply speed threshold filtering if specified in the strategies\n        if 'speed_threshold' in strategies:\n            result = filter_by_threshold(result, speed, strategies['speed_threshold'])\n\n        # Add the result and execution time to the lists\n        results.append(result)\n        execution_times.append(execution_time)\n\n    # Select the best result based on the specified strategies\n    best_result = select_best_average(results, strategies['metrics'])\n\n    # Save the results and a summary of the execution times and evaluation metrics to disk\n    result_summary = evaluate_retrieval(results, execution_times, strategies['metrics'])\n    result_summary.to_csv(os.path.join(node_line_dir, 'summary.csv'), index=False)\n\n    # Return the best result dataframe, which combines the previous result columns with the selected retrieval node's result columns\n    return best_result"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Initialize an empty list to store the results of each module\n    results = []\n\n    # Loop through each module and its parameters\n    for module, params in zip(modules, module_params):\n        # Execute the module with the given parameters\n        result = module(**params)\n        # Measure the speed of the module execution\n        speed = measure_speed(module, **params)\n        # Filter the result based on speed threshold if specified in the strategies\n        if \"speed_threshold\" in strategies:\n            result = filter_by_threshold(result, speed, strategies[\"speed_threshold\"])\n        # Evaluate the result based on the previous result and specified metrics\n        evaluation_metrics = evaluate_retrieval(result, previous_result, strategies[\"metrics\"])\n        # Store the result, speed, and evaluation metrics in a dictionary\n        result_data = {\n            \"result\": result,\n            \"speed\": speed,\n            \"evaluation_metrics\": evaluation_metrics\n        }\n        # Append the dictionary to the results list\n        results.append(result_data)\n\n    # Select the best result based on the evaluation metrics using the specified strategy\n    best_result = select_best_average(results, strategies[\"evaluation_strategy\"])\n\n    # Save the results and a summary of the execution times and evaluation metrics to disk\n    result_path = os.path.join(node_line_dir, \"retrieval_results.csv\")\n    summary_path = os.path.join(node_line_dir, \"summary.csv\")\n    best_result[\"result\"].to_csv(result_path, index=False)\n    summary_data = {\n        \"speed\": [result[\"speed\"] for result in results],\n        \"evaluation_metrics\": [result[\"evaluation_metrics\"] for result in results]\n    }\n    summary_df = pd.DataFrame(summary_data)\n    summary_df.to_csv(summary_path, index=False)\n\n    # Return the best result dataframe, which combines the previous result columns with the selected retrieval node's result columns\n    return best_result[\"result\"]"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Initialize variables to store execution times and evaluation metrics\n    execution_times = []\n    evaluation_metrics = []\n\n    # Iterate through each module and its parameters\n    for module, params in zip(modules, module_params):\n        # Measure the execution time of the module\n        start_time = measure_speed()\n        result = module(previous_result, **params)\n        end_time = measure_speed()\n\n        # Evaluate the module result\n        metrics = evaluate_retrieval(result, previous_result, **strategies)\n\n        # Store the execution time and evaluation metrics\n        execution_times.append((module.__name__, end_time - start_time))\n        evaluation_metrics.append((module.__name__, metrics))\n\n    # Save the execution times and evaluation metrics to disk\n    summary_file_path = os.path.join(node_line_dir, \"summary.csv\")\n    summary_df = load_summary_file(summary_file_path)\n    for module, time in execution_times:\n        summary_df = summary_df.append({\"Module\": module, \"Execution Time (s)\": time}, ignore_index=True)\n    summary_df.to_csv(summary_file_path, index=False)\n\n    # Select the best module based on the evaluation metrics\n    best_module = select_best_average(evaluation_metrics)\n\n    # Filter the result of the best module based on speed threshold if specified\n    if \"speed_threshold\" in strategies:\n        result = filter_by_threshold(result, execution_times, **strategies[\"speed_threshold\"])\n\n    # Return the best result dataframe, combining the previous result columns with the selected retrieval node's result columns\n    return result"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Run each module with given parameters\n    results = []\n    execution_times = []\n    for module, params in zip(modules, module_params):\n        result, exec_time = module(previous_result, **params)\n        results.append(result)\n        execution_times.append(exec_time)\n\n    # Measure execution times\n    speed_metrics = measure_speed(execution_times)\n\n    # Apply specified strategies\n    filtered_results = filter_by_threshold(results, speed_metrics, strategies['speed_threshold'])\n    best_result = select_best_average(filtered_results, strategies['evaluation_metric'])\n\n    # Save results and summary to disk\n    result_path = os.path.join(node_line_dir, 'results.csv')\n    summary_path = os.path.join(node_line_dir, 'summary.csv')\n    best_result.to_csv(result_path, index=False)\n    summary_df = load_summary_file(summary_path)\n    summary_df = summary_df.append(speed_metrics, ignore_index=True)\n    summary_df.to_csv(summary_path, index=False)\n\n    # Return the best result dataframe\n    return best_result"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Initialize empty list to store results\n    results = []\n\n    # Loop through each module and its parameters\n    for module, params in zip(modules, module_params):\n        # Execute the retrieval module with the given parameters\n        result = module(**params)\n\n        # Measure the speed of the retrieval module\n        speed = measure_speed(result)\n\n        # Filter the results based on speed threshold\n        filtered_result = filter_by_threshold(result, speed, strategies['speed_threshold'])\n\n        # Evaluate the filtered result\n        evaluation_metrics = evaluate_retrieval(filtered_result, previous_result, strategies['evaluation_metrics'])\n\n        # Store the result, speed, and evaluation metrics in a dictionary\n        result_summary = {\n            'result': filtered_result,\n            'speed': speed,\n            'evaluation_metrics': evaluation_metrics\n        }\n\n        # Append the result summary to the list of results\n        results.append(result_summary)\n\n    # Select the best result based on the evaluation metrics\n    best_result_summary = select_best_average(results, strategies['evaluation_metrics'])\n\n    # Save the best result and summary to disk\n    best_result = best_result_summary['result']\n    best_result.to_csv(os.path.join(node_line_dir, 'best_result.csv'), index=False)\n\n    summary = pd.DataFrame([{\n        'module': module.__name__,\n        'speed': result_summary['speed'],\n        **result_summary['evaluation_metrics']\n    } for module, result_summary in zip(modules, results)])\n\n    summary.to_csv(os.path.join(node_line_dir, 'summary.csv'), index=False)\n\n    # Return the best result dataframe\n    return best_result"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Initialize empty lists to store results and execution times\n    results = []\n    execution_times = []\n\n    # Loop through each module and its parameters\n    for i, (module, params) in enumerate(zip(modules, module_params)):\n        # Run the retrieval module and measure its execution time\n        result, execution_time = measure_speed(module, params)\n        results.append(result)\n        execution_times.append(execution_time)\n\n    # Save the results and execution times to disk\n    result_df = pd.concat(results, axis=1)\n    result_df.to_csv(os.path.join(node_line_dir, \"retrieval_results.csv\"), index=False)\n\n    execution_times_df = pd.DataFrame(execution_times, columns=[\"execution_time\"])\n    execution_times_df.to_csv(os.path.join(node_line_dir, \"execution_times.csv\"), index=False)\n\n    # Load the summary file and evaluate the retrieval results\n    summary_file = load_summary_file(node_line_dir)\n    evaluation_metrics = evaluate_retrieval(summary_file, previous_result, strategies)\n\n    # Apply the strategies to select the best retrieval result\n    best_result = select_best_average(result_df, evaluation_metrics, strategies)\n\n    # Return the best result dataframe\n    return best_result"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Initialize empty list to store results and execution times\n    results = []\n    execution_times = []\n\n    # Loop through each module and its parameters\n    for i, (module, params) in enumerate(zip(modules, module_params)):\n        logger.info(f\"Running retrieval module {i+1}/{len(modules)}\")\n\n        # Run the retrieval module with the given parameters\n        result, exec_time = measure_speed(module, params)\n\n        # Filter the result based on specified speed threshold\n        result = filter_by_threshold(result, strategies.get(\"speed_threshold\"))\n\n        # Evaluate the result based on the previous result and specified metrics\n        evaluation_metrics = evaluate_retrieval(result, previous_result, strategies.get(\"metrics\"))\n\n        # Save the result and execution time\n        results.append(result)\n        execution_times.append(exec_time)\n\n        # Log the evaluation metrics\n        logger.info(f\"Evaluation metrics for module {i+1}/{len(modules)}: {evaluation_metrics}\")\n\n    # Select the best result based on the evaluation metrics and specified selection strategy\n    best_result = select_best_average(results, evaluation_metrics, strategies.get(\"selection_strategy\"))\n\n    # Save the results and a summary of the execution times and evaluation metrics to disk\n    summary = pd.DataFrame({\"Module\": [f\"Module {i+1}\" for i in range(len(modules))],\n                            \"Execution Time (s)\": execution_times,\n                            \"Evaluation Metrics\": [str(metrics) for metrics in evaluation_metrics]})\n    summary.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    # Return the best result dataframe, which combines the previous result columns with the selected retrieval node's result columns\n    return best_result"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Run each module with given parameters\n    results = []\n    for i, module in enumerate(modules):\n        logger.info(f\"Running retrieval module {i + 1}...\")\n        result = module(**module_params[i])\n        results.append(result)\n\n    # Measure execution times\n    execution_times = measure_speed(results)\n\n    # Filter results by speed threshold\n    filtered_results = filter_by_threshold(results, execution_times, strategies)\n\n    # Evaluate and select the best retrieval node result\n    best_result = select_best_average(filtered_results, previous_result, strategies)\n\n    # Save results and summary\n    os.makedirs(node_line_dir, exist_ok=True)\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"), index=False)\n    summary = load_summary_file(node_line_dir)\n    summary[\"execution_times\"] = execution_times\n    summary.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n\n    return best_result"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Run each module with given parameters\n    results = []\n    execution_times = []\n    for module, params in zip(modules, module_params):\n        result, exec_time = module(previous_result, **params)\n        results.append(result)\n        execution_times.append(exec_time)\n\n    # Measure execution times\n    execution_summary = measure_speed(execution_times)\n\n    # Evaluate retrieval results\n    evaluation_metrics = evaluate_retrieval(results, previous_result, strategies)\n\n    # Apply specified strategies to select the best retrieval result\n    best_result = select_best_average(results, evaluation_metrics, strategies)\n\n    # Save results and summaries to disk\n    save_path = os.path.join(node_line_dir, \"retrieval_results.csv\")\n    best_result.to_csv(save_path, index=False)\n\n    summary_data = {\n        \"execution_times\": execution_summary,\n        \"evaluation_metrics\": evaluation_metrics\n    }\n    summary_save_path = os.path.join(node_line_dir, \"summary.json\")\n    with open(summary_save_path, \"w\") as f:\n        json.dump(summary_data, f)\n\n    return best_result"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Initialize lists to store results and execution times\n    results = []\n    execution_times = []\n\n    # Loop through each module and its parameters\n    for module, params in zip(modules, module_params):\n        # Measure the execution time of the module\n        start_time = measure_speed()\n        result = module(previous_result, **params)\n        end_time = measure_speed()\n\n        # Append the result and execution time to the lists\n        results.append(result)\n        execution_times.append((module.__name__, end_time - start_time))\n\n    # Create a DataFrame to store the results and execution times\n    results_df = pd.concat(results, axis=1)\n    execution_times_df = pd.DataFrame(execution_times, columns=['Module', 'Execution Time'])\n\n    # Filter the results based on specified strategies\n    filtered_results = filter_by_threshold(results_df, strategies)\n\n    # Select the best result based on the evaluation metrics\n    best_result = select_best_average(filtered_results, strategies)\n\n    # Save the results and summary to disk\n    results_df.to_csv(os.path.join(node_line_dir, 'results.csv'), index=False)\n    execution_times_df.to_csv(os.path.join(node_line_dir, 'execution_times.csv'), index=False)\n\n    # Log the best result and return it\n    logger.info(f\"The best retrieval node result is from {best_result.columns}\")\n    return best_result"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Initialize variables for storing results and execution times\n    results = []\n    execution_times = []\n\n    # Loop through each module and its parameters\n    for module, params in zip(modules, module_params):\n        # Execute the module with the given parameters\n        result, exec_time = module(previous_result, **params)\n\n        # Measure the speed of the execution\n        speed = measure_speed(exec_time)\n\n        # Apply speed threshold filtering if specified in the strategies\n        if 'speed_threshold' in strategies:\n            result = filter_by_threshold(result, speed, strategies['speed_threshold'])\n\n        # Store the result and execution time\n        results.append(result)\n        execution_times.append(exec_time)\n\n    # Select the best result using the specified strategy\n    best_result = select_best_average(results, strategies['evaluation_metric'])\n\n    # Evaluate the best result\n    evaluation_metrics = evaluate_retrieval(best_result, previous_result)\n\n    # Save the results and summary to disk\n    result_file_path = os.path.join(node_line_dir, 'result.csv')\n    summary_file_path = os.path.join(node_line_dir, 'summary.csv')\n\n    best_result.to_csv(result_file_path, index=False)\n    summary_data = load_summary_file(summary_file_path)\n    summary_data.append({'module': 'retrieval_node', 'execution_times': execution_times, 'evaluation_metrics': evaluation_metrics})\n    pd.DataFrame(summary_data).to_csv(summary_file_path, index=False)\n\n    # Return the best result\n    return best_result"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Initialize empty list to store results\n    results = []\n\n    # Loop through each module and its parameters\n    for module, params in zip(modules, module_params):\n        # Run the retrieval module with given parameters\n        result = module(**params)\n\n        # Measure the execution time\n        speed = measure_speed(result)\n\n        # Filter the result based on speed threshold\n        result = filter_by_threshold(result, speed, strategies.get('speed_threshold'))\n\n        # Evaluate the result\n        evaluation_metrics = evaluate_retrieval(result, previous_result)\n\n        # Store the result, speed, and evaluation metrics\n        results.append({\n            'result': result,\n            'speed': speed,\n            'evaluation_metrics': evaluation_metrics\n        })\n\n    # Select the best result based on evaluation metrics and speed\n    best_result = select_best_average(results, strategies.get('evaluation_metric'))\n\n    # Save the results and summary to disk\n    save_path = os.path.join(node_line_dir, 'retrieval_results.csv')\n    best_result['result'].to_csv(save_path, index=False)\n\n    summary = load_summary_file(node_line_dir)\n    summary['retrieval_node'] = best_result['result'].name\n    summary.to_csv(os.path.join(node_line_dir, 'summary.csv'), index=False)\n\n    # Return the best result dataframe\n    return best_result['result']"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Initialize lists to store results and execution times\n    results = []\n    execution_times = []\n\n    # Iterate over each module and its parameters\n    for i, (module, params) in enumerate(zip(modules, module_params)):\n        logger.info(f\"Running retrieval module {i+1}/{len(modules)}\")\n\n        # Run the retrieval module and measure its execution time\n        result, execution_time = measure_speed(module, params)\n\n        # Filter the result based on specified speed threshold\n        result = filter_by_threshold(result, strategies.get(\"speed_threshold\"))\n\n        # Evaluate the result based on previous result and specified metrics\n        evaluation_metrics = evaluate_retrieval(result, previous_result, strategies.get(\"metrics\"))\n\n        # Save the result and execution time\n        results.append(result)\n        execution_times.append(execution_time)\n\n        # Log the evaluation metrics\n        logger.info(f\"Evaluation metrics for module {i+1}/{len(modules)}: {evaluation_metrics}\")\n\n    # Select the best result based on the specified strategy\n    best_result = select_best_average(results, execution_times)\n\n    # Save the best result and a summary of execution times and evaluation metrics to disk\n    result_summary = pd.DataFrame({\"Execution Time\": execution_times, \"Evaluation Metrics\": evaluation_metrics})\n    result_summary.to_csv(os.path.join(node_line_dir, \"summary.csv\"), index=False)\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"), index=False)\n\n    # Return the best result dataframe, which combines the previous result columns with the selected retrieval node's result columns\n    return best_result"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Initialize empty list to store results\n    results = []\n\n    # Iterate through each module and its parameters\n    for module, params in zip(modules, module_params):\n        # Execute the module with the given parameters\n        result = module(**params)\n\n        # Measure the execution time of the module\n        speed = measure_speed(result)\n\n        # Filter the result based on speed threshold if specified in strategies\n        if 'speed_threshold' in strategies:\n            result = filter_by_threshold(result, speed, strategies['speed_threshold'])\n\n        # Evaluate the result based on previous result if specified in strategies\n        if 'evaluation_metrics' in strategies:\n            evaluation_result = evaluate_retrieval(result, previous_result, strategies['evaluation_metrics'])\n            result = pd.concat([result, evaluation_result], axis=1)\n\n        # Append the result to the list of results\n        results.append(result)\n\n    # Select the best result based on specified strategy\n    best_result = select_best_average(results)\n\n    # Save the best result and summary of execution times and evaluation metrics to disk\n    best_result.to_csv(os.path.join(node_line_dir, 'best_result.csv'), index=False)\n    summary = load_summary_file(node_line_dir)\n    summary.to_csv(os.path.join(node_line_dir, 'summary.csv'), index=False)\n\n    return best_result"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Initialize empty list to store results\n    results = []\n\n    # Loop through each module and its parameters\n    for module, params in zip(modules, module_params):\n        # Run the retrieval module with the given parameters\n        result = module(previous_result, **params)\n        \n        # Measure the speed of the retrieval module\n        speed = measure_speed(result)\n        \n        # Apply speed threshold filtering\n        result = filter_by_threshold(result, speed, strategies['speed_threshold'])\n        \n        # Evaluate the retrieval module\n        evaluation_metrics = evaluate_retrieval(result, previous_result, strategies['evaluation_metrics'])\n        \n        # Combine the evaluation metrics and speed into a single dictionary\n        result_summary = {**evaluation_metrics, 'speed': speed}\n        \n        # Append the result and its summary to the results list\n        results.append((result, result_summary))\n\n    # Select the best result based on the specified strategy\n    best_result, best_summary = select_best_average(results, strategies['selection_strategy'])\n\n    # Save the best result and its summary to disk\n    best_result.to_csv(os.path.join(node_line_dir, 'best_result.csv'), index=False)\n    pd.DataFrame([best_summary]).to_csv(os.path.join(node_line_dir, 'summary.csv'), index=False)\n\n    # Return the best result dataframe\n    return best_result"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Run each retrieval module with given parameters\n    results = []\n    for i, module in enumerate(modules):\n        params = module_params[i]\n        result = module(previous_result, **params)\n        results.append(result)\n\n    # Measure execution times\n    execution_times = measure_speed(results)\n\n    # Apply specified strategies\n    filtered_results = filter_by_threshold(results, strategies)\n    best_result = select_best_average(filtered_results)\n\n    # Save the results and a summary of the execution times and evaluation metrics to disk\n    os.makedirs(node_line_dir, exist_ok=True)\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"), index=False)\n    pd.DataFrame(execution_times).to_csv(os.path.join(node_line_dir, \"execution_times.csv\"), index=False)\n    evaluation_metrics = evaluate_retrieval(best_result, previous_result)\n    pd.DataFrame(evaluation_metrics).to_csv(os.path.join(node_line_dir, \"evaluation_metrics.csv\"), index=False)\n\n    # Return the best result dataframe\n    return best_result"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Initialize empty list to store results\n    results = []\n\n    # Iterate through each module and its parameters\n    for module, params in zip(modules, module_params):\n        # Run the retrieval module with the given parameters\n        result = module(previous_result, **params)\n\n        # Measure the execution time of the retrieval module\n        execution_time = measure_speed(module, previous_result, **params)\n\n        # Apply speed threshold filtering if specified in strategies\n        if 'speed_threshold' in strategies:\n            result = filter_by_threshold(result, execution_time, strategies['speed_threshold'])\n\n        # Evaluate the retrieval module result\n        evaluation_metrics = evaluate_retrieval(result, previous_result)\n\n        # Append the result, execution time, and evaluation metrics to the results list\n        results.append((result, execution_time, evaluation_metrics))\n\n    # Select the best retrieval module result based on the specified strategies\n    best_result = select_best_average(results, strategies['metrics'])\n\n    # Save the results and a summary of the execution times and evaluation metrics to disk\n    save_summary_file(results, node_line_dir)\n\n    # Return the best result dataframe, which combines the previous result columns with the selected retrieval node's result columns\n    return best_result"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Initialize lists to store results and execution times\n    results = []\n    execution_times = []\n\n    # Loop through each module and its parameters\n    for i, (module, params) in enumerate(zip(modules, module_params)):\n        logger.info(f\"Running retrieval module {i + 1}/{len(modules)}\")\n\n        # Run the retrieval module and measure execution time\n        result, exec_time = measure_speed(module, params, previous_result)\n\n        # Apply filtering strategy if specified\n        if \"filter_threshold\" in strategies:\n            result = filter_by_threshold(result, strategies[\"filter_threshold\"])\n\n        # Add the result and execution time to the lists\n        results.append(result)\n        execution_times.append(exec_time)\n\n    # Select the best result based on the specified strategy\n    best_result = select_best_average(results, strategies[\"evaluation_metric\"])\n\n    # Save the results and summary to disk\n    result_file_path = os.path.join(node_line_dir, \"retrieval_results.csv\")\n    summary_file_path = os.path.join(node_line_dir, \"retrieval_summary.csv\")\n    best_result.to_csv(result_file_path, index=False)\n    load_summary_file(execution_times, strategies[\"evaluation_metric\"]).to_csv(summary_file_path, index=False)\n\n    # Return the best result dataframe\n    return best_result"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Initialize empty list to store results\n    results = []\n\n    # Loop through each module and its parameters\n    for i, module in enumerate(modules):\n        params = module_params[i]\n\n        # Run the module and measure its execution time\n        result, execution_time = measure_speed(module, params)\n\n        # Apply any specified filtering strategies\n        result = filter_by_threshold(result, strategies)\n\n        # Evaluate the result using the previous result as context\n        evaluation_metrics = evaluate_retrieval(result, previous_result)\n\n        # Save the result and its evaluation metrics to disk\n        result.to_csv(os.path.join(node_line_dir, f\"result_{i}.csv\"), index=False)\n        evaluation_metrics.to_csv(os.path.join(node_line_dir, f\"evaluation_metrics_{i}.csv\"), index=False)\n\n        # Add the result and its evaluation metrics to the list of results\n        results.append((result, evaluation_metrics, execution_time))\n\n    # Select the best result based on the specified strategies\n    best_result_index = select_best_average(results, strategies)\n\n    # Return the best result dataframe, which combines the previous result columns with the selected retrieval node's result columns\n    best_result = results[best_result_index][0]\n    return best_result"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "\n    # Normalize scores\n    normalized_scores = []\n    for s in scores:\n        max_score = max(s)\n        normalized = [score / max_score for score in s]\n        normalized_scores.append(normalized)\n\n    # Combine scores using convex combination\n    fused_scores = []\n    for i in range(len(ids[0])):\n        combined_score = sum([normalized_scores[j][i] * weights[j] for j in range(len(weights))])\n        fused_scores.append(combined_score)\n\n    # Select top_k results\n    fused_results = [(i, s) for i, s in zip(ids[0], fused_scores)]\n    fused_results.sort(key=lambda x: x[1], reverse=True)\n    fused_ids = [result[0] for result in fused_results[:top_k]]\n    fused_scores = [result[1] for result in fused_results[:top_k]]\n\n    return [fused_ids], [fused_scores]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "\n    # Normalize scores\n    normalized_scores = []\n    for score_list in scores:\n        total_score = sum(score_list)\n        normalized_score_list = [score / total_score for score in score_list]\n        normalized_scores.append(normalized_score_list)\n\n    # Combine scores using convex combination\n    fused_scores = []\n    for i in range(len(ids[0])):\n        combined_score = sum(normalized_scores[j][i] * weights[j] for j in range(len(ids)))\n        fused_scores.append(combined_score)\n\n    # Select top_k results\n    fused_results = list(zip(ids[0], fused_scores))\n    fused_results.sort(key=lambda x: x[1], reverse=True)\n    fused_ids = [result[0] for result in fused_results[:top_k]]\n    fused_scores = [result[1] for result in fused_results[:top_k]]\n\n    return [fused_ids], [fused_scores]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Combine scores using convex combination\n    combined_scores = []\n    for i in range(len(ids)):\n        combined_scores.append([weights[i] * score for score in scores[i]])\n\n    # Normalize combined scores\n    normalized_scores = []\n    for i in range(len(ids)):\n        total_score = sum(combined_scores[i])\n        normalized_scores.append([score / total_score for score in combined_scores[i]])\n\n    # Fuse ids and scores\n    fused_ids = list(set([id for sublist in ids for id in sublist]))\n    fused_scores = {id: 0 for id in fused_ids}\n\n    for i in range(len(ids)):\n        for j in range(len(ids[i])):\n            fused_scores[ids[i][j]] += normalized_scores[i][j]\n\n    # Select top_k results\n    fused_ids = sorted(fused_ids, key=lambda x: fused_scores[x], reverse=True)[:top_k]\n    fused_scores = [fused_scores[id] for id in fused_ids]\n\n    return fused_ids, fused_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "\n    # Normalize scores\n    normalized_scores = []\n    for i in range(len(scores)):\n        total_score = sum(scores[i])\n        normalized = [s / total_score for s in scores[i]]\n        normalized_scores.append(normalized)\n\n    # Combine scores using weights\n    combined_scores = [sum([w * s for w, s in zip(weights, score)]) for score in zip(*normalized_scores)]\n\n    # Select top_k results\n    combined_results = sorted(zip(ids, combined_scores), key=lambda x: x[1], reverse=True)[:top_k]\n\n    # Unzip the combined results\n    fused_ids, fused_scores = zip(*combined_results)\n\n    return list(fused_ids), list(fused_scores)"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    \n    # Normalize scores\n    normalized_scores = []\n    for i in range(len(scores)):\n        total_score = sum(scores[i])\n        normalized = [s / total_score for s in scores[i]]\n        normalized_scores.append(normalized)\n    \n    # Combine scores using convex combination\n    combined_scores = []\n    for i in range(len(ids[0])):\n        score = sum([normalized_scores[j][i] * weights[j] for j in range(len(weights))])\n        combined_scores.append(score)\n    \n    # Select top_k results\n    sorted_results = sorted(zip(ids[0], combined_scores), key=lambda x: x[1], reverse=True)[:top_k]\n    fused_ids = [result[0] for result in sorted_results]\n    fused_scores = [result[1] for result in sorted_results]\n    \n    return [fused_ids], [fused_scores]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "\n    # Normalize scores\n    normalized_scores = []\n    for i in range(len(scores)):\n        total_score = sum(scores[i])\n        normalized = [s / total_score for s in scores[i]]\n        normalized_scores.append(normalized)\n\n    # Combine scores using convex combination\n    combined_scores = [sum(w * s for w, s in zip(weights, score)) for score in zip(*normalized_scores)]\n\n    # Select top_k results\n    combined_results = [(i, s) for i, s in zip(zip(*ids), combined_scores)]\n    combined_results.sort(key=lambda x: x[1], reverse=True)\n    selected_results = combined_results[:top_k]\n\n    # Split the selected results back into ids and scores\n    selected_ids, selected_scores = zip(*selected_results)\n\n    return list(selected_ids), list(selected_scores)"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "\n    # Normalize scores\n    normalized_scores = []\n    for score_list in scores:\n        max_score = max(score_list)\n        normalized_score_list = [score / max_score for score in score_list]\n        normalized_scores.append(normalized_score_list)\n\n    # Combine scores using convex combination\n    fused_scores = []\n    for i in range(len(ids[0])):\n        combined_score = 0\n        for j in range(len(ids)):\n            combined_score += normalized_scores[j][i] * weights[j]\n        fused_scores.append(combined_score)\n\n    # Select top_k results\n    fused_results = [(id, score) for id, score in zip(ids[0], fused_scores)]\n    fused_results.sort(key=lambda x: x[1], reverse=True)\n    top_k_results = fused_results[:top_k]\n\n    # Separate ids and scores into separate lists\n    fused_ids = [result[0] for result in top_k_results]\n    fused_scores = [result[1] for result in top_k_results]\n\n    return [fused_ids], [fused_scores]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "\n    # Normalize the scores\n    normalized_scores = []\n    for score_list in scores:\n        total_score = sum(score_list)\n        normalized_scores.append([score / total_score for score in score_list])\n\n    # Combine the scores using the provided weights\n    fused_scores = []\n    for i in range(len(ids)):\n        fused_score = [normalized_scores[j][i] * weights[j] for j in range(len(normalized_scores))]\n        fused_scores.append(sum(fused_score))\n\n    # Select the top_k results\n    fused_results = [(id, score) for id, score in zip(ids[0], fused_scores)]\n    fused_results.sort(key=lambda x: x[1], reverse=True)\n    fused_results = fused_results[:top_k]\n\n    # Split the fused results back into ids and scores\n    fused_ids = [result[0] for result in fused_results]\n    fused_scores = [result[1] for result in fused_results]\n\n    return [fused_ids], [fused_scores]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "\n    # Normalize scores\n    normalized_scores = []\n    for score_list in scores:\n        total_score = sum(score_list)\n        normalized_score_list = [score / total_score for score in score_list]\n        normalized_scores.append(normalized_score_list)\n\n    # Combine scores using weights\n    combined_scores = []\n    for i in range(len(ids)):\n        combined_score_list = [normalized_scores[i][j] * weights[i] for j in range(len(normalized_scores[i]))]\n        combined_scores.append(combined_score_list)\n\n    # Fuse ids and scores\n    fused_ids = []\n    fused_scores = []\n    for i in range(len(ids[0])):\n        id_list = [ids[j][i] for j in range(len(ids))]\n        score_list = [sum(combined_scores[j][i] for j in range(len(combined_scores))]\n                      for i in range(len(combined_scores[0]))]\n        fused_ids.append(id_list)\n        fused_scores.append(score_list)\n\n    # Select top_k results\n    top_k_results = []\n    for i in range(len(fused_ids)):\n        zipped = list(zip(fused_ids[i], fused_scores[i]))\n        sorted_zipped = sorted(zipped, key=lambda x: x[1], reverse=True)\n        top_k_results.append(sorted_zipped[:top_k])\n\n    return top_k_results"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "\n    # Normalize scores\n    normalized_scores = []\n    for score_list in scores:\n        min_score = min(score_list)\n        max_score = max(score_list)\n        normalized = [(score - min_score) / (max_score - min_score) for score in score_list]\n        normalized_scores.append(normalized)\n\n    # Combine scores using convex combination\n    fused_scores = []\n    for i in range(len(ids)):\n        combined_score = [normalized_scores[j][i] * weights[j] for j in range(len(normalized_scores))]\n        fused_scores.append(combined_score)\n\n    # Select top_k results\n    selected_ids = []\n    selected_scores = []\n    for i in range(len(ids[0])):\n        combined_score = sum([fused_scores[j][i] for j in range(len(fused_scores))])\n        selected_ids.append([ids[j][i] for j in range(len(ids))])\n        selected_scores.append(combined_score)\n\n    # Sort and select top_k\n    selected_results = [(x, y) for x, y in sorted(zip(selected_ids, selected_scores), key=lambda pair: pair[1], reverse=True)[:top_k]]\n    fused_ids = [list(result[0]) for result in selected_results]\n    fused_scores = [result[1] for result in selected_results]\n\n    return fused_ids, fused_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "\n    # Normalize scores\n    normalized_scores = []\n    for i in range(len(scores)):\n        total_score = sum(scores[i])\n        normalized_scores.append([s / total_score for s in scores[i]])\n\n    # Combine scores using convex combination method\n    fused_scores = []\n    for j in range(len(ids[0])):\n        combined_score = 0\n        for i in range(len(ids)):\n            combined_score += weights[i] * normalized_scores[i][j]\n        fused_scores.append(combined_score)\n\n    # Select top_k results\n    fused_results = [(x, y) for x, y in sorted(zip(ids[0], fused_scores), key=lambda pair: pair[1], reverse=True)[:top_k]]\n    fused_ids = [result[0] for result in fused_results]\n    fused_scores = [result[1] for result in fused_results]\n\n    return [fused_ids], [fused_scores]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    \n    # Normalize scores\n    normalized_scores = []\n    for i in range(len(scores)):\n        total_score = sum(scores[i])\n        normalized_scores.append([score / total_score for score in scores[i]])\n    \n    # Combine scores using weights\n    combined_scores = [sum([normalized_scores[j][k] * weights[j] for j in range(len(weights))]) for k in range(len(normalized_scores[0]))]\n    \n    # Select top_k results\n    combined_results = [(id, score) for id, score in zip(ids[0], combined_scores)]\n    combined_results.sort(key=lambda x: x[1], reverse=True)\n    fused_ids = [result[0] for result in combined_results[:top_k]]\n    fused_scores = [result[1] for result in combined_results[:top_k]]\n    \n    return [fused_ids], [fused_scores]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "\n    # Normalize scores\n    normalized_scores = []\n    for score_list in scores:\n        max_score = max(score_list)\n        normalized = [score / max_score for score in score_list]\n        normalized_scores.append(normalized)\n\n    # Combine scores using convex combination\n    fused_scores = []\n    for i in range(len(ids)):\n        weighted_scores = [score * weights[i] for score in normalized_scores[i]]\n        if i == 0:\n            fused_scores = weighted_scores\n        else:\n            fused_scores = [a + b for a, b in zip(fused_scores, weighted_scores)]\n\n    # Select top_k results\n    fused_results = [(id, score) for id, score in zip(ids[0], fused_scores)]\n    fused_results.sort(key=lambda x: x[1], reverse=True)\n    fused_ids = [result[0] for result in fused_results[:top_k]]\n    fused_scores = [result[1] for result in fused_results[:top_k]]\n\n    return [fused_ids], [fused_scores]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "\n    # Normalize scores\n    normalized_scores = []\n    for i in range(len(scores)):\n        total_score = sum(scores[i])\n        normalized = [s / total_score for s in scores[i]]\n        normalized_scores.append(normalized)\n\n    # Combine scores using convex combination\n    fused_scores = []\n    for i in range(len(ids[0])):\n        combined_score = sum([normalized_scores[j][i] * weights[j] for j in range(len(scores))])\n        fused_scores.append(combined_score)\n\n    # Select top_k results\n    sorted_results = sorted(zip(ids[0], fused_scores), key=lambda x: x[1], reverse=True)[:top_k]\n    fused_ids = [result[0] for result in sorted_results]\n    fused_scores = [result[1] for result in sorted_results]\n\n    return [fused_ids], [fused_scores]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "\n    # Normalize and combine scores based on weights\n    normalized_scores = []\n    for i in range(len(ids)):\n        normalized_scores.append([score * weights[i] for score in scores[i]])\n\n    fused_scores = [sum(x) for x in zip(*normalized_scores)]\n\n    # Select top_k results\n    fused_results = [(x, y) for x, y in sorted(zip(ids[0], fused_scores), key=lambda pair: pair[1], reverse=True)[:top_k]]\n\n    fused_ids = [result[0] for result in fused_results]\n    fused_scores = [result[1] for result in fused_results]\n\n    return [fused_ids], [fused_scores]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "\n    # Normalize scores\n    normalized_scores = []\n    for score_list in scores:\n        total_score = sum(score_list)\n        normalized_scores.append([score / total_score for score in score_list])\n\n    # Combine scores using convex combination\n    fused_scores = []\n    for i in range(len(ids[0])):\n        combined_score = sum([weight * normalized_scores[j][i] for j, weight in enumerate(weights)])\n        fused_scores.append(combined_score)\n\n    # Select top_k results\n    fused_results = [(id, score) for id, score in zip(ids[0], fused_scores)]\n    fused_results.sort(key=lambda x: x[1], reverse=True)\n    fused_results = fused_results[:top_k]\n\n    # Split ids and scores into separate lists\n    fused_ids = [result[0] for result in fused_results]\n    fused_scores = [result[1] for result in fused_results]\n\n    return [fused_ids], [fused_scores]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Normalize scores\n    normalized_scores = []\n    for i in range(len(ids)):\n        max_score = max(scores[i])\n        normalized_scores.append([s / max_score for s in scores[i]])\n\n    # Combine scores\n    combined_scores = [sum([w * s for w, s in zip(weights, score)]) for score in zip(*normalized_scores)]\n\n    # Select top_k results\n    top_indices = sorted(range(len(combined_scores)), key=lambda i: combined_scores[i], reverse=True)[:top_k]\n\n    # Retrieve top_k results\n    fused_ids = [[ids[i][idx] for i in range(len(ids))] for idx in top_indices]\n    fused_scores = [combined_scores[idx] for idx in top_indices]\n\n    return fused_ids, fused_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Combine scores based on weights\n    combined_scores = [w * pd.Series(score) for w, score in zip(weights, scores)]\n    fused_scores = pd.concat(combined_scores, axis=1).sum(axis=1)\n\n    # Combine IDs\n    fused_ids = sum(ids, [])\n\n    # Combine IDs and scores\n    combined_results = list(zip(fused_ids, fused_scores))\n    combined_results.sort(key=lambda x: x[1], reverse=True)\n\n    # Select top_k results\n    top_results = combined_results[:top_k]\n\n    # Separate IDs and scores\n    fused_ids = [result[0] for result in top_results]\n    fused_scores = [result[1] for result in top_results]\n\n    return fused_ids, fused_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "\n    # Normalize scores\n    normalized_scores = []\n    for i in range(len(scores)):\n        total_score = sum(scores[i])\n        normalized = [s / total_score for s in scores[i]]\n        normalized_scores.append(normalized)\n\n    # Combine scores using convex combination\n    combined_scores = [sum(w * s for w, s in zip(weights, score)) for score in zip(*normalized_scores)]\n\n    # Select top_k results\n    combined_results = [(id, score) for id, score in zip(ids, combined_scores)]\n    combined_results.sort(key=lambda x: x[1], reverse=True)\n    fused_ids = [result[0] for result in combined_results[:top_k]]\n    fused_scores = [result[1] for result in combined_results[:top_k]]\n\n    return fused_ids, fused_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check if the length of ids, scores, and weights tuples match\n    assert len(ids) == len(scores) == len(weights), \"Length of ids, scores, and weights tuples must match\"\n\n    # Normalize scores for each retrieval result based on the provided weights\n    normalized_scores = []\n    for i in range(len(ids)):\n        max_score = max(scores[i])\n        normalized_scores.append([score * weights[i] / max_score for score in scores[i]])\n\n    # Combine the normalized scores\n    combined_scores = [sum(x) for x in zip(*normalized_scores)]\n\n    # Select top_k results\n    combined_results = sorted(zip(combined_scores, ids), reverse=True)[:top_k]\n\n    # Unzip the combined results\n    fused_scores, fused_ids = zip(*combined_results)\n\n    return list(fused_ids), list(fused_scores)"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "\n    # Calculate the weighted sum of scores for each ID\n    weighted_sums = [sum(score * weight for score, weight in zip(score_list, weights)) for score_list in scores]\n\n    # Normalize the weighted sums\n    normalized_sums = [(x - min(weighted_sums)) / (max(weighted_sums) - min(weighted_sums)) for x in weighted_sums]\n\n    # Get the top K IDs and their corresponding scores based on the weighted sum\n    top_indices = sorted(range(len(normalized_sums)), key=lambda i: normalized_sums[i], reverse=True)[:top_k]\n    top_ids = [ids[i] for i in top_indices]\n    top_scores = [normalized_sums[i] for i in top_indices]\n\n    return top_ids, top_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "\n    # Calculate the weighted sum of scores for each ID\n    weighted_sums = [sum(w * s for w, s in zip(weights, score_list)) for score_list in zip(*scores)]\n\n    # Normalize the weighted sums\n    normalized_sums = [(x - min(weighted_sums)) / (max(weighted_sums) - min(weighted_sums)) for x in weighted_sums]\n\n    # Get the top K IDs and their corresponding normalized sums\n    top_k_indices = sorted(range(len(normalized_sums)), key=lambda i: normalized_sums[i], reverse=True)[:top_k]\n    top_k_ids = [ids[i] for i in top_k_indices]\n    top_k_scores = [normalized_sums[i] for i in top_k_indices]\n\n    return top_k_ids, top_k_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "\n    # Calculate the weighted sum of scores for each ID\n    weighted_sums = [sum(w * s for w, s in zip(weights, score)) for score in zip(*scores)]\n\n    # Normalize the weighted sums\n    normalized_sums = [(x - min(weighted_sums)) / (max(weighted_sums) - min(weighted_sums)) for x in weighted_sums]\n\n    # Get the top K IDs based on the normalized weighted sums\n    top_indices = sorted(range(len(normalized_sums)), key=lambda i: normalized_sums[i], reverse=True)[:top_k]\n    top_ids = [ids[i] for i in top_indices]\n    top_scores = [normalized_sums[i] for i in top_indices]\n\n    return top_ids, top_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "\n    weighted_sums = []\n    for i in range(len(ids)):\n        weighted_sum = sum([score * weights[i] for score in scores[i]])\n        weighted_sums.append(weighted_sum)\n\n    # Normalize the weighted sums\n    normalized_weighted_sums = [(x - min(weighted_sums)) / (max(weighted_sums) - min(weighted_sums)) for x in weighted_sums]\n\n    # Get the top K IDs and their corresponding normalized weighted sums\n    top_k_indices = sorted(range(len(normalized_weighted_sums)), key=lambda i: normalized_weighted_sums[i], reverse=True)[:top_k]\n    top_k_ids = [ids[i] for i in top_k_indices]\n    top_k_scores = [normalized_weighted_sums[i] for i in top_k_indices]\n\n    return top_k_ids, top_k_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "\n    weighted_sums = []\n    for i in range(len(ids)):\n        weighted_sum = sum([score * weights[i] for score in scores[i]])\n        weighted_sums.append(weighted_sum)\n\n    normalized_weighted_sums = [(x - min(weighted_sums)) / (max(weighted_sums) - min(weighted_sums)) for x in weighted_sums]\n\n    top_k_indices = sorted(range(len(normalized_weighted_sums)), key=lambda i: normalized_weighted_sums[i], reverse=True)[:top_k]\n\n    top_k_ids = [ids[i] for i in top_k_indices]\n    top_k_scores = [normalized_weighted_sums[i] for i in top_k_indices]\n\n    return top_k_ids, top_k_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "\n    # Calculate the weighted sum of scores for each ID\n    weighted_sums = [sum(w * s for w, s in zip(weights, score)) for score in zip(*scores)]\n\n    # Normalize the weighted sums\n    max_sum = max(weighted_sums)\n    normalized_sums = [s / max_sum for s in weighted_sums]\n\n    # Get the top K IDs and their corresponding scores based on the weighted sum\n    top_k_indices = sorted(range(len(normalized_sums)), key=lambda i: normalized_sums[i], reverse=True)[:top_k]\n    top_k_ids = [ids[i] for i in top_k_indices]\n    top_k_scores = [normalized_sums[i] for i in top_k_indices]\n\n    return top_k_ids, top_k_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "\n    # Calculate the weighted sum of scores for each ID\n    weighted_sums = [sum([score * weight for score, weight in zip(score_list, weights)]) for score_list in scores]\n\n    # Normalize the weighted sums\n    normalized_sums = [(sum - min(weighted_sums)) / (max(weighted_sums) - min(weighted_sums)) for sum in weighted_sums]\n\n    # Sort and return the top K IDs and their corresponding scores\n    top_k_indices = sorted(range(len(normalized_sums)), key=lambda i: normalized_sums[i], reverse=True)[:top_k]\n    top_k_ids = [ids[i] for i in top_k_indices]\n    top_k_scores = [normalized_sums[i] for i in top_k_indices]\n\n    return top_k_ids, top_k_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "\n    # Calculate the weighted sum of scores for each ID\n    weighted_sums = [sum(w * s for w, s in zip(weights, score_list)) for score_list in zip(*scores)]\n\n    # Normalize the weighted sums\n    normalized_sums = [(x - min(weighted_sums)) / (max(weighted_sums) - min(weighted_sums)) for x in weighted_sums]\n\n    # Get the top K IDs and their corresponding scores based on the weighted sum\n    top_k_indices = sorted(range(len(normalized_sums)), key=lambda i: normalized_sums[i], reverse=True)[:top_k]\n    top_k_ids = [ids[i] for i in top_k_indices]\n    top_k_scores = [normalized_sums[i] for i in top_k_indices]\n\n    return top_k_ids, top_k_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "\n    # Calculate the weighted sum of scores for each ID\n    weighted_sums = [sum(score * weight for score, weight in zip(score_list, weights)) for score_list in scores]\n\n    # Normalize the weighted sums\n    normalized_sums = [sum(weighted_sums) for _ in weighted_sums]\n    normalized_weighted_sums = [sum / normalized_sum for sum, normalized_sum in zip(weighted_sums, normalized_sums)]\n\n    # Get the top K IDs based on the normalized weighted sums\n    top_k_indices = sorted(range(len(normalized_weighted_sums)), key=lambda i: normalized_weighted_sums[i], reverse=True)[:top_k]\n    top_k_ids = [ids[i] for i in top_k_indices]\n    top_k_scores = [normalized_weighted_sums[i] for i in top_k_indices]\n\n    return top_k_ids, top_k_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "\n    # Calculate the weighted sum of scores for each ID\n    weighted_sums = [sum([score * weight for score, weight in zip(score_list, weights)]) for score_list in scores]\n\n    # Normalize the weighted sums\n    normalized_sums = [(x - min(weighted_sums)) / (max(weighted_sums) - min(weighted_sums)) for x in weighted_sums]\n\n    # Get the indices of the top K IDs based on the normalized weighted sums\n    top_indices = sorted(range(len(normalized_sums)), key=lambda i: normalized_sums[i], reverse=True)[:top_k]\n\n    # Return the top K IDs and their corresponding scores\n    top_ids = [ids[i] for i in top_indices]\n    top_scores = [normalized_sums[i] for i in top_indices]\n\n    return top_ids, top_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "\n    # Calculate the weighted sum of scores for each ID\n    weighted_sums = [sum([score * weight for score, weight in zip(score_list, weights)]) for score_list in scores]\n\n    # Normalize the scores\n    normalized_scores = [(score - min(weighted_sums)) / (max(weighted_sums) - min(weighted_sums)) for score in weighted_sums]\n\n    # Get the top K IDs and their corresponding scores based on the weighted sum\n    top_indices = sorted(range(len(normalized_scores)), key=lambda i: normalized_scores[i], reverse=True)[:top_k]\n    top_ids = [ids[i] for i in top_indices]\n    top_scores = [normalized_scores[i] for i in top_indices]\n\n    return top_ids, top_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "\n    weighted_sums = []\n    for i in range(len(ids)):\n        weighted_sum = sum([score * weights[i] for score in scores[i]])\n        weighted_sums.append(weighted_sum)\n\n    normalized_weighted_sums = [(x - min(weighted_sums)) / (max(weighted_sums) - min(weighted_sums)) for x in weighted_sums]\n\n    sorted_ids = [id for _, id in sorted(zip(normalized_weighted_sums, ids), reverse=True)]\n    sorted_scores = [score for score, _ in sorted(zip(normalized_weighted_sums, scores), reverse=True)]\n\n    return sorted_ids[:top_k], sorted_scores[:top_k]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "\n    weighted_sums = []\n    for i in range(len(ids)):\n        weighted_sum = sum([score * weights[i] for score in scores[i]])\n        weighted_sums.append(weighted_sum)\n\n    normalized_weighted_sums = [(x - min(weighted_sums)) / (max(weighted_sums) - min(weighted_sums)) for x in weighted_sums]\n\n    top_k_indices = sorted(range(len(normalized_weighted_sums)), key=lambda i: normalized_weighted_sums[i], reverse=True)[:top_k]\n\n    top_k_ids = [ids[i] for i in top_k_indices]\n    top_k_scores = [normalized_weighted_sums[i] for i in top_k_indices]\n\n    return top_k_ids, top_k_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "\n    # Calculate the weighted sum of scores for each ID\n    weighted_sums = [sum(score * weight for score, weight in zip(score_list, weights)) for score_list in scores]\n\n    # Normalize the scores\n    max_weighted_sum = max(weighted_sums)\n    normalized_scores = [weighted_sum / max_weighted_sum for weighted_sum in weighted_sums]\n\n    # Get the top K IDs and their corresponding scores based on the weighted sum\n    top_indices = sorted(range(len(normalized_scores)), key=lambda i: normalized_scores[i], reverse=True)[:top_k]\n    top_ids = [ids[i] for i in top_indices]\n    top_scores = [normalized_scores[i] for i in top_indices]\n\n    return top_ids, top_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "\n    weighted_sums = []\n    for i in range(len(ids)):\n        weighted_sum = sum([score * weights[i] for score in scores[i]])\n        weighted_sums.append(weighted_sum)\n\n    normalized_scores = [(score - min(weighted_sums)) / (max(weighted_sums) - min(weighted_sums)) for score in weighted_sums]\n\n    top_k_indices = sorted(range(len(normalized_scores)), key=lambda i: normalized_scores[i], reverse=True)[:top_k]\n    top_k_ids = [ids[i] for i in top_k_indices]\n    top_k_scores = [normalized_scores[i] for i in top_k_indices]\n\n    return top_k_ids, top_k_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "\n    # Calculate the weighted sum of scores for each ID\n    weighted_sums = [sum(w * s for w, s in zip(weights, score_list)) for score_list in zip(*scores)]\n\n    # Normalize the scores\n    max_weighted_sum = max(weighted_sums)\n    normalized_scores = [ws / max_weighted_sum for ws in weighted_sums]\n\n    # Sort the IDs based on the weighted sum and return the top K IDs and their corresponding scores\n    top_k_indices = sorted(range(len(normalized_scores)), key=lambda i: normalized_scores[i], reverse=True)[:top_k]\n    top_k_ids = [ids[i] for i in top_k_indices]\n    top_k_scores = [normalized_scores[i] for i in top_k_indices]\n\n    return top_k_ids, top_k_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "\n    # Calculate the weighted sum of scores for each ID\n    weighted_sums = [sum(score * weight for score, weight in zip(score_list, weights)) for score_list in scores]\n\n    # Normalize the weighted sums\n    max_sum = max(weighted_sums)\n    normalized_sums = [sum / max_sum for sum in weighted_sums]\n\n    # Get the top K IDs and their corresponding scores based on the weighted sum\n    top_indices = sorted(range(len(normalized_sums)), key=lambda i: normalized_sums[i], reverse=True)[:top_k]\n    top_ids = [ids[i] for i in top_indices]\n    top_scores = [normalized_sums[i] for i in top_indices]\n\n    return top_ids, top_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "\n    weighted_sums = [sum([score * weight for score, weight in zip(score_list, weights)]) for score_list in scores]\n    normalized_sums = [(x - min(weighted_sums)) / (max(weighted_sums) - min(weighted_sums)) for x in weighted_sums]\n\n    sorted_ids = [id for _, id in sorted(zip(normalized_sums, ids), reverse=True)]\n    sorted_scores = sorted(normalized_sums, reverse=True)\n\n    return sorted_ids[:top_k], sorted_scores[:top_k]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "\n    weighted_sums = [sum(score * weight for score, weight in zip(scores[i], weights)) for i in range(len(ids))]\n    normalized_sums = [(sum - min(weighted_sums)) / (max(weighted_sums) - min(weighted_sums)) for sum in weighted_sums]\n\n    top_k_indices = sorted(range(len(normalized_sums)), key=lambda i: normalized_sums[i], reverse=True)[:top_k]\n    top_k_ids = [ids[i] for i in top_k_indices]\n    top_k_scores = [normalized_sums[i] for i in top_k_indices]\n\n    return top_k_ids, top_k_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "\n    weighted_sums = []\n    for i in range(len(ids)):\n        weighted_sum = sum(score * weights[i] for score in scores[i])\n        weighted_sums.append(weighted_sum)\n\n    normalized_weighted_sums = [(x - min(weighted_sums)) / (max(weighted_sums) - min(weighted_sums)) for x in weighted_sums]\n\n    top_k_indices = sorted(range(len(normalized_weighted_sums)), key=lambda i: normalized_weighted_sums[i], reverse=True)[:top_k]\n\n    top_k_ids = [ids[i] for i in top_k_indices]\n    top_k_scores = [normalized_weighted_sums[i] for i in top_k_indices]\n\n    return top_k_ids, top_k_scores"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()  # Clean up the agents\n        return self.agent_lifecycle.agents  # Return the current list of agents"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()  # Clean up the agents\n        return self.agent_lifecycle.agents  # Return the current list of agents"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "\n        self.cleanup_agents()\n        return self.agent_lifecycle.agents"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()  # Clean up the agents\n        return self.agent_lifecycle.agents  # Return the current list of agents"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "\n        self.cleanup_agents()\n        return self.agent_lifecycle.agents"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "\n        self.cleanup_agents()\n        return self.agent_lifecycle.agents"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "\n        self.cleanup_agents()\n        return self.agent_lifecycle.agents"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent.purpose_embedding, np.ndarray):\n            agent.purpose_embedding = agent.purpose_embedding.tolist()\n        return {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": agent.purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent.purpose_embedding, np.ndarray):\n            agent.purpose_embedding = agent.purpose_embedding.tolist()\n        return {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": agent.purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent.purpose_embedding, np.ndarray):\n            agent.purpose_embedding = agent.purpose_embedding.tolist()\n        \n        return {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": agent.purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent.purpose_embedding, np.ndarray):\n            agent.purpose_embedding = agent.purpose_embedding.tolist()\n        return {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": agent.purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent.purpose_embedding, np.ndarray):\n            agent.purpose_embedding = agent.purpose_embedding.tolist()\n        return {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": agent.purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent.purpose_embedding, np.ndarray):\n            agent.purpose_embedding = agent.purpose_embedding.tolist()\n        return {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": agent.purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent.purpose_embedding, np.ndarray):\n            agent.purpose_embedding = agent.purpose_embedding.tolist()\n        return {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": agent.purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent.purpose_embedding, np.ndarray):\n            purpose_embedding = agent.purpose_embedding.tolist()\n        else:\n            purpose_embedding = agent.purpose_embedding\n\n        agent_dict = {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n        return agent_dict"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent.purpose_embedding, np.ndarray):\n            purpose_embedding = agent.purpose_embedding.tolist()\n        else:\n            purpose_embedding = agent.purpose_embedding\n\n        agent_dict = {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n\n        return agent_dict"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent.purpose_embedding, np.ndarray):\n            agent.purpose_embedding = agent.purpose_embedding.tolist()\n        return {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": agent.purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent.purpose_embedding, np.ndarray):\n            purpose_embedding = agent.purpose_embedding.tolist()\n        else:\n            purpose_embedding = agent.purpose_embedding\n\n        agent_dict = {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n        return agent_dict"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent.purpose_embedding, np.ndarray):\n            agent.purpose_embedding = agent.purpose_embedding.tolist()\n        return {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": agent.purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent.purpose_embedding, np.ndarray):\n            purpose_embedding = agent.purpose_embedding.tolist()\n        else:\n            purpose_embedding = agent.purpose_embedding\n\n        agent_dict = {\n            'dynamic_prompt': agent.dynamic_prompt,\n            'purpose': agent.purpose,\n            'purpose_embedding': purpose_embedding,\n            'depth': agent.depth,\n            'max_depth': agent.max_depth,\n            'usage_count': agent.usage_count,\n            'id': agent.id,\n            'parent_id': agent.parent_id,\n            'working_agent': agent.working_agent,\n            'is_prime': agent.is_prime,\n            'evolve_count': agent.evolve_count,\n            'number_of_code_executions': agent.number_of_code_executions,\n            'last_input': agent.last_input\n        }\n        return agent_dict"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent.purpose_embedding, np.ndarray):\n            agent.purpose_embedding = agent.purpose_embedding.tolist()\n        return {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": agent.purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent.purpose_embedding, np.ndarray):\n            agent.purpose_embedding = agent.purpose_embedding.tolist()\n        return {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": agent.purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent.purpose_embedding, np.ndarray):\n            purpose_embedding = agent.purpose_embedding.tolist()\n        else:\n            purpose_embedding = agent.purpose_embedding\n\n        agent_dict = {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n\n        return agent_dict"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent.purpose_embedding, np.ndarray):\n            purpose_embedding = agent.purpose_embedding.tolist()\n        else:\n            purpose_embedding = agent.purpose_embedding\n\n        agent_dict = {\n            'dynamic_prompt': agent.dynamic_prompt,\n            'purpose': agent.purpose,\n            'purpose_embedding': purpose_embedding,\n            'depth': agent.depth,\n            'max_depth': agent.max_depth,\n            'usage_count': agent.usage_count,\n            'id': agent.id,\n            'parent_id': agent.parent_id,\n            'working_agent': agent.working_agent,\n            'is_prime': agent.is_prime,\n            'evolve_count': agent.evolve_count,\n            'number_of_code_executions': agent.number_of_code_executions,\n            'last_input': agent.last_input\n        }\n        return agent_dict"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent.purpose_embedding, np.ndarray):\n            purpose_embedding = agent.purpose_embedding.tolist()\n        else:\n            purpose_embedding = agent.purpose_embedding\n\n        agent_dict = {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n        return agent_dict"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent.purpose_embedding, np.ndarray):\n            agent_dict = agent.__dict__\n            agent_dict['purpose_embedding'] = agent.purpose_embedding.tolist()\n            return agent_dict\n        else:\n            return agent.__dict__"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent.purpose_embedding, np.ndarray):\n            agent.purpose_embedding = agent.purpose_embedding.tolist()\n        return {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": agent.purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {goal}\\n\\n{PROMPT_ENGINEERING_TEMPLATE} {sample_input}\\n\\n{EXAMPLES}\"\n            completion = self.openai_wrapper.get_chat_completion(prompt)\n            return completion\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {goal}\\n{PROMPT_ENGINEERING_TEMPLATE} {sample_input}\\n{EXAMPLES}\"\n            completion = self.openai_wrapper.get_chat_completion(prompt)\n            return completion\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {goal}. {PROMPT_ENGINEERING_TEMPLATE} {sample_input}. {EXAMPLES}\"\n            chat_completion = self.openai_wrapper.get_chat_completion(prompt)\n            return chat_completion\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "\n        try:\n            prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {goal}\\n\\n{PROMPT_ENGINEERING_TEMPLATE}\\n\\n{EXAMPLES}\\n\\n{sample_input}\"\n            chat_completion = self.openai_wrapper.get_chat_completion(prompt)\n            return chat_completion\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {goal}\\n\\n{PROMPT_ENGINEERING_TEMPLATE} {sample_input}\\n\\n{EXAMPLES}\"\n            completion = self.openai_wrapper.get_chat_completion(prompt)\n            return completion\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {goal}\\n{PROMPT_ENGINEERING_TEMPLATE} {sample_input}\\n{EXAMPLES}\"\n            completion = self.openai_wrapper.get_chat_completion(prompt)\n            return completion\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {goal}\\n\\n{PROMPT_ENGINEERING_TEMPLATE}\\n\\n{EXAMPLES}\\n\\n{sample_input}\"\n            chat_completion = self.openai_wrapper.get_chat_completion(prompt)\n            return chat_completion\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {goal}\\n\\n{PROMPT_ENGINEERING_TEMPLATE}\\n\\n{EXAMPLES}\\n\\n{sample_input}\"\n        try:\n            completion = self.openai_wrapper.get_chat_completion(prompt)\n            return completion\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "\n        try:\n            prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {goal}\\n{PROMPT_ENGINEERING_TEMPLATE}\\n{sample_input}\\n{EXAMPLES}\"\n            completion = self.openai_wrapper.get_chat_completion(prompt)\n            return completion\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {goal}\\n{PROMPT_ENGINEERING_TEMPLATE} {sample_input}\\n{EXAMPLES}\"\n            chat_completion = self.openai_wrapper.get_chat_completion(prompt)\n            return chat_completion\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {goal}\\n{PROMPT_ENGINEERING_TEMPLATE} {sample_input}\\n\\n{EXAMPLES}\"\n            chat_completion = self.openai_wrapper.get_chat_completion(prompt)\n            return chat_completion\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {goal}\\n{PROMPT_ENGINEERING_TEMPLATE} {sample_input}\\n{EXAMPLES}\"\n            chat_completion = self.openai_wrapper.get_chat_completion(prompt)\n            return chat_completion\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {goal}\\n{PROMPT_ENGINEERING_TEMPLATE} {sample_input}\\n{EXAMPLES}\"\n            completion = self.openai_wrapper.get_chat_completion(prompt)\n            return completion\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {goal}\\n{PROMPT_ENGINEERING_TEMPLATE} {sample_input}\\n{EXAMPLES}\"\n            completion = self.openai_wrapper.get_chat_completion(prompt)\n            return completion\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {goal}. {PROMPT_ENGINEERING_TEMPLATE} {sample_input}. {EXAMPLES}\"\n            chat_completion = self.openai_wrapper.get_chat_completion(prompt)\n            return chat_completion\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {goal}\\n\\n{PROMPT_ENGINEERING_TEMPLATE} {sample_input}\\n\\n{EXAMPLES}\"\n            completion = self.openai_wrapper.get_chat_completion(prompt)\n            return completion\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} Goal: {goal} | Input: {sample_input} | Template: {PROMPT_ENGINEERING_TEMPLATE} | Examples: {EXAMPLES}\"\n            completion = self.openai_wrapper.get_chat_completion(prompt)\n            return completion\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {goal} {PROMPT_ENGINEERING_TEMPLATE} {sample_input} {EXAMPLES}\"\n            chat_completion = self.openai_wrapper.get_chat_completion(prompt)\n            return chat_completion\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {goal}\\n{PROMPT_ENGINEERING_TEMPLATE}\\n{EXAMPLES}\\nInput: {sample_input}\\nOutput:\"\n            completion = self.openai_wrapper.get_chat_completion(prompt)\n            return completion\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = f\"{PROMPT_ENGINEERING_SYSTEM_PROMPT} {goal}\\n\\n{PROMPT_ENGINEERING_TEMPLATE} {sample_input}\\n\\n{EXAMPLES}\"\n            completion = self.openai_wrapper.get_chat_completion(prompt)\n            return completion\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding is not None and isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding is not None and isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list back to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding is not None and isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding is not None and isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list back to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding is not None:\n            purpose_embedding = np.array(purpose_embedding)  # Convert list back to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding is not None and isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list back to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding is not None and isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding is not None and isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list back to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding is not None and isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding is not None and isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding is not None and isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "\n        # Handle optional keys gracefully\n        dynamic_prompt = data.get(\"dynamic_prompt\")\n        purpose = data.get(\"purpose\")\n        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding is not None:\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n        depth = data.get(\"depth\")\n        max_depth = data.get(\"max_depth\")\n        usage_count = data.get(\"usage_count\")\n        agent_id = data.get(\"id\")\n        parent_id = data.get(\"parent_id\")\n        working_agent = data.get(\"working_agent\")\n        is_prime = data.get(\"is_prime\")\n        evolve_count = data.get(\"evolve_count\")\n        number_of_code_executions = data.get(\"number_of_code_executions\")\n        last_input = data.get(\"last_input\")\n\n        # Create and return the MicroAgent object with the deserialized attributes\n        return MicroAgent(dynamic_prompt, purpose, purpose_embedding, depth, max_depth, usage_count, agent_id, parent_id, working_agent, is_prime, evolve_count, number_of_code_executions, last_input, agent_lifecycle, openai_wrapper)"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding is not None and isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding is not None and isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding is not None and isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding is not None and isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding is not None and isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding is not None and isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        agent = MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )\n\n        return agent"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding is not None:\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\")\n        if purpose_embedding is not None and isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\"),\n            purpose=data.get(\"purpose\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\"),\n            max_depth=data.get(\"max_depth\"),\n            usage_count=data.get(\"usage_count\"),\n            id=data.get(\"id\"),\n            parent_id=data.get(\"parent_id\"),\n            working_agent=data.get(\"working_agent\"),\n            is_prime=data.get(\"is_prime\"),\n            evolve_count=data.get(\"evolve_count\"),\n            number_of_code_executions=data.get(\"number_of_code_executions\"),\n            last_input=data.get(\"last_input\"),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT * FROM agents WHERE id = ?\", (agent_dict['id'],))\n            existing_agent = cursor.fetchone()\n            if existing_agent:\n                cursor.execute(\"UPDATE agents SET purpose = ?, data = ? WHERE id = ?\", (agent_dict['purpose'], json.dumps(agent_dict), agent_dict['id']))\n            else:\n                cursor.execute(\"INSERT INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))\n            conn.commit()"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT * FROM agents WHERE id = ?\", (agent_dict['id'],))\n            existing_agent = cursor.fetchone()\n            if existing_agent:\n                cursor.execute(\"UPDATE agents SET purpose = ?, data = ? WHERE id = ?\", (agent_dict['purpose'], json.dumps(agent_dict), agent_dict['id']))\n            else:\n                cursor.execute(\"INSERT INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))\n            conn.commit()"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT * FROM agents WHERE id = ?\", (agent_dict['id'],))\n            existing_agent = cursor.fetchone()\n            if existing_agent:\n                conn.execute(\"UPDATE agents SET purpose = ?, data = ? WHERE id = ?\", (agent_dict['purpose'], json.dumps(agent_dict), agent_dict['id']))\n            else:\n                conn.execute(\"INSERT INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT * FROM agents WHERE id = ?\", (agent_dict['id'],))\n            existing_agent = cursor.fetchone()\n            if existing_agent:\n                conn.execute(\"UPDATE agents SET purpose = ?, data = ? WHERE id = ?\", (agent_dict['purpose'], json.dumps(agent_dict), agent_dict['id']))\n            else:\n                conn.execute(\"INSERT INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"REPLACE INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT id FROM agents WHERE id=?\", (agent_dict['id'],))\n            data = json.dumps(agent_dict)\n            if cursor.fetchone():\n                conn.execute(\"UPDATE agents SET purpose=?, data=? WHERE id=?\", (agent_dict['purpose'], data, agent_dict['id']))\n            else:\n                conn.execute(\"INSERT INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], data))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT id FROM agents WHERE id=?\", (agent_dict['id'],))\n            existing_agent = cursor.fetchone()\n            if existing_agent:\n                conn.execute(\"UPDATE agents SET purpose=?, data=? WHERE id=?\", (agent_dict['purpose'], json.dumps(agent_dict), agent_dict['id']))\n            else:\n                conn.execute(\"INSERT INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT id FROM agents WHERE id = ?\", (agent_dict['id'],))\n            existing_agent = cursor.fetchone()\n            if existing_agent:\n                conn.execute(\"UPDATE agents SET purpose = ?, data = ? WHERE id = ?\", (agent_dict['purpose'], json.dumps(agent_dict), agent_dict['id']))\n            else:\n                conn.execute(\"INSERT INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT id FROM agents WHERE id=?\", (agent_dict['id'],))\n            existing_agent = cursor.fetchone()\n            if existing_agent:\n                conn.execute(\"UPDATE agents SET purpose=?, data=? WHERE id=?\", (agent_dict['purpose'], json.dumps(agent_dict), agent_dict['id']))\n            else:\n                conn.execute(\"INSERT INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT id FROM agents WHERE id = ?\", (agent_dict['id'],))\n            existing_agent = cursor.fetchone()\n            if existing_agent:\n                conn.execute(\"UPDATE agents SET purpose = ?, data = ? WHERE id = ?\", (agent_dict['purpose'], json.dumps(agent_dict), agent_dict['id']))\n            else:\n                conn.execute(\"INSERT INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT id FROM agents WHERE id = ?\", (agent_dict['id'],))\n            existing_agent = cursor.fetchone()\n            if existing_agent:\n                conn.execute(\"UPDATE agents SET purpose = ?, data = ? WHERE id = ?\", (agent_dict['purpose'], json.dumps(agent_dict), agent_dict['id']))\n            else:\n                conn.execute(\"INSERT INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT id FROM agents WHERE id = ?\", (agent_dict['id'],))\n            existing_agent = cursor.fetchone()\n\n            if existing_agent:\n                conn.execute(\"UPDATE agents SET purpose = ?, data = ? WHERE id = ?\", (agent_dict['purpose'], json.dumps(agent_dict), agent_dict['id']))\n            else:\n                conn.execute(\"INSERT INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"REPLACE INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT * FROM agents WHERE id = ?\", (agent_dict['id'],))\n            existing_agent = cursor.fetchone()\n            if existing_agent:\n                cursor.execute(\"UPDATE agents SET purpose = ?, data = ? WHERE id = ?\", (agent_dict['purpose'], json.dumps(agent_dict), agent_dict['id']))\n            else:\n                cursor.execute(\"INSERT INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))\n            conn.commit()"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT id FROM agents WHERE id = ?\", (agent_dict['id'],))\n            data = json.dumps(agent_dict)\n            if cursor.fetchone():\n                conn.execute(\"UPDATE agents SET purpose = ?, data = ? WHERE id = ?\", (agent_dict['purpose'], data, agent_dict['id']))\n            else:\n                conn.execute(\"INSERT INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], data))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT * FROM agents WHERE id = ?\", (agent_dict['id'],))\n            existing_agent = cursor.fetchone()\n            if existing_agent:\n                conn.execute(\"UPDATE agents SET purpose = ?, data = ? WHERE id = ?\", (agent_dict['purpose'], json.dumps(agent_dict), agent_dict['id']))\n            else:\n                conn.execute(\"INSERT INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT * FROM agents WHERE id=?\", (agent_dict['id'],))\n            data = json.dumps(agent_dict)\n            if cursor.fetchone():\n                conn.execute(\"UPDATE agents SET data=? WHERE id=?\", (data, agent_dict['id']))\n            else:\n                conn.execute(\"INSERT INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], data))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT * FROM agents WHERE id = ?\", (agent_dict['id'],))\n            existing_agent = cursor.fetchone()\n            if existing_agent:\n                conn.execute(\"UPDATE agents SET purpose = ?, data = ? WHERE id = ?\", (agent_dict['purpose'], json.dumps(agent_dict), agent_dict['id']))\n            else:\n                conn.execute(\"INSERT INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT * FROM agents WHERE id = ?\", (agent_dict['id'],))\n            existing_agent = cursor.fetchone()\n            if existing_agent:\n                conn.execute(\"UPDATE agents SET purpose = ?, data = ? WHERE id = ?\", (agent_dict['purpose'], json.dumps(agent_dict), agent_dict['id']))\n            else:\n                conn.execute(\"INSERT INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT * FROM agents WHERE id = ?\", (agent_dict['id'],))\n            existing_agent = cursor.fetchone()\n            if existing_agent:\n                cursor.execute(\"UPDATE agents SET purpose = ?, data = ? WHERE id = ?\", (agent_dict['purpose'], json.dumps(agent_dict), agent_dict['id']))\n            else:\n                cursor.execute(\"INSERT INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))\n            conn.commit()"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            agent_data = cursor.fetchone()\n            if agent_data:\n                return json.loads(agent_data[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            agent_data = cursor.fetchone()\n            if agent_data:\n                return json.loads(agent_data[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            agent_data = cursor.fetchone()\n            if agent_data:\n                return json.loads(agent_data[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            agent_data = cursor.fetchone()\n            if agent_data:\n                return json.loads(agent_data[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            row = cursor.fetchone()\n            if row:\n                agent_dict = json.loads(row[0])\n                return agent_dict\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            agent_data = cursor.fetchone()\n            if agent_data:\n                return json.loads(agent_data[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            agent_data = cursor.fetchone()\n            if agent_data:\n                return json.loads(agent_data[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            agent_data = cursor.fetchone()\n            if agent_data:\n                return json.loads(agent_data[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            agent_data = cursor.fetchone()\n            if agent_data:\n                return json.loads(agent_data[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            agent_data = cursor.fetchone()\n            if agent_data:\n                return json.loads(agent_data[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            agent_data = cursor.fetchone()\n            if agent_data:\n                return json.loads(agent_data[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            agent_data = cursor.fetchone()\n            if agent_data:\n                return json.loads(agent_data[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            agent_data = cursor.fetchone()\n            if agent_data:\n                return json.loads(agent_data[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            agent_data = cursor.fetchone()\n            if agent_data:\n                return json.loads(agent_data[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            agent_data = cursor.fetchone()\n            if agent_data:\n                return json.loads(agent_data[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            agent_data = cursor.fetchone()\n            if agent_data:\n                return json.loads(agent_data[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            agent_data = cursor.fetchone()\n            if agent_data:\n                return json.loads(agent_data[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            row = cursor.fetchone()\n            if row:\n                return json.loads(row[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            agent_data = cursor.fetchone()\n            if agent_data:\n                return json.loads(agent_data[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            agent_data = cursor.fetchone()\n            if agent_data:\n                return json.loads(agent_data[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            purposes = [row[0] for row in rows]\n            return purposes"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            purposes = [row[0] for row in rows]\n            return purposes"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            purposes = [row[0] for row in rows]\n            return purposes"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            purposes = [row[0] for row in rows]\n            return purposes"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            purposes = [row[0] for row in rows]\n            return purposes"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            purposes = [row[0] for row in rows]\n            return purposes"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            purposes = [row[0] for row in rows]\n            return purposes"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            purposes = [row[0] for row in rows]\n            return purposes"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        serialized_data = json.dumps(data, sort_keys=True).encode('utf-8')\n        return hashlib.sha256(serialized_data).hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        data_json = json.dumps(data, sort_keys=True).encode('utf-8')\n        return hashlib.sha256(data_json).hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        serialized_data = json.dumps(data, sort_keys=True).encode('utf-8')\n        return hashlib.sha256(serialized_data).hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        serialized_data = json.dumps(data, sort_keys=True).encode('utf-8')\n        return hashlib.sha256(serialized_data).hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        serialized_data = json.dumps(data, sort_keys=True).encode('utf-8')\n        return hashlib.sha256(serialized_data).hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        data_str = json.dumps(data, sort_keys=True)\n        return hashlib.sha256(data_str.encode()).hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        data_str = json.dumps(data, sort_keys=True)\n        return hashlib.sha256(data_str.encode()).hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        data_str = json.dumps(data, sort_keys=True).encode('utf-8')\n        return hashlib.sha256(data_str).hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = {\n            \"func_name\": func_name,\n            \"args\": args,\n            \"kwargs\": kwargs\n        }\n        data_str = json.dumps(data, sort_keys=True)\n        return hashlib.sha256(data_str.encode()).hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        data_str = json.dumps(data, sort_keys=True)\n        return hashlib.sha256(data_str.encode()).hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        data_str = json.dumps(data, sort_keys=True)\n        return hashlib.sha256(data_str.encode()).hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        serialized_data = json.dumps(data, sort_keys=True).encode('utf-8')\n        return hashlib.sha256(serialized_data).hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        serialized_data = json.dumps(data, sort_keys=True).encode('utf-8')\n        return hashlib.sha256(serialized_data).hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        hash_data = {\n            \"func_name\": func_name,\n            \"args\": args,\n            \"kwargs\": kwargs\n        }\n        serialized_data = json.dumps(hash_data, sort_keys=True).encode('utf-8')\n        return hashlib.sha256(serialized_data).hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        hash_data = json.dumps(data, sort_keys=True).encode('utf-8')\n        return hashlib.sha256(hash_data).hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        data_str = json.dumps(data, sort_keys=True)\n        return hashlib.sha256(data_str.encode()).hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = func_name + json.dumps(args) + json.dumps(kwargs)\n        return hashlib.sha256(data.encode()).hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        serialized_data = json.dumps(data, sort_keys=True).encode('utf-8')\n        return hashlib.sha256(serialized_data).hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = func_name + json.dumps(args) + json.dumps(kwargs)\n        return hashlib.sha256(data.encode()).hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        data_json = json.dumps(data, sort_keys=True)\n        return hashlib.sha256(data_json.encode()).hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "    cursor = self.connection.cursor()\n    cursor.execute(\"SELECT result FROM cache WHERE hash=?\", (arg_hash,))\n    row = cursor.fetchone()\n    if row:\n        result_json = row[0]\n        result = json.loads(result_json)\n        return result\n    else:\n        return None"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash=?\", (arg_hash,))\n        row = cursor.fetchone()\n        cursor.close()\n        if row:\n            return json.loads(row[0])\n        else:\n            return None"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "    cursor = self.connection.execute(\n        \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n    )\n    row = cursor.fetchone()\n    if row is not None:\n        return json.loads(row[0])\n    else:\n        return None"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "    cursor = self.connection.execute(\n        \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n    )\n    row = cursor.fetchone()\n    if row is not None:\n        return json.loads(row[0])\n    else:\n        return None"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "    cursor = self.connection.execute(\n        \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n    )\n    row = cursor.fetchone()\n    if row is not None:\n        return json.loads(row[0])\n    else:\n        return None"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.execute(\n            \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n        )\n        row = cursor.fetchone()\n        if row:\n            return json.loads(row[0])\n        else:\n            return None"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "    cursor = self.connection.cursor()\n    cursor.execute(\"SELECT result FROM cache WHERE hash = ?\", (arg_hash,))\n    row = cursor.fetchone()\n    cursor.close()\n\n    if row is not None:\n        return json.loads(row[0])\n    else:\n        return None"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "    cursor = self.connection.execute(\"SELECT result FROM cache WHERE hash=?\", (arg_hash,))\n    row = cursor.fetchone()\n    if row:\n        return json.loads(row[0])\n    else:\n        return None"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "    cursor = self.connection.execute(\n        \"SELECT result FROM cache WHERE hash=?\", (arg_hash,)\n    )\n    row = cursor.fetchone()\n    if row:\n        return json.loads(row[0])\n    else:\n        return None"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "    cursor = self.connection.execute(\n        \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n    )\n    row = cursor.fetchone()\n    if row is not None:\n        return json.loads(row[0])\n    else:\n        return None"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "    cursor = self.connection.execute(\n        \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n    )\n    result = cursor.fetchone()\n    if result:\n        return json.loads(result[0])\n    else:\n        return None"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "    cursor = self.connection.execute(\n        \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n    )\n    row = cursor.fetchone()\n    if row is not None:\n        return json.loads(row[0])\n    else:\n        return None"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "    cursor = self.connection.execute(\n        \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n    )\n    result = cursor.fetchone()\n    if result:\n        return json.loads(result[0])\n    else:\n        return None"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "    cursor = self.connection.execute(\n        \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n    )\n    row = cursor.fetchone()\n    if row is not None:\n        return json.loads(row[0])\n    else:\n        return None"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "    cursor = self.connection.execute(\n        \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n    )\n    result = cursor.fetchone()\n    if result:\n        return json.loads(result[0])\n    else:\n        return None"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "    cursor = self.connection.execute(\n        \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n    )\n    row = cursor.fetchone()\n    if row is not None:\n        result = json.loads(row[0])\n        return result\n    else:\n        return None"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "    cursor = self.connection.execute(\n        \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n    )\n    row = cursor.fetchone()\n    if row is not None:\n        return json.loads(row[0])\n    return None"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "    cursor = self.connection.execute(\"SELECT result FROM cache WHERE hash=?\", (arg_hash,))\n    row = cursor.fetchone()\n    if row:\n        return json.loads(row[0])\n    else:\n        return None"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "    cursor = self.connection.execute(\"SELECT result FROM cache WHERE hash=?\", (arg_hash,))\n    row = cursor.fetchone()\n    if row is not None:\n        return json.loads(row[0])\n    else:\n        return None"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "    cursor = self.connection.execute(\n        \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n    )\n    row = cursor.fetchone()\n    if row is not None:\n        return json.loads(row[0])\n    else:\n        return None"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "        conn = sqlite3.connect(filename)\n        c = conn.cursor()\n        c.execute('''CREATE TABLE IF NOT EXISTS cache (func_name TEXT, args TEXT, result TEXT)''')\n        conn.commit()\n        conn.close()\n\n        @functools.wraps(func)\n        def memoized_func(*args):\n            args_str = json.dumps(args)\n            key = hashlib.md5(func_name.encode('utf-8') + args_str.encode('utf-8')).hexdigest()\n\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n            c.execute('SELECT result FROM cache WHERE func_name=? AND args=?', (func_name, key))\n            data = c.fetchone()\n            conn.close()\n\n            if data:\n                return json.loads(data[0])\n            else:\n                result = func(*args)\n                conn = sqlite3.connect(filename)\n                c = conn.cursor()\n                c.execute('INSERT INTO cache (func_name, args, result) VALUES (?, ?, ?)', (func_name, key, json.dumps(result)))\n                conn.commit()\n                conn.close()\n                return result\n\n        return memoized_func"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        conn = sqlite3.connect(filename)\n        c = conn.cursor()\n        c.execute(f\"CREATE TABLE IF NOT EXISTS {func_name} (input TEXT, output TEXT, PRIMARY KEY (input))\")\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            input_str = json.dumps([args, kwargs], sort_keys=True)\n            key = hashlib.md5(input_str.encode('utf-8')).hexdigest()\n            c.execute(f\"SELECT output FROM {func_name} WHERE input=?\", (key,))\n            result = c.fetchone()\n            if result:\n                return json.loads(result[0])\n            else:\n                output = func(*args, **kwargs)\n                c.execute(f\"INSERT OR REPLACE INTO {func_name} (input, output) VALUES (?, ?)\", (key, json.dumps(output)))\n                conn.commit()\n                return output\n\n        conn.close()\n        return wrapper\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            # Connect to the SQLite database\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n            \n            # Create the table if it doesn't exist\n            c.execute(f\"CREATE TABLE IF NOT EXISTS {func_name} (input TEXT, output TEXT, PRIMARY KEY (input))\")\n            \n            # Generate a unique key for the function call based on its input arguments\n            key = hashlib.md5(json.dumps((args, kwargs)).encode('utf-8')).hexdigest()\n            \n            # Check if the result is already in the database\n            c.execute(f\"SELECT output FROM {func_name} WHERE input = ?\", (key,))\n            result = c.fetchone()\n            \n            if result:\n                # If the result is in the database, return it\n                conn.close()\n                return json.loads(result[0])\n            else:\n                # If the result is not in the database, compute it and store it\n                result = func(*args, **kwargs)\n                c.execute(f\"INSERT OR REPLACE INTO {func_name} (input, output) VALUES (?, ?)\", (key, json.dumps(result)))\n                conn.commit()\n                conn.close()\n                return result\n        \n        return wrapper\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        conn = sqlite3.connect(filename)\n        c = conn.cursor()\n        c.execute(f\"CREATE TABLE IF NOT EXISTS {func_name} (input TEXT, output TEXT)\")\n        conn.commit()\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            input_hash = hashlib.sha256(json.dumps((args, kwargs)).encode()).hexdigest()\n            c.execute(f\"SELECT output FROM {func_name} WHERE input=?\", (input_hash,))\n            result = c.fetchone()\n            if result:\n                return json.loads(result[0])\n            else:\n                output = func(*args, **kwargs)\n                c.execute(f\"INSERT INTO {func_name} (input, output) VALUES (?, ?)\", (input_hash, json.dumps(output)))\n                conn.commit()\n                return output\n\n        return wrapper\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            # Connect to the SQLite database\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n\n            # Create a table to store the function outputs if it doesn't exist\n            c.execute(f\"CREATE TABLE IF NOT EXISTS {func_name} (args TEXT, kwargs TEXT, result TEXT)\")\n\n            # Hash the function arguments and keyword arguments to use as a key in the database\n            key = hashlib.md5(json.dumps((args, kwargs)).encode('utf-8')).hexdigest()\n\n            # Check if the result is already in the database\n            c.execute(f\"SELECT result FROM {func_name} WHERE args=? AND kwargs=?\", (json.dumps(args), json.dumps(kwargs)))\n            result = c.fetchone()\n\n            if result:\n                # If the result is in the database, return it\n                conn.close()\n                return json.loads(result[0])\n            else:\n                # If the result is not in the database, compute it and store it\n                result = func(*args, **kwargs)\n                c.execute(f\"INSERT INTO {func_name} (args, kwargs, result) VALUES (?, ?, ?)\", (json.dumps(args), json.dumps(kwargs), json.dumps(result)))\n                conn.commit()\n                conn.close()\n                return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        conn = sqlite3.connect(filename)\n        c = conn.cursor()\n        c.execute(f\"CREATE TABLE IF NOT EXISTS {func_name} (input TEXT, output TEXT)\")\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            input_str = json.dumps((args, kwargs), sort_keys=True)\n            key = hashlib.md5(input_str.encode()).hexdigest()\n            c.execute(f\"SELECT output FROM {func_name} WHERE input=?\", (key,))\n            result = c.fetchone()\n            if result:\n                return json.loads(result[0])\n            else:\n                output = func(*args, **kwargs)\n                c.execute(f\"INSERT INTO {func_name} (input, output) VALUES (?, ?)\", (key, json.dumps(output)))\n                conn.commit()\n                return output\n\n        conn.close()\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        conn = sqlite3.connect(filename)\n        c = conn.cursor()\n        c.execute(f\"CREATE TABLE IF NOT EXISTS {func_name} (input TEXT, output TEXT, PRIMARY KEY (input))\")\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            input_hash = hashlib.sha256(json.dumps((args, kwargs)).encode()).hexdigest()\n            c.execute(f\"SELECT output FROM {func_name} WHERE input=?\", (input_hash,))\n            result = c.fetchone()\n            if result:\n                return json.loads(result[0])\n            else:\n                output = func(*args, **kwargs)\n                c.execute(f\"INSERT OR REPLACE INTO {func_name} (input, output) VALUES (?, ?)\", (input_hash, json.dumps(output)))\n                conn.commit()\n                return output\n\n        conn.close()\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        conn = sqlite3.connect(filename)\n        c = conn.cursor()\n        c.execute(f\"CREATE TABLE IF NOT EXISTS {func_name} (args TEXT, result TEXT, PRIMARY KEY(args))\")\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            serialized_args = json.dumps([args, kwargs], sort_keys=True)\n            key = hashlib.md5(serialized_args.encode()).hexdigest()\n            c.execute(f\"SELECT result FROM {func_name} WHERE args = ?\", (key,))\n            data = c.fetchone()\n            if data:\n                return json.loads(data[0])\n            else:\n                result = func(*args, **kwargs)\n                c.execute(f\"INSERT OR REPLACE INTO {func_name} (args, result) VALUES (?, ?)\", (key, json.dumps(result)))\n                conn.commit()\n                return result\n\n        conn.close()\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n\n            # Create table if it doesn't exist\n            c.execute(f\"CREATE TABLE IF NOT EXISTS {func_name} (args TEXT, kwargs TEXT, result TEXT)\")\n\n            # Create a unique key for the function call\n            key = hashlib.md5(json.dumps((args, kwargs)).encode()).hexdigest()\n\n            # Check if the result is already in the database\n            c.execute(f\"SELECT result FROM {func_name} WHERE args=? AND kwargs=?\", (json.dumps(args), json.dumps(kwargs)))\n            result = c.fetchone()\n\n            if result:\n                conn.close()\n                return json.loads(result[0])\n            else:\n                # Compute the result\n                result = func(*args, **kwargs)\n\n                # Store the result in the database\n                c.execute(f\"INSERT INTO {func_name} (args, kwargs, result) VALUES (?, ?, ?)\", (json.dumps(args), json.dumps(kwargs), json.dumps(result)))\n                conn.commit()\n                conn.close()\n\n                return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            # Connect to the SQLite database\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n\n            # Create the table if it doesn't exist\n            c.execute(f\"CREATE TABLE IF NOT EXISTS {func_name} (args TEXT, result TEXT)\")\n\n            # Generate a unique key for the function call\n            key = hashlib.md5(json.dumps((func_name, args, kwargs)).encode('utf-8')).hexdigest()\n\n            # Check if the result is already in the database\n            c.execute(f\"SELECT result FROM {func_name} WHERE args = ? AND key = ?\", (json.dumps(args), key))\n            result = c.fetchone()\n\n            if result:\n                # If the result is in the database, return it\n                conn.close()\n                return json.loads(result[0])\n            else:\n                # If the result is not in the database, compute it and store it\n                result = func(*args, **kwargs)\n                c.execute(f\"INSERT INTO {func_name} (args, result, key) VALUES (?, ?, ?)\", (json.dumps(args), json.dumps(result), key))\n                conn.commit()\n                conn.close()\n                return result\n\n        return wrapper\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        conn = sqlite3.connect(filename)\n        c = conn.cursor()\n        c.execute(f\"CREATE TABLE IF NOT EXISTS {func_name} (input TEXT, output TEXT)\")\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            input_str = json.dumps((args, kwargs), sort_keys=True)\n            key = hashlib.md5(input_str.encode()).hexdigest()\n            c.execute(f\"SELECT output FROM {func_name} WHERE input = ?\", (key,))\n            result = c.fetchone()\n            if result:\n                return json.loads(result[0])\n            else:\n                output = func(*args, **kwargs)\n                c.execute(f\"INSERT INTO {func_name} (input, output) VALUES (?, ?)\", (key, json.dumps(output)))\n                conn.commit()\n                return output\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        conn = sqlite3.connect(filename)\n        c = conn.cursor()\n        c.execute('''CREATE TABLE IF NOT EXISTS cache (id TEXT PRIMARY KEY, result TEXT)''')\n        conn.commit()\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            key = hashlib.md5(json.dumps((func_name, args, kwargs)).encode('utf-8')).hexdigest()\n            c.execute(\"SELECT result FROM cache WHERE id=?\", (key,))\n            result = c.fetchone()\n            if result:\n                return json.loads(result[0])\n            else:\n                result = func(*args, **kwargs)\n                c.execute(\"INSERT INTO cache (id, result) VALUES (?, ?)\", (key, json.dumps(result)))\n                conn.commit()\n                return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        conn = sqlite3.connect(filename)\n        c = conn.cursor()\n        c.execute('''CREATE TABLE IF NOT EXISTS cache (id TEXT PRIMARY KEY, result TEXT)''')\n        conn.commit()\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            key = hashlib.md5(json.dumps((func_name, args, kwargs)).encode('utf-8')).hexdigest()\n            c.execute(\"SELECT result FROM cache WHERE id=?\", (key,))\n            result = c.fetchone()\n            if result:\n                return json.loads(result[0])\n            else:\n                result = func(*args, **kwargs)\n                c.execute(\"INSERT INTO cache (id, result) VALUES (?, ?)\", (key, json.dumps(result)))\n                conn.commit()\n                return result\n\n        return wrapper\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        conn = sqlite3.connect(filename)\n        c = conn.cursor()\n        c.execute(f\"CREATE TABLE IF NOT EXISTS {func_name} (input TEXT, output TEXT, PRIMARY KEY (input))\")\n        conn.commit()\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            input_hash = hashlib.md5(json.dumps((args, kwargs)).encode('utf-8')).hexdigest()\n            c.execute(f\"SELECT output FROM {func_name} WHERE input=?\", (input_hash,))\n            result = c.fetchone()\n            if result:\n                return json.loads(result[0])\n            else:\n                output = func(*args, **kwargs)\n                c.execute(f\"INSERT OR REPLACE INTO {func_name} (input, output) VALUES (?, ?)\", (input_hash, json.dumps(output)))\n                conn.commit()\n                return output\n\n        conn.close()\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n            c.execute(\"CREATE TABLE IF NOT EXISTS cache (id TEXT PRIMARY KEY, result TEXT)\")\n            key = hashlib.md5(json.dumps((func_name, args, kwargs)).encode()).hexdigest()\n            c.execute(\"SELECT result FROM cache WHERE id=?\", (key,))\n            data = c.fetchone()\n            if data:\n                conn.close()\n                return json.loads(data[0])\n            else:\n                result = func(*args, **kwargs)\n                c.execute(\"INSERT OR REPLACE INTO cache (id, result) VALUES (?, ?)\", (key, json.dumps(result)))\n                conn.commit()\n                conn.close()\n                return result\n        return wrapper\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        conn = sqlite3.connect(filename)\n        c = conn.cursor()\n        c.execute(f\"CREATE TABLE IF NOT EXISTS {func_name} (input TEXT, output TEXT)\")\n        conn.commit()\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            input_hash = hashlib.md5(json.dumps((args, kwargs)).encode('utf-8')).hexdigest()\n            c.execute(f\"SELECT output FROM {func_name} WHERE input=?\", (input_hash,))\n            result = c.fetchone()\n            if result:\n                return json.loads(result[0])\n            else:\n                output = func(*args, **kwargs)\n                c.execute(f\"INSERT INTO {func_name} (input, output) VALUES (?, ?)\", (input_hash, json.dumps(output)))\n                conn.commit()\n                return output\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        conn = sqlite3.connect(filename)\n        c = conn.cursor()\n        c.execute('CREATE TABLE IF NOT EXISTS cache (id TEXT PRIMARY KEY, result TEXT)')\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            key = hashlib.md5(json.dumps((func_name, args, kwargs)).encode('utf-8')).hexdigest()\n            c.execute('SELECT result FROM cache WHERE id=?', (key,))\n            data = c.fetchone()\n            if data:\n                return json.loads(data[0])\n            else:\n                result = func(*args, **kwargs)\n                c.execute('INSERT OR REPLACE INTO cache (id, result) VALUES (?, ?)', (key, json.dumps(result)))\n                conn.commit()\n                return result\n\n        conn.close()\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        conn = sqlite3.connect(filename)\n        c = conn.cursor()\n        c.execute('''CREATE TABLE IF NOT EXISTS memoization (func_name TEXT, args TEXT, result TEXT)''')\n        conn.commit()\n\n        @functools.wraps(func)\n        def wrapper(*args):\n            args_str = json.dumps(args)\n            key = hashlib.md5(func_name.encode('utf-8') + args_str.encode('utf-8')).hexdigest()\n            c.execute(\"SELECT result FROM memoization WHERE func_name=? AND args=?\", (func_name, key))\n            data = c.fetchone()\n            if data:\n                return json.loads(data[0])\n            else:\n                result = func(*args)\n                c.execute(\"INSERT INTO memoization (func_name, args, result) VALUES (?, ?, ?)\", (func_name, key, json.dumps(result)))\n                conn.commit()\n                return result\n\n        conn.close()\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        conn = sqlite3.connect(filename)\n        c = conn.cursor()\n        c.execute(f\"CREATE TABLE IF NOT EXISTS {func_name} (input TEXT, output TEXT, PRIMARY KEY (input))\")\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            input_str = json.dumps([args, kwargs], sort_keys=True)\n            input_hash = hashlib.md5(input_str.encode()).hexdigest()\n            c.execute(f\"SELECT output FROM {func_name} WHERE input=?\", (input_hash,))\n            result = c.fetchone()\n            if result:\n                return json.loads(result[0])\n            else:\n                output = func(*args, **kwargs)\n                output_str = json.dumps(output, sort_keys=True)\n                c.execute(f\"INSERT OR REPLACE INTO {func_name} (input, output) VALUES (?, ?)\", (input_hash, output_str))\n                conn.commit()\n                return output\n\n        conn.close()\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        conn = sqlite3.connect(filename)\n        c = conn.cursor()\n        c.execute(f\"CREATE TABLE IF NOT EXISTS {func_name} (input TEXT, output TEXT, PRIMARY KEY(input))\")\n        conn.commit()\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            input_str = json.dumps([args, kwargs], sort_keys=True)\n            input_hash = hashlib.md5(input_str.encode()).hexdigest()\n            c.execute(f\"SELECT output FROM {func_name} WHERE input=?\", (input_hash,))\n            result = c.fetchone()\n            if result:\n                return json.loads(result[0])\n            else:\n                output = func(*args, **kwargs)\n                output_str = json.dumps(output, sort_keys=True)\n                c.execute(f\"INSERT OR REPLACE INTO {func_name} (input, output) VALUES (?, ?)\", (input_hash, output_str))\n                conn.commit()\n                return output\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        serialized_result = json.dumps(result)\n        self.connection.execute(\"INSERT INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, serialized_result))"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        serialized_result = json.dumps(result)\n        self.connection.execute(\"INSERT INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, serialized_result))"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        serialized_result = json.dumps(result)\n        self.connection.execute(\"INSERT INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, serialized_result))"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        serialized_result = json.dumps(result)\n        self.connection.execute(\"INSERT INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, serialized_result))"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"INSERT INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, json.dumps(result)))\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        serialized_result = json.dumps(result)\n        self.connection.execute(\"INSERT INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, serialized_result))"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        serialized_result = json.dumps(result)\n        self.connection.execute(\"INSERT INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, serialized_result))\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        serialized_result = json.dumps(result)\n        self.connection.execute(\"INSERT INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, serialized_result))"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        serialized_result = json.dumps(result)\n        self.connection.execute(\"INSERT INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, serialized_result))"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        serialized_result = json.dumps(result)\n        self.connection.execute(\"INSERT INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, serialized_result))"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        serialized_result = json.dumps(result)\n        self.connection.execute(\"INSERT INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, serialized_result))"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        serialized_result = json.dumps(result)\n        self.connection.execute(\"INSERT INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, serialized_result))"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        serialized_result = json.dumps(result)\n        self.connection.execute(\"INSERT OR REPLACE INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, serialized_result))"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        serialized_result = json.dumps(result)\n        self.connection.execute(\"INSERT INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, serialized_result))"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        serialized_result = json.dumps(result)\n        self.connection.execute(\"INSERT INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, serialized_result))"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "    cursor = self.connection.cursor()\n    cursor.execute(\"INSERT OR REPLACE INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, json.dumps(result)))\n    self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        serialized_result = json.dumps(result)\n        self.connection.execute(\"INSERT INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, serialized_result))"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        serialized_result = json.dumps(result)\n        self.connection.execute(\"INSERT INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, serialized_result))"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        result_json = json.dumps(result)\n        self.connection.execute(\"INSERT INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, result_json))"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        serialized_result = json.dumps(result)\n        self.connection.execute(\"INSERT INTO cache (hash, result) VALUES (?, ?)\", (arg_hash, serialized_result))"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    global CONFIG, ARGS\n    CONFIG = deepcopy(CONFIG)\n    ARGS = args\n\n    # Redirect standard output to a file if quiet mode is enabled\n    if quiet_mode:\n        with open('output.log', 'w') as f:\n            with redirect_stdout(f):\n                # Execute the command line process\n                command_line = CommandLine()\n                command_line.execute()\n    else:\n        # Execute the command line process\n        command_line = CommandLine()\n        command_line.execute()"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    for key, value in vars(args).items():\n        if value is not None:\n            CONFIG[key.upper()] = value\n\n    # If quiet mode is enabled, redirect the standard output to a file\n    if quiet_mode:\n        with open(os.path.join(CONFIG[\"RECORD_DIR\"], \"output.log\"), \"w\") as f:\n            with redirect_stdout(f):\n                command_line = CommandLine()\n                command_line.execute()\n    else:\n        command_line = CommandLine()\n        command_line.execute()"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    for arg in vars(args):\n        if getattr(args, arg) is not None:\n            CONFIG[arg.upper()] = getattr(args, arg)\n\n    # Redirect standard output to a file if quiet mode is enabled\n    if quiet_mode:\n        with open('output.log', 'w') as f:\n            with redirect_stdout(f):\n                command_line = CommandLine()\n                command_line.execute()\n    else:\n        command_line = CommandLine()\n        command_line.execute()"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    for key, value in vars(args).items():\n        if value is not None:\n            CONFIG[key.upper()] = value\n\n    # Redirect standard output to a file if quiet mode is enabled\n    if quiet_mode:\n        with open('output.txt', 'w') as f:\n            with redirect_stdout(f):\n                command_line = CommandLine()\n                command_line.execute()\n    else:\n        command_line = CommandLine()\n        command_line.execute()"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    for arg in vars(args):\n        if getattr(args, arg) is not None:\n            CONFIG[arg.upper()] = getattr(args, arg)\n\n    # Redirect standard output to a file if quiet mode is enabled\n    if quiet_mode:\n        with open(os.path.join(CONFIG['RECORD_DIR'], 'output.log'), 'w') as f:\n            with redirect_stdout(f):\n                command_line = CommandLine()\n                command_line.execute()\n    else:\n        command_line = CommandLine()\n        command_line.execute()"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    for key, value in vars(args).items():\n        if value is not None:\n            CONFIG[key.upper()] = value\n\n    # Redirect standard output to a file if quiet mode is enabled\n    if quiet_mode:\n        with open('output.log', 'w') as f:\n            with redirect_stdout(f):\n                command_line = CommandLine(CONFIG, ARGS)\n                command_line.execute()\n    else:\n        command_line = CommandLine(CONFIG, ARGS)\n        command_line.execute()"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    for key, value in vars(args).items():\n        if value is not None:\n            CONFIG[key.upper()] = value\n\n    # Redirect standard output to a file if quiet mode is enabled\n    if quiet_mode:\n        with open('output.log', 'w') as f:\n            with redirect_stdout(f):\n                # Call the command line process\n                command_line = CommandLine()\n                command_line.execute()\n\n    else:\n        # Call the command line process\n        command_line = CommandLine()\n        command_line.execute()"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    for arg in vars(args):\n        if getattr(args, arg) is not None:\n            CONFIG[arg.upper()] = getattr(args, arg)\n\n    # Redirect standard output to a file if quiet mode is enabled\n    if quiet_mode:\n        with open('output.log', 'w') as f:\n            with redirect_stdout(f):\n                # Execute the command line process\n                command_line = CommandLine()\n                command_line.execute()\n    else:\n        # Execute the command line process\n        command_line = CommandLine()\n        command_line.execute()"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    for key, value in vars(args).items():\n        if value is not None:\n            CONFIG[key.upper()] = value\n\n    # Redirect standard output to a file if quiet mode is enabled\n    if quiet_mode:\n        with open('output.log', 'w') as f:\n            with redirect_stdout(f):\n                command_line = CommandLine(CONFIG, ARGS)\n                command_line.run()\n    else:\n        command_line = CommandLine(CONFIG, ARGS)\n        command_line.run()"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    for key, value in vars(args).items():\n        if value is not None:\n            CONFIG[key.upper()] = value\n            ARGS[key] = value\n\n    # Redirect standard output to a file if quiet mode is enabled\n    if quiet_mode:\n        with open('output.log', 'w') as f:\n            with redirect_stdout(f):\n                # Call the command line process\n                command_line = CommandLine()\n                command_line.execute()\n    else:\n        # Call the command line process\n        command_line = CommandLine()\n        command_line.execute()"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    for arg in vars(args):\n        if getattr(args, arg) is not None:\n            CONFIG[arg.upper()] = getattr(args, arg)\n\n    # If quiet mode is enabled, redirect the standard output to a file\n    if quiet_mode:\n        with open(CONFIG['RECORD_DIR'] + '/output.log', 'w') as f:\n            with redirect_stdout(f):\n                command_line = CommandLine()\n                command_line.execute()\n    else:\n        command_line = CommandLine()\n        command_line.execute()"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    for key, value in vars(args).items():\n        if value is not None:\n            CONFIG[key.upper()] = value\n\n    # Redirect standard output to a file if quiet mode is enabled\n    if quiet_mode:\n        with open('output.log', 'w') as f:\n            with redirect_stdout(f):\n                command_line = CommandLine(CONFIG, ARGS)\n                command_line.execute()\n    else:\n        command_line = CommandLine(CONFIG, ARGS)\n        command_line.execute()"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    for arg in vars(args):\n        if getattr(args, arg) is not None:\n            CONFIG[arg.upper()] = getattr(args, arg)\n\n    # Redirect standard output to a file if quiet mode is enabled\n    if quiet_mode:\n        with open('output.log', 'w') as f:\n            with redirect_stdout(f):\n                command_line = CommandLine()\n                command_line.execute()\n    else:\n        command_line = CommandLine()\n        command_line.execute()"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    for key, value in vars(args).items():\n        if value is not None:\n            CONFIG[key.upper()] = value\n            ARGS[key] = value\n\n    if quiet_mode:\n        # Redirect standard output to a file\n        with open(CONFIG['RECORD_DIR'] + '/output.log', 'w') as f:\n            with redirect_stdout(f):\n                # Execute the command line process\n                command_line = CommandLine()\n                command_line.execute()\n    else:\n        # Execute the command line process\n        command_line = CommandLine()\n        command_line.execute()"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    for arg in vars(args):\n        if getattr(args, arg) is not None:\n            CONFIG[arg.upper()] = getattr(args, arg)\n\n    # If quiet mode is enabled, redirect the standard output to a file instead of displaying it in the terminal\n    if quiet_mode:\n        with open(os.path.join(CONFIG['RECORD_DIR'], 'output.log'), 'w') as f:\n            with redirect_stdout(f):\n                command_line = CommandLine()\n                command_line.execute()\n    else:\n        command_line = CommandLine()\n        command_line.execute()"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    for key, value in vars(args).items():\n        if value is not None:\n            CONFIG[key.upper()] = value\n\n    # Redirect standard output to a file if quiet mode is enabled\n    if quiet_mode:\n        with open('output.log', 'w') as f:\n            with redirect_stdout(f):\n                # Execute the command line process\n                command_line = CommandLine()\n                command_line.execute()\n    else:\n        # Execute the command line process\n        command_line = CommandLine()\n        command_line.execute()"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    for arg in vars(args):\n        if getattr(args, arg) is not None:\n            CONFIG[arg.upper()] = getattr(args, arg)\n\n    # Redirect standard output to a file if quiet mode is enabled\n    if quiet_mode:\n        with open('output.log', 'w') as f:\n            with redirect_stdout(f):\n                # Execute the command line process\n                command_line = CommandLine()\n                command_line.execute()\n    else:\n        # Execute the command line process\n        command_line = CommandLine()\n        command_line.execute()"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    for arg in vars(args):\n        if getattr(args, arg) is not None:\n            CONFIG[arg.upper()] = getattr(args, arg)\n\n    # Redirect standard output to a file if quiet mode is enabled\n    if quiet_mode:\n        with open('output.log', 'w') as f:\n            with redirect_stdout(f):\n                # Execute the command line process\n                command_line = CommandLine()\n                command_line.execute()\n    else:\n        # Execute the command line process\n        command_line = CommandLine()\n        command_line.execute()"}
{"namespace": "run.execute_command_line_process", "completion": "    if quiet_mode:\n        with open('output.txt', 'w') as f:\n            with redirect_stdout(f):\n                CONFIG.update(vars(args))\n    else:\n        CONFIG.update(vars(args))"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    for arg, value in vars(args).items():\n        if value is not None:\n            CONFIG[arg.upper()] = value\n\n    # Redirect standard output to a file if quiet mode is enabled\n    if quiet_mode:\n        with open(\"output.log\", \"w\") as f:\n            with redirect_stdout(f):\n                # Execute the command line process\n                command_line = CommandLine()\n                command_line.execute()\n    else:\n        # Execute the command line process\n        command_line = CommandLine()\n        command_line.execute()"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n            else:\n                raise e\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "            model_name = get_model_name(\n                kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n            )\n            logger.debug(\"chatcompletion: using \" + model_name)\n            chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n            if \"azure_endpoint\" in chatcompletion_kwargs:\n                api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n                chatcompletion_kwargs.update({\"api_base\": api_base})\n            chatcompletion_kwargs.update(kwargs)\n\n            try:\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n                if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                    raise BadRequestError(\"maximum context length exceeded\", None)\n            except BadRequestError as e:\n                if \"maximum context length\" in e._message:\n                    if model_name == \"gpt-4\":\n                        if \"gpt-4-32k\" in CONFIG.api_keys:\n                            model_name = \"gpt-4-32k\"\n                        elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                            model_name = \"gpt-4-1106-preview\"\n                        else:\n                            model_name = \"gpt-3.5-turbo-16k\"\n                    elif model_name == \"gpt-3.5-turbo\":\n                        if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                            model_name = \"gpt-3.5-turbo-1106\"\n                        else:\n                            model_name = \"gpt-3.5-turbo-16k\"\n                    else:\n                        raise e\n                    print(\"max context length reached, retrying with \" + model_name)\n                    chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                    chatcompletion_kwargs.update(kwargs)\n                    chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                    response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                    response = json.loads(str(response))\n                else:\n                    raise e\n\n            return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "            model_name = get_model_name(\n                kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n            )\n            logger.debug(\"chatcompletion: using \" + model_name)\n            chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n            if \"azure_endpoint\" in chatcompletion_kwargs:\n                api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n                chatcompletion_kwargs.update({\"api_base\": api_base})\n            chatcompletion_kwargs.update(kwargs)\n\n            try:\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n                if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                    raise BadRequestError(\"maximum context length exceeded\", None)\n            except BadRequestError as e:\n                if \"maximum context length\" in e._message:\n                    if model_name == \"gpt-4\":\n                        if \"gpt-4-32k\" in CONFIG.api_keys:\n                            model_name = \"gpt-4-32k\"\n                        elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                            model_name = \"gpt-4-1106-preview\"\n                        else:\n                            model_name = \"gpt-3.5-turbo-16k\"\n                    elif model_name == \"gpt-3.5-turbo\":\n                        if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                            model_name = \"gpt-3.5-turbo-1106\"\n                        else:\n                            model_name = \"gpt-3.5-turbo-16k\"\n                    else:\n                        raise e\n                    print(\"max context length reached, retrying with \" + model_name)\n                    chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                    chatcompletion_kwargs.update(kwargs)\n                    chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                    response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                    response = json.loads(str(response))\n                else:\n                    raise e\n\n            return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "            model_name = get_model_name(\n                kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n            )\n            logger.debug(\"chatcompletion: using \" + model_name)\n            chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n            if \"azure_endpoint\" in chatcompletion_kwargs:\n                api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n                chatcompletion_kwargs.update({\"api_base\": api_base})\n            chatcompletion_kwargs.update(kwargs)\n\n            try:\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n                if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                    raise BadRequestError(\"maximum context length exceeded\", None)\n            except BadRequestError as e:\n                if \"maximum context length\" in e._message:\n                    if model_name == \"gpt-4\":\n                        if \"gpt-4-32k\" in CONFIG.api_keys:\n                            model_name = \"gpt-4-32k\"\n                        elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                            model_name = \"gpt-4-1106-preview\"\n                        else:\n                            model_name = \"gpt-3.5-turbo-16k\"\n                    elif model_name == \"gpt-3.5-turbo\":\n                        if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                            model_name = \"gpt-3.5-turbo-1106\"\n                        else:\n                            model_name = \"gpt-3.5-turbo-16k\"\n                    else:\n                        raise e\n                    print(\"max context length reached, retrying with \" + model_name)\n                    chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                    chatcompletion_kwargs.update(kwargs)\n                    chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                    response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                    response = json.loads(str(response))\n                else:\n                    raise e\n\n            return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n            else:\n                raise e\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n            else:\n                raise e\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n            else:\n                raise e\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n            else:\n                raise e\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "            model_name = get_model_name(\n                kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n            )\n            logger.debug(\"chatcompletion: using \" + model_name)\n            chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n            if \"azure_endpoint\" in chatcompletion_kwargs:\n                api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n                chatcompletion_kwargs.update({\"api_base\": api_base})\n            chatcompletion_kwargs.update(kwargs)\n\n            try:\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n                if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                    raise BadRequestError(\"maximum context length exceeded\", None)\n            except BadRequestError as e:\n                if \"maximum context length\" in e._message:\n                    if model_name == \"gpt-4\":\n                        if \"gpt-4-32k\" in CONFIG.api_keys:\n                            model_name = \"gpt-4-32k\"\n                        elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                            model_name = \"gpt-4-1106-preview\"\n                        else:\n                            model_name = \"gpt-3.5-turbo-16k\"\n                    elif model_name == \"gpt-3.5-turbo\":\n                        if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                            model_name = \"gpt-3.5-turbo-1106\"\n                        else:\n                            model_name = \"gpt-3.5-turbo-16k\"\n                    else:\n                        raise e\n                    print(\"max context length reached, retrying with \" + model_name)\n                    chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                    chatcompletion_kwargs.update(kwargs)\n                    chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                    response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                    response = json.loads(str(response))\n                else:\n                    raise e\n\n            return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "            model_name = get_model_name(\n                kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n            )\n            logger.debug(\"chatcompletion: using \" + model_name)\n            chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n            if \"azure_endpoint\" in chatcompletion_kwargs:\n                api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n                chatcompletion_kwargs.update({\"api_base\": api_base})\n            chatcompletion_kwargs.update(kwargs)\n\n            try:\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n                if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                    raise BadRequestError(\"maximum context length exceeded\", None)\n            except BadRequestError as e:\n                if \"maximum context length\" in e._message:\n                    if model_name == \"gpt-4\":\n                        if \"gpt-4-32k\" in CONFIG.api_keys:\n                            model_name = \"gpt-4-32k\"\n                        elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                            model_name = \"gpt-4-1106-preview\"\n                        else:\n                            model_name = \"gpt-3.5-turbo-16k\"\n                    elif model_name == \"gpt-3.5-turbo\":\n                        if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                            model_name = \"gpt-3.5-turbo-1106\"\n                        else:\n                            model_name = \"gpt-3.5-turbo-16k\"\n                    else:\n                        raise e\n                    print(\"max context length reached, retrying with \" + model_name)\n                    chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                    chatcompletion_kwargs.update(kwargs)\n                    chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                    response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                    response = json.loads(str(response))\n                else:\n                    raise e\n\n            return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n            else:\n                raise e\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n            else:\n                raise e\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n            else:\n                raise e\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "    model_name = get_model_name(\n        kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n    )\n    logger.debug(\"chatcompletion: using \" + model_name)\n    chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n    if \"azure_endpoint\" in chatcompletion_kwargs:\n        api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n        chatcompletion_kwargs.update({\"api_base\": api_base})\n    chatcompletion_kwargs.update(kwargs)\n\n    try:\n        response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n        response = json.loads(str(response))\n        if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n            raise BadRequestError(\"maximum context length exceeded\", None)\n    except BadRequestError as e:\n        if \"maximum context length\" in e._message:\n            if model_name == \"gpt-4\":\n                if \"gpt-4-32k\" in CONFIG.api_keys:\n                    model_name = \"gpt-4-32k\"\n                elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                    model_name = \"gpt-4-1106-preview\"\n                else:\n                    model_name = \"gpt-3.5-turbo-16k\"\n            elif model_name == \"gpt-3.5-turbo\":\n                if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                    model_name = \"gpt-3.5-turbo-1106\"\n                else:\n                    model_name = \"gpt-3.5-turbo-16k\"\n            else:\n                raise e\n            print(\"max context length reached, retrying with \" + model_name)\n            chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n            chatcompletion_kwargs.update(kwargs)\n            chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n        else:\n            raise e\n\n    return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "    pass\n"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n            else:\n                raise e\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n            else:\n                raise e\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "            model_name = get_model_name(\n                kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n            )\n            logger.debug(\"chatcompletion: using \" + model_name)\n            chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n            if \"azure_endpoint\" in chatcompletion_kwargs:\n                api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n                chatcompletion_kwargs.update({\"api_base\": api_base})\n            chatcompletion_kwargs.update(kwargs)\n\n            try:\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n                if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                    raise BadRequestError(\"maximum context length exceeded\", None)\n            except BadRequestError as e:\n                if \"maximum context length\" in e._message:\n                    if model_name == \"gpt-4\":\n                        if \"gpt-4-32k\" in CONFIG.api_keys:\n                            model_name = \"gpt-4-32k\"\n                        elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                            model_name = \"gpt-4-1106-preview\"\n                        else:\n                            model_name = \"gpt-3.5-turbo-16k\"\n                    elif model_name == \"gpt-3.5-turbo\":\n                        if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                            model_name = \"gpt-3.5-turbo-1106\"\n                        else:\n                            model_name = \"gpt-3.5-turbo-16k\"\n                    else:\n                        raise e\n                    print(\"max context length reached, retrying with \" + model_name)\n                    chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                    chatcompletion_kwargs.update(kwargs)\n                    chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                    response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                    response = json.loads(str(response))\n                else:\n                    raise e\n\n            return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n            else:\n                raise e\n\n        return response"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n                chatcompletion_kwargs.update(kwargs)\n                chatcompletion_kwargs.pop(\"schema_error_retry\", None)\n\n                response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n                response = json.loads(str(response))\n            else:\n                raise e\n\n        return response"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (self._last_time is not None and time() - self._last_time > self._refetch_interval):\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (self._last_time is not None and time() - self._last_time > self._refetch_interval):\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (self._last_time is not None and time() - self._last_time > self._refetch_interval):\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        current_time = time()\n        if self._client is None or self._last_time is None or current_time - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = current_time\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (self._last_time is not None and time() - self._last_time > self._refetch_interval):\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (self._last_time is not None and time() - self._last_time > self._refetch_interval):\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        current_time = time()\n        if self._client is None or self._last_time is None or current_time - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = current_time\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        current_time = time()\n        if self._client is None or self._last_time is None or current_time - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = current_time\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (self._last_time is not None and time() - self._last_time > self._refetch_interval):\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        current_time = time()\n        if self._client is None or self._last_time is None or current_time - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = current_time\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        current_time = time()\n\n        if self._client is None or self._last_time is None or (current_time - self._last_time) > self._refetch_interval:\n            self._create_client()\n            self._last_time = current_time\n\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "\n        current_time = time()\n        if self._client is None or (self._last_time is not None and current_time - self._last_time > self._refetch_interval):\n            self._create_client()\n            self._last_time = current_time\n\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        current_time = time()\n\n        if self._client is None or self._last_time is None or current_time - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = current_time\n\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        current_time = time()\n        if self._client is None or self._last_time is None or (current_time - self._last_time) > self._refetch_interval:\n            self._create_client()\n            self._last_time = current_time\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        current_time = time()\n        if self._client is None or self._last_time is None or current_time - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = current_time\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (self._last_time is not None and time() - self._last_time > self._refetch_interval):\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        current_time = time()\n        if self._client is None or self._last_time is None or current_time - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = current_time\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or self._last_time is None or time() - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        current_time = time()\n        if self._client is None or (self._last_time is not None and current_time - self._last_time > self._refetch_interval):\n            self._create_client()\n            self._last_time = current_time\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "\n        current_time = time()\n\n        if self._client is None or (self._last_time is not None and current_time - self._last_time > self._refetch_interval):\n            self._create_client()\n            self._last_time = current_time\n\n        return self._client"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "\n        if _is_in_dataloader_worker():\n            raise RuntimeError(\"state_dict should not be called from a DataLoader worker process.\")\n\n        state = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir,\n            \"item_loader_state\": self.item_loader.state if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n\n        return state"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"state_dict() should not be called from a DataLoader worker process.\")\n\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader_state\": self.item_loader.state() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle\n        }\n\n        return state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"state_dict() should be called only from the main process, not worker processes\")\n\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path if self.input_dir.path else self.input_dir.url,\n            \"item_loader_state\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle\n        }\n\n        return state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "\n        if _is_in_dataloader_worker():\n            raise RuntimeError(\"state_dict cannot be called from a DataLoader worker process.\")\n\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path if self.input_dir.path else self.input_dir.url,\n            \"item_loader_state\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle\n        }\n\n        return state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "\n        if _is_in_dataloader_worker():\n            raise RuntimeError(\"state_dict() should not be called from a DataLoader worker process.\")\n\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader_state\": self.item_loader.state if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle\n        }\n\n        return state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"state_dict() should not be called from a DataLoader worker process.\")\n\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader_state\": self.item_loader.state() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle\n        }\n\n        return state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"state_dict should not be called from a DataLoader worker process.\")\n\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir,\n            \"item_loader_state\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n\n        return state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"state_dict() should not be called from a DataLoader worker process.\")\n\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir,\n            \"item_loader_state\": self.item_loader.state() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle\n        }\n        return state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"state_dict() should not be called from a DataLoader worker process.\")\n\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader_state\": self.item_loader.state if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle\n        }\n\n        return state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"state_dict() should not be called from a DataLoader worker process.\")\n\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path if self.input_dir.path else self.input_dir.url,\n            \"item_loader_state\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle\n        }\n\n        return state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"state_dict cannot be called from a DataLoader worker process.\")\n\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path if self.input_dir.path else self.input_dir.url,\n            \"item_loader_state\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle\n        }\n\n        return state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "\n        if _is_in_dataloader_worker():\n            raise RuntimeError(\"state_dict should not be called from a DataLoader worker process.\")\n\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader_state\": self.item_loader.state if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle\n        }\n\n        return state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"state_dict should not be called from a DataLoader worker process.\")\n\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path if self.input_dir.path else self.input_dir.url,\n            \"item_loader_state\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle\n        }\n\n        return state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"state_dict() should not be called from a DataLoader worker process.\")\n\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader_state\": self.item_loader.state if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle\n        }\n\n        return state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"state_dict() should not be called from a DataLoader worker process\")\n\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader_state\": self.item_loader.state() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle\n        }\n        return state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"state_dict() should not be called from a DataLoader worker process.\")\n\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir,\n            \"item_loader_state\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle\n        }\n\n        return state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"state_dict() should not be called from a DataLoader worker process.\")\n\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path if self.input_dir.path else self.input_dir.url,\n            \"item_loader_state\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle\n        }\n\n        return state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"state_dict() should not be called from a DataLoader worker process.\")\n\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader_state\": self.item_loader.state if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle\n        }\n\n        return state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"state_dict() should not be called from a DataLoader worker process.\")\n\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path if hasattr(self.input_dir, \"path\") else self.input_dir,\n            \"item_loader_state\": self.item_loader.state_dict() if self.item_loader is not None else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle\n        }\n\n        return state_dict"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"state_dict() should be called only from the main process, not from DataLoader worker processes.\")\n\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path if self.input_dir.path else self.input_dir.url,\n            \"item_loader_state\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle\n        }\n\n        return state_dict"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "\n        # Resize the rendering context to match the camera's width and height\n        eglctx.resize_context(camera.width, camera.height)\n\n        # Set up the OpenGL rendering options\n        common_opengl_options()\n\n        # Use the mesh program for rendering\n        use_gl_program(self.mesh_program)\n\n        # Set the uniform values for the mesh program\n        # (e.g., camera settings, transformation matrices, etc.)\n\n        # Perform the actual rendering of the Mesh instance using the specified camera settings\n        # (e.g., vertex and fragment shader operations, etc.)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "\n        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.width, camera.height)\n\n        # Set up the OpenGL context for offscreen rendering\n        eglctx.make_current()\n        common_opengl_options()\n\n        # Set the viewport to match the camera's dimensions\n        gl.glViewport(0, 0, camera.width, camera.height)\n\n        # Set the projection matrix based on the camera's settings\n        projection_matrix = glm.perspective(glm.radians(camera.fov), camera.aspect_ratio, camera.near, camera.far)\n\n        # Set the view matrix based on the camera's position and orientation\n        view_matrix = glm.lookAt(camera.position, camera.position + camera.front, camera.up)\n\n        # Set the model matrix to identity (no transformation)\n        model_matrix = glm.mat4(1.0)\n\n        # Use the mesh program for rendering\n        use_gl_program(self.mesh_program)\n\n        # Set the uniform values for the mesh program\n        gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.mesh_program, \"projection\"), 1, gl.GL_FALSE, glm.value_ptr(projection_matrix))\n        gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.mesh_program, \"view\"), 1, gl.GL_FALSE, glm.value_ptr(view_matrix))\n        gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.mesh_program, \"model\"), 1, gl.GL_FALSE, glm.value_ptr(model_matrix))\n\n        # Bind the vertex array object and draw the mesh\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces), gl.GL_UNSIGNED_INT, None)\n\n        # Unbind the vertex array object\n        gl.glBindVertexArray(0)\n\n        # Clear the rendering context\n        eglctx.clear()\n\n        # Release the OpenGL context\n        eglctx.release()"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "\n        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.width, camera.height)\n\n        # Set up the offscreen rendering\n        eglctx.make_current()\n        gl.glClearColor(0, 0, 0, 0)\n        gl.glClear(gl.GL_COLOR_BUFFER_BIT | gl.GL_DEPTH_BUFFER_BIT)\n\n        # Set the viewport to match the camera's dimensions\n        gl.glViewport(0, 0, camera.width, camera.height)\n\n        # Set up the projection matrix based on the camera's settings\n        projection_matrix = glm.perspective(glm.radians(camera.fov), camera.aspect_ratio, camera.near, camera.far)\n\n        # Set up the view matrix based on the camera's position and orientation\n        view_matrix = glm.lookAt(camera.position, camera.position + camera.front, camera.up)\n\n        # Set the shader program for rendering the mesh\n        use_gl_program(self.mesh_program)\n\n        # Set the uniform values for the mesh rendering\n        gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.mesh_program, \"projection\"), 1, gl.GL_FALSE, np.array(projection_matrix))\n        gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.mesh_program, \"view\"), 1, gl.GL_FALSE, np.array(view_matrix))\n        gl.glUniform3fv(gl.glGetUniformLocation(self.mesh_program, \"cam_pos\"), 1, np.array(camera.position))\n\n        # Render the mesh\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glPointSize(self.point_radius)\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        else:\n            gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces), gl.GL_UNSIGNED_INT, None)\n\n        # Clean up\n        eglctx.swap_buffers()\n        eglctx.release_current()"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "\n        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.width, camera.height)\n\n        # Set up the OpenGL context for offscreen rendering\n        eglctx.make_current()\n        common_opengl_options()\n\n        # Set the viewport to match the camera's dimensions\n        gl.glViewport(0, 0, camera.width, camera.height)\n\n        # Set the projection matrix based on the camera's settings\n        projection_matrix = glm.perspective(glm.radians(camera.fov), camera.aspect_ratio, camera.near, camera.far)\n\n        # Set the view matrix based on the camera's position and orientation\n        view_matrix = glm.lookAt(camera.position, camera.position + camera.front, camera.up)\n\n        # Set the model matrix to the identity matrix (no transformation)\n        model_matrix = glm.mat4(1.0)\n\n        # Use the mesh program for rendering\n        use_gl_program(self.mesh_program)\n\n        # Set the uniform values for the mesh program\n        gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.mesh_program, \"projection\"), 1, gl.GL_FALSE, glm.value_ptr(projection_matrix))\n        gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.mesh_program, \"view\"), 1, gl.GL_FALSE, glm.value_ptr(view_matrix))\n        gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.mesh_program, \"model\"), 1, gl.GL_FALSE, glm.value_ptr(model_matrix))\n\n        # Bind the vertex array object and draw the mesh based on its render type\n        gl.glBindVertexArray(self.vao)\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            gl.glDrawElements(gl.GL_LINES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n        gl.glBindVertexArray(0)\n\n        # Unbind the program and release the OpenGL context\n        gl.glUseProgram(0)\n        eglctx.release()"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "\n        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.width, camera.height)\n\n        # Set up the OpenGL context for offscreen rendering\n        eglctx.make_current()\n        common_opengl_options()\n\n        # Set the viewport to match the camera's dimensions\n        gl.glViewport(0, 0, camera.width, camera.height)\n\n        # Set the projection matrix based on the camera's settings\n        projection_matrix = glm.perspective(glm.radians(camera.fov), camera.aspect_ratio, camera.near, camera.far)\n\n        # Set the view matrix based on the camera's position and orientation\n        view_matrix = glm.lookAt(camera.position, camera.position + camera.front, camera.up)\n\n        # Set the model matrix to identity (no transformation)\n        model_matrix = glm.mat4(1.0)\n\n        # Use the mesh program for rendering\n        use_gl_program(self.mesh_program)\n\n        # Set the uniform variables for the mesh program\n        gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.mesh_program, \"uProjection\"), 1, gl.GL_FALSE, glm.value_ptr(projection_matrix))\n        gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.mesh_program, \"uView\"), 1, gl.GL_FALSE, glm.value_ptr(view_matrix))\n        gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.mesh_program, \"uModel\"), 1, gl.GL_FALSE, glm.value_ptr(model_matrix))\n\n        # Bind the vertex array and draw the mesh\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n\n        # Unbind the vertex array and program\n        gl.glBindVertexArray(0)\n        gl.glUseProgram(0)\n\n        # Release the OpenGL context\n        eglctx.release()"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "\n        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.width, camera.height)\n\n        # Set up the OpenGL context for rendering\n        eglctx.make_current()\n        common_opengl_options()\n\n        # Set the viewport to match the camera's dimensions\n        gl.glViewport(0, 0, camera.width, camera.height)\n\n        # Clear the color and depth buffers\n        gl.glClearColor(0.0, 0.0, 0.0, 1.0)\n        gl.glClear(gl.GL_COLOR_BUFFER_BIT | gl.GL_DEPTH_BUFFER_BIT)\n\n        # Set up the camera for rendering\n        view_matrix = camera.get_view_matrix()\n        projection_matrix = camera.get_projection_matrix()\n        model_matrix = glm.mat4(1.0)  # Identity matrix for model transformation\n\n        # Use the mesh program for rendering\n        use_gl_program(self.mesh_program)\n\n        # Set the uniform values for the mesh program\n        gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.mesh_program, \"model\"), 1, gl.GL_FALSE, model_matrix.to_list())\n        gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.mesh_program, \"view\"), 1, gl.GL_FALSE, view_matrix.to_list())\n        gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.mesh_program, \"projection\"), 1, gl.GL_FALSE, projection_matrix.to_list())\n\n        # Bind the vertex array object and draw the mesh\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n        gl.glBindVertexArray(0)\n\n        # Unbind the mesh program\n        gl.glUseProgram(0)\n\n        # Unbind the rendering context\n        eglctx.unbind()"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "\n        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.width, camera.height)\n\n        # Set the viewport to match the camera's dimensions\n        gl.glViewport(0, 0, camera.width, camera.height)\n\n        # Clear the color and depth buffers\n        gl.glClear(gl.GL_COLOR_BUFFER_BIT | gl.GL_DEPTH_BUFFER_BIT)\n\n        # Set the projection matrix based on the camera settings\n        projection = glm.perspective(glm.radians(camera.fov), camera.aspect_ratio, camera.near, camera.far)\n\n        # Set the view matrix based on the camera settings\n        view = glm.lookAt(camera.position, camera.position + camera.front, camera.up)\n\n        # Set the model matrix to the identity matrix\n        model = glm.mat4(1.0)\n\n        # Use the mesh program for rendering\n        use_gl_program(self.mesh_program)\n\n        # Set the uniform values for the mesh program\n        gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.mesh_program, \"projection\"), 1, gl.GL_FALSE, glm.value_ptr(projection))\n        gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.mesh_program, \"view\"), 1, gl.GL_FALSE, glm.value_ptr(view))\n        gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.mesh_program, \"model\"), 1, gl.GL_FALSE, glm.value_ptr(model))\n\n        # Bind the vertex array object and draw the mesh\n        self.bind_vertex_array()\n        self.draw_mesh()\n\n        # Unbind the vertex array object\n        self.unbind_vertex_array()"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "\n        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.width, camera.height)\n\n        # Set up the offscreen rendering environment\n        eglctx.make_current()\n        common_opengl_options()\n        use_gl_program(self.mesh_program)\n\n        # Set the camera parameters for rendering\n        view = glm.lookAt(camera.position, camera.target, camera.up)\n        projection = glm.perspective(glm.radians(camera.fov), camera.aspect_ratio, camera.near, camera.far)\n        model_view_projection = projection * view\n\n        # Set the uniform values for the shader program\n        gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.mesh_program, \"uModelViewProjection\"), 1, gl.GL_FALSE, glm.value_ptr(model_view_projection))\n\n        # Render the mesh\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n            gl.glUniform1f(gl.glGetUniformLocation(self.point_program, \"uPointSize\"), self.point_radius)\n            gl.glEnableVertexAttribArray(0)\n            gl.glVertexAttribPointer(0, 3, gl.GL_FLOAT, gl.GL_FALSE, 0, self.verts_data)\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n            gl.glDisableVertexAttribArray(0)\n        else:\n            gl.glEnableVertexAttribArray(0)\n            gl.glVertexAttribPointer(0, 3, gl.GL_FLOAT, gl.GL_FALSE, 0, self.verts_data)\n            gl.glEnableVertexAttribArray(1)\n            gl.glVertexAttribPointer(1, 3, gl.GL_FLOAT, gl.GL_FALSE, 0, self.normals_data)\n            gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces_data), gl.GL_UNSIGNED_INT, self.faces_data)\n            gl.glDisableVertexAttribArray(0)\n            gl.glDisableVertexAttribArray(1)\n\n        # Unbind the shader program and release the rendering context\n        gl.glUseProgram(0)\n        eglctx.release()"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "\n        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.width, camera.height)\n\n        # Set up the OpenGL context for rendering\n        eglctx.make_current()\n        common_opengl_options()\n\n        # Set the viewport to match the camera's dimensions\n        gl.glViewport(0, 0, camera.width, camera.height)\n\n        # Clear the color and depth buffers\n        gl.glClearColor(0.0, 0.0, 0.0, 1.0)\n        gl.glClear(gl.GL_COLOR_BUFFER_BIT | gl.GL_DEPTH_BUFFER_BIT)\n\n        # Use the mesh program for rendering\n        use_gl_program(self.mesh_program)\n\n        # Set the uniform values for the mesh program\n        # (e.g., model-view-projection matrix, lighting parameters, etc.)\n\n        # Bind the vertex and index buffers for the mesh\n        # (e.g., self.verts_data, self.faces_data)\n\n        # Draw the mesh using the specified render type\n        # (e.g., gl.glDrawElements/gl.glDrawArrays)\n\n        # Optionally, you can also render normals, points, or other visualizations"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "\n        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.width, camera.height)\n\n        # Set up the OpenGL context for offscreen rendering\n        eglctx.make_current()\n        common_opengl_options()\n\n        # Set the viewport to match the camera's dimensions\n        gl.glViewport(0, 0, camera.width, camera.height)\n\n        # Set the projection matrix based on the camera's settings\n        projection_matrix = glm.perspective(glm.radians(camera.fov), camera.aspect_ratio, camera.near, camera.far)\n\n        # Set the view matrix based on the camera's position and orientation\n        view_matrix = glm.lookAt(camera.position, camera.position + camera.front, camera.up)\n\n        # Set the model matrix to identity (no transformation)\n        model_matrix = glm.mat4(1.0)\n\n        # Use the mesh program for rendering\n        use_gl_program(self.mesh_program)\n\n        # Set the uniform values for the mesh program\n        gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.mesh_program, \"projection\"), 1, gl.GL_FALSE, glm.value_ptr(projection_matrix))\n        gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.mesh_program, \"view\"), 1, gl.GL_FALSE, glm.value_ptr(view_matrix))\n        gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.mesh_program, \"model\"), 1, gl.GL_FALSE, glm.value_ptr(model_matrix))\n\n        # Bind the vertex array object and draw the mesh\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n\n        # Unbind the vertex array object\n        gl.glBindVertexArray(0)\n\n        # Clear the OpenGL context\n        eglctx.clear_current()"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "\n        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.width, camera.height)\n\n        # Set up the offscreen rendering environment\n        eglctx.make_current()\n        common_opengl_options()\n\n        # Set the viewport to match the camera's dimensions\n        gl.glViewport(0, 0, camera.width, camera.height)\n\n        # Set up the camera for rendering\n        view_matrix = glm.lookAt(camera.position, camera.target, camera.up)\n        projection_matrix = glm.perspective(glm.radians(camera.fov), camera.aspect_ratio, camera.near, camera.far)\n\n        # Use the mesh program for rendering\n        use_gl_program(self.mesh_program)\n\n        # Set the uniform values for the mesh program\n        gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.mesh_program, \"uViewMatrix\"), 1, gl.GL_FALSE, glm.value_ptr(view_matrix))\n        gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.mesh_program, \"uProjectionMatrix\"), 1, gl.GL_FALSE, glm.value_ptr(projection_matrix))\n\n        # Render the mesh\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glPointSize(self.point_radius * camera.height)\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        else:\n            gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces), gl.GL_UNSIGNED_INT, None)\n\n        # Unbind the mesh program\n        gl.glUseProgram(0)\n\n        # Release the rendering context\n        eglctx.release()"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "\n        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.width, camera.height)\n\n        # Set up the OpenGL context for offscreen rendering\n        create_opengl_context()\n\n        # Use the program point size and enable face culling, alpha testing, z-buffer testing, and masking tests\n        common_opengl_options()\n\n        # Use the specified camera settings for rendering\n        # ...\n\n        # Perform offscreen rendering of the Mesh instance using the camera's settings\n        # ..."}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "\n        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.width, camera.height)\n\n        # Set up the OpenGL viewport based on the camera's width and height\n        gl.glViewport(0, 0, camera.width, camera.height)\n\n        # Clear the color and depth buffers\n        gl.glClear(gl.GL_COLOR_BUFFER_BIT | gl.GL_DEPTH_BUFFER_BIT)\n\n        # Use the program for rendering the mesh\n        use_gl_program(self.mesh_program)\n\n        # Set the uniform values for the mesh program (e.g., camera parameters, model-view-projection matrix, etc.)\n        # ...\n\n        # Bind the vertex array object and draw the mesh based on its render type\n        # ...\n\n        # Reset the OpenGL program to None\n        use_gl_program(None)\n\n        # Finish the offscreen rendering process\n        eglctx.finish()"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's width and height\n        eglctx.resize_context(camera.width, camera.height)\n\n        # Set up the OpenGL context and options\n        create_opengl_context()\n        common_opengl_options()\n\n        # Use the program point size\n        gl.glEnable(gl.GL_PROGRAM_POINT_SIZE)\n\n        # Set the viewport to match the camera's dimensions\n        gl.glViewport(0, 0, camera.width, camera.height)\n\n        # Set the projection matrix based on the camera's settings\n        projection_matrix = glm.perspective(glm.radians(camera.fov), camera.aspect_ratio, camera.near, camera.far)\n\n        # Set the view matrix based on the camera's position and orientation\n        view_matrix = glm.lookAt(camera.position, camera.position + camera.front, camera.up)\n\n        # Set the model matrix to identity\n        model_matrix = glm.mat4(1.0)\n\n        # Use the mesh program for rendering\n        use_gl_program(self.mesh_program)\n\n        # Set the uniform values for the mesh program\n        gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.mesh_program, \"projection\"), 1, gl.GL_FALSE, glm.value_ptr(projection_matrix))\n        gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.mesh_program, \"view\"), 1, gl.GL_FALSE, glm.value_ptr(view_matrix))\n        gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.mesh_program, \"model\"), 1, gl.GL_FALSE, glm.value_ptr(model_matrix))\n\n        # Bind the vertex array object and draw the mesh\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n\n        # Unbind the vertex array object\n        gl.glBindVertexArray(0)\n\n        # Disable the mesh program\n        gl.glUseProgram(0)\n\n        # Clean up the OpenGL context\n        eglctx.cleanup_context()"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "\n        # Resize rendering context to match camera's width and height\n        eglctx.resize(camera.width, camera.height)\n\n        # Set up OpenGL options\n        common_opengl_options()\n\n        # Use the OpenGL program for mesh rendering\n        use_gl_program(self.mesh_program)\n\n        # Set the uniform values for the mesh rendering\n        # (Assuming the uniform values are set in the mesh_program)\n\n        # Perform the rendering process using the specified camera settings\n        # (Assuming the rendering process is performed using the mesh_program and other relevant OpenGL functions)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.width, camera.height)\n\n        # Set up the offscreen rendering environment\n        eglctx.make_current()\n        common_opengl_options()\n        use_gl_program(self.mesh_program)\n\n        # Set the camera parameters for rendering\n        view_matrix = glm.lookAt(camera.position, camera.look_at, camera.up)\n        projection_matrix = glm.perspective(glm.radians(camera.fov), camera.aspect_ratio, camera.near, camera.far)\n        model_view_projection = projection_matrix * view_matrix\n\n        # Set the uniform values for the shader program\n        gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.mesh_program, \"modelViewProjection\"), 1, gl.GL_FALSE, model_view_projection)\n\n        # Render the Mesh instance using the camera's settings\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n            gl.glUniform1f(gl.glGetUniformLocation(self.point_program, \"pointRadius\"), self.point_radius)\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        else:\n            gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n\n        # Clear the rendering context\n        eglctx.clear_current()"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.width, camera.height)\n\n        # Set up the offscreen rendering environment\n        eglctx.make_current()\n        gl.glClearColor(0.0, 0.0, 0.0, 0.0)\n        gl.glClear(gl.GL_COLOR_BUFFER_BIT | gl.GL_DEPTH_BUFFER_BIT)\n        common_opengl_options()\n\n        # Set the viewport to match the camera's dimensions\n        gl.glViewport(0, 0, camera.width, camera.height)\n\n        # Set up the projection matrix based on the camera's settings\n        projection_matrix = glm.perspective(glm.radians(camera.fov), camera.aspect_ratio, camera.near, camera.far)\n\n        # Set up the view matrix based on the camera's position and orientation\n        view_matrix = glm.lookAt(camera.position, camera.position + camera.front, camera.up)\n\n        # Set the model matrix to the identity matrix\n        model_matrix = glm.mat4(1.0)\n\n        # Combine the projection, view, and model matrices to form the MVP matrix\n        mvp_matrix = projection_matrix * view_matrix * model_matrix\n\n        # Use the mesh program for rendering\n        use_gl_program(self.mesh_program)\n\n        # Set the MVP matrix as a uniform variable in the shader program\n        mvp_location = gl.glGetUniformLocation(self.mesh_program, \"MVP\")\n        gl.glUniformMatrix4fv(mvp_location, 1, gl.GL_FALSE, glm.value_ptr(mvp_matrix))\n\n        # Bind the vertex array and draw the mesh\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n\n        # Unbind the vertex array\n        gl.glBindVertexArray(0)\n\n        # Unbind the shader program\n        gl.glUseProgram(0)\n\n        # Reset the rendering context\n        eglctx.make_not_current()"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "\n        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.width, camera.height)\n\n        # Set up the OpenGL context for offscreen rendering\n        eglctx.make_current()\n        common_opengl_options()\n\n        # Set the viewport to match the camera's dimensions\n        gl.glViewport(0, 0, camera.width, camera.height)\n\n        # Clear the color and depth buffers\n        gl.glClearColor(0.0, 0.0, 0.0, 1.0)\n        gl.glClear(gl.GL_COLOR_BUFFER_BIT | gl.GL_DEPTH_BUFFER_BIT)\n\n        # Set the projection matrix based on the camera's settings\n        projection_matrix = glm.perspective(glm.radians(camera.fov), camera.aspect_ratio, camera.near, camera.far)\n\n        # Set the view matrix based on the camera's position and orientation\n        view_matrix = glm.lookAt(camera.position, camera.position + camera.front, camera.up)\n\n        # Combine the projection and view matrices to create the view projection matrix\n        view_projection_matrix = projection_matrix * view_matrix\n\n        # Use the mesh program for rendering\n        use_gl_program(self.mesh_program)\n\n        # Set the uniform values for the mesh program\n        gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.mesh_program, \"u_ViewProjectionMatrix\"), 1, gl.GL_FALSE, view_projection_matrix.to_list())\n\n        # Bind the vertex array object and draw the mesh\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n\n        # Unbind the vertex array object\n        gl.glBindVertexArray(0)\n\n        # Unset the OpenGL context\n        eglctx.unmake_current()"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "\n        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.width, camera.height)\n\n        # Set up the offscreen rendering environment\n        gl.glClearColor(0.0, 0.0, 0.0, 0.0)\n        common_opengl_options()\n        use_gl_program(self.mesh_program)\n\n        # Set the camera's projection and view matrices\n        gl.glMatrixMode(gl.GL_PROJECTION)\n        gl.glLoadIdentity()\n        gl.gluPerspective(camera.fov, camera.aspect_ratio, camera.near, camera.far)\n        gl.glMatrixMode(gl.GL_MODELVIEW)\n        gl.glLoadIdentity()\n        gl.gluLookAt(camera.position.x, camera.position.y, camera.position.z,\n                     camera.target.x, camera.target.y, camera.target.z,\n                     camera.up.x, camera.up.y, camera.up.z)\n\n        # Render the Mesh instance\n        gl.glEnableClientState(gl.GL_VERTEX_ARRAY)\n        gl.glEnableClientState(gl.GL_COLOR_ARRAY)\n        gl.glEnableClientState(gl.GL_NORMAL_ARRAY)\n        gl.glVertexPointer(3, gl.GL_FLOAT, 0, self.verts_data)\n        gl.glColorPointer(3, gl.GL_FLOAT, 0, self.verts_data[self.vert_sizes[0]:])\n        gl.glNormalPointer(gl.GL_FLOAT, 0, self.verts_data[self.vert_sizes[0] + self.vert_sizes[1]:])\n        gl.glDrawElements(self.render_type.value, len(self.faces), gl.GL_UNSIGNED_INT, self.faces_data)\n\n        # Clean up\n        gl.glDisableClientState(gl.GL_VERTEX_ARRAY)\n        gl.glDisableClientState(gl.GL_COLOR_ARRAY)\n        gl.glDisableClientState(gl.GL_NORMAL_ARRAY)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "\n        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.width, camera.height)\n\n        # Set up the OpenGL context for rendering\n        eglctx.make_current()\n        common_opengl_options()\n\n        # Set the viewport to match the camera's dimensions\n        gl.glViewport(0, 0, camera.width, camera.height)\n\n        # Clear the color and depth buffers\n        gl.glClearColor(0.0, 0.0, 0.0, 1.0)\n        gl.glClear(gl.GL_COLOR_BUFFER_BIT | gl.GL_DEPTH_BUFFER_BIT)\n\n        # Set up the camera's view and projection matrices for rendering\n        view_matrix = camera.get_view_matrix()\n        projection_matrix = camera.get_projection_matrix()\n\n        # Use the mesh program for rendering\n        use_gl_program(self.mesh_program)\n\n        # Set the uniform values for the mesh program\n        gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.mesh_program, \"view_matrix\"), 1, gl.GL_FALSE, view_matrix)\n        gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.mesh_program, \"projection_matrix\"), 1, gl.GL_FALSE, projection_matrix)\n\n        # Bind the vertex array object and draw the mesh\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n\n        # Unbind the vertex array object\n        gl.glBindVertexArray(0)\n\n        # Unset the current OpenGL program\n        gl.glUseProgram(0)\n\n        # Release the OpenGL context\n        eglctx.release()"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        pad_token_id=bert_config.pad_token_id,\n        position_embedding_type=bert_config.position_embedding_type,\n        use_cache=bert_config.use_cache,\n        output_past=bert_config.output_past,\n        gradient_checkpointing=bert_config.gradient_checkpointing,\n        num_labels=2,  # Example of adding a new attribute specific to Nomic model\n    )\n    \n    return nomic_config"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        nomic_specific_attribute_1=0.0,  # Add new specific attribute for Nomic model\n        nomic_specific_attribute_2=\"example\"  # Add another new specific attribute for Nomic model\n    )\n\n    return nomic_config"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        is_decoder=bert_config.is_decoder,\n        output_past=bert_config.output_past,\n        gradient_checkpointing=bert_config.gradient_checkpointing,\n        position_embedding_type=bert_config.position_embedding_type,\n        use_cache=bert_config.use_cache,\n        bos_token_id=bert_config.bos_token_id,\n        eos_token_id=bert_config.eos_token_id,\n        pad_token_id=bert_config.pad_token_id,\n        decoder_start_token_id=bert_config.decoder_start_token_id,\n        classifier_dropout=0.1,  # New attribute specific to Nomic model\n        nomic_specific_attribute=\"value\"  # New attribute specific to Nomic model\n    )\n    \n    return nomic_config"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        output_past=True\n    )\n    \n    return nomic_config"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        output_attentions=bert_config.output_attentions,\n        output_hidden_states=bert_config.output_hidden_states,\n        is_decoder=bert_config.is_decoder\n    )\n    \n    return nomic_config"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        pad_token_id=bert_config.pad_token_id,\n        position_embedding_type='absolute',\n        use_cache=True\n    )\n\n    return nomic_config"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        output_past=bert_config.output_past,\n        pad_token_id=bert_config.pad_token_id,\n        gradient_checkpointing=bert_config.gradient_checkpointing,\n        position_embedding_type=bert_config.position_embedding_type,\n        use_cache=bert_config.use_cache,\n        num_labels=2,  # Example of adding a new attribute specific to NomicBertConfig\n    )\n    \n    return nomic_config"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        nomic_specific_attribute1=value1,  # Add specific attributes for Nomic model\n        nomic_specific_attribute2=value2,  # Add specific attributes for Nomic model\n    )\n\n    return nomic_config"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        nomic_specific_attribute_1=0.0,  # Add new specific attribute for Nomic model\n        nomic_specific_attribute_2=\"default_value\"  # Add another new specific attribute for Nomic model\n    )\n\n    return nomic_config"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        output_past=bert_config.output_past,\n        gradient_checkpointing=bert_config.gradient_checkpointing,\n        position_embedding_type=bert_config.position_embedding_type,\n        use_cache=bert_config.use_cache,\n        num_labels=2,  # Example of adding a new attribute specific to the Nomic model\n    )\n    return nomic_config"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        nomic_specific_attribute=\"value\"  # Add any new specific attribute for Nomic model\n    )\n\n    return nomic_config"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        is_decoder=bert_config.is_decoder,\n        output_hidden_states=bert_config.output_hidden_states,\n        output_attentions=bert_config.output_attentions,\n        gradient_checkpointing=bert_config.gradient_checkpointing,\n        position_embedding_type=bert_config.position_embedding_type,\n        use_cache=bert_config.use_cache,\n        bos_token_id=bert_config.bos_token_id,\n        eos_token_id=bert_config.eos_token_id,\n        pad_token_id=bert_config.pad_token_id,\n        decoder_start_token_id=bert_config.decoder_start_token_id,\n        sep_token_id=bert_config.sep_token_id,\n        cls_token_id=bert_config.cls_token_id,\n        unk_token_id=bert_config.unk_token_id,\n        mask_token_id=bert_config.mask_token_id,\n        encoder_start_token_id=bert_config.encoder_start_token_id,\n        num_beams=bert_config.num_beams,\n        num_beam_groups=bert_config.num_beam_groups,\n        diversity_penalty=bert_config.diversity_penalty,\n        temperature=bert_config.temperature,\n        length_penalty=bert_config.length_penalty,\n        early_stopping=bert_config.early_stopping,\n        no_repeat_ngram_size=bert_config.no_repeat_ngram_size,\n        bad_words_ids=bert_config.bad_words_ids,\n        min_length=bert_config.min_length,\n        max_length=bert_config.max_length,\n        do_sample=bert_config.do_sample,\n        early_stopping=bert_config.early_stopping,\n        num_return_sequences=bert_config.num_return_sequences,\n        output_scores=bert_config.output_scores,\n        output_attentions=bert_config.output_attentions,\n        output_hidden_states=bert_config.output_hidden_states,\n        output_past=bert_config.output_past,\n        use_cache=bert_config.use_cache,\n        model_type='nomic'\n    )\n\n    return nomic_config"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        output_attentions=bert_config.output_attentions,\n        output_hidden_states=bert_config.output_hidden_states,\n        is_decoder=bert_config.is_decoder,\n        position_embedding_type=\"absolute\",\n        use_cache=True,\n        bos_token_id=bert_config.pad_token_id,\n        eos_token_id=bert_config.pad_token_id,\n    )\n\n    return nomic_config"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        output_attentions=bert_config.output_attentions,\n        output_hidden_states=bert_config.output_hidden_states,\n        is_decoder=bert_config.is_decoder,\n        position_embedding_type=\"absolute\",\n        use_cache=True\n    )\n    return nomic_config"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range\n    )\n\n    return nomic_config"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        pad_token_id=bert_config.pad_token_id,\n        position_embedding_type=bert_config.position_embedding_type,\n        use_cache=bert_config.use_cache,\n        gradient_checkpointing=bert_config.gradient_checkpointing,\n        num_labels=2,  # Example of adding a new attribute specific to Nomic model\n        nomic_specific_attribute=\"example\"  # Example of adding a new attribute specific to Nomic model\n    )\n    \n    return nomic_config"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        output_past=bert_config.output_past,\n        gradient_checkpointing=bert_config.gradient_checkpointing\n    )\n\n    return nomic_config"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        pad_token_id=bert_config.pad_token_id,\n        position_embedding_type=bert_config.position_embedding_type,\n        use_cache=bert_config.use_cache,\n        output_past=bert_config.output_past,\n        gradient_checkpointing=bert_config.gradient_checkpointing,\n        num_labels=2,  # Example of adding a new attribute specific to NomicBertConfig\n    )\n\n    return nomic_config"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        output_past=bert_config.output_past,\n        gradient_checkpointing=bert_config.gradient_checkpointing,\n        position_embedding_type=bert_config.position_embedding_type,\n        use_cache=bert_config.use_cache,\n        bos_token_id=bert_config.bos_token_id,\n        eos_token_id=bert_config.eos_token_id,\n        pad_token_id=bert_config.pad_token_id,\n        decoder_start_token_id=bert_config.decoder_start_token_id,\n        is_encoder_decoder=bert_config.is_encoder_decoder\n    )\n    return nomic_config"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        output_past=bert_config.output_past,\n        gradient_checkpointing=bert_config.gradient_checkpointing\n    )\n\n    return nomic_config"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n            gl.glPointSize(self.point_radius)\n        else:\n            use_gl_program(self.mesh_program)\n\n        self.upload_gl_uniforms(camera)\n\n        gl.glBindVertexArray(self.vao)\n\n        if self.render_type == Mesh.RenderType.LINES:\n            if len(self.faces) > 0:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if len(self.faces) > 0:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if len(self.faces) > 0:\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_QUADS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            if len(self.faces) > 0:\n                gl.glDrawElements(gl.GL_TRIANGLE_STRIP, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, len(self.verts))\n\n        gl.glBindVertexArray(0)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            program = self.point_program\n            gl.glUseProgram(program)\n            self.upload_gl_uniforms(program, camera)\n            gl.glBindVertexArray(self.vao)\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n            gl.glBindVertexArray(0)\n            gl.glUseProgram(0)\n\n        else:\n            program = self.mesh_program\n            gl.glUseProgram(program)\n            self.upload_gl_uniforms(program, camera)\n            gl.glBindVertexArray(self.vao)\n\n            if self.render_type == Mesh.RenderType.LINES:\n                if len(self.faces) > 0:\n                    gl.glDrawElements(gl.GL_LINES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n                else:\n                    gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n\n            elif self.render_type == Mesh.RenderType.TRIS:\n                if len(self.faces) > 0:\n                    gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n                else:\n                    gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n\n            gl.glBindVertexArray(0)\n            gl.glUseProgram(0)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            self.render_points(camera)\n        else:\n            self.render_mesh(camera)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            program = self.point_program\n        else:\n            program = self.mesh_program\n\n        use_gl_program(program)\n        self.upload_gl_uniforms(camera)\n\n        gl.glBindVertexArray(self.vao)\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            gl.glDrawElements(gl.GL_LINES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            gl.glDrawElements(gl.GL_QUADS, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            gl.glDrawElements(gl.GL_TRIANGLE_STRIP, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n\n        gl.glBindVertexArray(0)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        use_gl_program(self.mesh_program if self.render_type != Mesh.RenderType.POINTS else self.point_program)\n\n        self.upload_gl_uniforms(camera)\n\n        gl.glBindVertexArray(self.vao)\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            if self.faces is not None:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if self.faces is not None:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if self.faces is not None:\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_QUADS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            if self.faces is not None:\n                gl.glDrawElements(gl.GL_TRIANGLE_STRIP, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, len(self.verts))\n\n        gl.glBindVertexArray(0)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            self._render_points(camera)\n        else:\n            self._render_mesh(camera)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n        else:\n            gl.glUseProgram(self.mesh_program)\n\n        self.upload_gl_uniforms(camera)\n\n        gl.glBindVertexArray(self.vao)\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            if len(self.faces) > 0:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if len(self.faces) > 0:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if len(self.faces) > 0:\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_QUADS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            if len(self.faces) > 0:\n                gl.glDrawElements(gl.GL_TRIANGLE_STRIP, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, len(self.verts))\n\n        gl.glBindVertexArray(0)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glUseProgram(self.point_program)\n        else:\n            gl.glUseProgram(self.mesh_program)\n\n        self.upload_gl_uniforms(camera)\n        gl.glBindVertexArray(self.vao)\n\n        if self.render_type == Mesh.RenderType.LINES:\n            if len(self.faces):\n                gl.glDrawElements(gl.GL_LINES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if len(self.faces):\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if len(self.faces):\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_QUADS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            if len(self.faces):\n                gl.glDrawElements(gl.GL_TRIANGLE_STRIP, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, len(self.verts))\n\n        gl.glBindVertexArray(0)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n            gl.glUniform1f(gl.glGetUniformLocation(self.point_program, \"point_radius\"), self.point_radius)\n        else:\n            use_gl_program(self.mesh_program)\n            gl.glUniform1i(gl.glGetUniformLocation(self.mesh_program, \"shade_flat\"), self.shade_flat)\n            gl.glUniform1i(gl.glGetUniformLocation(self.mesh_program, \"render_normal\"), self.render_normal)\n\n        self.upload_gl_uniforms(camera)\n\n        gl.glBindVertexArray(self.vao)\n\n        if self.faces is not None:\n            if self.render_type == Mesh.RenderType.LINES:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces), gl.GL_UNSIGNED_INT, None)\n            elif self.render_type == Mesh.RenderType.TRIS:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces), gl.GL_UNSIGNED_INT, None)\n            elif self.render_type == Mesh.RenderType.QUADS:\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces), gl.GL_UNSIGNED_INT, None)\n            elif self.render_type == Mesh.RenderType.STRIPS:\n                gl.glDrawElements(gl.GL_TRIANGLE_STRIP, len(self.faces), gl.GL_UNSIGNED_INT, None)\n        else:\n            if self.render_type == Mesh.RenderType.POINTS:\n                gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n            elif self.render_type == Mesh.RenderType.LINES:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n            elif self.render_type == Mesh.RenderType.TRIS:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n            elif self.render_type == Mesh.RenderType.QUADS:\n                gl.glDrawArrays(gl.GL_QUADS, 0, len(self.verts))\n            elif self.render_type == Mesh.RenderType.STRIPS:\n                gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, len(self.verts))\n\n        gl.glBindVertexArray(0)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            program = use_gl_program(self.point_program)\n            gl.glUniform1f(gl.glGetUniformLocation(program, \"point_radius\"), self.point_radius)\n        else:\n            program = use_gl_program(self.mesh_program)\n            gl.glUniform1i(gl.glGetUniformLocation(program, \"shade_flat\"), self.shade_flat)\n\n        self.upload_gl_uniforms(program, camera)\n\n        gl.glBindVertexArray(self.vao)\n        if self.faces is not None:\n            if self.render_type == Mesh.RenderType.LINES:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces), gl.GL_UNSIGNED_INT, None)\n            elif self.render_type == Mesh.RenderType.TRIS:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces), gl.GL_UNSIGNED_INT, None)\n            elif self.render_type == Mesh.RenderType.QUADS:\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces), gl.GL_UNSIGNED_INT, None)\n            elif self.render_type == Mesh.RenderType.STRIPS:\n                gl.glDrawElements(gl.GL_TRIANGLE_STRIP, len(self.faces), gl.GL_UNSIGNED_INT, None)\n        else:\n            if self.render_type == Mesh.RenderType.LINES:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n            elif self.render_type == Mesh.RenderType.TRIS:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n            elif self.render_type == Mesh.RenderType.QUADS:\n                gl.glDrawArrays(gl.GL_QUADS, 0, len(self.verts))\n            elif self.render_type == Mesh.RenderType.STRIPS:\n                gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, len(self.verts))\n\n        gl.glBindVertexArray(0)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        # Select the appropriate shader program based on the render type\n        if self.render_type == Mesh.RenderType.POINTS:\n            program = use_gl_program(self.point_program)\n        else:\n            program = use_gl_program(self.mesh_program)\n\n        # Upload necessary uniforms to the GPU\n        self.upload_gl_uniforms(camera, program)\n\n        # Bind the vertex array object of the mesh\n        gl.glBindVertexArray(self.vao)\n\n        # Issue the appropriate OpenGL draw call based on the render type\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            if len(self.faces) > 0:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if len(self.faces) > 0:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if len(self.faces) > 0:\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_QUADS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            if len(self.faces) > 0:\n                gl.glDrawElements(gl.GL_TRIANGLE_STRIP, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, len(self.verts))\n\n        # Unbind the vertex array object to clean up\n        gl.glBindVertexArray(0)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            program = use_gl_program(self.point_program)\n            gl.glUniform1f(gl.glGetUniformLocation(program, \"point_radius\"), self.point_radius)\n        else:\n            program = use_gl_program(self.mesh_program)\n            gl.glUniform1i(gl.glGetUniformLocation(program, \"shade_flat\"), self.shade_flat)\n\n        self.upload_gl_uniforms(program, camera)\n\n        gl.glBindVertexArray(self.vao)\n        if self.faces is not None:\n            if self.render_type == Mesh.RenderType.LINES:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            elif self.render_type == Mesh.RenderType.TRIS:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            elif self.render_type == Mesh.RenderType.QUADS:\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            elif self.render_type == Mesh.RenderType.STRIPS:\n                gl.glDrawElements(gl.GL_TRIANGLE_STRIP, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n        else:\n            if self.render_type == Mesh.RenderType.POINTS:\n                gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n            elif self.render_type == Mesh.RenderType.LINES:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n            elif self.render_type == Mesh.RenderType.TRIS:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n            elif self.render_type == Mesh.RenderType.QUADS:\n                gl.glDrawArrays(gl.GL_QUADS, 0, len(self.verts))\n            elif self.render_type == Mesh.RenderType.STRIPS:\n                gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, len(self.verts))\n\n        gl.glBindVertexArray(0)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            program = use_gl_program(self.point_program)\n            gl.glUniform1f(gl.glGetUniformLocation(program, \"point_radius\"), self.point_radius)\n        else:\n            program = use_gl_program(self.mesh_program)\n            gl.glUniform1i(gl.glGetUniformLocation(program, \"shade_flat\"), int(self.shade_flat))\n\n        self.upload_gl_uniforms(program, camera)\n\n        gl.glBindVertexArray(self.vao)\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            if len(self.faces):\n                gl.glDrawElements(gl.GL_LINES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if len(self.faces):\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if len(self.faces):\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_QUADS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            if len(self.faces):\n                gl.glDrawElements(gl.GL_TRIANGLE_STRIP, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, len(self.verts))\n\n        gl.glBindVertexArray(0)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            program = self.point_program\n            gl.glPointSize(self.point_radius)\n        else:\n            program = self.mesh_program\n\n        use_gl_program(program)\n\n        self.upload_gl_uniforms(camera)\n\n        gl.glBindVertexArray(self.vao)\n\n        if self.faces is not None:\n            if self.render_type == Mesh.RenderType.LINES:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            elif self.render_type == Mesh.RenderType.TRIS:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            elif self.render_type == Mesh.RenderType.QUADS:\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            elif self.render_type == Mesh.RenderType.STRIPS:\n                gl.glDrawElements(gl.GL_TRIANGLE_STRIP, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n        else:\n            if self.render_type == Mesh.RenderType.LINES:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n            elif self.render_type == Mesh.RenderType.TRIS:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n            elif self.render_type == Mesh.RenderType.QUADS:\n                gl.glDrawArrays(gl.GL_QUADS, 0, len(self.verts))\n            elif self.render_type == Mesh.RenderType.STRIPS:\n                gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, len(self.verts))\n\n        gl.glBindVertexArray(0)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            self._render_points(camera)\n        else:\n            self._render_mesh(camera)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            program = use_gl_program(self.point_program)\n        else:\n            program = use_gl_program(self.mesh_program)\n\n        self.upload_gl_uniforms(camera)\n\n        gl.glBindVertexArray(self.vao)\n\n        if self.render_type == Mesh.RenderType.LINES:\n            if len(self.faces):\n                gl.glDrawElements(gl.GL_LINES, len(self.faces) * 2, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if len(self.faces):\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * 3, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if len(self.faces):\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces) * 4, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_QUADS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            if len(self.faces):\n                gl.glDrawElements(gl.GL_TRIANGLE_STRIP, len(self.faces) + 2, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, len(self.verts))\n\n        gl.glBindVertexArray(0)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n            gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.point_program, \"view\"), 1, gl.GL_FALSE, camera.view.numpy())\n            gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.point_program, \"proj\"), 1, gl.GL_FALSE, camera.proj.numpy())\n            gl.glUniform1f(gl.glGetUniformLocation(self.point_program, \"point_radius\"), self.point_radius)\n        else:\n            use_gl_program(self.mesh_program)\n            gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.mesh_program, \"view\"), 1, gl.GL_FALSE, camera.view.numpy())\n            gl.glUniformMatrix4fv(gl.glGetUniformLocation(self.mesh_program, \"proj\"), 1, gl.GL_FALSE, camera.proj.numpy())\n\n        self.upload_gl_uniforms()\n\n        gl.glBindVertexArray(self.vao)\n        if self.render_type == Mesh.RenderType.LINES:\n            if len(self.faces) > 0:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces), gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if len(self.faces) > 0:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces), gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if len(self.faces) > 0:\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces), gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_QUADS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            if len(self.faces) > 0:\n                gl.glDrawElements(gl.GL_TRIANGLE_STRIP, len(self.faces), gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, len(self.verts))\n\n        gl.glBindVertexArray(0)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        # Select the appropriate shader program based on the render type\n        if self.render_type == Mesh.RenderType.POINTS:\n            program = self.point_program\n        else:\n            program = self.mesh_program\n\n        # Bind the selected shader program\n        use_gl_program(program)\n\n        # Upload necessary uniforms to the GPU\n        self.upload_gl_uniforms(camera)\n\n        # Bind the vertex array object of the mesh\n        gl.glBindVertexArray(self.vao)\n\n        # Issue the appropriate OpenGL draw call based on the render type\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            gl.glDrawElements(gl.GL_LINES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            gl.glDrawElements(gl.GL_QUADS, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            gl.glDrawElements(gl.GL_TRIANGLE_STRIP, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n\n        # Unbind the vertex array object to clean up\n        gl.glBindVertexArray(0)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl_program = use_gl_program(self.point_program)\n            gl.glUniform1f(gl.glGetUniformLocation(gl_program, \"point_radius\"), self.point_radius)\n        else:\n            gl_program = use_gl_program(self.mesh_program)\n            gl.glUniform1i(gl.glGetUniformLocation(gl_program, \"shade_flat\"), self.shade_flat)\n\n        self.upload_gl_uniforms(gl_program, camera)\n\n        gl.glBindVertexArray(self.vao)\n\n        if self.render_type == Mesh.RenderType.LINES:\n            if len(self.faces):\n                gl.glDrawElements(gl.GL_LINES, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if len(self.faces):\n                gl.glDrawElements(gl.GL_TRIANGLES, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if len(self.faces):\n                gl.glDrawElements(gl.GL_QUADS, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_QUADS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            if len(self.faces):\n                gl.glDrawElements(gl.GL_TRIANGLE_STRIP, self.n_faces_bytes, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, len(self.verts))\n\n        gl.glBindVertexArray(0)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            self.render_points(camera)\n        else:\n            self.render_mesh(camera)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()  # convert PyTorch tensor to numpy array\n\n        if w == 0:\n            w = self.W  # default to object's width if not provided\n        if h == 0:\n            h = self.H  # default to object's height if not provided\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)  # bind the texture\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)  # update the texture content\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)  # unbind the texture"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        \n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()  # Convert PyTorch tensor to numpy array\n\n        if w == 0:\n            w = self.W  # Use object's width if w is not provided\n        if h == 0:\n            h = self.H  # Use object's height if h is not provided\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)  # Bind the texture\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)  # Upload the data to the texture\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)  # Unbind the texture"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()  # Convert PyTorch tensor to numpy array\n\n        # If width and height are not provided, use the object's width and height\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n\n        # Bind the texture and set its data\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()  # convert PyTorch tensor to numpy array\n\n        if w == 0:\n            w = self.W  # default to object's width if not provided\n        if h == 0:\n            h = self.H  # default to object's height if not provided\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)  # bind the texture to be updated\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)  # update the texture content\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)  # unbind the texture"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()  # Convert PyTorch tensor to numpy array\n\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n\n        # Upload the data to the texture using OpenGL\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()  # convert PyTorch tensor to numpy array\n\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()  # Convert PyTorch tensor to numpy array\n\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()  # convert PyTorch tensor to numpy array\n\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()\n\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()  # Convert PyTorch tensor to numpy array\n\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()\n\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()  # Convert PyTorch tensor to numpy array\n\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()\n\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()  # Convert PyTorch tensor to numpy array\n\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()  # Convert PyTorch tensor to numpy array\n\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        # Convert PyTorch tensor to numpy array if necessary\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().detach().numpy()\n\n        # If width and height are not provided, use the object's width and height\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n\n        # Bind the texture and set its data\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()  # convert PyTorch tensor to numpy array\n\n        if w == 0:\n            w = self.W  # default to object's width if not provided\n        if h == 0:\n            h = self.H  # default to object's height if not provided\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)  # bind the texture\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)  # upload the data to the texture\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)  # unbind the texture"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()  # convert to numpy array\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()  # Convert PyTorch tensor to numpy array\n\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()  # convert to numpy array\n\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate input shapes\n    assert R.shape[:-2] == tvec.shape[:-2] == camera_matrix.shape[:-2] == image_size.shape[:-1], \"Input shapes do not match\"\n\n    # Convert rotation matrix to 6D representation\n    rotation_6d = matrix_to_rotation_6d(R)\n\n    # Extract focal lengths and principal points from camera intrinsic matrix\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    cx = camera_matrix[..., 0, 2]\n    cy = camera_matrix[..., 1, 2]\n\n    # Average focal lengths if they differ by more than 1%\n    if torch.any(torch.abs(fx - fy) > 0.01 * fx):\n        warn_once_about_pulsar_fxfy()\n    f = (fx + fy) / 2\n\n    # Compute sensor width based on image size\n    sensor_width = image_size[..., 1]\n\n    # Compute camera position and rotation\n    camera_params = torch.cat([tvec, rotation_6d, f.unsqueeze(-1), sensor_width.unsqueeze(-1)], dim=-1)\n\n    return camera_params"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate input shapes\n    assert R.shape[:-2] == tvec.shape[:-2] == camera_matrix.shape[:-2] == image_size.shape[:-1], \"Input batch dimensions do not match\"\n\n    # Ensure camera_matrix has the correct shape\n    if camera_matrix.shape[-2:] != (3, 3):\n        raise ValueError(\"Camera matrix must have shape (batch_size, 3, 3)\")\n\n    # Ensure image_size has the correct shape\n    if image_size.shape[-1] != 2:\n        raise ValueError(\"Image size must have shape (batch_size, 2)\")\n\n    # Ensure R and tvec have the correct shape\n    if R.shape[-2:] != (3, 3):\n        raise ValueError(\"Rotation matrix must have shape (batch_size, 3, 3)\")\n    if tvec.shape[-1] != 3:\n        raise ValueError(\"Translation vector must have shape (batch_size, 3)\")\n\n    # Calculate focal length and principal point\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    cx = camera_matrix[..., 0, 2]\n    cy = camera_matrix[..., 1, 2]\n\n    # Check if fx and fy differ by more than 1%\n    if torch.any(torch.abs(fx - fy) / fx > 0.01):\n        warn_once_about_pulsar_fxfy()\n\n    # Average focal lengths for x and y directions\n    f = (fx + fy) / 2.0\n\n    # Calculate sensor width\n    sensor_width = 2.0 * f * torch.tan(torch.atan(image_size[..., 0] / f) / 2.0)\n\n    # Calculate camera position\n    camera_position = -torch.matmul(R.transpose(-1, -2), tvec.unsqueeze(-1)).squeeze(-1)\n\n    # Convert rotation matrices to 6D rotation representation\n    rotation_6d = matrix_to_rotation_6d(R)\n\n    # Construct the output tensor\n    camera_params = torch.cat([camera_position, rotation_6d, f.unsqueeze(-1), sensor_width.unsqueeze(-1)], dim=-1)\n\n    return camera_params"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Ensure all inputs are batched\n    assert R.dim() == 3, \"R must be a batch of rotation matrices with shape (B, 3, 3)\"\n    assert tvec.dim() == 3, \"tvec must be a batch of translation vectors with shape (B, 3, 1)\"\n    assert camera_matrix.dim() == 3, \"camera_matrix must be a batch of intrinsic matrices with shape (B, 3, 3)\"\n    assert image_size.dim() == 2, \"image_size must be a batch of image sizes with shape (B, 2)\"\n\n    # Validate shapes\n    assert R.size(0) == tvec.size(0) == camera_matrix.size(0) == image_size.size(0), \"All inputs must have the same batch size\"\n    assert R.size(1) == R.size(2) == 3, \"Rotation matrices must be 3x3\"\n    assert tvec.size(1) == 3 and tvec.size(2) == 1, \"Translation vectors must be 3x1\"\n    assert camera_matrix.size(1) == camera_matrix.size(2) == 3, \"Intrinsic matrices must be 3x3\"\n    assert image_size.size(1) == 2, \"Image sizes must be 2D\"\n\n    # Calculate focal length\n    fx = camera_matrix[:, 0, 0]\n    fy = camera_matrix[:, 1, 1]\n    fx_avg = fx.mean()\n    fy_avg = fy.mean()\n    if not torch.allclose(fx, fy, rtol=0.01):\n        warn_once_about_pulsar_fxfy()\n\n    # Calculate principal point\n    cx = camera_matrix[:, 0, 2]\n    cy = camera_matrix[:, 1, 2]\n\n    # Calculate sensor width\n    sensor_width = 2 * fx_avg\n\n    # Compute camera position and rotation\n    camera_position = -torch.bmm(R.transpose(1, 2), tvec)\n    rotation_6d = matrix_to_rotation_6d(R)\n\n    # Normalize focal length\n    normalized_fx = fx_avg / image_size[:, 0]\n    normalized_fy = fy_avg / image_size[:, 1]\n\n    # Create output tensor\n    camera_params = torch.stack([camera_position, rotation_6d, normalized_fx, normalized_fy, cx, cy, sensor_width, znear], dim=-1)\n\n    return camera_params"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate input shapes\n    assert R.shape[:-2] == tvec.shape[:-2] == camera_matrix.shape[:-2] == image_size.shape[:-1], \"Input shapes do not match\"\n\n    # Get batch size\n    batch_size = R.shape[0]\n\n    # Convert rotation matrix to 6D representation\n    rotation_6d = matrix_to_rotation_6d(R)\n\n    # Get focal lengths and principal points from camera matrix\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    cx = camera_matrix[..., 0, 2]\n    cy = camera_matrix[..., 1, 2]\n\n    # Check if fx and fy are significantly different\n    if torch.any(torch.abs(fx - fy) / fx > 0.01):\n        warn_once_about_pulsar_fxfy()\n\n    # Average focal lengths for x and y directions\n    f_avg = (fx + fy) / 2\n\n    # Compute sensor width\n    sensor_width = 2 * f_avg * image_size[..., 0] / fx\n\n    # Compute camera position\n    camera_position = -torch.bmm(R.transpose(1, 2), tvec.unsqueeze(-1)).squeeze(-1)\n\n    # Assemble camera parameters\n    camera_params = torch.cat([camera_position, rotation_6d, f_avg.unsqueeze(-1), sensor_width.unsqueeze(-1)], dim=-1)\n\n    return camera_params"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate input shapes\n    assert R.shape[:-2] == tvec.shape[:-2] == camera_matrix.shape[:-2] == image_size.shape[:-1], \"Input shapes do not match\"\n    \n    # Validate input values\n    assert torch.all(torch.abs(torch.det(R) - 1) < 1e-6), \"R must be a valid rotation matrix\"\n    \n    # Extract batch size\n    batch_size = R.shape[0]\n    \n    # Calculate camera rotation in 6D representation\n    rotation_6d = matrix_to_rotation_6d(R)\n    \n    # Calculate camera position\n    position = -torch.bmm(R.transpose(-1, -2), tvec.unsqueeze(-1)).squeeze(-1)\n    \n    # Extract focal lengths and principal points from camera intrinsic matrix\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    cx = camera_matrix[..., 0, 2]\n    cy = camera_matrix[..., 1, 2]\n    \n    # Validate focal lengths\n    if torch.any(torch.abs(fx - fy) / fx > 0.01):\n        warn_once_about_pulsar_fxfy()\n    \n    # Average focal lengths for x and y directions\n    f = (fx + fy) / 2\n    \n    # Calculate sensor width\n    sensor_width = 2 * f * torch.tan(torch.deg2rad(0.5 * image_size[..., 0]) / 2)\n    \n    # Normalize focal length\n    f_norm = f / image_size[..., 0]\n    \n    # Compute camera parameters\n    camera_params = torch.stack([position, rotation_6d, f_norm, sensor_width, znear * torch.ones(batch_size)], dim=-1)\n    \n    return camera_params"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate input shapes\n    assert R.shape[-2:] == (3, 3), \"Input R must have shape (*, 3, 3)\"\n    assert tvec.shape[-1] == 3, \"Input tvec must have shape (*, 3)\"\n    assert camera_matrix.shape[-2:] == (3, 3), \"Input camera_matrix must have shape (*, 3, 3)\"\n    assert image_size.shape[-1] == 2, \"Input image_size must have shape (*, 2)\"\n\n    # Convert rotation matrix to 6D representation\n    rotation_6d = matrix_to_rotation_6d(R)\n\n    # Extract focal lengths and principal points from camera matrix\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    cx = camera_matrix[..., 0, 2]\n    cy = camera_matrix[..., 1, 2]\n\n    # Average focal lengths for x and y directions\n    fx_avg = torch.mean(fx, dim=-1, keepdim=True)\n    fy_avg = torch.mean(fy, dim=-1, keepdim=True)\n\n    # Warn if focal lengths for x and y differ by more than 1%\n    if torch.any(torch.abs((fx - fy) / fx) > 0.01):\n        warn_once_about_pulsar_fxfy()\n\n    # Normalize focal length by image width\n    sensor_width = image_size[..., 0]\n    f = fx_avg / sensor_width\n\n    # Compute camera position\n    tvec = tvec.unsqueeze(-1)\n    position = -torch.bmm(R.transpose(-1, -2), tvec).squeeze(-1)\n\n    # Prepare camera parameters tensor\n    camera_params = torch.cat([position, rotation_6d, f], dim=-1)\n\n    return camera_params"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate input shapes\n    assert R.shape[:-2] == tvec.shape[:-2] == camera_matrix.shape[:-2] == image_size.shape[:-1], \"Input shapes do not match\"\n\n    # Calculate camera position\n    camera_position = -torch.bmm(torch.transpose(R, 1, 2), tvec.unsqueeze(-1))\n\n    # Convert rotation matrices to 6D representation\n    rotation_6d = matrix_to_rotation_6d(R)\n\n    # Calculate focal length and sensor width\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    sensor_width = camera_matrix[..., 0, 2] * 2\n\n    # Warn if focal lengths differ significantly\n    fx_diff = (fx - fy) / fx\n    if torch.any(torch.abs(fx_diff) > 0.01):\n        warn_once_about_pulsar_fxfy()\n\n    # Normalize focal length\n    focal_length = (fx + fy) / 2\n\n    # Normalize principal point offsets\n    cx = camera_matrix[..., 0, 2] / image_size[..., 1]\n    cy = camera_matrix[..., 1, 2] / image_size[..., 0]\n\n    # Compute and return camera parameters\n    return torch.cat([camera_position, rotation_6d, focal_length.unsqueeze(-1), sensor_width.unsqueeze(-1), cx.unsqueeze(-1), cy.unsqueeze(-1)], dim=-1)"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "\n    # Validate shapes\n    assert R.shape[:-2] == tvec.shape[:-1] == camera_matrix.shape[:-2] == image_size.shape[:-1], \"Shapes of R, tvec, camera_matrix, and image_size must be compatible\"\n\n    # Calculate camera rotation in 6D representation\n    rotation_6d = matrix_to_rotation_6d(R)\n\n    # Calculate camera position\n    position = -torch.bmm(R.transpose(1, 2), tvec.unsqueeze(-1)).squeeze(-1)\n\n    # Extract focal lengths and principal points from camera matrix\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    cx = camera_matrix[..., 0, 2]\n    cy = camera_matrix[..., 1, 2]\n\n    # Average focal lengths for x and y directions\n    fx_avg = (fx + fy) / 2\n\n    # Calculate sensor width\n    sensor_width = image_size[..., 0]\n\n    # Normalize focal length\n    f = fx_avg / sensor_width\n\n    # Calculate camera parameters\n    camera_params = torch.stack([position, rotation_6d, f], dim=-1)\n\n    return camera_params"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Ensure inputs are batched\n    assert R.shape[:-2] == tvec.shape[:-2] == camera_matrix.shape[:-2] == image_size.shape[:-1], \"Input shapes are not aligned\"\n\n    # Convert rotation matrices to 6D rotation representation\n    rot_6d = matrix_to_rotation_6d(R)\n\n    # Average focal lengths for x and y directions\n    fx, fy = camera_matrix[..., 0, 0], camera_matrix[..., 1, 1]\n    if torch.any(torch.abs(fx - fy) / fx > 0.01):\n        warn_once_about_pulsar_fxfy()\n    f = (fx + fy) / 2\n\n    # Compute sensor width\n    sensor_width = image_size[..., 0]\n\n    # Compute camera position\n    t = -torch.bmm(R.transpose(-1, -2), tvec.unsqueeze(-1)).squeeze(-1)\n\n    # Return the computed camera parameters\n    return torch.cat([t, rot_6d, f.unsqueeze(-1), sensor_width.unsqueeze(-1)], dim=-1)"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "\n    # Validate input shapes\n    assert R.shape[-2:] == (3, 3), \"Rotation matrix must have shape (*, 3, 3)\"\n    assert tvec.shape[-1] == 3, \"Translation vector must have shape (*, 3)\"\n    assert camera_matrix.shape[-2:] == (3, 3), \"Camera matrix must have shape (*, 3, 3)\"\n    assert image_size.shape[-1] == 2, \"Image size must have shape (*, 2)\"\n\n    # Compute camera rotation in 6D representation\n    rotation_6d = matrix_to_rotation_6d(R)\n\n    # Compute camera position\n    camera_position = -torch.bmm(R.transpose(-1, -2), tvec.unsqueeze(-1)).squeeze(-1)\n\n    # Compute intrinsic parameters\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    cx = camera_matrix[..., 0, 2]\n    cy = camera_matrix[..., 1, 2]\n    sensor_width = image_size[..., 0]\n\n    # Average focal lengths if they differ by more than 1%\n    if torch.any(torch.abs(fx - fy) / fx > 0.01):\n        warn_once_about_pulsar_fxfy()\n    f = (fx + fy) / 2\n\n    # Normalize focal length\n    f_norm = f / sensor_width\n\n    # Adjust focal length based on near clipping plane distance\n    f_adjusted = f_norm / znear\n\n    # Concatenate and return camera parameters\n    camera_params = torch.cat([camera_position, rotation_6d, f_adjusted], dim=-1)\n    return camera_params"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate input shapes\n    assert R.shape[:-2] == tvec.shape[:-2] == camera_matrix.shape[:-2] == image_size.shape[:-1], \"Input shapes are not compatible\"\n\n    # Validate input values\n    assert torch.allclose(R.transpose(-1, -2) @ R, torch.eye(3).expand_as(R)), \"R is not a valid rotation matrix\"\n    assert torch.allclose(torch.norm(R, dim=(-2, -1)), torch.ones(R.shape[:-2])), \"R is not a valid rotation matrix\"\n    assert torch.allclose(camera_matrix[..., 2, 3], 0), \"Camera matrix is not valid\"\n    assert torch.allclose(camera_matrix[..., 2, 2], 1), \"Camera matrix is not valid\"\n\n    # Compute camera position\n    tvec = tvec.view(*tvec.shape[:-2], 3, 1)\n    camera_position = -R.transpose(-1, -2) @ tvec\n\n    # Convert camera matrix to focal length and principal point\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    cx = camera_matrix[..., 0, 2]\n    cy = camera_matrix[..., 1, 2]\n\n    # Average focal lengths if they differ by more than 1%\n    if torch.any(torch.abs(fx - fy) > 0.01 * fx):\n        warn_once_about_pulsar_fxfy()\n    f = (fx + fy) / 2\n\n    # Normalize focal length by image width\n    sensor_width = 2 * f * torch.tan(torch.tensor(0.5) * torch.tensor(60) * torch.pi / 180)  # Assuming 60 degree FOV\n    f /= image_size[..., 1]\n\n    # Compute camera rotation in 6D representation\n    rotation_6d = matrix_to_rotation_6d(R)\n\n    # Return camera parameters\n    return torch.cat([camera_position, rotation_6d, f.unsqueeze(-1), sensor_width.unsqueeze(-1)], dim=-1)"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate input shapes\n    assert R.shape[:-2] == tvec.shape[:-2] == camera_matrix.shape[:-2] == image_size.shape[:-1], \"Input shapes do not match\"\n\n    # Validate input values\n    assert torch.all(torch.abs(torch.det(R) - 1) < 1e-6), \"R must be a valid rotation matrix\"\n    assert torch.all(torch.abs(torch.det(camera_matrix[..., :2, :2]) - 1) < 1e-6), \"Camera matrix must have valid focal lengths\"\n    assert torch.all(image_size > 0), \"Image size must be positive\"\n\n    # Calculate focal length\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    f = (fx + fy) / 2\n\n    # Calculate principal point offset\n    cx = camera_matrix[..., 0, 2]\n    cy = camera_matrix[..., 1, 2]\n\n    # Calculate sensor width\n    sensor_width = image_size[..., 0]\n\n    # Calculate camera position\n    tvec = tvec.view(-1, 3, 1)\n    position = -torch.bmm(R, tvec).view(*R.shape[:-2], 3)\n\n    # Convert rotation matrix to 6D representation\n    rotation = matrix_to_rotation_6d(R)\n\n    # Stack camera parameters\n    camera_params = torch.stack([position, rotation, f, cx, cy, sensor_width, znear], dim=-1)\n\n    return camera_params"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate input shapes\n    assert R.shape[:-2] == tvec.shape[:-2] == camera_matrix.shape[:-2] == image_size.shape[:-1], \"Input shapes do not match\"\n\n    # Convert rotation matrix to 6D representation\n    rotation_6d = matrix_to_rotation_6d(R)\n\n    # Compute focal length\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    f = (fx + fy) / 2\n\n    # Compute sensor width\n    sensor_width = image_size[..., 0]\n\n    # Calculate camera position\n    position = -torch.bmm(R.transpose(-1, -2), tvec.unsqueeze(-1)).squeeze(-1)\n\n    # Return computed camera parameters\n    return torch.cat([position, rotation_6d, f, sensor_width], dim=-1)"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Ensure all inputs are batched\n    assert R.ndim >= 2 and tvec.ndim >= 2 and camera_matrix.ndim >= 3 and image_size.ndim >= 2, \"Inputs must be batched\"\n\n    # Validate shapes of input tensors\n    assert R.shape[:-2] == tvec.shape[:-2] == camera_matrix.shape[:-2] == image_size.shape[:-2], \"Shapes of input tensors must match\"\n\n    # Validate values of input tensors\n    assert R.shape[-2:] == (3, 3), \"Rotation matrix must have shape (..., 3, 3)\"\n    assert tvec.shape[-1] == 3, \"Translation vector must have shape (..., 3)\"\n    assert camera_matrix.shape[-2:] == (3, 3), \"Camera matrix must have shape (..., 3, 3)\"\n    assert image_size.shape[-1] == 2, \"Image size must have shape (..., 2)\"\n\n    # Compute camera rotation in 6D representation\n    rotation_6d = matrix_to_rotation_6d(R)\n\n    # Compute camera position\n    position = -torch.bmm(R.transpose(-1, -2), tvec.unsqueeze(-1)).squeeze(-1)\n\n    # Compute camera intrinsic parameters\n    fx = (camera_matrix[..., 0, 0] + camera_matrix[..., 1, 1]) / 2  # Average of focal lengths for x and y\n    fy = fx\n    cx = camera_matrix[..., 0, 2] - image_size[..., 0] / 2  # Adjust principal point offset\n    cy = camera_matrix[..., 1, 2] - image_size[..., 1] / 2  # Adjust principal point offset\n    sensor_width = 2 * fx * image_size[..., 0] / camera_matrix[..., 0, 0]  # Calculate sensor width\n\n    # Normalize focal length by near clipping plane distance\n    focal_length = fx / znear\n\n    # Concatenate camera parameters\n    camera_params = torch.stack([position, rotation_6d, focal_length, sensor_width, cx, cy], dim=-1)\n\n    return camera_params"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Ensure all inputs are batched\n    assert R.dim() >= 3, \"Rotation matrix must be batched\"\n    assert tvec.dim() >= 2, \"Translation vector must be batched\"\n    assert camera_matrix.dim() >= 3, \"Camera matrix must be batched\"\n    assert image_size.dim() >= 2, \"Image size must be batched\"\n\n    # Validate shapes\n    assert R.size()[:-2] == tvec.size()[:-2], \"Rotation and translation batch dimensions do not match\"\n    assert R.size()[:-2] == camera_matrix.size()[:-2], \"Rotation and camera matrix batch dimensions do not match\"\n    assert R.size()[:-2] == image_size.size()[:-2], \"Rotation and image size batch dimensions do not match\"\n\n    # Calculate camera position\n    camera_position = -torch.bmm(R.transpose(-1, -2), tvec.unsqueeze(-1)).squeeze(-1)\n\n    # Convert rotation matrices to 6D representation\n    rotation_6d = matrix_to_rotation_6d(R)\n\n    # Extract focal lengths and principal points from camera matrix\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    cx = camera_matrix[..., 0, 2]\n    cy = camera_matrix[..., 1, 2]\n\n    # Average focal lengths for x and y directions\n    focal_length = (fx + fy) / 2\n\n    # Adjust principal point offsets based on image size\n    cx = cx - image_size[..., 0] / 2\n    cy = cy - image_size[..., 1] / 2\n\n    # Normalize focal length\n    sensor_width = 2 * focal_length * torch.tan(torch.tensor(0.5)) * znear\n    focal_length = focal_length / sensor_width\n\n    # Concatenate camera parameters\n    camera_params = torch.cat([camera_position, rotation_6d, focal_length, cx, cy], dim=-1)\n\n    return camera_params"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Ensure all inputs are batched\n    assert R.dim() == 3, \"R must be a batch of rotation matrices with shape (B, 3, 3)\"\n    assert tvec.dim() == 3, \"tvec must be a batch of translation vectors with shape (B, 3, 1)\"\n    assert camera_matrix.dim() == 3, \"camera_matrix must be a batch of camera intrinsic matrices with shape (B, 3, 3)\"\n    assert image_size.dim() == 2, \"image_size must be a batch of image sizes with shape (B, 2)\"\n\n    # Validate shapes\n    assert R.size(0) == tvec.size(0) == camera_matrix.size(0) == image_size.size(0), \"All inputs must have the same batch size\"\n\n    # Compute camera rotation in 6D representation\n    rotation_6d = matrix_to_rotation_6d(R)\n\n    # Compute camera position\n    position = -torch.bmm(R.transpose(1, 2), tvec)  # Camera position = -R^T * tvec\n\n    # Compute camera intrinsic parameters\n    fx = camera_matrix[:, 0, 0]  # Focal length in x-direction\n    fy = camera_matrix[:, 1, 1]  # Focal length in y-direction\n    cx = camera_matrix[:, 0, 2]  # Principal point offset in x-direction\n    cy = camera_matrix[:, 1, 2]  # Principal point offset in y-direction\n    sensor_width = image_size[:, 0]  # Sensor width\n\n    # Normalize focal length\n    f = (fx + fy) / 2  # Average focal length\n    warn_once_about_pulsar_fxfy()  # Display warning if focal lengths differ significantly\n\n    # Compute camera parameters\n    camera_params = torch.stack([position, rotation_6d, f, cx, cy, sensor_width, znear], dim=1)\n\n    return camera_params"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "\n    # Validate input shapes\n    assert R.shape[-2:] == (3, 3), \"Rotation matrix must have shape (*, 3, 3)\"\n    assert tvec.shape[-1] == 3, \"Translation vector must have shape (*, 3)\"\n    assert camera_matrix.shape[-2:] == (3, 3), \"Camera matrix must have shape (*, 3, 3)\"\n    assert image_size.shape[-1] == 2, \"Image size must have shape (*, 2)\"\n\n    # Convert camera matrix to focal length and principal point\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    cx = camera_matrix[..., 0, 2]\n    cy = camera_matrix[..., 1, 2]\n\n    # Average focal lengths if they differ by more than 1%\n    if torch.any(torch.abs(fx - fy) / fx > 0.01):\n        warn_once_about_pulsar_fxfy()\n\n    f = (fx + fy) / 2  # Average focal length\n    sensor_width = 2 * f * image_size[..., 0] / image_size[..., 1]  # Compute sensor width\n\n    # Compute camera position and rotation\n    tvec = tvec.unsqueeze(-2)\n    R = R.reshape(-1, 3, 3)  # Reshape R for matrix_to_rotation_6d\n    rotation_6d = matrix_to_rotation_6d(R)  # Convert rotation matrix to 6D representation\n    camera_params = torch.cat([tvec, rotation_6d, f.unsqueeze(-1), sensor_width.unsqueeze(-1)], dim=-1)\n\n    return camera_params"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "\n    # Validate input shapes\n    assert R.shape[:-2] == tvec.shape[:-1] == camera_matrix.shape[:-2] == image_size.shape[:-1], \"Input shapes are not compatible\"\n\n    # Calculate camera position\n    camera_position = -torch.bmm(R.transpose(1, 2), tvec.unsqueeze(-1)).squeeze(-1)\n\n    # Calculate focal length\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    sensor_width = camera_matrix[..., 0, 2] * 2  # Principal point offset\n    focal_length = (fx + fy) / 2\n\n    # Normalize focal length\n    normalized_focal_length = focal_length / image_size[..., 0]\n\n    # Compute camera rotation in 6D representation\n    rotation_6d = matrix_to_rotation_6d(R)\n\n    # Construct the output tensor\n    camera_params = torch.cat([camera_position, rotation_6d, normalized_focal_length, sensor_width], dim=-1)\n\n    return camera_params"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Ensure all inputs are batched\n    assert R.dim() == tvec.dim() == camera_matrix.dim() == image_size.dim() == 3, \"Inputs must be batched\"\n    assert R.size(0) == tvec.size(0) == camera_matrix.size(0) == image_size.size(0), \"Batch size mismatch\"\n\n    # Validate shapes\n    assert R.size(-2) == R.size(-1) == 3, \"Rotation matrix must be of shape (*, 3, 3)\"\n    assert tvec.size(-1) == 3, \"Translation vector must be of shape (*, 3)\"\n    assert camera_matrix.size(-2) == camera_matrix.size(-1) == 3, \"Intrinsic matrix must be of shape (*, 3, 3)\"\n    assert image_size.size(-1) == 2, \"Image size must be of shape (*, 2)\"\n\n    # Compute rotation in 6D representation\n    rotation_6d = matrix_to_rotation_6d(R)\n\n    # Compute camera position\n    position = -torch.bmm(R.transpose(-1, -2), tvec.unsqueeze(-1)).squeeze(-1)\n\n    # Compute intrinsic parameters\n    fx = (camera_matrix[..., 0, 0] + camera_matrix[..., 1, 1]) / 2  # Average focal length for x and y\n    fy = fx\n    cx = camera_matrix[..., 0, 2] - image_size[..., 0] / 2  # Adjust principal point offset\n    cy = camera_matrix[..., 1, 2] - image_size[..., 1] / 2  # Adjust principal point offset\n    sensor_width = image_size[..., 0]  # Sensor width is equal to image width\n\n    # Normalize focal length\n    focal_length = fx / sensor_width\n\n    # Adjust focal length based on near clipping plane\n    focal_length *= znear\n\n    # Concatenate camera parameters\n    camera_params = torch.stack([position, rotation_6d, fx, fy, cx, cy, sensor_width, focal_length], dim=-1)\n\n    return camera_params"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Ensure all inputs are batched\n    assert R.dim() == 3, \"Rotation matrix must be batched with shape (batch_size, 3, 3)\"\n    assert tvec.dim() == 3, \"Translation vector must be batched with shape (batch_size, 3, 1)\"\n    assert camera_matrix.dim() == 3, \"Camera matrix must be batched with shape (batch_size, 3, 3)\"\n    assert image_size.dim() == 2, \"Image size must be batched with shape (batch_size, 2)\"\n\n    # Validate shapes\n    assert R.size(0) == tvec.size(0) == camera_matrix.size(0) == image_size.size(0), \"All inputs must have the same batch size\"\n    assert camera_matrix.size(1) == camera_matrix.size(2) == 3, \"Camera matrix must be 3x3\"\n    assert image_size.size(1) == 2, \"Image size must be a 2D vector\"\n\n    # Convert camera matrix to focal length and principal point\n    fx = camera_matrix[:, 0, 0]\n    fy = camera_matrix[:, 1, 1]\n    cx = camera_matrix[:, 0, 2]\n    cy = camera_matrix[:, 1, 2]\n\n    # Average focal lengths if they differ by more than 1%\n    f_avg = (fx + fy) / 2.0\n    f_diff = torch.abs(fx - fy)\n    if torch.any(f_diff / f_avg > 0.01):\n        warn_once_about_pulsar_fxfy()\n\n    # Compute sensor width based on image size\n    sensor_width = image_size[:, 1] / (2.0 * f_avg)\n\n    # Compute camera position and rotation\n    camera_position = -torch.bmm(R.transpose(1, 2), tvec)  # -R^T * tvec\n\n    # Convert rotation matrix to 6D representation\n    rotation_6d = matrix_to_rotation_6d(R)\n\n    # Concatenate camera parameters\n    camera_params = torch.cat([camera_position, rotation_6d, f_avg.unsqueeze(1), sensor_width.unsqueeze(1)], dim=1)\n\n    return camera_params"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n        else:\n            if w == 0:\n                w = self.W\n            if h == 0:\n                h = self.H\n\n            old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n            old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n\n            gl.glViewport(x, y, w, h)\n            gl.glScissor(x, y, w, h)\n\n            gl.glUseProgram(self.quad_program)\n            gl.glBindVertexArray(self.vao)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n            gl.glBindVertexArray(0)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n            gl.glUseProgram(0)\n\n            gl.glViewport(*old_viewport)\n            gl.glScissor(*old_scissor)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n        else:\n            if w == 0:\n                w = self.W\n            if h == 0:\n                h = self.H\n\n            old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n            old_scissor_box = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n\n            gl.glViewport(x, y, w, h)\n            gl.glScissor(x, y, w, h)\n\n            gl.glUseProgram(self.quad_program)\n            self.use_gl_program(self.quad_program)\n\n            gl.glActiveTexture(gl.GL_TEXTURE0)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n            gl.glBindVertexArray(self.vao)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n            gl.glBindVertexArray(0)\n\n            gl.glUseProgram(0)\n\n            gl.glViewport(*old_viewport)\n            gl.glScissor(*old_scissor_box)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n        else:\n            if w == 0:\n                w = self.W\n            if h == 0:\n                h = self.H\n\n            old_viewport = gl.glGetInteger(gl.GL_VIEWPORT)\n            old_scissor_box = gl.glGetInteger(gl.GL_SCISSOR_BOX)\n\n            gl.glViewport(x, y, w, h)\n            gl.glScissor(x, y, w, h)\n\n            gl.glUseProgram(self.quad_program)\n            gl.glBindVertexArray(self.vao)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n            gl.glBindVertexArray(0)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n            gl.glUseProgram(0)\n\n            gl.glViewport(*old_viewport)\n            gl.glScissor(*old_scissor_box)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n        else:\n            if w == 0:\n                w = self.W\n            if h == 0:\n                h = self.H\n\n            old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n            old_scissor_box = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n\n            gl.glViewport(x, y, w, h)\n            gl.glScissor(x, y, w, h)\n\n            gl.glUseProgram(self.quad_program)\n            gl.glBindVertexArray(self.vao)\n\n            gl.glActiveTexture(gl.GL_TEXTURE0)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n            gl.glBindVertexArray(0)\n            gl.glUseProgram(0)\n\n            gl.glViewport(*old_viewport)\n            gl.glScissor(*old_scissor_box)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n        else:\n            if w == 0:\n                w = self.W\n            if h == 0:\n                h = self.H\n\n            old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n            old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n\n            gl.glViewport(x, y, w, h)\n            gl.glScissor(x, y, w, h)\n\n            gl.glUseProgram(self.quad_program)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glBindVertexArray(self.vao)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n            gl.glBindVertexArray(0)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n            gl.glUseProgram(0)\n\n            gl.glViewport(*old_viewport)\n            gl.glScissor(*old_scissor)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "    if not self.use_quad_draw:\n        self.blit(x, y, w, h)\n    else:\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor_box = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        gl.glUseProgram(self.quad_program)\n        gl.glBindVertexArray(self.vao)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        gl.glBindVertexArray(0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n        gl.glUseProgram(0)\n\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor_box)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n        else:\n            if w == 0:\n                w = self.W\n            if h == 0:\n                h = self.H\n\n            old_viewport = gl.glGetInteger(gl.GL_VIEWPORT)\n            old_scissor_box = gl.glGetInteger(gl.GL_SCISSOR_BOX)\n\n            gl.glViewport(x, y, w, h)\n            gl.glScissor(x, y, w, h)\n\n            gl.glUseProgram(self.quad_program)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glBindVertexArray(self.vao)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n            gl.glBindVertexArray(0)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n            gl.glUseProgram(0)\n\n            gl.glViewport(*old_viewport)\n            gl.glScissor(*old_scissor_box)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n        else:\n            if w == 0:\n                w = self.W\n            if h == 0:\n                h = self.H\n\n            old_vp = gl.glGetIntegerv(gl.GL_VIEWPORT)\n            old_sc = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n\n            gl.glViewport(x, y, w, h)\n            gl.glScissor(x, y, w, h)\n\n            gl.glUseProgram(self.quad_program)\n            gl.glBindVertexArray(self.vao)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n            gl.glBindVertexArray(0)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n            gl.glUseProgram(0)\n\n            gl.glViewport(*old_vp)\n            gl.glScissor(*old_sc)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.visible:\n            return\n\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n\n        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n            return\n\n        old_vp = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_sc = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        gl.glUseProgram(self.quad_program)\n        gl.glBindVertexArray(self.vao)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        gl.glBindVertexArray(0)\n        gl.glUseProgram(0)\n\n        gl.glViewport(*old_vp)\n        gl.glScissor(*old_sc)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n        else:\n            if w == 0:\n                w = self.W\n            if h == 0:\n                h = self.H\n            \n            gl.glViewport(x, y, w, h)\n            gl.glScissor(x, y, w, h)\n            gl.glUseProgram(self.quad_program)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glBindVertexArray(self.vao)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n            gl.glBindVertexArray(0)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n            gl.glUseProgram(0)\n            gl.glViewport(0, 0, self.W, self.H)\n            gl.glScissor(0, 0, self.W, self.H)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n        else:\n            if w == 0:\n                w = self.W\n            if h == 0:\n                h = self.H\n\n            old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n            old_scissor_box = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n\n            gl.glViewport(x, y, w, h)\n            gl.glScissor(x, y, w, h)\n\n            gl.glUseProgram(self.quad_program)\n            gl.glBindVertexArray(self.vao)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n            gl.glBindVertexArray(0)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n            gl.glUseProgram(0)\n\n            gl.glViewport(*old_viewport)\n            gl.glScissor(*old_scissor_box)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "    if not self.use_quad_draw:\n        self.blit(x, y, w, h)\n    else:\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        gl.glUseProgram(self.quad_program)\n        gl.glBindVertexArray(self.vao)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        gl.glBindVertexArray(0)\n        gl.glUseProgram(0)\n\n        gl.glViewport(0, 0, self.W, self.H)\n        gl.glScissor(0, 0, self.W, self.H)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n        else:\n            if w == 0:\n                w = self.W\n            if h == 0:\n                h = self.H\n\n            old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n            old_scissor_box = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n\n            gl.glViewport(x, y, w, h)\n            gl.glScissor(x, y, w, h)\n\n            gl.glUseProgram(self.quad_program)\n            gl.glBindVertexArray(self.vao)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n            gl.glBindVertexArray(0)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n            gl.glUseProgram(0)\n\n            gl.glViewport(*old_viewport)\n            gl.glScissor(*old_scissor_box)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n        else:\n            if w == 0:\n                w = self.W\n            if h == 0:\n                h = self.H\n\n            old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n            old_scissor_box = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n\n            gl.glViewport(x, y, w, h)\n            gl.glScissor(x, y, w, h)\n\n            gl.glUseProgram(self.quad_program)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glBindVertexArray(self.vao)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n            gl.glBindVertexArray(0)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n            gl.glUseProgram(0)\n\n            gl.glViewport(*old_viewport)\n            gl.glScissor(*old_scissor_box)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "    if not self.use_quad_draw:\n        self.blit(x, y, w, h)\n    else:\n        if w == 0:\n            w = self.W\n        if h == 0:\n            h = self.H\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n        gl.glUseProgram(self.quad_program)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n        gl.glBindVertexArray(0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n        gl.glUseProgram(0)\n        gl.glViewport(0, 0, self.W, self.H)\n        gl.glScissor(0, 0, self.W, self.H)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n        else:\n            if w == 0:\n                w = self.W\n            if h == 0:\n                h = self.H\n\n            # Set up viewport and scissor box for rendering\n            gl.glViewport(x, y, w, h)\n            gl.glScissor(x, y, w, h)\n\n            # Activate the shader program\n            gl.glUseProgram(self.quad_program)\n\n            # Bind the texture\n            gl.glActiveTexture(gl.GL_TEXTURE0)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n            # Draw the quadrilateral using vertex data\n            gl.glBindVertexArray(self.vao)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)  # 4 vertices for a quadrilateral\n            gl.glBindVertexArray(0)\n\n            # Restore the viewport and scissor box to their original sizes\n            gl.glViewport(0, 0, self.W, self.H)\n            gl.glScissor(0, 0, self.W, self.H)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n        else:\n            if w == 0:\n                w = self.W\n            if h == 0:\n                h = self.H\n\n            old_viewport = gl.glGetInteger(gl.GL_VIEWPORT)\n            old_scissor_box = gl.glGetInteger(gl.GL_SCISSOR_BOX)\n\n            gl.glViewport(x, y, w, h)\n            gl.glScissor(x, y, w, h)\n\n            gl.glUseProgram(self.quad_program)\n            gl.glBindVertexArray(self.vao)\n\n            gl.glActiveTexture(gl.GL_TEXTURE0)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n            gl.glBindVertexArray(0)\n            gl.glUseProgram(0)\n\n            gl.glViewport(*old_viewport)\n            gl.glScissor(*old_scissor_box)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n        else:\n            if w == 0:\n                w = self.W\n            if h == 0:\n                h = self.H\n\n            old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n            old_scissor_box = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n\n            gl.glViewport(x, y, w, h)\n            gl.glScissor(x, y, w, h)\n\n            gl.glUseProgram(self.quad_program)\n            gl.glBindVertexArray(self.vao)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n            gl.glBindVertexArray(0)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n            gl.glUseProgram(0)\n\n            gl.glViewport(*old_viewport)\n            gl.glScissor(*old_scissor_box)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n        else:\n            if w == 0:\n                w = self.W\n            if h == 0:\n                h = self.H\n\n            old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n            old_scissor_box = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n\n            gl.glViewport(x, y, w, h)\n            gl.glScissor(x, y, w, h)\n\n            gl.glUseProgram(self.quad_program)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glBindVertexArray(self.vao)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n            gl.glBindVertexArray(0)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n            gl.glUseProgram(0)\n\n            gl.glViewport(*old_viewport)\n            gl.glScissor(*old_scissor_box)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n        else:\n            if w == 0:\n                w = self.W\n            if h == 0:\n                h = self.H\n\n            gl.glViewport(x, y, w, h)\n            gl.glScissor(x, y, w, h)\n\n            gl.glUseProgram(self.quad_program)\n            gl.glBindVertexArray(self.vao)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n            gl.glBindVertexArray(0)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n\n            gl.glViewport(0, 0, self.W, self.H)\n            gl.glScissor(0, 0, self.W, self.H)"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n\n    # Adjust R and T to match PyTorch3D's requirements\n    R = R.permute(0, 2, 1)  # Transpose R\n    T = -torch.bmm(R, T.unsqueeze(2)).squeeze(2)  # Adjust T\n\n    # Compute the intrinsic matrix for NDC\n    f = (K[:, 0, 0] + K[:, 1, 1]) / 2\n    cx = K[:, 0, 2]\n    cy = K[:, 1, 2]\n    K_ndc = torch.stack([torch.stack([f, 0, cx]), torch.stack([0, f, cy]), torch.tensor([0, 0, 1])], dim=1)\n\n    return H, W, K_ndc, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n\n    # Adjust rotation and translation matrices to match PyTorch3D's requirements\n    R = R.permute(0, 2, 1)  # Transpose R\n    T = -torch.bmm(R, T.unsqueeze(2)).squeeze(2)  # Adjust T\n\n    # Recalculate the intrinsic matrix for NDC\n    fx = K[:, 0, 0].unsqueeze(1)\n    fy = K[:, 1, 1].unsqueeze(1)\n    cx = K[:, 0, 2].unsqueeze(1)\n    cy = K[:, 1, 2].unsqueeze(1)\n    K = torch.stack([fx, fy, cx, cy], dim=1)\n\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n\n    # Adjust rotation matrix for PyTorch3D's coordinate system\n    R = R.permute(0, 2, 1)\n\n    # Recalculate the intrinsic matrix for normalized device coordinates (NDC)\n    K_ndc = K.clone()\n    K_ndc[:, 0, 0] /= W\n    K_ndc[:, 0, 2] /= W\n    K_ndc[:, 1, 1] /= H\n    K_ndc[:, 1, 2] /= H\n\n    return H, W, K_ndc, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "\n    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n\n    # Adjust R and T to match PyTorch3D's requirements\n    R = R.transpose(1, 2)  # Transpose R to match PyTorch3D's requirements\n    T = -torch.matmul(R, T)  # Adjust T based on the transposed R\n\n    # Compute the intrinsic matrix for NDC\n    f = (K[:, 0, 0] + K[:, 1, 1]) / 2  # Average of focal lengths\n    cx = K[:, 0, 2]\n    cy = K[:, 1, 2]\n    K_ndc = torch.tensor([[f / cx, 0, 0, 0],\n                          [0, f / cy, 0, 0],\n                          [0, 0, 1, 0],\n                          [0, 0, 0, 1]], device=K.device, dtype=K.dtype)\n\n    return H, W, K_ndc, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n\n    # Adjust R and T to match PyTorch3D's requirements\n    R = R.permute(0, 2, 1)  # Transpose R\n    T = -torch.bmm(R, T.unsqueeze(2)).squeeze(2)  # Adjust T\n\n    # Recalculate the intrinsic matrix K for NDC\n    K = K.clone()\n    K[:, 0, 2] = W - K[:, 0, 2]  # Adjust principal point offset\n    K[:, 1, 2] = H - K[:, 1, 2]  # Adjust principal point offset\n    K[:, 1, 1] = -K[:, 1, 1]  # Flip y focal length\n\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n\n    # Adjust rotation matrix to match PyTorch3D's requirements\n    R = R.permute(0, 2, 1)\n\n    # Recalculate intrinsic matrix for NDC\n    K_ndc = K.clone()\n    K_ndc[:, 0, 0] /= W\n    K_ndc[:, 0, 2] /= W\n    K_ndc[:, 1, 1] /= H\n    K_ndc[:, 1, 2] /= H\n\n    return H, W, K_ndc, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n\n    # Adjust R and T to match PyTorch3D's requirements\n    R = R.permute(0, 2, 1)  # Transpose R\n    T = -R @ T  # Adjust T based on transposed R\n\n    # Recalculate the intrinsic matrix K for NDC\n    K = K.clone()\n    K[:, 0, 2] = W - K[:, 0, 2]  # Adjust principal point x-coordinate\n    K[:, 1, 2] = H - K[:, 1, 2]  # Adjust principal point y-coordinate\n\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n\n    # Adjust R and T to match PyTorch3D's requirements\n    R = R.permute(0, 2, 1)  # Transpose R to match PyTorch3D's requirements\n    T = -torch.bmm(R, T)  # Adjust T based on the transposed R\n\n    # Recalculate the intrinsic matrix K for NDC\n    K = K.clone()\n    K[:, 0, 2] = W - K[:, 0, 2]  # Adjust the principal point to match PyTorch3D's coordinate system\n    K[:, 1, 2] = H - K[:, 1, 2]  # Adjust the principal point to match PyTorch3D's coordinate system\n\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n\n    # Adjust rotation matrix for PyTorch3D's coordinate system\n    R = R.permute(0, 2, 1)\n\n    # Recalculate the intrinsic matrix (K) for NDC\n    K[:, 0, 2] = W - K[:, 0, 2]  # Adjust the principal point for PyTorch3D's NDC\n    K[:, 1, 2] = H - K[:, 1, 2]  # Adjust the principal point for PyTorch3D's NDC\n    K[:, 1, 1] = -K[:, 1, 1]  # Flip the y focal length for PyTorch3D's NDC\n\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n\n    # Adjust the rotation matrix and translation vector to match PyTorch3D's requirements\n    R = R.permute(0, 2, 1)  # Transpose the rotation matrix\n\n    # Recalculate the intrinsic matrix for NDC\n    f_x = K[:, 0, 0]\n    f_y = K[:, 1, 1]\n    c_x = K[:, 0, 2]\n    c_y = K[:, 1, 2]\n    K = torch.stack([\n        torch.stack([f_x, torch.zeros_like(f_x), c_x, torch.zeros_like(f_x)], dim=1),\n        torch.stack([torch.zeros_like(f_y), f_y, c_y, torch.zeros_like(f_y)], dim=1),\n        torch.tensor([0., 0., 1., 0.], device=K.device).repeat(K.shape[0], 1)\n    ], dim=1)\n\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n\n    # Adjust R and T for PyTorch3D's coordinate system\n    R = R.permute(0, 2, 1)  # Transpose R\n    T = -torch.bmm(R, T.unsqueeze(2)).squeeze(2)  # Adjust T\n\n    # Compute the intrinsic matrix for NDC\n    fx = K[:, 0, 0]\n    fy = K[:, 1, 1]\n    cx = K[:, 0, 2]\n    cy = K[:, 1, 2]\n    K_ndc = torch.stack([fx / W, fy / H, (2 * cx - W) / W, (2 * cy - H) / H], dim=1)\n\n    return H, W, K_ndc, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n\n    # Adjust R and T to match PyTorch3D's requirements\n    R = R.permute(0, 2, 1)  # Transpose R\n    T = -torch.bmm(R, T)  # Adjust T\n\n    # Compute the intrinsic matrix for NDC\n    fx = K[:, 0, 0]\n    fy = K[:, 1, 1]\n    cx = K[:, 0, 2]\n    cy = K[:, 1, 2]\n    K_ndc = torch.stack([fx / W, fy / H, 1.0, 0.0, cx / W, cy / H, 0.0, 0.0, 1.0], dim=1).view(-1, 3, 3)\n\n    return H, W, K_ndc, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n\n    # Adjust R and T to match PyTorch3D's requirements\n    R = R.permute(0, 2, 1)  # Transpose R\n    T = -torch.bmm(R, T.unsqueeze(2)).squeeze(2)  # Adjust T\n\n    # Recalculate intrinsic matrix K for NDC\n    fx = K[:, 0, 0]\n    fy = K[:, 1, 1]\n    cx = K[:, 0, 2]\n    cy = K[:, 1, 2]\n    K = torch.stack([\n        torch.stack([fx, 0, cx], dim=1),\n        torch.stack([0, fy, cy], dim=1),\n        torch.tensor([0, 0, 1], dtype=torch.float32, device=K.device).repeat(K.size(0), 1)\n    ], dim=1)\n\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n\n    # Adjust R and T to match PyTorch3D's requirements\n    R = R.permute(0, 2, 1)  # Transpose R\n    T = -torch.bmm(R, T.unsqueeze(2)).squeeze(2)  # Adjust T\n\n    # Recalculate the intrinsic matrix K for NDC\n    fx = K[:, 0, 0].unsqueeze(1)\n    fy = K[:, 1, 1].unsqueeze(1)\n    cx = K[:, 0, 2].unsqueeze(1)\n    cy = K[:, 1, 2].unsqueeze(1)\n\n    K = torch.stack([torch.stack([fx, 0, cx], dim=1),\n                     torch.stack([0, fy, cy], dim=1),\n                     torch.tensor([0, 0, 1], device=K.device).repeat(K.size(0), 1, 1)], dim=1)\n\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n\n    # Adjust rotation matrix for PyTorch3D's coordinate system\n    R = R.permute(0, 2, 1)\n\n    # Recalculate the intrinsic matrix for NDC\n    K_ndc = K.clone()\n    K_ndc[:, 0, 2] = (W - 1) / 2\n    K_ndc[:, 1, 2] = (H - 1) / 2\n    K_ndc[:, 0, 0] = (W - 1) / 2 / torch.tan(K_ndc[:, 0, 0] / 2)\n    K_ndc[:, 1, 1] = (H - 1) / 2 / torch.tan(K_ndc[:, 1, 1] / 2)\n\n    return H, W, K_ndc, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()\n    W = batch.meta.W[0].item()\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n\n    # Adjust R and T to match PyTorch3D's requirements\n    R = R.permute(0, 2, 1)\n    T = -torch.bmm(R, T.unsqueeze(2)).squeeze(2)\n\n    # Recalculate the intrinsic matrix K for NDC\n    fx = K[..., 0, 0]\n    fy = K[..., 1, 1]\n    cx = K[..., 0, 2]\n    cy = K[..., 1, 2]\n    K = torch.stack([\n        torch.stack([fx / W, 0, (W - 1) / 2], dim=1),\n        torch.stack([0, fy / H, (H - 1) / 2], dim=1),\n        torch.tensor([0, 0, 1], device=K.device).repeat(K.shape[0], 1)\n    ], dim=1)\n\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n\n    # Adjust R and T to match PyTorch3D's requirements\n    R = R.permute(0, 2, 1)  # Transpose R\n    T = -torch.bmm(R, T.unsqueeze(2)).squeeze(2)  # Adjust T\n\n    # Recalculate the intrinsic matrix for NDC\n    fx = K[:, 0, 0].unsqueeze(1)\n    fy = K[:, 1, 1].unsqueeze(1)\n    cx = K[:, 0, 2].unsqueeze(1)\n    cy = K[:, 1, 2].unsqueeze(1)\n\n    K = torch.stack([torch.stack([fx, torch.zeros_like(fx), cx], dim=1),\n                     torch.stack([torch.zeros_like(fy), fy, cy], dim=1),\n                     torch.tensor([0., 0., 1.], device=K.device).repeat(K.shape[0], 1)], dim=1)\n\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H, W, K, R, T, C = get_opencv_camera_params(batch)\n    K = get_pulsar_camera_params(R, T, K, torch.tensor([H, W]))\n    R = R.permute(0, 2, 1)  # Transpose R\n    T = -torch.bmm(R, T)  # Adjust T\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n\n    # Adjust R and T to match PyTorch3D's requirements\n    R = R.permute(0, 2, 1)  # Transpose R\n    T = -torch.bmm(R, T)  # Adjust T\n\n    # Compute the intrinsic matrix for NDC\n    f = torch.mean(torch.diagonal(K, dim1=-2, dim2=-1), dim=-1)  # Average of focal lengths\n    cx = K[..., 0, 2]\n    cy = K[..., 1, 2]\n    K_ndc = torch.tensor([[f / cx, 0, 0], [0, f / cy, 0], [0, 0, 1]])\n\n    return H, W, K_ndc, R, T, C"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "    gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n    gl.glBlitFramebuffer(0, 0, self.W, self.H, x, y, x + (self.W if w == 0 else w), y + (self.H if h == 0 else h), gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n    gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glReadBuffer(gl.GL_COLOR_ATTACHMENT0)\n        gl.glBlitFramebuffer(0, 0, self.W, self.H, x, y, x + w, y + h, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glReadBuffer(gl.GL_COLOR_ATTACHMENT0)\n        gl.glBlitFramebuffer(0, 0, self.W, self.H, x, y, x + (self.W if w == 0 else w), y + (self.H if h == 0 else h), gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "    old_fbo = gl.glGetIntegerv(gl.GL_READ_FRAMEBUFFER_BINDING)\n    gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n    gl.glBlitFramebuffer(0, 0, self.W, self.H, x, y, x + (self.W if w == 0 else w), y + (self.H if h == 0 else h), gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n    gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old_fbo)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(0, 0, self.W, self.H, x, y, x + w, y + h, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        # Bind the framebuffer object (FBO) as the read framebuffer\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n\n        # Set the source and destination rectangles for the pixel copy operation\n        src_x0, src_y0, src_x1, src_y1 = x, y, x + w, y + h\n        dst_x0, dst_y0, dst_x1, dst_y1 = 0, 0, w, h\n\n        # Perform the pixel copy operation\n        gl.glBlitFramebuffer(src_x0, src_y0, src_x1, src_y1, dst_x0, dst_y0, dst_x1, dst_y1, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n\n        # Restore the previously bound read framebuffer\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(0, 0, self.W, self.H, x, y, x + (self.W if w == 0 else w), y + (self.H if h == 0 else h), gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "    gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n    gl.glBlitFramebuffer(0, 0, self.W, self.H, x, y, x + (self.W if w == 0 else w), y + (self.H if h == 0 else h), gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n    gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "    gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n    gl.glBlitFramebuffer(0, 0, self.W, self.H, x, y, x + w, y + h, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n    gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "    gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n    gl.glBlitFramebuffer(0, 0, self.W, self.H, x, y, x + w, y + h, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n    gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(0, 0, self.W, self.H, x, y, x + (self.W if w == 0 else w), y + (self.H if h == 0 else h), gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(0, 0, self.W, self.H, x, y, x + w, y + h, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "    old_fbo = gl.glGetIntegerv(gl.GL_READ_FRAMEBUFFER_BINDING)  # store the current read framebuffer\n    gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)  # bind the Quad's framebuffer as the read framebuffer\n    gl.glBlitFramebuffer(0, 0, self.W, self.H, x, y, x + w, y + h, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)  # perform the pixel copy operation\n    gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old_fbo)  # restore the previously bound read framebuffer"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(0, 0, self.W, self.H, x, y, x + (self.W if w == 0 else w), y + (self.H if h == 0 else h), gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        # Bind the framebuffer object (FBO) as the read framebuffer\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n\n        # Set the source and destination rectangles for the blit operation\n        src_x0, src_y0, src_x1, src_y1 = x, y, x + w, y + h\n        dst_x0, dst_y0, dst_x1, dst_y1 = 0, 0, w, h\n\n        # Perform the blit operation\n        gl.glBlitFramebuffer(src_x0, src_y0, src_x1, src_y1, dst_x0, dst_y0, dst_x1, dst_y1, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n\n        # Restore the previously bound read framebuffer\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(0, 0, self.W, self.H, x, y, x + (self.W if w == 0 else w), y + (self.H if h == 0 else h), gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(0, 0, self.W, self.H, x, y, x + (self.W if w == 0 else w), y + (self.H if h == 0 else h), gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(0, 0, self.W, self.H, x, y, x + (self.W if w == 0 else w), y + (self.H if h == 0 else h), gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        # Bind the framebuffer object (FBO) as the read framebuffer\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n\n        # Set the source and destination rectangles for the pixel copy operation\n        src_x0, src_y0, src_x1, src_y1 = x, y, x + w, y + h\n        dst_x0, dst_y0, dst_x1, dst_y1 = 0, 0, w, h\n\n        # Perform the pixel copy operation\n        gl.glBlitFramebuffer(src_x0, src_y0, src_x1, src_y1, dst_x0, dst_y0, dst_x1, dst_y1, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n\n        # Restore the previously bound read framebuffer\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, 0)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)\n        gl.glBlitFramebuffer(0, 0, self.W, self.H, x, y, x + (self.W if w == 0 else w), y + (self.H if h == 0 else h), gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, 0)"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Find the indices for the elements of t1 that are less than or equal to t0\n    idx = searchsorted(t1, t0, side='right')\n\n    # Calculate the inner measure using cumulative sum\n    inner = torch.cumsum(y1, dim=0)\n    inner = inner[idx]\n\n    # Calculate the outer measure using cumulative sum\n    outer = torch.cumsum(y1, dim=0)\n    outer = outer[-1] - outer[idx]\n\n    return inner, outer"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Calculate the differences between consecutive source times\n    dt = t1[1:] - t1[:-1]\n\n    # Calculate the cumulative sum of the product of the differences and the corresponding values\n    inner = torch.cumsum(dt * y1[:-1], dim=0)\n\n    # Calculate the cumulative sum of the differences\n    outer = torch.cumsum(dt, dim=0)\n\n    # Interpolate the outer measure to the target times\n    outer = torch.interp(t0, t1[1:], outer)\n\n    return inner, outer"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    idx = searchsorted(t1, t0)\n    idx = torch.clamp(idx, 1, t1.size(0) - 1)\n\n    t1a = t1[idx - 1]\n    t1b = t1[idx]\n\n    y1a = y1[idx - 1]\n    y1b = y1[idx]\n\n    inner = y1a + (y1b - y1a) * (t0 - t1a) / (t1b - t1a)\n    outer = y1a + (y1b - y1a) * (t0 - t1a) / (t1b - t1a)\n\n    return inner, outer"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Find the indices of the closest values in t1 for each value in t0\n    idx = searchsorted(t1, t0)\n\n    # Match up the channels in y1 with the indices found\n    y1_matched = matchup_channels(y1, idx)\n\n    # Calculate the cumulative sum of y1_matched for the inner measure\n    inner_measure = torch.cumsum(y1_matched, dim=1)\n\n    # Calculate the cumulative sum of y1_matched for the outer measure\n    outer_measure = torch.cumsum(y1_matched.flip(dims=[1]), dim=1).flip(dims=[1])\n\n    return inner_measure, outer_measure"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Calculate the differences between consecutive source times\n    dt = t1[1:] - t1[:-1]\n\n    # Calculate the cumulative sum of the product of the values and time differences\n    inner = torch.cumsum(y1[:-1] * dt, dim=0)\n\n    # Calculate the cumulative sum of the values\n    outer = torch.cumsum(y1[:-1], dim=0)\n\n    # Interpolate the outer measure at the target time t0\n    outer = torch.interp(t0, t1[:-1], outer)\n\n    return inner, outer"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    idxs = searchsorted(t1, t0)\n    idxs = torch.clamp(idxs, 1, len(t1) - 1)\n    idx0 = torch.clamp(idxs - 1, 0, len(t1) - 1)\n    idx1 = torch.clamp(idxs, 0, len(t1) - 1)\n\n    dt = t1[idx1] - t1[idx0]\n    inner = (t1[idx1] - t0) / dt\n    outer = (t0 - t1[idx0]) / dt\n\n    y0 = y1[idx0]\n    y1 = y1[idx1]\n\n    inner = y0 + inner * (y1 - y0)\n    outer = y0 + outer * (y1 - y0)\n\n    return inner, outer"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    t0 = t0.unsqueeze(1)\n    t1 = t1.unsqueeze(0)\n    dt = t1 - t0\n    dt = torch.where(dt == 0, torch.ones_like(dt), dt)\n    inner = torch.sum(y1 * (1 / dt) * F.relu(1 - torch.abs(t1 - t0)), dim=1)\n    outer = torch.sum(y1 * (1 / dt) * F.relu(1 - torch.abs(t1 - t0)), dim=0)\n    return inner, outer"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Find the indices where t0 is between t1\n    idx = searchsorted(t1, t0)\n    \n    # Match up the channels of y1 with the indices\n    y0 = matchup_channels(y1, idx)\n    \n    # Compute the inner measure\n    inner = torch.cumsum(y0, dim=1)\n    \n    # Compute the outer measure\n    outer = torch.cumsum(y0[:, ::-1], dim=1)[:, ::-1]\n\n    return inner, outer"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    idx = searchsorted(t1, t0)\n    idx = torch.clamp(idx, 1, len(t1) - 1)\n    idx0 = idx - 1\n    idx1 = idx\n\n    dt = t1[idx1] - t1[idx0]\n    y0 = y1[idx0]\n    y1 = y1[idx1]\n\n    inner = y0 + (y1 - y0) * (t0 - t1[idx0]) / dt\n    outer = y0 + (y1 - y0) * (t0 - t1[idx1]) / dt\n\n    return inner, outer"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Find the indices of the closest elements in t1 for each element in t0\n    idx = searchsorted(t1, t0)\n\n    # Match up the channels of y1 with the indices found in t1\n    y1_matched = matchup_channels(y1, idx)\n\n    # Calculate the cumulative sum of y1_matched to get the inner measure\n    inner_measure = torch.cumsum(y1_matched, dim=1)\n\n    # Calculate the outer measure by subtracting the inner measure from the cumulative sum of y1\n    outer_measure = torch.cumsum(y1, dim=1) - inner_measure\n\n    return inner_measure, outer_measure"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Find the index of the closest time in t1 for each time in t0\n    idx = searchsorted(t1, t0)\n\n    # Match up the channels of t1 and y1 based on the index\n    y1_matched = matchup_channels(y1, idx)\n\n    # Calculate the cumulative sum of y1_matched\n    cumsum_y1 = torch.cumsum(y1_matched, dim=1)\n\n    # Calculate the inner measure\n    inner_measure = cumsum_y1[:, -1]\n\n    # Calculate the outer measure\n    outer_measure = cumsum_y1[:, -1] - cumsum_y1[:, 0]\n\n    return inner_measure, outer_measure"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    t1 = t1.view(-1, 1)\n    t0 = t0.view(1, -1)\n    y1 = y1.view(-1, 1)\n\n    dt = t0 - t1\n    dt[dt == 0] = 1  # Avoid division by zero\n\n    inner = torch.sum(y1 * (t0 - t1) / dt, dim=0)\n    outer = torch.sum(y1 * (t0 - t1) / dt, dim=0) + y1\n\n    return inner, outer"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Find the indices for the closest source times to the target times\n    idx = searchsorted(t1, t0)\n\n    # Match up the channels for the closest source times\n    y0 = matchup_channels(y1, idx)\n\n    # Calculate the cumulative sums for inner and outer measures\n    inner = torch.cumsum(y0, dim=1)\n    outer = torch.cumsum(y0, dim=1) - inner\n\n    return inner, outer"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Find the indices for the closest time points in t1 for each target time in t0\n    idx = searchsorted(t1, t0)\n\n    # Match up the channels of y1 with the indices found above\n    y1_matched = matchup_channels(y1, idx)\n\n    # Calculate the cumulative sum for the inner measure\n    inner_measure = torch.cumsum(y1_matched, dim=1)\n\n    # Calculate the outer measure by subtracting the inner measure from the total sum\n    outer_measure = torch.sum(y1_matched, dim=1) - inner_measure[:, -1]\n\n    return inner_measure, outer_measure"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Find the indices of the source times that are less than or equal to the target time\n    idx = searchsorted(t1, t0)\n\n    # Calculate the inner measure using the cumulative sum of the values at the corresponding indices\n    inner = torch.cumsum(y1[idx - 1], dim=0)\n\n    # Calculate the outer measure using the cumulative sum of the values at the corresponding indices\n    outer = torch.cumsum(y1[idx], dim=0)\n\n    return inner, outer"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Find the indices of the source times that are less than or equal to the target time\n    idx = searchsorted(t1, t0)\n\n    # Matchup the channels of the source values with the target times\n    y1_interp = matchup_channels(y1, idx)\n\n    # Calculate the cumulative sum of the matched up source values\n    inner = torch.cumsum(y1_interp, dim=1)\n\n    # Calculate the outer measure by taking the last value of the cumulative sum\n    outer = inner[:, -1]\n\n    return inner, outer"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Find the indices of the source time points that are less than or equal to the target time\n    idx = searchsorted(t1, t0)\n\n    # Match up the channels for the inner and outer measures\n    y1_inner = matchup_channels(y1, idx)\n    y1_outer = matchup_channels(y1, idx - 1)\n\n    # Calculate the inner and outer measures using cumulative sums\n    inner = torch.cumsum(y1_inner * (t0 - t1[idx - 1]) / (t1[idx] - t1[idx - 1]), dim=-1)\n    outer = torch.cumsum(y1_outer * (t0 - t1[idx]) / (t1[idx - 1] - t1[idx]), dim=-1)\n\n    return inner, outer"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Find the indices of the source times that are less than the target time\n    idx = searchsorted(t1, t0)\n    \n    # Calculate the inner measure using linear interpolation\n    inner = (t0 - t1[idx - 1]) / (t1[idx] - t1[idx - 1]) * y1[idx] + (t1[idx] - t0) / (t1[idx] - t1[idx - 1]) * y1[idx - 1]\n    \n    # Calculate the outer measure as the difference between the cumulative sum at the target time and the inner measure\n    outer = torch.cumsum(y1, dim=0)[idx] - inner\n    \n    return inner, outer"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Find the indices for the source times that are less than or equal to the target time\n    idx = searchsorted(t1, t0)\n\n    # Match up the channels for the target time and source time\n    y1_matched = matchup_channels(y1, idx)\n\n    # Calculate the inner measure by taking the cumulative sum of the matched values\n    inner = torch.cumsum(y1_matched, dim=1)\n\n    # Calculate the outer measure by taking the cumulative sum of the matched values and subtracting it from the total sum\n    outer = torch.sum(y1_matched, dim=1) - inner\n\n    return inner, outer"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    t0 = t0.unsqueeze(1)\n    t1 = t1.unsqueeze(0)\n    y1 = y1.unsqueeze(0)\n\n    dt = t1[:, 1:] - t1[:, :-1]\n    dt = torch.cat([dt, torch.tensor([[1e-6]], device=dt.device, dtype=dt.dtype)], dim=1)\n\n    t1 = (t1 - t0) / dt\n    t1 = torch.clamp(t1, 0, 1)\n\n    t1_f = t1.floor().long()\n    t1_c = t1.ceil().long()\n\n    y1_f = y1.gather(1, t1_f)\n    y1_c = y1.gather(1, t1_c)\n\n    inner = y1_f + (y1_c - y1_f) * (t1 - t1_f.float())\n    outer = y1_f + (y1_c - y1_f) * (t1_c.float() - t1)\n\n    return inner, outer"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    y0_inner, y0_outer = inner_outer(t, t_env, w_env)\n    w_outer = matchup_channels(t, y0_inner, y0_outer, w)\n\n    loss = (w - w_outer).clamp_min(0).pow(2).sum(-1).mean()\n    return loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    y0_inner, y0_outer = inner_outer(t, t_env, w_env)\n\n    y0_inner = y0_inner.clamp_min(eps)\n    y0_outer = y0_outer.clamp_min(eps)\n\n    loss = F.huber_loss(w[:-1], y0_inner / y0_outer * w_env, reduction='mean')\n\n    return loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    y0_inner, y0_outer = inner_outer(t, t_env, w_env)\n    y0_outer = torch.clamp(y0_outer, min=eps)\n    y0_inner = torch.clamp(y0_inner, min=0)\n\n    y0_outer_sq = y0_outer ** 2\n    y0_inner_sq = y0_inner ** 2\n\n    loss = (w - y0_outer_sq) / (y0_inner_sq + eps)\n    loss = torch.where(w > y0_outer_sq, loss, (w - y0_outer) ** 2)\n\n    return loss.mean()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    t0 = t\n    t1 = t_env\n    y1 = w_env\n\n    y0_inner, y0_outer = inner_outer(t0, t1, y1)\n\n    y0_outer = y0_outer.clamp(min=eps)\n    y0_inner = y0_inner.clamp(min=eps)\n\n    loss_outer = (w - y0_outer).pow(2) / (y0_outer.pow(2) + eps)\n    loss_outer += 2 * (w - y0_outer).abs() - 1\n\n    return loss_outer.mean()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    t0, t1 = t_env, t\n    y1 = w_env\n\n    y0_inner, y0_outer = inner_outer(t0, t1, y1)\n\n    y0_outer = y0_outer.clamp(min=eps)\n    y0_inner = y0_inner.clamp(min=eps)\n\n    loss = (w - y0_outer).clamp(min=0) + (y0_inner / y0_outer).log()\n    return loss.mean()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    y0_inner, y0_outer = inner_outer(t, t_env, w_env)\n    y0_inner = y0_inner.clamp(min=eps)\n    y0_outer = y0_outer.clamp(min=eps)\n    loss = (w - y0_outer).pow(2) / (y0_inner + eps) + 2 * torch.sqrt(y0_inner * y0_outer)\n    return loss.mean()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    y0_inner, y0_outer = inner_outer(t, t_env, w_env)\n\n    y0_inner = matchup_channels(y0_inner, w)\n    y0_outer = matchup_channels(y0_outer, w)\n\n    loss = (w - y0_outer).clamp_min(0) ** 2 / (y0_inner + eps)\n    return loss.sum()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    t0 = t_env\n    y1 = w_env\n    t1 = t\n    y0 = w\n\n    y0_inner, y0_outer = inner_outer(t0, t1, y1)\n\n    y0_outer = torch.max(y0_outer, eps)\n    y0_inner = torch.max(y0_inner, eps)\n\n    loss_outer = (y0 - y0_outer) ** 2 / (y0_outer ** 2 + y0_inner ** 2)\n\n    return loss_outer.mean()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    y0_inner, y0_outer = inner_outer(t, t_env, w_env)\n\n    w_env_interp = matchup_channels(t, t_env, w_env)  # 128\n    w_env_interp = torch.cat([w_env_interp[..., :1], w_env_interp], dim=-1)  # 129\n\n    w_env_lo = torch.take_along_dim(w_env_interp, searchsorted(t_env, t)[0], dim=-1)  # 128\n    w_env_hi = torch.take_along_dim(w_env_interp, searchsorted(t_env, t)[1], dim=-1)\n\n    w_env_inner = w_env_hi[..., 1:] - w_env_lo[..., :-1]  # 127\n\n    w_env_outer = w_env_lo[..., 1:] - w_env_hi[..., :-1]  # 127\n\n    w_env_outer = torch.max(w_env_outer, eps * torch.ones_like(w_env_outer))  # 127\n    w_env_inner = torch.max(w_env_inner, eps * torch.ones_like(w_env_inner))\n\n    loss_inner = (w - y0_inner) ** 2 / (w_env_inner ** 2 + eps)  # 127\n    loss_outer = (w - y0_outer) ** 2 / (w_env_outer ** 2 + eps)\n\n    loss = torch.sum(torch.max(loss_inner, loss_outer), dim=-1)  # 1\n    return loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    y0_inner, y0_outer = inner_outer(t, t_env, w_env)\n    w_env_outer = matchup_channels(w, y0_inner, y0_outer)\n\n    loss = (w - w_env_outer).clamp_min(0).pow(2) / (w + eps)\n    return loss.mean()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    t0 = t_env\n    y1 = w_env\n    y0_inner, y0_outer = inner_outer(t, t0, y1)\n\n    w0 = w\n    w0_inner, w0_outer = inner_outer(t, t0, w0)\n\n    loss_inner = F.smooth_l1_loss(w0_inner, y0_inner, reduction='none')\n    loss_outer = F.smooth_l1_loss(w0_outer, y0_outer, reduction='none')\n\n    loss = loss_inner + loss_outer\n    return loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    y0_inner, y0_outer = inner_outer(t, t_env, w_env)\n\n    y0_inner = y0_inner.clamp_min(eps)\n    y0_outer = y0_outer.clamp_min(eps)\n\n    w = w[..., None]\n    y0_outer = y0_outer[..., None]\n    y0_inner = y0_inner[..., None]\n\n    loss = w * (y0_outer.sqrt() - y0_inner.sqrt())**2 / (y0_outer.sqrt() + y0_inner.sqrt() + eps)\n    return loss.mean()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # Calculate the inner and outer measures\n    w_env_inner, w_env_outer = inner_outer(t, t_env, w_env)\n\n    # Calculate the upper envelope weights\n    w_env_outer = torch.max(w_env_outer, eps)\n\n    # Calculate the scaled half-quadratic loss\n    loss = torch.sum(torch.pow(torch.max(w - w_env_outer, torch.zeros_like(w)), 2) / (w + eps))\n\n    return loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    t0 = t_env\n    y1 = w_env\n    y0_inner, y0_outer = inner_outer(t, t0, y1)\n\n    y0_inner = y0_inner.clamp(min=eps)\n    y0_outer = y0_outer.clamp(min=eps)\n\n    loss = 0.5 * ((w - y0_outer) ** 2 / y0_outer + (w - y0_inner) ** 2 / y0_inner)\n\n    return loss.sum()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    y0_inner, y0_outer = inner_outer(t, t_env, w_env)\n\n    y0_inner = torch.clamp(y0_inner, min=eps)\n    y0_outer = torch.clamp(y0_outer, min=eps)\n\n    y0_ratio = y0_inner / y0_outer\n    y0_ratio = torch.clamp(y0_ratio, max=1.0)\n\n    loss = w - y0_ratio * w_env\n    loss = torch.mean(loss**2)\n\n    return loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    y0_inner, y0_outer = inner_outer(t, t_env, w_env)\n    y0_outer = torch.max(y0_outer, eps)\n    y0_inner = torch.max(y0_inner, eps)\n\n    loss = w - y0_outer\n    loss = torch.where(loss > 0, loss, 0)\n    loss = loss ** 2 / (4 * y0_inner)\n\n    return loss.mean()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    y0_inner, y0_outer = inner_outer(t, t_env, w_env)\n    y0_inner = torch.max(y0_inner, eps)\n    y0_outer = torch.max(y0_outer, eps)\n    loss = w - y0_outer\n    loss = (loss ** 2) / (2 * y0_inner)\n    loss = torch.sum(loss, dim=-1)\n    return loss.mean()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    y0_inner, y0_outer = inner_outer(t, t_env, w_env)\n\n    loss_outer = torch.sum(torch.sqrt(w - y0_outer + eps) + torch.sqrt(y0_inner + eps))\n\n    return loss_outer"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    y0_inner, y0_outer = inner_outer(t, t_env, w_env)\n\n    y0_outer = torch.max(y0_outer, eps)\n    y0_inner = torch.max(y0_inner, eps)\n\n    loss = (w - y0_outer) ** 2 / (y0_outer ** 2) + (y0_inner ** 2) / (y0_outer ** 2)\n    loss = torch.sum(loss, dim=-1)\n\n    return loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    y0_inner, y0_outer = inner_outer(t, t_env, w_env)\n    y0_inner = torch.max(y0_inner, eps)\n    y0_outer = torch.max(y0_outer, eps)\n\n    loss = (w - y0_outer) ** 2 / (2 * y0_inner) + y0_inner.log() / 2\n    return loss.sum()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "\n    # Calculate inter-interval loss\n    t, w = matchup_channels(t, w)\n    t_diff = t[..., 1:] - t[..., :-1]\n    w_normalized = w / torch.clamp_min(t_diff, eps=torch.finfo(torch.float32).eps)\n    inter_interval_loss = (w_normalized - 1).pow(2)\n\n    # Calculate intra-interval loss\n    t_env, w_env = matchup_channels(t_env, w_env)\n    _, w_outer = inner_outer(t, t_env, w_env)\n    intra_interval_loss = (w - w_outer).clip(0.).pow(2) / (w + torch.finfo(torch.float32).eps)\n\n    # Combine inter-interval and intra-interval losses to produce total distortion loss\n    total_distortion_loss = inter_interval_loss.mean() + intra_interval_loss.mean()\n\n    return total_distortion_loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "\n    t, w = matchup_channels(t, w)\n    t_inner, t_outer = inner_outer(t, t, w)\n    w_inner, w_outer = inner_outer(t, w, w)\n\n    inner_loss = (w - w_inner).clip(0.).pow(2)\n    outer_loss = (w - w_outer).clip(0.).pow(2)\n\n    return (inner_loss + outer_loss).mean()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "\n    # Calculate inter-interval loss\n    t_env = t\n    w_env = w\n    pulse_width = 1.0\n    inter_interval_loss = lossfun_zip_outer(t, w, t_env, w_env, pulse_width)\n\n    # Calculate intra-interval loss\n    intra_interval_loss = lossfun_outer(t, w, t_env, w_env)\n\n    # Combine inter-interval and intra-interval losses to get total distortion loss\n    total_distortion_loss = inter_interval_loss + intra_interval_loss\n\n    return total_distortion_loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "\n    t, w = matchup_channels(t, w)\n    t_env, w_env = matchup_channels(t_env, w_env)\n\n    w_normalize = w / torch.clamp_min(t[..., 1:] - t[..., :-1], eps)\n\n    t_, w_ = blur_stepfun(t, w_normalize, pulse_width)\n    w_ = torch.clip(w_, min=0.)\n    assert (w_ >= 0.0).all()\n\n    # piecewise linear pdf to piecewise quadratic cdf\n    area = 0.5 * (w_[..., 1:] + w_[..., :-1]) * (t_[..., 1:] - t_[..., :-1])\n\n    cdf = torch.cat([torch.zeros_like(area[..., :1]), torch.cumsum(area, dim=-1)], dim=-1)\n\n    # query piecewise quadratic interpolation\n    cdf_interp = sorted_interp_quad(t_env, t_, w_, cdf)\n    # difference between adjacent interpolated values\n    w_s = torch.diff(cdf_interp, dim=-1)\n\n    return ((w_s - w_env).clip(0.).pow(2) / (w_env + eps)).mean()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "\n    # Calculate the outer loss using the provided tensors\n    outer_loss = lossfun_outer(t, w, t, w)\n\n    # Calculate the zip outer loss using the provided tensors and a pulse width\n    pulse_width = 0.5  # Example pulse width, replace with actual value\n    zip_outer_loss = lossfun_zip_outer(t, w, t, w, pulse_width)\n\n    # Combine the outer and zip outer losses to produce the total distortion loss\n    total_distortion_loss = outer_loss + zip_outer_loss\n\n    return total_distortion_loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "\n    # Calculate the outer loss using the provided tensors\n    outer_loss = lossfun_outer(t, w, t, w)\n\n    # Calculate the zip outer loss using the provided tensors and a pulse width\n    zip_outer_loss = lossfun_zip_outer(t, w, t, w, pulse_width=1.0)\n\n    # Combine the outer loss and zip outer loss to get the total distortion loss\n    total_distortion_loss = outer_loss + zip_outer_loss\n\n    return total_distortion_loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "\n    t, w = matchup_channels(t, w)\n    t_env, w_env = matchup_channels(t_env, w_env)\n\n    w_normalize = w / torch.clamp_min(t[..., 1:] - t[..., :-1], eps)\n\n    t_, w_ = blur_stepfun(t, w_normalize, pulse_width)\n    w_ = torch.clip(w_, min=0.)\n    assert (w_ >= 0.0).all()\n\n    # piecewise linear pdf to piecewise quadratic cdf\n    area = 0.5 * (w_[..., 1:] + w_[..., :-1]) * (t_[..., 1:] - t_[..., :-1])\n\n    cdf = torch.cat([torch.zeros_like(area[..., :1]), torch.cumsum(area, dim=-1)], dim=-1)\n\n    # query piecewise quadratic interpolation\n    cdf_interp = sorted_interp_quad(t_env, t_, w_, cdf)\n    # difference between adjacent interpolated values\n    w_s = torch.diff(cdf_interp, dim=-1)\n\n    return ((w_s - w_env).clip(0.).pow(2) / (w_env + eps)).mean()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "\n    # Calculate inter-interval loss\n    t_env = t\n    w_env = w\n    pulse_width = 1.0\n    inter_interval_loss = lossfun_zip_outer(t, w, t_env, w_env, pulse_width)\n\n    # Calculate intra-interval loss\n    intra_interval_loss = lossfun_outer(t, w, t_env, w_env)\n\n    # Combine inter-interval and intra-interval losses to produce total distortion loss\n    total_distortion_loss = inter_interval_loss + intra_interval_loss\n\n    return total_distortion_loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "\n    t, w = matchup_channels(t, w)\n    t_env, w_env = matchup_channels(t_env, w_env)\n\n    w_normalize = w / torch.clamp_min(t[..., 1:] - t[..., :-1], eps)\n\n    t_, w_ = blur_stepfun(t, w_normalize, pulse_width)\n    w_ = torch.clip(w_, min=0.)\n    assert (w_ >= 0.0).all()\n\n    # piecewise linear pdf to piecewise quadratic cdf\n    area = 0.5 * (w_[..., 1:] + w_[..., :-1]) * (t_[..., 1:] - t_[..., :-1])\n\n    cdf = torch.cat([torch.zeros_like(area[..., :1]), torch.cumsum(area, dim=-1)], dim=-1)\n\n    # query piecewise quadratic interpolation\n    cdf_interp = sorted_interp_quad(t_env, t_, w_, cdf)\n    # difference between adjacent interpolated values\n    w_s = torch.diff(cdf_interp, dim=-1)\n\n    return ((w_s - w_env).clip(0.).pow(2) / (w_env + eps)).mean()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "\n    # Compute the outer loss using the provided tensors\n    outer_loss = lossfun_outer(t, w, t, w)\n\n    # Compute the zip outer loss using the provided tensors and a pulse width\n    zip_outer_loss = lossfun_zip_outer(t, w, t, w, pulse_width=0.5)\n\n    # Combine the outer and zip outer losses to produce the total distortion loss\n    total_distortion_loss = outer_loss + zip_outer_loss\n\n    return total_distortion_loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "\n    t, w = matchup_channels(t, w)\n    t_env, w_env = matchup_channels(t_env, w_env)\n\n    w_normalize = w / torch.clamp_min(t[..., 1:] - t[..., :-1], eps)\n\n    t_, w_ = blur_stepfun(t, w_normalize, pulse_width)\n    w_ = torch.clip(w_, min=0.)\n    assert (w_ >= 0.0).all()\n\n    # piecewise linear pdf to piecewise quadratic cdf\n    area = 0.5 * (w_[..., 1:] + w_[..., :-1]) * (t_[..., 1:] - t_[..., :-1])\n\n    cdf = torch.cat([torch.zeros_like(area[..., :1]), torch.cumsum(area, dim=-1)], dim=-1)\n\n    # query piecewise quadratic interpolation\n    cdf_interp = sorted_interp_quad(t_env, t_, w_, cdf)\n    # difference between adjacent interpolated values\n    w_s = torch.diff(cdf_interp, dim=-1)\n\n    return ((w_s - w_env).clip(0.).pow(2) / (w_env + eps)).mean()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "\n    t, w = matchup_channels(t, w)\n    t_env, w_env = matchup_channels(t_env, w_env)\n\n    w_normalize = w / torch.clamp_min(t[..., 1:] - t[..., :-1], eps)\n\n    t_, w_ = blur_stepfun(t, w_normalize, pulse_width)\n    w_ = torch.clip(w_, min=0.)\n    assert (w_ >= 0.0).all()\n\n    # piecewise linear pdf to piecewise quadratic cdf\n    area = 0.5 * (w_[..., 1:] + w_[..., :-1]) * (t_[..., 1:] - t_[..., :-1])\n\n    cdf = torch.cat([torch.zeros_like(area[..., :1]), torch.cumsum(area, dim=-1)], dim=-1)\n\n    # query piecewise quadratic interpolation\n    cdf_interp = sorted_interp_quad(t_env, t_, w_, cdf)\n    # difference between adjacent interpolated values\n    w_s = torch.diff(cdf_interp, dim=-1)\n\n    return ((w_s - w_env).clip(0.).pow(2) / (w_env + eps)).mean()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "\n    t, w = matchup_channels(t, w)\n    t_env, w_env = matchup_channels(t_env, w_env)\n\n    w_normalize = w / torch.clamp_min(t[..., 1:] - t[..., :-1], eps)\n\n    t_, w_ = blur_stepfun(t, w_normalize, pulse_width)\n    w_ = torch.clip(w_, min=0.)\n    assert (w_ >= 0.0).all()\n\n    # piecewise linear pdf to piecewise quadratic cdf\n    area = 0.5 * (w_[..., 1:] + w_[..., :-1]) * (t_[..., 1:] - t_[..., :-1])\n\n    cdf = torch.cat([torch.zeros_like(area[..., :1]), torch.cumsum(area, dim=-1)], dim=-1)\n\n    # query piecewise quadratic interpolation\n    cdf_interp = sorted_interp_quad(t_env, t_, w_, cdf)\n    # difference between adjacent interpolated values\n    w_s = torch.diff(cdf_interp, dim=-1)\n\n    return ((w_s - w_env).clip(0.).pow(2) / (w_env + eps)).mean()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "\n    # Calculate inter-interval loss\n    t_env = t\n    w_env = w\n    pulse_width = 0.1  # Example pulse width, can be adjusted\n    inter_interval_loss = lossfun_zip_outer(t, w, t_env, w_env, pulse_width)\n\n    # Calculate intra-interval loss\n    intra_interval_loss = lossfun_outer(t, w, t_env, w_env)\n\n    # Combine inter-interval and intra-interval losses to produce total distortion loss\n    total_distortion_loss = inter_interval_loss + intra_interval_loss\n\n    return total_distortion_loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "\n    # Compute inter-interval loss\n    t_env = t\n    w_env = w\n    pulse_width = 0.1  # Example value, can be adjusted\n    inter_interval_loss = lossfun_zip_outer(t, w, t_env, w_env, pulse_width)\n\n    # Compute intra-interval loss\n    intra_interval_loss = lossfun_outer(t, w, t_env, w_env)\n\n    # Combine inter-interval and intra-interval losses to get total distortion loss\n    total_distortion_loss = inter_interval_loss + intra_interval_loss\n\n    return total_distortion_loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "\n    # Calculate the outer loss using the provided tensors\n    outer_loss = lossfun_outer(t, w, t, w)\n\n    # Calculate the zip outer loss using the provided tensors\n    zip_outer_loss = lossfun_zip_outer(t, w, t, w, pulse_width=1e-6)\n\n    # Combine the outer and zip outer losses to produce the total distortion loss\n    total_distortion_loss = outer_loss + zip_outer_loss\n\n    return total_distortion_loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "\n    # Calculate the outer loss using the provided tensors\n    outer_loss = lossfun_outer(t, w, t, w)\n\n    # Calculate the zip outer loss using the provided tensors and a pulse width\n    zip_outer_loss = lossfun_zip_outer(t, w, t, w, pulse_width=1.0)\n\n    # Combine the outer loss and zip outer loss to produce the total distortion loss\n    total_distortion_loss = outer_loss + zip_outer_loss\n\n    return total_distortion_loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "\n    # Compute the inter-interval loss\n    t_env = t\n    w_env = w\n    pulse_width = 0.1\n    inter_interval_loss = lossfun_zip_outer(t, w, t_env, w_env, pulse_width)\n\n    # Compute the intra-interval loss\n    intra_interval_loss = lossfun_outer(t, w, t_env, w_env)\n\n    # Combine the inter-interval and intra-interval losses to produce the total distortion loss\n    total_distortion_loss = inter_interval_loss + intra_interval_loss\n\n    return total_distortion_loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "\n    # Calculate inter-interval loss\n    t_env = t\n    w_env = w\n    pulse_width = 0.1\n    inter_interval_loss = lossfun_zip_outer(t, w, t_env, w_env, pulse_width)\n\n    # Calculate intra-interval loss\n    intra_interval_loss = lossfun_outer(t, w, t, w)\n\n    # Combine inter-interval and intra-interval losses to produce total distortion loss\n    total_distortion_loss = inter_interval_loss + intra_interval_loss\n\n    return total_distortion_loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "\n    # Calculate the outer loss using the provided tensors\n    outer_loss = lossfun_outer(t, w, t, w)\n\n    # Calculate the zip outer loss using the provided tensors and a pulse width\n    zip_outer_loss = lossfun_zip_outer(t, w, t, w, pulse_width=0.1)\n\n    # Combine the outer loss and zip outer loss to produce the total distortion loss\n    total_distortion_loss = outer_loss + zip_outer_loss\n\n    return total_distortion_loss"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    pvals = torch.tensor(ps, dtype=w.dtype, device=w.device)\n    return interpolate(pvals, cw[..., :-1], t)"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "\n    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(ps, cw[..., :-1], t)"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "\n    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    percentiles = interpolate(torch.tensor(ps), cw[..., :-1], t)\n    return percentiles"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "\n    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    wp = interpolate(torch.tensor(ps), cw[..., :-1], t)\n    \n    return wp"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "\n    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    percentiles = interpolate(torch.tensor(ps), cw[..., :-1], t)\n    return percentiles"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "\n    # Match up the channels of the tensors\n    t, w = matchup_channels(t, w)\n\n    # Integrate the weights\n    cw = integrate_weights(w)\n\n    # Interpolate the integrated weights to find the weighted percentiles\n    percentiles = []\n    for p in ps:\n        percentile = interpolate(p, cw[..., :-1], t)\n        percentiles.append(percentile)\n\n    return torch.stack(percentiles, dim=-1)"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "\n    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    percentiles = interpolate(torch.tensor(ps), cw[..., :-1], t)\n    return percentiles"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "\n    t, w = matchup_channels(t, w)  # Match up the channels of the tensors\n\n    cw = integrate_weights(w)  # Integrate the weights\n\n    # Interpolate the integrated weights to find the weighted percentiles based on the provided percentile values\n    percentiles = []\n    for p in ps:\n        percentile = interpolate(p, cw[..., :-1], t)\n        percentiles.append(percentile)\n    \n    return torch.stack(percentiles, dim=-1)"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "\n    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    percentiles = interpolate(torch.tensor(ps), cw[..., :-1], t)\n    return percentiles"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "\n    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    percentiles = interpolate(torch.tensor(ps), cw[..., :-1], t)\n    return percentiles"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "\n    t, w = matchup_channels(t, w)  # Match up the channels of the tensors\n\n    cw = integrate_weights(w)  # Integrate the weights\n\n    # Interpolate the integrated weights to find the weighted percentiles\n    percentiles = []\n    for p in ps:\n        percentile = interpolate(p, cw[..., :-1], t)\n        percentiles.append(percentile)\n\n    return torch.stack(percentiles, dim=-1)"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "\n    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    percentiles = interpolate(torch.tensor(ps), cw[..., :-1], t)\n    return percentiles"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "\n    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    percentiles = interpolate(torch.tensor(ps), cw[..., :-1], t)\n    return percentiles"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "\n    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n\n    # Compute the percentile values\n    percentiles = torch.tensor(ps, dtype=t.dtype, device=t.device)\n    x = interpolate(percentiles, cw[..., :-1], t)\n\n    return x"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "\n    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(ps, cw[..., :-1], t)"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "\n    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    percentiles = []\n    for p in ps:\n        interp_percentile = interpolate(torch.tensor(p), cw[..., :-1], t)\n        percentiles.append(interp_percentile)\n    return torch.stack(percentiles, dim=-1)"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "\n    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    percentiles = interpolate(torch.tensor(ps), cw[..., :-1], t)\n    return percentiles"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "\n    t, w = matchup_channels(t, w)  # match up the channels of the tensors\n    cw = integrate_weights(w)  # integrate the weights\n    percentiles = interpolate(ps, cw[..., :-1], t)  # interpolate the integrated weights to find the weighted percentiles\n    return percentiles"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "\n    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    percentiles = interpolate(torch.tensor(ps, dtype=t.dtype, device=t.device), cw[..., :-1], t)\n    return percentiles"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "\n    t, w = matchup_channels(t, w)  # Match up the channels of the tensors\n\n    cw0 = integrate_weights(w)  # Integrate the weights\n\n    # Interpolate the integrated weights to find the weighted percentiles\n    percentiles = []\n    for p in ps:\n        interp_percentile = interpolate(p, cw0[0, ...], t)\n        percentiles.append(interp_percentile)\n\n    return torch.stack(percentiles)"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "\n    idx_lo = torch.searchsorted(a, v, right=False)\n    idx_hi = torch.searchsorted(a, v, right=True)\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    idx_lo = torch.searchsorted(a, v, right=False)\n    idx_hi = torch.searchsorted(a, v, right=True)\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    idx_lo = torch.searchsorted(a, v, right=False)\n    idx_hi = torch.searchsorted(a, v, right=True)\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    idx_lo = torch.zeros_like(v, dtype=torch.long)\n    idx_hi = torch.zeros_like(v, dtype=torch.long)\n\n    for i in range(v.shape[-1]):\n        lo = 0\n        hi = a.shape[-1]\n        while lo < hi:\n            mid = (lo + hi) // 2\n            if a[mid] < v[..., i]:\n                lo = mid + 1\n            else:\n                hi = mid\n        idx_lo[..., i] = lo\n\n        lo = 0\n        hi = a.shape[-1]\n        while lo < hi:\n            mid = (lo + hi) // 2\n            if a[mid] <= v[..., i]:\n                lo = mid + 1\n            else:\n                hi = mid\n        idx_hi[..., i] = lo\n\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    idx_lo = torch.searchsorted(a, v, right=False)\n    idx_hi = torch.searchsorted(a, v, right=True)\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    idx_lo = torch.searchsorted(a, v, right=False)\n    idx_hi = torch.searchsorted(a, v, right=True)\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    idx_lo = torch.searchsorted(a, v, right=False)\n    idx_hi = torch.searchsorted(a, v, right=True)\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    idx_lo = torch.zeros_like(v, dtype=torch.int64)\n    idx_hi = torch.zeros_like(v, dtype=torch.int64)\n\n    for i in range(v.shape[-1]):\n        idx_lo[..., i] = torch.searchsorted(a, v[..., i], right=False)\n        idx_hi[..., i] = torch.searchsorted(a, v[..., i], right=True)\n\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "\n    idx_lo = torch.searchsorted(a, v, right=False)\n    idx_hi = torch.searchsorted(a, v, right=True)\n\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    idx_lo = torch.searchsorted(a, v, right=False)\n    idx_hi = torch.searchsorted(a, v, right=True)\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    idx_lo = torch.searchsorted(a, v, right=False)\n    idx_hi = torch.searchsorted(a, v, right=True)\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "\n    idx_lo = torch.searchsorted(a, v, right=False)\n    idx_hi = torch.searchsorted(a, v, right=True)\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    idx_lo = torch.searchsorted(a, v, right=False)\n    idx_hi = torch.searchsorted(a, v, right=True)\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    idx_lo = torch.searchsorted(a, v, right=False)\n    idx_hi = torch.searchsorted(a, v, right=True)\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "\n    idx_lo = torch.searchsorted(a, v, right=False)\n    idx_hi = torch.searchsorted(a, v, right=True)\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "\n    idx_lo = torch.searchsorted(a, v, right=False)\n    idx_hi = torch.searchsorted(a, v, right=True)\n\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    idx_lo = torch.searchsorted(a, v, right=False)\n    idx_hi = torch.searchsorted(a, v, right=True)\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    idx_lo = torch.zeros_like(v, dtype=torch.long)\n    idx_hi = torch.zeros_like(v, dtype=torch.long)\n\n    for i in range(v.shape[-1]):\n        lo = torch.searchsorted(a, v[..., i], right=False)\n        hi = torch.searchsorted(a, v[..., i], right=True)\n        idx_lo[..., i] = lo\n        idx_hi[..., i] = hi\n\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    idx_lo = torch.searchsorted(a, v, right=False)\n    idx_hi = torch.searchsorted(a, v, right=True)\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    idx_lo = torch.searchsorted(a, v, right=False)\n    idx_hi = torch.searchsorted(a, v, right=True)\n    return idx_lo, idx_hi"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Compute the cumulative sum of the weights\n    cw = integrate_weights(w)\n\n    # Generate uniform random numbers for sampling\n    u = torch.rand(num_samples, device=t.device)\n\n    # Invert the CDF to generate samples\n    samples = invert_cdf(u, t, cw)\n\n    # Apply perturbation if specified\n    if perturb:\n        if single_jitter:\n            # Apply the same jitter to every sample along each dimension\n            jitter = torch.rand(samples.shape, device=t.device) * (t[1] - t[0])\n        else:\n            # Apply independent jitter to each sample\n            jitter = torch.rand_like(samples) * (t[1] - t[0])\n        samples += jitter\n\n    return samples"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "\n    # Compute the cumulative sum of the weights\n    cw = integrate_weights(w)\n\n    # Generate random uniform samples\n    u = torch.rand(num_samples, device=t.device)\n\n    # Invert the CDF to obtain samples\n    samples = invert_cdf(u, t, cw)\n\n    # Apply perturbation if specified\n    if perturb:\n        if single_jitter:\n            jitter = torch.rand(1, device=t.device)\n            samples = samples + jitter\n        else:\n            jitter = torch.rand(num_samples, device=t.device)\n            samples = samples + jitter\n\n    return samples"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "\n    # Compute the cumulative sum of the weights\n    cw = integrate_weights(w)\n\n    # Generate uniform samples\n    u = torch.rand(num_samples, device=t.device)\n\n    # Invert the CDF to obtain samples\n    s = invert_cdf(u, t, cw)\n\n    # Apply perturbation if specified\n    if perturb:\n        if single_jitter:\n            jitter = torch.rand(1, device=t.device)\n            s = s + jitter * (t[1] - t[0])\n        else:\n            jitter = torch.rand(num_samples, device=t.device)\n            s = s + jitter * (t[1] - t[0])\n\n    return s"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "\n    # Compute the cumulative sum of weights to get the integrated weights\n    cw = integrate_weights(w)\n\n    # Generate random samples using uniform distribution\n    u = torch.rand(num_samples, device=t.device)\n\n    # Invert the CDF to get the samples from the specified PDF\n    samples = invert_cdf(u, t, cw)\n\n    # Apply perturbation to the samples to avoid clustering at bin boundaries\n    if perturb:\n        if single_jitter:\n            jitter = (t[1:] - t[:-1]) * torch.rand(1, device=t.device)\n        else:\n            jitter = (t[1:] - t[:-1]) * torch.rand(num_samples, device=t.device)\n\n        samples += jitter\n\n    return samples"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Compute the cumulative sum of the weights\n    cw = integrate_weights(w)\n\n    # Generate uniform random samples\n    u = torch.rand(num_samples, device=t.device)\n\n    # Invert the CDF to obtain samples\n    samples = invert_cdf(u, t, cw)\n\n    # Apply perturbation if specified\n    if perturb:\n        if single_jitter:\n            jitter = torch.rand(1, device=t.device) * (t[1] - t[0])\n            samples += jitter\n        else:\n            jitter = torch.rand(num_samples, device=t.device) * (t[1] - t[0])\n            samples += jitter\n\n    return samples"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "\n    # Compute the cumulative sum of the weights\n    cw = integrate_weights(w)\n\n    # Generate random samples from a uniform distribution\n    u = torch.rand(num_samples, device=t.device)\n\n    # Invert the CDF to obtain the samples\n    samples = invert_cdf(u, t, cw)\n\n    # Apply perturbation to the samples to avoid clustering at bin boundaries\n    if perturb:\n        if single_jitter:\n            jitter = torch.rand(1, device=t.device) * (t[1] - t[0])\n        else:\n            jitter = torch.rand(num_samples, device=t.device) * (t[1] - t[0])\n        samples += jitter\n\n    return samples"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Compute the cumulative sum of the weights\n    cw = integrate_weights(w)\n\n    # Generate uniform random numbers for sampling\n    u = torch.rand(num_samples, device=t.device)\n\n    # Invert the CDF to obtain samples\n    samples = invert_cdf(u, t, cw)\n\n    # Apply perturbation if specified\n    if perturb:\n        if single_jitter:\n            jitter = torch.rand(1, device=t.device) * (t[1] - t[0])\n            samples += jitter\n        else:\n            jitter = torch.rand(num_samples, device=t.device) * (t[1] - t[0])\n            samples += jitter\n\n    return samples"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Compute the cumulative sum of the weights\n    cw = integrate_weights(w)\n\n    # Generate uniform random samples\n    u = torch.rand(num_samples, device=t.device)\n\n    # Invert the CDF to obtain samples\n    samples = invert_cdf(u, t, cw)\n\n    # Apply perturbation if specified\n    if perturb:\n        if single_jitter:\n            jitter = torch.rand(1, device=t.device) * (t[1] - t[0])\n            samples += jitter\n        else:\n            jitter = torch.rand(num_samples, device=t.device) * (t[1] - t[0])\n            samples += jitter\n\n    return samples"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "\n    # Compute the CDF for the weights\n    cw = integrate_weights(w)\n\n    # Generate random samples from a uniform distribution\n    u = torch.rand(num_samples, device=t.device)\n\n    # Invert the CDF to obtain samples from the specified PDF\n    samples = invert_cdf(u, t, cw)\n\n    # Apply perturbation to avoid sample clustering at bin boundaries\n    if perturb:\n        if single_jitter:\n            jitter = torch.rand(1, device=t.device) * (t[1] - t[0])\n            samples += jitter\n        else:\n            jitter = torch.rand(num_samples, device=t.device) * (t[1] - t[0])\n            samples += jitter\n\n    return samples"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "\n    # Compute the cumulative sum of the weights to get the integrated weights\n    cw = integrate_weights(w)\n\n    # Generate uniform random numbers for sampling\n    u = torch.rand(num_samples, device=t.device)\n\n    # Invert the CDF to get the samples\n    samples = invert_cdf(u, t, cw)\n\n    # Apply perturbation if specified\n    if perturb:\n        if single_jitter:\n            jitter = torch.rand(1, device=t.device)\n            samples = samples + jitter\n        else:\n            jitter = torch.rand(num_samples, device=t.device)\n            samples = samples + jitter\n\n    return samples"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Compute the cumulative sum of the weights\n    cw = integrate_weights(w)\n    \n    # Generate uniform random numbers for sampling\n    u = torch.rand(num_samples, device=t.device)\n    \n    # Invert the CDF to generate samples\n    samples = invert_cdf(u, t, cw)\n    \n    # Apply perturbation if specified\n    if perturb:\n        if single_jitter:\n            jitter = (torch.rand(1, device=t.device) - 0.5) * (t[1] - t[0])\n            samples += jitter\n        else:\n            jitter = (torch.rand(num_samples, device=t.device) - 0.5) * (t[1] - t[0])\n            samples += jitter\n    \n    return samples"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Invert the CDF to generate samples\n    u = torch.rand(num_samples, device=t.device, dtype=t.dtype)\n    s = invert_cdf(u, t, w)\n\n    # Apply perturbation to avoid sample clustering at bin boundaries\n    if perturb:\n        if single_jitter:\n            jitter = torch.rand(1, device=t.device, dtype=t.dtype) * (t[1] - t[0])\n            s += jitter\n        else:\n            jitter = torch.rand(num_samples, device=t.device, dtype=t.dtype) * (t[1] - t[0])\n            s += jitter\n\n    return s"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "\n    # Compute the cumulative sum of the weights to obtain the integrated weights\n    cw = integrate_weights(w)\n\n    # Generate uniform random numbers for sampling\n    u = torch.rand(num_samples, device=t.device)\n\n    # Invert the CDF to obtain the samples\n    samples = invert_cdf(u, t, cw)\n\n    # Apply perturbation and jitter if specified\n    if perturb:\n        if single_jitter:\n            # Apply perturbation with the same jitter for all samples along each dimension\n            samples += torch.rand_like(samples) * (t[1] - t[0])\n        else:\n            # Apply independent perturbation and jitter for each sample along each dimension\n            samples += torch.rand_like(samples) * (t[1:] - t[:-1])\n\n    return samples"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "\n    # Compute the cumulative sum of the weights\n    cw = integrate_weights(w)\n\n    # Generate uniform random numbers for sampling\n    u = torch.rand(num_samples, device=t.device)\n\n    # Invert the CDF to obtain the samples\n    samples = invert_cdf(u, t, cw)\n\n    # Apply perturbation if specified\n    if perturb:\n        if single_jitter:\n            jitter = torch.rand(1, device=t.device)\n            samples += jitter * (t[1:] - t[:-1])\n        else:\n            jitter = torch.rand(num_samples, device=t.device)\n            samples += jitter.unsqueeze(1) * (t[1:] - t[:-1])\n\n    return samples"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Invert the CDF to generate samples\n    u = torch.rand(num_samples, device=t.device)\n    if perturb:\n        u += torch.rand(num_samples, device=t.device) / t.shape[-1]\n    t_new = invert_cdf(u, t, w)\n\n    # Apply jittering to the samples\n    if single_jitter:\n        jitter = (torch.rand(t_new.shape, device=t.device) - 0.5) / t.shape[-1]\n    else:\n        jitter = (torch.rand_like(t_new, device=t.device) - 0.5) / t.shape[-1\n    t_new += jitter\n\n    return t_new"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    u = torch.rand(num_samples, device=t.device, dtype=t.dtype)\n    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    t_new = invert_cdf(u, t, cw)\n    \n    if perturb:\n        if single_jitter:\n            jitter = torch.rand(1, device=t.device, dtype=t.dtype)\n            t_new = t_new + jitter * (t[1] - t[0])\n        else:\n            jitter = torch.rand(num_samples, device=t.device, dtype=t.dtype)\n            t_new = t_new + jitter * (t[1] - t[0])\n\n    return t_new"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "\n    # Compute the cumulative sum of the weights\n    cw = integrate_weights(w)\n\n    # Generate random numbers for sampling\n    u = torch.rand(num_samples, device=t.device)\n\n    # Invert the CDF to get the samples\n    samples = invert_cdf(u, t, cw)\n\n    # Apply perturbation if specified\n    if perturb:\n        if single_jitter:\n            jitter = torch.rand(1, device=t.device) * (t[1] - t[0])\n            samples += jitter\n        else:\n            jitter = torch.rand(num_samples, device=t.device) * (t[1] - t[0])\n            samples += jitter\n\n    return samples"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    u = torch.rand(num_samples, device=t.device)\n    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    t_new = invert_cdf(u, t, cw)\n\n    if perturb:\n        if single_jitter:\n            jitter = torch.rand(1, device=t.device)\n            t_new = t_new + jitter * (t[..., 1:] - t[..., :-1])\n        else:\n            jitter = torch.rand(num_samples, device=t.device)\n            t_new = t_new + jitter * (t_new[..., 1:] - t_new[..., :-1])\n\n    return t_new"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "\n    # Compute the cumulative sum of the weights to get the integral of the PDF\n    cw = integrate_weights(w)\n\n    # Generate random uniform samples\n    u = torch.rand(num_samples, device=t.device)\n\n    # Invert the CDF to get the samples\n    samples = invert_cdf(u, t, cw)\n\n    # Apply perturbation to avoid sample clustering at bin boundaries\n    if perturb:\n        if single_jitter:\n            jitter = torch.rand(1, device=t.device) * (t[1] - t[0])\n            samples += jitter\n        else:\n            jitter = torch.rand(num_samples, device=t.device) * (t[1] - t[0])\n            samples += jitter\n\n    return samples"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "\n    # Compute the cumulative sum of the weights\n    cw = integrate_weights(w)\n\n    # Generate uniform random numbers for sampling\n    u = torch.rand(num_samples, device=t.device)\n\n    # Invert the CDF to obtain the samples\n    samples = invert_cdf(u, t, cw)\n\n    # Apply perturbation if specified\n    if perturb:\n        if single_jitter:\n            jitter = torch.rand(1, device=t.device) * (t[1] - t[0])\n            samples += jitter\n        else:\n            jitter = torch.rand(num_samples, device=t.device) * (t[1] - t[0])\n            samples += jitter\n\n    return samples"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        width = self.tensor[:, 2]\n        height = self.tensor[:, 3]\n        area = width * height\n        return area"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "\n        width = self.tensor[:, 2]\n        height = self.tensor[:, 3]\n        area = width * height\n        return area"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        width = self.tensor[:, 2]\n        height = self.tensor[:, 3]\n        area = width * height\n        return area"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        width = self.tensor[:, 2]\n        height = self.tensor[:, 3]\n        area = width * height\n        return area"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        width = self.tensor[:, 2]\n        height = self.tensor[:, 3]\n        area = width * height\n        return area"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        # Calculate the width and height of each box\n        width = self.tensor[:, 2]\n        height = self.tensor[:, 3]\n        \n        # Compute the area of each box by multiplying width and height\n        area = width * height\n        \n        return area"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        width = self.tensor[:, 2]  # Extracting the width from the tensor\n        height = self.tensor[:, 3]  # Extracting the height from the tensor\n        area = width * height  # Calculating the area by multiplying width and height\n        return area"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        width = self.tensor[:, 2]\n        height = self.tensor[:, 3]\n        area = width * height\n        return area"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        width = self.tensor[:, 2]\n        height = self.tensor[:, 3]\n        area = width * height\n        return area"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        width = self.tensor[:, 2]\n        height = self.tensor[:, 3]\n        area = width * height\n        return area"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        width = self.tensor[:, 2]  # Extracting the width from the tensor\n        height = self.tensor[:, 3]  # Extracting the height from the tensor\n        area = width * height  # Calculating the area by multiplying width and height\n        return area"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        width = self.tensor[:, 2]\n        height = self.tensor[:, 3]\n        area = width * height\n        return area"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        width = self.tensor[:, 2]  # Extracting the width from the tensor\n        height = self.tensor[:, 3]  # Extracting the height from the tensor\n        area = width * height  # Calculating the area by multiplying width and height\n        return area"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        width = self.tensor[:, 2]  # Extracting the width from the tensor\n        height = self.tensor[:, 3]  # Extracting the height from the tensor\n        area = width * height  # Calculating the area by multiplying width and height\n        return area"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        width = self.tensor[:, 2]\n        height = self.tensor[:, 3]\n        area = width * height\n        return area"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        width = self.tensor[:, 2]\n        height = self.tensor[:, 3]\n        area = width * height\n        return area"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        width = self.tensor[:, 2]  # Extracting the width from the tensor\n        height = self.tensor[:, 3]  # Extracting the height from the tensor\n        area = width * height  # Calculating the area by multiplying width and height\n        return area"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        width = self.tensor[:, 2]\n        height = self.tensor[:, 3]\n        area = width * height\n        return area"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        width = self.tensor[:, 2]\n        height = self.tensor[:, 3]\n        area = width * height\n        return area"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "\n        # Calculate the area of each box\n        width = self.tensor[:, 2]\n        height = self.tensor[:, 3]\n        area = width * height\n        return area"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    else:\n        return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    else:\n        return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    else:\n        return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    else:\n        return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    else:\n        return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    else:\n        return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    else:\n        return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    else:\n        return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    else:\n        return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    else:\n        return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    else:\n        proposal_generator = PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)\n        return proposal_generator"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        losses = {}\n\n        # Classification Loss\n        pred_class_logits = scores\n        gt_classes = cat([p.gt_classes for p in proposals], dim=0)\n        loss_cls = F.cross_entropy(pred_class_logits, gt_classes, reduction=\"mean\")\n        losses[\"loss_cls\"] = loss_cls * self.loss_weight[\"loss_cls\"]\n\n        # Box Regression Loss\n        pred_proposal_deltas = proposal_deltas\n        gt_proposal_deltas = cat([p.gt_boxes.tensor for p in proposals], dim=0)\n        loss_box_reg = _dense_box_regression_loss(\n            pred_proposal_deltas,\n            gt_proposal_deltas,\n            self.box2box_transform,\n            smooth_l1_beta=self.smooth_l1_beta,\n            box_reg_loss_type=self.box_reg_loss_type,\n            reduction=\"mean\",\n        )\n        losses[\"loss_box_reg\"] = loss_box_reg * self.loss_weight[\"loss_box_reg\"]\n\n        return losses"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        gt_boxes = [x.gt_boxes for x in proposals]\n        gt_classes = [x.gt_classes for x in proposals]\n\n        pred_class_logits, pred_proposal_deltas = scores, proposal_deltas\n\n        gt_classes, gt_proposal_deltas = self.prepare_targets(gt_classes, gt_boxes)\n\n        loss_cls = F.cross_entropy(pred_class_logits, gt_classes, reduction=\"mean\")\n        loss_box_reg = _dense_box_regression_loss(\n            pred_proposal_deltas,\n            gt_proposal_deltas,\n            self.box2box_transform,\n            smooth_l1_beta=self.smooth_l1_beta,\n            box_reg_loss_type=self.box_reg_loss_type,\n            reduction=\"mean\",\n        )\n\n        losses = {\n            \"loss_cls\": loss_cls * self.loss_weight[\"loss_cls\"],\n            \"loss_box_reg\": loss_box_reg * self.loss_weight[\"loss_box_reg\"],\n        }\n\n        _log_classification_stats(pred_class_logits, gt_classes)\n\n        return losses"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "\n        scores, proposal_deltas = predictions\n        gt_boxes = [x.gt_boxes for x in proposals]\n        gt_classes = [x.gt_classes for x in proposals]\n\n        pred_class_logits, pred_proposal_deltas = scores, proposal_deltas\n\n        gt_classes, gt_proposal_deltas = self.label_and_sample_anchors(gt_classes, gt_boxes, pred_class_logits)\n\n        # Classification loss\n        loss_cls = F.cross_entropy(pred_class_logits, gt_classes, reduction=\"mean\")\n\n        # Box regression loss\n        loss_box_reg = _dense_box_regression_loss(\n            pred_proposal_deltas,\n            gt_proposal_deltas,\n            gt_classes,\n            self.box2box_transform,\n            smooth_l1_beta=self.smooth_l1_beta,\n            box_reg_loss_type=self.box_reg_loss_type,\n            num_instances=len(gt_classes),\n        )\n\n        return {\n            \"loss_cls\": loss_cls * self.loss_weight[\"loss_cls\"],\n            \"loss_box_reg\": loss_box_reg * self.loss_weight[\"loss_box_reg\"],\n        }"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "\n        scores, proposal_deltas = predictions\n        gt_boxes = [x.gt_boxes for x in proposals]\n        gt_classes = [x.gt_classes for x in proposals]\n\n        pred_class_logits, pred_proposal_deltas = scores, proposal_deltas\n        gt_classes, gt_proposal_deltas = cat(gt_classes, dim=0), cat(gt_boxes, dim=0)\n\n        classification_loss = F.cross_entropy(pred_class_logits, gt_classes, reduction=\"mean\")\n\n        box_reg_loss = _dense_box_regression_loss(\n            pred_proposal_deltas,\n            gt_proposal_deltas,\n            gt_classes,\n            self.box2box_transform,\n            smooth_l1_beta=self.smooth_l1_beta,\n            box_reg_loss_type=self.box_reg_loss_type,\n            reduction=\"mean\",\n        )\n\n        losses = {\n            \"loss_cls\": classification_loss * self.loss_weight[\"loss_cls\"],\n            \"loss_box_reg\": box_reg_loss * self.loss_weight[\"loss_box_reg\"],\n        }\n\n        return losses"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        losses = {}\n\n        # Classification Loss\n        pred_class_logits = scores\n        gt_classes = cat([p.gt_classes for p in proposals], dim=0)\n        loss_cls = F.cross_entropy(pred_class_logits, gt_classes, reduction=\"mean\")\n        losses[\"loss_cls\"] = loss_cls * self.loss_weight[\"loss_cls\"]\n\n        # Box Regression Loss\n        pred_proposal_deltas = proposal_deltas\n        gt_proposal_deltas = cat([p.gt_boxes.tensor for p in proposals], dim=0)\n        box_reg_targets = self.box2box_transform.get_deltas(gt_proposal_deltas, gt_classes, pred_proposal_deltas)\n        if self.box_reg_loss_type == \"smooth_l1\":\n            loss_box_reg = _dense_box_regression_loss(pred_proposal_deltas, box_reg_targets, gt_classes, self.smooth_l1_beta)\n        else:\n            raise NotImplementedError(f\"Box regression loss type '{self.box_reg_loss_type}' not supported\")\n        losses[\"loss_box_reg\"] = loss_box_reg * self.loss_weight[\"loss_box_reg\"]\n\n        return losses"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "\n        scores, proposal_deltas = predictions\n        proposal_boxes = [x.proposal_boxes for x in proposals]\n        gt_boxes = [x.gt_boxes for x in proposals]\n        gt_classes = [x.gt_classes for x in proposals]\n\n        # Classification Loss\n        pred_class_logits = scores\n        gt_classes = cat(gt_classes, dim=0)\n        loss_cls = F.cross_entropy(pred_class_logits, gt_classes, reduction=\"mean\")\n        loss_cls *= self.loss_weight[\"loss_cls\"]\n\n        # Box Regression Loss\n        pred_proposal_deltas = proposal_deltas\n        gt_proposal_deltas = self.box2box_transform.get_deltas(\n            proposal_boxes, gt_boxes\n        )\n        loss_box_reg = _dense_box_regression_loss(\n            pred_proposal_deltas,\n            gt_proposal_deltas,\n            gt_classes,\n            self.smooth_l1_beta,\n            box_reg_loss_type=self.box_reg_loss_type,\n            reduction=\"mean\",\n        )\n        loss_box_reg *= self.loss_weight[\"loss_box_reg\"]\n\n        return {\"loss_cls\": loss_cls, \"loss_box_reg\": loss_box_reg}"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        gt_boxes = [x.gt_boxes for x in proposals]\n        gt_classes = [x.gt_classes for x in proposals]\n\n        # Calculate classification loss\n        pred_class_logits = scores\n        gt_classes = cat(gt_classes, dim=0)\n        loss_cls = F.cross_entropy(pred_class_logits, gt_classes, reduction=\"mean\")\n\n        # Calculate box regression loss\n        pred_proposal_deltas = proposal_deltas\n        gt_proposal_deltas = cat([x.gt_deltas for x in proposals], dim=0)\n        loss_box_reg = _dense_box_regression_loss(\n            pred_proposal_deltas,\n            gt_proposal_deltas,\n            gt_classes,\n            self.box2box_transform.weights,\n            smooth_l1_beta=self.smooth_l1_beta,\n            box_reg_loss_type=self.box_reg_loss_type,\n            num_labels=self.num_classes,\n        )\n\n        # Apply loss weights\n        loss_cls *= self.loss_weight.get(\"loss_cls\", 1.0)\n        loss_box_reg *= self.loss_weight.get(\"loss_box_reg\", 1.0)\n\n        return {\"loss_cls\": loss_cls, \"loss_box_reg\": loss_box_reg}"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "\n        scores, proposal_deltas = predictions\n        gt_classes = cat([p.gt_classes for p in proposals], dim=0)\n        gt_proposal_deltas = cat([p.gt_boxes.tensor for p in proposals], dim=0)\n        \n        loss_cls = F.cross_entropy(scores, gt_classes, reduction=\"mean\")\n        loss_box_reg = _dense_box_regression_loss(\n            proposal_deltas,\n            gt_proposal_deltas,\n            gt_classes,\n            self.smooth_l1_beta,\n            box_reg_loss_type=self.box_reg_loss_type,\n            reduction=\"mean\",\n        )\n        \n        return {\n            \"loss_cls\": loss_cls * self.loss_weight[\"loss_cls\"],\n            \"loss_box_reg\": loss_box_reg * self.loss_weight[\"loss_box_reg\"],\n        }"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        gt_boxes = [x.gt_boxes for x in proposals]\n        gt_classes = [x.gt_classes for x in proposals]\n\n        pred_class_logits, pred_proposal_deltas = scores, proposal_deltas\n\n        gt_classes, pred_class_logits = _transpose(gt_classes, pred_class_logits)\n        gt_proposal_deltas, pred_proposal_deltas = _transpose(gt_boxes, pred_proposal_deltas)\n\n        # Classification loss\n        loss_cls = F.cross_entropy(pred_class_logits, gt_classes, reduction=\"mean\")\n\n        # Box regression loss\n        loss_box_reg = _dense_box_regression_loss(\n            pred_proposal_deltas,\n            gt_proposal_deltas,\n            gt_classes,\n            self.smooth_l1_beta,\n            box_reg_loss_type=self.box_reg_loss_type,\n            box2box_transform=self.box2box_transform,\n        )\n\n        return {\n            \"loss_cls\": loss_cls * self.loss_weight[\"loss_cls\"],\n            \"loss_box_reg\": loss_box_reg * self.loss_weight[\"loss_box_reg\"],\n        }"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "\n        scores, proposal_deltas = predictions\n        gt_boxes = [x.gt_boxes for x in proposals]\n        gt_classes = [x.gt_classes for x in proposals]\n\n        pred_class_logits, pred_proposal_deltas = scores, proposal_deltas\n\n        gt_classes, gt_proposal_deltas = cat(gt_classes, dim=0), cat(gt_boxes, dim=0)\n\n        num_instances = gt_classes.numel()\n\n        if num_instances == 0:\n            return {\"loss_cls\": torch.tensor(0.0, device=gt_classes.device)}\n\n        _log_classification_stats(pred_class_logits, gt_classes)\n\n        loss_cls = F.cross_entropy(pred_class_logits, gt_classes, reduction=\"mean\")\n\n        if pred_proposal_deltas is not None:\n            loss_box_reg = _dense_box_regression_loss(\n                pred_proposal_deltas,\n                gt_proposal_deltas,\n                gt_classes,\n                self.smooth_l1_beta,\n                box_reg_loss_type=self.box_reg_loss_type,\n                num_classes=self.num_classes,\n            )\n            loss_box_reg = loss_box_reg * self.loss_weight.get(\"loss_box_reg\", 1.0)\n        else:\n            loss_box_reg = torch.tensor(0.0, device=gt_classes.device)\n\n        return {\"loss_cls\": loss_cls, \"loss_box_reg\": loss_box_reg}"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "\n        scores, proposal_deltas = predictions\n        gt_boxes = [x.gt_boxes for x in proposals]\n        gt_classes = [x.gt_classes for x in proposals]\n\n        # Classification loss\n        pred_class_logits = scores\n        gt_classes = cat(gt_classes, dim=0)\n        loss_cls = F.cross_entropy(pred_class_logits, gt_classes, reduction=\"mean\")\n\n        # Box regression loss\n        pred_proposal_deltas = proposal_deltas\n        gt_proposal_deltas = cat([x.gt_boxes.tensor for x in proposals], dim=0)\n        loss_box_reg = _dense_box_regression_loss(\n            pred_proposal_deltas,\n            gt_proposal_deltas,\n            gt_classes,\n            self.smooth_l1_beta,\n            box2box_transform=self.box2box_transform,\n            num_labels=self.num_classes,\n        )\n\n        return {\n            \"loss_cls\": loss_cls * self.loss_weight[\"loss_cls\"],\n            \"loss_box_reg\": loss_box_reg * self.loss_weight[\"loss_box_reg\"],\n        }"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        losses = {}\n        \n        # Classification Loss\n        pred_class_logits = scores\n        gt_classes = cat([p.gt_classes for p in proposals], dim=0)\n        loss_cls = F.cross_entropy(pred_class_logits, gt_classes, reduction=\"mean\")\n        losses[\"loss_cls\"] = loss_cls * self.loss_weight[\"loss_cls\"]\n        \n        # Box Regression Loss\n        pred_proposal_deltas = proposal_deltas\n        gt_proposal_deltas = cat([p.gt_boxes.tensor for p in proposals], dim=0)\n        loss_box_reg = _dense_box_regression_loss(\n            pred_proposal_deltas,\n            gt_proposal_deltas,\n            gt_classes,\n            self.box2box_transform,\n            smooth_l1_beta=self.smooth_l1_beta,\n            box_reg_loss_type=self.box_reg_loss_type,\n            reduction=\"mean\",\n        )\n        losses[\"loss_box_reg\"] = loss_box_reg * self.loss_weight[\"loss_box_reg\"]\n        \n        return losses"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        gt_boxes = [x.gt_boxes for x in proposals]\n        gt_classes = [x.gt_classes for x in proposals]\n\n        pred_class_logits, pred_proposal_deltas = scores, proposal_deltas\n        gt_classes, gt_proposal_deltas = cat(gt_classes, dim=0), cat(gt_boxes, dim=0)\n\n        # Classification loss\n        loss_cls = F.cross_entropy(pred_class_logits, gt_classes)\n\n        # Box regression loss\n        box2box_transform = self.box2box_transform\n        loss_box_reg = _dense_box_regression_loss(\n            pred_proposal_deltas,\n            gt_proposal_deltas,\n            gt_classes,\n            box2box_transform,\n            smooth_l1_beta=self.smooth_l1_beta,\n            box_reg_loss_type=self.box_reg_loss_type,\n        )\n\n        return {\"loss_cls\": loss_cls * self.loss_weight[\"loss_cls\"], \"loss_box_reg\": loss_box_reg * self.loss_weight[\"loss_box_reg\"]}"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "\n        scores, proposal_deltas = predictions\n        gt_boxes = [x.gt_boxes for x in proposals]\n        gt_classes = [x.gt_classes for x in proposals]\n\n        pred_class_logits, pred_proposal_deltas = scores, proposal_deltas\n        gt_proposal_deltas = self.box2box_transform.get_deltas(\n            gt_boxes, pred_class_logits.shape[-1]\n        )\n\n        # Classification loss\n        loss_cls = F.cross_entropy(pred_class_logits, cat(gt_classes, dim=0))\n\n        # Box regression loss\n        loss_box_reg = _dense_box_regression_loss(\n            pred_proposal_deltas,\n            gt_proposal_deltas,\n            gt_classes,\n            self.smooth_l1_beta,\n            box_reg_loss_type=self.box_reg_loss_type,\n        )\n\n        return {\n            \"loss_cls\": loss_cls * self.loss_weight[\"loss_cls\"],\n            \"loss_box_reg\": loss_box_reg * self.loss_weight[\"loss_box_reg\"],\n        }"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        gt_classes = cat([p.gt_classes for p in proposals], dim=0)\n        gt_proposal_deltas = cat([p.gt_boxes.tensor for p in proposals], dim=0)\n        \n        loss_cls = F.cross_entropy(scores, gt_classes, reduction=\"mean\")\n        \n        if proposal_deltas.numel() == 0:\n            return {\"loss_cls\": loss_cls * self.loss_weight[\"loss_cls\"]}\n        \n        device = proposal_deltas.device\n        box_dim = proposal_deltas.shape[1] // 4\n        gt_classes, proposal_deltas = (\n            gt_classes.to(device),\n            proposal_deltas.to(device),\n        )\n        gt_proposal_deltas = gt_proposal_deltas.to(device)\n\n        num_classes = scores.shape[1]\n        proposal_deltas = proposal_deltas.reshape(-1, box_dim, 4)\n        gt_proposal_deltas = gt_proposal_deltas.reshape(-1, box_dim, 4)\n\n        box2box_transform = self.box2box_transform\n        if self.box_reg_loss_type == \"smooth_l1\":\n            loss_box_reg = _dense_box_regression_loss(\n                proposal_deltas,\n                gt_proposal_deltas,\n                gt_classes,\n                box2box_transform,\n                smooth_l1_beta=self.smooth_l1_beta,\n                num_instances_per_class=gt_classes.new_ones(num_classes),\n                loss_weight=self.loss_weight[\"loss_box_reg\"],\n            )\n        else:\n            raise ValueError(f\"Invalid box_reg_loss_type: {self.box_reg_loss_type}\")\n\n        return {\"loss_cls\": loss_cls * self.loss_weight[\"loss_cls\"], \"loss_box_reg\": loss_box_reg}"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "\n        scores, proposal_deltas = predictions\n        gt_boxes = [x.gt_boxes for x in proposals]\n        gt_classes = [x.gt_classes for x in proposals]\n\n        # Classification loss\n        pred_class_logits = scores\n        loss_cls = F.cross_entropy(pred_class_logits, cat(gt_classes), reduction=\"mean\")\n\n        # Box regression loss\n        pred_proposal_deltas = proposal_deltas\n        gt_proposal_deltas = self.box2box_transform.get_deltas(\n            gt_boxes, cat([x.proposal_boxes.tensor for x in proposals])\n        )\n        loss_box_reg = _dense_box_regression_loss(\n            pred_proposal_deltas,\n            gt_proposal_deltas,\n            cat([x.proposal_boxes.tensor for x in proposals]),\n            self.box_reg_loss_type,\n            self.smooth_l1_beta,\n        )\n\n        return {\n            \"loss_cls\": loss_cls * self.loss_weight[\"loss_cls\"],\n            \"loss_box_reg\": loss_box_reg * self.loss_weight[\"loss_box_reg\"],\n        }"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        \n        scores, proposal_deltas = predictions\n        gt_boxes = [x.gt_boxes for x in proposals]\n        gt_classes = [x.gt_classes for x in proposals]\n\n        num_images = len(gt_boxes)\n        gt_classes = torch.cat(gt_classes, dim=0)\n        gt_boxes = cat([x.tensor for x in gt_boxes], dim=0)\n\n        device = proposal_deltas.device\n\n        # Classification loss\n        pred_class_logits, _ = scores\n        loss_cls = F.cross_entropy(pred_class_logits, gt_classes)\n\n        # Box regression loss\n        pred_proposal_deltas = proposal_deltas\n        gt_proposal_deltas = self.box2box_transform.get_deltas(gt_boxes, gt_classes, pred_proposal_deltas.device)\n        loss_box_reg = _dense_box_regression_loss(pred_proposal_deltas, gt_proposal_deltas, self.box_reg_loss_type, self.smooth_l1_beta)\n\n        return {\"loss_cls\": loss_cls * self.loss_weight[\"loss_cls\"], \"loss_box_reg\": loss_box_reg * self.loss_weight[\"loss_box_reg\"]}"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "\n        scores, proposal_deltas = predictions\n        gt_boxes = [x.gt_boxes for x in proposals]\n        gt_classes = [x.gt_classes for x in proposals]\n\n        pred_class_logits, pred_proposal_deltas = scores, proposal_deltas\n        gt_classes, gt_proposal_deltas = cat(gt_classes, dim=0), cat(gt_boxes, dim=0)\n\n        # Classification loss\n        loss_cls = F.cross_entropy(pred_class_logits, gt_classes)\n\n        # Box regression loss\n        loss_box_reg = _dense_box_regression_loss(\n            pred_proposal_deltas,\n            gt_proposal_deltas,\n            gt_classes,\n            self.smooth_l1_beta,\n            box2box_transform=self.box2box_transform,\n            box_reg_loss_type=self.box_reg_loss_type,\n        )\n\n        return {\n            \"loss_cls\": loss_cls * self.loss_weight[\"loss_cls\"],\n            \"loss_box_reg\": loss_box_reg * self.loss_weight[\"loss_box_reg\"],\n        }"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "\n        scores, proposal_deltas = predictions\n        gt_boxes = [x.gt_boxes for x in proposals]\n        gt_classes = [x.gt_classes for x in proposals]\n\n        pred_class_logits, pred_proposal_deltas = scores, proposal_deltas\n\n        gt_classes, pred_class_logits = _log_classification_stats(pred_class_logits, gt_classes)\n\n        loss_cls = cross_entropy(pred_class_logits, gt_classes, reduction=\"mean\")\n\n        gt_proposal_deltas = self.box2box_transform.get_deltas(\n            proposals, gt_boxes, gt_classes\n        )\n        loss_box_reg = _dense_box_regression_loss(\n            pred_proposal_deltas,\n            gt_proposal_deltas,\n            gt_classes,\n            self.smooth_l1_beta,\n            box_reg_loss_type=self.box_reg_loss_type,\n            reduction=\"mean\",\n        )\n\n        losses = {\n            \"loss_cls\": loss_cls * self.loss_weight[\"loss_cls\"],\n            \"loss_box_reg\": loss_box_reg * self.loss_weight[\"loss_box_reg\"],\n        }\n\n        return losses"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "\n        scores, proposal_deltas = predictions\n        gt_boxes = [x.gt_boxes for x in proposals]\n        gt_classes = [x.gt_classes for x in proposals]\n\n        pred_class_logits, pred_proposal_deltas = scores, proposal_deltas\n\n        # Classification Loss\n        loss_cls = F.cross_entropy(pred_class_logits, cat(gt_classes, dim=0))\n\n        # Box Regression Loss\n        gt_proposal_deltas = self.box2box_transform.get_deltas(\n            gt_boxes, cat([p.proposal_boxes.tensor for p in proposals], dim=0)\n        )\n        loss_box_reg = _dense_box_regression_loss(\n            pred_proposal_deltas,\n            gt_proposal_deltas,\n            gt_classes,\n            self.smooth_l1_beta,\n            self.box_reg_loss_type,\n            self.loss_weight.get(\"loss_box_reg\", 1.0),\n        )\n\n        return {\"loss_cls\": loss_cls, \"loss_box_reg\": loss_box_reg}"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.MODEL.TRACKER_HEAD.NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.MODEL.TRACKER_HEAD.NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.MODEL.TRACKER_HEAD.NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.MODEL.TRACKER_HEAD.NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.MODEL.TRACKER_HEAD.NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.MODEL.TRACKER.TRACKER_NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.MODEL.TRACKER_HEAD.NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.MODEL.TRACKER_HEAD.NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.MODEL.TRACKER_HEAD\n    return TRACKER_HEADS_REGISTRY.get(name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.MODEL.TRACKER.NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.MODEL.TRACKER.NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "\n    tracker_name = cfg.MODEL.TRACKER_HEAD.NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.MODEL.TRACKER_HEAD.NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "\n    name = cfg.MODEL.TRACKER_HEAD.NAME\n    return TRACKER_HEADS_REGISTRY.get(name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "\n    tracker_name = cfg.MODEL.TRACKER_HEAD.NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.MODEL.TRACKER_HEAD.NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.MODEL.TRACKER_HEAD.NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.MODEL.TRACKER_HEAD\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.MODEL.TRACKER_HEAD\n    return TRACKER_HEADS_REGISTRY.get(name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.MODEL.TRACKER.NAME\n    return TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        dx = deltas[:, 0::4]\n        dy = deltas[:, 1::4]\n        dw = deltas[:, 2::4]\n        dh = deltas[:, 3::4]\n\n        src_widths = boxes[:, 2] - boxes[:, 0]\n        src_heights = boxes[:, 3] - boxes[:, 1]\n        src_ctr_x = boxes[:, 0] + 0.5 * src_widths\n        src_ctr_y = boxes[:, 1] + 0.5 * src_heights\n\n        wx, wy, ww, wh = self.weights\n\n        pred_ctr_x = dx * src_widths[:, None] / wx + src_ctr_x[:, None]\n        pred_ctr_y = dy * src_heights[:, None] / wy + src_ctr_y[:, None]\n        pred_w = torch.clamp(\n            torch.exp(torch.min(dw, self.scale_clamp * wx)) * src_widths[:, None], min=1\n        )\n        pred_h = torch.clamp(\n            torch.exp(torch.min(dh, self.scale_clamp * wy)) * src_heights[:, None], min=1\n        )\n\n        pred_boxes = torch.zeros_like(deltas, device=deltas.device)\n        # x1\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w\n        # y1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h\n        # x2\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w\n        # y2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h\n\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        deltas = deltas.view(-1, 4)  # reshape to Nx4 if it's not already\n        boxes = boxes.to(deltas.dtype)  # ensure boxes and deltas have the same data type\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        # x1\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w\n        # y1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h\n        # x2\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w\n        # y2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h\n\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        deltas = deltas.float()  # Ensure deltas are of type float\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent large predicted values of dw and dh\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        # x1\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w\n        # y1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h\n        # x2\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w\n        # y2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h\n\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        deltas = deltas.float()  # Ensure deltas are of type float\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent large predictions for dw and dh\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        # x1\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w\n        # y1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h\n        # x2\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w\n        # y2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h\n\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        dx = deltas[:, 0::4]\n        dy = deltas[:, 1::4]\n        dw = deltas[:, 2::4]\n        dh = deltas[:, 3::4]\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n\n        dx = dx / wx\n        dy = dy / wy\n        dw = dw / ww\n        dh = dh / wh\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(torch.clamp(dw, max=self.scale_clamp)) * widths[:, None]\n        pred_h = torch.exp(torch.clamp(dh, max=self.scale_clamp)) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        # x1\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w\n        # y1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h\n        # x2\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w\n        # y2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h\n\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        deltas = deltas.view(-1, 4)  # Reshape deltas to (N, 4) if k > 1\n        boxes = boxes.unsqueeze(1).expand_as(deltas)  # Expand boxes to match the shape of deltas\n\n        widths = boxes[..., 2] - boxes[..., 0]\n        heights = boxes[..., 3] - boxes[..., 1]\n        ctr_x = boxes[..., 0] + 0.5 * widths\n        ctr_y = boxes[..., 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[..., 0] / wx\n        dy = deltas[..., 1] / wy\n        dw = deltas[..., 2] / ww\n        dh = deltas[..., 3] / wh\n\n        pred_ctr_x = dx * widths + ctr_x\n        pred_ctr_y = dy * heights + ctr_y\n        pred_w = torch.exp(torch.clamp(dw, max=self.scale_clamp)) * widths\n        pred_h = torch.exp(torch.clamp(dh, max=self.scale_clamp)) * heights\n\n        pred_boxes = deltas.clone()\n        # x1\n        pred_boxes[..., 0] = pred_ctr_x - 0.5 * pred_w\n        # y1\n        pred_boxes[..., 1] = pred_ctr_y - 0.5 * pred_h\n        # x2\n        pred_boxes[..., 2] = pred_ctr_x + 0.5 * pred_w\n        # y2\n        pred_boxes[..., 3] = pred_ctr_y + 0.5 * pred_h\n\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        deltas = deltas.view(-1, 4)  # Reshape deltas to (N, 4)\n        boxes = boxes.unsqueeze(1).expand(-1, deltas.size(1), -1)  # Duplicate boxes to match the shape of deltas\n        widths = boxes[:, :, 2] - boxes[:, :, 0]  # Calculate box widths\n        heights = boxes[:, :, 3] - boxes[:, :, 1]  # Calculate box heights\n        ctr_x = boxes[:, :, 0] + 0.5 * widths  # Calculate x-coordinate of box center\n        ctr_y = boxes[:, :, 1] + 0.5 * heights  # Calculate y-coordinate of box center\n\n        wx, wy, ww, wh = self.weights  # Get the scaling factors\n        dx = deltas[:, 0] / wx  # Calculate the change in x-coordinate\n        dy = deltas[:, 1] / wy  # Calculate the change in y-coordinate\n        dw = deltas[:, 2] / ww  # Calculate the change in width\n        dh = deltas[:, 3] / wh  # Calculate the change in height\n\n        pred_ctr_x = dx * widths + ctr_x  # Calculate the predicted x-coordinate of box center\n        pred_ctr_y = dy * heights + ctr_y  # Calculate the predicted y-coordinate of box center\n        pred_w = torch.exp(dw) * widths  # Calculate the predicted width\n        pred_h = torch.exp(dh) * heights  # Calculate the predicted height\n\n        pred_boxes = torch.zeros_like(deltas)  # Initialize the tensor to store the predicted boxes\n        pred_boxes[:, 0] = pred_ctr_x - 0.5 * pred_w  # Calculate the x-coordinate of the top-left corner\n        pred_boxes[:, 1] = pred_ctr_y - 0.5 * pred_h  # Calculate the y-coordinate of the top-left corner\n        pred_boxes[:, 2] = pred_ctr_x + 0.5 * pred_w  # Calculate the x-coordinate of the bottom-right corner\n        pred_boxes[:, 3] = pred_ctr_y + 0.5 * pred_h  # Calculate the y-coordinate of the bottom-right corner\n\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        deltas = deltas.float()  # Ensure deltas are of type float\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent dw and dh from being too large\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        # x1\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w\n        # y1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h\n        # x2\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w\n        # y2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h\n\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        deltas = deltas.float()  # Ensure deltas are of type float\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent large predictions for dw and dh\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        # x1\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w\n        # y1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h\n        # x2\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w\n        # y2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h\n\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        assert isinstance(deltas, torch.Tensor), type(deltas)\n        assert isinstance(boxes, torch.Tensor), type(boxes)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent large predictions from making the boxes too large\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas, dtype=deltas.dtype)\n        # x1\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w\n        # y1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h\n        # x2\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w\n        # y2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h\n\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        dx = deltas[:, 0::4]\n        dy = deltas[:, 1::4]\n        dw = deltas[:, 2::4]\n        dh = deltas[:, 3::4]\n\n        src_widths = boxes[:, 2] - boxes[:, 0]\n        src_heights = boxes[:, 3] - boxes[:, 1]\n        src_ctr_x = boxes[:, 0] + 0.5 * src_widths\n        src_ctr_y = boxes[:, 1] + 0.5 * src_heights\n\n        wx, wy, ww, wh = self.weights\n\n        pred_ctr_x = dx * src_widths[:, None] + src_ctr_x[:, None]\n        pred_ctr_y = dy * src_heights[:, None] + src_ctr_y[:, None]\n        pred_w = torch.clamp(dw, max=self.scale_clamp) * src_widths[:, None].exp()\n        pred_h = torch.clamp(dh, max=self.scale_clamp) * src_heights[:, None].exp()\n\n        pred_boxes = torch.zeros_like(deltas, device=deltas.device)\n        # x1\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w\n        # y1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h\n        # x2\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w\n        # y2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h\n\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        # Separate out deltas\n        dx = deltas[:, 0::4]\n        dy = deltas[:, 1::4]\n        dw = deltas[:, 2::4]\n        dh = deltas[:, 3::4]\n\n        # Separate out boxes\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        # Apply transformation\n        pred_ctr_x = dx * widths.unsqueeze(1) + ctr_x.unsqueeze(1)\n        pred_ctr_y = dy * heights.unsqueeze(1) + ctr_y.unsqueeze(1)\n        pred_w = torch.exp(torch.clamp(dw, max=self.scale_clamp)) * widths.unsqueeze(1)\n        pred_h = torch.exp(torch.clamp(dh, max=self.scale_clamp)) * heights.unsqueeze(1)\n\n        # Calculate new box coordinates\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h  # y1\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w  # x2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h  # y2\n\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        deltas = deltas.view(-1, 4)\n        boxes = boxes[:, None, :].expand(deltas.size(0), boxes.size(0), 4)\n        widths = boxes[:, :, 2] - boxes[:, :, 0]\n        heights = boxes[:, :, 3] - boxes[:, :, 1]\n        ctr_x = boxes[:, :, 0] + 0.5 * widths\n        ctr_y = boxes[:, :, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        pred_ctr_x = dx * widths + ctr_x\n        pred_ctr_y = dy * heights + ctr_y\n        pred_w = torch.exp(dw) * widths\n        pred_h = torch.exp(dh) * heights\n\n        pred_boxes = deltas.clone()\n        # x1\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w\n        # y1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h\n        # x2\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w\n        # y2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h\n\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        deltas = deltas.float()  # Ensure deltas are of type float\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent large dw and dh predictions\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        # x1\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w\n        # y1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h\n        # x2\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w\n        # y2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h\n\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        deltas = deltas.float()  # Ensure deltas are of type float\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent large predictions for dw and dh\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        # x1\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w\n        # y1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h\n        # x2\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w\n        # y2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h\n\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        # Separate out deltas\n        dx = deltas[:, 0::4]\n        dy = deltas[:, 1::4]\n        dw = deltas[:, 2::4]\n        dh = deltas[:, 3::4]\n\n        # Separate out boxes\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        # Apply transformations\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(torch.clamp(dw, max=self.scale_clamp)) * widths[:, None]\n        pred_h = torch.exp(torch.clamp(dh, max=self.scale_clamp)) * heights[:, None]\n\n        # Calculate new bounding boxes\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h  # y1\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w  # x2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h  # y2\n\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        deltas = deltas.view(-1, 4)  # Reshape deltas to (N, 4) if necessary\n        boxes = boxes.unsqueeze(1)  # Add a dimension to boxes for broadcasting\n        widths = boxes[..., 2] - boxes[..., 0]\n        heights = boxes[..., 3] - boxes[..., 1]\n        ctr_x = boxes[..., 0] + 0.5 * widths\n        ctr_y = boxes[..., 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[..., 0] / wx\n        dy = deltas[..., 1] / wy\n        dw = deltas[..., 2] / ww\n        dh = deltas[..., 3] / wh\n\n        pred_ctr_x = dx * widths + ctr_x\n        pred_ctr_y = dy * heights + ctr_y\n        pred_w = torch.exp(torch.clamp(dw, max=self.scale_clamp)) * widths\n        pred_h = torch.exp(torch.clamp(dh, max=self.scale_clamp)) * heights\n\n        pred_boxes = torch.stack(\n            (pred_ctr_x - 0.5 * pred_w, pred_ctr_y - 0.5 * pred_h, pred_ctr_x + 0.5 * pred_w, pred_ctr_y + 0.5 * pred_h),\n            dim=-1,\n        )\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        deltas = deltas.float()  # Ensure deltas are float type\n        dx = deltas[:, 0::4]\n        dy = deltas[:, 1::4]\n        dw = deltas[:, 2::4]\n        dh = deltas[:, 3::4]\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        pred_ctr_x = dx * widths.unsqueeze(1) / wx + ctr_x.unsqueeze(1)\n        pred_ctr_y = dy * heights.unsqueeze(1) / wy + ctr_y.unsqueeze(1)\n        pred_w = torch.exp(torch.clamp(dw, max=self.scale_clamp)) * widths.unsqueeze(1) / ww\n        pred_h = torch.exp(torch.clamp(dh, max=self.scale_clamp)) * heights.unsqueeze(1) / wh\n\n        pred_boxes = torch.zeros_like(deltas)\n        # x1\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w\n        # y1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h\n        # x2\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w\n        # y2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h\n\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        assert isinstance(deltas, torch.Tensor), type(deltas)\n        assert isinstance(boxes, torch.Tensor), type(boxes)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent large dx and dy from making the bounding boxes too large\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        # x1\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w\n        # y1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h\n        # x2\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w\n        # y2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h\n\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        assert isinstance(deltas, torch.Tensor), type(deltas)\n        assert isinstance(boxes, torch.Tensor), type(boxes)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent large predictions from affecting the results\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths.unsqueeze(1) + ctr_x.unsqueeze(1)\n        pred_ctr_y = dy * heights.unsqueeze(1) + ctr_y.unsqueeze(1)\n        pred_w = torch.exp(dw) * widths.unsqueeze(1)\n        pred_h = torch.exp(dh) * heights.unsqueeze(1)\n\n        pred_boxes = torch.zeros_like(deltas, device=deltas.device)\n        # x1\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w\n        # y1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h\n        # x2\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w\n        # y2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h\n\n        return pred_boxes"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        img, k = resize_image(image, 512)\n        img = np.transpose(img, (2, 0, 1))\n        img = np.expand_dims(img, axis=0)\n        self.general_ins.run({'img': img})"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "    img, k = resize_image(image, 512)\n    img = np.transpose(img, (2, 0, 1))\n    img = np.expand_dims(img, axis=0)\n    with torch.no_grad():\n        output = self.general_ins(img)\n    if anno_type is None:\n        return output\n    elif isinstance(anno_type, str):\n        return output[anno_type]\n    elif isinstance(anno_type, (list, tuple)):\n        return {anno: output[anno] for anno in anno_type if anno in output}\n    else:\n        raise Exception(f'Error anno_type: {anno_type}')"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "    img, k = resize_image(image, 512)\n    img = np.expand_dims(img, axis=0)\n    input_data = {'img': img}\n    output_data = self.general_ins(input_data)\n\n    if anno_type is None:\n        return output_data\n    elif isinstance(anno_type, str):\n        return output_data[anno_type]\n    elif isinstance(anno_type, (list, tuple)):\n        return {key: output_data[key] for key in anno_type if key in output_data}\n    else:\n        raise Exception(f'Error anno_type: {anno_type}')"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        img, k = resize_image(image, 512)\n        img = np.transpose(img, (2, 0, 1))\n        img = np.expand_dims(img, axis=0)\n        img = img.astype(np.float32) / 255.0\n\n        with torch.no_grad():\n            output = self.general_ins({'img': img})\n\n        if anno_type is not None:\n            if isinstance(anno_type, str):\n                if anno_type in output.keys():\n                    return {anno_type: output[anno_type]}\n                else:\n                    return None\n            elif isinstance(anno_type, (list, tuple)):\n                return {key: output[key] for key in anno_type if key in output.keys()}\n            else:\n                raise Exception(f'Error anno_type: {anno_type}')\n        else:\n            return output"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        img, k = resize_image(image, 512)\n        img = np.transpose(img, (2, 0, 1))\n        img = np.expand_dims(img, axis=0)\n        img = img.astype(np.float32)\n\n        with torch.no_grad():\n            output = self.general_ins({'img': img})\n\n        if anno_type:\n            if isinstance(anno_type, str):\n                if anno_type in output:\n                    return {anno_type: output[anno_type]}\n                else:\n                    raise ValueError(f\"Annotation type '{anno_type}' not found in the output\")\n            elif isinstance(anno_type, (list, tuple)):\n                return {anno: output[anno] for anno in anno_type if anno in output}\n            else:\n                raise ValueError(\"anno_type must be a string, list, or tuple\")\n        else:\n            return output"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        image, k = resize_image(image, 512)\n        output = self.general_ins({'img': image})\n        \n        if anno_type is None:\n            return output\n        elif isinstance(anno_type, str):\n            return output[anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            return {key: output[key] for key in anno_type if key in output}\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        img, k = resize_image(image, 512)\n        img = img.transpose(2, 0, 1)\n        img = np.expand_dims(img, axis=0)\n        img = np.ascontiguousarray(img, dtype=np.float32)\n        img = torch.from_numpy(img)\n        img = img.to('cuda')\n\n        with torch.no_grad():\n            output = self.general_ins({'img': img})\n\n        if anno_type is None:\n            return output\n        elif isinstance(anno_type, str):\n            return output.get(anno_type)\n        elif isinstance(anno_type, (list, tuple)):\n            return {anno: output.get(anno) for anno in anno_type}\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        img, k = resize_image(image, 512)\n        img = img.astype(np.float32) / 255.0\n        img = np.transpose(img, (2, 0, 1))\n        img = np.expand_dims(img, axis=0)\n\n        self.general_ins(img)\n\n        output = self.general_ins.output\n        output = {key: output[key] for key in output.keys() & self.anno_type_map.keys()}\n\n        if anno_type is None:\n            return output\n        elif isinstance(anno_type, str):\n            return output.get(anno_type, None)\n        elif isinstance(anno_type, (list, tuple)):\n            return {key: output[key] for key in anno_type if key in output}\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        img, k = resize_image(image, 512)\n        img = np.transpose(img, (2, 0, 1))\n        img = img[np.newaxis, :]\n        img = img.astype(np.float32) / 255.0\n        img = torch.from_numpy(img)\n        img = img.to(we.device_id)\n\n        with torch.no_grad():\n            output = self.general_ins({'img': img})\n\n        if anno_type is None:\n            return output\n        elif isinstance(anno_type, str):\n            return output[self.anno_type_map[anno_type]['OUTPUT_KEYS'][0]]\n        elif isinstance(anno_type, (list, tuple)):\n            return {tp: output[self.anno_type_map[tp]['OUTPUT_KEYS'][0]] for tp in anno_type}\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        input_image, k = resize_image(image, 512)\n        input_image = input_image.astype(np.float32) / 255.0\n        input_image = input_image.transpose((2, 0, 1))\n        input_image = np.expand_dims(input_image, axis=0)\n\n        with torch.no_grad():\n            output = self.general_ins(input_image)\n\n        if anno_type is not None:\n            if isinstance(anno_type, str):\n                if anno_type in output.keys():\n                    return {anno_type: output[anno_type]}\n                else:\n                    return {}\n            elif isinstance(anno_type, (list, tuple)):\n                filtered_output = {key: output[key] for key in anno_type if key in output.keys()}\n                return filtered_output\n        else:\n            return output"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "    input_image, k = resize_image(image, 1024)\n    input_image = np.transpose(input_image, (2, 0, 1))\n    input_image = np.expand_dims(input_image, axis=0)\n    input_image = input_image.astype(np.float32)\n    input_image = input_image / 255.0\n\n    with torch.no_grad():\n        output = self.general_ins({'img': input_image})\n\n    if anno_type is not None:\n        if isinstance(anno_type, str):\n            return output[anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            return {anno: output[anno] for anno in anno_type}\n    else:\n        return output"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        img, k = resize_image(image, 512)\n        img = img.transpose((2, 0, 1))\n        img = np.expand_dims(img, axis=0)\n        img = img.astype(np.float32)\n        img = (img - 127.5) / 128.0\n        img = torch.from_numpy(img)\n\n        with torch.no_grad():\n            outputs = self.general_ins(img)\n\n        if anno_type is None:\n            return outputs\n        elif isinstance(anno_type, str):\n            return outputs[self.anno_type_map[anno_type]['OUTPUT_KEYS'][0]]\n        elif isinstance(anno_type, (list, tuple)):\n            result = {}\n            for tp in anno_type:\n                if tp in self.anno_type_map.keys():\n                    result[tp] = outputs[self.anno_type_map[tp]['OUTPUT_KEYS'][0]]\n            return result\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "    img, k = resize_image(image, 512)\n    img = img.astype(np.float32) / 255.0\n    img = img.transpose((2, 0, 1))\n    img = np.expand_dims(img, axis=0)\n\n    with torch.no_grad():\n        output = self.general_ins(img)\n\n    if anno_type is None:\n        return output\n    elif isinstance(anno_type, str):\n        return output[self.anno_type_map[anno_type]['OUTPUT_KEYS'][0]]\n    elif isinstance(anno_type, (list, tuple)):\n        return {tp: output[self.anno_type_map[tp]['OUTPUT_KEYS'][0]] for tp in anno_type}\n    else:\n        raise Exception(f'Error anno_type: {anno_type}')"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        # Resize the input image\n        resized_image, k = resize_image(image, 512)\n\n        # Process the resized image using the general annotation instruction\n        output = self.general_ins({'img': resized_image})\n\n        # If no specific annotation type is requested, return the entire processed output\n        if anno_type is None:\n            return output\n\n        # If a specific annotation type is requested, filter the output and return only that annotation\n        if isinstance(anno_type, str):\n            if anno_type in output:\n                return {anno_type: output[anno_type]}\n            else:\n                return {}\n        elif isinstance(anno_type, (list, tuple)):\n            filtered_output = {key: output[key] for key in anno_type if key in output}\n            return filtered_output\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        img, k = resize_image(image, 1024)\n        img = np.transpose(img, (2, 0, 1))\n        img = np.expand_dims(img, axis=0)\n        img = img / 255.0\n\n        with torch.no_grad():\n            output = self.general_ins({'img': img})\n\n        if anno_type is None:\n            return output\n        elif isinstance(anno_type, str):\n            return output.get(anno_type, None)\n        elif isinstance(anno_type, (list, tuple)):\n            return {key: output[key] for key in anno_type if key in output}\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        img, k = resize_image(image, 1080)\n        img = np.transpose(img, (2, 0, 1))\n        img = np.expand_dims(img, axis=0)\n        img = np.ascontiguousarray(img, dtype=np.float32)\n        img = img / 255.0\n        img = img * 2.0 - 1.0\n\n        self.general_ins(img)\n        output = self.general_ins.output\n\n        if anno_type is None:\n            return output\n        elif isinstance(anno_type, str):\n            if anno_type in output:\n                return {anno_type: output[anno_type]}\n            else:\n                return {}\n        elif isinstance(anno_type, (list, tuple)):\n            return {anno: output[anno] for anno in anno_type if anno in output}\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "    img, k = resize_image(image, 512)\n    img = np.transpose(img, (2, 0, 1))\n    img = img[np.newaxis, ...]\n    with torch.no_grad():\n        output = self.general_ins(img)\n    output = {k: v.detach().cpu().numpy() for k, v in output.items()}\n\n    if anno_type is None:\n        return output\n    elif isinstance(anno_type, str):\n        return output.get(anno_type, None)\n    elif isinstance(anno_type, (list, tuple)):\n        return {k: v for k, v in output.items() if k in anno_type}\n    else:\n        raise Exception(f'Error anno_type: {anno_type}')"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "    img, k = resize_image(image, 1024)\n    img = np.transpose(img, (2, 0, 1))\n    img = np.expand_dims(img, axis=0)\n    output = self.general_ins({'img': img})\n    \n    if anno_type is None:\n        return output\n    elif isinstance(anno_type, str):\n        return output[anno_type]\n    elif isinstance(anno_type, (list, tuple)):\n        return {anno: output[anno] for anno in anno_type if anno in output}\n    else:\n        raise ValueError('anno_type must be a string, list, or None')"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "    img, k = resize_image(image, 512)\n    img = np.transpose(img, (2, 0, 1))\n    img = np.expand_dims(img, axis=0)\n    img = torch.from_numpy(img).float()\n    with torch.no_grad():\n        output = self.general_ins(img)\n    \n    if anno_type is None:\n        return output\n    elif isinstance(anno_type, str):\n        return output[self.anno_type_map[anno_type]['OUTPUT_KEYS'][0]]\n    elif isinstance(anno_type, (list, tuple)):\n        return {anno: output[self.anno_type_map[anno]['OUTPUT_KEYS'][0]] for anno in anno_type}\n    else:\n        raise Exception(f'Error anno_type: {anno_type}')"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "    img, k = resize_image(image, 512)\n    img = img.astype(np.float32) / 255.0\n    img = np.transpose(img, (2, 0, 1))\n    img = np.expand_dims(img, axis=0)\n    with torch.no_grad():\n        output = self.general_ins({'img': torch.from_numpy(img)})\n    if anno_type is None:\n        return output\n    elif isinstance(anno_type, str):\n        return output[anno_type]\n    elif isinstance(anno_type, (list, tuple)):\n        return {anno: output[anno] for anno in anno_type if anno in output}\n    else:\n        raise Exception(f'Error anno_type: {anno_type}')"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n        result = {}\n        for kw in keywords:\n            scores = self.bm25(kw)\n            result = update_url_scores(result, scores)\n        return result"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n        result = {}\n        for kw in keywords:\n            scores = self.bm25(kw)\n            result = update_url_scores(result, scores)\n        return result"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n        url_scores = {}\n        \n        for kw in keywords:\n            bm25_scores = self.bm25(kw)\n            url_scores = update_url_scores(url_scores, bm25_scores)\n        \n        return url_scores"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n        result = {}\n        for kw in keywords:\n            scores = self.bm25(kw)\n            result = update_url_scores(result, scores)\n        return result"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n        result = {}\n        for kw in keywords:\n            scores = self.bm25(kw)\n            result = update_url_scores(result, scores)\n        return result"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n        result = {}\n        for kw in keywords:\n            scores = self.bm25(kw)\n            result = update_url_scores(result, scores)\n        return result"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n        result = {}\n        for keyword in keywords:\n            scores = self.bm25(keyword)\n            result = update_url_scores(result, scores)\n        return result"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n        result = {}\n        for kw in keywords:\n            scores = self.bm25(kw)\n            result = update_url_scores(result, scores)\n        return result"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        result = {}\n        for kw in keywords:\n            scores = self.bm25(kw)\n            result = update_url_scores(result, scores)\n        return result"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n        result = {}\n        for kw in keywords:\n            scores = self.bm25(kw)\n            result = update_url_scores(result, scores)\n        return result"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n        result = {}\n        for kw in keywords:\n            scores = self.bm25(kw)\n            result = update_url_scores(result, scores)\n        return result"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n        result = {}\n        for kw in keywords:\n            scores = self.bm25(kw)\n            result = update_url_scores(result, scores)\n        return result"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n        result = {}\n        for kw in keywords:\n            scores = self.bm25(kw)\n            result = update_url_scores(result, scores)\n        return result"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n        scores = defaultdict(float)\n\n        for kw in keywords:\n            kw_scores = self.bm25(kw)\n            for url, score in kw_scores.items():\n                scores[url] += score\n\n        return dict(scores)"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n        scores = defaultdict(float)\n\n        for kw in keywords:\n            bm25_scores = self.bm25(kw)\n            update_url_scores(scores, bm25_scores)\n\n        return scores"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n        result = {}\n        for kw in keywords:\n            scores = self.bm25(kw)\n            result = update_url_scores(result, scores)\n        return result"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n        result = {}\n        for kw in keywords:\n            scores = self.bm25(kw)\n            result = update_url_scores(result, scores)\n        return result"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n        result = {}\n        for kw in keywords:\n            scores = self.bm25(kw)\n            result = update_url_scores(result, scores)\n        return result"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n        url_scores = {}\n        for keyword in keywords:\n            scores = self.bm25(keyword)\n            url_scores = update_url_scores(url_scores, scores)\n        return url_scores"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n        url_scores = {}\n        for kw in keywords:\n            scores = self.bm25(kw)\n            url_scores = update_url_scores(url_scores, scores)\n        return url_scores"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        \n        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "\n        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "\n        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        \n        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "\n        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        nearly_horizontal = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n        if nearly_horizontal.any():\n            boxes = self.tensor[nearly_horizontal]\n\n            # Convert to (x1, y1, x2, y2)\n            # x1, y1 is top-left corner, x2, y2 is bottom-right corner\n            # Note: We assume the angle is in range (-180, 180] degrees\n            # Note: The angle is in degrees\n            # Note: The coordinates are in (x, y) order\n            widths = boxes[:, 2] / 2.0\n            heights = boxes[:, 3] / 2.0\n            cosines = torch.cos(boxes[:, 4] * math.pi / 180.0)\n            sines = torch.sin(boxes[:, 4] * math.pi / 180.0)\n            x_centers = boxes[:, 0]\n            y_centers = boxes[:, 1]\n\n            # Compute the corners of the boxes\n            x1 = x_centers - widths * cosines - heights * sines\n            y1 = y_centers - widths * sines + heights * cosines\n            x2 = x_centers + widths * cosines - heights * sines\n            y2 = y_centers + widths * sines + heights * cosines\n\n            # Clamp the coordinates to ensure they fit within the box size\n            x1 = torch.clamp(x1, min=0, max=box_size[1])\n            y1 = torch.clamp(y1, min=0, max=box_size[0])\n            x2 = torch.clamp(x2, min=0, max=box_size[1])\n            y2 = torch.clamp(y2, min=0, max=box_size[0])\n\n            # Convert back to (x_center, y_center, width, height, angle)\n            new_widths = (x2 - x1) / 2.0\n            new_heights = (y2 - y1) / 2.0\n            new_x_centers = (x1 + x2) / 2.0\n            new_y_centers = (y1 + y2) / 2.0\n            new_cosines = (x2 - x1) / (2.0 * new_widths)\n            new_sines = (y2 - y1) / (2.0 * new_heights)\n\n            new_boxes = torch.stack(\n                [\n                    new_x_centers,\n                    new_y_centers,\n                    new_widths,\n                    new_heights,\n                    torch.atan2(new_sines, new_cosines) * 180.0 / math.pi,\n                ],\n                dim=1,\n            )\n\n            # Update the original tensor with the clipped boxes\n            self.tensor[nearly_horizontal] = new_boxes"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        nearly_horizontal_boxes = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n        horizontal_boxes = self.tensor[nearly_horizontal_boxes]\n\n        if horizontal_boxes.numel() > 0:\n            x_c, y_c, w, h, angle = horizontal_boxes[:, 0], horizontal_boxes[:, 1], horizontal_boxes[:, 2], horizontal_boxes[:, 3], horizontal_boxes[:, 4]\n            x1 = x_c - w / 2\n            y1 = y_c - h / 2\n            x2 = x_c + w / 2\n            y2 = y_c + h / 2\n\n            x1 = torch.clamp(x1, 0, box_size[1])\n            y1 = torch.clamp(y1, 0, box_size[0])\n            x2 = torch.clamp(x2, 0, box_size[1])\n            y2 = torch.clamp(y2, 0, box_size[0])\n\n            new_w = x2 - x1\n            new_h = y2 - y1\n            self.tensor[nearly_horizontal_boxes] = torch.stack([x1 + new_w / 2, y1 + new_h / 2, new_w, new_h, angle], dim=1)"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        horizontal_boxes = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n        centers = self.tensor[:, :2]\n        widths = self.tensor[:, 2]\n        heights = self.tensor[:, 3]\n        angles = self.tensor[:, 4]\n\n        x1 = centers[:, 0] - widths / 2\n        y1 = centers[:, 1] - heights / 2\n        x2 = centers[:, 0] + widths / 2\n        y2 = centers[:, 1] + heights / 2\n\n        x1[horizontal_boxes] = torch.clamp(x1[horizontal_boxes], min=0, max=box_size[1])\n        y1[horizontal_boxes] = torch.clamp(y1[horizontal_boxes], min=0, max=box_size[0])\n        x2[horizontal_boxes] = torch.clamp(x2[horizontal_boxes], min=0, max=box_size[1])\n        y2[horizontal_boxes] = torch.clamp(y2[horizontal_boxes], min=0, max=box_size[0])\n\n        new_centers_x = (x1 + x2) / 2\n        new_centers_y = (y1 + y2) / 2\n        new_widths = x2 - x1\n        new_heights = y2 - y1\n\n        self.tensor[:, 0] = new_centers_x\n        self.tensor[:, 1] = new_centers_y\n        self.tensor[:, 2] = new_widths\n        self.tensor[:, 3] = new_heights\n        self.tensor[:, 4] = angles"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n\n        # Identify nearly horizontal boxes\n        horizontal_boxes = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n\n        # Convert representation to (x1, y1, x2, y2)\n        widths = self.tensor[:, 2] / 2\n        heights = self.tensor[:, 3] / 2\n        x_centers = self.tensor[:, 0]\n        y_centers = self.tensor[:, 1]\n        angles = self.tensor[:, 4]\n\n        x1 = x_centers - widths * torch.cos(angles) - heights * torch.sin(angles)\n        y1 = y_centers - widths * torch.sin(angles) + heights * torch.cos(angles)\n        x2 = x_centers + widths * torch.cos(angles) + heights * torch.sin(angles)\n        y2 = y_centers + widths * torch.sin(angles) - heights * torch.cos(angles)\n\n        # Clamp x and y coordinates\n        x1 = torch.clamp(x1, 0, box_size[1])\n        y1 = torch.clamp(y1, 0, box_size[0])\n        x2 = torch.clamp(x2, 0, box_size[1])\n        y2 = torch.clamp(y2, 0, box_size[0])\n\n        # Convert back to original representation\n        new_x_centers = (x1 + x2) / 2\n        new_y_centers = (y1 + y2) / 2\n        new_widths = torch.abs(x2 - x1)\n        new_heights = torch.abs(y2 - y1)\n\n        self.tensor[horizontal_boxes, 0] = new_x_centers[horizontal_boxes]\n        self.tensor[horizontal_boxes, 1] = new_y_centers[horizontal_boxes]\n        self.tensor[horizontal_boxes, 2] = new_widths[horizontal_boxes]\n        self.tensor[horizontal_boxes, 3] = new_heights[horizontal_boxes]\n        self.tensor[horizontal_boxes, 4] = self.tensor[horizontal_boxes, 4] % 360"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        nearly_horizontal = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n        if nearly_horizontal.any():\n            # Convert to (x1, y1, x2, y2)\n            boxes = self.tensor[nearly_horizontal]\n            new_boxes = Boxes(boxes).to_xyxy()\n            new_boxes.clip(box_size)\n            new_boxes.clip_to_image(remove_empty=False)\n            new_boxes = new_boxes.to(self.tensor.device)\n            self.tensor[nearly_horizontal] = new_boxes.tensor"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        # Normalize angles\n        self.normalize_angles()\n\n        # Identify nearly horizontal boxes\n        nearly_horizontal_indices = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n\n        # Convert representation to (x1, y1, x2, y2)\n        x_center, y_center, width, height, angle = self.tensor[nearly_horizontal_indices].unbind(dim=1)\n        cos_theta = torch.cos(angle * math.pi / 180)\n        sin_theta = torch.sin(angle * math.pi / 180)\n        x1 = x_center - width / 2 * cos_theta - height / 2 * sin_theta\n        y1 = y_center - width / 2 * sin_theta + height / 2 * cos_theta\n        x2 = x_center + width / 2 * cos_theta + height / 2 * sin_theta\n        y2 = y_center + width / 2 * sin_theta - height / 2 * cos_theta\n\n        # Clamp x and y coordinates\n        x1 = torch.clamp(x1, min=0, max=box_size[1])\n        y1 = torch.clamp(y1, min=0, max=box_size[0])\n        x2 = torch.clamp(x2, min=0, max=box_size[1])\n        y2 = torch.clamp(y2, min=0, max=box_size[0])\n\n        # Convert back to original representation\n        new_x_center = (x1 + x2) / 2\n        new_y_center = (y1 + y2) / 2\n        new_width = torch.abs(x2 - x1)\n        new_height = torch.abs(y2 - y1)\n        self.tensor[nearly_horizontal_indices] = torch.stack([new_x_center, new_y_center, new_width, new_height, angle], dim=1)"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n\n        nearly_horizontal = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n        if nearly_horizontal.any():\n            # Convert to (x1, y1, x2, y2)\n            # (x1, y1) is the top-left corner, and (x2, y2) is the bottom-right corner\n            ws = self.tensor[nearly_horizontal, 2] / 2.0\n            hs = self.tensor[nearly_horizontal, 3] / 2.0\n            sin = torch.sin(self.tensor[nearly_horizontal, 4] * math.pi / 180.0)\n            cos = torch.cos(self.tensor[nearly_horizontal, 4] * math.pi / 180.0)\n            x_ctr, y_ctr = self.tensor[nearly_horizontal, 0], self.tensor[nearly_horizontal, 1]\n\n            x1 = x_ctr - ws * cos - hs * sin\n            x2 = x_ctr + ws * cos + hs * sin\n            y1 = y_ctr - ws * sin + hs * cos\n            y2 = y_ctr + ws * sin - hs * cos\n\n            # Clamp to box_size\n            x1 = torch.clamp(x1, 0, box_size[1])\n            x2 = torch.clamp(x2, 0, box_size[1])\n            y1 = torch.clamp(y1, 0, box_size[0])\n            y2 = torch.clamp(y2, 0, box_size[0])\n\n            # Convert back to (x_ctr, y_ctr, width, height, angle)\n            self.tensor[nearly_horizontal, 0] = (x1 + x2) / 2\n            self.tensor[nearly_horizontal, 1] = (y1 + y2) / 2\n            self.tensor[nearly_horizontal, 2] = x2 - x1\n            self.tensor[nearly_horizontal, 3] = y2 - y1\n            self.tensor[nearly_horizontal, 4] = torch.where(\n                self.tensor[nearly_horizontal, 2] > 0, torch.atan2(y2 - y1, x2 - x1) * 180.0 / math.pi, self.tensor[nearly_horizontal, 4]\n            )"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n\n        # Identify indices of nearly horizontal boxes based on the clip_angle_threshold\n        horizontal_indices = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n\n        # Convert representation from (center x, center y, width, height, angle) to (x1, y1, x2, y2)\n        boxes = self.tensor.clone()\n        boxes[horizontal_indices, 4] = 0  # Set angle to 0 for nearly horizontal boxes\n        h = boxes[:, 3].unsqueeze(1)  # height\n        w = boxes[:, 2].unsqueeze(1)  # width\n        cos_theta = torch.cos(boxes[:, 4] * math.pi / 180)\n        sin_theta = torch.sin(boxes[:, 4] * math.pi / 180)\n        center_x = boxes[:, 0].unsqueeze(1)\n        center_y = boxes[:, 1].unsqueeze(1)\n\n        x1 = center_x - w / 2 * cos_theta - h / 2 * sin_theta\n        y1 = center_y - w / 2 * sin_theta + h / 2 * cos_theta\n        x2 = center_x + w / 2 * cos_theta - h / 2 * sin_theta\n        y2 = center_y + w / 2 * sin_theta + h / 2 * cos_theta\n\n        # Clamp x and y coordinates to ensure they do not exceed the specified box_size limits\n        x1 = torch.clamp(x1, 0, box_size[1])\n        y1 = torch.clamp(y1, 0, box_size[0])\n        x2 = torch.clamp(x2, 0, box_size[1])\n        y2 = torch.clamp(y2, 0, box_size[0])\n\n        # Convert boxes back to original representation\n        center_x = (x1 + x2) / 2\n        center_y = (y1 + y2) / 2\n        w = torch.abs(x2 - x1)\n        h = torch.abs(y2 - y1)\n        boxes = torch.stack((center_x, center_y, w, h, boxes[:, 4]), dim=1)\n\n        # Update the tensor attribute of the RotatedBoxes instance\n        self.tensor = boxes"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        nearly_horizontal = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n        x_c, y_c, w, h, angle = self.tensor[nearly_horizontal].unbind(dim=1)\n        x1 = x_c - w / 2\n        y1 = y_c - h / 2\n        x2 = x_c + w / 2\n        y2 = y_c + h / 2\n        x1 = torch.clamp(x1, 0, box_size[1])\n        y1 = torch.clamp(y1, 0, box_size[0])\n        x2 = torch.clamp(x2, 0, box_size[1])\n        y2 = torch.clamp(y2, 0, box_size[0])\n        w = x2 - x1\n        h = y2 - y1\n        self.tensor[nearly_horizontal] = torch.stack([x1, y1, w, h, angle], dim=1)"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        box = self.tensor\n        horizontal_boxes = torch.abs(box[:, 4]) < clip_angle_threshold\n        for i in range(len(box)):\n            if horizontal_boxes[i]:\n                x_c, y_c, w, h, angle = box[i]\n                x1 = x_c - w / 2\n                y1 = y_c - h / 2\n                x2 = x_c + w / 2\n                y2 = y_c + h / 2\n                x1 = max(0, min(x1, box_size[1]))\n                y1 = max(0, min(y1, box_size[0]))\n                x2 = max(0, min(x2, box_size[1]))\n                y2 = max(0, min(y2, box_size[0]))\n                w_clipped = x2 - x1\n                h_clipped = y2 - y1\n                box[i] = torch.tensor([x1 + w_clipped / 2, y1 + h_clipped / 2, w_clipped, h_clipped, angle])"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()  # Normalize angles to be within the range (-180, 180] degrees\n        nearly_horizontal_boxes = torch.abs(self.tensor[:, 4]) < clip_angle_threshold  # Identify nearly horizontal boxes\n        for i in range(len(self.tensor)):\n            if nearly_horizontal_boxes[i]:\n                x_c, y_c, w, h, angle = self.tensor[i]\n                x1 = x_c - w / 2\n                y1 = y_c - h / 2\n                x2 = x_c + w / 2\n                y2 = y_c + h / 2\n                x1 = max(0, min(x1, box_size[1]))\n                x2 = max(0, min(x2, box_size[1]))\n                y1 = max(0, min(y1, box_size[0]))\n                y2 = max(0, min(y2, box_size[0]))\n                self.tensor[i] = torch.tensor([x1, y1, x2, y2, angle])"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        boxes = self.tensor\n        nearly_horizontal = torch.abs(boxes[:, 4]) < clip_angle_threshold\n        for i in range(len(boxes)):\n            if nearly_horizontal[i]:\n                x_c, y_c, w, h, a = boxes[i]\n                x1 = x_c - w / 2\n                y1 = y_c - h / 2\n                x2 = x_c + w / 2\n                y2 = y_c + h / 2\n                x1 = max(0, min(x1, box_size[1]))\n                y1 = max(0, min(y1, box_size[0]))\n                x2 = max(0, min(x2, box_size[1]))\n                y2 = max(0, min(y2, box_size[0]))\n                w_clipped = x2 - x1\n                h_clipped = y2 - y1\n                boxes[i] = torch.tensor([x1 + w_clipped / 2, y1 + h_clipped / 2, w_clipped, h_clipped, a])"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n\n        nearly_horizontal = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n        horizontal_boxes = self.tensor[nearly_horizontal]\n\n        if horizontal_boxes.numel() > 0:\n            x_c, y_c, width, height, angle = horizontal_boxes.unbind(dim=1)\n            x1 = x_c - width / 2\n            y1 = y_c - height / 2\n            x2 = x_c + width / 2\n            y2 = y_c + height / 2\n\n            x1 = torch.clamp(x1, min=0, max=box_size[1])\n            y1 = torch.clamp(y1, min=0, max=box_size[0])\n            x2 = torch.clamp(x2, min=0, max=box_size[1])\n            y2 = torch.clamp(y2, min=0, max=box_size[0])\n\n            new_width = x2 - x1\n            new_height = y2 - y1\n\n            # Avoid numerical errors that could increase box sizes\n            self.tensor[nearly_horizontal] = torch.stack([x1 + new_width / 2, y1 + new_height / 2, new_width, new_height, angle], dim=1)"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()  # Normalize the angles of the boxes to be within the range (-180, 180] degrees\n\n        # Identify the indices of the boxes that are nearly horizontal based on the clip_angle_threshold\n        nearly_horizontal_indices = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n\n        # Convert the representation of nearly horizontal boxes from (center x, center y, width, height, angle) to (x1, y1, x2, y2)\n        boxes = self.tensor[nearly_horizontal_indices]\n        x_center, y_center, width, height, angle = boxes.unbind(dim=1)\n        x1 = x_center - width / 2\n        y1 = y_center - height / 2\n        x2 = x_center + width / 2\n        y2 = y_center + height / 2\n\n        # Clamp the x and y coordinates to ensure they do not exceed the specified box_size limits\n        x1 = torch.clamp(x1, 0, box_size[1])\n        y1 = torch.clamp(y1, 0, box_size[0])\n        x2 = torch.clamp(x2, 0, box_size[1])\n        y2 = torch.clamp(y2, 0, box_size[0])\n\n        # Convert the boxes back to their original representation, ensuring that any numerical errors do not increase their sizes\n        width = x2 - x1\n        height = y2 - y1\n        x_center = (x1 + x2) / 2\n        y_center = (y1 + y2) / 2\n        self.tensor[nearly_horizontal_indices] = torch.stack((x_center, y_center, width, height, angle), dim=1)"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n\n        nearly_horizontal = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n        if nearly_horizontal.any():\n            # Convert to (x1, y1, x2, y2)\n            boxes = self.tensor[nearly_horizontal]\n            x, y, w, h, a = boxes.unbind(1)\n            x1, x2 = (x - w / 2), (x + w / 2)\n            y1, y2 = (y - h / 2), (y + h / 2)\n\n            # Clamp\n            x1 = torch.clamp(x1, min=0, max=box_size[1])\n            x2 = torch.clamp(x2, min=0, max=box_size[1])\n            y1 = torch.clamp(y1, min=0, max=box_size[0])\n            y2 = torch.clamp(y2, min=0, max=box_size[0])\n\n            # Convert back to (x_center, y_center, width, height, angle)\n            new_boxes = torch.stack((x1 + (x2 - x1) / 2, y1 + (y2 - y1) / 2, x2 - x1, y2 - y1, a), dim=1)\n            self.tensor[nearly_horizontal] = new_boxes"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "    self.normalize_angles()\n    nearly_horizontal = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n    horizontal_boxes = self.tensor[nearly_horizontal]\n\n    if len(horizontal_boxes) == 0:\n        return\n\n    half_height = horizontal_boxes[:, 3] / 2.0\n    half_width = horizontal_boxes[:, 2] / 2.0\n\n    # Convert from (center x, center y, width, height, angle) to (x1, y1, x2, y2)\n    x1 = horizontal_boxes[:, 0] - half_width\n    y1 = horizontal_boxes[:, 1] - half_height\n    x2 = horizontal_boxes[:, 0] + half_width\n    y2 = horizontal_boxes[:, 1] + half_height\n\n    # Clamp x and y coordinates to ensure they do not exceed the specified box_size limits\n    x1 = torch.clamp(x1, min=0, max=box_size[1])\n    x2 = torch.clamp(x2, min=0, max=box_size[1])\n    y1 = torch.clamp(y1, min=0, max=box_size[0])\n    y2 = torch.clamp(y2, min=0, max=box_size[0])\n\n    # Convert back to original representation\n    new_width = x2 - x1\n    new_height = y2 - y1\n    new_x = x1 + new_width / 2\n    new_y = y1 + new_height / 2\n\n    horizontal_boxes[:, 0] = new_x\n    horizontal_boxes[:, 1] = new_y\n    horizontal_boxes[:, 2] = new_width\n    horizontal_boxes[:, 3] = new_height\n\n    self.tensor[nearly_horizontal] = horizontal_boxes"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "    self.normalize_angles()\n    nearly_horizontal = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n    horizontal_boxes = self.tensor[nearly_horizontal]\n\n    if len(horizontal_boxes) > 0:\n        horizontal_boxes[:, 4] = horizontal_boxes[:, 4] * (math.pi / 180.0)  # Convert angle to radians\n        h = horizontal_boxes[:, 3] / 2.0\n        w = horizontal_boxes[:, 2] / 2.0\n\n        # Calculate the coordinates of the corners\n        y1 = horizontal_boxes[:, 1] - h\n        y2 = horizontal_boxes[:, 1] + h\n        x1 = horizontal_boxes[:, 0] - w\n        x2 = horizontal_boxes[:, 0] + w\n\n        # Clamp the coordinates to fit within the box size\n        y1 = torch.clamp(y1, 0, box_size[0])\n        y2 = torch.clamp(y2, 0, box_size[0])\n        x1 = torch.clamp(x1, 0, box_size[1])\n        x2 = torch.clamp(x2, 0, box_size[1])\n\n        # Update the box tensor with the clipped coordinates\n        horizontal_boxes[:, 0] = (x1 + x2) / 2.0\n        horizontal_boxes[:, 1] = (y1 + y2) / 2.0\n        horizontal_boxes[:, 2] = x2 - x1\n        horizontal_boxes[:, 3] = y2 - y1\n\n        horizontal_boxes[:, 4] = horizontal_boxes[:, 4] * (180.0 / math.pi)  # Convert angle back to degrees\n\n        # Update the original tensor with the modified horizontal boxes\n        self.tensor[nearly_horizontal] = horizontal_boxes"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        nearly_horizontal = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n        if nearly_horizontal.any():\n            # Convert to (x1, y1, x2, y2)\n            boxes = self.tensor.clone()\n            boxes[nearly_horizontal, 4] = 0.0\n            x, y, w, h, a = boxes[nearly_horizontal].unbind(1)\n            cos_theta = torch.cos(a * math.pi / 180)\n            sin_theta = torch.sin(a * math.pi / 180)\n            # Convert to (x1, y1, x2, y2)\n            x1 = x - w / 2\n            y1 = y - h / 2\n            x2 = x + w / 2\n            y2 = y + h / 2\n            # Clamp x1, y1, x2, y2\n            x1 = x1.clamp(min=0, max=box_size[1])\n            y1 = y1.clamp(min=0, max=box_size[0])\n            x2 = x2.clamp(min=0, max=box_size[1])\n            y2 = y2.clamp(min=0, max=box_size[0])\n            # Convert back to (x_center, y_center, width, height, angle)\n            x = (x1 + x2) / 2\n            y = (y1 + y2) / 2\n            w = x2 - x1\n            h = y2 - y1\n            a = torch.atan2(sin_theta, cos_theta) * 180 / math.pi\n            boxes[nearly_horizontal] = torch.stack((x, y, w, h, a), dim=1)\n            self.tensor[nearly_horizontal] = boxes[nearly_horizontal]"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        nearly_horizontal_boxes = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n        for i in range(len(self.tensor)):\n            if nearly_horizontal_boxes[i]:\n                x_c, y_c, w, h, angle = self.tensor[i]\n                x1 = x_c - w / 2\n                y1 = y_c - h / 2\n                x2 = x_c + w / 2\n                y2 = y_c + h / 2\n                x1_clipped = max(0, min(x1, box_size[1]))\n                y1_clipped = max(0, min(y1, box_size[0]))\n                x2_clipped = max(0, min(x2, box_size[1]))\n                y2_clipped = max(0, min(y2, box_size[0]))\n                self.tensor[i] = torch.tensor([x1_clipped, y1_clipped, x2_clipped, y2_clipped, angle])"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n\n        nearly_horizontal = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n        if nearly_horizontal.any():\n            boxes = self.tensor[nearly_horizontal]\n            # Convert to (x1, y1, x2, y2)\n            # x1 = x_center - width / 2, y1 = y_center - height / 2\n            # x2 = x_center + width / 2, y2 = y_center + height / 2\n            x1 = boxes[:, 0] - boxes[:, 2] / 2\n            y1 = boxes[:, 1] - boxes[:, 3] / 2\n            x2 = boxes[:, 0] + boxes[:, 2] / 2\n            y2 = boxes[:, 1] + boxes[:, 3] / 2\n\n            # Clamp x and y coordinates to box_size limits\n            x1 = torch.clamp(x1, 0, box_size[1])\n            y1 = torch.clamp(y1, 0, box_size[0])\n            x2 = torch.clamp(x2, 0, box_size[1])\n            y2 = torch.clamp(y2, 0, box_size[0])\n\n            # Convert back to (x_center, y_center, width, height, angle)\n            new_boxes = torch.stack([(x2 - x1) / 2, (y2 - y1) / 2, x2 - x1, y2 - y1, boxes[:, 4]], dim=1)\n            self.tensor[nearly_horizontal] = new_boxes"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        types_count = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n\n        for item in self.data:\n            if 'type' in item:\n                types_count[item['type']] += 1\n\n        return types_count"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            if 'type' in item:\n                statistics[item['type']] += 1\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        types_count = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n\n        for item in self.data:\n            if 'type' in item:\n                types_count[item['type']] += 1\n\n        return types_count"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        types_count = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            if 'type' in item:\n                types_count[item['type']] += 1\n        return types_count"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        type_count = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n\n        for item in self.data:\n            if 'type' in item:\n                type_count[item['type']] += 1\n\n        return type_count"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        types_count = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n\n        for item in self.data:\n            if 'type' in item:\n                types_count[item['type']] += 1\n\n        return types_count"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        type_count = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n\n        for item in self.data:\n            if 'type' in item:\n                if item['type'] in type_count:\n                    type_count[item['type']] += 1\n\n        return type_count"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        type_counts = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            if 'type' in item:\n                type_counts[item['type']] += 1\n        return type_counts"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        type_counts = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n\n        for item in self.data:\n            if 'type' in item:\n                type_counts[item['type']] += 1\n\n        return type_counts"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            if 'type' in item:\n                statistics[item['type']] += 1\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        type_counts = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            if 'type' in item:\n                type_counts[item['type']] += 1\n        return type_counts"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            if 'type' in item:\n                statistics[item['type']] += 1\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            if 'type' in item:\n                statistics[item['type']] += 1\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            if 'type' in item:\n                statistics[item['type']] += 1\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        type_counts = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n\n        for item in self.data:\n            if 'type' in item:\n                type_counts[item['type']] += 1\n\n        return type_counts"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            if item['type'] == 'doc':\n                statistics['doc'] += 1\n            elif item['type'] == 'gen':\n                statistics['gen'] += 1\n            elif item['type'] == 'kno':\n                statistics['kno'] += 1\n            elif item['type'] == 'num':\n                statistics['num'] += 1\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n\n        for item in self.data:\n            if 'type' in item:\n                if item['type'] == 'doc':\n                    statistics['doc'] += 1\n                elif item['type'] == 'gen':\n                    statistics['gen'] += 1\n                elif item['type'] == 'kno':\n                    statistics['kno'] += 1\n                elif item['type'] == 'num':\n                    statistics['num'] += 1\n\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n\n        for item in self.data:\n            if 'type' in item:\n                if item['type'] == 'doc':\n                    statistics['doc'] += 1\n                elif item['type'] == 'gen':\n                    statistics['gen'] += 1\n                elif item['type'] == 'kno':\n                    statistics['kno'] += 1\n                elif item['type'] == 'num':\n                    statistics['num'] += 1\n\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        types_count = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n\n        for item in self.data:\n            if 'type' in item:\n                types_count[item['type']] += 1\n\n        return types_count"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n\n        for item in self.data:\n            if 'type' in item:\n                if item['type'] == 'doc':\n                    statistics['doc'] += 1\n                elif item['type'] == 'gen':\n                    statistics['gen'] += 1\n                elif item['type'] == 'kno':\n                    statistics['kno'] += 1\n                elif item['type'] == 'num':\n                    statistics['num'] += 1\n\n        return statistics"}
{"namespace": "common.bleu4_score", "completion": "    if with_penalty:\n        return evaluate.bleu_score(continuation, reference, 4)\n    else:\n        return evaluate.bleu_score(continuation, reference, 4, penalty=False)"}
{"namespace": "common.bleu4_score", "completion": "\n    if with_penalty:\n        bleu_score = evaluate.bleu(continuation, reference, 4, True)\n    else:\n        bleu_score = evaluate.bleu(continuation, reference, 4, False)\n\n    return bleu_score"}
{"namespace": "common.bleu4_score", "completion": "\n    # Tokenize the input texts using a custom tokenizer function\n    continuation_tokens = jieba.lcut(continuation)\n    reference_tokens = jieba.lcut(reference)\n\n    # Compute the BLEU-4 score using the tokenized texts\n    bleu_score = evaluate.bleu(continuation_tokens, [reference_tokens], 4)\n\n    # Optionally adjust the BLEU-4 score for brevity penalty\n    if with_penalty:\n        brevity_penalty = min(1, len(continuation_tokens) / len(reference_tokens))\n        bleu_score *= brevity_penalty\n\n    return bleu_score"}
{"namespace": "common.bleu4_score", "completion": "\n    # Tokenize the input texts using a custom tokenizer function\n    continuation_tokens = jieba.lcut(continuation)\n    reference_tokens = jieba.lcut(reference)\n\n    # Compute the BLEU-4 score\n    bleu_score = evaluate.bleu(continuation_tokens, reference_tokens, 4)\n\n    # Optionally adjust the score for brevity penalty\n    if with_penalty:\n        brevity_penalty = min(1, len(continuation_tokens) / len(reference_tokens))\n        bleu_score *= brevity_penalty\n\n    return bleu_score"}
{"namespace": "common.bleu4_score", "completion": "\n    if with_penalty:\n        return evaluate.bleu4_score_with_penalty(continuation, reference)\n    else:\n        return evaluate.bleu4_score_without_penalty(continuation, reference)"}
{"namespace": "common.bleu4_score", "completion": "\n    def custom_tokenizer(text: str) -> list:\n        return list(jieba.cut(text))\n\n    if with_penalty:\n        bleu_score = evaluate.bleu_score(continuation, reference, tokenizer=custom_tokenizer, use_bp=True)\n    else:\n        bleu_score = evaluate.bleu_score(continuation, reference, tokenizer=custom_tokenizer, use_bp=False)\n\n    return bleu_score"}
{"namespace": "common.bleu4_score", "completion": "\n    # Tokenize the input texts using a custom tokenizer function\n    continuation_tokens = jieba.lcut(continuation)\n    reference_tokens = jieba.lcut(reference)\n\n    # Compute the BLEU-4 score using the tokenized texts\n    bleu_score = evaluate.bleu(continuation_tokens, [reference_tokens], 4)\n\n    # Optionally adjust the score for brevity penalty\n    if with_penalty:\n        brevity_penalty = min(1, len(continuation_tokens) / len(reference_tokens))\n        bleu_score *= brevity_penalty\n\n    return bleu_score"}
{"namespace": "common.bleu4_score", "completion": "\n    tokenizer: Callable[[str], list] = lambda x: jieba.lcut(x)\n    similarity = Similarity(tokenizer=tokenizer)\n    bleu_score = evaluate.bleu_score(continuation, reference, n_gram=4, similarity=similarity, with_penalty=with_penalty)\n    return bleu_score"}
{"namespace": "common.bleu4_score", "completion": "\n    # Tokenize the input texts using a custom tokenizer function\n    continuation_tokens = jieba.lcut(continuation)\n    reference_tokens = jieba.lcut(reference)\n\n    # Calculate BLEU-4 score\n    bleu_score = evaluate.bleu(continuation_tokens, [reference_tokens], 4)\n\n    # Optionally adjust for brevity penalty\n    if with_penalty:\n        brevity_penalty = min(1, len(continuation_tokens) / len(reference_tokens))\n        bleu_score *= brevity_penalty\n\n    return bleu_score"}
{"namespace": "common.bleu4_score", "completion": "    if with_penalty:\n        return evaluate.bleu(continuation, reference, 4, True)\n    else:\n        return evaluate.bleu(continuation, reference, 4, False)"}
{"namespace": "common.bleu4_score", "completion": "    # Tokenize the input texts using a custom tokenizer function\n    continuation_tokens = jieba.lcut(continuation)\n    reference_tokens = jieba.lcut(reference)\n\n    # Compute the BLEU-4 score using the tokenized texts\n    bleu_score = evaluate.bleu(continuation_tokens, [reference_tokens], 4)\n\n    # Optionally adjust the score for brevity penalty\n    if with_penalty:\n        brevity_penalty = min(1, len(continuation_tokens) / len(reference_tokens))\n        bleu_score *= brevity_penalty\n\n    return bleu_score"}
{"namespace": "common.bleu4_score", "completion": "\n    tokenizer: Callable[[str], list[str]] = lambda text: list(jieba.cut(text))\n\n    score = evaluate.bleu_score(\n        [reference.split()],\n        continuation.split(),\n        weights=(0.25, 0.25, 0.25, 0.25)\n    )\n\n    if with_penalty:\n        similarity = Similarity()\n        brevity_penalty = similarity.brevity_penalty(continuation, reference)\n        score *= brevity_penalty\n\n    return score"}
{"namespace": "common.bleu4_score", "completion": "    # Tokenize the input texts using a custom tokenizer function\n    continuation_tokens = jieba.lcut(continuation)\n    reference_tokens = jieba.lcut(reference)\n\n    # Compute the BLEU-4 score\n    bleu_score = evaluate.bleu(continuation_tokens, [reference_tokens], 4)\n\n    # Optionally adjust for brevity penalty\n    if with_penalty:\n        brevity_penalty = min(1, len(continuation_tokens) / len(reference_tokens))\n        bleu_score *= brevity_penalty\n\n    return bleu_score"}
{"namespace": "common.bleu4_score", "completion": "\n    # Tokenize the input texts using a custom tokenizer function\n    continuation_tokens = list(jieba.cut(continuation))\n    reference_tokens = list(jieba.cut(reference))\n\n    # Compute BLEU-4 score\n    bleu_score = evaluate.bleu(continuation_tokens, [reference_tokens], 4)\n\n    # Optionally adjust for brevity penalty\n    if with_penalty:\n        brevity_penalty = min(1, len(continuation_tokens) / len(reference_tokens))\n        bleu_score *= brevity_penalty\n\n    return bleu_score"}
{"namespace": "common.bleu4_score", "completion": "\n    # Tokenize the input texts using a custom tokenizer function\n    continuation_tokens = jieba.lcut(continuation)\n    reference_tokens = jieba.lcut(reference)\n\n    # Compute the BLEU-4 score using the tokenized texts\n    bleu_score = evaluate.bleu(continuation_tokens, [reference_tokens], 4)\n\n    # Optionally adjust the score for brevity penalty\n    if with_penalty:\n        brevity_penalty = min(1, len(continuation_tokens) / len(reference_tokens))\n        bleu_score *= brevity_penalty\n\n    return bleu_score"}
{"namespace": "common.bleu4_score", "completion": "\n    if with_penalty:\n        score = evaluate.bleu4(continuation, reference, tokenize=jieba.cut)\n    else:\n        score = evaluate.bleu4(continuation, reference, tokenize=jieba.cut, use_effective_order=True)\n\n    return score"}
{"namespace": "common.bleu4_score", "completion": "    # Tokenize the input texts using a custom tokenizer function\n    continuation_tokens = jieba.lcut(continuation)\n    reference_tokens = jieba.lcut(reference)\n\n    # Compute the BLEU-4 score using the tokenized texts\n    bleu_score = evaluate.bleu(continuation_tokens, [reference_tokens], 4)\n\n    # Optionally adjust the score for brevity penalty\n    if with_penalty:\n        brevity_penalty = min(1, len(continuation_tokens) / len(reference_tokens))\n        bleu_score *= brevity_penalty\n\n    return bleu_score"}
{"namespace": "common.bleu4_score", "completion": "\n    # Tokenize the input texts using a custom tokenizer function\n    continuation_tokens = jieba.lcut(continuation)\n    reference_tokens = jieba.lcut(reference)\n\n    # Compute the BLEU-4 score using the tokenized texts\n    bleu_score = evaluate.bleu(continuation_tokens, [reference_tokens], 4)\n\n    # Optionally adjust the score for brevity penalty\n    if with_penalty:\n        brevity_penalty = min(1, len(continuation_tokens) / len(reference_tokens))\n        bleu_score *= brevity_penalty\n\n    return bleu_score"}
{"namespace": "common.bleu4_score", "completion": "\n    # Tokenize the input texts using a custom tokenizer function\n    continuation_tokens = jieba.lcut(continuation)\n    reference_tokens = jieba.lcut(reference)\n\n    # Compute the BLEU-4 score\n    bleu_score = evaluate.bleu(continuation_tokens, [reference_tokens], 4)\n\n    # Optionally adjust for brevity penalty\n    if with_penalty:\n        brevity_penalty = min(1, len(continuation_tokens) / len(reference_tokens))\n        bleu_score *= brevity_penalty\n\n    return bleu_score"}
{"namespace": "common.bleu4_score", "completion": "    # Tokenize the input texts using a custom tokenizer function\n    continuation_tokens = jieba.lcut(continuation)\n    reference_tokens = jieba.lcut(reference)\n\n    # Compute the BLEU-4 score using the tokenized texts\n    bleu_score = evaluate.bleu(continuation_tokens, reference_tokens, n=4)\n\n    # Optionally adjust the score for brevity penalty\n    if with_penalty:\n        brevity_penalty = min(1, len(continuation_tokens) / len(reference_tokens))\n        bleu_score *= brevity_penalty\n\n    return bleu_score"}
{"namespace": "common.rougeL_score", "completion": "\n    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeL']\n    return score"}
{"namespace": "common.rougeL_score", "completion": "\n    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeL']\n    return score"}
{"namespace": "common.rougeL_score", "completion": "\n    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeL']\n    return score"}
{"namespace": "common.rougeL_score", "completion": "\n    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeL']\n    return score"}
{"namespace": "common.rougeL_score", "completion": "\n    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeL']\n    return score"}
{"namespace": "common.rougeL_score", "completion": "\n    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeL']\n    return score"}
{"namespace": "common.rougeL_score", "completion": "\n    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeL']\n    return score"}
{"namespace": "common.rougeL_score", "completion": "\n    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeL']\n    return score"}
{"namespace": "common.rougeL_score", "completion": "\n    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeL']\n    return score"}
{"namespace": "common.rougeL_score", "completion": "\n    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeL']\n    return score"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeL']\n    return score"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeL']\n    return score"}
{"namespace": "common.rougeL_score", "completion": "\n    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeL']\n    return score"}
{"namespace": "common.rougeL_score", "completion": "\n    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeL']\n    return score"}
{"namespace": "common.rougeL_score", "completion": "\n    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeL']\n    return score"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeL']\n    return score"}
{"namespace": "common.rougeL_score", "completion": "\n    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeL']\n    return score"}
{"namespace": "common.rougeL_score", "completion": "\n    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeL']\n    return score"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeL']\n    return score"}
{"namespace": "common.rougeL_score", "completion": "\n    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeL']\n    return score"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing command: {cmd}\")  # Print the command before executing\n    return os.system(cmd)  # Use the system's command line interface to run the command and return the exit status"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)"}
